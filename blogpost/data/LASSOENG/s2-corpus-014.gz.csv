title,abstract,year,journal
Private Empirical Risk Minimization Beyond the Worst Case: The Effect of the Constraint Set Geometry,"Empirical Risk Minimization (ERM) is a standard technique in machine learning, where a model is selected by minimizing a loss function over constraint set. When the training dataset consists of private information, it is natural to use a differentially private ERM algorithm, and this problem has been the subject of a long line of work started with Chaudhuri and Monteleoni 2008. A private ERM algorithm outputs an approximate minimizer of the loss function and its error can be measured as the difference from the optimal value of the loss function. When the constraint set is arbitrary, the required error bounds are fairly well understood~\cite{BassilyST14}. In this work, we show that the geometric properties of the constraint set can be used to derive significantly better results. Specifically, we show that a differentially private version of Mirror Descent leads to error bounds of the form $\tilde{O}(G_{\mathcal{C}}/n)$ for a lipschitz loss function, improving on the $\tilde{O}(\sqrt{p}/n)$ bounds in Bassily, Smith and Thakurta 2014. Here $p$ is the dimensionality of the problem, $n$ is the number of data points in the training set, and $G_{\mathcal{C}}$ denotes the Gaussian width of the constraint set that we optimize over. We show similar improvements for strongly convex functions, and for smooth functions. In addition, we show that when the loss function is Lipschitz with respect to the $\ell_1$ norm and $\mathcal{C}$ is $\ell_1$-bounded, a differentially private version of the Frank-Wolfe algorithm gives error bounds of the form $\tilde{O}(n^{-2/3})$. This captures the important and common case of sparse linear regression (LASSO), when the data $x_i$ satisfies $|x_i|_{\infty} \leq 1$ and we optimize over the $\ell_1$ ball. We show new lower bounds for this setting, that together with known bounds, imply that all our upper bounds are tight.",2014,ArXiv
"Continuous plankton records: The distribution of the Euphausiacea (Crustacea: Malacostraca) in the north Atlantic and the North Sea, 1966-1967","An account is given of the occurrence of nineteen species of euphausiids taken at a depth of 10 m in the survey of the north Atlantic and the North Sea with Continuous Plankton Recorders in 1966 and 1967. The distri- butions of seventeen species recorded north of 41 ON are illustrated and interpreted with reference to the current systems and the bathymetry of the area. Most species occurred mainly or entirely over deeper waters beyond the edge of the continental shelf. Several (e.g. Euphausia hemigibba) occurred exclusively in the warm, highly saline waters of the Gulf Stream, to the south and east of Newfoundland. Others (e.g. Euphausia krohni) were widely distributed in the warm North Atlantic Current. Meganyctiphanes norvegica was most abundant over the continental slopes and oceanic ridges in the north-eastern Atlantic, low temperature limiting its occurrence in the west. Thysanoessa longicaudata and Thysanopoda acutifrons were most abundant in the colder waters of the Labrador-Irminger Gyre. Three species had neritic distributions: Thysanoessa inermis and T. raschi in colder northern coastal waters on both sides of the Atlantic, and Nyctiphanes couchi in warmer waters on the European coasts. Five parasites of euphausiids were found: Thalassomyces fagei, Anisakis sp. larvae, Ascarophis sp. larva, acanthocephalan larvae and Heterophryxus appendi-",1977,Journal of Biogeography
Acute neurologic complications of hemodialysis,"We have examined and subjected to statistical analysis the transient acute neurological complications arising in the course of hemodialysis in 103 patients with chronic renal failure (13,969 hemodialysis sessions).Our data show that such complications are multiform. Some of the symptoms are aspecific: headache, nausea and/or vomiting, muscle cramps. We have found these symptoms in over 96% of patients, often combined with extraneurological symptoms and phenomena, such as cardiocirculatory shock or increased blood pressure.The other symptoms denote real cerebral impairment: convulsions, consciousness disturbances, psychomotor agitation. They are present in 36% of the patients, but only 10.5% of the patients show a combination of at least two symptoms. In these patients the so-called â€œDisequilibrium syndromeâ€ is present: its percentage in our case-series is similar to that reported in leterature.SommarioAbbiamo censito e sottoposto ad indagine statistica le complicanze neurologiche acute transitorie insorgenti nel corso di emodialisi in 103 pazienti con insufficienza renale cronica (sono state esaminate 13.969 emodialisi).Dai nostri dati risulta che tali complicanze consistono di una sintomatologia multiforme: parte dei sintomi presentati dai pazienti sono aspecifici (cefalea, nausea e/o vomito, crampi muscolari). Sono presenti in oltre il 96% dei pazienti, associati a sintomi e fenomeni extraneurologici, quali collasso circolatorio o aumento di pressione arteriosa).Altri sintomi denotanti una vera compromissione cerebrale (convulsioni, disturbi di coscienza, agitazione psicomotoria) sono meno frequenti (compaiono nel 36% dei pazienti) e solo il 10,5% dei soggetti presenta un'associazione di almeno due di questi sintomi, configurando una â€œSindrome da disequilibrioâ€, con percentuale, nel nostro campione, analoga a quella riferita in letteratura.",2006,The Italian Journal of Neurological Sciences
Adaptive LASSO Estimation for ARDL Models with GARCH Innovations,"In this paper, we show the validity of the adaptive least absolute shrinkage and selection operator (LASSO) procedure in estimating stationary autoregressive distributed lag(p,q) models with innovations in a broad class of conditionally heteroskedastic models. We show that the adaptive LASSO selects the relevant variables with probability converging to one and that the estimator is oracle efficient, meaning that its distribution converges to the same distribution of the oracle-assisted least squares, i.e., the least square estimator calculated as if we knew the set of relevant variables beforehand. Finally, we show that the LASSO estimator can be used to construct the initial weights. The performance of the method in finite samples is illustrated using Monte Carlo simulation.",2017,Econometric Reviews
Predictive analysis of heat transfer characteristics of nanofluids in helically coiled tube heat exchanger using regression approach,"Nanofluids are the combination of base fluid and nanoparticles which offer 
 higher thermal conductivity resulting higher heat transfer. In this research 
 article, soft computing tool is used to find the accurate Nusselt number of 
 coiled tube heat exchanger handling Al2O3/H2O nanofluids at three different 
 volume concentrations and at different mass flow rate in terms of Dean 
 number (De). The input predictor variables used in this model are convective 
 heat transfer coefficient, thermal conductivity of nanofluids and Dean 
 number and the output response variable is Nusselt number. Linear 
 Regression (LM), Generalized Linear Regression (GLM) and Lasso and 
 Elastic-Net Regularized Generalized Linear Models (GLM_NET) methodologies 
 are taken to predict the Nusselt number. It is observed that the linear 
 regression method shows an accurate agreement with experimental data with 
 Root Mean Square Error (RMSE) value of 0.05614 and regression coefficient 
 value (R2) is 0.99. It is studied that the experimental data holds good 
 accordance with the predicted data given by the trained network. The average 
 relative errors in the prediction of Nusselt number and heat transfer 
 coefficients are found to be 0.3% and 0.2%, respectively.",2020,Thermal Science
Equivalence of graphical lasso and thresholding for sparse graphs,"This paper is concerned with the problem of finding a sparse graph capturing the conditional dependence between the entries of a Gaussian random vector, where the only available information is a sample correlation matrix. A popular approach is to solve a graphical lasso problem with a sparsity-promoting regularization term. This paper derives a simple condition under which the computationally-expensive graphical lasso behaves the same as the simple heuristic method of thresholding. This condition depends only on the solution of graphical lasso and makes no direct use of the sample correlation matrix or the regularization coefficient. It is also proved that this condition is always satisfied if the solution of graphical lasso is replaced by its first-order Taylor approximation. The condition is tested on several random problems and it is shown that graphical lasso and the thresholding method (based on the correlation matrix) lead to a similar result (if not equivalent), provided the regularization term is high enough to seek a sparse graph.",2014,"2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton)"
Proton scattering radiography using an emulsion detector: a feasibility study,"A least absolute shrinkage and selection operator (LASSO) method was used for feature selection. Model performance was evaluated using Harrellâ€™s concordance-index (c-index). Fitted model included sum entropy (GLCM), high intensity large area emphasis (GLSZM), volume with a minimum relative intensity of 60% of the maximum SUV â€“ AVRI60% (IVH), grey level non-uniformity and long run emphasis (RLGL) and volume (shape) â€“ Table 1. Internal performance of the model was 0.64 (p<0.01), while externally it achieved a performance of 0.61 (p = 0.05) and 0.58 (0.20), with no further calibration done. Maximum and mean SUV had a univariable performance in the training data of 0.51 and 0.55, respectively. The reduced accuracy of the model validation can be associated with dissimilarities among data, particularly the different timing and delivered dose of the second scan. Nevertheless, we do see benefit on a timely assessment of response to radiotherapy using the described imaging analysis, particularly when compared with the limited capacity of humans to infer accurate predictions and risk groups identification (5). From the Radiomics analysis one can optimally benefit from early response metrics based on changes in metabolism measured with FDG-PET, even before anatomic changes become noticeable, while treatment can still be adapted. We developed and validated a predictive model on the percentage variation of Radiomics features, the so-called â€œDelta Radiomicsâ€ concept, from repeated FDG-PET scans of NSCLC patients.",2016,
Regularized Partial Phase Synchrony Index Applied to Dynamical Functional Connectivity Estimation,"We study the inference of conditional independence graph from the partial Phase Locking Value (PLV) index of mul-tivariate time series. A typical application is the inference of temporal functional connectivity from brain data. We extend the recently proposed time-varying graphical lasso to the measurement of partial locking values, yielding a sparse and temporally coherent dynamical graph that characterizes the evolution of the phase synchrony between each pair of signals. Cast as an optimization problem, we solve it using the alternating direction method of multipliers. The approach is validated on simulated Gaussian multivariate signals and Roessler oscillators. The potential of this regularized partial PLV is then illustrated on actual iEEG data during an epileptic seizure.",2020,
"Kondisi Dan Strategis Pengelolaan Komunitas Padang Lamun Di Wilayah Pesisir Kota Denpasar, Provinsi Bali","A study on condition and management strategy for sea grass community was undertaken on the beach area of Denpasar City, Bali Province between March and June, 2010. The study was undertaken on two locations: Sanur and Serangan beaches. Aim of the study was to find out recent condition, problems related to sea grass and set up its management strategy. The study was utilising Transect Plot methods. Six sampling stations was determined. Identification of condition and degradation of sea grass community was undertaken by retrospective approaches. Data analyses was undertaken by utilising kualitative and kuantitative approaches; refering to determination of Ã¢â‚¬Å“Kriteria Baku Kerusakan dan Pedoman Penentuan Status Padang LamunÃ¢â‚¬Â (the standard criteria for damage and manual for determination of the status of sea grass) refering to Decission of State Minister on Environment Number 200 year 2004 and cualitative ecology index and analogist comparative approach on formulating management strategy. Species richness of sea grass on beaches of Denpasar city was 10 out of 12 of those existed in Indonesia, namely: Zostera sp., Halodule pinifolia, Halodule uninervis, Cymodocea rotundata, Cymodocea serrulata, Syringodium isoetifolium, Thalassodendron ciliatum, Enhalus acoroides, Halophila ovalis and Thalassia hemprichii. Species density of sea grass varied across locations and observation stations, ie. Sanur beach (209 individual/sq.m) and Serangan Island (276 ind/sq.m); with the higest density made by Cymodocea rotundata. Persentage of sea grass cover on the beach of Denpasar was between 28.79% Ã¢â‚¬â€œ 42.74%, with the highest at Serangan-III and the lowest at Sanur-I. Based on the cover, the status of condition of sea grass on the beach area of Denpasar was classified into the category of bad/poor -moderate/less healthy. The average score of level of damage of sea grass on the beach area of Denpasar varied between 8.89 % Ã¢â‚¬â€œ 15.79 %, which was within the category of low level of damage, where the highest level of damage was at Station I of Ã¢â‚¬Å“Perairan SeranganÃ¢â‚¬Â and the lowest at Serangan II-III, where there were no damage reported to occur. The change in domination of sea grass in Sanur and Serangan from Enhalus acoroides into Cymodocea rotundata and Thalassia hemprichii was observed because the change in the texture of substrate after reclamation of the beach and sedimentation. Human activities which caused damage of sea grass on Sanur and Serangan beaches such as anchoring the fishermanÃ¢â‚¬â„¢s canoes, propeler boats, crib constructions, break water and beach reclamations. For keeping the sea grass ecosystem of Denpasar sustainable, it is recommended for a better management of beaches/sea on the area where sea grass grows and implementing strategy of integrated management of sea grass with integrated coastal and sea management.",2011,
PAPER How do islands become green,"Aim Four long-distance dispersal (LDD) modes have generally been considered to play central roles in the colonization of islands by plants: anemochory (dispersal by wind), thalassochory (dispersal by oceanic currents), endozoochory (internal dispersal by animals) and epizoochory (external dispersal by animals).However,seeds can also be transported by vectors different from those to which they are best suited (non-standard dispersal), meaning that the actual vector of colonization cannot be inferred based on diaspore traits alone. We propose an alternative approach to explore the relative contribution of LDD syndromes to island colonization. Location Europe and the Azores. Methods We scored the presence of syndromes relevant for LDD in the native flora of Europe (c.10,000 species) and the Azores (148 species).We then contrasted the importance of each syndrome in the recipient flora (Azores) and the source floras (Europe and mainland Portugal) to estimate which, if any, syndrome was particularly successful for overseas colonization. We further investigated whether particular LDD syndromes increased plant distribution within the Azores archipelago. Results Most native species in Europe (63%), mainland Portugal (67%) and the Azores (63%) produce unspecialized diaspores. Only species adapted to sea dispersal were overrepresented in the Azores, while those adapted to wind dispersal were underrepresented. The presence of LDD syndromes did not significantly improve the distribution of plant species across the archipelago, except for the moderate advantage of endozoochorous diaspores. Differences in the importance of LDD syndromes across plant families at least partially explain the floristic disharmony of the Azorean flora.",2014,
O n the schem e dependence ofgravitationalbeta functions,"W e discussthearbitrarinessin the choiceofcutoschem ein calculationsofbeta functions.W edene a classof\pure"" cutoschem es,in which thecutoiscom pletely independentoftheparam etersthatappear in theaction.In a sensethey areattheoppositeextrem eofthe\spectrally adjusted"" cutos,which depend on alltheparam etersthatappearin theaction.W ecom paretheresultsforthebeta functionsofNewton's constantand ofthecosm ologicalconstantobtained with a typicalcutoand with a purecutoï¿½,keeping all elsexed. W end thatthe dependence ofthexed pointon an arbitrary param eterin the pure cutois ratherm ild.W e then show in generalthatifa spectrally adjusted cutoproducesaxed point,thereisa corresponding purecutothatwillgiveaxed pointin thesam eposition.",2009,
"Sperm and milt characteristics and male v. female gametic investment in the Caribbean reef fish, Thalassoma bifasciatum","Individual sperm cells produced by two male morphs of the bluehead wrasse Thalassoma bifasciatum did not differ in size (i.e. cell volume). Initial phase (IP) males (high sperm competition) had a 60% higher sperm concentration in their milt than did terminal phase (TP) males (low sperm competition), which may reflect differences in how accurately the two male morphs need to allocate sperm to their spawns. The energy density of milt was about 16% lower than that of eggs. Estimates of gametic energy investment based on (a) the difference in testis weights between the beginning and the end of the spawning period and (b) the number of sperm released in natural spawns (determined in other studies), suggested that, on a daily basis, IP males invest about 65% of that of females. Estimates based on stripping milt from IP males at the beginning and the end of the spawning period, however, indicated that their daily energy investment in gamete production is about 10% of that of females. Gametic investment by TP males is lower than that by both IP males and females.",1999,Journal of Fish Biology
"Las Habilidades LingÃ¼Ã­sticas en el Desarrollo Personal en los niÃ±os de EducaciÃ³n Inicial 2, de la escuela â€œManuel Lasso GuzÃ±ayâ€ cantÃ³n Guamote, provincia de Chimborazo periodo 2014-2015","It has been carried out this research work â€œLanguage skills in chidrenÂ´s personal development of Educacion Inicial 2, of â€œManuel Lasso Guznayâ€ school, in Guamote canton, Chimborazo province, in period 2014-2015. The following objective was found: To determine the impact of the application of language skills to improve the personal development in children of Educacion Inicial 2, of â€œManuel Lasso Guznayâ€ school, in Guamote canton, Chimborazo province, in period 2014-2015. In the theoretical framework are as follows: scientific substantiation.-philosophical, epistemological, psychological, pedagogical, legal; concepts about skills, linguistics, language ability, factors that influence the development of oral language, language functions, language classification, personal and social development. Research is design non-experimental and applicative, transverse type because it considered that it is an obligation to perform a thesis that solutions to the problems encountered. Thirty-two boys and girls were investigated, a document with language skills, with songs, tongue twisters, and riddles were developed, they are common knowledge, which motivated and aroused the interest to fulfill the objectives. Deductive method and observation technique was used; for testing the general hypothesis was took into account the results that are expressed in tables and graphs, and with the percentages obtained from each song, tongue-twisters and riddles was possible to establish critical nodes which must be attended by teachers in this field. Conclusions according to the results and experience gained in research were obtained, with their recommendations. One of them determines that the incidence of language skills through songs is a motivating potential for use in classes so that children can reach levels suitable personal development, even with understanding that it is in early ages that should be pointing to it.",2016,
Partial least squares regression for high dimensional and correlated data,"This thesis focuses on the investigation of partial least squares (PLS) method- ology to deal with high-dimensional correlated data. Current develop- ments in technology have enabled experiments to produce data that are characterised by, first, the number of variables that far exceeds the number of observations and, second, variables that are substantially correlated be- tween them. These types of data are common to be found in, first, chemo- metrics where absorbance levels of chemical samples are recorded across hundreds of wavelengths in a calibration of near-infrared (NIR) spectrom- eter. Second, they are also common to be found in genomics where copy number alterations (CNA) are recorded across thousands of genomic re- gions from cancer patients. PLS is a well-known method to employ in the analysis of high-dimensional data as a regression method in chemo- metric data or as a classification method in genomic data. It deals with those characteristics of the data by constructing latent variables, called components, to represent the original variables. However, there are some challenges in the application of PLS for such analysis and, in this research, there are several areas of investigation that we have performed to deal with them. The first one is that there are three main PLS algorithms with po- tentially different interpretation of relevant quantities. We deal with this problem by consolidating those three algorithms and identify the case in which those three algorithms would give the same estimates. The second one is the unusual negative shrinkage factors (or â€œfilter factorsâ€) that PLS experiences in the model fitting. One of the main reasons PLS can deal with high-dimensional data is that the estimates experience a shrinkage. Unlike ridge regression or principal component regression that experience shrinkage factors between zero and one, PLS can experience shrinkage factors more than one or even negative (hence, more appropriate to be called â€œfilter factorsâ€ than â€œshrinkage factorsâ€). To our knowledge, there has been no previous meaningful investigation on the negative filter fac- tors (NFF) in PLS. In this research we present a novel result whereby we identify the condition for NFF to happen and investigate characteristics of the data that are associated with NFF to get an insight. Lastly, the main challenge of the application of PLS is in the interpretation of weights as- sociated with the predictors. With hundreds and thousands of predictors, each and every predictor variable has non-zero weight. However, we ex- pect that only some predictor variables are contributing to the association with the outcome variable. We therefore resort to the sparse estimation of predictor weights where some weights are zero estimated and the other weights are non-zero. A (standard) lasso estimation has a weakness in dealing with correlated variables as it picks up one variable within a corre- lation â€œblockâ€ without knowing the reason. A novel approach is needed to take into account the dependencies between predictor variables in estimat- ing the weights. We propose a new method where a new penalty function is introduced in the likelihood function associated with the estimation of weights. The penalty function is a combination of a lasso penalty that im- poses sparsity and a penalty based on Cauchy distribution with a smoother matrix to take into account dependencies between genomic regions. The results show that the estimates of the weights are sparse: many weights are zero estimated, and those non-zero estimates are grouped and exhibit smoothness within them. The interpretation on genomic regions becomes easy and identification of important regions for each component can be done simultaneously with prediction in a single modelling framework. We investigate the relation between PLS and graphical modelling using the in- formation in the weights to construct the graph with unsuccessful results.",2019,
WE-E-BRE-05: Ensemble of Graphical Models for Predicting Radiation Pneumontis Risk.,"PURPOSE
We propose a prior knowledge-based approach to construct an interaction graph of biological and dosimetric radiation pneumontis (RP) covariates for the purpose of developing a RP risk classifier.


METHODS
We recruited 59 NSCLC patients who received curative radiotherapy with minimum 6 month follow-up. 16 RP events was observed (CTCAE grade â‰¥2). Blood serum was collected from every patient before (pre-RT) and during RT (mid-RT). From each sample the concentration of the following five candidate biomarkers were taken as covariates: alpha-2-macroglobulin (Î±2M), angiotensin converting enzyme (ACE), transforming growth factor Î² (TGF-Î²), interleukin-6 (IL-6), and osteopontin (OPN). Dose-volumetric parameters were also included as covariates. The number of biological and dosimetric covariates was reduced by a variable selection scheme implemented by L1-regularized logistic regression (LASSO). Posterior probability distribution of interaction graphs between the selected variables was estimated from the data under the literature-based prior knowledge to weight more heavily the graphs that contain the expected associations. A graph ensemble was formed by averaging the most probable graphs weighted by their posterior, creating a Bayesian Network (BN)-based RP risk classifier.


RESULTS
The LASSO selected the following 7 RP covariates: (1) pre-RT concentration level of Î±2M, (2) Î±2M level mid- RT/pre-RT, (3) pre-RT IL6 level, (4) IL6 level mid-RT/pre-RT, (5) ACE mid-RT/pre-RT, (6) PTV volume, and (7) mean lung dose (MLD). The ensemble BN model achieved the maximum sensitivity/specificity of 81%/84% and outperformed univariate dosimetric predictors as shown by larger AUC values (0.78âˆ¼0.81) compared with MLD (0.61), V20 (0.65) and V30 (0.70). The ensembles obtained by incorporating the prior knowledge improved classification performance for the ensemble size 5âˆ¼50.


CONCLUSION
We demonstrated a probabilistic ensemble method to detect robust associations between RP covariates and its potential to improve RP prediction accuracy. Our Bayesian approach to incorporate prior knowledge can enhance efficiency in searching of such associations from data. The authors acknowledge partial support by: 1) CREATE Medical Physics Research Training Network grant of the Natural Sciences and Engineering Research Council (Grant number: 432290) and 2) The Terry Fox Foundation Strategic Training Initiative for Excellence in Radiation Research for the 21st Century (EIRR21).",2014,Medical physics
"Structural Properties Of Faint Milky Way, Dark Matter, Artificial Cognitive Computers Das Ganze Ist Mehr Als Die Summe Seiner Teile: Whole Is Greater Than Sum Of Its Parts : Zitterbewegung And Heiligenschein: Bright Halo And Trembling Motions","structural compatibilities and imperative variabilities of stability analysis and Solutional behaviour of the systems is studied for the system structural properties of faint milky way, dark matter, x, enon100 experiment, artificial cognitive computers, pp and ppb collisions, Shorâ€™s factoring algorithm, decoherence, control, and symmetry, high phi effect, motion perception, waterfall illusion, default perception, neurons' ability to react to new experiences, d-brane cosmology, pure phenomenology, Dasein as being-in-the-world, Daseinâ€™s existence constitutes a branch-point at which it chooses a way to be, the world â€œwith its skin offâ€, Cartesianism, spatiality and pure phenomenology, embodiment and thing hood, being-with, dacd derivatives and g-quadruple dna, fault-tolerant architecture, dynamical decoupling, quantum resource distribution, arbitrary quantum computations, dissipation-assisted quantum computation, constants that produce extant structure of the universe, problem of the continuity or temporalization of consciousness, phenomenology of the consciousness of internal time, Husserlian flux, â€œthe time-constituting flow as absolute subjectivity.â€, structurality of consciousness, flux of a Humean order, pure engaged subject, readiness-to-hand, modes of encounter (Heidegger), 'bundle of impressions' , time consciousness, bounds for the quantity of information, irreversible noise processes, quantum computing and probability, bulk fault-tolerant quantum information processing, surface code quantum computing, Levi strauss paradox, universe signified long before we began to know that what is signifying, outside penetrates and thus determines the insideâ€ (derrida 1988, 152), logic of excision in accounts of generative systems, ontologically permeable boundary between self and non-self, extended cognition, shared forms of cognition that distinguish humans from non-humans, grammatical composition and reflectivity as simulacra, sense of â€œspeculationâ€, â€œuntimely becomingsâ€, swirls in remnants of big bang, twist e modes into b modes by gravitational lensing, b modes from inflation are caused by gravitational waves, â€œspeculative posthumanism.â€, transhumanists dialectics, â€œthe technological singularity,â€, subject and object would â€¦â€¦â€¦..be indissociably related (Meillassoux 2006)., â€œcorrelationism,â€, â€œposthuman impasse.â€, singularity is formally analogous to Kantâ€™s thing-in-itself, epistemic action, demands spread of epistemic credit, cyborgian thinking erases the animate/inanimate distinctionâ€ (Hayles 1999, 84)., â€œcyborg manifestoâ€ gestures beyond the deconstructive obsession with the divided subject (Haraway 1989), relative invariance of interpretation over contexts. The full paper: http://www.iiste.org/PDFshare/APTA-PAGENO-138423-143734.pdf",2013,Advances in Physics Theories and Applications
Virologic and host determinants of breastfeeding transmission of human retroviruses,"Breastfeeding (BF) transmission is responsible for approximately 300,000 new paediatric HIV infections each year. Mechanisms of transmission of HIV by BF are difficult to decipher due to the progressive maturation of the neonate/infant defences and to the evolving content of human milk over different stages of lactation. HIV is distributed and diversifies according to the constraints of anatomic sites. This is particularly true for the mammary gland and breast milk. The portal of entry of HIV on infant's mucosal surface remains largely mysterious. A rabbit model suggests that M cells may transport HIV particles by transcytosis to the lamina propria of Peyer's patches. In an ex vivo human model, HIV enters human enterocyte from HIV-infected cells through an agrindependent viral synapse, is transported by transcytosis across the enterocyte's cytoplasm and delivered in the vicinity of lamina propria. A macaque model suggests that tonsils crypts may behave as portal of entry for SIV. Cellassociated HIV in milk is the source of infection in most of the early transmission events and that free virus in milk is more frequently involved later on. Latently HIV infected T cells in breast milk are considerably more prone to enter viral cycle after ex vivo activation and to produce viral particles than their blood counterparts. This strongly suggests that local microenvironment in milk may favour transcription of integrated viral DNA from latently infected cells and its translation into proteins and new virions. Human milk contains also DCSIGN-expressing monocytes and dendritic cells that are able to transport and propagate R5 viruses in breast milk. It contains also HIVspecific MHC class I-restricted CD8+ Cytotoxic T lymphocytes that may play a role in the clearance of HIVinfected cells in breast milk. Human milk is extraordinary rich in soluble factors, some of them with immunomodulating or antiinfectious properties. Lactoferrin, Lewis X factor, SLPI, Interleukin-7 and Î±defensins have all been suggested either in vitro or in vivo to modulate transmission. Breast milk of HIV infected women contains high concentration of HIV antibodies. HIV-specific secretory IGA and IgM have been associated with an absence of breast milk transmission in some but not all studies. Transmission of HIV by BF is a clearly multifactorial. The exact picture remains unclear but certainly involves a complex intercompartment cell trafficking, fuelled with complex viral populations, and modulated by a richly diversified microenvironment. Knowledge of the mechanisms of mucosal transmission of retroviruses should help designing new preventive interventions. from Fourth Dominique Dormont International Conference. Host-Pathogen Interactions in Chronic Infections Paris, France. 13-15 December 2007",2008,Retrovirology
Kajian Metode Least Absolute Selection and Shrinkage Operator (LASSO) pada Data yang Mengandung Heteroskedastisitas,"MEIRA MAWATI. Study of Least Absolute Selection and Shrinkage Operator (LASSO) Method Under Heteroscedasticity. Under the supervision of KUSMAN SADIK and BAGUS SARTONO. Least Absolute Selection and Shrinkage Operator (LASSO) has been acknowledged to analyse high dimention data to select variables and to estimate parameters. LASSO estimators obtained by minimizing the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Jia et al. (2010), in his research, conducted an analysis on a medical imaging application data using LASSO when error variance of the data suffered heteroscedasticity problem, which is Poisson-like distributed. This research aimed to study the similar problem. LASSO is evaluated by using heteroscedastic regression data. By conducting simulation approach, the result showed that LASSO encountered difficulties. In regression data that has too many zerocoefficients estimator, LASSO is not selective. Compared to OLS (Ordinary Least Square) and Best Subset, LASSO doesnâ€™t offer better solution.",2015,
Solution of l1Minimization Problems by LARS/Homotopy Methods,"Many applications in signal processing lead to the optimization problems min parxpar1 subject to y = Ax, and min parxpar1 subject to pary - Axpar les epsi, where A is a given d times n matrix, d < n, and y is a given n times 1 vector. In this work we consider l1 minimization by using LARS, Lasso, and homotopy methods (Efron et al., Tibshirani, Osborne et al.). While these methods were first proposed for use in statistical model selection, we show that under certain conditions these methods find the sparsest solution rapidly, as opposed to conventional general purpose optimizers which are prohibitively slow. We define a phase transition diagram which shows how algorithms behave for random problems, as the ratio of unknowns to equations and the ratio of the sparsity to equations varies. We find that whenever the number k of nonzeros in the sparsest solution is less than d/2log(n) then LARS/homotopy obtains the sparsest solution in k steps each of complexity O(d2)",2006,2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings
Predicting Mass Incidents from Weibo,"The outbreak of mass incidents severely affects the stability of society. If we can predict mass incidents in advance, we may find the solution to avoid the confliction in time. Some of the existing approaches rely on emotional modeling. Much research has been conducted on microblog incident detection using statistical models, like LASSO regression method, Dynamic Query Expansion DQE and so on. In this paper, we propose to combine sentiment analysis and statistical methods, and uses LASSO regression method for mass incidents prediction. Experiments on Qingdao demonstrated that our proposed approach achieves a good performance.",2016,
Dielectric Spectroscopy of Nanoparticulate Semiconductors in Thin Films,"Very little has been published on dielectric spectra, i.e., a9 (u), a0 (u) (dielectric permittivity and loss, respectively), of thin Â®lms, aside from studies of neat polymeric Â®lms. It also appears that little has been published on the sub-optical dielectric properties of nanoparticulates, particularly thin Â®lms of such nanoparticles. Interestingly, Hamon's dielectric study [1] of relatively large (1 im) copper phthalocyanine particles in parafÂ®n wax is among the `classical' dielectric spectroscopy studies available in the literature, but such studies do not appear to have been followed up in the nanoparticulate semiconductor literature. Very thin Â®lms of nanoparticulate semiconductors, such as antimony-doped tin oxide in this study, can be prepared by coating colloidal dispersions of such nanoparticulates dispersed in aqueous binders such as gelatin or other aqueous dispersible polymers. Such thin Â®lms are useful as antistatic layers in photographic and packaging technology where electrostatic charge dissipation is warranted [2Â±5]. We present here the Â®rst sub-optical dielectric loss spectra for thin Â®lms of nanoparticulates. Using such tin oxide nanoparticulates dispersed with gelatin at several different tin oxide-to-gelatin weight ratios, we have discovered that these thin Â®lm coatings exhibit pronounced peaks in the dielectric loss spectra. These spectra are correlated with surface electrical resistances, and a simple heterogeneous model is used to derive a proportionality relating the loss peak frequency and the thin Â®lm conductivity. Infrared optical properties of nanoparticulate gold by Harris and co-workers [6, 7] have been related to high frequency conductivity, and these measurements have been re-analyzed in terms of conduction on fractal structures by Niklasson and Granqvist [8]. Fractal scaling analysis has also been applied to the analysis of conduction percolation in thin discontinuous Au Â®lms based upon a.c. conductivity measurements over the region of 100 Hz to 10 MHz [9], and a.c. admittances over 0.01 Hz to 10 MHz have been reported by Morris [10] for discontinuous metal thin Â®lms. Roy and co-workers [11] reported frequency-dependent resistivities (100 HzÂ±100 kHz) for sputtered Au-Eikonel (an aromatic polyester) Â®lms and did not report any loss spectra. The nanoparticulate tin oxide used in this work was doped with antimony (8 mol %). This material was obtained from Ishihara Sangyo Kaisha Ltd. (Yokkaichi, Japan) as an aqueous dispersion at 30% (w=w) solids. Particle sizing was done by image analysis of transmission electron micrographs. Although clusters of particles were prevalent, the sizing was done by focusing on the primary particle size (diameters of individual particles in clusters). Thin Â®lms were prepared by using gelatin as a binder and by coating aqueous gelatin and tin oxide colloidal dispersions on a 100 im thick polyethylene terephthalate (PET) support. Thin Â®lms at tin oxideto-gelatin weight ratios of 65=35, 75=25 and 85=15 were prepared by combining the tin oxide colloidal dispersion and aqueous gelatin at these respective solid component ratios and then coating this mixture at 16.1 ml my2 on the PET support. The Â®lms were dried immediately after coating. Surface electrical resistance (SER) in units of U squarey1 was measured after equilibrating the thin Â®lms for 24 h at 5% relative humidity (RH). These SER were obtained by measuring the direct current between two parallel stainless-steel electrodes (25.4 mm long and spaced 6.35 mm apart) held at a potential difference of 200 V, similar to a method described previously [5]. Dielectric spectroscopy was done using an automated Novocontrol system comprising a SolartronÂ± Schlumberger SI 1260 frequency response analyzer and a Chelsea high-impedance pre-ampliÂ®er of variable gain. Heated nitrogen was used to maintain a constant temperature of 25 8C. Circular samples approximately 2.9 cm in diameter were excised from the coatings and placed in the spectrometer bridge circuit between two brass electrodes 2.0 cm and 2.5 cm in diameter, respectively. Measurements of permittivity and dielectric loss were made over the 1 Hz to 1 MHz range. The RH was recorded but not controlled during dielectric measurements. Examination of the doped tin oxide nanoparticulates by transmission electron microscopy (TEM) and image analysis showed that the primary particle size was about 8 nm. TEM of cross-sections (,75 nm thick) of the thin Â®lms suggested that particle aggregation in the dried Â®lms was not uniform. Differential interference contrast light microscopy normal to the thin Â®lms showed that the Â®lm surface appeared fairly uniform over large areas. Atomic force microscopy showed that the surface roughness corresponded to the approximate diameter of the tin oxide particles.",1999,Journal of Materials Science Letters
A new atlantasellid isopod (Asellota: Aselloidea) from the flooded coastal karst of the Dominican Republic (Hispaniola): evidence for an exopod on a thoracic limb and biogeographical,"A new representative of the thus far monotypic, Bermudan aselloid family Atlantasellidae is described from the freshwater layers of two coastal sinkholes on the south-west Dominican Republic, Hispaniola. Atlantasellus dominicanus sp. nov. is extraordinary among isopods in retaining a remnant of the exopod on one of its pereiopods; no other isopod is known to express a schizopodous condition of thoracic limbs. The locomotory behaviour, body volvation habits, and apparent specificity of the new taxon for life on submerged decaying wood in cave waters are described. Analysis of palaeogeographic and ecological evidence supports the interpretation of the Atlantasellidae as a thalassoid lineage, contrary to previous phylogenetically supported assumptions considering them to be an ancient, freshwater lineage.",2001,
Estimation Consistency of Group Lasso with Special Diagonal Matrix,"Group Lasso is an efficient regularized leastsquare regression algorithm, and is now being used as a computationally feasible method to select grouped variables. In this paper, we address the issue of estimation consistency of the group Lasso with special diagonal matrix. We derive sufficient condition for the consistency of group Lasso under practical assumptions, such as model misspecification. This sufficient condition, which depends mainly on the covariance of the predictor variables, states that group Lasso selects the true model consistently if the predictors that are in and not in the true model have low correlation. Specifically, the consistency condition adopts the regularization with special kernel matrix. Experiments are carried out to provide insights and understanding of this result.",2009,2009 Second International Conference on Intelligent Networks and Intelligent Systems
A six-microRNA signature can better predict overall survival of patients with esophagus adenocarcinoma,"Background
The microRNAs (miRNAs) have been validated as prognostic markers in many cancers. Here, we aimed at developing a miRNA-based signature for predicting the prognosis of esophagus adenocarcinoma (EAC).


Methods
The RNA-sequencing data set of EAC was downloaded from The Cancer Genome Atlas (TCGA). Eighty-four patients with EAC were classified into a training set and a test set randomly. Using univariate Cox regression analysis and the least absolute shrinkage and selection operator (LASSO), we identified prognostic factors and constructed a prognostic miRNA signature. The accuracy of the signature was evaluated by the receiver operating characteristic (ROC) curve.


Result
In general, in the training set, six miRNAs (hsa-mir-425, hsa-let-7b, hsa-mir-23a, hsa-mir-3074, hsa-mir-424 and hsa-mir-505) displayed good prognostic power as markers of overall survival for EAC patients. Relative to patients in the low-risk group, those assigned to the high-risk group according to their risk scores of the designed miRNA model displayed reduced overall survival. This 6-miRNA model was validated in test and entire set. The area under curve (AUC) for ROC at 3 years was 0.959, 0.840, and 0.868 in training, test, and entire set, respectively. Molecular functional analysis and pathway enrichment analysis indicated that the target messenger RNAs associated with 6-miRNA signature were closely related to several pathways involved in carcinogenesis, especially cell cycle.


Conclusion
In summary, a novel 6-miRNA expression-based prognostic signature derived from the EAC data of TCGA was constructed and validated for predicting the prognosis of EAC.",2019,PeerJ
Histopathology-based immunoscore predicts recurrence for intrahepatic cholangiocarcinoma after hepatectomy,"Intrahepatic cholangiocarcinoma (ICC) is a rare malignancy with poor prognosis. The evaluation of recurrence risk after liver resection is of great importance for ICCs. We aimed to assess the prognostic value of intra- and peritumoral immune infiltrations and to establish a novel histopathology-related immunoscore (HRI) associated with ICC recurrence. A total of 280 ICC patients who received curative resection between February 2005 and July 2011 were enrolled in our study. Patients were randomly assigned to the derivation cohort (nâ€‰=â€‰176) or the validation cohort (nâ€‰=â€‰104). Sixteen immune biomarkers in both intra- and peritumoral tissues were examined by immunohistochemistry. The least absolute shrinkage and selection operator (LASSO) Cox model was used to establish the HRI score. Cox regression analysis was used for multivariate analysis. Nine recurrence-related immune features were identified and integrated into the HRI score. The HRI score was used to categorize patients into low-risk and high-risk groups using the X-tile software. Kaplanâ€“Meier analysis presented that the HRI score showed good stratification between low-risk and high-risk groups in both the derivation cohort (Pâ€‰<â€‰0.001) and the validation cohort (Pâ€‰=â€‰0.014), respectively. Multivariate analysis demonstrated that serum Î³-glutamyl transpeptidase, carbohydrate antigen 19-9, lymphoid metastasis, tumor numbers, and the HRI score were independent risk factors associated with recurrence-free survival (RFS). The combination of Shenâ€™s model and HRI score provided better performance in recurrence prediction compared with traditional staging systems. The HRI score might serve as a promising RFS predictor for ICC with prognostic values.",2019,"Cancer Immunology, Immunotherapy"
"Sparse Group Lasso: Optimal Sample Complexity, Convergence Rate, and Statistical Inference","In this paper, we study sparse group Lasso for high-dimensional double sparse linear regression, where the parameter of interest is simultaneously element-wise and group-wise sparse. This problem is an important instance of the simultaneously structured model -- an actively studied topic in statistics and machine learning. In the noiseless case, we provide matching upper and lower bounds on sample complexity for the exact recovery of sparse vectors and for stable estimation of approximately sparse vectors, respectively. In the noisy case, we develop upper and matching minimax lower bounds for estimation error. We also consider the debiased sparse group Lasso and investigate its asymptotic property for the purpose of statistical inference. Finally, numerical studies are provided to support the theoretical results.",2019,ArXiv
Annealed Sparsity via Adaptive and Dynamic Shrinking,"Sparse learning has received tremendous amount of interest in high-dimensional data analysis due to its model interpretability and the low-computational cost. Among the various techniques, adaptive l1-regularization is an effective framework to improve the convergence behaviour of the LASSO, by using varying strength of regularization across different features. In the meantime, the adaptive structure makes it very powerful in modelling grouped sparsity patterns as well, being particularly useful in high-dimensional multi-task problems. However, choosing an appropriate, global regularization weight is still an open problem. In this paper, inspired by the annealing technique in material science, we propose to achieve ""annealed sparsity"" by designing a dynamic shrinking scheme that simultaneously optimizes the regularization weights and model coefficients in sparse (multi-task) learning. The dynamic structures of our algorithm are twofold. Feature-wise (spatially), the regularization weights are updated interactively with model coefficients, allowing us to improve the global regularization structure. Iteration-wise (temporally), such interaction is coupled with gradually boosted l1-regularization by adjusting an equality norm-constraint, achieving an annealing effect to further improve model selection. This renders interesting shrinking behaviour in the whole solution path. Our method competes favorably with state-of-the-art methods in sparse (multi-task) learning. We also apply it in expression quantitative trait loci analysis (eQTL), which gives useful biological insights in human cancer (melanoma) study.",2016,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
The Fate of Theology after the Speculative Turn,"It will be our contention that the religious turn in continental philosophy has little to offer the domain of theology, despite the resurgence of interest in the latter on account of the historical trajectory of the former, and that, consequently, speculative theologians should welcome Meillassouxâ€™s â€˜critique of Critiqueâ€™. We will come to see that Meillassouxâ€™s work has opened up a space for theological discourse, albeit one limited on polarized ends: on the one hand, Meillassoux's rejection of dogmatic pre-critical metaphysics, and on the other, the judgment that contemporary continental philosophy of religion is an historical error based on the faulty reasoning of post-Kantian epistemological finitism. The former pole guards against the vampiric return of classical metaphysical theology, and the latter warns of the dangers associated with various contextual theologies, stemming as they do from the â€œreligionizing of reasonâ€. Our proposal will be that a specific form of theology can find its way through this narrow passage, and that a thorough rapprochement with Meillassouxâ€™s critique of religious and theological thought in After Finitude can be had without completely abandoning theological discourse.",2014,ThÃ©oRÃ¨mes
The outlier-corrected-data-adaptive Lasso: A new robust estimator for the independent contamination model,"Many of today's signal processing tasks consider sparse models where the number of explanatory variables exceeds the sample size. When dealing with real-world data, the presence of impulsive noise and outliers must also be accounted for. Accurate and robust parameter estimation and consistent variable selection are needed simultaneously. Recently, some popular robust methods have been adapted to such complex settings. Especially, in high dimensional settings, however, it is possible to have a single contaminated predictor being responsible for many outliers. The amount of outliers introduced by this predictor easily exceeds the breakdown point of any existing robust estimator. Therefore, we propose a new robust and sparse estimator, the Outlier-Corrected-Data-(Adaptive) Lasso (OCD-(A) Lasso). It simultaneously handles highly contaminated predictors in the dataset and performs well under the classical contamination model. In a numerical study, it outperforms competing Lasso estimators, at a largely reduced computational complexity compared to its robust counterparts.",2017,2017 25th European Signal Processing Conference (EUSIPCO)
Multi-Label Learning Based on Clustering Optimization,"Multi-label learning has been widely used in various fields. One problem in multi-label learning is that mining the correlation information between class labels in the entire label space is not only computationally unaffordable, but may be inappropriate (possibly inconsistent with the real world), which leads to the incorrect introduction of some label dependencies. So, the common solution is to divide the whole label space into several subspaces. However, the process of sub-space partitioning is usually independent of the classifier training process in the existing multi-label learning algorithms, which leads to the division is not optimal for the next classifiers training. In order to solve the above-mentioned problems, we propose a method whose basic idea is to optimize the label clustering process and the classifiers training process simultaneously. In addition, we apply group lasso constraints to the coefficient matrix to ensure that the output of classifiers can maintain the characteristics of consistency within each label cluster and mutually exclusive between label clusters. Experiments conducted on five benchmark multi-label datasets demonstrate the competitive performance of our proposed method compared with several state-of-the-art methods.",2019,"2019 IEEE International Conferences on Ubiquitous Computing & Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS)"
Oracle Inequalities for High Dimensional Vector Autoregressions,This paper establishes non-asymptotic oracle inequalities for the prediction error and estimation accuracy of the LASSO in stationary vector autoregressive models. These inequalities are used to establish consistency of the LASSO even when the number of parameters is of a much larger order of magnitude than the sample size. We also state conditions under which no relevant variables are excluded.,2012,Journal of Econometrics
Lasso Regressions and Forecasting Models in Applied Stress Testing,"Model selection and forecasting in stress tests can be facilitated using machine learning techniques. These techniques have proved robust in other fields for dealing with the curse of dimensionality, a situation often encountered in applied stress testing. Lasso regressions, in particular, are well suited for building forecasting models when the number of potential covariates is large, and the number of observations is small or roughly equal to the number of covariates. This paper presents a conceptual overview of lasso regressions, explains how they fit in applied stress tests, describes its advantages over other model selection methods, and illustrates their application by constructing forecasting models of sectoral probabilities of default in an advanced emerging market economy.",2015,
AnÃ¡lisis Sobre La RelaciÃ³n Padres-hijos.,"La presente comunicacion forma parte de la produccion de un Grupo de investigacion de la Facultad de Psicologia, de la Universidad Nacional de Mar del Plata, denominado â€œPsicologia y moralidadâ€, en el que se desarrollan proyectos de investigacion que tienen como tema principal las relaciones entre los sujetos y los discursos normativos. Nos interesa aqui centrarnos en la posicion que adoptan aquellos que encarnan el lugar de Otro, en este caso la posicion de padres. Para ello realizamos una breve referencia a los resultados del trabajo de investigacion â€œLey, sancion y familia. Una investigacion sobre los modos de transmision parentales de la leyâ€. Focalizamos la presente comunicacion en el analisis de observaciones realizadas en diversos escenarios de la ciudad, centradas en la relacion padres-hijos, la posicion que adoptan los primeros frente a laso segundos y su posicion frente a su rol de padres. 
Palabras clave 
Padres Subjetivizacion Ley Observaciones 
 
ABSTRACT 
ANALYSIS ON THE PARENT-CHILD RELATIONSHIP This paper is part of the production of a psychologyâ€™s investigation group of the National University of Mar del Plata, named â€œPsychology and Moralityâ€. In the mentioned group we developed different projects that has as s main problem the relations between individuals and normativeâ€™s speeches. Our interest in this paper is to focus in the position that adopt those who take the place of Other, in this case the parents. In that purpose we realized a brief reference to the results of the investigationâ€™s work â€œLaw, sanction and family. This communication we focus on the analysis of observations made at different stages in the city, focusing on parent-child relationship, the position adopted by the early compared to lasso seconds, and its position in relation to their role as parents. 
Key words 
Parent subjectivity Law Observations",2010,
Batch Effect Confounding Leads to Strong Bias in Performance Estimates Obtained by Cross-Validation,"BACKGROUND
With the large amount of biological data that is currently publicly available, many investigators combine multiple data sets to increase the sample size and potentially also the power of their analyses. However, technical differences (""batch effects"") as well as differences in sample composition between the data sets may significantly affect the ability to draw generalizable conclusions from such studies.


FOCUS
The current study focuses on the construction of classifiers, and the use of cross-validation to estimate their performance. In particular, we investigate the impact of batch effects and differences in sample composition between batches on the accuracy of the classification performance estimate obtained via cross-validation. The focus on estimation bias is a main difference compared to previous studies, which have mostly focused on the predictive performance and how it relates to the presence of batch effects.


DATA
We work on simulated data sets. To have realistic intensity distributions, we use real gene expression data as the basis for our simulation. Random samples from this expression matrix are selected and assigned to group 1 (e.g., 'control') or group 2 (e.g., 'treated'). We introduce batch effects and select some features to be differentially expressed between the two groups. We consider several scenarios for our study, most importantly different levels of confounding between groups and batch effects.


METHODS
We focus on well-known classifiers: logistic regression, Support Vector Machines (SVM), k-nearest neighbors (kNN) and Random Forests (RF). Feature selection is performed with the Wilcoxon test or the lasso. Parameter tuning and feature selection, as well as the estimation of the prediction performance of each classifier, is performed within a nested cross-validation scheme. The estimated classification performance is then compared to what is obtained when applying the classifier to independent data.",2014,PLoS ONE
Improved LASSO priors for shrinkage quantitative trait loci mapping,"Recently, the Bayesian least absolute shrinkage and selection operator (LASSO) has been successfully applied to multiple quantitative trait loci (QTL) mapping, which assigns the double-exponential prior and the Studentâ€™s t prior to QTL effect that lead to the shrinkage estimate of QTL effect. However, as reported by many researchers, the Bayesian LASSO usually cannot effectively shrink the effects of zero-effect QTL very close to zero. In this study, the double-exponential prior and Studentâ€™s t prior are modified so that the estimate of the effect for zero-effect QTL can be effectively shrunk toward zero. It is also found that the Studentâ€™s t prior is virtually the same as the Jeffreysâ€™ prior, since both the shape and scale parameters of the scaled inverse Chi-square prior involved in the Studentâ€™s t prior are estimated very close to zero. Besides the two modified Bayesian Markov chain Monte Carlo (MCMC) algorithms, an expectationâ€“maximization (EM) algorithm with use of the modified double-exponential prior is also adapted. The results shows that the three new methods perform similarly on true positive rate and false positive rate for QTL detection, and all of them outperform the Bayesian LASSO.",2012,Theoretical and Applied Genetics
Updated analysis of flatfish recruitment response to climate variability and ocean conditions in the Eastern Bering Sea,"Abstract This study provides a retrospective analysis of the relationship between physical oceanography, biology and recruitment of three Eastern Bering Sea flatfish stocks: flathead sole (Hippoglossoides elassodon), northern rock sole (Lepidopsetta polyxystra), and arrowtooth flounder (Atheresthes stomias) during the period 1978â€“2005. Stock assessment model estimates of recruitment and spawning stock size indicate that temporal patterns in productivity are consistent with decadal scale (or shorter) patterns in climate variability, which may influence marine survival during the early life history phases. Density-dependence (through spawning stock size) was statistically significant in a Ricker stock-recruit model of flatfish recruitment that included environmental terms. Wind-driven advection of northern rock sole and flathead sole larvae to favorable nursery grounds was found to coincide with years of above-average recruitment. Ocean forcing of Bristol Bay surface waters during springtime was mostly on-shelf (eastward) during the 1980s and again in the early 2000s, but was off-shelf (westerly) during the 1990s, corresponding with periods of good and poor recruitment, respectively. Finally, the Arctic Oscillation was found to be an important indicator of arrowtooth flounder productivity. Model results were applied to IPCC (Intergovernmental Panel on Climate Change) future springtime wind scenarios to predict the future impact of climate on northern rock sole productivity and indicated that a moderate future increase in recruitment might be expected because the climate trends favor on-shelf transport but that density-dependence will dampen this effect such that northern rock sole abundance will not be substantially affected by climate change.",2013,Deep-sea Research Part Ii-topical Studies in Oceanography
lassopack: Model selection and prediction with regularized regression in Stata,"This article introduces lassopack, a suite of programs for regularized regression in Stata. lassopack implements lasso, square-root lasso, elastic net, ridge regression, adaptive lasso and post-estimation OLS. The methods are suitable for the high-dimensional setting where the number of predictors $p$ may be large and possibly greater than the number of observations, $n$. We offer three different approaches for selecting the penalization (`tuning') parameters: information criteria (implemented in lasso2), $K$-fold cross-validation and $h$-step ahead rolling cross-validation for cross-section, panel and time-series data (cvlasso), and theory-driven (`rigorous') penalization for the lasso and square-root lasso for cross-section and panel data (rlasso). We discuss the theoretical framework and practical considerations for each approach. We also present Monte Carlo results to compare the performance of the penalization approaches.",2019,arXiv: Econometrics
Kernel-Based Microfluidic Constriction Assay for Tumor Sample Identification.,"A high-throughput multiconstriction microfluidic channels device can distinguish human breast cancer cell lines (MDA-MB-231, HCC-1806, MCF-7) from immortalized breast cells (MCF-10A) with a confidence level of âˆ¼81-85% at a rate of 50-70 cells/min based on velocity increment differences through multiconstriction channels aligned in series. The results are likely related to the deformability differences between nonmalignant and malignant breast cells. The data were analyzed by the methods/algorithms of Ridge, nonnegative garrote on kernel machine (NGK), and Lasso using high-dimensional variables, including the cell sizes, velocities, and velocity increments. In kernel learning based methods, the prediction values of 10-fold cross-validations are used to represent the difference between two groups of data, where a value of 100% indicates the two groups are completely distinct and identifiable. The prediction value is used to represent the difference between two groups using the established algorithm classifier from high-dimensional variables. These methods were applied to heterogeneous cell populations prepared using primary tumor and adjacent normal tissue obtained from two patients. Primary breast cancer cells were distinguished from patient-matched adjacent normal cells with a prediction ratio of 70.07%-75.96% by the NGK method. Thus, this high-throughput multiconstriction microfluidic device together with the kernel learning method can be used to perturb and analyze the biomechanical status of cells obtained from small primary tumor biopsy samples. The resultant biomechanical velocity signatures identify malignancy and provide a new marker for evaluation in risk assessment.",2018,ACS sensors
Organic facies variability during the Toarcian Oceanic Anoxic Event record of the Grands Causses and Quercy basins (southern France),"Abstract The early Toarcian is marked worldwide by major environmental changes that resulted in organic-rich black shale deposition, the Toarcian Oceanic Anoxic Event (T-OAE). This organic-rich sedimentation is particularly recorded in the Grands Causses (GCB) and Quercy (QB) basins. The main objectives of this study are the characterization, through organic petrology and geochemistry techniques, of the organic matter (OM) of the late Pliensbachian â€“ early Toarcian sedimentary successions of these basins and the definition of the organic facies, assessing their implications in the evolution of depositional paleoenvironments. In the GCB sedimentation occurred, during the late Pliensbachian, in a well oxygenated water body (Total Organic Carbon - TOC 0.6Â wt.% and low Amorphous Organic Matter - AOM) proximal to the terrestrial source area (high terrestrial contribution) with marine influence. In the lattermost Pliensbachian a shallowing of the water column is observed with decrease of marine influence and separation from the terrestrial source area (TOC 0.9Â wt.%, AOM and zooclasts co-dominate) under an arid climate ( Classopollis ssp.). From the Tenuicostatum to early Serpentinum chronozones a restricted and stagnated environment (TOC 5.7Â wt.%, AOM dominates) is implemented. From middle to late Serpentinum Chronozone the reestablishment of the oxygen levels (decrease in TOC and AOM) takes place, as well as paleoceanographic circulation patterns. In the QB, the late Pliensbachian to earliest Toarcian is characterized by low TOC (0.2Â wt.%) with sedimentation occurring in a shallow oxygenated proximal water body (amorphous Hydrozoans dominate) separated from the terrestrial source area with arid climate ( Classopollis ssp.), and with episodes of emersion. From the Semicelatum Subchronozone to Serpentinum Chronozone the development of dysoxic to anoxic conditions (TOC 4.2Â wt.%) takes place, associated with water column stratification and more effective non-carbonate sedimentation, and with an increase in water level. For the lattermost Serpentinum Chronozone shallowing of a more oxidizing water body, with some oxygen depletion still present is proposed. The differences in these paleoenvironmental depositional contexts further demonstrate that, although the T-OAE has a global character, local control mechanisms in these basins play a pivotal role. Furthermore, the first occurrence of Hydrozoans, namely its free-swimming medusoid forms, is described in organopalynological preparations of sediments from the Pliensbachianâ€“Toarcian and their first paleoenvironmental application in a palynofacies based study is made.",2017,International Journal of Coal Geology
"Performance Limits for Estimators of the Risk or Distribution of Shrinkage-type Estimators, and Some General Lower Risk-bound Results","We consider the problem of estimating measures of precision of shrinkage-type estimators like their risk or distribution. The notion of shrinkage-type estimators here refers to estimators like the James-Stein estimator or Lasso-type estimators, as well as to 'thresholding' estimators such as, e.g., Hodges' so-called superefficient estimator. While the precision measures of such estimators typically can be estimated consistently, we show that they cannot be estimated uniformly consistently (even locally). This follows as a corollary to (locally) uniform lower bounds on the performance of estimators of the precision measures that we also obtain. These lower bounds are typically quite large (e.g., they approach 1/2 or 1 depending on the situation considered). The analysis is based on some general lower risk bounds and related general results on the (non)existence of uniformly consistent estimators.",2003,Econometric Theory
Bridging Information Criteria and Parameter Shrinkage for Model Selection,"Model selection based on classical information criteria, such as BIC, is generally computationally demanding, but its properties are well studied. On the other hand, model selection based on parameter shrinkage by $\ell_1$-type penalties is computationally efficient. In this paper we make an attempt to combine their strengths, and propose a simple approach that penalizes the likelihood with data-dependent $\ell_1$ penalties as in adaptive Lasso and exploits a fixed penalization parameter. Even for finite samples, its model selection results approximately coincide with those based on information criteria; in particular, we show that in some special cases, this approach and the corresponding information criterion produce exactly the same model. One can also consider this approach as a way to directly determine the penalization parameter in adaptive Lasso to achieve information criteria-like model selection. As extensions, we apply this idea to complex models including Gaussian mixture model and mixture of factor analyzers, whose model selection is traditionally difficult to do; by adopting suitable penalties, we provide continuous approximators to the corresponding information criteria, which are easy to optimize and enable efficient model selection.",2013,ArXiv
Application of Bayesian least absolute shrinkage and selection operator (LASSO) and BayesCÏ€ methods for genomic selection in French Holstein and MontbÃ©liarde breeds.,"Recently, the amount of available single nucleotide polymorphism (SNP) marker data has considerably increased in dairy cattle breeds, both for research purposes and for application in commercial breeding and selection programs. Bayesian methods are currently used in the genomic evaluation of dairy cattle to handle very large sets of explanatory variables with a limited number of observations. In this study, we applied 2 bayesian methods, BayesCÏ€ and bayesian least absolute shrinkage and selection operator (LASSO), to 2 genotyped and phenotyped reference populations consisting of 3,940 Holstein bulls and 1,172 MontbÃ©liarde bulls with approximately 40,000 polymorphic SNP. We compared the accuracy of the bayesian methods for the prediction of 3 traits (milk yield, fat content, and conception rate) with pedigree-based BLUP, genomic BLUP, partial least squares (PLS) regression, and sparse PLS regression, a variable selection PLS variant. The results showed that the correlations between observed and predicted phenotypes were similar in BayesCÏ€ (including or not pedigree information) and bayesian LASSO for most of the traits and whatever the breed. In the Holstein breed, bayesian methods led to higher correlations than other approaches for fat content and were similar to genomic BLUP for milk yield and to genomic BLUP and PLS regression for the conception rate. In the MontbÃ©liarde breed, no method dominated the others, except BayesCÏ€ for fat content. The better performances of the bayesian methods for fat content in Holstein and MontbÃ©liarde breeds are probably due to the effect of the DGAT1 gene. The SNP identified by the BayesCÏ€, bayesian LASSO, and sparse PLS regression methods, based on their effect on the different traits of interest, were located at almost the same position on the genome. As the bayesian methods resulted in regressions of direct genomic values on daughter trait deviations closer to 1 than for the other methods tested in this study, bayesian methods are suggested for genomic evaluations of French dairy cattle.",2013,Journal of dairy science
The lassoâ€”a novel method for predictive covariate model building in nonlinear mixed effects models,"Covariate models for population pharmacokinetics and pharmacodynamics are often built with a stepwise covariate modelling procedure (SCM). When analysing a small dataset this method may produce a covariate model that suffers from selection bias and poor predictive performance. The lasso is a method suggested to remedy these problems. It may also be faster than SCM and provide a validation of the covariate model. The aim of this study was to implement the lasso for covariate selection within NONMEM and to compare this method to SCM.In the lasso all covariates must be standardised to have zero mean and standard deviation one. Subsequently, the model containing all potential covariateâ€“parameter relations is fitted with a restriction: the sum of the absolute covariate coefficients must be smaller than a value, t. The restriction will force some coefficients towards zero while the others are estimated with shrinkage. This means in practice that when fitting the model the covariate relations are tested for inclusion at the same time as the included relations are estimated. For a given SCM analysis, the model size depends on the P-value required for selection. In the lasso the model size instead depends on the value of t which can be estimated using cross-validation.The lasso was implemented as an automated tool using PsN. The method was compared to SCM in 16 scenarios with different dataset sizes, number of investigated covariates and starting models for the covariate analysis. Hundred replicate datasets were created by resampling from a PK-dataset consisting of 721 stroke patients. The two methods were compared primarily on the ability to predict external data, estimate their own predictive performance (external validation), and on the computer run-time.In all 16 scenarios the lasso predicted external data better than SCM with any of the studied P-values (5%, 1% and 0.1%), but the benefit was negligible for large datasets. The lasso cross-validation provided a precise and nearly unbiased estimate of the actual prediction error. On a single processor, the lasso was faster than SCM. Further, the lasso could run completely in parallel whereas SCM must run in steps.In conclusion, the lasso is superior to SCM in obtaining a predictive covariate model on a small dataset or on small subgroups (e.g. rare genotype). Run in parallel the lasso could be much faster than SCM. Using cross-validation, the lasso provides a validation of the covariate model and does not require the user to specify a P-value for selection.",2007,Journal of Pharmacokinetics and Pharmacodynamics
Flexible approach for novel transcript reconstruction from RNA-seq data using maximum likelihood integer programming,"In this paper, we propose a novel, intuitive and flexible approach for transcriptome reconstruction from single RNA-Seq reads, called â€œ Maximum Likelihood Integer Programming â€ (MLIP) method. MLIP creates a splice graph based on aligned RNA-Seq reads and enumerates all maximal paths corresponding to putative transcripts. The problem of selecting true transcripts is formulated as an integer program which minimizes the number of selected candidate transcripts. Our method purpose is to predict the minimum number of transcripts explaining the set of input reads with the highest quantification accuracy. This is achieved by coupling a integer programming formulation with an expectation maximization model for transcript expression estimation. MLIP has the advantage of offering different levels of stringency that would gear the results towards higher precision or higher sensitivity, according to the user preference. We test MLIP method on simulated and real data, and we show that MLIP outperforms both Cufflinks and IsoLasso.",2013,
Statistical Seasonal Prediction Based on Regularized Regression,"AbstractThis paper proposes a regularized regression procedure for finding a predictive relation between one variable and a field of other variables. The procedure estimates a linear prediction model under the constraint that the regression coefficients have smooth spatial structure. The smoothness constraint is imposed using a novel approach based on the eigenvectors of the Laplace operator over the domain, which results in a constrained optimization problem equivalent to either ridge regression or least absolute shrinkage and selection operator (LASSO) regression, which can be solved by standard numerical software. In addition, this paper explores an unconventional procedure whereby regression models are estimated from dynamical model output and then verified against observationsâ€”the reverse of the traditional order. The methodology is illustrated by constructing statistical prediction models of summer Texas-area temperature based on concurrent Pacific sea surface temperature (SST). None of the regulari...",2017,Journal of Climate
Ãœber die Elimination der WiderstandsÃ¼berspannung an drahtfÃ¶rmigen Elektroden mittels der Methode der Abstandsvariation,"Bei der Messung einer Bezugsspannung bei groseren Stromdichten wird, wie allgemein bekannt, ein Spannungsanteil miterfast, der in einer auf der Elektrodenoberflache sitzenden, schlecht leitenden Deckschicht und in der Elektrolytschicht zwischen Versuchselektrode und Spitze der zur Bezugselektrode fuhrenden Kapillare lokalisiert sein kann. Dieser Spannungsanteil soll im folgenden kurz mit Widerstandsuberspannung bezeichnet werden1). Uber die bei der Elimination des Ohmschen Potentialabfalls im Elektrolyten (ohmic drop) durch Messung der Bezugsspannung in verschiedenen Abstanden von der Versuchselektrode und Extrapolation auf die Elektrodenoberflache auftretenden Fehler sind in letzter Zeit besonders von Piontelli und Mitarbeitern2) wesentliche Untersuchungen angestellt worden. Diese Betrachtungen blieben jedoch auf ebene Potentialverteilungen zwischen ebenen Elektroden in Blechform beschrankt. Bei der Untersuchung der Kinetik der Wasserstoffabscheidung und vielen anderen elektrochemischen Untersuchungen finden jedoch auch drahtformige Elektroden Verwendung, die sich einerseits besser aktivieren lassen als Bleche3) und an denen andererseits wegen ihrer relativ kleinen Oberflache sich grosere Stromdichten, insbesondere bei Anwendung der modernen â€žinstationarenâ€ Untersuchungsmethoden4), technisch leichter erzielen lassen als an blechformigen Elektroden mit relativ groser Oberflache. Es erschien uns bereits aus diesem Grunde zweckmasig, einmal die Methode der Abstandsvariation in einem geeigneten rotationssymmetrischen Feld bei bestimmter Form der Kapillare zu diskutieren. Weiterhin kann man bekanntlich durch Messung des sehr schnell erfolgenden anfanglichen Spannungsabfalls5) bzw. Anstiegs nach Stromunterbrechung bzw. Einschaltung die gesamte Widerstandsuberspannung1) und mit Hilfe der Abstandsvariation den Ohmschen Potentialabfall im Elektrolyten getrennt bestimmen. Durch eine Kombination beider Methoden6) ist es deshalb moglich, den bei Stromflus an einer Deckschicht auftretenden Potentialabfall zu bestimmen, sofern dieser Potentialabfall von derselben Grosenordnung wie der Ohmsche Potentialabfall im Elektrolyten ist. 
 
 
 
Besonders in diesem Zusammenhang kommt der Methode der Abstandsvariation grose Wichtigkeit zu. 
 
 
 
Bei Benutzung der im folgenden naher beschriebenen Versuchsanordnung last sich die in diesem Fall ebene Potentialverteilung im Elektrolyten naherungsweise rechnerisch ermitteln. Unter der Annahme, das die Versuchselektrode eine Aquipotentialflache bleibt, wird zunachst die Stromdichteverteilung unter Berucksichtigung der Glassonde [primary current distribution7)] funktionentheoretisch berechnet. Dabei ergibt sich aber fur die Abstande zwischen Versuchselektrode und Glassonde, die bei der Messung in Betracht kommen, eine ortlich verschiedene Stromdichte auf der Oberflache der Versuchselektrode. Da die bei elektrochemischen Vorgangen auftretende Polarisation der Versuchselektrode bekanntlich von der Stromdichte abhangt, ist die Annahme, das die Versuchselektrode eine Aquipotentialflache darstellt, nicht mehr aufrechtzuerhalten. Der maximale Einflus der Polarisation auf die Potentialverteilung im Elektrolyten last sich nun dadurch abschatzen, das man die Potentialgleichung nur fur den Elektrolysenraum mit der Randbedingung eines linearen Zusammenhanges zwischen Potential und Stromdichte auf der Elektrodenoberflache naherungsweise lost8)9)10). Man vernachlassigt dabei erstens die Moglichkeit eines Potentialausgleichs innerhalb der metallischen Versuchselektrode und zweitens die Tatsache, das der Zusammenhang zwischen Polarisation und Stromdichte im allgemeinen einen logarithmischen Charakter besitzt. Die Grosenordnung des durch die erste Vernachlassigung begangenen Fehlers muste prinzipiell durch die Behandlung eines einfacheren doppelten Randwertproblems (Metallraum + Elektrolsenraum) abzuschatzen sein. Die zweite Vernachlassigung wird um so weniger ins Gewicht fallen, je weiter die Glassonde von der Versuchselektrode entfernt und je geringer deswegen die Abdeckung durch die Sonde ist. Aut jeden Fall kann man mit Hilfe dieser Abschatzung einen Mindestabstand der Sonde von der Versuchselektrode angeben, von dem ab der Einflus der Polarisation auf die mit der Kapillare gemessene Bezugsspannung vernachlassigt werden kann. Messungen, die bei kathodischer Wasserstoffabscheidung in diesem Bereich durchgefuhrt wurden, zeigen eine gute Ubereinstimmung zwischen der experimentell ermittelten und der gemas der Theorie zu erwartenden Abhangigkeit der Uberspannung von dem Abstand der Sonde von der Versuchselektrode. Weiterhin wird der Einflus einer Temperaturerhohung des Elektrolyten an der Versuchselektrode und der Einflus der Blasenbildung bei groseren kathodischen Stromdichten auf die Elimination des Potentialbfalls im Elektrolyten diskutiert. Die Betrachtungen werden unter der bei Verwendung von konzentrierten sauren Losungen in dem untersuchten Stromdichtebereich erfullten Voraussetzung einer ortlich konstanten H3O+-Ionenkonzentration in der Umgebung der Kathode durchgefuhrt.",1956,
Study of the Nutrient Composition of Organic Fertilizers in the Zone of Bobo-Dioulasso (Burkina Faso),"This study has the aim to do a chemical characterization of the organic fertilizers used in the urban agriculture in Bobo-Dioulasso. For this reason, seven (07) fertilizers of animal's origin were taken away and analyzed in the laboratory. The comparison of the nitrogen averages shows that the poultry droppings and the pig's manure have the respective highest contents of 2.5% and of 2.6% of the studied sample. The poultry droppings (total P=2.7%) were the most affluent in phosphorus followed by the pig's manure (1.4%), while donkeys manure had the lowest content (0.7%). The monogastric animals (poultry, pigs, and rabbits) had the highest contents in total N, total P and the C:N ratio. The lower content in total K was the rabbits and the pig's manure. These results give the possibility to optimize the recovering as fertilizers of the cultures or to make the soils more affluent.",2016,"International journal of scientific research in science, engineering and technology"
Oracle inequalities for the Lasso in the high-dimensional Aalen multiplicative intensity model,"In a general counting process setting, we consider the problem of obtaining a prognostic on the survival time adjusted on covariates in high-dimension. Towards this end, we construct an estimator of the whole conditional intensity. We estimate it by the best Cox proportional hazards model given two dictionaries of functions. The first dictionary is used to construct an approximation of the logarithm of the baseline hazard function and the second to approximate the relative risk. We introduce a new data-driven weighted Lasso procedure to estimate the unknown parameters of the best Cox model approximating the intensity. We provide non-asymptotic oracle inequalities for our procedure in terms of an appropriate empirical Kullback divergence. Our results rely on an empirical Bernstein's inequality for martingales with jumps and properties of modified self-concordant functions.",2012,Annales De L Institut Henri Poincare-probabilites Et Statistiques
Ekstraksi Dan Pemurnian Organosolv Lignin dari Limbah Serbuk Kayu Meranti,"Organosolv pulping is a promising pathway to extract high purity lignin from biomass. Organosolv pulping are able to produce higher pulp yield and diminished environmental stress as comparred to the kraft pulping. The aim of this research was to investigated the extraction efficiency and purity of organosolv lignin which extracted from meranti wood waste powder with different concentration of ethanol. In this work, meranti wood waste powder were refluxed in ethanol solution with different concentration i.e 0%, 16.6%, 33.3%, 50%, 66.6%, 83.3%, 100% v/v at boiling temperature of the solution for two hours. Purification process were prepared by refluxed the extracted organosolv lignin into aqua dm at 100 0C for two hours. The purity of organosolv lignin were determined by ash content test, volatile content test and klasson lignin. The highest yield were obtained for organosolv lignin prepared by using 83.3% ethanol solution, that is 3.3%. The highest purity of organosolv lignin were obtained for organosolv lignin prepared by using 66.6% ethanol solution, that is 92%.",2017,
"Sound quality prediction based on systematic metric selection and shrinkage: Comparison of stepwise, lasso, and elastic-net algorithms and clustering preprocessing","Abstract Sound quality is the impression of quality that is transmitted by the sound of a device. Its importance in sound and acoustical design of consumer products no longer needs to be demonstrated. One of the challenges is the creation of a prediction model that is able to predict the results of a listening test while using metrics derived from the sound stimuli. Often, these models are either derived using linear regression on a limited set of experimenter-selected metrics, or using more complex algorithms such as neural networks. In the former case, the user-selected metrics can bias the model and reflect the engineer pre-conceived idea of sound quality while missing potential features. In the latter case, although prediction might be efficient, the model is often in the form of a black-box which is difficult to use as a sound design guideline for engineers. In this paper, preprocessing by participants clustering and three different algorithms are compared in order to construct a sound quality prediction model that does not suffer from these limitations. The lasso, elastic-net and stepwise algorithms are tested for listening tests of consumer product for which 91 metrics areÂ used as potential predictors. Based on the reported results, it is shown that the most promising algorithm is the lasso which is able to (1) efficiently limit the number of metrics, (2) most accurately predict the results of listening tests, and (3) provide a meaningful model that can be used as understandable design guidelines.",2017,Journal of Sound and Vibration
Ð“Ñ–Ð´Ñ€Ð¾Ð³ÐµÐ¾Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ð° Ð¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ° ÐÐ¸Ð¶Ð½ÑŒÐ¾ÐºÑ€ÐµÐ¹Ð´Ð¾Ð²Ð¾Ð³Ð¾ Ð¢ÐµÑ€Ð¸Ð³ÐµÐ½Ð½Ð¾Ð³Ð¾ ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÑƒ ÐšÐ°Ñ€ÐºÑ–Ð½Ñ–Ñ‚ÑÑŒÐºÐ¾-Ð¿Ñ–Ð²Ð½Ñ–Ñ‡Ð½Ð¾ÐºÑ€Ð¸Ð¼ÑÑŒÐºÐ¾Ð³Ð¾ ÐŸÑ€Ð¾Ð³Ð¸Ð½Ñƒ Ð’ ÐÑÐ¿ÐµÐºÑ‚Ñ– ÐÐ°Ñ„Ñ‚Ð¾Ð³Ð°Ð·Ð¾Ð½Ð¾ÑÐ½Ð¾ÑÑ‚Ñ–,"Purpose. To s ubstantiate the prospects for oil and gas presence in the Lower Cretaceous sediments of the Karkinit-Northern Crimean deep based on hydrogeological (hydrogeochemical, gas-hydrogeochemical and geobaric) features. Methodology. Investigations of formation waters and water-dissolved gases were based on the methods of chemical, elementary spectral and gas chromatographic analyses executed at the laboratories of subsidiary joint-stock company ""Chornomornaftogaz"", subsidiary ""Crimean Geology"" and the Institute of Geology and Geochemistry of Combustible Minerals of NASU. For the comparison of formation pressure we applied the hydrostatic coefficient (C h ). C h is the ratio of measured formation pressure to conditionally hydrostatic at the depth of the measuring with Î³=1.000 (Ð  f /Ð  ch ), which eliminates the influence of uneven depths of measurement and different water densities, that is, to get the reduced value. For processing materials Excell, Corell Draw and Surfer are used. Results. Regional features of formation waters in the Lower Cretaceous complex as well as their chemical composition formation conditions are established. According to retrospective data analysis on the Crimean Plains, using the information received on the Black Sea shelf, we come to a conclusion that formation waters of the Lower Cretaceous complex are mainly sedimentogenic. The sulfate-natrium (S.Na) waters of the basal horizon and the Lower Cretaceous aquiferous complex most likely are infiltrative. This is evidenced by the decrease in the indicators of metamorphism of rCa/rMg, r(Cl-Na)/rMg and the increase in Cl/Br to over 1000, the lowered content of iodine (J) and bromine (Br). Infiltrative (paleoinfiltrative) waters mixed with primary sedimentogenic waters. This was accompanied by the decrease in their mineralization and thalassogenic trace elements contents in them. Modern infiltration from the land of meteoric waters at depths of more than 2000â€“3000 meters through the hydrodynamic barriers of the elision water drive system is impossible, but it could be realized at the continental infiltration stages of the foreground development and before the late Cretaceous time. This is evidenced by the continuous continental conditions marked by denudation of rocks. The main processes in the chemical composition formation of formation waters of Cretaceous and Lower Cretaceous complexes could have been: leaching rocks, mixing of infiltrative fresh or saline waters with thalassogenic waters; mixing of these waters with waters of the high temperature (>200 0 C) dehydration of clay rocks with formation of non-infiltrative (S.Na) and (Hyd.Car.Na) waters. Based on the analysis of the hydrostatic coeficient distribution (C h ) in the basal and Lower Cretaceous aquiferous complexes the existence of the elision water pressure system within the Karkinit-Northern Crimean deep is confirmed. The cause of overhydrostatic pressures is most likely to be the dehydration of clay rocks and the intrusion of deep gases. Geobaric conditions and filtration parameters suggest that the water flows of the elision water pressure system can move from the deepest parts of the Karkinit-Northern Crimean deep towards its sides. Originality and practical significance. The nature and forming conditions of formation waters have been substantiated. According to gas-hydrogeochemical and geobaric features it was possible to distinguish localities promising for hydrocarbon prospecting in the Lower Cretaceous deposits.",2018,
Does $\ell _{p}$ -Minimization Outperform $\ell _{1}$ -Minimization?,"In many application areas ranging from bioinformatics to imaging, we are faced with the following question: can we recover a sparse vector <inline-formula> <tex-math notation=""LaTeX"">$x_{o} \in \mathbb {R}^{N}$ </tex-math></inline-formula> from its undersampled set of noisy observations <inline-formula> <tex-math notation=""LaTeX"">$y \in \mathbb {R}^{n}$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=""LaTeX"">$y= A x_{o}+ w$ </tex-math></inline-formula>. The last decade has witnessed a surge of algorithms and theoretical results to address this question. One of the most popular schemes is the <inline-formula> <tex-math notation=""LaTeX"">$\ell _{p}$ </tex-math></inline-formula>-regularized least squares given by the following formulation:<inline-formula> <tex-math notation=""LaTeX"">$\hat x(\gamma ,p ) \in {\arg \min }_{x}~({1}/{2})\| {y - Ax} \|_{2}^{2} + \gamma {\| x \|_{p}^{p}}$ </tex-math></inline-formula>, where <inline-formula> <tex-math notation=""LaTeX"">$p \in [{0, 1}]$ </tex-math></inline-formula>. Among these optimization problems, the case <inline-formula> <tex-math notation=""LaTeX"">$p = 1$ </tex-math></inline-formula>, also known as LASSO, is the best accepted in practice, for the following two reasons. First, thanks to the extensive studies performed in the fields of high-dimensional statistics and compressed sensing, we have a clear picture of LASSOâ€™s performance. Second, it is convex and efficient algorithms exist for finding its global minima. Unfortunately, neither of the above two properties hold for <inline-formula> <tex-math notation=""LaTeX"">$0 \leq p<1$ </tex-math></inline-formula>. However, they are still appealing because of the following folklores in the high-dimensional statistics. First, <inline-formula> <tex-math notation=""LaTeX"">$\hat x(\gamma , p )$ </tex-math></inline-formula> is closer to <inline-formula> <tex-math notation=""LaTeX"">$x_{o}$ </tex-math></inline-formula> than <inline-formula> <tex-math notation=""LaTeX"">$\hat {x}(\gamma ,1)$ </tex-math></inline-formula>. Second, if we employ iterative methods that aim to converge to a local minima of <inline-formula> <tex-math notation=""LaTeX"">$ {\arg \min }_{x}~({1}/{2})\| {y - Ax} \|_{2}^{2} + \gamma {\| x \|_{p}^{p}}$ </tex-math></inline-formula>, then under good initialization, these algorithms converge to a solution that is still closer to <inline-formula> <tex-math notation=""LaTeX"">$x_{o}$ </tex-math></inline-formula> than <inline-formula> <tex-math notation=""LaTeX"">$\hat {x}(\gamma ,1)$ </tex-math></inline-formula>. In spite of the existence of plenty of empirical results that support these folklore theorems, the theoretical progress to establish them has been very limited. This paper aims to study the above-mentioned folklore theorems and establish their scope of validity. Starting with approximate message passing (AMP) algorithm as a heuristic method for solving <inline-formula> <tex-math notation=""LaTeX"">$\ell _{p}$ </tex-math></inline-formula>-regularized least squares, we study the following questions. First, what is the impact of initialization on the performance of the algorithm? Second, when does the algorithm recover the sparse signal <inline-formula> <tex-math notation=""LaTeX"">$x_{o}$ </tex-math></inline-formula> under a â€œgoodâ€ initialization? Third, when does the algorithm converge to the sparse signal regardless of the initialization? Studying these questions will not only shed light on the second folklore theorem, but also lead us to the answer the first one, i.e., the performance of the global optima <inline-formula> <tex-math notation=""LaTeX"">$\hat x(\gamma , p )$ </tex-math></inline-formula>. For that purpose, we employ the replica analysis<xref rid=""fn1"" ref-type=""fn""><sup>1</sup></xref> to show the connection between the solution of AMP and <inline-formula> <tex-math notation=""LaTeX"">$\hat {x}(\gamma , p)$ </tex-math></inline-formula> in the asymptotic settings. This enables us to compare the accuracy of <inline-formula> <tex-math notation=""LaTeX"">$\hat x(\gamma ,p )$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$\hat x(\gamma ,1 )$ </tex-math></inline-formula>. In particular, we will present an accurate characterization of the phase transition and noise sensitivity of <inline-formula> <tex-math notation=""LaTeX"">$\ell _{p}$ </tex-math></inline-formula>-regularized least squares for every <inline-formula> <tex-math notation=""LaTeX"">$0 \leq p \leq 1$ </tex-math></inline-formula>. Our results in the noiseless setting confirm that <inline-formula> <tex-math notation=""LaTeX"">$\ell _{p}$ </tex-math></inline-formula>-regularized least squares (if <inline-formula> <tex-math notation=""LaTeX"">$\gamma $ </tex-math></inline-formula> is tuned optimally) exhibits the same phase transition for every <inline-formula> <tex-math notation=""LaTeX"">$0 \leq p< 1$ </tex-math></inline-formula> and this phase transition is much better than that of LASSO. Furthermore, we show that in the noisy setting, there is a major difference between the performance of <inline-formula> <tex-math notation=""LaTeX"">$\ell _{p}$ </tex-math></inline-formula>-regularized least squares with different values of <inline-formula> <tex-math notation=""LaTeX"">$p$ </tex-math></inline-formula>. For instance, we will show that for very small and very large measurement noises, <inline-formula> <tex-math notation=""LaTeX"">$p = 0$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$p = 1$ </tex-math></inline-formula> outperform the other values of <inline-formula> <tex-math notation=""LaTeX"">$p$ </tex-math></inline-formula>, respectively.<fn id=""fn1""><label><sup>1</sup></label><p>Replica method is a widely accepted heuristic in statistical physics for analyzing large disordered systems.</p></fn>",2017,IEEE Transactions on Information Theory
Structural studies of thymidine kinases from Bacillus anthracis and Bacillus cereus provide insights into quaternary structure and conformational changes upon substrate binding.,"Thymidine kinase (TK) is the key enzyme in salvaging thymidine to produce thymidine monophosphate. Owing to its ability to phosphorylate nucleoside analogue prodrugs, TK has gained attention as a rate-limiting drug activator. We describe the structures of two bacterial TKs, one from the pathogen Bacillus anthracis in complex with the substrate dT, and the second from the food-poison-associated Bacillus cereus in complex with the feedback inhibitor dTTP. Interestingly, in contrast with previous structures of TK in complex with dTTP, in this study dTTP occupies the phosphate donor site and not the phosphate acceptor site. This results in several conformational changes compared with TK structures described previously. One of the differences is the way tetramers are formed. Unlike B. anthracis TK, B. cereus TK shows a loose tetramer. Moreover, the lasso-domain is in open conformation in B. cereus TK without any substrate in the active site, whereas in B. anthracis TK the loop conformation is closed and thymidine occupies the active site. Another conformational difference lies within a region of 20 residues that we refer to as phosphate-binding beta-hairpin. The phosphate-binding beta-hairpin seems to be a flexible region of the enzyme which becomes ordered upon formation of hydrogen bonds to the alpha-phosphate of the phosphate donor, dTTP. In addition to descriptions of the different conformations that TK may adopt during the course of reaction, the oligomeric state of the enzyme is investigated.",2007,The FEBS journal
How to Predict Mood? Delving into Features of Smartphone-Based Data,"Smartphones are increasingly utilized in society and enable scientists to record a wide range of behavioral and environmental information. These information, referred to as Unobtrusive Ecological Momentary Assessment Data, might support prediction procedures regarding the mood level of users and simultaneously contribute to an enhancement of therapy strategies. In this paper, we analyze how the mood level of healthy clients is affected by unobtrusive measures and how this kind of data contributes to the prediction performance of various statistical models (Bayesian methods, Lasso procedures, etc.). We conduct analyses on a non-user and a user level. We then compare the models by utilizing introduced performance measures. Our findings indicate that the prediction performance increases when considering individual users. However, the implemented models only perform slightly better than the introduced mean model. Indicated by feature selection methods, we assume that more meaningful variables regarding the outcome can potentially increase prediction performance.",2016,
Node estimate for sparse random vector functional-link networks,"A random vector functional-link (RVFL) network is a neural network composed of a randomised hidden layer and an adaptable output layer. Training such a network is reduced to a linear least-squares problem, which can be solved efficiently. Still, selecting a proper number of nodes in the hidden layer is a critical issue, since an improper choice can lead to either overfitting or underfitting for the problem at hand. Additionally, small sized RVFL networks are favoured in situations where computational considerations are important. In the case of RVFL networks with a single output, unnecessary neurons can be removed adaptively with the use of sparse training algorithms such as Lasso, which are suboptimal for the case of multiple outputs. In this paper, we extend some prior ideas in order to devise a group sparse training algorithm which avoids the shortcomings of previous approaches. We validate our proposal on a large set of experimental benchmarks, and we analyse several state-of-the-art optimisation techniques in order to solve the overall training problem. We show that the proposed approach can obtain an accuracy comparable to standard algorithms, while at the same time resulting in extremely sparse hidden layers.",2016,
Predicting miRNA targets for head and neck squamous cell carcinoma using an ensemble method,"Background: This study aimed to uncover potential microRNA (miRNA) targets in head and neck squamous cell carcinoma (HNSCC) using an ensemble method which combined 3 different methods: Pearsonâ€™s correlation coefficient (PCC), Lasso and a causal inference method (i.e., intervention calculus when the directed acyclic graph (DAG) is absent [IDA]), based on Borda count election. Methods: The Borda count election method was used to integrate the top 100 predicted targets of each miRNA generated by individual methods. Afterwards, to validate the performance ability of our method, we checked the TarBase v6.0, miRecords v2013, miRWalk v2.0 and miRTarBase v4.5 databases to validate predictions for miRNAs. Pathway enrichment analysis of target genes in the top 1,000 miRNAâ€“messenger RNA (mRNA) interactions was conducted to focus on significant KEGG pathways. Finally, we extracted target genes based on occurrence frequency â‰¥3. Results: Based on an absolute value of PCC >0.7, we found 33 miRNAs and 288 mRNAs for further analysis. We extracted 10 target genes with predicted frequencies not less than 3. The target gene MYO5C possessed the highest frequency, which was predicted by 7 different miRNAs. Significantly, a total of 8 pathways were identified; the pathways of cytokineâ€“cytokine receptor interaction and chemokine signaling pathway were the most significant. Conclusions: We successfully predicted target genes and pathways for HNSCC relying on miRNA expression data, mRNA expression profile, an ensemble method and pathway information. Our results may offer new information for the diagnosis and estimation of the prognosis of HNSCC.",2018,The International Journal of Biological Markers
Standard vaccines incr ease HIV-1 transcription during antiretroviral therapy,"Methods: Twenty-six HIV-infected individuals on suppressive antiretroviral therapy were randomized to receive a vaccination schedule (n1â„413) or placebo (n1â„413). Cellassociated RNA and DNA were extracted from peripheral blood mononuclear cells, and HIV was quantified by droplet digital PCR using primers for gag and 2-LTR (for HIV DNA), unspliced gag RNA (gag usRNA), multispliced tat-rev RNA (tat-rev msRNA) and polyA mRNA.",2016,
Genomic selection for meat quality traits in Nelore cattle.,"The objective of this study was to present heritability estimates and accuracy of genomic prediction using different methods for meat quality traits in Nelore cattle. Approximately 5000 animals with phenotypes and genotypes of 412,000 SNPs, were divided into two groups: (1) training population: animals born from 2008 to 2013 and (2) validation population: animals born in 2014. A single-trait animal model was used to estimate heritability and to adjust the phenotype. The methods of GBLUP, Improved Bayesian Lasso and Bayes CÏ€ were performed to estimate the SNP effects. Accuracy of genomic prediction was calculated using Pearson's correlations between direct genomic values and adjusted phenotypes, divided by the square root of heritability of each trait (0.03-0.19). The accuracies varied from 0.23 to 0.73, with the lowest accuracies estimated for traits associated with fat content and the greatest accuracies observed for traits of meat color and tenderness. There were small differences in genomic prediction accuracy between methods.",2019,Meat science
On universality of finite products of Polish spaces,"Weintroduce and study the n-DimensionalPerfect Homotopy Approximation Property(briefly n-PHAP)equivalent to thediscreten-Cellspropertyln therealm ofLCn-SpaCeS.Itis shown thattheproductXx Y ofaspace Xwithn-PHAP anda space Y Withm-PHAPhas(n+m+1)-PHAP.Wederiveä¸˜omthisthatfbra (nowhereloca11ycompact)locallyconnectedPolishspaceXwithout ä¸˜ee arcs and fbr each nâ‰§O the power Xn+1contains a closed topologicalcopy of each at most n-dimensionalcompact(respãƒ» Polish)space. AtopologlCalspaceXisca11edä¿®ä¸€universal,Where(ç´†isaclassofspaces,if X contains aclosed topologlCalcopyofeach space Câˆˆä¿®ãƒ»Byã‚‰A@o andJWIWe denote the classes of metrizable compacta and Polish(=SeParable completer metrizable)spaces,reSPeCtively.Foraclasså“²ofspacesby q[n]we denotethe subclass ofå“²consistlng Of allspaces Câˆˆå“²with dimCâ‰¦nãƒ»Alltopo ãƒ»å©(ãƒ»å…«å·â€²è¡€ãƒ ãƒªVI/è¡€â€²/â€²(ä¸€/å²¬=ãƒ»â€˜è‚Œä¸€â€²å·ã€ƒå±±ãƒ‹â€˜â€²/ç—‡â€˜ä»™/ãƒ»~å©lè‚Œæ­¤ä¸€ã€â€œ//å·å²¬ã€ãƒ»ã€Ÿæ±€...â€²åœ",2004,Tsukuba journal of mathematics
Stationary-sparse causality network learning,"Recently, researchers have proposed penalized maximum likelihood to identify network topology underlying a dynamical system modeled by multivariate time series. The time series of interest are assumed to be stationary, but this restriction is never taken into consideration by existing estimation methods. Moreover, practical problems of interest may have ultra-high dimensionality and obvious node collinearity. In addition, none of the available algorithms provides a probabilistic measure of the uncertainty for the obtained network topology which is informative in reliable network identification. The main purpose of this paper is to tackle these challenging issues. We propose the S2 learning framework, which stands for stationary-sparse network learning. We propose a novel algorithm referred to as the Berhu iterative sparsity pursuit with stationarity (BISPS), where the Berhu regularization can improve the Lasso in detection and estimation. The algorithm is extremely easy to implement, efficient in computation and has a theoretical guarantee to converge to a global optimum. We also incorporate a screening technique into BISPS to tackle ultra-high dimensional problems and enhance computational efficiency. Furthermore, a stationary bootstrap technique is applied to provide connection occurring frequency for reliable topology learning. Experiments show that our method can achieve stationary and sparse causality network learning and is scalable for high-dimensional problems.",2013,J. Mach. Learn. Res.
Value of radiomics in differential diagnosis of chromophobe renal cell carcinoma and renal oncocytoma,"To explore the value of CT-enhanced quantitative features combined with machine learning for differential diagnosis of renal chromophobe cell carcinoma (chRCC) and renal oncocytoma (RO). Sixty-one cases of renal tumors (chRCCâ€‰=â€‰44; ROâ€‰=â€‰17) that were pathologically confirmed at our hospital between 2008 and 2018 were retrospectively analyzed. All patients had undergone preoperative enhanced CT scans including the corticomedullary (CMP), nephrographic (NP), and excretory phases (EP) of contrast enhancement. Volumes of interest (VOIs), including lesions on the images, were manually delineated using the RadCloud platform. A LASSO regression algorithm was used to screen the image features extracted from all VOIs. Five machine learning classifications were trained to distinguish chRCC from RO by using a fivefold cross-validation strategy. The performance of the classifier was mainly evaluated by areas under the receiver operating characteristic (ROC) curve and accuracy. In total, 1029 features were extracted from CMP, NP, and EP. The LASSO regression algorithm was used to screen out the four, four, and six best features, respectively, and eight features were selected when CMP and NP were combined. All five classifiers had good diagnostic performance, with area under the curve (AUC) values greater than 0.850, and support vector machine (SVM) classifier showed a diagnostic accuracy of 0.945 (AUC 0.964â€‰Â±â€‰0.054; sensitivity 0.999; specificity 0.800), showing the best performance. Accurate preoperative differential diagnosis of chRCC and RO can be facilitated by a combination of CT-enhanced quantitative features and machine learning.",2019,Abdominal Radiology
Short-term Power Load Forecasting of Residential Community Based on GRU Neural Network,"The power load of residential community has the characteristics of wild fluctuations, complex influence factors and difficult forecasting. To deal with that, a short-term load forecasting (STLF) method for residential community based on gated recurrent unit (GRU) neural network was proposed. The least absolute shrinkage and selection operator (Lasso) and partial correlation analysis are used to analyze the influence of temperature, humidity, rainfall and wind speed on the load. It shows that the average temperature affects the change of the load most among various factors, thus the average temperature is added as an input variable to the load forecasting model based on GRU network. The simulation results show that the proposed method is faster within the similar forecasting accuracy, compared with the long short-term memory (LSTM) network and traditional recurrent neural network (RNN). Itâ€™s proven to be a more effective residential community short-term load forecasting method.",2018,2018 International Conference on Power System Technology (POWERCON)
Short-term traffic flow forecasting: Multi-metric KNN with related station discovery,"Nonparametric regression is a classic method for short-term traffic flow forecasting in Intelligent Transportation Systems (ITS). Feature space construction and distance metric selection are two important parts in nonparametric regression. Few of previous works have taken both these two aspects into account together. In addition, how to use information of related stations in network scale is a key to improve the performance of ITS. In this paper, we propose a novel three-stage framework based on KNN to handle the issues above for short-term traffic flow forecasting. In the first stage, the related origin stations and destination stations of target task are discovered from the whole traffic network. Then for each target task, a particular distance metric is learned in the second stage. Finally, an extended multi-metric k-nearest neighbor regression model is built in the third stage. Experimental results on real-world traffic dataset show that our multi-metric KNN model with Lasso outperforms the traditional KNN model and the feature construction method is effective.",2015,2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)
HOMINID: a framework for identifying associations between host genetic variation and microbiome composition,"Recent studies have uncovered a strong effect of host genetic variation on the composition of host-associated microbiota. Here, we present HOMINID, a computational approach based on Lasso linear regression, that given host genetic variation and microbiome taxonomic composition data, identifies host single nucleotide polymorphisms (SNPs) that are correlated with microbial taxa abundances. Using simulated data, we show that HOMINID has accuracy in identifying associated SNPs and performs better compared with existing methods. We also show that HOMINID can accurately identify the microbial taxa that are correlated with associated SNPs. Lastly, by using HOMINID on real data of human genetic variation and microbiome composition, we identified 13 human SNPs in which genetic variation is correlated with microbiome taxonomic composition across body sites. In conclusion, HOMINID is a powerful method to detect host genetic variants linked to microbiome composition and can facilitate discovery of mechanisms controlling host-microbiome interactions.",2017,GigaScience
Learning Gaussian Graphical Models Using Discriminated Hub Graphical Lasso,"We develop a new method called Discriminated Hub Graphical Lasso (DHGL) based on Hub Graphical Lasso (HGL) by providing the prior information of hubs. We apply this new method in two situations: with known hubs and without known hubs. Then we compare DHGL with HGL using several measures of performance. When some hubs are known, we can always estimate the precision matrix better via DHGL than HGL. When no hubs are known, we use Graphical Lasso (GL) to provide information of hubs and find that the performance of DHGL will always be better than HGL if correct prior information is given, and will rarely degenerate when the prior information is incorrect.",2018,"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Komponist Und Musicus Im Renaissance-zeitalter,"Das Jahrhundert DÃ¼rers, Leonardo da Vincis, Calderons und Orlando di Lassos, das die individuelle schÃ¶pferische Leistung in Wissenschaften und KÃ¼nsten hochschÃ¤tzte, steigerte die Verehrung des KÃ¼nstlers bis zur Glorifizierung als eines â€žhuomo divin o "" . Dieses Zeitalter reflektierte auch erstmals im Bereiche der Musik zwei bis dahin nur beilÃ¤ufig verwendete Termini, und zwar â€žaucteur"" und â€žcomposi tor"" sowie â€žopus musicum"". Beide Vokabeln, die Berufsbezeichnung wie die Sachbezeichnung, werden seit der Wende vom 15. zum 16. Jahrhundert auch auf schriftlich fixierte, klingende Zeitgestalten angewendet, die von KÃ¼nstlern hergestellt sind, ohne in der Natur gegenstÃ¤ndlich vorhanden zu sein. Kunstwerke wurden bis dahin lediglich von BildkÃ¼nstlern und Poeten geschaffen. Tonwerke gab es zwar spÃ¤testens seit dem 14. Jahrhundert, seit der sogenannten Ars antiqua und Ars nova, indessen wurden diese stets nur in Stimmen notierten Gebilde nicht als solche erkannt und definiert. Es blieb dem Renaissance-Zeitalter vorbehalten, das vollkommene musikalische Kunstwerk und den ingeniÃ¶sen Komponisten als gleichwertige Erscheinungen einer von Menschen mitgeschaffenen Kultur im Bereich der KÃ¼nste anzuerkennen. Seither ziehen Werke der Kunst einen Sinn und eine DignitÃ¤t an sich, die vordem ungeteilt nur den gÃ¶ttlichen Werken zukam.",1975,Ã–sterreichische Musikzeitschrift
High-dimensional immunomonitoring models of HIV-1-specific CD8 T-cell responses accurately identify subjects achieving spontaneous viral control.,"UNLABELLED
The development of immunomonitoring models to determine HIV-1 vaccine efficacy is a major challenge. Studies suggest that HIV-1â€“specific CD8 T cells play a critical role in subjects achieving spontaneous viral control (HIV-1 controllers) and that they will be important in immune interventions. However, no single CD8 T-cell function is uniquely associated with controller status and the heterogeneity of responses targeting different epitopes further complicates the discovery of determinants of protective immunity. In the present study, we describe immunomonitoring models integrating multiple functions of epitope-specific CD8 T cells that distinguish controllers from subjects with treated or untreated progressive infection. Models integrating higher numbers of variables and trained with the least absolute shrinkage and selection operator (LASSO) variant of logistic regression and 10-fold cross-validation produce â€œdiagnostic testsâ€ that display an excellent capacity to delineate subject categories. The test accuracy reaches 75% area under the receiving operating characteristic curve in cohorts matched for prevalence of protective alleles. Linear mixed-effects model analyses show that the proliferative capacity, cytokine production, and kinetics of cytokine secretion are associated with HIV-1 control. Although proliferative capacity is the strongest single discriminant, integrated modeling of different dimensions of data leverages individual associations. This strategy may have important applications in predictive model development and immune monitoring of HIV-1 vaccine trials.


KEY POINTS
Immune monitoring models integrating multiple functions of HIV-1-specific CD8 T cells distinguish controllers from subjects with progressive HIV-1 infection. This strategy may have important applications in predictive model development and immune monitoring of HIV-1 vaccine trials.",2013,Blood
Bacterial chemotaxis in the ultraoligotrophic Eastern Mediterranean Sea - molecular and culture-based analyses,2.3 Phosphate â€“ an essential nutrient for microbial life 10 2.3.1 The marine phosphorus cycle 11 2.3.2 Bacteria exhibit various strategies to cope with low concentrations of inorganic phosphate 13 2.4 Chemotaxis in marine bacteria 16 2.4.1 Chemotaxis in prokaryotes 16 2.4.2 Chemotaxis and its implications in the marine environment 18 2.5 The Alphaproteobacterium Thalassospira sp. 21 2.6 Aim of the present work 23 3 Material and Methods 25 3.1 Physiological methods and in situ measurements 25 3.1.1 Samling locations and in situ measurements 25 3.1.2 Bacterial cell numbers 25 3.1.3 Measuring of exoenzymatic activities using fluorogenic substrate analogues 26 3.1.4 Growth experiments in dialysis cultures 27 3.1.5,2011,
Eight key long non-coding RNAs predict hepatitis virus positive hepatocellular carcinoma as prognostic targets,"BACKGROUND
Hepatitis B virus, together with hepatitis C virus, has been recognized as the leading causes of hepatocellular carcinoma (HCC). Long non-coding RNAs (lncRNAs) have been suggested in increasing studies to be the potential prognostic factors for HCC. However, the role of combined application of lncRNAs in estimating overall survival (OS) for hepatitis virus positive HCC (VHCC) is uncertain.


AIM
To construct an lncRNA signature related to the OS of VHCC patients to enhance the accuracy of prognosis prediction.


METHODS
The expression patterns of lncRNAs, as well as related clinical data were collected from 149 VHCC patients from The Cancer Genome Atlas database. The R package was adopted to obtain the differentially expressed lncRNAs (DElncRNAs). LncRNAs significantly associated with OS were screened by means of univariate Cox regression analysis, so as to construct a least absolute shrinkage and selection operator (LASSO) model. Subsequently, the constructed lncRNA signature was developed and validated. Afterwards, the prognostic nomogram was established, which combined the as-established lncRNA signature as well as the clinical features. Meanwhile, subgroup analysis stratified by the virus type was also performed. Finally, the above-mentioned lncRNAs were enriched to corresponding pathways according to the markedly co-expressed genes.


RESULTS
A total of 1420 DElncRNAs were identified, among which 406 were significant in univariate Cox regression analysis. LASSO regression confirmed 8 out of the 406 lncRNAs, including AC005722.2, AC107959.3, AL353803.1, AL589182.1, AP000844.2, AP002478.1, FLJ36000, and NPSR1-AS1. Then, the prognostic risk score was calculated. Our results displayed a significant association between the risk model and the OS of VHCC [hazard ratio = 1.94, 95% confidence interval (CI): 1.61-2.34, log-rank P = 2e-10]. The inference tree suggested that the established lncRNA signature was useful in the risk stratification of VHCC. Furthermore, a nomogram was plotted, and the concordance index of internal validation was 0.763 (95%CI: 0.700-0.826). Moreover, the subgroup analysis regarding etiology confirmed this risk model. In addition, the Wnt signaling pathway, angiogenesis, the p53 pathway, and the PI3 kinase pathway were the remarkably enriched pathways.


CONCLUSION
An eight-lncRNA signature has been established to predict the prognosis for VHCC, which contributes to providing a novel foundation for the targeted therapy of VHCC.",2019,World Journal of Gastrointestinal Oncology
Variable Selection in Composite Quantile Regression Models with Adaptive Group Lasso,"Variable selection plays an important role in the model building process. In this paper, we extend the oracle properties of adaptive group lasso penalty to the context of composite quantile regression model, simultaneously estimate regression coefficient and implement variable selection in linear regression model. By combing the information of multiple quantile regression models, we obtain the more efficient estimator of the regression coefficient compared to the standard least square estimator. In addition, we show theoretically that our proposed method is able to identify the true model consistently, and the resulting estimator can be as efficient as oracle. A real data analysis confirmed that the optimal model selected by the adaptive group lasso based on composite quantile regression procure consistently demonstrate the smallest average model size, regardless of which selection method is used.",2013,International journal of applied mathematics and statistics
"Household expenditure on malaria prevention and treatment for families in the town Bobo-Dioulasso, Burkina Faso.","Abstract A study of household expenditure associated with malaria prevention and treatment was carried out in the town of Bobo-Dioulasso, Burkina Faso. In January 1992 interviews were conducted with the heads of 150 families concerning expenditure during the past 6 months (corresponding to the peak transmission season). Families were selected by cluster sampling in the central, intermediate and outlying zones of the town. Families consisted of 6â€“7 people on average and had a total average monthly income of US $288 per month. During the preceding transmission season families had experienced an average of 16 episodes of malaria (â€˜feverâ€™) and 85% treated this illness with traditional or modern drugs without reference to a health agent or healer. Seventy-seven per cent of families had been given a prescription by a health agent for one or more episodes of malaria. The average total cost of treatment for the preceding 6 months was US $42 per family. Malaria prevention techniques included chemical prophylaxis, aerosol sprays, mosquito coils and non-im-pregnated bed nets and the average cost over the previous 6 months was estimated as US $33 per family. Expenditure for prevention and treatment was highest in the central zone of the town. The overall expenditure on malaria prevention and treatment (US $75) was nearly 5% of total family income during the 6 months transmission season. These findings confirm that there is a pattern of high expenditure on disease prevention and treatment among families in many parts of Africa and suggest that family resources could be used more effectively to promote better health.",1994,Transactions of the Royal Society of Tropical Medicine and Hygiene
TemperaturabhÃ¤ngigkeit der ZerreiÃŸfestigkeit von GlasstÃ¤ben,"ZusammenfassungDie Festigkeit von GlasstÃ¤ben gegen Zugbeanspruchung ist im Falle des ZerreiÃŸens unter â€žSpiegelâ€œbildung mindestens durch zwei verschiedene Materialkonstanten zu kennzeichnen: a) die untere ZerreiÎ²grenze Zu im Falle vollkommen spiegelnder BruchflÃ¤chen, b) die obere ZerreiÎ²grenze Z0, welche fÃ¼r mÃ¤ÃŸige SpiegelgrÃ¶ÃŸen (5 bis 40% des StÃ¤bchenquerschnitts) in einfacher Weise aus der gewÃ¶hnlichen ZerreiÃŸfestigkeit errechnet werden kann. Die AbhÃ¤ngigkeit der SpiegelgrÃ¶ÃŸen sowie der oberen ZerreiÃŸgrenze Z0 vom StÃ¤bchenquerschnitt, der Vorbehandlung des Materials und der Versuchstemperatur wird fÃ¼r sechs verschiedene Glassorten untersucht. Die Abnahme von Z0 bei steigender Temperatur ist desto stÃ¤rker, je grÃ¶ÃŸer der Temperaturgang des ElastizitÃ¤tsmoduls der betreffenden Glassorte. Sie ist erheblich grÃ¶ÃŸer als nach der Griffithschen Bruchtheorie zu erwarten wÃ¤re, doch dÃ¼rfte die letztere ohne weitere Ausgestaltung nur fÃ¼r die untere ZerreiÃŸgrenze Zu maÃŸgebend sein.",1931,Zeitschrift fÃ¼r Physik
"Supporting Information for: Forecasting dengue and influenza incidences using a sparse representation of Google trends, electronic health records, and time series data","The Autoregressive Likelihood Ratio algorithm is an example of a stepwise regression method where we start with a trivial autoregressive model and then build up a sparse model by adding only the most statistically significant variables and removing the least significant variables using a statistically principled approach. The algorithm is described below. In the subsequent section, a novel technique that enables a computationally efficient implementation of the algorithm is described. Next, Autoregressive Likelihood Ratio method is compared with the lasso method. The time complexity of the two methods are compared in the final section.",2019,
"""Love ya, jerkface"": Using Sparse Log-Linear Models to Build Positive and Impolite Relationships with Teens","One challenge of implementing spoken dialogue systems for long-term interaction is how to adapt the dialogue as user and system become more familiar. We believe this challenge includes evoking and signaling aspects of long-term relationships such as rapport. For tutoring systems, this may additionally require knowing how relationships are signaled among non-adult users. We therefore investigate conversational strategies used by teenagers in peer tutoring dialogues, and how these strategies function differently among friends or strangers. In particular, we use annotated and automatically extracted linguistic devices to predict impoliteness and positivity in the next turn. To take into account the sparse nature of these features in real data we use models including Lasso, ridge estimator, and elastic net. We evaluate the predictive power of our models under various settings, and compare our sparse models with standard non-sparse solutions. Our experiments demonstrate that our models are more accurate than non-sparse models quantitatively, and that teens use unexpected kinds of language to do relationship work such as signaling rapport, but friends and strangers, tutors and tutees, carry out this work in quite different ways from one another.",2012,
Moving Beyond Sub-Gaussianity in High-Dimensional Statistics: Applications in Covariance Estimation and Linear Regression,"Concentration inequalities form an essential toolkit in the study of high-dimensional statistical methods. Most of the relevant statistics literature is based on the assumptions of sub-Gaussian/sub-exponential random vectors. In this paper, we bring together various probability inequalities for sums of independent random variables under much weaker exponential type (sub-Weibull) tail assumptions. These results extract a part sub-Gaussian tail behavior in finite samples, matching the asymptotics governed by the central limit theorem, and are compactly represented in terms of a new Orlicz quasi-norm - the Generalized Bernstein-Orlicz norm - that typifies such tail behaviors. 
We illustrate the usefulness of these inequalities through the analysis of four fundamental problems in high-dimensional statistics. In the first two problems, we study the rate of convergence of the sample covariance matrix in terms of the maximum elementwise norm and the maximum k-sub-matrix operator norm which are key quantities of interest in bootstrap procedures and high-dimensional structured covariance matrix estimation. The third example concerns the restricted eigenvalue condition, required in high dimensional linear regression, which we verify for all sub-Weibull random vectors under only marginal (not joint) tail assumptions on the covariates. To our knowledge, this is the first unified result obtained in such generality. In the final example, we consider the Lasso estimator for linear regression and establish its rate of convergence under much weaker tail assumptions (on the errors as well as the covariates) than those in the existing literature. The common feature in all our results is that the convergence rates under most exponential tails match the usual ones under sub-Gaussian assumptions. Finally, we also establish a high-dimensional CLT and tail bounds for empirical processes for sub-Weibulls.",2018,arXiv: Statistics Theory
Use of machine learning approaches to compare the contribution of different types of data for predicting an individual's risk of ill health: an observational study,"Abstract Background Public health science has made considerable effort to understand the determinants of health. Although substantial gains have been made in understanding the determinants of population health, our ability to translate discoveries at the population level towards discriminating between cases and non-cases of disease at the individual level has been limited despite increasing availability of data. This study draws from the recent advances in machine learning approaches to explore whether such methods can revolutionise how we build predictive models of health using social survey data. Methods Data from the Understanding Society survey (wave 2 [2010â€“12], 6830 individuals who took part in all aspects of data collection and for whom all data were included) were used to measure five types of data: personal (eg, age, sex), social (eg, occupation, education), health (eg, body weight, grip strength), biomarker (eg, cholesterol, hormones), and genetic. Outcome variables were presence of a limiting long-term illness, and type of illness or disability (eg, hypertension) 1 and 5 years from baseline (both overall status and predicting only new cases). Variable reduction was applied on the explanatory measures (âˆ¼200) within data type using LASSO regression. Deep learning via neural networks (using k-fold cross validation) was used to build predictive models on training data (75% of total sample). Model evaluation was performed on test data (25%) and compared several model fit statistics (eg, accuracy, sensitivity, specificity). Model fit was compared with simpler logistic regression models. Findings Health data had the strongest prediction of future health status (test data accuracy 71%), with personal data (61%) the poorest performing data type. Within the health data, physical activity and presence of some health conditions were strong individual predictors. Models only allowed for shallow learning of data, with more complex models adding little or reducing performance. However, the models only offered marginal improvements (âˆ¼1â€“2% accuracy improvements) compared with logistic regression models. Interpretation The project makes two main contributions to public health science: the evaluation of different data types and their relative contributions as predictors of health status; and exploring the potential of machine learning to improve predictive models of ill health. Funding Understanding Society Biomedical Data Fellowship Programme. The funder had no role in the research.",2018,The Lancet
"Comparative study of computational algorithms for the Lasso with high-dimensional, highly correlated data","Variable selection is important in high-dimensional data analysis. The Lasso regression is useful since it possesses sparsity, soft-decision rule, and computational efficiency. However, since the Lasso penalized likelihood contains a nondifferentiable term, standard optimization tools cannot be applied. Many computation algorithms to optimize this Lasso penalized likelihood function in high-dimensional settings have been proposed. To name a few, coordinate descent (CD) algorithm, majorization-minimization using local quadratic approximation, fast iterative shrinkage thresholding algorithm (FISTA) and alternating direction method of multipliers (ADMM). In this paper, we undertake a comparative study that analyzes relative merits of these algorithms. We are especially concerned with numerical sensitivity to the correlation between the covariates. We conduct a simulation study considering factors that affect the condition number of covariance matrix of the covariates, as well as the level of penalization. We apply the algorithms to cancer biomarker discovery, and compare convergence speed and stability.",2016,Applied Intelligence
"Flow pattern and residence time of groundwater within the south-eastern Taoudeni sedimentary basin (Burkina Faso, Mali)","The knowledge about groundwater flow conditions within the Southeastern Taoudeni Basin Aquifer shared by Burkina Faso and Mali is relatively limited with very little information on potentiometric heads, recharge processes, residence time and water quality. A better evaluation of groundwater resources in this area is a strategic point for water resources management in the entire Soudano-Sahelian region which endures since the beginning of the twentieth century a continuous decrease in precipitation amount. This paper provides a transboundary synthesis using water (18O, 2H and 3H) and carbon isotopes (13C and 14C) in conjunction with hydrogeological and hydrochemical data. The objectives are to improve the conceptual model of groundwater recharge and flow within this sandstone reservoir, and to assess the changes in the aquifer due to water abstraction and recent climate changes including an insight into Sahelian aquifers palaeorecharge processes. The local meteoric water line for the Bobo-Dioulasso station is proposed: Î´2HÂ =Â 8.0 (Â±0.5)Î´18OÂ +Â 10.2 (Â±2.1). Two main tendencies can be derived from groundwater chemistry. First, a slight evolution from the Caâ€“Mgâ€“HCO3 type towards a Naâ€“Kâ€“HCO3 type that indicates developed interactions between groundwater and clay minerals related to the residence time of groundwater. A second tendency towards Clâ€“NO3â€“SO4â€“HCO3 water types indicates the anthropogenic influence on groundwater related to the poor sanitary conditions observed around wells. The carbon-14 activity measured on the TDIC varies between 0.3 and 122Â pmC, so our record contains samples covering a wide period from Actual to Pleistocene suggesting a continuous recharge of the system through time even if the Sahel region has endured many different climate phases which have influenced the infiltration and recharge processes. All groundwater samples have stable isotope compositions in the range of the present day regional and global meteoric water line which suggests that the sampled groundwater was not significantly affected by evaporation during recharge. Evolved waters are depleted relative to unevolved samples by 1.5â€“2â€° in Î´18O and 10â€“15â€° in Î´2H. The whole dataset support the hypothesis of a largely unified homogeneous aquifer system with a multilayered structure but it also points out the very low renewability of the resource and a strong anthropogenic contamination of the shallowest horizons.",2011,Journal of Hydrology
Prognostic value of immune-related genes in clear cell renal cell carcinoma,"Clear cell renal cell carcinoma (ccRCC) is the most common pathological subtype of renal cell carcinoma, and immune-related genes (IRGs) are key contributors to its development. In this study, the gene expression profiles and clinical data of ccRCC patients were downloaded from The Cancer Genome Atlas database and the cBioPortal database, respectively. IRGs were obtained from the ImmPort database. We analyzed the expression of IRGs in ccRCC, and discovered 681 that were differentially expressed between ccRCC and normal kidney tissues. Univariate Cox regression analysis was used to identify prognostic differentially expressed IRGs (PDEIRGs). Using Lasso regression and multivariate Cox regression analyses, we detected seven optimal PDEIRGs (PLAU, ISG15, IRF9, ARG2, RNASE2, SEMA3G and UCN) and used them to construct a risk model to predict the prognosis of ccRCC patients. This model accurately stratified patients with different survival outcomes and precisely identified patients with different mutation burdens. Our findings suggest the seven PDEIRGs identified in this study are valuable prognostic predictors in ccRCC patients. These genes could be used to investigate the developmental mechanisms of ccRCC and to design individualized treatments for ccRCC patients.",2019,Aging (Albany NY)
Update on BCR-ABL 1-like precursor B-cell acute lymphoblastic leukemia,"Precursor B-cell acute lymphoblastic leukemia (B-ALL) is the most common type of leukemia in children and young adults. Our understanding of the genetic basis of B-ALL has greatly improved in recent years. Application of genomic profiling and sequencing has led to the identification of a clinically important subgroup of B-ALL patients who are BCR-ABL1 negative, but exhibit a gene expression profile similar to that of BCR-ABL1-positive ALL. This new subgroup has been referred to as BCR-ABL1-like ALL. Like BCR-ABL1-positive ALL, BCR-ABL1-like ALL patients are in the high-risk category, associated with poor outcome. The BCR-ABL1-like patients have a diverse range of genetic alterations that activate tyrosine kinase signaling. The recurrent genetic changes include ABL classor JAK pathway-associated translocations and IKZF1 deletions. Herein, we review the recent progress in BCR-ABL1-like ALL, the recurrent genetic alterations seen in these patients, and the therapeutic potential of targeting the identified molecular changes.",2016,
Fast and robust model selection based on ranks.,"We consider the problem of identifying important predictors in large data bases, where the relationship between the response variable and the explanatory variables is specified by the general single index model, with unknown link function and unknown distribution of the error term. We utilize the natural robust and efficient approach, which relies on replacing values of the response variable with their ranks and then identifying important predictors by using the well known LASSO. The resulting RankLasso coincides with the previously proposed distribution-based LASSO, where the relationship with the rank approach was not realized. We refine the consistency results for RankLasso provided in the earlier papers and extend the scope of applications of this method by proposing its thresholded and adaptive versions. We present theoretical results which show that similarly as in the context of regular LASSO, the proposed modifications are model selection consistent under much weaker assumptions than RankLasso. These theoretical results are illustrated by extensive simulation study, which shows that the proposed procedures are indeed much more efficient than the vanilla version of RankLasso and that they can properly identify relevant predictors, even if the error terms come from the Cauchy distribution. The simulation study shows also that concerning model selection RankLasso performs substantially better than LADLasso, which is a well established methodology for robust model selection.",2019,arXiv: Methodology
Gabon centre refocuses on emerging diseases,"In the latest twist in the tug-of-war between Native Americans and anthropologists, officials at the University of California have decided not to repatriate a pair of well-preserved skeletons that are nearly 10,000 years old. Archaeology students unearthed the bones in 1976 near the clifftop home of the chancellor of the University of California, San Diego (UCSD). It may be possible to extract some of the oldest human DNA in North America from the exquisitely preserved remains, say researchers. But in the past two years the bones have become a political football over US$7-million plans to demolish and rebuild the house. A group of 13 local bands, known as the Kumeyaay tribes, argued that the site was a sacred burial site, and that the bones found there should be repatriated to them. In March this year, UCSD dropped plans to knock down the house, opting instead for a renovation. But last week, University of California officials notified federal authorities that the bones could not be proved to be culturally affiliated with the Kumeyaay and thus would not be returned. Steve Banegas, a tribal spokesman for the Kumeyaay, says they hadnâ€™t been notified of the decision. â€œThey are our relatives,â€ he says. â€œWe want them reburied. They should stop playing politics with the remains.â€ The dispute reflects the increasingly acrimonious debate over decisions involving ancient skeletons. In 2004, a federal court ruled that the roughly 9,300-year-old Kennewick Man skeleton, found in a riverbank in Washington state, should not be returned to local tribes that could not prove cultural affiliation. In other cases, usually involving younger bones, museums have returned specimens when they were shown to be culturally affiliated to local tribes. In San Diego, tribes newly enriched by casino earnings have enlisted powerful state legislators to their cause. Facing such pressure, University of California officials are reviewing the 10-campus universityâ€™s policy on how cultural affiliation is determined. Currently, decisions about cultural affiliation are made by a panel of scientists â€” typically including a Native American â€” at each campus. Campus actions are then reviewed by a nine-person University of California panel, which includes two Native Americans, before a final decision is reached. But in September, the office of Mark Yudof, the president of the University of California, initiated discussions about possibly eliminating the system-wide committee. Four prominent University of California anthropologists wrote a letter to Yudof on 30 September, strenuously objecting to the proposed change. They include Phillip Walker and Michael Glassow of the University of California, Santa Barbara; Robert Bettinger of the University of Californa, Davis; and Philip Wilke of the University of California, Riverside. â€œIt is counterproductive to devolve final decision-making authority to the often inexperienced and legally ill-informed level of the local campus,â€ says the letter. In an interview, Bettinger said that the system-wide panel serves as a vital form of peer review. â€œIf the analysis is not rigorous, something is missed or a campus drops the ball, the University of California system-wide panel can correct that,â€ he says. â€œThis has happened a bunch of times.â€ For instance, in 2001 the system-wide committee overruled a decision by the University of California, Los Angeles, in which skeletons and funerary objects were recommended for repatriation to the Kumeyaay.",2008,Nature
Discussion: The Dantzig selector: Statistical estimation when p is much larger than n,"n log p, where s is the dimension of the sparsest model. These are, respectively, the conditions of this paper using the Dantzig selector and those of Bunea, Tsybakov and Wegkamp [2] and Meinshausen and Yu [9] using the Lasso. Strictly speaking, Bunea, Tsybakov and Wegkamp consider only prediction, not l2 loss, but in a paper in preparation with Ritov and Tsybakov we show that the spirit of their conditions is applicable for l2 loss as well. Since these authors emphasize different points and use different normalizations, I thought it would be useful to present them together. Write the model as Y = XnÃ—pÎ² + e,",2007,Annals of Statistics
Development and verification of a nomogram for prediction of recurrenceâ€free survival in clear cell renal cell carcinoma,"Nowadays, gene expression profiling has been widely used in screening out prognostic biomarkers in numerous kinds of carcinoma. Our studies attempt to construct a clinical nomogram which combines risk gene signature and clinical features for individual recurrent risk assessment and offer personalized managements for clear cell renal cell carcinoma. A total of 580 differentially expressed genes (DEGs) were identified via microarray. Functional analysis revealed that DEGs are of fundamental importance in ccRCC progression and metastasis. In our study, 338 ccRCC patients were retrospectively analysed and a risk gene signature which composed of 5 genes was obtained from a LASSO Cox regression model. Further analysis revealed that identified risk gene signature could usefully distinguish the patients with poor prognosis in training cohort (hazard ratio [HR]Â =Â 3.554, 95% confidence interval [CI] 2.261-7.472, PÂ <Â .0001, nÂ =Â 107). Moreover, the prognostic value of this gene-signature was independent of clinical features (PÂ =Â .002). The efficacy of risk gene signature was verified in both internal and external cohorts. The area under receiver operating characteristic curve of this signature was 0.770, 0.765 and 0.774 in the training, testing and external validation cohorts, respectively. Finally, a nomogram was developed for clinicians and did well in the calibration plots. This nomogram based on risk gene signature and clinical features might provide a practical way for recurrence prediction and facilitating personalized managements of ccRCC patients after surgery.",2019,Journal of Cellular and Molecular Medicine
Short-Term Covid-19 Forecast for Latecomers,"The number of Covid-19 cases is increasing dramatically worldwide. Therefore, the availability of reliable forecasts for the number of cases in the coming days is of fundamental importance. We propose a simple statistical method for short-term real-time forecasting of the number of Covid-19 cases and fatalities in countries that are latecomers â€“ i.e., countries where cases of the disease started to appear some time after others. In particular, we propose a penalized (LASSO) regression with an error correction mechanism to construct a model of a latecomer in terms of the other countries that were at a similar stage of the pandemic some days before. By tracking the number of cases and deaths in those countries, we forecast through an adaptive rolling-window scheme the number of cases and deaths in the latecomer. We apply this methodology to Brazil, and show that (so far) it has been performing very well. These forecasts aim to foster a better short-run management of the health system capacity.",2020,
Penalization method for sparse time series model,"Vector autoregressive (VAR) model has been widely used in many field, e.g., genetics, science, economics and finance. Especially, in genetics, VAR model with high dimensional setting is studied extensively. In order to find a suitable VAR model and improve the forecasting accuracy, capability of true model selection is important matter in several areas. In recent years, numerous studies on penalization method have been going on for true model selection of VAR model. Haufe et al. (2008) proposed several sparse approaches (e.g. ridge regression and multiple test, granger causality test, lasso, group lasso). Ren and Zhang (2010) proposed the subset selection methods for VAR model using a adaptive lasso in order to overcome lassoâ€™s problem by different amount of penalty to each coefficient. Shimamura et al. (2009) proposed a recursive regularization for VAR model for n â‰¤ p case using an elastic net which has a combination penalty term the ridge and the lasso. However, existing penalization methods can not reflect properties of time series model with lagged variables. In order to improve the forecasting accuracy of univariate time series model, Park and Sakaori (2011) proposed a lag weighted lasso which reflects deceasing variable effect as the lag increase. The lag weighted lasso assigns different penalties depend on not only coefficient size but also lag effect. The superiority of the lag weighted lasso is identified in forecasting accuracy and true model selection for univariate time series model. In this study, we extend the lag weighted lasso from univariate to multivariate time series model. We also propose a lag weighted penalization methods for VAR model namely a lag weighted ridge regression and a lag weighted elastic net. And we show that superiority of the lag weighted penalization methods in forecasting accuracy and true model selection for VAR model.",2011,
Repositioning Technique for the Decompression of Symptomatic Dolichoectatic Vertebrobasilar Pathology: A Comprehensive Review of Sling Characteristics and Surgical Experience.,"OBJECTIVE
The repositioning of a dolichoectatic vertebrobasilar artery (VBA) for arterial decompression has been extensively used in the clinical setting. We aimed to describe and summarize the technical characteristics and clinical results of the sling technique.


METHODS
The terms ""dolichoectatic aneurysm,"" ""dolichoectasia,"" ""ectasia,"" and ""megadolichoectasia"" were used to search for pertinent reports related to the VBA territory. Studies related to the ""decompression,"" ""repositioning,"" ""transposition,"" ""anchoring,"" ""pexy,"" and ""sling"" techniques were screened, collected, and summarized by 1 of us (L.W.).


RESULTS
We identified 20 pertinent reports involving 59 cases. The sling repositioning techniques were divided into the following 4 subtypes: suture-lasso, vasculopexy, clip-lasso, and wrap-sling. Overall, 35 of the 59 patients (59.3%) were treated using the wrap-sling technique. Among these cases, Gore-Tex grafts were the most common sling material used. Of the cases with reported postoperative characteristics, all the patients except for 1 had experienced complete or significant remission of symptoms. Although 11 of the 59 patients (18.6%) had developed complications, the rate of adverse effects had decreased to 3.6% (2 of 55) during the long-term follow-up period (mean, 40.4 months; range, 2.1-168), and the outcomes were unremarkable in 54 of the 55 patients (98.2%).


CONCLUSIONS
The excellent surgical outcomes and durable long-term results suggest that the repositioning technique is highly effective in resolving symptoms related to the compression of DVB pathology. The wrap-sling technique might be the preferred option owing to the simultaneous symptom relief and lower rate of temporary complications. However, cranial nerve manipulation should be meticulously implemented to avoid permanent negative effects.",2019,World neurosurgery
Testing-Based Forward Model Selection,"This paper introduces and analyzes a procedure called Testing-based forward model selection (TBFMS) in linear regression problems. This procedure inductively selects covariates that add predictive power into a working statistical model before estimating a final regression. The criterion for deciding which covariate to include next and when to stop including covariates is derived from a profile of traditional statistical hypothesis tests. This paper proves probabilistic bounds for prediction error and the number of selected covariates, which depend on the quality of the tests. The bounds are then specialized to a case with heteroskedastic data with tests derived from Huber-Eicker-White standard errors. TBFMS performance is compared to Lasso and Post-Lasso in simulation studies. TBFMS is then analyzed as a component into larger post-model selection estimation problems for structural economic parameters. Finally, TBFMS is used to illustrate an empirical application to estimating determinants of economic growth.",2015,arXiv: Statistics Theory
"The Necessity of Contingency or Contingent Necessity: Meillassoux, Hegel, and the Subject","This article addresses the relationship of contingency to necessity as developed by Quentin Meillassoux and G.W.F. Hegel. Meillassoux criticizes the restriction of possibility by modern philosophy to the conditions of the transcendental subject, which he calls â€˜correlationismâ€™, and opposes to this correlationism, mathematics as an absolute form of thought. The arch-figure of a metaphysical version of correlationism for Meillassoux is Hegel. This article argues that, while Meillassoux is right to criticize a version of correlationism for restricting the range of contingency, he overlooks Hegelâ€™s unique contribution to this issue. Hegel provides us a version of necessity modeled on the mathematical proof which answers Meillassouxâ€™s concerns about correlationist versions of necessity but does not altogether jettison the concept of the subject. Instead, the subject in Hegel is a contingent interruption which emerges from the breaks in the kinds of necessity we posit about the world. Hegel offers us a way of tying these two concepts together in what I call â€˜contingent necessityâ€™.",2011,Cosmos and history: the journal of natural and social philosophy
Assessing the Efficiency of Health Facilities in Indonesia,"Despite increased expenditures in Indonesian health facilities since 1999, health outcomes remain relatively poor. Inefï¬ciency in health facilities contributes to the rising cost of healthcare. This thesis uses an innovative combination of ratio and frontier analyses to ascertain the factors determining relative efï¬ciency in Indonesian health facilities. 
Chapter 1 presents the aim of the thesis. Chapter 2 offers a description of Indonesia and its healthcare system, and Chapter 3 discusses the methods used and the theoretical background of the study. 
In Chapter 4, we review measurements of efï¬ciency in empirical analyses conducted in low- and middle-income countries. We demonstrate that there is no consensus regarding the most appropriate technique to measure efï¬ciency, though most existing studies have relied on ratio analysis and data envelopment analysis. 
The empirical ï¬ndings in this thesis provide comprehensive analyses of the efï¬ciency of both primary care facilities and hospitals; this study makes a distinct contribution as the ï¬rst to use multiple national datasets. 
In Chapter 5, we combine Pabon-Lasso models and costing analysis to explore the characteristics of high-performing health facilities. In so doing, we demonstrate that it is feasible to measure efï¬ciency using easily reproducible, readily understandable methods. 
In Chapter 6, we analyse efï¬ciency in primary care facilities using frontier analysis, including both data envelopment analysis and stochastic frontier analysis. Chapter 7 uses frontier analysis to investigate efï¬ciency in hospitals by considering the complexity (case mix index) and quality (mortality ratio) of healthcare services. The use of a multiple approach offers a way of cross-checking the consistency of the results. This empirical analysis enable us to conclude unambiguously and robustly that there exist signiï¬cant associations between health facilitiesâ€™ contextual factors and their estimated efï¬ciency scores. 
Finally, Chapter 8 draws together the ï¬ndings, assesses the policy implications, and comments on appropriate further research.",2018,
Zwei seltene FÃ¤lle multipler geschwulstartiger Hauterkrankung,"Zwoi Qboraus intoressanto Fallo multiplor geschwulsiartigor ttauterkrankungon; deron fragmontarischo Krankongoschichton sich im Nachlasso unseros verstorbenon Lohrers Auspi tz vorfandon, sind es, mit deron MittheiIung und Bearbeitung wir, als seine letzten Schtilor, yon dor Redaction dieser Viortoljahrosschrift betraut wurden. So dankonswerth und ehronvoM aueh diese Mission ffir uns erscheint und so sohr wir auch bemfiht waron, trou den Lehren",2006,Vierteljahresschrift fÃ¼r Dermatologie und Syphilis
Cryptococcus neoformans Infection Immune Response to Pulmonary Scavenger Receptor A Modulates the,"Scavengerreceptorsrepresentanimportantclassofpatternrecognitionreceptorsshowntomediatebothbeneï¬cialanddetrimentalroles in host defense against microbial pathogens. The role of the major macrophage scavenger receptor, scavenger receptor A(SRA), in the immune response against the pathogenic fungus, Cryptococcus neoformans, is unknown. To evaluate the role ofSRA in anticryptococcal host defenses, SRA",2013,
Shrinking symbolic regression over medical and physiological signals,"Medical embedded systems of the present and future are recording vast sets of data related to medical conditions and physiology. Linear modeling techniques are proposed as a means to help explain relationships between two or more medical or physiological signal measurements from the same human subject. In this paper a statistical regression algorithm is explored for use in medical monitoring, telehealth, and medical research applications. An essential element in applying linear modeling to physiological data is determining functional forms for the predictor signals. In this paper we demonstrate an efficient method for symbolic regression and model selection among possible transformation functions for the predictor variables. The three-stage method uses LASSO shrinkage regression to select a brief functional form and performs an polynomial lag regression with this form. This method is applied to medical and physiological time series data exploring the link between respiration and blood oxygen saturation percentage in sleep apnea patients. We found that our method for selecting a functional transformation of the predictor variable dramatically improved the goodness of fit of the model according to standard analysis of variance measures. In the dataset examined, the model achieved a multiple R2 of 0.3373, while a plain time-lagged model without transformation or polynomial lags had a R2 of only 0.016. All of the variables in the model produced by the algorithm had high scores in t tests for validity.",2010,2010 2nd International Conference on Signal Processing Systems
Injuries on Stickleback from Attacks by a Toothed Predator (oncorhynchus) and Implications for the Evolution of Lateral Plates.,"in Relation to Sex, Second Edition. John Murray, London, UK. ENDLER, J. A. 1986. Natural Selection in the Wild. Princeton University Press, Princeton, NJ USA. LANDE, R., AND S. J. ARNOLD. 1983. The measurement of selection on correlated characters. Evolution 37:1210-1226. MADSEN, T. 1987. Natural and sexual selection in grass snakes, Natrix natrix, and adders, Vipera berus. Ph.D. Diss., University of Lund, Lund, Sweden. 1988. Reproductive success, mortality and sexual size dimorphism in the adder, Vipera berus. Holarctic Ecology 11:77-80. MADSEN, T., AND B. STILLE. 1988. The effect of size dependent mortality on colour morphs in male adders, Vipera berus. Oikos 52:73-78. MADSEN, T., R. SHnE, J. LoMArN, AND T. HAKANSSON. 1992. Determinants of mating success in male adders (Vipera berus). Anim. Behav. In press. PRESTT, I. 1971. An ecological study of the viper, Vipera berus, in southern Britain. J. Zool. 164:373418. STILLE, B., T. MADSEN, AND M. NIKLASSON. 1986. Multiple paternity in the adder, Vipera berus. Oikos 47:173-175. TURELLI, M., J. H. GILLESPIE, AND R. LANDE. 1988. Rate tests for selection on quantitative characters during macroevolution and microevolution. Evolution 42:1085-1089.",1992,Evolution; international journal of organic evolution
Feature selection based on functional group structure for microRNA expression data analysis,"Feature selection methods have been widely used in gene expression analysis to identify differentially expressed genes and explore potential biomarkers for complex diseases. While a lot of studies have shown that incorporating feature structure information can greatly enhance the performance of feature selection algorithms, and genes naturally fall into groups with regard to common function and co-regulation, only a few of gene expression studies utilized the structured properties. And, as far as we know, there has been no such study on microRNA (miRNA) expression analysis due to the lack of available functional annotation for miRNAs. In this study, we focus on miRNA expression analysis because of its importance in the diagnosis, prognosis prediction and new therapeutic target detection for complex diseases. MiRNAs tend to work in groups to play their regulation roles, thus the miRNA expression data also has group structure. We utilize the GO-based semantic similarity to infer miRNA functional groups, and propose a new feature selection method taking group structure into consideration, called MiRFFS (MiRNA Functional group-based Feature Selection). We also apply the group information to the sparse group Lasso method, and compare MiRFFS with the sparse group Lasso as well as some existing feature selection methods. The results on three miRNA microarray profiles of breast cancer show that MiRFFS can achieve a compact feature subset with high classification accuracy.",2016,2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)
"Restricted Application of Insecticides: A Promising Tsetse Control Technique, but What Do the Farmers Think of It?","BACKGROUND
Restricted application of insecticides to cattle is a cheap and safe farmer-based method to control tsetse. In Western Africa, it is applied using a footbath, mainly to control nagana and the tick Amblyomma variegatum. In Eastern and Southern Africa, it might help controlling the human disease, i.e., Rhodesian sleeping sickness as well. The efficiency of this new control method against ticks, tsetse and trypanosomoses has been demonstrated earlier. The invention, co-built by researchers and farmers ten years ago, became an innovation in Burkina Faso through its diffusion by two development projects.


METHODOLOGY/PRINCIPAL FINDINGS
In this research, we studied the process and level of adoption in 72 farmers inhabiting the peri-urban areas of Ouagadougou and Bobo-Dioulasso. Variables describing the livestock farming system, the implementation and perception of the method and the knowledge of the epidemiological system were used to discriminate three clusters of cattle farmers that were then compared using indicators of adoption. The first cluster corresponded to modern farmers who adopted the technique very well. The more traditional farmers were discriminated into two clusters, one of which showed a good adoption rate, whereas the second failed to adopt the method. The economic benefit and the farmers' knowledge of the epidemiological system appeared to have a low impact on the early adoption process whereas some modern practices, as well as social factors appeared critical. The quality of technical support provided to the farmers had also a great influence. Cattle farmers' innovation-risk appraisal was analyzed using Rogers' adoption criteria which highlighted individual variations in risk perceptions and benefits, as well as the prominent role of the socio-technical network of cattle farmers.


CONCLUSIONS/SIGNIFICANCE
Results are discussed to highlight the factors that should be taken into consideration, to move discoveries from bench to field for an improved control of trypanosomoses vectors.",2011,PLoS Neglected Tropical Diseases
hsa-mir-3199-2 and hsa-mir-1293 as Novel Prognostic Biomarkers of Papillary Renal Cell Carcinoma by COX Ratio Risk Regression Model Screening.,"Papillary renal cell carcinoma(PRCC) is the second most common and aggressive renal cell carcinoma. Identification of novel microRNA biomarkers could be beneficial for the diagnosis and prognosis of PRCC patients. We aimed to screen differentially expressed miRNAs that can act as prognostic factors and to predict the survival of PRCC patients. High-throughput data of miRNAs of 274 PRCC samples were downloaded from TCGA (The Cancer Genome Atlas) dataset and interested miRNAs were identified. Hierarchical clustering and principal component analysis (PCA) were performed on these miRNAs. Critical genes that can act as prognostic factors were screened by LASSO. What's more, Kaplan-Meier survival analysis and ROC (Receiver Operating Characteristic) growth curve were used to testify the accuracy of the model. Biological processes of putative targets of miRNAs were analyzed by bioinformatics methods such as GO (Go Ontology) and KEGG (Kyoto Encyclopedia of Genes and Genomes) analysis. A total of 105 differentially expressed miRNAs were screened out in PRCC samples compared with healthy controls. Two critical miRNAs, hsa-mir-3199-2, and hsa-mir-1293, were screened out by LASSO (Least Absolute Shrinkage and Selection Operator), including 197 and 189 target genes, respectively. Furthermore, its' accuracy was testified by ROC analysis with the AUC (Area under the curve) value of 0.7774968 and 0.6743466. These miRNAs were significantly enriched in pathways as platelet activating factor biosynthetic process, epithelial cell maturation, and IkappaB kinase complex. In conclusion, hsa-mir-3199-2 and hsa-mir-1293 that can act as prognostic biomarkers of PRCC were screened out, which can provide new insights for the clinical treatment of the disease. J. Cell. Biochem. 118: 3488-3494, 2017. Â© 2017 Wiley Periodicals, Inc.",2017,Journal of cellular biochemistry
Diagnostica per Immagini Di Un Capolavoro Di Caravaggio Immagini Oltre Il Visibile per Il Seppellimento Di Santa Lucia Proveniente Dalla Chiesa Di Santa Lucia Al Sepolcro Di Siracusa,"Il 28 maggio 1606 Michelangelo Merisi fugge da Roma dove non fara mai piu ritorno; lâ€™ultimo duello gli e costato laÂ condanna a morte. Iniziano per lui gli anni della latitanza, anni che trascorrera tra Napoli, Malta e la Sicilia. Nel suoÂ passaggio in Sicilia, Caravaggio realizza dipinti di eccezionale qualita, sicuramente tra i piu belli della sua breveÂ e intensa esistenza. Nellâ€™isola lâ€™artista arriva nellâ€™ottobre del 1608, dopo lâ€™ennesima fuga, questa volta da Malta.Â La sua prima tappa siciliana e Siracusa, dove vive un artista suo amico: Mario Minniti. Da lui trova riparo e lavoroÂ perche dipinge su commissione una grande tela per la chiesa di Santa Lucia al Sepolcro, Il Seppellimento di SantaÂ Lucia, realizzata in un breve lasso di tempo, trasferendosi Caravaggio a Messina nel dicembre dello stesso anno. Diagnostic campaign on Caravaggioâ€™s painting The Assessorato dei Beni Culturali e dellâ€™Identita Siciliana, Diparti-mento dei Beni Culturali e Â dell'Identita Siciliana, Regione SicilianaÂ (i nomi italiani tutti in corsivo) has carried out a diagnostic cam-paign on the painting Il Seppellimento di Santa Lucia (oil on canvas,Â 1608) by Michelangelo Merisi da Caravaggio, in order to evaluate theÂ state of conservation of the work of art before its return to Syracu-se, in the Church of S. Lucia al Sepolcro (the original placing fromÂ which the painting was removed at the end of the Seventies due toÂ the unsuitable and unstable environment conditions of the exhibi-tion area, which inevitably led to its bad conservation conditions).Â The diagnostic campaign has been carried out in situ with portableÂ instruments, for a one-month period, during the open exhibition inÂ the Regional Gallery of Sicily of Palazzo Abatellis in Palermo, whereÂ the painting has temporarily been displayed in 2006.Â The investigations were aimed at having a deeper knowledge of theÂ work of art with reference to its execution technique, to the originalÂ materials being employed and to any previous restoration work.The paper presents some results obtained from multi-spectral andÂ radiological investigations.",2012,
Estimation of Computational Complexity of Combinatorial-Genetic Algorithm COMBI-GA,"The article presents a description of the combinatorial-genetic algorithm COMBI-GA as well as results of theoretical estimation of its computational complexity and numerical comparison of its effectiveness with known algorithms COMBI, MULTI and LASSO in test tasks.",2019,2019 9th International Conference on Advanced Computer Information Technologies (ACIT)
Behavioral medicine and women : a comprehensive handbook,"Agras, Strickland, Forewords. Part I:Life Course Perspectives. Brooks-Gunn, Graber, Section Editors' Overview. Woods, Rosenstein, Brain and Behavior Development. Thoman, Infancy. Field, Maternal Cocaine use and Fetal Development. Olson, Maternal Alcohol Use and Fetal Developmetn. Szkrybalo, Ruble, Childhood: Gender Role Development. Petersen, Adolescence. Graber, Brooks-Gunn, Puberty. Millstein, Halpern-Flesher, Adolescent Sexuality. Hardy, Teenage and Adolescent Pregnancy. Helstrom, Blechman, Parnting. Seltzer, Parenting of Adults with Mental Retardation. Thomas, Midlife. Moen, Aging. Part II: Stress and Coping. Blechman, Section Editor Overview. Beach, Attachment. Fincham, Marital Quality. O'Leary, Marital Conflict. Wills, Social Support. Eysenck, Personality. Basso, Type A Behavior Pattern. Smith, Hostility. Gustafson, Achievement. Carver, Optimism. Maddi, Hardiness. Wright,Resilience. Repetti, Multiple Roles. Sweeting, Life Events. Aspinwall, Social Comparison. Ryff, Positive Mental Health. Part III: Prevention. King, Section Editor Overview. Sikkema, HIV Prevention. Mantell, Susser, HIV Prvention among Homeless Women. Mayer, Breast Cancer Screening: Improving Adherence. Kaplan, Breast Cancer Screening: When to Begin? Nelson, Osteoporosis Prevention. Killen, Smoking Prevention. Tucker, Preventing Alcohol Problems. Brunner, St. Jeor, Nutrition: Diet and Disease. Brunner, St. Jeor, Nutrition: Guidelines, Attitudes and Behaviors. Glanz, Nutrition Education. Osborne, Oral Health. Dubbert, Exercise. Douthitt Exercise for Adolescents. Gregerson, Relaxation. Part IV: Health Care Paradigms, Policies, and Settings Gilchrist, Section Editor Overview. Edmunds, Health Care Policy. Levy, Accountability. Wallis, Medical Curricula and Training. Wallen, Substance Abuse and Health Care Utilization. Balassone, School-Based Clinics. Maheu, Worksite Nicotine Treatment. Pierce, The Military and Health. Brown, Prenatal Care Access. Black, Scott, Self-Administered Interventions. Cornman, Self-Administered Interventions. Cornman, Alternative Medicine. Part V: Body Image and Substance Use. Brownell, Section Editor Overview. Sokol, Gray, Anorexia Nervosa. Hefferman, Bulimia Nervosa. Troop, Stress and Coping in Eating Disorders. Polivy, McFarlane, Dieting, Exercise, and Body Weight. Eklund, Social Physique Anxiety. Rosen, Negative Body Image. Cash, The Emergence of Negative Body Images. Pruzinsky, Breast Implants. Wing Obesity. Rohsenow, Alcoholoism. Baraona, Alcohol Metabolism. McCaul, Drug Abuse. Hall, Drug Abuse Treatment. Husten, Cigarette Smoking. Part VI: Sexuality and Reproduction. Williams, Section Editor Hall, Drug Abuse Treatment. Husten, Cigarette Smoking. Part VI: Sexuality and Reproduction. Williams, Section Editor Overview. Morokoff, Sexual Functioning. Warren, Solidum, Reproductive Endrocrinology. McFarlane, Premenstrual Disorders. Wilkie, Schmidt, Gynecological Pain. Laws, Sexual Abuse. Dunkel-Schetter, Lobel, Pregnancy and Childbirth. Rogers, Pregnancy in Women with Disabilities. Gotlib, Postpartum Depression. Lawrence, Breastfeeding. Labbok, The Lactational Lactational Amenorrhea Method. Ballagh, Contraception. Alder, Smith, Abotion. Giudice, Reproductive Technologies. O'Hanlan, Menopause. Zeiss, Sexuiality and Aging. Part VII: Physiological Disorders with Behavioral Psychosocial C",1998,
Input Use and Productivity across Farm Sizes: A Comparison of the Two Punjabst,"Agricultural production depends upon certain crucial inputs e.g., water, fertilizer etc. In the less developed regions of South Asiain general, and the Indo-Pakistan sub-continent in particular, the use of these inputs depends not only upon the financial affordability but also upon the institutional accessibility of farmers to these inputs. Besideshigh economic costs, bureaucratic controls and corruption regarding the distribution of inputs have created problems of limited accessibility, especially to the small farmers. In the absence of any credit, information and/or inputdistribution networks, the use of these inputs, and related productivity gains,become confined to that classof farmers which not only has better accessto these inputs but is capable of using them in the best possible way e.g. use of water and fertilizer in the appropriate amount and at the appropriate time.",1988,The Pakistan Development Review
A new comorbidity index: the health-related quality of life comorbidity index.,"OBJECTIVE
To derive and validate the health-related quality of life comorbidity index (HRQL-CI).


STUDY DESIGN AND SETTING
Of 261 clinical classification codes (CCCs) in the 2003 Medical Expenditure Panel Survey (MEPS), 44 were identified as adult, gender-neutral, chronic conditions. The least absolute shrinkage and selection operator (LASSO) procedure identified CCCs significantly associated with the Short Form-12 physical component summary (PCS) and mental component summary (MCS) scores. Regression models were fitted with the selected CCCs, resulting in two subsets corresponding to PCS and MCS, collectively called the HRQL-CI. Internal validation was assessed using 10-fold cross-validation, whereas external validation in terms of prediction accuracy was assessed in the 2005 MEPS database. Prediction errors and model RÂ² were compared between HRQL-CI models and models using the Charlson-CI.


RESULTS
LASSO identified 20 CCCs significantly associated with PCS and 15 with MCS. The RÂ² for the models, including the HRQL-CI (0.28 for PCS and 0.16 for MCS) were greater than those using the Charlson-CI (0.13 for PCS and 0.01 for MCS). The same pattern of higher RÂ² for models using the HRQL-CI was observed in the validation tests.


CONCLUSION
The HRQL-CI is a valid risk adjustment index, outperforming the Charlson-CI. Further work is needed to test its performance in other patient populations and measures of HRQL.",2011,Journal of clinical epidemiology
Extending classical statistical methods to study customer satisfaction. An application to a private indoor climbing centre in France,"book 86 Extending classical statistical methods to study customer satisfaction. An application to a private indoor climbing centre in France Authors: StÃ©phane Champely & Ã‰ric Boutroy Institution: Centre for Research and Innovation in Sport (CRIS), Lyon 1 University, France. E-mail: champely@univ-lyon1.fr Abstract keywords Customer satisfaction study, Statistics, Importanceperformance analysis, Tetraclasse model, Lasso.keywords Customer satisfaction study, Statistics, Importanceperformance analysis, Tetraclasse model, Lasso. Background For managers, it is crucial to identify the key drivers that determine customer satisfaction. Importance-Performance Analysis (IPA) is a simple albeit effective tool to allocate scarce resources. The three-factor theory of customer satisfaction nevertheless suggests that the study of the relationship between attributes performance and overall satisfaction is more informative (Kano, 1984). Aims The paper will review and extend some classical statistical tools for studying customer satisfaction: IPA and the tetraclasse model (TM; Bodet, 2006). An innovative data learning technique, the lasso, will also be presented. Research design A customer satisfaction survey was carried out in November 2011 in the biggest French private indoor climbing centre. A census method was used during one week long (n=921). The questionnaire comprises in particular 25 attribute importance measurements and 25 corresponding performance measurements, each defined on a 4-point Likert scale. These variables describe primary and secondary services, service quality and atmosphere. In addition, overall satisfaction was evaluated. Initially rated as a 10-level Likert scale, it was later recoded as a 4-category ordinal variable. Methodology and data analysis IPA studies quality attributes on two dimensions: their performance level (satisfaction) and their importance to the customer. The resulting scatterplot helps to set high and low priorities, and possible overkill. Yet, this EPA display heavily depends on the survey sample size and the variability of both importance and performance measurements. It seems thus interesting to add some confidence intervals to study the robustness of this analysis (Farnum & Hall, 2007). Moreover, some market segmentation by sporting expertise or occupation can be also tested and depicted using the IPA plot. To study the relationship between an overall satisfaction measurement and attributes performances, the Llosaâ€™s TM employs a correspondence analysis. It is here proved that a similar plot can be obtained using basic percentage computations. Moreover, the resulting scales are easier to interpret and introduce light and shade into manager decisions. Supplementary confidence intervals can again be drawn. When overall satisfaction is measured on an ordinal response scale, the proportional odds model is a suitable regression tool. To select the most significant attributes performances, automatic selection algorithms are commonly used. However, when the number of explanatory variables is high, selection procedures exhibit a high variability. A different and innovative technique is presented: the lasso (Archer, 2011). By penalizing the coefficients size, more robust estimations are obtained. Plotting the coefficients against the penalizing parameter gives an idea of the results stability. Information criteria help to select the best-fitting model. Standardized coefficient (beta) could then be printed, plotted and interpreted. Furthermore, to detect the asymmetric impact of attributes performances on overall satisfaction, dummy variables can be introduced to identify excitement, performance and basic factors (Matzler et al, 2004). Results IPA indicates that satisfaction and importance are usually high for core services (good and varied routes, route renewal). On the contrary, price, cleanliness and waiting time are considered as important but not so well satisfied. These three attributes and the fitness room (not important in IPA) are classified as â€œplusâ€ by the TM. The core services and also conviviality and reception quality are considered as â€œbasicâ€. Advices, supervision and equipment renting seem to be key factors (for beginners). The lasso shows that overall satisfaction is a function of price, core services, reception quality, conviviality and cleanliness. Discussion and implications/conclusions The private indoor climbing centre must clearly concentrate its resources on its core services and does not try to become a general leisure centre. Human resources, mostly recruited for their sporting diploma (climbing), must be trained to customer relationship. A particular attention must be given to beginners. The IPA, the TM, the lasso analysis impact of each attributeâ€™s performance on overall satisfaction and the asymmetric impact analysis will be compared, emphasizing their respective strengths and weaknesses and the different kind of results that can be obtained. It seems nevertheless difficult to give a definitive answer to the question of the best approach. Depending on the manager goals, the measurement scales, the sample size, the prior knowledge about the attributes dimension and the mathematical sophistication of the user, advice may vary. In our mind, the four analyses are more complementary than rival to yield prescriptions for customer satisfaction management.",2012,
Statistical downscaling modeling with quantile regression using lasso to estimate extreme rainfall,"Rainfall is one of the climatic elements with high diversity and has many negative impacts especially extreme rainfall. Therefore, there are several methods that required to minimize the damage that may occur. So far, Global circulation models (GCM) are the best method to forecast global climate changes include extreme rainfall. Statistical downscaling (SD) is a technique to develop the relationship between GCM output as a global-scale independent variables and rainfall as a local- scale response variable. Using GCM method will have many difficulties when assessed against observations because GCM has high dimension and multicollinearity between the variables. The common method that used to handle this problem is principal components analysis (PCA) and partial least squares regression. The new method that can be used is lasso. Lasso has advantages in simultaneuosly controlling the variance of the fitted coefficients and performing automatic variable selection. Quantile regression is a method that can be us...",2016,
Stability SCAD: a powerful approach to detect interactions in large-scale genomic study,"BackgroundEvidence suggests that common complex diseases may be partially due to SNP-SNP interactions, but such detection is yet to be fully established in a high-dimensional small-sample (small-n-large-p) study. A number of penalized regression techniques are gaining popularity within the statistical community, and are now being applied to detect interactions. These techniques tend to be over-fitting, and are prone to false positives. The recently developed stability least absolute shrinkage and selection operator (SLASSO) has been used to control family-wise error rate, but often at the expense of power (and thus false negative results).ResultsHere, we propose an alternative stability selection procedure known as stability smoothly clipped absolute deviation (SSCAD). Briefly, this method applies a smoothly clipped absolute deviation (SCAD) algorithm to multiple sub-samples, and then identifies cluster ensemble of interactions across the sub-samples. The proposed method was compared with SLASSO and two kinds of traditional penalized methods by intensive simulation. The simulation revealed higher power and lower false discovery rate (FDR) with SSCAD. An analysis using the new method on the previously published GWAS of lung cancer confirmed all significant interactions identified with SLASSO, and identified two additional interactions not reported with SLASSO analysis.ConclusionsBased on the results obtained in this study, SSCAD presents to be a powerful procedure for the detection of SNP-SNP interactions in large-scale genomic data.",2013,BMC Bioinformatics
Percolation analysis of the two-dimensional Widom-Rowlinson lattice model,"We consider the two-dimensional Widom-Rowlinson lattice model. This discrete spin model describes a surface on Which a one to one mixture of two gases is sprayed. 
These gases shall be strongly repelling on short distances. 
We indicate the amount of gas by a positive parameter, the so called activity. 

The main result of this thesis states that given an activity larger than 2, there are at most two ergodic Widom-Rowlinson measures if the underlying graph is the star lattice. 
This falls naturally into two parts: 

The first part is quite general and establishes a new sufficient condition for the existence of at most two ergodic Widom-Rowlinson measures. 
This condition demands the existence of 1*lassos, i.e., 1*circuits 1*connected to the boundary, with probability bounded away from zero. 
Our approach is based upon the infinite cluster method. 
More precisely, we prevent the (co)existence of infinite clusters of certain types. 
To this end, we first have to improve the existing results in this direction, which will be done in a general setting for two-dimensional dependent percolation. 

The second part is devoted to verify the sufficient condition of the first part for activities larger than 2. 
To this end, we have to compare the probabilities of configurations exhibiting 1*lassos to the ones exhibiting 0lassos. 
This will be done by constructing an injection that fills certain parts of 0circuits with 1spins and, hereby, forms a 1*lasso.",2012,
Polygenic Risk Scores for Prediction of Breast Cancer and Breast Cancer Subtypes,"Stratification of women according to their risk of breast cancer based on polygenic risk scores (PRSs) could improve screening and prevention strategies. Our aim was to develop PRSs, optimized for prediction of estrogen receptor (ER)-specific disease, from the largest available genome-wide association dataset and to empirically validate the PRSs in prospective studies. The development dataset comprised 94,075 case subjects and 75,017 control subjects of European ancestry from 69 studies, divided into training and validation sets. Samples were genotyped using genome-wide arrays, and single-nucleotide polymorphisms (SNPs) were selected by stepwise regression or lasso penalized regression. The best performing PRSs were validated in an independent test set comprising 11,428 case subjects and 18,323 control subjects from 10 prospective studies and 190,040 women from UK Biobank (3,215 incident breast cancers). For the best PRSs (313 SNPs), the odds ratio for overall disease per 1 standard deviation in ten prospective studies was 1.61 (95%CI: 1.57-1.65) with area under receiver-operator curve (AUC) = 0.630 (95%CI: 0.628-0.651). The lifetime risk of overall breast cancer in the top centile of the PRSs was 32.6%. Compared with women in the middle quintile, those in the highest 1% of risk had 4.37- and 2.78-fold risks, and those in the lowest 1% of risk had 0.16- and 0.27-fold risks, of developing ER-positive and ER-negative disease, respectively. Goodness-of-fit tests indicated that this PRS was well calibrated and predicts disease risk accurately in the tails of the distribution. This PRS is a powerful and reliable predictor of breast cancer risk that may improve breast cancer prevention programs.",2019,American Journal of Human Genetics
"The venomous toadfish Thalassophryne nattereri (niquim or miquim): report of 43 injuries provoked in fishermen of SalinÃ³polis (ParÃ¡ State) and Aracaju (Sergipe State), Brazil.","Fishes of family Batrachoididae are responsible for great number of injuries in fishermen in North and Northeast regions of Brazil. The genus Thalassophryne presents various venomous species of fishes found in the Brazilian coast, T. nattereri being the most common of them. The venom is ejected through two hollow spines on the dorsal fin and two on pre-opercular regions, which present a venomous gland in the base and can be erected or depressed by the fish. The manifestations of the envenoming were intense local pain, edema and erythema in 43 patients observed in SalinÃ³polis (ParÃ¡ State) and Aracaju (Sergipe State). There were no systemic manifestations, but necrosis was detected in eight and bacterial infection in ten injured fishermen. The circumstances of the contacts and therapeutic aspects are discussed. Envenoming by the genus Thalassophryne is important and frequent and should be considered of moderate severity grade, since there are not the excruciating pain or the massive local necrosis provoked by scorpionfishes (Scorpaena) or stingrays injuries nor the systemic manifestations that are the most important marker of severe envenoming.",2003,Revista do Instituto de Medicina Tropical de Sao Paulo
"Statistical Recovery of Discrete, Geometric and Invariant Structures","The main objective of the workshop was to bring together researchers in mathematical statistics and related areas in order to discuss recent advances and problems associated with statistical recovery of geometric and invariant structures. Topics include adaptive estimation, confidence sets and testing techniques, as well as statistical algorithms for geometrical structure recovery and data analysis. Mathematics Subject Classification (2010): 62Gxx, 62Cxx, 62Fxx, 62Mxx,60Fxx, 60Gxx. Introduction by the Organisers The theory of optimal function and density estimation has been fundamental to mathematical statistics for many decades. However, it is well understood nowadays that for many modern complex statistical models the full reconstruction of the underlying function is an overly ambitious task. Similarly, this problem arises for the recovery of the full parameter vector in high and ultra high dimensional (generalized) linear models. This becomes particularly apparent if rigorous statistical inference is targeted, e.g. confidence statements for the underlying object to be recovered. There is a variety of results available nowadays which detail these limitations: as one concrete example, it has been shown that adaptive confidence bands (in sup norm) for functions with different smoothness index (e.g. for Sobolev scales) cannot exist as this function space is too complex. Currently, two possible routes out of this dilemma are being developed, and both have been discussed in this workshop to elucidate a unifying perspective: 950 Oberwolfach Report 16/2017 (1) To restrict the object of interest by prior information on its geometry, in particular for discrete structures. This leads to new challenges for geometrically-constrained inference at the cutting edge of statistical efficiency and efficient computation. This includes the estimation of discrete structures such as the active nodes in graphical models, networks, or rankings. (2) To focus on partial information of the structure which potentially allows for inference uniformly over the underlying set of models. In this workshop a large variety of new results on geometric and invariant inference acquired in seemingly different directions have been reflected from this unifying point of view. The following aspects of geometric and invariant inference jave been in the focus of the proposed meeting. High dimensional Inference. Various aspects, including optimal shrinkage of covariance matrices (D. Donoho), the relationship between Slope estimation and the Lasso estimator (A. Tsybakov), and compatibility constants for the Lasso (S. van de Geer) have been discussed. Recovery of Algebraic Structures. P. Rigollet reported on recent results for estimation under algebraic constraints, S. Mukherjee on the geometry of synchronization problems and learning group actions, and M. Yuan on how to analyze large data tensors. Statistical Optimal Transport. V. Panaretos discussed FrÃ©chet means and procrustes analysis in Wasserstein space and M. Cuturi surveyed recent methods for computation of regularized optimal transport. M. Sommerfeld addressed inference issues for the empirical Wasserstein distance. Recovery of Networks. S. Olhede surveyed statistical issues of network recovery with combinatorical and nonparametric methods and E. Levina discussed prediction issues in networks with cohesion. In his talk, A. Rinaldo addressed Markov properties of networks models, including attention to their geometry and exchangeability issues. Inference for Complex Structured Data. E. Candes discussed model-free knockoff methods for replicable selections and S. Balakrishnan discussed local minimax results for hypothesis testing of densities and high-dimensional multinomials. W. Polonik reported on recent results to extract multiscale geometric information extraction and its use for classification. Causal Inference. T. Richardson discussed how to identify nonparametrically causal effects in the presence of unobserved variables and P. Jonas gave a survey talk on causality and novel ways of exploiting invariance for causal inference. Multidimensional Regularization. This topic has been addressed by L. DÃ¼mbgen, who related geodesic convexity and regularized scatter estimation; by R. Samworth who talked on efficient multivariate entropy estimation; and by V. Vu who prsented recent results on group invariance and computational sufficiency for regularized M-estimators. Statistical Recovery of Discrete, Geometric and Invariant Structures 951 Clustering and Classification. V. Spokoiny presented a novel methodology for nonparametric clustering using adaptive weights and H. Zhou talked on statistical and computational guarantees for Lloydâ€™s algorithm and variants thereof. Finally J. Schmidt-Hieber discussed nonparametric Bayesian analysis for support boundary recovery and M. Belkin gave a talk on eigenvectors of orthogonally decomposable functions. The workshop was complemented by a young researchers late night session, where a total of 11 PhD students and early postdocs presented their work in short talks. This was accompanied by wine and cheese served by the organizers, which created a particularly relaxed atmosphere. In summary, this was an extremely fruitful and lively workshop where many ideas around geometric and invariant inference have been exchanged between different communities. This includes experts in network analysis, sparse recovery, function estimation, statistics for metric structures and causality, to mention a few. Acknowledgement: The organizers would like to cordially thank the MFO and its staff for its support and hospitality. The MFO and the workshop organizers would like to thank the National Science Foundation for supporting the participation of junior researchers in the workshop by the grant DMS-1049268, â€œUS Junior Oberwolfach Fellowsâ€. Moreover, the MFO and the workshop organizers would like to thank the Simons Foundation for their support. Statistical Recovery of Discrete, Geometric and Invariant Structures 953 Workshop: Statistical Recovery of Discrete, Geometric and Invariant Structures",2018,Oberwolfach Reports
Post-Selection Inference for â„“1-Penalized Likelihood Models.,"We present a new method for post-selection inference for â„“1 (lasso)-penalized likelihood models, including generalized regression models. Our approach generalizes the post-selection framework presented in Lee et al. (2013). The method provides p-values and confidence intervals that are asymptotically valid, conditional on the inherent selection done by the lasso. We present applications of this work to (regularized) logistic regression, Cox's proportional hazards model and the graphical lasso. We do not provide rigorous proofs here of the claimed results, but rather conceptual and theoretical sketches.",2018,The Canadian journal of statistics = Revue canadienne de statistique
"Age of the Bashijiqike Formation from Kuche Foreland Basin, Xinjiang","The microfossils from the Bashijiqike Formation of Kuche Foreland Basin, Xinjiang have been classed as Latonia-Cypridea-Damonella ostracode assemblage, Aclistochara huihuibaoensis-Mesochara voluta-Sphaerochara charophyte assemblage, and Cicatricosisporites-Lygodiumsporites-Classopollis sporo-pollen assemblage. The former two assemblages are referred to the middle Early Cretaceous and the latter is referred to the Cretaceous, thus the age of the Bashijiqike Formation is middle Early Cretaceous, probably corresponding to the Barremian.",2001,Journal of stratigraphy
The genetic basis of kidney cancer: implications for management and use of targeted therapeutic approaches.,"Each year there are >270 000 cases and 115 000 deaths from kidney cancer worldwide [1]. Although localized kidney cancer is most often treated successfully with surgery, patients who present with advanced disease have 2-yr survival of <20%. Kidney cancer is not a single disease; it is composed of a number of diseases, each of which has a different genetic cause, a clinical course that can be predicted on the basis of genotype, a different histology, and a unique response to therapy. Fifteen genes, including von HippelLindau (VHL), met proto-oncogene (MET), folliculin (FLCN), fumarate hydratase (FH), succinate dehydrogenase (SDH), tuberous sclerosis 1 (TSC1), tuberous sclerosis 2 (TSC2), phosphatase and tensin homolog (PTEN), transcription factor binding to IGHM enhancer 3 (TFE3), transcription factor EB (TFEB), and microphthalmia-associated transcription factor (MITF), have been found to cause or to be associated with the development of either sporadic or inherited forms of kidney cancer [2,3]. In the last 5 yr, there has been considerable progress in the development of therapeutic approaches that target the VHL pathway in clear cell kidney cancer. Seven novel agentsâ€”sunitinib, sorafenib, bevacizumab, temsirolimus, everolimus, pazaponib, and, just recently, axitinibâ€”have been approved in the United States for the treatment of patients with advanced kidney cancer. Although these exciting targeted therapeutic agents have benefited many patients, there are currently few documented complete responses to therapy with the use of any of these agents, and most patients eventually develop progressive disease. Understanding the genetic basis of cancer of the kidney has been the critical foundation that has led to improved methods for molecular diagnosis and to the development of targeted approaches to therapy for various kidney cancers. In the early 1990s, the gene for the hereditary form of clear cell kidney cancer associated with VHL was identified [4]. Significant insight about growth rates as well as metastasis rates of VHL gene mutationâ€“associated clear cell kidney cancer has been gained from the longitudinal studies of patients with VHL-associated kidney cancer. In careful follow-up of hundreds of patients with VHLassociated clear cell kidney cancer managed over a 20-yr period, no patient on active surveillance using highly sensitive imaging techniques developed metastases when kidney tumors were removed surgically before the largest tumor grew to a 3-cm-diameter size. In VHL patients, these tumors had a known genetic mutation of the VHL gene. Clear cell kidney cancer makes up approximately 75% of the cases of sporadic, noninherited kidney cancer. The VHL gene has been found to be mutated (or silenced by methylation) in 80â€“90% of tumors from patients with sporadic, noninherited kidney cancers [5]. The genes that cause non-VHL mutated clear cell kidney cancer are not yet known. Recently, histone modifying genes, including polybromo 1 (PBRM1), were found to be mutated in a significant subset of clear cell kidney cancers [6]. Clear cell kidney cancers have also been found in patients with germline mutations of TSC1, TSC2, FLCN, and FH, but patients with these genotypes more commonly present with different histologic patterns, including papillary cancer. In their article in European Urology, Kroeger et al. report analysis of immunohistochemical staining profiles on 196 randomly selected kidney cancers from 1989 to 2000 and cytogenetic characterization of 272 clear cell kidney cancers from 1989 to 2007 to characterize the determinants of lymphatic spread [7]. Analysis of the immunohistochemical staining revealed a strong correlation between decreased",2012,European urology
Enhanced Sparse Imputation Techniques for a Robust Speech Recognition Front-End,"Missing data techniques (MDTs) have been widely employed and shown to improve speech recognition results under noisy conditions. This paper presents a new technique which improves upon previously proposed sparse imputation techniques relying on the least absolute shrinkage and selection operator (LASSO). LASSO is widely employed in compressive sensing problems. However, the problem with LASSO is that it does not satisfy oracle properties in the event of a highly collinear dictionary, which happens with features extracted from most speech corpora. When we say that a variable selection procedure satisfies the oracle properties, we mean that it enjoys the same performance as though the underlying true model is known. Through experiments on the Aurora 2.0 noisy spoken digits database, we demonstrate that the Least Angle Regression implementation of the Elastic Net (LARS-EN) algorithm is able to better exploit the properties of a collinear dictionary, and thus is significantly more robust in terms of basis selection when compared to LASSO on the continuous digit recognition task with estimated mask. In addition, we investigate the effects and benefits of a good measure of sparsity on speech recognition rates. In particular, we demonstrate that a good measure of sparsity greatly improves speech recognition rates, and that the LARS modification of LASSO and LARS-EN can be terminated early to achieve improved recognition results, even though the estimation error is increased.",2011,"IEEE Transactions on Audio, Speech, and Language Processing"
SNP annotation-based whole genomic prediction and selection: an application to feed efficiency and its component traits in pigs.,"The study investigated genetic architecture and predictive ability using genomic annotation of residual feed intake (RFI) and its component traits (daily feed intake [DFI], ADG, and back fat [BF]). A total of 1,272 Duroc pigs had both genotypic and phenotypic records, and the records were split into a training (968 pigs) and a validation dataset (304 pigs) by assigning records as before and after January 1, 2012, respectively. SNP were annotated by 14 different classes using Ensembl variant effect prediction. Predictive accuracy and prediction bias were calculated using Bayesian Power LASSO, Bayesian A, B, and CÏ€, and genomic BLUP (GBLUP) methods. Predictive accuracy ranged from 0.508 to 0.531, 0.506 to 0.532, 0.276 to 0.357, and 0.308 to 0.362 for DFI, RFI, ADG, and BF, respectively. BayesCÏ€100.1 increased accuracy slightly compared to the GBLUP model and other methods. The contribution per SNP to total genomic variance was similar among annotated classes across different traits. Predictive performance of SNP classes did not significantly differ from randomized SNP groups. Genomic prediction has accuracy comparable to observed phenotype, and use of genomic prediction can be cost effective by replacing feed intake measurement. Genomic annotation had less impact on predictive accuracy traits considered here but may be different for other traits. It is the first study to provide useful insights into biological classes of SNP driving the whole genomic prediction for complex traits in pigs.",2015,Journal of animal science
A 5-Gene Signature Is Closely Related to Tumor Immune Microenvironment and Predicts the Prognosis of Patients with Non-Small Cell Lung Cancer,"Purpose
Establishing prognostic gene signature to predict clinical outcomes and guide individualized adjuvant therapy is necessary. Here, we aim to establish the prognostic efficacy of a gene signature that is closely related to tumor immune microenvironment (TIME).


Methods and Results
There are 13,035 gene expression profiles from 130 tumor samples of the non-small cell lung cancer (NSCLC) in the data set GSE103584. A 5-gene signature was identified by using univariate survival analysis and Least Absolute Shrinkage and Selection Operator (LASSO) to build risk models. Then, we used the CIBERSORT method to quantify the relative levels of different immune cell types in complex gene expression mixtures. It was found that the ratio of dendritic cells (DCs) activated and mast cells (MCs) resting in the low-risk group was higher than that in the high-risk group, and the difference was statistically significant (P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and P < 0.001 and.


Conclusion
The 5-gene signature is a powerful and independent predictor that could predict the prognosis of NSCLC patients. In addition, our gene signature is correlated with TIME parameters, such as DCs activated and MCs resting. Our findings suggest that the 5-gene signature closely related to TIME could predict the prognosis of NSCLC patients and provide some reference for immunotherapy.",2020,BioMed Research International
Relationship between the MDS-UPDRS and Quality of Life: A large multicenter study of 3206 patients.,"BACKGROUND
The relationship between Health-Related Quality of Life (HRQoL) and MDS-UPDRS has not been fully studied so far. The aim of this study was to evaluate the relationship between all MDS-UPDRS components and HRQoL in a representative international cohort of PD patients.


METHODS
We collected demographic and disease-related data as well as MDS-UPDRS and PDQ8 scales. Data were analyzed using correlations between PDQ8 and all MDS-UPDRS items, subsequently two hierarchical multiple regressions were performed, first between the scores of the MDS-UPDRS Parts and PDQ8 and second between individual items from those Parts demonstrating significant relationship to PDQ8 scores in the first regression. LASSO regression analyses were performed to evaluate the relationship between PDQ8 and all individual MDS-UPDRS items.


RESULTS
A total of 3206 PD patients were included in the study. In the first regression analysis, PDQ8 was significantly related to MDS-UPDRS parts I and II, but not to III and IV. In the second regression model, significant contributions to PDQ8 were found for Part I items Fatigue, Pain, Depressed mood, Apathy; and Part II items Dressing, Doing hobbies, Freezing, Speech and Tremor. In the LASSO analysis, six Part I, seven Part II, three Part III and one Part IV items contributed to PDQ8 scores. The five items most significantly related to the model were Depressed mood, Dressing, Apathy, Pain and Fatigue.


CONCLUSIONS
This is so far the largest study related to HRQoL issues in PD. Restrictions in activities of daily living and non-motor symptoms significantly contribute to HRQoL in PD.",2018,Parkinsonism & related disorders
Gene expression profiles for a prognostic immunoscore in gastric cancer,"BACKGROUND
Increasing evidence has indicated an association between immune infiltration in gastric cancer and clinical outcome. However, reliable prognostic signatures, based on systematic assessments of the immune landscape inferred from bulk tumour transcriptomes, have not been established. The aim was to develop an immune signature, based on the cellular composition of the immune infiltrate inferred from bulk tumour transcriptomes, to improve the prognostic predictions of gastric cancer.


METHODS
Twenty-two types of immune cell fraction were estimated based on large public gastric cancer cohorts from the Gene Expression Omnibus using CIBERSORT. An immunoscore based on the fraction of immune cell types was then constructed using a least absolute shrinkage and selection operator (LASSO) Cox regression model.


RESULTS
Using the LASSO model, an immunoscore was established consisting of 11 types of immune cell fraction. In the training cohort (490 patients), significant differences were found between high- and low-immunoscore groups in overall survival across and within subpopulations with an identical TNM stage. Multivariable analysis revealed that the immunoscore was an independent prognostic factor (hazard ratio 1Â·92, 95 per cent c.i. 1Â·54 to 2Â·40). The prognostic value of the immunoscore was also confirmed in the validation (210) and entire (700) cohorts.


CONCLUSION
The proposed immunoscore represents a promising signature for estimating overall survival in patients with gastric cancer.",2018,The British Journal of Surgery
Statistical Theory (M16),"This is a course on parametric statistical theory that goes hand in hand with the Lent term course on nonparametric statistical theory. We begin by reviewing some basic principles and models in statistical inference that motivate the development, in the second chapter, of general inferential methods based on the likelihood function. Although these methods are usually perfectly adequate for relatively low-dimensional models, they can fail badly in high-dimensions { in particular, when the dimension of the parameter space (usually denoted p) is larger than the number of observations, n. These â€˜large p, small nâ€™ problems occur in a very wide range of applications, from microarray experiments in biology to portfolio selection in nance, and are at the forefront of modern Statistics. In Chapter 3, we will outline some of the most important recent developments, though this remains a very active research area. Basic principles and models: Likelihood and related quantities, suciency , linear models. Exponential families. [4] First-order theory: Review of basic probability, modes of convergence, Slutskyâ€™s theorem, stochastic order notation, moments and cumulants, Cochranâ€™s theorem. Review of Wald, score, likelihood ratio statistics and signed root versions, distribution theory in no nuisance parameter case. Generalised linear models. [5] High dimensional problems: Shrinkage. Ridge regression. Sparsity and traditional variable selection methods (e.g. AIC). Penalised likelihood, the LASSO and LARS algorithm, other penalty functions (e.g. SCAD). Multiple testing: Bonferroni correction. False discovery rate, Benjamini{Hochberg procedure. [7]",2005,
New Nearctic and Neotropical Muscoidean Diptera (Sarcophagidae and Tachinidae),"Among the species described herein, 5 are neotropical and 11 nearctic, of which only Neophyto refossa n. sp. belongs to the family Sarcophagidae and the remainder to Tachinidae. Seven new genera, based upon the following new species listed are described: Trismegistus pumilis, Chessipus notialis, Elassomyia defecta, Telemus trossulus, Tarpessita fulgen s, Eurylochus dissitus, and Solieriopsis boreotis. Eight new species assigned to established genera are characterized under the following combinations: Paradmontia picticornis, Mauromyia finit in a, Puna clista fidelis, Blondelia leucophaeata, B. cinefacta, Eljia viridis, Houghia nigripalpis and Zizyphomyia arguta. Continued studies of new world muscoidean Diptera accumulated during recent years by various collectors and submitted for study or identification have brought to light many new and little known species. The following descriptions are based in large measure upon materials so received and include a portion of the more noteworthy forms. Unless retained, location of all types is specified under the description. Neophyto refossa, n. sp. Differs from the type species, N. setosa (Coquillett) (1895), in having distinctly longer antennae; male front much more narrowed above middle; abdomen without discals, etc. Male. Head black in ground color, cheek cinereous, parafacial and parafrontal subsilvery; frontalia deep red, wider than one parafrontal on entire length; vertex 0.30 of head width, widening rapidly into facial angle; fron tais uniform in length, stopping at antennal base; inner vertical erect; proclinate ocellars weak and sometimes scarcely dif ferentiated; parafacial with a median row of weak bristly hairs and sparsely setose outside of latter; vibrissae decussate, far above lower margin of head ; antennae black, reaching below mid face level, segments 2 and 3 subequal in length; arista long pubescent, slender beyond black subbulbous base; cheek one-half eye length; palpus black, barely thickened apically and subequal to length' of haustellum ; occiput gently convex, lightly dusted with cinereous pollen and clothed with short black hairs. Thorax and scutellum black, notum feebly shiny, marked with three broad black vittae. Chaetotaxy: acrostichal 2, 2 (none near suture); 1 Contribution No. 5442, Department of Entomology, Texas Agricultural Ex periment Station, College Station, Texas. Accepted for publication July 11, 1966. Journal of the Kansas Entomological Society 40:94-110. January, 1967. This content downloaded from 157.55.39.45 on Thu, 01 Sep 2016 04:38:16 UTC All use subject to http://about.jstor.org/terms Vol. 40, No. 1, January, 1967 95 dorsocentral 2, 3; intraalar 3; supraalar 3; notopleural 3; humeral 4-5; sternopleural 3; scutellum normally with 3 marginal pairs all about equal in length and 1 smaller discal pair; postscutellum recessive; postnotal slope scantily haired, posternum bare; propleuron setose. Legs black, mid-tibiae with two anterodorsal bristles; claws and pulvilli strongly elongated. Wing gray hyaline tinged with yellow basally; first posterior cell closed at costa shortly before wing tip ; cubitulus obtusely angula ted, bearing a fold in membrane; third vein sparsely setulose on basal third or more; costal spine strong; calypters pale tawny, semi transparent. Abdomen narrower than thorax and tapered to apex, with dense grayish pollen above extending to hind margin of each segment but distinctly interrupted along median line; segment 2 with a pair of median marginals and a marginal row on segments 3 and 4 ; no discals ; terminalia black and retracted in repose; inner forceps scarcely exceed ing their fused basal width, prongs depressed, tapered to tips, which are separated by a V-shaped excision, basal margin behind densely clothed with long wavy hairs; outer forceps flattened and broadly rounded on apex, which is beset with a few not very long bristly hairs; basal stalk of penis short, enlarged distal segment sub triangular in profile, bearing a membranous lobe extending forward from near middle of front margin; fourth sternite subequal to width of preceding, sparsely haired on sides but with closely set stubby bristles on hind margin. Female. Abdomen less densely pollinose or darker in general aspect; otherwise similar to male except for the usual sexual differences. Length, 5.5-9.5 mm. Holotype male and allotype female, Mt. Mitchell, N. C, Camp Alice rd. to Peak, 58-6000 ft., May 24-29, 1960, in Dr. P. A. Arnaud's col lection. Paratypes: four males and two females same data as type but dated May 20-31, 1960 (H. C. Huckett).",1967,Journal of the Kansas Entomological Society
Hybrid Parallelization of Particle in Cell Monte Carlo Collision (PIC-MCC) Algorithm for Simulation of Low Temperature Plasmas,"We illustrate the parallelization of PIC code, for kinetic simulation of Low Temperature Plasmas, on Intel Multicore (Xeon) and Manycore (Xeon Phi) architectures, and subsequently on a HPC cluster. The implementation of 2D-3v PIC-MCC algorithm described in the paper involves computational solution of Vlassov-Poisson equations, which provides the spatial and temporal evolution of charged-particle velocity distribution functions in plasmas under the effect of self-consistent electromagnetic fields and collisions. Stringent numerical constraints on total number of particles, number of grid points and simulation time-scale associated with PIC codes makes it computationally prohibitive on CPUs (serial code) in case of large problem sizes. We first describe a shared memory parallelization technique using OpenMP library and then propose a hybrid parallel scheme (OpenMP+MPI) consisting of a distributed memory system. OpenMP based PIC code has been executed on Xeon processor and Xeon-Phi co-processors (Knights Corner and Knights Landing) and we compare our results against a serial implementation on Intel core i5 processor. Finally, we compare the results of the hybrid parallel code with the OpenMP based parallel code. Hybrid strategy based on OpenMP and MPI, involving a three-level parallelization (instruction-level, thread-level over many cores and node-level across a cluster of Xeon processors), achieves a linear speedup on an HPC cluster with 4 nodes (total 64 cores). The results show that our particle decomposition based hybrid parallelization technique using private grids scale efficiently with increasing problem size and number of cores in the cluster.",2018,
The impact of fear of the sea on working memory performance: a research based on virtual reality,"The sea has been manifested to cause the emotion of fear to people when it comes to a very depth, especially to those who have thalassophobia. Many people have to work in the sea while nearly no research on influence of fear of the sea to cognition has been carried out. This study explores the impact of fear of the sea induced by immersive virtual reality on working memory which is a cognitive system with a limited capacity. Participants were required to complete n-back working memory task of three difficulty levels in the non-emotional environment and the undersea environment respectively by means of virtual reality. Pupil diameter changes were recorded along with the task performance. In addition to reaction times and accuracy (correctly press a button in response to targets) as two task performance indices used in most researches, the commission errors (incorrectly press a button in response to non-targets) and omission errors (incorrectly do not press a button in response to targets) were also differentiated herein. The results of the study indicated that the virtual undersea environment did induce the emotion of fear. As for the task performance, except that the performance of low-level task did not differ much between the two environments, the fear of the sea increased the accuracy of the medium level n-back task but decreased it of high-level n-back task. Result of omission errors was just the opposite and commission errors were increased in both levels of task. The findings, including the positive role of a moderate level of fear of the sea in the performance of working memory task, make a lot of sense for future cognitive work in the sea.",2018,Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology
