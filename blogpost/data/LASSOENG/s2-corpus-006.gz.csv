title,abstract,year,journal
Fully Bayesian Classification with Heavy-tailed Priors for Selection in High-dimensional Features with Grouping Structure,"Author(s): Jiang, Lai; Li, Longhai; Yao, Weixin | Abstract: Feature selection is demanded in many modern scientific research problems that use high-dimensional data. A typical example is to find the most useful genes that are related to a certain disease (eg, cancer) from high-dimensional gene expressions. The expressions of genes have grouping structures, for example, a group of co-regulated genes that have similar biological functions tend to have similar expressions. Many statistical methods have been proposed to take the grouping structure into consideration in feature selection, including group LASSO, supervised group LASSO, and regression on group representatives. In this paper, we propose a fully Bayesian Robit regression method with heavy-tailed (sparsity) priors (shortened by FBRHT) for selecting features with grouping structure. The main features of FBRHT include that it discards more aggressively unrelated features than LASSO, and it can make feature selection within groups automatically without a pre-specified grouping structure. In this paper, we use simulated and real datasets to demonstrate that the predictive power of the sparse feature subsets selected by FBRHT are comparable with other much larger feature subsets selected by LASSO, group LASSO, supervised group LASSO, penalized logistic regression and random forest, and that the succinct feature subsets selected by FBRHT have significantly better predictive power than the feature subsets of the same size taken from the top features selected by the aforementioned methods.",2018,arXiv: Methodology
Average path-length parameter of diffuse light in scattering media.,"We use Monte Carlo simulations to study in detail the propagation of light in a plane-parallel medium containing scattering particles. In particular, we compute the forward and backward average path-length parameters (FAPP and BAPP, respectively) of four-flux radiative transfer models as functions of the optical depth. Strong dependence on the single scattering albedo and phase function asymmetry is found for both quantities. In general the values of the FAPP decrease with increasing absorption, whereas the opposite occurs for the BAPP. A similar effect is produced when changing from isotropic phase functions to phase functions with a large asymmetry in the forward direction. We present analytical results for the asymptotic values of the FAPP and BAPP as functions of albedo for the particular case of isotropic scattering. Our results differ markedly from the predictions obtained recently with two multiple-scattering models by Vargas and Niklasson [J. Opt. Soc. Am. A 14, 2243 (1997); Appl. Opt. 36, 3735 (1997)]. The differences found point out the intrinsic limitations of these models.",1999,Applied optics
Targeted metabolomics reveals reduced levels of polyunsaturated choline plasmalogens and a smaller dimethylarginine/arginine ratio in the follicular fluid of patients with a diminished ovarian reserve,"STUDY QUESTION
Does the metabolomic profile of the follicular fluid (FF) of patients with a diminished ovarian reserve (DOR) differ from that of patients with a normal ovarian reserve (NOR)?


SUMMARY ANSWER
The metabolomic signature of the FF reveals a significant decrease in polyunsaturated choline plasmalogens and methyl arginine transferase activity in DOR patients compared to NOR patients.


WHAT IS KNOWN ALREADY
The composition of the FF reflects the exchanges between the oocyte and its microenvironment during its acquisition of gametic competence. Studies of the FF have allowed identification of biomarkers and metabolic pathways involved in various pathologies affecting oocyte quality, but no large metabolomic analysis in the context of ovarian ageing and DOR has been undertaken so far.


STUDY DESIGN, SIZE, DURATION
This was an observational study of the FF retrieved from 57 women undergoing in vitro fertilization at the University Hospital of Angers, France, from November 2015 to September 2016. The women were classified in two groups: one including 28 DOR patients, and the other including 29 NOR patients, serving as controls.


PARTICIPANTS/MATERIALS, SETTING, METHODS
Patients were enrolled in the morning of oocyte retrieval after ovarian stimulation. Once the oocytes were isolated for fertilization and culture, the FF was pooled and centrifuged for analysis. A targeted quantitative metabolomic analysis was performed using high-performance liquid chromatography coupled with tandem mass spectrometry, and the Biocrates Absolute IDQ p180 kit. The FF levels of 188 metabolites and several sums and ratios of metabolic significance were assessed by multivariate and univariate analyses.


MAIN RESULTS AND THE ROLE OF CHANCE
A total of 136 metabolites were accurately quantified and used for calculating 23 sums and ratios. Samples were randomly divided into training and validation sets. The training set, allowed the construction of multivariate statistical models with a projection-supervised method, i.e. orthogonal partial least squares discriminant analysis (OPLS-DA), applied to the full set of metabolites, or the penalized least absolute shrinkage and selection operator with logistic regression (LASSO-LR), applied to the ratios and sums of the metabolites. Both multivariate models showed good predictive performances when applied to the validation set. The final penalized model retained the three most significant variables, i.e. the total dimethylarginine-to-arginine ratio (Total DMA/Arginine), the sum of the polyunsaturated choline plasmalogens (PUFA ae), and the patient's age. The negative coefficients of Total DMA/Arginine and PUFA ae indicated that these FF variables had lower values in DOR patients than in NOR patients.


LARGE SCALE DATA
N/A.


LIMITATIONS REASONS FOR CAUTION
This study presents two limitations. First, with this targeted metabolomics analysis, we have explored only a limited portion of the FF metabolome. Second, although the signature found was highly significant, the mechanism underlying the dysfunction remains undetermined.


WIDER IMPLICATIONS OF THE FINDINGS
The understanding of the mechanisms implied in ovarian ageing is essential for providing an adequate response to affected women desiring pregnancy. Our study proposes an incoming signature that may open new paths towards this goal.


STUDY FUNDING/COMPETING INTEREST(S)
This study was supported by the University Hospital of Angers, the University of Angers, and the French national research centers, INSERM and the CNRS. There were no competing interests.",2017,Human Reproduction
Infinite Predictor Subspace Models for Multitask Learning,"Given several related learning tasks, we propose a nonparametric Bayesian model that captures task relatedness by assuming that the task parameters (i.e., predictors) share a latent subspace. More specifically, the intrinsic dimensionality of the task subspace is not assumed to be known a priori. We use an infinite latent feature model to automatically infer this number (depending on and limited by only the number of tasks). Furthermore, our approach is applicable when the underlying task parameter subspace is inherently sparse, drawing parallels with â€˜1 regularization and LASSO-style models. We also propose an augmented model which can make use of (labeled, and additionally unlabeled if available) inputs to assist learning this subspace, leading to further improvements in the performance. Experimental results demonstrate the efficacy of both the proposed approaches, especially when the number of examples per task is small. Finally, we discuss an extension of the proposed framework where a nonparametric mixture of linear subspaces can be used to learn a nonlinear manifold over the task parameters, and also deal with the issue of negative transfer from unrelated tasks.",2010,
Regularized quantile regression applied to genome-enabled prediction of quantitative traits.,"Genomic selection (GS) is a variant of marker-assisted selection, in which genetic markers covering the whole genome predict individual genetic merits for breeding. GS increases the accuracy of breeding values (BV) prediction. Although a variety of statistical models have been proposed to estimate BV in GS, few methodologies have examined statistical challenges based on non-normal phenotypic distributions, e.g., skewed distributions. Traditional GS models estimate changes in the phenotype distribution mean, i.e., the function is defined for the expected value of trait-conditional on markers, E(Y|X). We proposed an approach based on regularized quantile regression (RQR) for GS to improve the estimation of marker effects and the consequent genomic estimated BV (GEBV). The RQR model is based on conditional quantiles, QÏ„(Y|X), enabling models that fit all portions of a trait probability distribution. This allows RQR to choose one quantile function that ""best"" represents the relationship between the dependent and independent variables. Data were simulated for 1000 individuals. The genome included 1500 markers; most had a small effect and only a few markers with a sizable effect were simulated. We evaluated three scenarios according to symmetrical, positively, and negatively skewed distributions. Analyses were performed using Bayesian LASSO (BLASSO) and RQR considering three quantiles (0.25, 0.50, and 0.75). The use of RQR to estimate GEBV was efficient; the RQR method achieved better results than BLASSO, at least for one quantile model fit for all evaluated scenarios. The gains in relation to BLASSO were 86.28 and 55.70% for positively and negatively skewed distributions, respectively.",2017,Genetics and molecular research : GMR
Some exercises with the Lasso and its compatibility constant,"We consider the Lasso for a noiseless experiment where one has observations $X \beta^0$ and uses the penalized version of basis pursuit. We compute for some special designs the compatibility constant, a quantity closely related to the restricted eigenvalue. We moreover show the dependence of the (penalized) prediction error on this compatibility constant. This exercise illustrates that compatibility is necessarily entering into the bounds for the (penalized) prediction error and that the bounds in the literature therefore are - up to constants - tight. We also give conditions that show that in the noisy case the dominating term for the prediction error is given by the prediction error of the noiseless case.",2017,arXiv: Statistics Theory
"Dietary exposures, epigenetics and pubertal tempo","Gene expression changes mediated by DNA methylation may play a role in pubertal tempo regulation, and availability of methyl donor nutrients affects these pathways. We examined first trimester maternal and adolescent diet patterns that may be associated with DNA methylation at long interspersed nucleotide (LINE-1) repetitive elements in adolescence using least absolute shrinkage and selection operator (LASSO) and calculated an 'Epigenetics-Associated Diet Score' (EADS) for each pattern; then tested the associations of these scores with pubertal tempo among adolescent boys and girls. The analytic sample included 118 boys and 132 girls aged 10-18 years. DNA methylation at LINE-1 repetitive elements was quantified. Typical maternal and adolescent nutrient intakes were estimated using food frequency questionnaires. Interval-censored time to event and ordinal regression models were used to examine associations EADS scores with pubertal tempo using physician-assessed Tanner stages and self-reported menarche, respectively, adjusted for confounders. We observed associations between maternal EADS and pubertal onset, but not pubertal progression. Each standard deviation (SD) greater maternal EADS was associated with 52% higher odds of having later onset of menarche in both cross-sectional and prospective analysis (P = 0.031 and 0.028, respectively). In contrast, we observed associations between adolescent EADS and pubertal progression, but not pubertal onset. Among boys, for each SD higher adolescent EADS, there was 13% increase in odds of slower genital progression (P = 0.050), as well as 26 and 27% increase in odds of slower left and right testicular development, respectively (P = 0.001). Epigenetic-associated diet influences pubertal tempo in a sex- and timing-specific manner.",2019,Environmental Epigenetics
bamlss: A Lego Toolbox for Flexible Bayesian Regression (and Beyond),"Over the last decades, the challenges in applied regression and in predictive modeling have been changing considerably: (1) More flexible model specifications are needed as big(ger) data become available, facilitated by more powerful computing infrastructure. (2) Full probabilistic modeling rather than predicting just means or expectations is crucial in many applications. (3) Interest in Bayesian inference has been increasing both as an appealing framework for regularizing or penalizing model estimation as well as a natural alternative to classical frequentist inference. However, while there has been a lot of research in all three areas, also leading to associated software packages, a modular software implementation that allows to easily combine all three aspects has not yet been available. For filling this gap, the R package bamlss is introduced for Bayesian additive models for location, scale, and shape (and beyond). At the core of the package are algorithms for highly-efficient Bayesian estimation and inference that can be applied to generalized additive models (GAMs) or generalized additive models for location, scale, and shape (GAMLSS), also known as distributional regression. However, its building blocks are designed as ""Lego bricks"" encompassing various distributions (exponential family, Cox, joint models, ...), regression terms (linear, splines, random effects, tensor products, spatial fields, ...), and estimators (MCMC, backfitting, gradient boosting, lasso, ...). It is demonstrated how these can be easily recombined to make classical models more flexible or create new custom models for specific modeling challenges.",2019,ArXiv
A Metaheuristic LASSO Model for Diabetic Readmission Prediction,"Hospital readmission prediction continues to be a highly-encouraged area of investigation mainly because of the readmissions reduction program by the Centers for Medicare and Medicaid services (CMS). The overall goal is to reduce the number of early hospital readmissions by identifying the key risk factors that cause hospital readmissions. This is especially important in Intensive Care Unit (ICU), where patient readmission increases the likelihood of mortality due to the worsening of the patient condition. Traditional approaches use simple logistic regression or other linear classification methods to identify the key features that provide high prediction accuracy. However, these methods are not sufficient since they cannot capture the complex patterns between different features. In this paper, we propose a hybrid Evolutionary Simulating Annealing LASSO Logistic Regression (ESALOR) model to accurately predict the hospital readmission rate and identify the important risk factors. The proposed model combines the evolutionary simulated annealing method with a sparse logistic regression model of Lasso. The ESALOR model was tested on a publicly available diabetes readmission dataset, and the results show that the proposed model provides better results compared to conventional classification methods including Support Vector Machines (SVM), Decision Tree, Naive Bayes, and Logistic Regression.",2016,
Sparse recovery based on q-ratio constrained minimal singular values,"We study verifiable sufficient conditions and computable performance bounds for sparse recovery algorithms such as the Basis Pursuit, the Dantzig selector and the Lasso estimator, in terms of a newly defined family of quality measures for the measurement matrices. With high probability, the developed measures for subgaussian random matrices are bounded away from zero as long as the number of measurements is reasonably large. Comparing to the restricted isotropic constant based performance analysis, the arguments in this paper are much more concise and the obtained bounds are tighter. Numerical experiments are presented to illustrate our theoretical results.",2019,Signal Process.
Prevalence and patterns of multimorbidity among the elderly in Burkina Faso: cross-sectional study.,"OBJECTIVES
To assess the prevalence and distribution patterns of multimorbidity among urban older adults in Burkina Faso.


METHODS
Cross-sectional study among community-dwelling elderly people aged â‰¥60 in Bobo-Dioulasso. We performed interviews, clinical examination and medical record review. Multimorbidity was defined as co-occurrence of at least two chronic diseases in one person whether as a coincidence or not.


RESULTS
The overall prevalence of multimorbidity among older adults was 65%. Age â‰¥70 was associated with multimorbidity in multivariate analysis: adjusted OR = 1.65, 95% CI (1.01-2.68, P = 0.04). The most common chronic diseases were hypertension (82%) 95% CI (78; 86), malnutrition (39%) 95% CI (34; 44), visual impairments (28%) 95% CI (24; 33) and diabetes mellitus (27%) 95% CI (22; 31). Those aged â‰¥70 had significantly more malnutrition (50% vs. 31%, P = 0.0003) and osteoarthritis (8% vs. 3%, P = 0.01) than those aged 60-69.


CONCLUSIONS
The high prevalence of multimorbidity requires a reorganization of healthcare systems in sub-Saharan Africa, especially in Burkina Faso. Interventions and care guidelines usually focused on individual diseases should be improved to better reflect this reality.",2014,Tropical medicine & international health : TM & IH
On The Proper Treatment of Semantic Systematicity,"The past decade has witnessed the emergence of a novel stance on semantic representation, and its relationship to context sensitivity. Connectionist-minded philosophers, including Clark and van Gelder, have espoused the merits of viewing hidden-layer, context-sensitive representations as possessing semantic content, where this content is partially revealed via the representations' position in vector space. In recent work, BodÃ©n and Niklasson have incorporated a variant of this view of semantics within their conception of semantic systematicity. Moreover, BodÃ©n and Niklasson contend that they have produced experimental results which not only satisfy a kind of context-based, semantic systematicity, but which, to the degree that reality permits, effectively deals with challenges posed by Fodor and Pylyshyn (1988), and Hadley (1994a). The latter challenge involved well-defined criteria for strong semantic systematicity. This paper examines the relevant claims and experiments of BodÃ©n and Niklasson. It is argued that their case fatally involves two fallacies of equivocation; one concerning 'semantic content' and the other concerning 'novel test sentences'. In addition, it is argued that their ultimate construal of context sensitive semantics contains serious confusions. These confusions are also found in certain publications dealing with ""latent semantic analysis"". Thus, criticisms presented here have relevance beyond the work of BodÃ©n and Niklasson.",2004,Minds and Machines
Cleaning interactions at the only atoll in the South Atlantic,"In marine ecosystems, cleaning is a mutualistic relationship in which so-called cleaners remove ectoparasites, diseased tissue, or mucus from the body of their clients, and thus help to maintain a healthy reef community. In spite of its importance in many marine habitats, this interaction remains poorly understood, particularly at oceanic islands. Here, we present the first comprehensive study of cleaning interactions in a reef fish assemblage at Rocas, the only atoll in the South Atlantic. We recorded 318 cleaning events, in which six fish species, including two endemic ones, and two shrimp species acted as cleaners. The clients serviced by these cleaners were 21 bony fish species, one shark and one sea turtle. The cleaner wrasse Thalassoma noronhanum and the cleaner goby Elacatinus phthirophagus were the cleaners with the greatest number of events and species richness of clients. Additionally, 82% of clients in the cleaning events were non-piscivores, and the abundance of both cleaners and clients positively influenced the number of cleaning events (R2Â =Â 0.4; pÂ <Â 0.001). Our results indicate that Rocas atoll has a high species richness of cleaner species despite its small size and highlight the importance of studies of cleaning symbiosis, even in isolated places with low species richness, for a better comprehension of this association in reefs.",2017,Environmental Biology of Fishes
"Foods and Aspects of Growth in the Antarctic Petrel and Southern Fulmar Breeding at Hop Island, Rauer Group, East Antarctica","Foods of adult Antarctic Petrels Thalassoica antarctica and Southern Fulmars Fulmarus glacialoides breeding on Hop Island, Rauer Group, East Antarctica, were obtained using water-offloading techniques, from late incubation to late post-guard periods. Both species took mainly krill, particularly Euphausia superba, and fish, almost entirely Pleuragramma antarcticum; other crustaceans and cephalopods were infrequent. The increase of E. crystallorophias, particularly in Southern Fulmars, was associated with increased P. antarcticum in the diet of both species. No significant differences in prey sizes were detected but the smaller Antarctic Petrel tended to contain more fish and less krill. Results are compared with previous studies; all show a restricted number of prey species, and a wide range of prey sizes. Variations in proportions of specific groups may reflec sampling methods, but more likely reflect prey abundance or availability. The importance of ice cover is discussed. Inshore feeding by Southern Fulmars, and differing feeding methods, may allow segregation of foraging: assuming similar rates of digestion, the more digested food in Antarctic Petrels suggests a greater foraging range. This is supported by differences in attendance shifts at nests. Growth rates of chicks deprived a meal were compared with those of chicks given supplementary meals, and controls. Deprivation apparently caused no immediate effects; additional meals tended to increase growth of Antarctic Petrel chicks. Small sample sizes confounded interpretation but suggested that Antarctic Petrels, which typically breed further south than Southern Fulmars, are better adapted to local conditions where sympatric with Southern Fulmars. The slightly larger volumes of oil retrieved with Antarctic Petrel food supports this since oil offers a more efficient method of transporting food to growing chicks. For these two fulmarine petrels, segregation of food requirements may be by foraging differences; where sympatric, segregation of peak demands may also result from separation of laying periods.",1992,Emu
Joint multiple quantitative trait loci mapping for allometries of body compositions and metabolic traits to body weights in broiler.,"In order to map quantitative trait loci (QTLs) for allometries of body compositions and metabolic traits in chicken, we phenotypically characterize the allometric growths of multiple body components and metabolic traits relative to BWs using joint allometric scaling models and then establish random regression models (RRMs) to fit genetic effects of markers and minor polygenes derived from the pedigree on the allometric scalings. Prior to statistically inferring the QTLs for the allometric scalings by solving the RRMs, the LASSO technique is adopted to rapidly shrink most of marker genetic effects to zero. Computer simulation analysis confirms the reliability and adaptability of the so-called LASSO-RRM mapping method. In the F2 population constructed by multiple families, we formulate two joint allometric scaling models of body compositions and metabolic traits, in which six of nine body compositions are tested as significant, while six of eight metabolic traits are as significant. For body compositions, a total of 14 QTLs, of which 9 dominant, were detected to be associated with the allometric scalings of drumstick, fat, heart, shank, liver and spleen to BWs; while for metabolic traits, a total of 19 QTLs also including 9 dominant be responsible for the allometries of T4, IGFI, IGFII, GLC, INS, IGR to BWs. The detectable QTLs or highly linked markers can be used to regulate relative growths of the body components and metabolic traits to BWs in marker-assisted breeding of chickens.",2020,Animal : an international journal of animal bioscience
Improvement of experimental testing and network training conditions with genome-wide microarrays for more accurate predictions of drug gene targets,"BackgroundGenome-wide microarrays have been useful for predicting chemical-genetic interactions at the gene level. However, interpreting genome-wide microarray results can be overwhelming due to the vast output of gene expression data combined with off-target transcriptional responses many times induced by a drug treatment. This study demonstrates how experimental and computational methods can interact with each other, to arrive at more accurate predictions of drug-induced perturbations. We present a two-stage strategy that links microarray experimental testing and network training conditions to predict gene perturbations for a drug with a known mechanism of action in a well-studied organism.ResultsS. cerevisiae cells were treated with the antifungal, fluconazole, and expression profiling was conducted under different biological conditions using Affymetrix genome-wide microarrays. Transcripts were filtered with a formal network-based method, sparse simultaneous equation models and Lasso regression (SSEM-Lasso), under different network training conditions. Gene expression results were evaluated using both gene set and single gene target analyses, and the drugâ€™s transcriptional effects were narrowed first by pathway and then by individual genes. Variables included: (i) Testing conditions â€“ exposure time and concentration and (ii) Network training conditions â€“ training compendium modifications. Two analyses of SSEM-Lasso output â€“ gene set and single gene â€“ were conducted to gain a better understanding of how SSEM-Lasso predicts perturbation targets.ConclusionsThis study demonstrates that genome-wide microarrays can be optimized using a two-stage strategy for a more in-depth understanding of how a cell manifests biological reactions to a drug treatment at the transcription level. Additionally, a more detailed understanding of how the statistical model, SSEM-Lasso, propagates perturbations through a network of gene regulatory interactions is achieved.",2012,BMC Systems Biology
[A case of rhinofacial entomophthoromycosis in Soudano-Sahelian tropical climate in Burkina Faso].,"We describe a rhinofacial entomophthoramycosis case in a sexagenarian (65Â years old) housewife. She was immunocompetent and resident of Burkina Faso. She consulted both the service of dermatology and the service of stomatology of the Teaching Hospital of Bobo-Dioulasso in February 2016Â for a diffuse facial tumefaction evolving over six months. This tumefaction was associated with headaches and a left nasal obstruction. Histological examination of the lesion showed an important and polymorphic inflammatory reaction. Also, a filamentous fungus with wide non-septated hyphae and right-angled fungal branching, consistent with mucormycosis was isolated. Mycological diagnosis based on fungal culture with Sabouraud medium without any antibiotic and cyclohexemide after incubation at 27Â°C and at 30Â°C was negative. Furthermore, it was not possible to amplify the DNA extracted from biopsy. Antifungal therapy based on the administration of fluconazole per os at 800mg/day was started allowing clinical improvement. This is the first case of a rhinofacial entomophtharomycosis documented in Bobo-Dioulasso. Rhinofacial entomophthoromycosis is largely unknown, even in tropical regions such as Burkina Faso. This lack of knowledge results in a delay in the diagnosis, and subsequently a bad prognosis. It is therefore urgent to improve knowledge on this disease to guide diagnostic steps, prognosis of outcome, and antifungal therapy.",2017,Journal de mycologie medicale
"Complementing the power of deep learning with statistical model fusion: Probabilistic forecasting of influenza in Dallas County, Texas, USA.","Influenza is one of the main causes of death, not only in the USA but worldwide. Its significant economic and public health impacts necessitate development of accurate and efficient algorithms for forecasting of any upcoming influenza outbreaks. Most currently available methods for influenza prediction are based on parametric time series and regression models that impose restrictive and often unverifiable assumptions on the data. In turn, more flexible machine learning models and, particularly, deep learning tools whose utility is proven in a wide range of disciplines, remain largely under-explored in epidemiological forecasting. We study the seasonal influenza in Dallas County by evaluating the forecasting ability of deep learning with feedforward neural networks as well as performance of more conventional statistical models, such as beta regression, autoregressive integrated moving average (ARIMA), least absolute shrinkage and selection operators (LASSO), and non-parametric multivariate adaptive regression splines (MARS) models for one week and two weeks ahead forecasting. Furthermore, we assess forecasting utility of Google search queries and meteorological data as exogenous predictors of influenza activity. Finally, we develop a probabilistic forecasting of influenza in Dallas County by fusing all the considered models using Bayesian model averaging.",2019,Epidemics
Short-term forecasting of emerging on-demand ride services,"In the last few years, on-demand ride services boomed worldwide, and different modes of ridesourcing services emerged, too. However, there have been few qualitative and quantitative analyses on these ride service patterns, partially due to the lack or unavailability of detailed on-demand ride service data. In this paper, we analyze the real-world individual-level order and the trip data extracted from the DiDi's on-demand mobility platform in Hangzhou, China. This study intends to understand the temporal and spatial travel pattern of passengers' demand and ride services which include four types, i.e., Taxi Hailing, Private Car Service, Hitch, and Express. We study the relationship between different service modes of the drivers from a selected region in specific time periods. In order to predict travel demand of the aforementioned on-demand ride services, we utilize LASSO (least absolute shrinkage and selection operator) to rank features of the on-demand platform data (e.g., distance, fee, and waiting time). An on-demand ride prediction model is established based on the random forest (RF), which is then compared with the autoregressive integrated moving average (ARIMA) and support vector regression (SVR). The results show that RF outperforms other models and it is utilized to provide an insight for forecasting the demand of distinctive on-demand ride service patterns. To the best knowledge of authors, this paper is among the first attempts to learn the temporal and spatial travel patterns, also to forecast emerging on-demand ride services.",2017,2017 4th International Conference on Transportation Information and Safety (ICTIS)
Graph Projection Block Splitting for Distributed Optimization,"This paper describes a general purpose method for solving convex optimization problems in a distributed computing environment. In particular, if the problem data includes a large linear operator or matrix A, the method allows for handling each subblock of A on a separate machine. The approach works as follows. First, we define a canonical problem form called graph form, in which we have two sets of variables x and y related by a linear operator A, such that the objective function is separable across these two sets of variables. Many problems are easily expressed in graph form, including cone programs and a wide variety of regularized loss minimization problems from statistics, like logistic regression, the support vector machine, and the lasso. Next, we describe graph projection splitting, a form of Douglas-Rachford splitting or the alternating direction method of multipliers, to solve graph form problems serially. Finally, we derive a distributed block splitting algorithm based on graph projection splitting. In a statistical or machine learning context, this allows for training models exactly with a huge number of both training examples and features, such that each processor handles only a subset of both. To the best of our knowledge, this is the only general purpose method with this property. We present several numerical experiments in both the serial and distributed settings.",2012,
Rehabilitation after palliative surgery of coxarthrosis,"The functional balance of the patient is disturbed in matter of motion as well as psychologically after palliative surgery of the hip osteoarthritis. In the favourable cases, good rehabilitation allowed recovery of function for the activies of daily livia : Walking, car driving domestic and leisure activities, except for some elementary precautions. When the functional constraint and the pain continue, a complementary physical treatment is proposed, essentially balneotherapical. The conditions are varied, that is why thalassotherapy and hydrotherapy are taking all their importance. In addition to the benefit of the weightlessness work on the musculature and the warmth will have a favourable effect. Lastly, the delay in weight-bearing and in carrying-out these different therapies will allow the surgeon to adopt a detached attitude to evaluate the value of a possible new intervention.",1991,
La plasticitÃ  e lâ€™ingegnere costruttore,"Sunto1.- GeneralitÃ .2.- Le ipotesi sulla plasticizzazione (ipotesi delle tensioni, delle deformazioni, del Potenziale elastico). - Tensore sferico, deviatore, espressioni della condizione di plasticitÃ .3.- Relazione fra tensioni e deformazioni. - Legge diPrandtl-Reuss. - Leggi lineari semplificate dello stato di tensione mono-assiale.4.- Lâ€™adattamento plastico in una sezione inflessa. - Calcolo a rottura e coefficiente di sicurezza. - Momento limite e momento plastico. - La condizione diDutheil. - La torsione.5.- Il problema plastico nelle strutture staticamente indeterminate. - Il metodo delle successive approssimazioni in un sistema iperstatico con zone plasticizzate. â€” Le cerniere plastiche, il meccanismo di collasso, i teoremi diFeinberg e diGreenberg-Prager.6.- I carichi pulsanti, il collasso incrementale, la plasticitÃ  alternata. - Il carico di stabilizzazione plastico.7.- La plasticitÃ  nei fenomeni di instabilitÃ . - La linea di biforcazione. - Le teorie diEngesser-Karman e diEngesser-Shanley per il carico di punta.8.- Osservazioni riassuntive e conclusioni.9.- Bibliografia.",1960,Rendiconti del Seminario Matematico e Fisico di Milano
On the Connection between the Hamilton-Jacobi-Bellman and the Fokker-Planck Control Frameworks,"In the framework of 
stochastic processes, the connection between the dynamic programming scheme 
given by the Hamilton-Jacobi-Bellman equation and a recently proposed control 
approach based on the Fokker-Planck equation is discussed. Under appropriate 
assumptions it is shown that the two strategies are equivalent in the case of 
expected cost functionals, while the Fokker-Planck formalism allows considering 
a larger classof objectives. To illustratethe connection between the two 
control strategies, the cases of an ItÅ stochastic process and of a 
piecewise-deterministic process are considered.",2014,Applied Mathematics-a Journal of Chinese Universities Series B
Cyst Fluid Biosignature to Predict Intraductal Papillary Mucinous Neoplasms of the Pancreas with High Malignant Potential.,"BACKGROUND
Current standard-of-care technologies, such as imaging and cyst fluid analysis, are unable to consistently distinguish intraductal papillary mucinous neoplasms (IPMNs) of the pancreas at high risk of pancreatic cancer from low-risk IPMNs. The objective was to create a single-platform assay to identify IPMNs that are at high risk for malignant progression.


STUDY DESIGN
Building on the Verona International Consensus Conference branch duct IPMN biomarker review, additional protein, cytokine, mucin, DNA, and microRNA cyst fluid targets were identified for creation of a quantitative polymerase chain reaction-based assay. This included messenger RNA markers: ERBB2, GNAS, interleukin 1Î², KRAS, MUCs1, 2, 4, 5AC, 7, prostaglandin E2R, PTGER2, prostaglandin E synthase 2, prostaglandin E synthase 1, TP63; microRNA targets: miRs 101, 106b, 10a, 142, 155, 17, 18a, 21, 217, 24, 30a, 342, 532, 92a, and 99b; and GNAS and KRAS mutational analysis. A multi-institutional international collaborative contributed IPMN cyst fluid samples to validate this platform. Cyst fluid gene expression levels were normalized, z-transformed, and used in classification and regression analysis by a support vector machine training algorithm.


RESULTS
From cyst fluids of 59 IPMN patients, principal component analysis confirmed no institutional bias/clustering. Lasso (least absolute shrinkage and selection operator)-penalized logistic regression with binary classification and 5-fold cross-validation used area under the curve as the evaluation criterion to create the optimal signature to discriminate IPMNs as low risk (low/moderate dysplasia) or high risk (high-grade dysplasia/invasive cancer). The most predictive signature was achieved with interleukin 1Î², MUC4, and prostaglandin E synthase 2 to accurately discriminate high-risk cysts from low-risk cysts with an area under the curve of up to 0.86 (pÂ = 0.002).


CONCLUSIONS
We have identified a single-platform polymerase chain reaction-based assay of cyst fluid to accurately predict IPMNs with high malignant potential for additional studies.",2019,Journal of the American College of Surgeons
Unbiased Adaptive LASSO Parameter Estimation for Diffusion Processes,"The adaptive Least Absolute Shrinkage and Selection Operator (aLASSO) method is an algorithm for simultaneous model selection and parameter estimation with oracle properties. In this work we derive an adaptive LASSO type estimator for diffusion driven stochastic differential equation under weak conditions, specifically that the algorithm does not rely on high frequency properties.All conditional moments needed in our quasi likelihood function are computed from the Kolmogorov Backward equation. This means that a single equation is solved numerically, regardless of the number of observations. The LASSO problem is solved using the Alternating Direction Method of Multipliers (ADMM) method.Our simulations show that the resulting algorithm is able to find the correct model with high probability while obtaining unbiased parameter estimates when evaluated on two qualitatively different data sets. (Less)",2018,IFAC-PapersOnLine
Domestic Violence Awareness.,"Domestic or intimate partner violence is alarmingly prevalent, and, for victims, a major contributor to depression, anxiety, and other forms of mental illness. Psychological problemsandpsychiatric syndromesoften are the antecedents of domestic violence for the perpetrator and also can be risk factors for becoming a victim. Remarkably, the two dominant mental health fields, psychiatry and clinical psychologyâ€”the ones charged with investigating and attending to the mind, brain, andbehaviorâ€”are largelyabsent fromdomestic violence research and intervention. More than one in three women and at least one in four men have been the victim of rape, physical violence, or stalking by an intimate partner (1). However, women are far more likely than men to experience severe sexual and physical violence from apartnerortobekilledbyone(1,2). IntheUnitedStates, intimate partnerhomicidesmakeupbetween40%and50%ofallmurders of women (3). Domestic violence crosses geographic and socioeconomic stratification, although studies indicate that lowerincomewomen in rural communities experience higher rates of violence and, specifically, sexual abuse (4, 5). Victims suffer from dramatic rates of depression, anxiety, and posttraumatic stress disorder,aswellassubstanceabuseandsuicidality(6â€“8).Arecent study based on a representativeU.S. sample ofmore than 25,000 adults indicatedthatnewonsetsofmajormentalhealthproblems were more than twice as common among those exposed to domestic violence in the past year than among nonvictims (9). Millionsofchildrenâ€”asmanyas 15million, according to some estimatesâ€”witness domestic violence each year (10). For male children there is a 1,000% greater risk of reproducing this violence in their own spousal relationships (11). A recent epidemiologic study found prior domestic violence victimization to bemore strongly associatedwith domestic violence perpetration than any other factor (12). Despite its prevalence in the general population, domestic violence is underrepresented in our consulting rooms in part because victims, and especially perpetrators, rarely voluntarily self-identifyorseektreatment(8, 13, 14).Shame,guilt, anddenial are obvious deterrents. These factors are often compounded by a sense of futility resulting from learned helplessness, and a profound unraveling of self-esteem (15). More practical considerations include fears for personal security, economic codependence, and the concerns that disclosure will trigger social services engagement, particularly child protection (8). Finally, disclosure represents a potential threat to the continuance of a romantic relationship, which, though abusive, involves emotional investment. Without experience handling domestic violence situations, clinicians can feel ill-prepared and deskilled, lacking knowledge about referral sources, emergent threats of bodily harm, and the accompanying legal and ethical obligations. This lack of presentation in clinical settings contributes to a â€œdonâ€™t askâ€ scenario (8). Since 1986, numerous medical institutions have advocated for domestic violence screening inroutinemedicalcare(16, 17); in2001, theAmerican Psychiatric Association followed suit. That same year, the AmericanPsychologicalAssociationâ€™s IntimatePartner Abuse and Relationship Violence Working Group launched a curriculumon domestic violence but appears to have done little to foster relevant training in clinical interventions. Domestic violence is an exceptionally challenging clinical situation. Those in domestic violence relationships areat risk for repeating this experience, and likely have abuse or exposure to it in their backgrounds (11, 18), adding immense complexity to treatment. Thework presents unique challenges, including safety planning and patientsâ€™minimization of abuse, which may induce feelings of helplessness in the context of significant urgency anddanger (19â€“21). There noware targeted treatments for domestic violence intervention, such as Seeking Safety (22) and Child-Parent Psychotherapy (23), though few psychologists and psychiatrists are trained in them. Of course the question of how clinically to respond to perpetrators is a complicated one, independentof thenecessary legal consequences.However, treatment and prevention programs are emerging, such as the Melissa Institute for Violence Prevention and Treatment. Beyond the â€œprofessional counter-transferenceâ€ is possibly a more personal one. Aggression is a fundamental human impulse, and violence a socially unacceptable manifestation of it. Underlying any violent interaction is the universal human struggle with aggression and its myriad complex antecedents: family and developmental history; self-esteem; power dynamics; fear of abandonment and humiliation; emotional regulation; impulse control; and the capacity for empathy, guilt, and remorse. The possibility that domestic",2015,The American journal of psychiatry
Classification and Regression Using an Outer Approximation Projection-Gradient Method,"This paper deals with sparse feature selection and grouping for classification and regression. The classification or regression problems under consideration consists of minimizing a convex empirical risk function subject to an <inline-formula><tex-math notation=""LaTeX"">$\ell ^1$</tex-math></inline-formula> constraint, a pairwise <inline-formula> <tex-math notation=""LaTeX"">$\ell ^\infty$</tex-math></inline-formula> constraint, or a pairwise <inline-formula> <tex-math notation=""LaTeX"">$\ell ^1$</tex-math></inline-formula> constraint. Existing work, such as the Lasso formulation, has focused mainly on Lagrangian penalty approximations, which often require <italic>ad hoc</italic> or computationally expensive procedures to determine the penalization parameter. We depart from this approach and address the constrained problem directly via a splitting method. The structure of the method is that of the classical gradient-projection algorithm, which alternates a gradient step on the objective and a projection step onto the lower level set modeling the constraint. The novelty of our approach is that the projection step is implemented via an outer approximation scheme in which the constraint set is approximated by a sequence of simple convex sets consisting of the intersection of two half-spaces. Convergence of the iterates generated by the algorithm is established for a general smooth convex minimization problem with inequality constraints. Experiments on both synthetic and biological data show that our method outperforms penalty methods.",2017,IEEE Transactions on Signal Processing
Automated Variable Selection and Shrinkage for Day-Ahead Electricity Price Forecasting,"In day-ahead electricity price forecasting (EPF) variable selection is a crucial issue. Conducting an empirical study involving state-of-the-art parsimonious expert models as benchmarks, datasets from three major power markets and five classes of automated selection and shrinkage procedures (single-step elimination, stepwise regression, ridge regression, lasso and elastic nets), we show that using the latter two classes can bring significant accuracy gains compared to commonly-used EPF models. In particular, one of the elastic nets, a class that has not been considered in EPF before, stands out as the best performing model overall.",2016,Energies
The Feminist Futures of Reading Diffractively : How Barad ' s Methodology Replaces Conflict-based Readings of Beauvoir and Irigaray,"Quantum leaps happen in texts, too. This reading of the role of the quantum leap in Karen Barad's agential realism is necessary, because arguing that the diffractive reading strategy proposed by Barad's ethico-onto-epistemology mirrors the physical phenomenon of diffraction would indeed be representationalist. Reviewing how Baradâ€”in her own oeuvreâ€”has transformed diffraction into an innovative reading methodology that could not only potentially challenge the epistemological underpinnings of the canonization process that is at work in feminist theory, but could also radically change the canonization practice of feminist oeuvres itself, our article embarks on a detailed examination of the ways in which the oeuvres of Simone de Beauvoir and Luce Irigaray have been mistakenly categorized and canonized in a hierarchical and Oedipalized manner. This conflict-based narrative has not only paralyzed the oeuvres of Irigaray and Beauvoir, but also has had a negative impact on the canonization of sexual difference philosophy as a whole in feminist theory. By (re)reading the oeuvres diffractively, this article brings the feminist philosophies of Beauvoir and Irigaray together by invalidating the idea that the feminist canonization process always has to run along the lines of discontinuity, Oedipalization and dialectization. Introduction: from conflict to affirmation [1] Most feminist theorists will have a hard time when confronted with philosopher Slavoj Å½iÅ¾ek's recent engagements with physicist-philosopher Karen Barad's work. His blatant sexist and homophobic attitude toward Barad is particularly striking, considering the fact that Å½iÅ¾ek thinks of himself as a radically progressive philosopher. In a lecture titled ""Ontological Incompleteness in Painting, Literature and Quantum Theory"" held at the European Graduate School in 2012,[1] Å½iÅ¾ek demonstrates that he does not have his theoretical physics straight, that he does not know his references, and that he can only read ""that woman"" (i.e. Barad) in an Oedipal and unashamedly confrontational manner. While saying that he likes Barad's rigorous and complex interpretation of Niels Bohr's physics and philosophy, he at the same time questions Barad's seriousness to the point of asking the audience to ""kick [him] in the face"". Unnecessary references are then made to Barad's friendship with Judith Butler, to the ""postmodern jargon"" (Å½iÅ¾ek) that both feminist theorists share, and to theirâ€”and Wendy Brown'sâ€”lesbian sexuality, which is presented as an insult to all men. It goes without saying that Å½iÅ¾ek is the real insulter here! [2] Feminist theorists cannot afford not to respond to Å½iÅ¾ek, in our opinion. The long history of feminist engagements with philosophy and science demonstrates that sexism and homophobia need to be fought against continuously and explicitly, within and outside the canon (Harding). Barad's oeuvre is not the only one that has been read through an Oedipalized focus: the philosophies and feminisms of French socalled 'equality' feminist Simone de Beauvoir and Belgian-born alleged 'difference' feminist Luce Irigaray have been interpreted in the exact same confrontational and oppositional manner. The Oedipalized misreadings and narratives of these oeuvres matter, just like Å½iÅ¾ek's problematic reading of Barad matters, because these readings and narratives have played a crucial role in the misconstruction of feminist theory as a scenery of catfights; a domain of women engaged in bitter, dividing debates. [3] A feminist reinterpretation of Å½iÅ¾ek's reading of Barad, in tandem with Å½iÅ¾ek's interpretation of French thinker Quentin Meillassoux's philosophy, could prove to be the ideal launch pad to expose the underlying Oedipal structure of such misreadings. Since Å½iÅ¾ek himself provides us with the building blocks of such an interpretationâ€”an interpretation that we will consequently develop in ""a mode of assenting to rather than dissenting from those 'primary' texts"" (Grosz 3)â€”his case reveals the ways in which we could put an end to Oedipalization via diffraction. Diffractive reading is a Baradian neologism (with roots in Donna Haraway's philosophy) and our argument in this article will be that Oedipal readings â€”of feminists/women and within feminismâ€”can be undone by the affirmative strategy of reading diffractively. On philosophical blind spots and deadlocks: Å½iÅ¾ek's reading of Barad and Meillassoux [4] Å½iÅ¾ek's Less than Nothing: Hegel and the Shadow of Dialectical Materialism is more than just a thick description of Hegelian philosophy, its theoretical predecessors and its travels through the canon of Western philosophyâ€”although Å½iÅ¾ek oddly enough forgot to include Beauvoir and Irigaray, two of G.W.F. Hegel's most important (but also most critical) feminist followers. Less than Nothing also engages with two very recent Continental philosophical inventions, namely speculative materialism, and agential realism. The first trend is by and large Meillassoux's, although many more scholars self-identify as such or are being slotted into this category (see Bryant et al.). The second movement is led by Barad. Å½iÅ¾ek asks how they interpret Hegel and to what extent they remain under the spell of (a) Hegelianism. [5] Å½iÅ¾ek spends a considerable amount of time reading Meillassoux in Less than Nothing and he convincingly argues how Meillassoux's work falls into its own trap, or is distorted by the same kind of blind spot that Meillassoux ironically enough previously attributed to idealist philosophers (Å½iÅ¾ek 627-8). Å½iÅ¾ek needs to be thanked for this evaluation, and for the analysis that follows, in which he claims that Meillassoux remains trapped in the question of the subject, while aiming at nothing less than eliminating anthropocentrism. Å½iÅ¾ek argues that Meillassoux remains confined to ""the masculine side of Lacan's formulae of sexuation"" (636) and to Hegelianism precisely in his critique of Hegel (636). What Å½iÅ¾ek successfully demonstrates is that Meillassoux cannot succeed in his project of moving away from ""representation in the Leibnizian monad; Schelling's Nature, or the objective subject-object; Hegelian Mind; Schopenhauer's Will; the Will (or Wills) to Power in Nietzsche; perception loaded with memory in Bergson; Deleuze's Life, etc"" (Meillassoux 37) on the basis of the charge of correlationism (a Kantianism). As feminists, however, this conflict in brotherly machines (see Jardine 223) should not be our main concern. [6] What does matter to us is that Å½iÅ¾ek's reading implies that Barad's and Meillassoux's positions differ: Meillassoux, in contrast to Barad, is unable to follow up on the philosophical impetus of Bohrian quantum physics. This is so, because this impetus pertains to the question of the subject. In Å½iÅ¾ek's words: Meillassoux is well aware that quantum physics, with its uncertainty principle and emphasis on the role the observer plays in the collapse of the wave function, seems to undermine the notion of objective reality independent of any observer and thus give an unexpected boost to Kantian transcendentalism; however, as he points out, their similarity is deceptive [...] while in Kant's transcendentalism the ""observer""-subject constitutes what he observes, in quantum physics, the observer's active role itself is re-inscribed into physical reality. (Å½iÅ¾ek 634) [7] Discussing Å½iÅ¾ek's reading of Barad's onto-epistemological in(ter)vention[2] would nonetheless lead us too far afield, since Å½iÅ¾ek's reading is plagued by a lot of internal problems (Heisenberg's uncertainty differs from Bohr's indeterminacy, for instance, and he consistently misquotes Barad throughout Less than Nothing).[3] For one thing, Å½iÅ¾ek (935) ascribes an ""implicit naturalism"" to Barad,[4] which, according to Å½iÅ¾ek, makes her disregard sexual difference. Where Barad makes her point about the subject's entanglement with/in agential reality, Å½iÅ¾ek attributes a hierarchical reasoning to Barad (quantum physics can understand classical physicists, whereas classical physics cannot understand quantum physicists) and claims that: [...] it would be too easy to simply privilege the 'feminine' non-All [quantum physics] and to reduce the masculine totalization-through-exception to a secondary illusion [classical physics]â€”here, more than ever, we should insist on (sexual) difference itself as a primary fact, as the impossible Real with regard to which both positions, 'masculine' and 'feminine,' appear as secondary, as two attempts to resolve its deadlock. (Å½iÅ¾ek 934-5) [8] Contrary to what Å½iÅ¾ek believes, feminist philosophers have taken on the issue of sexual difference and the practice of psychoanalysis. In most general terms, feminist philosophers have dealt with the Real (symptoms, psychoses) while claiming the empirical. You may ask what this feminist attempt looks like, and whether it has been successful. Let us shuffle the cards and keep in mind that feminist work can indeed demonstrate how ""[t]he structure of sexual difference is already that of diffraction"" (Å½iÅ¾ek 935). In the following sections we will first discuss how Beauvoir and Irigaray have developed a notion of sexual difference by reflecting upon the mother-daughter relationship and how this has resulted in their commentators reading a possible antinomy between their feminist philosophical positions. In the next step, we will explore what a diffractive reading can bring to both this claimed antinomy and the nature of sexual difference. Hence, diffractionâ€”which will also be introduced as a reading methodology in one of the sections belowâ€”features on multiple levels in our article. Following Barad's methodological innovation, diffraction is ""a physical phenomenon that lies at the center of some key discussions in physics and the philosophy of physics"" and ""an apt metaphor for describing the methodological approach [...] of reading insights through one another in attending to and responding to the details and specificities of relations",2017,
Lasso peptides from Actinobacteria - Chemical diversity and ecological role,"Lasso peptides are ribosomally synthesized and post-translationally modified peptides produced by bacteria, characterized by a remarkable mechanically-interlocked structure. The lasso topology, reminiscent to a rotaxane, consists in an N-terminal macrolactam ring threaded by a C-terminal tail. This compact and stable structure is stabilized by steric entrapping of the tail in the ring, through bulky amino acid(s) and/or disulphide bonds. Lasso peptides produced by Actinobacteria display the greatest chemical diversity and a range of biological activities (antibacterial, anti-HIV, receptor antagonistâ€¦), therefore are of high pharmaceutical interest. Genome mining revealed that Actinobacteria have enormous potential to biosynthesize novel lasso peptides, e.g. harbouring new post-translational modifications. However, the expression of these peptides is generally controlled by complex regulatory systems, making their production under laboratory conditions difficult. Understanding the ecological role and regulation mechanisms of lasso peptides would help to improve production and better exploit the biotechnological potential of these molecules. The first part of my work deals with the identification of new lasso peptides from Actinobacteria, using heterologous expression in Streptomyces hosts. The second part of my work deals with the regulation mechanism and ecological role of lasso peptides using sviceucin, a lasso peptide produced by Streptomyces sviceus, as the model for study.",2016,
"Geist, Contingency and the Future of God: Hegel and Meillassoux","This paper traces the way Quentin Meillassouxâ€™s metaphysics of the absolute and his thought on contingency and the future coming of God both follows Hegelâ€™s notion of â€˜Geist,â€™ in an unexpected manner, and creates an impasse that only a certain return to Hegelâ€™s ontoanthropology can overcome. The challenge which Hegel accepts and Meillassoux takes up is to make thinkable the possibility for the secular to bring forth absolute newness and the event of the absolute â€“ moreover, for Hegel, anthropologically, we are Geist, we are contingency, the possibility of being-otherwise incarnate",2013,
Sparse Principal Component Analysis,"Principal component analysis (PCA) is widely used in data processing and dimensionality reduction. However, PCA suffers from the fact that each principal component is a linear combination of all the original variables, thus it is often difficult to interpret the results. We introduce a new method called sparse principal component analysis (SPCA) using the lasso (elastic net) to produce modified principal components with sparse loadings. We first show that PCA can be formulated as a regression-type optimization problem; sparse loadings are then obtained by imposing the lasso (elastic net) constraint on the regression coefficients. Efficient algorithms are proposed to fit our SPCA models for both regular multivariate data and gene expression arrays. We also give a new formula to compute the total variance of modified principal components. As illustrations, SPCA is applied to real and simulated data with encouraging results.",2006,Journal of Computational and Graphical Statistics
Marine fishes from the Seychelles: 108 new records,"The following 108 species of fishes are recorded for the first time from the Seychelles: Himantura granulata, Gymnothorax breedeni, G. chilospilus, G. fimbriatus, G. melatremus, G. nudivomer, G. zonipectis, Rhinomuraena quaesita, Uropterygius macrocephalus, Kaupichthys diodontus, Synodus binotatus, S. jaculum, Trachinocephalus myops, Ophidion smithi, Carapus mourlani, Brosmophyciops pautzkei, Antennarius hispidus, Myripristis berndti, M. melanosticta, Eurypegasus draconis, Cosmocampus banneri, Dunckerocampus dactyliophorus, Hippocampus histrix, H. whitei, Inimicus filamentosus, Cephalopholis sexmaculata, Pseudanthias cooperi, P. pulcherrimus, Variola albimarginata, Cyprinocirrhites polyactis, Oxycirrhites typus, Apogon evermanni, Apogon punctatus, Fowleria abocellata,, Pseudamia tarri, Siphamia mossambica, Caranx lugubris, Lutjanus bengalensis, Pterocaesio marri, Parupeneus jansenii, P. pleurostigma, Parapriacanthus ransonneti, Pempheris schwenkii, Platax orbicularis, Centropyge acanthops, Chromis analis, C. atripectoralis, C. lepidolepis, C. xutha, Teixeirichthys jordani, Anampses lineatus, Cheilinus bimaculatus, Cirrhilabrus exquisitus, Halichoeres cosmetus, H. trispilus, Hologymnosus annulatus, Labropsis xanthonota, Macropharyngodon bipartitus, Paracheilinus mccoskeri, Pseudocoris heteroptera, Pseudojuloides argyreogaster, P. erythrops, Thalassoma genivittatum, T. quinquevittatum, Uranoscopas archionema, Limnichthys nitidus, Trichonotus marleyi, Parapercis schauinslandii, Cirripectes auritus, Enneapterygius abeli, Callionymus persicus, Synchiropus stellatus, Amblygobius tekomaji, Asterropteryx spinosus, Bathygobius cocosensis, B. crassiceps, Bryaninops natans, Callogobius sclateri, Ctenogobiops maculosus, Eviota guttata, E. sebreei, Feia nympha, Hetereleotris tentaculatus, Istigobius decoratus, Kelloggella quindecimfasciata, Lubricogobius pumilis, Paragobiodon modestus, P. xanthosoma, Pleurosicya boldinghi, P. plicata, Stonogobiops nematodes, Trimma haima, T. sheppardi, Valenciennea helsdingenii, V. puellaris, V. wardii, Nemateleotris magnifica, Acanthurus auranticavus, Ctenochaetus binotatus, Bothus mancus, Samariscus triocellatus, Pseudobalistes fuscus, Paramonacanthus nematophorus, Canthigaster smithae, C. tyleri, Torquigener flavimaculosus, Diodon liturosus, and Masturus lanceolatus.",1994,Zoologische Verhandelingen
Statistical Model to Detect Voids for Curled or Warped Concrete Pavements,"A statistical classifier was developed to interpret falling weight deflectometer data for the detection of voids under jointed concrete pavement slabs. The classifier was trained with the Seasonal Monitoring Program sections in the Long-Term Pavement Performance (LTPP) database and data from the Minnesota Road Research Facility. A two-level cross-validation process was used to assess the performance of existing void detection methods, according to a threshold of a single variable, and the least absolute shrinkage and selection operator (LASSO) classifier, which is based on several variables. Simple void detection methods based on the normalized 9,000-lb deflection were found to perform better than void detection methods based on variable deflection analysis. The LASSO classifier outperformed any of the existing void detection techniques. The LASSO classifier was validated through two field trials in Pennsylvania and an LTPP general pavement section in which significant faulting had developed.",2017,Transportation Research Record
Selection of Spatial-Temporal Lattice Models: Assessing the Impact of Climate Conditions on a Mountain Pine Beetle Outbreak,"Insects are among the most significant indicators of a changing climate. Here we evaluate the impact of temperature, precipitation, and elevation on the tree-killing ability of an eruptive species of bark beetle in pine forests of British Columbia, Canada. We consider a spatial-temporal linear regression model and in particular, a new statistical method that simultaneously performs model selection and parameter estimation. This approach is penalized maximum likelihood estimation under a spatial-temporal adaptive Lasso penalty, paired with a computationally efficient algorithm to obtain approximate penalized maximum likelihood estimates. A simulation study shows that finite-sample properties of these estimates are sound. In a case study, we apply this approach to identify the appropriate components of a general class of landscape models which features the factors that propagate an outbreak. We interpret the results from ecological perspectives and compare our method with alternative model selection procedures.",2012,"Journal of Agricultural, Biological, and Environmental Statistics"
Intraductal Placement of Non-flared Fully Covered Metallic Stent for Refractory Anastomotic Biliary Strictures After Living Donor Liver Transplantation: Long-term Results of Prospective Multicenter Trial.,"BACKGROUND
Fully covered self-expandable metallic stent (FCSEMS) may be an effective modality for managing anastomotic biliary stricture (ABS) after liver transplantation. However, stent migration and stent-induced ductal injury are main limitations. The objective of this study was to evaluate the usefulness of an unflared, intraductal FCSEMS that was designed to minimize migration and ductal injury for refractory ABS after living donor liver transplantation (LDLT).


METHODS
A total of 32 consecutive patients with symptomatic ABS after LDLT unresolved by plastic stents with or without balloon dilation at four tertiary medical centers were prospectively enrolled. A short (3 or 5 cm) FCSEMS having long lasso (10 cm) used in this study had unflared convex ends to minimize tissue hyperplasia and smaller center portion to prevent migration. The FCSEMS was placed above the papilla and removed at 3-4 months after stenting.


RESULTS
Technical and clinical success rates of intraductal placement with FCSEMS were 100% (32/32) and 81.2% (26/32), respectively. Early stent migration was observed in 5 (15.6%) patients. However, 3 patients with early stent migration had stricture resolution without needing additional intervention. Intended stent removal was successful in 27 (100%) patients (median, 101 days; range, 23-118 days). No stent-induced ductal change was observed in all patients. Stricture recurrence was observed in 11.5% (3/26) of patients during 639 days of median duration of follow-up (range, 366-2079 days).


CONCLUSIONS
Intraductal placement of an unflared short FCSEMS may be a promising option for refractory ABS after LDLT with minimal stent-induced ductal injury and stent migration.",2019,Journal of gastroenterology and hepatology
References,"1. National Kidney Foundation. K/DOQI clinical practice guidelines for chronic kidney disease: evaluation, classification, and stratification. Am J Kidney Dis 2002; 39: S1â€“266. 2. Astor BC, Matsushita K, Gansevoort RT et al. Lower estimated glomerular filtration rate and higher albuminuria are associated with mortality and end-stage renal disease. A collaborative meta-analysis of kidney disease population cohorts. Kidney Int 2011; 79: 1331â€“1340. 3. Gansevoort RT, Matsushita K, van der Velde M et al. Lower estimated GFR and higher albuminuria are associated with adverse kidney outcomes. A collaborative meta-analysis of general and high-risk population cohorts. Kidney Int 2011; 80: 93â€“104. 4. Matsushita K, van der Velde M, Astor BC et al. Association of estimated glomerular filtration rate and albuminuria with all-cause and cardiovascular mortality in general population cohorts: a collaborative metaanalysis. Lancet 2010; 375: 2073â€“2081. 5. van der Velde M, Matsushita K, Coresh J et al. Lower estimated glomerular filtration rate and higher albuminuria are associated with allcause and cardiovascular mortality. A collaborative meta-analysis of high-risk population cohorts. Kidney Int 2011; 79: 1341â€“1352. 6. Levey AS, Stevens LA, Coresh J. Conceptual model of CKD: applications and implications. Am J Kidney Dis 2009; 53: S4â€“16. 7. KDIGO AKI Work Group. KDIGO clinical practice guideline for acute kidney injury. Kidney inter., Suppl. 2012; 2: 1â€“138. 8. KDIGO GN Work Group. KDIGO clinical practice guideline for glomerulonephritis. Kidney inter., Suppl. 2012; 2: 139â€“274. 9. KDIGO CKD-MBD Work Group. KDIGO clinical practice guideline for the diagnosis, evaluation, prevention, and treatment of Chronic Kidney DiseaseMineral and Bone Disorder (CKD-MBD). Kidney Int Suppl 2009; 76(Suppl 113): S1â€“130. 10. KDIGO BP Work Group. KDIGO clinical practice guideline for the management of blood pressure in chronic kidney disease. Kidney inter., Suppl. 2012; 2: 337â€“414. 11. KDIGO Anemia Work Group. KDIGO clinical practice guideline for anemia in chronic kidney disease. Kidney inter., Suppl. 2012; 2: 279â€“335. 12. Herzog CA, Asinger RW, Berger AK et al. Cardiovascular disease in chronic kidney disease. A clinical update from Kidney Disease: Improving Global Outcomes (KDIGO). Kidney Int 2011; 80: 572â€“586. 13. Matzke GR, Aronoff GR, Atkinson AJ, Jr. et al. Drug dosing consideration in patients with acute and chronic kidney disease-a clinical update from Kidney Disease: Improving Global Outcomes (KDIGO). Kidney Int 2011; 80: 1122â€“1137. 14. Hsu CY, Ordonez JD, Chertow GM et al. The risk of acute renal failure in patients with chronic kidney disease. Kidney Int 2008; 74: 101â€“107. 15. Hailpern SM, Melamed ML, Cohen HW et al. Moderate chronic kidney disease and cognitive function in adults 20 to 59 years of age: Third National Health and Nutrition Examination Survey (NHANES III). J Am Soc Nephrol 2007; 18: 2205â€“2213. 16. James MT, Hemmelgarn BR, Wiebe N et al. Glomerular filtration rate, proteinuria, and the incidence and consequences of acute kidney injury: a cohort study. Lancet 2010; 376: 2096â€“2103. 17. James MT, Quan H, Tonelli M et al. CKD and risk of hospitalization and death with pneumonia. Am J Kidney Dis 2009; 54: 24â€“32. 18. Wilhelm-Leen ER, Hall YN, M KT et al. Frailty and chronic kidney disease: the Third National Health and Nutrition Evaluation Survey. Am J Med 2009; 122: 664â€“671 e662. 19. Levey AS, Coresh J. Chronic kidney disease. Lancet 2012; 379: 165â€“180. 20. Wesson L. Physiology of the human kidney. Grune & Stratton: New York, 1969. 21. Rowe JW, Andres R, Tobin JD. Letter: Age-adjusted standards for creatinine clearance. Ann Intern Med 1976; 84: 567â€“569. 22. Poggio ED, Rule AD, Tanchanco R et al. Demographic and clinical characteristics associated with glomerular filtration rates in living kidney donors. Kidney Int 2009; 75: 1079â€“1087. 23. Rule AD, Amer H, Cornell LD et al. The association between age and nephrosclerosis on renal biopsy among healthy adults. Ann Intern Med 2010; 152: 561â€“567. 24. Barai S, Gambhir S, Prasad N et al. Levels of GFR and protein-induced hyperfiltration in kidney donors: a single-center experience in India. Am J Kidney Dis 2008; 51: 407â€“414. 25. Eastwood JB, Kerry SM, Plange-Rhule J et al. Assessment of GFR by four methods in adults in Ashanti, Ghana: the need for an eGFR equation for lean African populations. Nephrol Dial Transplant 2010; 25: 2178â€“2187. 26. Jafar TH, Islam M, Jessani S et al. Level and determinants of kidney function in a South Asian population in Pakistan. Am J Kidney Dis 2011; 58: 764â€“772. 27. Stevens LA, Coresh J, Greene T et al. Assessing kidney functionâ€“ measured and estimated glomerular filtration rate. N Engl J Med 2006; 354: 2473â€“2483. 28. Remuzzi G, Benigni A, Remuzzi A. Mechanisms of progression and regression of renal lesions of chronic nephropathies and diabetes. J Clin Invest 2006; 116: 288â€“296. 29. KDIGO Transplant Work Group. KDIGO clinical practice guideline for the care of kidney transplant recipients. Am J Transplant 2009; 9 (Suppl 3): S1â€“155. 30. Levey AS, de Jong PE, Coresh J et al. The definition, classification, and prognosis of chronic kidney disease: a KDIGO Controversies Conference report. Kidney Int 2011; 80: 17â€“28. 31. Levey AS, Eckardt KU, Tsukamoto Y et al. Definition and classification of chronic kidney disease: a position statement from Kidney Disease: Improving Global Outcomes (KDIGO). Kidney Int 2005; 67: 2089â€“2100. 32. Eckardt KU, Berns JS, Rocco MV et al. Definition and classification of CKD: the debate should be about patient prognosisâ€“a position statement from KDOQI and KDIGO. Am J Kidney Dis 2009; 53: 915â€“920. 33. Eknoyan G. Chronic kidney disease definition and classification: no need for a rush to judgment. Kidney Int 2009; 75: 1015â€“1018. 34. El Nahas M. Cardio-Kidney-Damage: a unifying concept. Kidney Int 2010; 78: 14â€“18. 35. Levey AS, Astor BC, Stevens LA et al. Chronic kidney disease, diabetes, and hypertension: whatâ€™s in a name? Kidney Int 2010; 78: 19â€“22. 36. Winearls CG, Glassock RJ. Dissecting and refining the staging of chronic kidney disease. Kidney Int 2009; 75: 1009â€“1014. 37. Silva FG. The aging kidney: a review â€“ part I. Int Urol Nephrol 2005; 37: 185â€“205. 38. Silva FG. The aging kidney: a reviewâ€“part II. Int Urol Nephrol 2005; 37: 419â€“432. 39. Weinstein JR, Anderson S. The aging kidney: physiological changes. Adv Chronic Kidney Dis 2010; 17: 302â€“307. 40. King AJ, Levey AS. Dietary protein and renal function. J Am Soc Nephrol 1993; 3: 1723â€“1737. 41. Vehaskari VM. Orthostatic proteinuria. Arch Dis Child 1982; 57: 729â€“730. 42. Seikaly MG, Ho PL, Emmett L et al. Chronic renal insufficiency in children: the 2001 Annual Report of the NAPRTCS. Pediatr Nephrol 2003; 18: 796â€“804. 43. Hogg RJ, Furth S, Lemley KV et al. National Kidney Foundationâ€™s Kidney Disease Outcomes Quality Initiative clinical practice guidelines for chronic kidney disease in children and adolescents: evaluation, classification, and stratification. Pediatrics 2003; 111: 1416â€“1421. 44. Schwartz GJ, Brion LP, Spitzer A. The use of plasma creatinine concentration for estimating glomerular filtration rate in infants, children, and adolescents. Pediatr Clin North Am 1987; 34: 571â€“590. 45. Aperia A, Broberger O, Elinder G et al. Postnatal development of renal function in pre-term and full-term infants. Acta Paediatr Scand 1981; 70: 183â€“187. 46. Bueva A, Guignard JP. Renal function in preterm neonates. Pediatr Res 1994; 36: 572â€“577. 47. Fetterman GH, Shuplock NA, Philipp FJ et al. The Growth and Maturation of Human Glomeruli and Proximal Convolutions from Term to Adulthood: Studies by Microdissection. Pediatrics 1965; 35: 601â€“619. 48. Guignard JP, Torrado A, Da Cunha O et al. Glomerular filtration rate in the first three weeks of life. J Pediatr 1975; 87: 268â€“272. 49. Haycock GB. Development of glomerular filtration and tubular sodium reabsorption in the human fetus and newborn. Br J Urol 1998; 81 (Suppl 2): 33â€“38. 50. Gallini F, Maggio L, Romagnoli C et al. Progression of renal function in preterm neonates with gestational age o or 1â„4 32 weeks. Pediatr Nephrol 2000; 15: 119â€“124. r e f e r e n c e s http://www.kidney-international.org",2012,Kidney International Supplements
Aesopâ€™s Fables by Martin West (review),"new Books for ChILdren And Young PeoPLe charge up San Juan Hill, but itâ€™s equally clear that Roosevelt was loving every minute of the battle: â€œThe charge itself was great fun. Oh, but we had a bully fight.â€ An inventive spread wryly suggests a touch of ambivalence as outdoorsman Teddy approaches his marriage among New York gentility with both feet rooted in a Western scene, while his elbow inches across the gutter into a landscape of urban townhouses. In a clever political satire that again alludes to Rooseveltâ€™s affinity to the West, a tiny TR lassos the money-clutching fist of a Big Trust, and in a scene thatâ€™s bound to be a reader favorite, the White House is tipped on an angle as the Roosevelt kids stilt-walk and leapfrog down the hallway while a pet guinea pig sprints off the lower corner of the page. Appended timeline, quotation sources, and suggestions for further reading will certainly assist readers bent on grinding this title into book report fodder. However, considering Rooseveltâ€™s claim, â€œI donâ€™t think any President ever enjoyed himself more than I did,â€ perhaps the greatest tribute readers can offer him is to simply share his delight. (See p. 279 for publication information.) Elizabeth Bush, Reviewer",2013,Bulletin of the Center for Children's Books
Super Resolution Image Reconstruction Using Linear Regression Regularized Sparse Representation,"This thesis addresses the generation and reconstruction of the high resolution (HR) image by using the single low resolution (LR) image and the linear coalition of sparse coefficients from a suitably chosen over-complete dictionary.The study of compressive sensing shows that under vague conditions the sparse representation of a signal can be effectively recovered from the downsampled version of the original signal. By training both LR and HR image patches simultaneously by coupled dictionary learning, we are enforcing the similarity between the sparse representation(SR) of LR and HR image patch pairs with respective to their LR and HR dictionaries. Literature survey suggests that different extracted features are used to compute the coefficients to boost the prediction accuracy of the HR image patch reconstruction. A set of Gabor filters has been employed to extract useful features from the LR dictionary. As the super resolution is an ill posed problem, in this thesis we have considered it as an optimization problem for getting the sparsest representation of image patches using linear regression regularized with L1 norm, known as a LASSO in statistics.Our method is found to be outperforming the other previous state of art methods in both quantitative and qualitative analysis. The results reveal that proposed method shows promising results in reconstructing the image textures and edges.",2015,
Estimation of Sparse Dynamical Model of Neural Functional Connectivity Using Group Lasso and Laguerre Basis Functions,"This paper describes a novel method for estimating the sparse dynamical model of neural functional connectivity. This method combines the group Lasso and Laguerre expansion techniques to achieve model sparsity. It has been applied to the identification of neural functional connectivity of hippocampal CA3-CA1. Results show that the sparse model out-performs the full model estimated with the standard maximum likelihood method in terms of out-of-sample prediction accuracy. I. INTRODUCTION Modeling the functional connectivity of brain regions using spiking data is an important problem in neuroscience and neural engineering. This type of model is typically under-determined due to the large number of coefficients associated with the multiple inputs and the input-output dynamics. In order to yield reliable estimation and avoid overfitting, we have developed and applied a novel estimation method combining group Lasso and Laguerre expansion techniques.",2013,Transactions of Japanese Society for Medical and Biological Engineering
Incomplete Label Multitask Deep Learning for Spatio-temporal Event Subtype Forecasting ( Supplemental Material ) Related Work,"Spatio-temporal Event Forecasting. Most previous research in this area has focused on temporal event, in various studies on forecasting elections (Oâ€™Connor et al. 2010), stock market movements (Argyriou, Evgeniou, and Pontil 2007), disease outbreaks (Achrekar et al. 2011), and box office ticket sales (Arias, Arratia, and Xuriguera 2013). There are several existing approaches that provide true spatiotemporal resolution for predicted events. For example, Gerber et al. (Gerber 2014) utilized a logistic regression model for spatiotemporal event forecasting using topic-related tweet volumes as features, Ramakrishnan et al. (Ramakrishnan et al. 2014) built separate LASSO models for different locations to predict the occurrence of civil unrest events, and Zhao et al. (Zhao et al. 2015a) designed a new predictive model based on a topic model that jointly characterizes the temporal evolution in terms of both the semantics and geographical burstiness. However, all these focus on the occurrence only, and are not able to handle specific subtypes of future events. There are few existing reports of research on event subtype forecasting. Ning et al. (Ning et al. 2016) performs a primitive experiment in forecasting event populations, but the model proposed in this paper is designed for the distant supervised learning setting (e.g., multi-instance learning), which can not be applied directly to generic multiclass classification. Multi-task Learning. Multi-task learning (MTL) refers to models that learn multiple related tasks simultaneously to improve their generalization performance (Arias, Arratia, and Xuriguera 2013; Thrun and OSullivan 1998). For event forecasting, many MTL approaches have been proposed (Tutz 2003). For example, Evgeniou et al. (Evgeniou and Pontil 2004) proposed a regularized MTL framework that constrains all task models to be close to each other. The task relatedness can also be modeled by constraining multiple tasks to share a common underlying structure, e.g., a common set of features (Argyriou, Evgeniou, and Pontil 2007), or a common subspace (Ando and Zhang 2005). Zhao et al. (Zhao et al. 2015b) demonstrated the utility of applying a Multi-Task Learning framework for spatiotemporal event forecasting. Recent years, multi-task learning has also been well stud-",2018,
Realized Networks,"We introduce lassoâ€“type regularization for large dimensional realized covariance estimators of logâ€“prices. The procedure consists of shrinking the offâ€“diagonal entries of the inverse realized covariance matrix towards zero. This technique produces covariance estimators that are positive definite and with a sparse inverse. We name the estimator realized network, since estimating a sparse inverse realized covariance matrix is equivalent to detecting the partial correlation network structure of the daily log-prices. The large sample consistency and selection properties of the estimator are established. An application to a panel of US bluechips shows the advantages of the estimator for outâ€“ofâ€“sample GMV asset allocation.",2015,
Title Feeding behavior of the ctenophore Thalassocalyce inconstans : revision of anatomy of the order Thalassocalycida Permalink,"Behavioral observations using a remotely operated vehicle (ROV) in the Gulf of California in March, 2003, provided insights into the vertical distribution, feeding and anatomy of the rare and delicate ctenophore Thalassocalyce inconstans. Additional archived ROV video records from the Monterey Bay Aquarium Research Institute of 288 sightings of T. inconstans and 2,437 individual observations of euphausiids in the Gulf of California and Monterey Canyon between 1989 and 2005 were examined to determine ctenophore and euphausiid prey depth distributions with respect to temperature and dissolved oxygen concentration [dO]. In the Gulf of California most ctenophores (96.9%) were above 350 m, the top of the oxygen minimum layer. In Monterey Canyon the ctenophores were more widely distributed throughout the water column, including the hypoxic zone, to depths as great as 3,500 m. Computer-aided behavioral analysis of two video records of the capture of euphausiids by T. inconstans showed that the ctenophore contracted its bell almost instantly (0.5 s), transforming its Xattened, hemispherical resting shape into a closed bi-lobed globe in which seawater and prey were engulfed. Euphausiids entrapped within the globe displayed a previously undescribed escape response for krill (â€˜probing behaviorâ€™), in which they hovered and gently probed the inner surfaces of the globe with antennae without stimulating further contraction by the ctenophore. Such rapid bell contraction could be eVected only by a peripheral sphincter muscle even though the presence of circumferential ring musculature was unknown for the Phylum Ctenophora. Thereafter, several live T. inconstans were collected by hand oV Barbados and microscopic observations conWrmed",2009,
Prediction of forest unit volume based on hybrid feature selection and ensemble learning,"Aiming at the characteristics of forestry data with high dimensionality and complex samples, this paper explores an ensemble learning method suitable for predicting forest unit volume, which provides a scientific basis for forest resource management and decision-making. According to the real data provided by the National Forestry Science Data Sharing Service Platform, a FL-Stacking model based on hybrid feature selection and ensemble learning is proposed. Firstly, the model extracts features based on Filter-Lasso hybrid method, then constructs the prediction model of forest unit volume based on ensemble learning, and uses eight prediction models such as Linear SVM regression as the fusion basis model in the training set by Stacking scheme. The data are verified by 10 folds cross-validation. Finally, the fusion and optimization of the basic model are carried out. The experimental results show that the optimal accuracy of the single model is 83.81%, the multi-model predicted by FL-Stacking model is 84.55%, and the R2 value is increased by 0.74 percentage points. The comparative analysis results of different models on real data sets show that the FL-Stacking integrated prediction model proposed in this paper has a high accuracy in estimating forest unit volume, and has a great practical research value.",2020,Evolutionary Intelligence
Discrete Data Analysis with R : Visualization and Modeling Techniques for Categorical and Count Data,"This book makes a very useful contribution by focusing on graphical methods for portraying discrete data and the results of fitting models to such data. Existing books on the analysis of discrete data pay relatively little attention to graphics. This bookâ€™s main emphasis is on categorical data and logistic and loglinear models for them, but two chapters deal with count data, including dealing with the common existence of overdispersion and zero-inflation. The authors show three types of plots: Data plots, Model plots, and Data+Model plots that combine the two, showing how well the model fits the data and portraying the uncertainty of estimated response means. The book has three sections: Getting Started introduces graphical methods for categorical data, working with the data in various forms (e.g., types of contingency tables), and fitting and graphing discrete distributions with useful displays, such as â€œrootograms,â€ â€œOrd plots,â€ and â€œPoissonness plots,â€ and extensions due to Dave Hoaglin and John Tukey for other distributions. Exploratory and Hypothesis-Testing Methods presents displays and plots for two-way contingency tables, mosaic displays for multiway contingency tables, and plots such as biplots for correspondence analysis. Model-Building Methods presents plots relevant for standard models for discrete data, emphasizing logistic regression and its extensions for multinomial data, loglinear models for contingency tables, and generalized linear models for count data and their extensions. The 11 chapters each have exercises for practicing the methods and their graphic displays. As the section outline suggests, the book covers the most popular statistical methods for analyzing discrete data. Among the types of graphical displays not presented are classification trees, graphical models for conditional independence structure, and depictions of estimates for models with large numbers of predictors (such as lasso estimates as functions of a smoothing parameter). Discrete modeling methods not covered include quasi-likelihood methods, such as generalized estimating equations for marginal models with multivariate responses, generalized linear mixed models, and Bayesian inference. But I believe it was sensible for the authors to emphasize graphics for basic methods, such as contingency table analysis and ordinary logistic regression, as the book already contains an impressive amount of material and will be very useful for most discrete-data analyses conducted by applied statisticians. Also, the authors consider many nonstandard models within these general classes, such as ordinal loglinear models and specialized models for square contingency tables. Probably, the reason graphics have received relatively little attention in existing books for categorical data is because of the challenge of reducing even a bivariate association between qualitative variables to a simple graphic in which the key information is quickly clear to the eye. It is easier to do this in the context of logistic regression with quantitative explanatory variables, in which case many of the plots resemble standard ones from normal regression modeling. Examples of useful plots include influence and diagnostic plots (e.g., plotting studentized residuals against hat values, with Cookâ€™s distance values portrayed by the size of a bubble) and added-variable plots. Especially helpful for portraying practical implications of the model parameter estimates are â€œeffect plotsâ€ that portray how the probability of an outcome varies across values",2016,
TIMSS 2011 Student and Teacher Predictors for Mathematics Achievement Explored and Identified via Elastic Net,"A substantial body of research has been conducted on variables relating to students' mathematics achievement with TIMSS. However, most studies have employed conventional statistical methods, and have focused on selected few indicators instead of utilizing hundreds of variables TIMSS provides. This study aimed to find a prediction model for students' mathematics achievement using as many TIMSS student and teacher variables as possible. Elastic net, the selected machine learning technique in this study, takes advantage of both LASSO and ridge in terms of variable selection and multicollinearity, respectively. A logistic regression model was also employed to predict TIMSS 2011 Korean 4th graders' mathematics achievement. Ten-fold cross-validation with mean squared error was employed to determine the elastic net regularization parameter. Among 162 TIMSS variables explored, 12 student and 5 teacher variables were selected in the elastic net model, and the prediction accuracy, sensitivity, and specificity were 76.06, 70.23, and 80.34%, respectively. This study showed that the elastic net method can be successfully applied to educational large-scale data by selecting a subset of variables with reasonable prediction accuracy and finding new variables to predict students' mathematics achievement. Newly found variables via machine learning can shed light on the existing theories from a totally different perspective, which in turn propagates creation of a new theory or complement of existing ones. This study also examined the current scale development convention from a machine learning perspective.",2018,Frontiers in Psychology
Bridging Computational Features Toward Multiple Semantic Features with Multi-task Regression: A Study of CT Pulmonary Nodules,"The gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (CAD) performance from clinical usage. To bridge such gap, we propose to utilize the multi-task regression (MTR) scheme that leverages heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (SDAE) and convolutional neural network (CNN) as well as Haar-like features to approach 8 semantic features of lung CT nodules. We regard that there may exist relations among the semantic features of â€œspiculationâ€, â€œtextureâ€, â€œmarginâ€, etc., that can be exploited with the multi-task learning technique. The Lung Imaging Database Consortium (LIDC) data is adopted for the rich annotations, where nodules were quantitatively rated for the semantic features from many radiologists. By treating each semantic feature as a task, the MTR selects and regresses the heterogeneous computational features toward the radiologistsâ€™ ratings with 10 fold cross-validation evaluation on the randomly selected LIDC 1400 nodules. The experimental results suggest that the predicted semantic scores from MTR are closer to the radiologistsâ€™ rating than the predicted scores from single-task LASSO and elastic net regression methods. The proposed semantic scoring scheme may provide richer quantitative assessments of nodules for deeper analysis and support more sophisticated clinical content retrieval in medical databases.",2016,
Bacterial communities associated with four ctenophore genera from the German Bight (North Sea).,"Intense research has been conducted on jellyfish and ctenophores in recent years. They are increasingly recognized as key elements in the marine ecosystem that serve as critical indicators and drivers of ecosystem performance and change. However, the bacterial community associated with ctenophores is still poorly investigated. Based on automated ribosomal intergenic spacer analysis (ARISA) and 16S ribosomal RNA gene amplicon pyrosequencing, we investigated bacterial communities associated with the frequently occurring ctenophore species Mnemiopsis leidyi, Beroe sp., Bolinopsis infundibulum and Pleurobrachia pileus at Helgoland Roads in the German Bight (North Sea). We observed significant differences between the associated bacterial communities of the different ctenophore species based on ARISA patterns. With respect to bacterial taxa, all ctenophore species were dominated by Proteobacteria as revealed by pyrosequencing. Mnemiopsis leidyi and P. pileus mainly harboured Gammaproteobacteria, with Marinomonas as the dominant phylotype of M. leidyi. By contrast, Pseudoalteromonas and Psychrobacter were the most abundant Gammaproteobacteria in P. pileus. Beroe sp. was mainly dominated by Alphaproteobacteria, particularly by the genus Thalassospira. For B. infundibulum, the bacterial community was composed of Alphaproteobacteria and Gammaproteobacteria in equal parts, which consisted of the genera Thalassospira and Marinomonas. In addition, the bacterial communities associated with M. leidyi display a clear variation over time that needs further investigation. Our results indicate that the bacterial communities associated with ctenophores are highly species- specific.",2015,FEMS microbiology ecology
Tephra from the Minoan Eruption of Santorini in the Territory of Sagalassos,"The marsh of Gravgaz (N37Â°34â€™, E30Â°24â€™) is located 20km southeast of Burdur and 15 km southwest of the ancient city of Sagalassos. A few kilometres to the southeast of the marsh, the ruins (with a well-preserved circuit wall) of an unidentifi ed early Iron Age proto-urban site, part of the Hellenistic territory of Sagalassos, occupying the rock promontory of Kepez Kalesi (Vanhaverbeke and Waelkens, 2003). The marsh at an elevation of 1215 m a.s.l. forms the lowest parts of a closed basin of 10.6 km2 surrounded by limestone mountains towards the south and the west reaching altitudes of 1550 m a.s.l. The Gravgaz basin is closed and characterized by endorheic drainage feeded by springs at the base of the western limestone slopes. Because of its closed structure nearly all eroded material is preserved within the basin. The marsh has been the subject of detailed Late Holocene palaeoenvironmental research (Vermoere et al., 2000, 2002a, 2002b, 2004; Six, 2004).",2008,
An argument for the principle of maximizing expected utility,"A transformative decision rule alters the representation of a decisionproblem, either by changing the sets of acts and states taken intoconsideration, or by modifying the probability or value assignments.Examples of decision rules belonging to this class are the principleof insufficient reason, Isaac Leviâ€™s condition of E-admissibility, Luceand Raiffaâ€™s merger of states-rule, and the de minimis principle. Inthis doctoral thesis transformative decision rules are analyzed froma foundational point of view, and applied to two decision theoreticalproblems: (i) How should a rational decision maker model a decisionproblem in a formal representation (â€˜problem specificationâ€™, â€˜formaldescriptionâ€™)? (ii) What role can transformative decision rules play inthe justification of the principle of maximizing expected utility?The thesis consists of a summary and seven papers. In Papers Iand II certain foundational issues concerning transformative decisionrules are investigated, and a number of formal properties of this classof rules are proved: convergence, iterativity, and permutability. InPaper III it is argued that there is in general no unique representationof a decision problem that is strictly better than all alternative representations.In Paper IV it is shown that the principle of maximizingexpected utility can be decomposed into a sequence of transformativedecision rules. A set of axioms is proposed that together justify theprinciple of maximizing expected utility. It is shown that the suggestedaxiomatization provides a resolution of Allaisâ€™ paradox that cannot beobtained by Savage-style, nor by von Neumann and Morgenstern-styleaxiomatizations. In Paper V the axiomatization from Paper IV is furtherelaborated, and compared to the axiomatizations proposed byvon Neumann and Morgenstern, and Savage. The main results in PaperVI are two impossibility theorems for catastrophe averse decisionrules, demonstrating that given a few reasonable desiderata for suchrules, there is no rule that can fulfill the proposed desiderata. In PaperVII transformative decision rules are applied to extreme risks, i.e.to a potential outcome of an act for which the probability is low, butwhose (negative) value is high.",2008,Theoria
The Instability of Cross-Validated Lasso,"In a situation where the number of available covariates greatly exceeds the number of observations, the fitting of a regression model to explain the connection between the response and the explanatory variables can be a challenging task. The problem can be compared to a set of equations with more unknowns than there are equations and requires application of a regularisation method to result in a useful solution. There are several such methods, with different properties. This thesis focuses on one such method: the Lasso in combination with crossvalidation (CV) to determine the level of regularisation. Specifically, we consider the method when applied on survival data where the covariates are thousands of gene expression levels. The combination of Lasso and CV proves to be unstable in the sense that repeated application of the standard R implementation often give varying results. This studyâ€™s main focus is to investigate what the causes of this instability may be. Data was simulated to map the factors that affect the stability. The simulated data setsâ€™ properties are easy to control and the effects on the regularisation results are easily observed. The tests show that the CV process cause marked instability (varying results) when the division into training and test sets involve test sets with size larger than one. Moreover, the stability of the regularisation depends on the properties of the data set. A unique prediction result is preferable to easily choose a prognostic gene signature. However, a range of signatures from repeated regularisations can be utilised to indicate the accuracy of the suggested signature. This thesis maps several factors that affect the stability of Lasso and CV, and will hopefully contribute to caution be a warning flag when utilising the Lasso method to find a prognostic model.",2013,
Sound zone reproduction using loudspeaker array,"Reproduction of a desired sound field over the target region is a hot topic in the research area of the spatial audio. For the multi-zone sound field reproduction (SFR) problem, I) an improved acoustic contrast control (ACC) method using multi-point equalization is proposed to avoid the difficulty of selecting the optimal spatial reference point, II) an algorithm integrated a Least-Square (LS) criteria with ACC constraint is proposed, which tunes the balance between the acoustic contrast and the spatial average error, III) two timedomain ACC design based on response variation and differential constraints is proposed, respectively, which can avoid the causality problem and maintain a flat frequency response in the â€œbrightâ€ zone. Moreover, the issues around ensuring robust performance in SFR systems are studied. A framework for robust SFR design is proposed, which allows a physical perspective on the regularization required for a system, increases robustness of the SFR systems against perturbations, and simplifies the SFR system design. For the single-zone SFR problem, I) an time-domain SFR method using the group Lasso is proposed, which achieves an accurate SFR over the target region using a small number of activated loudspeakers, II) two kinds of block sparse models to interpolate the early part of the acoustic transfer functions (eRTF) are proposed, which can accurately interpolate the broadband eRTF by using a random array containing a small number of microphones.",2018,
Risk factor selection in rate making: EM adaptive LASSO for zero-inflated poisson regression models.,"Risk factor selection is very important in the insurance industry, which helps precise rate making and studying the features of high-quality insureds. Zero-inflated data are common in insurance, such as the claim frequency data, and zero-inflation makes the selection of risk factors quite difficult. In this article, we propose a new risk factor selection approach, EM adaptive LASSO, for a zero-inflated Poisson regression model, which combines the EM algorithm and adaptive LASSO penalty. Under some regularity conditions, we show that, with probability approaching 1, important factors are selected and the redundant factors are excluded. We investigate the finite sample performance of the proposed method through a simulation study and the analysis of car insurance data from SAS Enterprise Miner database.",2014,Risk analysis : an official publication of the Society for Risk Analysis
Model selection and parameter estimation of a multinomial logistic regression model,"In the multinomial regression model, we consider the methodology for simultaneous model selection and parameter estimation by using the shrinkage and LASSO (least absolute shrinkage and selection operation) [R. Tibshirani, Regression shrinkage and selection via the LASSO, J. R. Statist. Soc. Ser. B 58 (1996), pp. 267â€“288] strategies. The shrinkage estimators (SEs) provide significant improvement over their classical counterparts in the case where some of the predictors may or may not be active for the response of interest. The asymptotic properties of the SEs are developed using the notion of asymptotic distributional risk. We then compare the relative performance of the LASSO estimator with two SEs in terms of simulated relative efficiency. A simulation study shows that the shrinkage and LASSO estimators dominate the full model estimator. Further, both SEs perform better than the LASSO estimators when there are many inactive predictors in the model. A real-life data set is used to illustrate the suggested shrinkage and LASSO estimators.",2014,Journal of Statistical Computation and Simulation
Schelling and the Future of God,"It seems, at least largely among the worldâ€™s educated, that Nietzscheâ€™s prognosis of the death of God is coming to pass. Not only is belief in a transcendent being or a grand, supremely real being (ens realissimum) waning, but also the philosophical grounds that made such objects in any way intelligible are collapsing. In such a situation, despite the recent and quite scintillating renaissance of serious interest in Schellingâ€™s philosophy, his various discourses on the Godhead (die Gottheit) are generally ignored, perhaps with mild embarrassment. For better or worse, however, what Schelling understood by the Godhead and even by religion has little in common with prevailing theistic traditions. Schelling did not take advantage of the great ontological lacuna that opened up with the demise of dogmatism in critical philosophy after Kant to insist on an irrational belief in a God that was no longer subject to rational demonstration. Schelling eschews all dogmatic thought, but does not therefore partake in its alternative: the reduction of all thought regarding the absolute to irrational beliefs in (or rational gambles on) the existence of God and other such absolutes. As Quentin Meillassoux has shown, â€œby forbidding reason any claim to the absolute, the end of metaphysics has taken the form of an exacerbated return of the religious.â€ 1 This gives rise to the reduction of religion and antireligion to fideism. Since both theism and atheism purport to believe in a rationally unsupportable absolute position, they are both symptoms of the return of the religious. In its return, however, such religion is as vague as the opening that permits it. Shorn of rituals or specific theological commitments, we speak in murky and suggestive terms of the â€œdivine,â€ the â€œmystery,â€ etc. Schelling was not and is not a religious reactionary, demanding a return to a dogmatic God at the very moment in which we are finally done with God. Nor was he trying to sneak God back into the conversation amid the collapse of all rationally defensible knowledge of the absolute, repackaging everything as beliefs or practical postulates. In fact, as Schelling complained to Hegel in a letter",2014,
Estimation of the Endotracheal Tube Pressure Drop During HFPV: A Flow-Independent Model,"High frequency percussive ventilation (HFPV) is a non-conventional ventilatory modality which has proven very effective and safe in patients with acute respiratory failure. HFPV ventilator measures airway pressure that represents the sum of the endotracheal tube pressure drop and the tracheal pressure dissipated to inflate a lung. The estimation of the difference between the peak airway and tracheal pressure âˆ†Pp may be very useful to the clinician to avoid lung injury. The aim of this study is to provide a comprehensive solution for estimation of âˆ†Pp in adult endotracheal tubes, by developing a flow-independent model, based on endotracheal tube size, ventilator set parameters (i.e. peak pressures, pulsatile frequencies) and patientâ€™s respiratory system resistance and compliance. The model for the estimation of âˆ†Pp was determined by using the Least Absolute Shrinkage and Selection Operator (LASSO) regularized least-squares regression technique. The identified model was successively assessed on test data set.",2016,
The degrees of freedom of penalized l1 minimization,"In this paper, we investigate the degrees of freedom (df) of penalized l1 minimization (also known as the Lasso) for linear regression models. We give a closed-form expression of the degrees of freedom of the Lasso response. Namely, we show that for any given Lasso regularization parameter$ \lambda$ and any observed data y belongs to a set of full measure, the cardinal of the support of a particular solution of the Lasso problem is an unbiased estimator of the degrees of freedom of the Lasso response. This work is achieved without any assumption on the uniqueness of the Lasso solution. Thus, our result remains true for both the underdetermined and the overdetermined case studied originally in Zou et al.. We also prove that a key result in Zou et al. is not true by providing a simple counterexample. An effective estimator of the number of degrees of freedom may have several applications including an objectively guided choice of the regularization parameter in the Lasso through the SURE framework.",2011,ArXiv
Identification of Novel Genes in Human Airway Epithelial Cells associated with Chronic Obstructive Pulmonary Disease (COPD) using Machine-Based Learning Algorithms,"The aim of this project was to identify candidate novel therapeutic targets to facilitate the treatment of COPD using machine-based learning (ML) algorithms and penalized regression models. In this study, 59 healthy smokers, 53 healthy non-smokers and 21 COPD smokers (9 GOLD stage I and 12 GOLD stage II) were included (nâ€‰=â€‰133). 20,097 probes were generated from a small airway epithelium (SAE) microarray dataset obtained from these subjects previously. Subsequently, the association between gene expression levels and smoking and COPD, respectively, was assessed using: AdaBoost Classification Trees, Decision Tree, Gradient Boosting Machines, Naive Bayes, Neural Network, Random Forest, Support Vector Machine and adaptive LASSO, Elastic-Net, and Ridge logistic regression analyses. Using this methodology, we identified 44 candidate genes, 27 of these genes had been previously been reported as important factors in the pathogenesis of COPD or regulation of lung function. Here, we also identified 17 genes, which have not been previously identified to be associated with the pathogenesis of COPD or the regulation of lung function. The most significantly regulated of these genes included: PRKAR2B, GAD1, LINC00930 and SLITRK6. These novel genes may provide the basis for the future development of novel therapeutics in COPD and its associated morbidities.",2018,Scientific Reports
Cadmium and lead removal by new bacterial isolates from coal and aluminum mines,"Heavy metals such as cadmium have dangerous effects on ecosystem and human health. In this study, the bacteria diversity of soil samples of coal, salt and aluminum mines and water sample of Mareh wetland of Iran were investigated and their potential to cadmium removal was assessed. Based on partial sequencing of 16S region, the 64 isolates were identified that water sample of Mareh wetland showed high bacterial diversity. Among the isolated bacterial, 11 isolates from 10 different genus including Leifsonia sp., Rhodococcus sp., Bacillus sp., Microbacterium sp., Enterobacter sp., Planomicrobium sp., Microbacterium sp., Thalassospira sp., Brevundimonas sp., Halomonas sp. and Micrococcaceae sp. (could grow under 50Â mg/L CdCl2) were selected to consider the cadmium bioremediation potential. The Microbacterium oxydans CM3 and Rhodococcus sp. AM1 as new strains exhibited high ability to removal of cadmium and also degraded 58 and 39% of 400Â mg/L lead after 72Â h of incubation, respectively. Our result revealed that M. oxydans strain CM3 as natural way has a great potential for absorbing and degrading the heavy metal such as cadmium and lead.",2019,International Journal of Environmental Science and Technology
Management der postoperativen Pankreasfistel,"ZusammenfassungDas Auftreten einer postoperativen Pankreasfistel ist eine der wichtigsten Komplikationen nach Pankreasresektionen. Die HÃ¤ufigkeit dieser Komplikation variiert zwischen 3â€‰% nach Pankreaskopfresektionen und bis zu 35â€‰% nach distaler Pankreatektomie. Im Jahr 2005 wurde die internationale Definition der postoperativen Pankreasfistel durch die International Study Group of Pancreatic Surgery (ISGPS) standardisiert und eine Abstufung des Schweregrades von A bis C eingefÃ¼hrt. Dadurch wurden die Ergebnisse unterschiedlicher Studien vergleichbar und die davor publizierten historischen Fistelraten konnten differenziert beurteilt werden. Die vorliegende Ãœbersichtsarbeit fasst die aktuelle Literatur zu Inzidenz, Risikofaktoren, fistelassoziierten Komplikationen und Management der postoperativen Pankreasfistel zusammen.AbstractThe occurrence of a postoperative pancreatic fistula is one of the most important complications following pancreatic resections. The frequency of this complication varies between 3â€‰% after pancreatic head resection and up to 35â€‰% following distal pancreatectomy. In 2005, the international definition of postoperative pancreatic fistula was standardized according to the approach of the International Study Group of Pancreatic Surgery (ISGPS) including an Aâ€“C grading system of the severity. Consequently, results from different studies have become comparable and the historically reported fistula rates can be evaluated more critically. The present review summarises the currently available data on incidence, risk factors, fistula-associated complications and management of postoperative pancreatic fistula.",2015,Der Chirurg
Inflammatory-Related Genetic Variants in Non-Muscle-Invasive Bladder Cancer Prognosis: A Multimarker Bayesian Assessment.,"BACKGROUND
Increasing evidence points to the role of tumor immunologic environment on urothelial bladder cancer prognosis. This effect might be partly dependent on the host genetic context. We evaluated the association of SNPs in inflammation-related genes with non-muscle-invasive bladder cancer (NMIBC) risk-of-recurrence and risk-of-progression.


METHODS
We considered 822 NMIBC included in the SBC/EPICURO Study followed-up >10 years. We selected 1,679 SNPs belonging to 251 inflammatory genes. The association of SNPs with risk-of-recurrence and risk-of-progression was assessed using Cox regression single-marker (SMM) and multimarker methods (MMM) Bayes A and Bayesian LASSO. Discriminative abilities of the models were calculated using the c index and validated with bootstrap cross-validation procedures.


RESULTS
While no SNP was found to be associated with risk-of-recurrence using SMM, three SNPs in TNIP1, CD5, and JAK3 showed very strong association with posterior probabilities >90% using MMM. Regarding risk-of-progression, one SNP in CD3G was significantly associated using SMM (HR, 2.69; P = 1.55 Ã— 10(-5)) and two SNPs in MASP1 and AIRE, showed a posterior probability â‰¥80% with MMM. Validated discriminative abilities of the models without and with the SNPs were 58.4% versus 60.5% and 72.1% versus 72.8% for risk-of-recurrence and risk-of-progression, respectively.


CONCLUSIONS
Using innovative analytic approaches, we demonstrated that SNPs in inflammatory-related genes were associated with NMIBC prognosis and that they improve the discriminative ability of prognostic clinical models for NMIBC.


IMPACT
This study provides proof of concept for the joint effect of genetic variants in improving the discriminative ability of clinical prognostic models. The approach may be extended to other diseases. Cancer Epidemiol Biomarkers Prev; 25(7); 1144-50. Â©2016 AACR.",2016,"Cancer epidemiology, biomarkers & prevention : a publication of the American Association for Cancer Research, cosponsored by the American Society of Preventive Oncology"
Identifying key radiogenomic associations between DCE-MRI and micro-RNA expressions for breast cancer,"Understanding the key radiogenomic associations for breast cancer between DCE-MRI and micro-RNA expressions is the foundation for the discovery of radiomic features as biomarkers for assessing tumor progression and prognosis. We conducted a study to analyze the radiogenomic associations for breast cancer using the TCGA-TCIA data set. The core idea that tumor etiology is a function of the behavior of miRNAs is used to build the regression models. The associations based on regression are analyzed for three study outcomes: diagnosis, prognosis, and treatment. The diagnosis group consists of miRNAs associated with clinicopathologic features of breast cancer and significant aberration of expression in breast cancer patients. The prognosis group consists of miRNAs which are closely associated with tumor suppression and regulation of cell proliferation and differentiation. The treatment group consists of miRNAs that contribute significantly to the regulation of metastasis thereby having the potential to be part of therapeutic mechanisms. As a first step, important miRNA expressions were identified and their ability to classify the clinical phenotypes based on the study outcomes was evaluated using the area under the ROC curve (AUC) as a figure-of-merit. The key mapping between the selected miRNAs and radiomic features were determined using least absolute shrinkage and selection operator (LASSO) regression analysis within a two-loop leave-one-out cross-validation strategy. These key associations indicated a number of radiomic features from DCE-MRI to be potential biomarkers for the three study outcomes.",2017,
Do marine aerosols improve human health,"Throughout mankindâ€™s history, exposure to seawater and sea-air have been linked to positive human health effects. The first records of thalassotherapy date back to the ancient Egyptians, Greeks and Romans (Verhaeghe, 1843; Lucchetta et al., 2007). Epidemiological research has fairly recently started to reveal and understand these coastal health effects (Brereton et al., 2008; Wheeler et al., 2012; White et al., 2013). Several hypotheses, related to immunoregulation and physiological mechanisms, have been put forward to explain the blue space/gym effect (Rook et al., 2013; White et al., 2014). Moore (2015) suggested that part of this coastal health effect is caused by the regular exposure to natural or biogenic compounds in sea spray aerosols (SSAs). It is proposed that these compounds induce the health effect via an inhibitory activity on the phosphatidylinositol-3 kinase/protein kinase B/mechanistic target of rapamycin (PI3K/Akt/mTOR) cell signaling pathway. This is based on the fact that the augmented activity of this kinase pathway, is related to multiple pathological conditions (i.e. cancers, inflammation, diabetes, neurodegenerative diseases, and immunosuppression) (Laplante et al., 2013). 
Interesting marine bioactive compounds, potentially taking part in the suggested biogenics theory, are algal toxins. Phycotoxins are best known for the shellfish poisoning syndromes (i.e. amnesic, neurotoxic, diarrhetic and paralytic) they may cause, via contaminated seafood, during harmful algal blooms (HABs). There are, however, also a few published cases where phycotoxins like brevetoxins (Cheng et al., 2005) and ovatoxins (Ciminiello et al., 2014) have been measured in sea spray aerosols (SSAs) on Floridian and Mediterranean beaches, respectively. While these extreme cases induced temporary respiratory syndromes, aerosolised phycotoxins conventionally occur at much lower (harmless) background concentrations. One of the most interesting phycotoxins is yessotoxin (YTX). In our study, we demonstrated that YTXs have a potential positive effect at much lower concentrations as compared to effect concentration of other phycotoxins (i.e. brevetoxin, okadaic acid). 
In this part of our research, the potential positive health effects of air-borne exposure to YTXs were examined. Since the respiratory system is the first level of exposure in this scenario, in vitro experiments were performed, using human lung tissue (A549 cell line). These epithelial adenocarcinoma alveolar cells were exposed for two days to pure standards and artificially produced aerosol extracts of homoyessotoxin (hYTX), a YTX analogue. Additionally, a natural aerosol extract, collected along the surf line in Ostend, was spiked at different doses to lung cell cultures. Both the phosphorylation status of the PI3K/Akt/mTOR kinase pathway and the related effects on gene-expression level were simultaneously assessed as endpoints in the performed experiments. The effects on the kinase pathway were examined using SDS-PAGE and western blotting. The analysis of the gene-expression was performed with RNA sequencing. Together with cell viability assays, previously performed in our study, a unique effects assessment on three different levels of biological organization is possible. An additional exploratory and holistic approach of this research lies in the use of artificial and natural aerosol extracts. 
The results of this study will contribute to the mechanistic understanding of the role of biogenics in regulating the PI3K/Akt/mTOR pathway, and thus in understanding the role of SSAs in coastal health promotion. 
This research was partly supported by a VLIZ (2017) Brilliant Marine Research Idea (BMRI) grant.",2018,
Erythropoietin-induced Hypertension in Dialyzed Uremics Is Influenced by Glycosylation Patterns of the Molecule,"A91 Nephrology Dialysis Transplantation Vol. 16 n.6 2001 SERUM STEM CELL FACTOR (SCF) AND ITS SOLUBLE RECEPTOR s-KIT LEVELS IN PATIENTS WITH CHRONIC RENAL FAILURE Elsawy M.A.1, Makawy M.A.2, Abdelmaksoud S.S.2, Shahin K.Y.2 and E. Arab S.2 Department of Internal Medicine1 and Clinical Pathology2, Ain Shams University, Egypt Background; Anemia is almost an invariable presentation of chronic renal failure (CRF). Lack of erythropoietin (EPO) synthesis as well as other contributing factors as reduction of red cell life span and iron and folate deficiency. Proliferation, differentiation, and survival of erythroid progenitor cells are mainly regulated by stem cell factor (SCF) and EPO. SCF exerts its biological effects by binding to a specific receptor, the tyrosine kinase c-KIT.SCF and c-KIT play an important role in the development, differentiation, and survival of hematopoietic stem cells. Patients and methods; This study was conducted on 42 patients suffering from various degrees of renal impairment. Group A included 23 chronic renal failure (CRF) patients on regular hemodialysis and group B included 19 patients on conservative treatment. The control group included 21 healthy volunteers. Results; Serum SCF in group of A was higher than group B. However, the difference was not statistically significant. In group B, serum SCF levels correlated directly with parameters of renal function such as BUN and creatinine and correlated inversely with Hb and RBCs. s-KIT levels were significantly higher in group B than the control group. However, no significant difference was found between the former group and group A patients. Also, s-KIT levels were significantly correlated with SCF levels in group B patients. Conclusion; Serum SCF levels are increased with renal function deterioration, which suggests the possibility that the increase in SCF levels may be the result of biological response to renal anemia in patients with EPO shortage. ERYTHROPOIETIN-INDUCED HYPERTENSION IN DIALYZED UREMICS IS INFLUENCED BY GLYCOSYLATION PATTERNS OF THE MOLECULE S Milutinovic, E Milutinovic, Ã Plavljanic, V. KuÅ¡ec Dept.of Nephrology, Sveti Duh Hospital, Zagreb, Croatia. Recombinant epoetins (Epo) exhibit differences in glycosylation structures. The carbohydrates are essential for the hormonâ€™s action in vivo and appear to have an impact on the potency and pharmacokinetics of the drug. Epo omega from BHK cells contains less O-glycans and considerably more sialylated N-glycans compared to epo alfa from CHO cells. Hypertension is a common adverse event of epo treatment. In order to assess whether glycosylation patterns of Epo molecules have an impact on epoetin-induced hypertension, we performed a comparative efficacy and safety trial of epo omega vs. alfa. Sixty dialyzed severely anemic patients (54+-11yrs, mean hemoglobin (Hb) 73g/l) were randomized in two groups and treated with epo omega or alfa for 16 weeks. The initial dose was 2x 50IU/kg BW/week for 4 weeks and adjusted thereafter to achieve a stable rise in Hb of 2-3g/week. The effect of epo omega vs. alfa on blood pressure and hemoglobin was compared. Both drugs induced a profound Hb increase, the changes being significantly more prominent with epo omega. The mean Hb increased by 4.7 vs. 2.0 g/L/week on epo omega and alfa, respectivelly (p<0.05). In the same time, mean systolic blood pressure (SBP) increased in both groups but significantly more so on epo alfa (in mmHg from 152 +-3.7 to 157+-4.9 and from 151+-3.8 to 162+-3.9, ie 5 vs 11 for epo omega and alfa, respectivelly (p<0.05)). In order to compare prohypertensive and anemia correcting effects of two Epoetins, individual patientâ€˜s SBP increase was expressed per unit Hb rise. Four-times higher mean SBP normalized values were obtained for epo alfa than for omega (1.24 vs.0.29 in mmHg*L/g, p<0.03). Any Hb rise attained after epo omega was accompanied with less SBP elevation compared with epo alfa. Prohypertensive action had an early onset reaching a maximum in treatment week 1-4, whereas Hb steadily increased throughout week 2-12 implicating different mechanisms. Better Hb response on Epo omega associated with less hypertension indicated a possible direct role of sugar moieties in inducing hypertension. DOES IRON SUPPLEMENTATION AGGRAVATE OXIDATIVE STRESS IN HAEMODIALYSIS PATIENTS? 1J Mimic-Oka, 2N Dimkovic, 1K Ille,1 A Radojevic-Savic, 1T Simic 1Institute of Biochemistry, and 2Institute for Renal Diseases Zvezdara, School of Medicine Belgrade, Yugoslavia Anaemia is most often, and a very serious complication in ESRD patients on haemodialysis and it has multifactorial origin. Iron deficiency is significant pathogenic factor and its correction is very important especially before epoetin therapy. It is known that i.v. iron application in a single dose increases oxidative stress in haemodialysis (HD) patients. However, the effects of repeated i.v. iron supplementation are less studied. Therefore, in the present study, markers of oxidative stress (carbonyl reactive derivatives, CRD, thiol groups, SH), and antioxidant enzyme activities (superoxide dismutase, SOD, glutathione peroxidase, GPX and catalase, CAT) were determined in plasma and red blood cells (RBC) of ten pts given a total iron dose of 625 mg (ferrogluconat, Ferrlecit, 62.5 mg) during 10 consecutive HD. Blood samples were taken before the first and the last dose of iron. The results (meanÂ±SD) obtained in plasma were: SH CRD SOD GPX CAT mmol/L Î¼mol/g prot. U/L U/L kU/L Before Fe 0.58Â±0.21 1.05Â±0.22 96Â±28 190Â±31 36Â±14 After Fe 0.48Â±0.20 1.14Â±0.15 91Â±17 211Â±37 43Â±16 The similar results have also been found in RBC (data not shown). Iron supplementation improves haematological parameters in HD pts. The correction of anaemia was not followed by significant differences in evaluated markers of oxidative stress. Based on this data it can be concluded that iron therapy in total dose of 625 mg does not aggravate oxidative stress in HD pts. FACTORS INFLUENCING RED BLOOD CELL OSMOTIC RESISTANCE IN DIALYSIS PATIENTS D Vlassopoulos1, D Hadjiyannakos1, A Anogiatis2, A Santikou3, C Nousias1,M Sonikian1, P Papandreou2, V Hadjiconstantinou1 1Nephrology, A Fleming Hosp, 2Hematology, Pendeli Pediatric Hosp, 3Aristotelio Renal Unit, Athens Greece Low red blood cell osmotic resistance (RBCOR) of uncertain origin aggravates dialysis anemia. We attempted to identify factors that influence RBCOR in 55 stable patients dialyzed for more than 6 months (M/F: 35/ 20), including 20 diabetics. Parameters studied were hematology, biochemistry, plasma osmotic pressure (POP), dialysis strategy, age, sex, time on dialysis (TOD), EPO treatment and RBCOR. Cuprophane membranes were associated with the most abnormal RBCOR values (Cuprophane: 0.468 Â± 0.026 / Synthetic: 0.443 Â± 0.025, P=0.002). Patients with abnormal RBCOR had higher EPO needs (r=0.37, P <0.005). 95% of the diabetics had abnormal RBCOR compared to only 31.5% of the non diabetics (x2=6.05, P=0.014). RBCOR improved with TOD (r=0.39, P<0.002) and higher serum albumin levels r=0.31, P<0.02). In diabetics, RBCOR was unfavorably correlated to POP (r=0.48, P<0.03). In the non diabetic group, normal RBCOR was measured in patients on longer dialysis sessions (0.441Â±0.030) and on synthetic membranes (0.438Â±0.024) (values for healthy individuals 0.436Â±0.010). Abnormal RBCOR, increases the needs for EPO in the dialysis population. Cuprophane membranes, shorter dialysis and higher POP in diabetics adversely affect RBCOR.",2001,
Scalable fused Lasso SVM for connectome-based disease prediction,"There is substantial interest in developing machine-based methods that reliably distinguish patients from healthy controls using high dimensional correlation maps known as functional connectomes (FC's) generated from resting state fMRI. To address the dimensionality of FC's, the current body of work relies on feature selection techniques that are blind to the spatial structure of the data. In this paper, we propose to use the fused Lasso regularized support vector machine to explicitly account for the 6-D structure of the FC (defined by pairs of points in 3-D brain space). In order to solve the resulting nonsmooth and large-scale optimization problem, we introduce a novel and scalable algorithm based on the alternating direction method. Experiments on real resting state scans show that our approach can recover results that are more neuroscientifically informative than previous methods.",2014,"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Adaptive Dantzig density estimation,"This paper deals with the problem of density estimation. We aim at building an estimate of an unknown density as a linear combination of functions of a dictionary. Inspired by Candes and Tao's approach, we propose an $\ell_1$-minimization under an adaptive Dantzig constraint coming from sharp concentration inequalities. This allows to consider a wide class of dictionaries. Under local or global coherence assumptions, oracle inequalities are derived. These theoretical results are also proved to be valid for the natural Lasso estimate associated with our Dantzig procedure. Then, the issue of calibrating these procedures is studied from both theoretical and practical points of view. Finally, a numerical study shows the significant improvement obtained by our procedures when compared with other classical procedures.",2009,Annales De L Institut Henri Poincare-probabilites Et Statistiques
Roberto Calasso : deconstructing mythology : a reading of Le nozze di Cadmo e Armonia,"This thesis reviews Roberto Calassoâ€™s Le nozze di Cadmo e Armonia (1988) and 
demonstrates that thematic and formal elements of this text allow us to to cast a postmodern 
and poststructuralist light on his theorization of â€˜absolute literatureâ€™ â€“ a 
declaration of faith in the power of literature which may appear to clash with the late 
twentieth century postmodern and poststructuralist climate responsible for concepts 
such as la mort de lâ€™auteur. 
The importance of these findings lies in their going against Calassoâ€™s claim that 
he never needed to use the word â€˜postmodernâ€™ and his complete silence on 
contemporary literary criticism, as well as on most contemporary authors. 
Calassoâ€™s self-representation (interviews, criticism and the themes of the part-fictional 
work-in-progress) acknowledges as influences ancient Greek authors, both canonical 
and marginal; French decadence; the finis Austriae; Marxism; Nietzsche; Hindu 
mythology and Aby Warburg. These influences are certainly at work in Le nozze, 
however they may be employed to subvert Calassoâ€™s self-presentation. 
I have explored in detail the representations of literature emerging from Le nozze, and 
shown that they allow the identification in Calassoâ€™s texts of elements confirming his 
fascination with poststructuralism, in particular with the thought of Jacques Derrida, 
despite the complete silence on this philosopher throughout Calassoâ€™s work.",2009,
Consistent selection via the Lasso for high dimensional approximating regression models,"In this article we investigate consistency of selection in regression models via the popular Lasso method. Here we depart from the traditional linear regression assumption and consider approximations of the regression function $f$ with elements of a given dictionary of $M$ functions. The target for consistency is the index set of those functions from this dictionary that realize the most parsimonious approximation to $f$ among all linear combinations belonging to an $L_2$ ball centered at $f$ and of radius $r_{n,M}^2$. In this framework we show that a consistent estimate of this index set can be derived via $\ell_1$ penalized least squares, with a data dependent penalty and with tuning sequence $r_{n,M}>\sqrt{\log(Mn)/n}$, where $n$ is the sample size. Our results hold for any $1\leq M\leq n^{\gamma}$, for any $\gamma>0$.",2008,arXiv: Statistics Theory
Prediction of Insurance Claim Severity Loss Using Regression Models,"The objective of this work is to predict the severity loss value of an insurance claim using machine learning regression techniques. The high dimensional data used for this research work is obtained from Allstate insurance company which consists of 116 categorical and 14 continuous predictor variables. We implemented Linear regression, Random forest regression (RFR), Support vector regression (SVR) and Feed forward neural network (FFNN) for this problem. The performance and accuracy of the models are compared using mean squared error (MSE) value and coefficient of determination (Rsquare) value. We predicted the claim severity loss value with a MSE value of 0.390 and a Rsquare value 0.562 using bagged RFR model. In addition where applicable, the final loss value was also predicted with an error of 0.440 using FFNN regression model. We also demonstrate the use of lasso regularization to avoid over-fitting for some of the regression models.",2017,
Transpiration dynamics support resource partitioning in African savanna trees and grasses,"It is still far from clear whether and to what extent trees and grasses partition soil moisture in tropical savannas. A major reason for this is that we don't know how snapshot data on rooting differences translate into ecologically relevant patterns of water use at seasonal scales. We used stable isotopes in soil and stem water to quantify functional rooting profiles in grasses and two tree species in a South African savanna. Concurrently, we measured tree sap-flow velocity, grass canopy temperature (a transpiration correlate), and soil moisture content at multiple depths over the course of a growing season. We used lasso regression to identify the dominant soil moisture layers driving daily variation in tree and grass water-use metrics while controlling for weather variables. We found clear rooting depth differences between grasses (shallow) and trees (deep) from the isotopic data, and these patterns were strongly supported by the water-use data, which showed that grasses and trees predominantly respond...",2015,Ecology
The Informational Content of the Term-Spread in Forecasting the U.S. Inflation Rate: A Nonlinear Approach,"The difficulty in modelling inflation and the significance in discovering the underlying data generating process of inflation is expressed in an ample literature regarding inflation forecasting. In this paper we evaluate nonlinear machine learning and econometric methodologies in forecasting the U.S. inflation based on autoregressive and structural models of the term structure. We employ two nonlinear methodologies: the econometric Least Absolute Shrinkage and Selection Operator (LASSO) and the machine learning Support Vector Regression (SVR) method. The SVR has never been used before in inflation forecasting considering the term--spread as a regressor. In doing so, we use a long monthly dataset spanning the period 1871:1 â€“ 2015:3 that covers the entire history of inflation in the U.S. economy. For comparison reasons we also use OLS regression models as benchmark. In order to evaluate the contribution of the term-spread in inflation forecasting in different time periods, we measure the out-of-sample forecasting performance of all models using rolling window regressions. Considering various forecasting horizons, the empirical evidence suggests that the structural models do not outperform the autoregressive ones, regardless of the modelâ€™s method. Thus we conclude that the term-spread models are not more accurate than autoregressive ones in inflation forecasting.",2017,Journal of Forecasting
Simple and Efficient Multiple Kernel Learning by Group Lasso,"We consider the problem of how to improve the efficiency of Multiple Kernel Learning (MKL). In literature, MKL is often solved by an alternating approach: (1) the minimization of the kernel weights is solved by complicated techniques, such as Semi-infinite Linear Programming, Gradient Descent, or Level method; (2) the maximization of SVM dual variables can be solved by standard SVM solvers. However, the minimization step in these methods is usually dependent on its solving techniques or commercial softwares, which therefore limits the efficiency and applicability. In this paper, we formulate a closed-form solution for optimizing the kernel weights based on the equivalence between group-lasso and MKL. Although this equivalence is not our invention, our derived variant equivalence not only leads to an efficient algorithm for MKL, but also generalizes to the case for Lp-MKL (p â‰¥ 1 and denoting the Lp-norm of kernel weights). Therefore, our proposed algorithm provides a unified solution for the entire family of Lp-MKL models. Experiments on multiple data sets show the promising performance of the proposed technique compared with other competitive methods.",2010,
"Oral History Interview with Connie Douglas Reeves, February 27, 1998","Interview with Connie Douglas Reeves, named Texas Woman of the Century, from Kerrville, Texas. Mrs. Reeves talks about her life in Eagle Pass and San Antonio Texas, her education as the only female in her law school class, her career as a high school schoolteacher, and her horseback riding experience at Camp Waldemar. She describes organizing a girls' riding group, called ""The Lassos,"" with whom she performed at the World's Fair in New York in 1938 and Washington D.C. Mrs. Reeves also briefly discusses the sheep ranching she did with her husband, Jack Reeves, the flood of 1928, and the flood of 1932.",1998,
New framework that uses patterns and relations to understand terrorist behaviors,"A new framework is proposed to understand the activity patterns and relations.A new similarity function is proposed to estimate the relationships among events.The new model is proposed to estimate the importance of the features.Over-training in the model is prevented by using the LASSO regularization.The government can control the terrorist behaviors using the intelligent framework. Terrorism is a complex phenomenon with high uncertainties in user strategy. The uncertain nature of terrorism is a main challenge in the design of counter-terrorism policy. Government agencies (e.g., CIA, FBI, NSA, etc.) cannot always use social media and telecommunications to capture the intentions of terrorists because terrorists are very careful in the use of these environments to plan and prepare attacks. To address this issue, this research aims to propose a new framework by defining the useful patterns of suicide attacks to analyze the terrorist activity patterns and relations, to understand behaviors and their future moves, and finally to prevent potential terrorist attacks. In the framework, a new network model is formed, and the structure of the relations is analyzed to infer knowledge about terrorist attacks. More specifically, an Evolutionary Simulating Annealing Lasso Logistic Regression (ESALLOR) model is proposed to select key features for similarity function. Subsequently, a new weighted heterogeneous similarity function is proposed to estimate the relationships among attacks. Moreover, a graph-based outbreak detection is proposed to define hazardous places for the outbreak of violence. Experimental results demonstrate the effectiveness of our framework with high accuracy (more than 90% accuracy) for finding patterns when compared with that of actual terrorism events in 2014 and 2015. In conclusion, by using this intelligent framework, governments can understand automatically how terrorism will impact future events, and governments can control terrorists behaviors and tactics to reduce the risk of future events.",2017,Expert Syst. Appl.
Randomized comparison of bipolar versus unipolar plus bipolar recordings during segmental ostial ablation of pulmonary veins.,"INTRODUCTION
Segmental ostial ablation to isolate pulmonary veins is guided by pulmonary vein potentials. The aim of this prospective randomized study was to compare the utility of unipolar plus bipolar electrograms versus only bipolar electrograms as a guide for segmental ablation to isolate the pulmonary veins in patients with atrial fibrillation.


METHODS AND RESULTS
Isolation of the left superior, right superior, and left inferior pulmonary veins was attempted in 44 patients (35 men and 9 women; mean age 54 +/- 10 years) with paroxysmal atrial fibrillation. A decapolar Lasso catheter was positioned in the pulmonary veins, near the ostium, and a conventional ablation catheter was used for segmental ablation aimed at elimination of all pulmonary vein potentials. One hundred fourteen pulmonary veins were randomly assigned for ostial ablation guided by either bipolar or unipolar plus bipolar recordings. Electrical isolation was achieved in 51 (96%) of 53 pulmonary veins randomized to the bipolar approach, and 57 (93%) of 61 pulmonary veins randomized to the unipolar plus bipolar approach (P = 0.7). In the unipolar plus bipolar group, the total duration of radiofrequency energy needed to achieve isolation, 5.5 +/- 2.8 minutes/vein, was significant shorter than in the bipolar group, 7.6 +/- 4.1 minutes/vein (P < 0.01). Mean procedure and fluoroscopy durations per vein were 19% to 28% shorter in the unipolar plus bipolar group.


CONCLUSION
Segmental ostial ablation to isolate the pulmonary veins can be achieved more efficiently and with less radiofrequency energy when guided by both unipolar and bipolar recordings than by bipolar recordings alone.",2002,Journal of cardiovascular electrophysiology
Unsupervised neighbor dependent nonlinear unmixing,"This communication proposes an unsupervised neighbor dependent nonlinear unmixing algorithm for hyperspectral data. The proposed mixing scheme models the reflectance vector of a pixel as the sum of a linear combination of the endmem-bers plus a nonlinear function acting on neighboring spectra. The nonlinear function belongs to a reproducing kernel Hilbert space. The observations themselves are considered as the endmember candidates, and the group lasso regulariza-tion is used to enable selecting the purest pixels among the candidates. Experiments on synthetic data demonstrate the effectiveness of the proposed approach.",2016,"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Scalable sparse machine learning methods for big data,"Sparse machine learning models have become increasingly popular in analyzing high-dimensional data. With the evolving era of Big Data, ultrahigh-dimensional, large-scale data sets are constantly collected in many areas such as genetics, genomics, biomedical imaging, social media analysis, and high-frequency finance. Mining valuable information efficiently from these massive data sets requires not only novel statistical models but also advanced computational techniques. This thesis focuses on the development of scalable sparse machine learning methods to facilitate Big Data analytics. Built upon the feature screening technique, the first part of this thesis proposes a family of hybrid safe-strong rules (HSSR) that incorporate safe screening rules into the sequential strong rule to remove unnecessary computational burden for solving the lasso-type models. We present two instances of HSSR, namely SSR-Dome and SSR-BEDPP, for the standard lasso problem. We further extend SSR-BEDPP to the elastic net and group lasso problems to demonstrate the generalizability of the hybrid screening idea. In the second part, we design and implement an R package called biglasso to extend the lasso model fitting to Big Data in R. Our package biglasso utilizes memory-mapped files to store the massive data on the disk, only reading data into memory when necessary during model fitting, and is thus able to handle data-larger-than-RAM cases seamlessly. Moreover, itâ€™s built upon our redesigned algorithm incorporated with the proposed HSSR screening, making it much more memoryand computation-efficient than existing R packages. Extensive numerical experiments with synthetic and real data sets are conducted in both parts to show the effectiveness of the proposed methods. In the third part, we consider a novel statistical model, namely the overlapping group logistic regression model, that allows for selecting important groups of features",2017,
What Is Medicaid? More Than Meets the Eye.,"Medicaid is at the center of the current national policy debate. Republican proposals to partially repeal the Affordable Care Act (ACA) include substantial changes to Medicaid that could affect more than 70 million US individuals. How Medicaid works, whom it covers, and how it is funded is a complicated but critical topic. This Viewpoint summarizes the main features of the Medicaid program and how proposed legislation might affect it. Medicaid has become the nationâ€™s largest source of health insurance, covering 77 million people in 2017 (Box). Yetthisstatementbeliesthemultifacetednatureoftheprogram, which covers numerous populations with different programfeatures.OneportionofMedicaidfunctionslargely asahealthinsuranceprogramforlow-incomefamilies.Contrary to popular perception, however, not all poor US residents are eligible for the program. Prior to the passage of the ACA, coverage was available only to low-income individuals in these categories of eligibility: children, pregnant women,parents,elderlyadults,andpeoplewithdisabilities. Medicaid, along with the Childrenâ€™s Health Insurance Program(CHIP),providesnearlyuniversalcoveragetopoor children.Since1984,allchildren18yearsoryoungerinfamilies below the poverty line have been eligible for Medicaid, and since 1997 CHIP has extended eligibility to near-poor and middle-income families. Together, the programs cover nearly one-third of US children. Medicaid also includes the Early and Periodic Screening, Diagnosis, and Treatment benefit,offeringpreventivescreeningsandcomprehensive care for children with special care needs. Medicaid is also available to pregnant women with incomesnearorbelowthepovertylevel. Itpaysformorethan 40% of the nearly 4 million US births per year, although many women become uninsured when their Medicaid eligibility ends 60 days after delivery. Prior to the ACA, some low-income parents were eligible for Medicaid, but states had considerable discretion to set income cutoffs. For instance, a parent with 2 children needed to have an annual income below $4000 to qualify for Medicaid in Texas; in New York, the cutoff was approximately $27 500. Meanwhile, for adults without children or a disability, Medicaid was not available in any state without a federal waiver; accordingly, most states did not cover this population before the ACA. To close these coverage gaps, the ACA sought to broaden Medicaid eligibility to all adults with incomes up to 138% of the poverty level, regardless of eligibility category(subjecttoimmigrationrequirements).However,the Supreme Court made this expansion optional. Nineteen states chose not to expand, leaving several million lowincome adults without coverage. Medicaidâ€™sothermainroleisprovidingcomprehensive insuranceandlong-termcarecoverageforolderadultsand disabled persons. These groups qualify for Medicaid based onstate-specificincomeandassetstandardsandfunctional limitation tests. Given their extensive care needs, these groups are expensive, representing less than one-fourth of Medicaid recipients but nearly two-thirds of expenditures. Medicaid is the nationâ€™s dominant payer of long-term care services, accounting for more than half of all spending, estimated at $158 billion in 2015.3 Historically, Medicaid longterm care had a strong institutional focus because states weremandatedtocovernursinghomeservices.Overtime, substantialgrowthhasoccurredinhome-andcommunitybased services, and today more than half of Medicaid longterm care spending occurs in those settings.3 Due to age or disability, approximately 11 million Medicaid recipients also qualify for Medicare.1 For these â€œdually eligibleâ€ beneficiaries, Medicare covers their medical care, whereasMedicaidpaysforlong-termcareservicesandprovidescost-sharingassistanceforMedicareservices.Historically,carehasbeenpoorlyintegratedacrossthe2programs. UndertheACA,13statesaretestingmodelsthatalignMedicare and Medicaid financing with the goal of improving coordination of services in this population.1 For all groups, Medicaid coverage is generous in terms ofcoveredbenefits,andco-paymentsforpatientshavetraditionallybeenquitelimited,incontrasttoprivateinsurance orMedicare.However,severalstatesareproposingtoraise cost-sharing substantially for some Medicaid beneficiaries. ThecurrentdebateoverMedicaidfocuseson2primary issues. The first is the fate of the ACAâ€™s Medicaid expansion; ifreversed,stateswouldlikelyreverttothepre-ACAsystem in which most childless adults and many low-income parents did not qualify for Medicaid. The second is a more fundamental restructuring of Medicaidâ€™s financing. Currently, states administer their Medicaid programs and receive reimbursement from the federal government according to a prespecifiedformula(theâ€œmatchrateâ€).High-incomestates likeMassachusettsreceivea50%match,whereasthepoorest state (Mississippi) receives a 75% match. Certain populations, including children in CHIP, receive higher match rates, and newly eligible adults under the ACA expansion qualify for a 95% match (declining to 90% by 2020). Subject to program rules, states can receive matched funds on their Medicaid spending without limit. Republican proposals would replace this open-ended entitlementwithafixedfederalcontribution,eitherablock grant or a cap on per-person spending. Proponents argue thatthiswill leadtomorestateflexibilityandgreaterbudget certainty for the federal government, while critics contend itwill leadtomajorreductionsinbenefitsandeligibility.The CongressionalBudgetOffice(CBO)recentlyestimatedthat this proposal, combined with phasing out the ACAâ€™s expansionfunding,wouldleadtoa26%reductioninfederalMedicaid spending within the next decade and 15 million fewer beneficiaries in the program (representing the majority of the 22 million projected to lose coverage overall under the proposal).4 Inresponse,thebipartisanNationalAssociation of Medicaid Directors issued a statement that read, in part, â€œNo amount of administrative or regulatory flexibility can compensateforthefederalspendingreductionsthatwould occur as a result of this bill.â€5 VIEWPOINT",2017,JAMA
"A novel sparse system estimation method based on least squares, â„“1-norm minimization and shrinkage","In this article, a novel low-complexity block-processing sparse system estimation method, based on least squares (LS), â„“1-norm minimization and support shrinkage, is proposed. The proposed method can be seen as a counterpart for the Least Absolute Shrinkage and Selection Operator (LASSO), in the sense that the proposed method aims to find the vector that minimizes its â„“1-norm subject to a maximum arbitrary value Jmax for the LS cost function. Thus, it is suitable to be used when there is no a priori knowledge of the maximum â„“1-norm value of the system impulse response. In addition, making Jmax directly proportional to the minimum LS cost function grants the proposed method low sensitivity to wide ranges of signal to noise-plus-interference ratio. Simulation results show that the proposed method has better convergence performance than the ordinary Full-support Least Squares (LS), the Recursive Least Squares with â„“1-norm regularization (â„“1-RLS), the Relaxations and the Basis Pursuit Denoising (BPDN) estimation methods.",2015,"2015 International Conference on Computing, Networking and Communications (ICNC)"
The Third Special Issue on Advances in Mixture Models,"There is little doubt that mixture models are now established as a standard approach in manymodelling scenarios. Their ubiquity owes much to their simple, and often meaningful, interpretation and the ease with which the mixture paradigm allows models to be extended to capture heterogeneity while simultaneously providing a clustering, or classification, of units. The apparent simplicity of the EM algorithm (Dempster et al., 1977) for mixtures has also been pivotal in this development, although problems with the performance of this and its implementation have also spurred many new developments in computational approaches for fittingmixtures. CSDA is a natural home for papers related tomixturemodels and as well as a steady flow of papers in regular issues there have been two previous special issues devoted to advances in mixture models. The first of these special issues (volume 51, issue 11, 2007) contained 20 papers and in the second special issue (volume 71, issues 1â€“2, 2014) a further 19 papers appeared on very diverse methodological developments and applications. This is now continued in this third special issue, where once again we are able to present 17 papers showing the scope of the mixture model paradigm and the ingenuity of work in this area. One issue in using mixture models for clustering is that there is no guarantee that mixture components will correspond to well defined clusters. For example, in using Gaussian finite mixture models two or more mixture components may be needed to reasonably approximate the distribution within a homogeneous group of observations. Scrucca (2016) addresses this problemusing the identification of high density regions to form cluster cores and shows that this approach improves the identification of non-Gaussian clusters. Oâ€™Hagan et al. (2016) consider the same issue but bymoving away from the Gaussian distribution and its implied elliptical group structure. Using a meanâ€“variance mixture of multivariate normal distributions with an inverse Gaussian mixing distribution (MNIG) provides a more flexible family of component distributions that can be skewed and have fatter tails than the normal distribution. The range of MNIG models is extended to include various eigendecomposed covariance structures and they provide a variation on the Kolmogorovâ€“Smirnov test to assess goodness of fit. Novel applications of mixture clustering continue to provide interesting challenges. Melnykov (2016) considers clickstream data, which are the sequences of visited web-sites or categories taken by individual users. The aim is to use these data to group users according to their preferences and subsequently target themwith related items and products. The problem hasmany particular aspects and difficulties; the large number of different categories, the time element, the varying length of the sequences. The approach adopted here is to use biclustering of both categories and userswith amixture of firstorder Markov models to capture the time element. In another application of biclustering, FernÃ¡ndez et al. (2016) consider ordinal responses and use finitemixtures of the stereotypemodel (Anderson, 1984). They develop estimationmethods using the EM algorithm and consider clustering of individuals (rows), the ordinal responses (columns), and row and columns simultaneously, illustrating their approach with examples from student feedback and ecology. Functional data analysis (Ramsay and Silverman, 1997, 2002) is widely used for the study of curves and more recently surfaces, although clustering and classification has concentrated on univariate functions. Nguyen et al. (2016) combine recent techniques in spatial spline regression with finite mixture and mixed effects models to provide techniques for the fitting, clustering, and discrimination classification of surfaces and demonstrate these in the context of handwritten character recognition. Functional data analysis also features in the work of Ciarleglio and Ogden (2016) where they extend the classical finite mixture regression model to incorporate functional predictors using a wavelet-based approach. Estimation again involves an EM algorithm approach with lasso penalization for regularization and feature selection. The method is applied to diffusion tensor imaging data frommultiple sclerosis patients and is able to identify two distinct groups with differing cognitive ability.",2016,Comput. Stat. Data Anal.
Taking Model Uncertainty Seriously : Modeling Autoregressive Distributed Lags via the Bayesian Adaptive Lasso,"Persistence is a salient characteristic of dynamic political phenomena. Autoregressive distributed lags can be used to estimate persistence of dynamic relationships. However, estimation with lagged variables is complicated by uncertainty in the choice of the number of lags. This uncertainty raises the following issues: 1) restricting the number of lags a priori produces underspecification; 2) estimating a parameter-rich general model having many lags avoids underspecification, but overfits the data; 3) it is infeasible to conduct stepwise searching for the â€œbestâ€ lag structure in large-scale multivariate time series models. To resolve these issues, I develop an estimation algorithm to fit time series models via the Bayesian adaptive lasso, a machine learning-based estimator that yields penalized estimation. This algorithm penalizes â€œunimportantâ€ lagged variables and mitigates overfitting, allowing analysts to employ large-scale time series. This new tool aids in discovering persistence of dynamic relationships or lagged policy effects, which have so far been difficult to theorize or test. These benefits are illustrated by a Monte Carlo simulation analysis and two applications to real-world data. âˆ—Department of Political Science, Washington University in St. Louis, One Brookings Dr., St. Louis MO 63130, https://graduate.artsci.wustl.edu/tpark, t.park@wustl.edu.",2016,
"Hydrocarbon potential, palynology and palynofacies of four sedimentary basins in the Benue Trough, northern Cameroon","Abstract Organic geochemical, palynological and palynofacies analyses were carried out on 79 selected samples from four sedimentary basins (Mayo-Rey, Mayo-Oulo-Lere, Hamakoussou and Benue) in northern Cameroon. Rock-Eval pyrolysis and Total Organic Carbon results indicate that most of the samples of the studied basins are thermally immature to mature. The organic matter consists of terrestrial components (peat, lignite, bituminous coal, and anthracite) associated with organic matter of marine origin. Based on the appraisal of multiple parameters: Total Organic Carbon (TOC), maximum Temperature (T-max), Hydrogen Index (HI), Oxygen Index (OI) and Production Index (PI), some samples are organically rich both in oil and/or gas-prone kerogen Type-II, II/III and III. The source rock quality ranges from poor to very good. The source material is composed of both algae and higher plants. Samples from these basins yielded palynological residue composed of translucent and opaque phytoclasts, Amorphous Organic Matter (AOM), fungal remains, algal cysts pollen and pteridophyte spores. Abundance and diversity of the palynomorphs overall low and include Monoporopollenites annulatus (= Monoporites annulatus ), indeterminate periporate pollen, indeterminate tetracolporate pollen, indeterminate tricolporate pollen, indeterminate triporate pollen, indeterminate trilete spores, Polypodiaceoisporites spp., Biporipsilonites sp., Rhizophagites sp., Striadiporites sp., Botryococcus sp. (colonial, freshwater green algae), and Chomotriletes minor (cyst of zygnematalean freshwater green algae). Age assigned confidently for all these basins the palynological data except for one sample of Hamakoussou that can be dated as Early to Mid-Cretaceous in age. Callialasporites dampieri , Classopollis spp., Eucommiidites spp. and Araucariacites australis indicate, an Aptian to Cenomanian age. The other pollen and spores recovered may indicate a Tertiary or younger age (especially Monoporopollenites annulatus ), or have arisen from modern contamination. Geochemical data show that sediments are wackes, arkose, iron-sandstone and iron-shale. The Chemical Index of Alteration (CIA-K) is low moderate to high, suggesting a shorter exposure time and fast erosion and transport. The studied sequences cover various depositional settings ranging from wetlands to dry environment inside island arc, passive margin or active continental margin. This study reveals new data and the economic potential of this part of Cameroon.",2018,Journal of African Earth Sciences
A New Approach to Predict Progression-free Survival in Stage IV EGFR-mutant NSCLC Patients with EGFR-TKI Therapy.,"Purpose: We established a CT-derived approach to achieve accurate progression-free survival (PFS) prediction to EGFR tyrosine kinase inhibitors (TKI) therapy in multicenter, stage IV EGFR-mutated non-small cell lung cancer (NSCLC) patients.Experimental Design: A total of 1,032 CT-based phenotypic characteristics were extracted according to the intensity, shape, and texture of NSCLC pretherapy images. On the basis of these CT features extracted from 117 stage IV EGFR-mutant NSCLC patients, a CT-based phenotypic signature was proposed using a Cox regression model with LASSO penalty for the survival risk stratification of EGFR-TKI therapy. The signature was validated using two independent cohorts (101 and 96 patients, respectively). The benefit of EGFR-TKIs in stratified patients was then compared with another stage-IV EGFR-mutant NSCLC cohort only treated with standard chemotherapy (56 patients). Furthermore, an individualized prediction model incorporating the phenotypic signature and clinicopathologic risk characteristics was proposed for PFS prediction, and also validated by multicenter cohorts.Results: The signature consisted of 12 CT features demonstrated good accuracy for discriminating patients with rapid and slow progression to EGFR-TKI therapy in three cohorts (HR: 3.61, 3.77, and 3.67, respectively). Rapid progression patients received EGFR TKIs did not show significant difference with patients underwent chemotherapy for progression-free survival benefit (P = 0.682). Decision curve analysis revealed that the proposed model significantly improved the clinical benefit compared with the clinicopathologic-based characteristics model (P < 0.0001).Conclusions: The proposed CT-based predictive strategy can achieve individualized prediction of PFS probability to EGFR-TKI therapy in NSCLCs, which holds promise of improving the pretherapy personalized management of TKIs. Clin Cancer Res; 24(15); 3583-92. Â©2018 AACR.",2018,Clinical cancer research : an official journal of the American Association for Cancer Research
"La ""mystagogie"", : ou traitÃ© sur les symboles de la liturgie de Maxime le Confesseur (580-660). Edition, traduction, commentaire","Maxime le confesseur, moine palestinien et marque par la philosophie d'origene selon la source syriaque, a compose sans doute a carthage dans les annees 630, un traite sur les symboles de la liturgie, ou > qu'il destine a theochariste, un proche de l'eparque d'arique georges, et a l'elite chretienne hellenophone d'afrique. Il s'agit d'un traite philosophique qui suit l'ordre et la rhetorique du genre, notamment la division que nous avons decouverte en une partie theorique tripartite (l'eglise image de dieu, du monde et de l'homme) et une partie analytique (commentaire sur les actions liturgiques de l'eucharistie). Maxime pretend, dans cette tradition litteraire, s'inspirer d'un ancien, dont l'horizon conceptuel semble origenien (les 3 lieux d'incarnation du logos, l'image et ressemblance de dieu, le mystere comme enseignement). Ce veillard n'est donc pas le pseudo denys l'areopagite, a cause de la difference des themes abordes. Maxime imite parfois le style eleve de denys, il remplace le role du grand pretre de la > par celui de l'eglise, concue comme une entite agissante. Par ce changement, la symbolique de l'eglise de la premiere partie apparait comme le fondement de l'efficacite liturgique des actes decrits dans la deuxieme partie. Le point de vue adopte par l'auteur, a la difference de denys, est celui des fideles, repartis en simples fideles, pratiques et gnostiques selon une division evagrienne. L'originalite du traite de maxime reside dans la combinaison de l'eschatologie annoncee par les actions liturgiques, avec le spectacle intellectuel qu'elles permettent : telle est l'efficacite du mystere, de transformer celui qui y participe dignement a l'image (intellectuelle et eschatologique) de ce qu'il parvient a contempler. Nous presentons les 48 manuscrits de la tradition directe et nous les classons en 4 groupes, le >, le groupe de patmos (que nous avons decouvert), la nebuleuse wpc (dont nous faisons l'hypothese), une tradition ancienne italiote. Nous editons l'accord de ces deux derniers groupes. Le texte grec avec une douzaine de manuscrits cites, est debarrasse des titres qui induisaient a confusion. Nous donnons un apparat pour les textes marginaux et une traduction du texte.",2000,
Comment on â€˜Fingolimod to treat severe MS after natalizumab-associated progressive multifocal leukoencephalopathy: a valid option?â€™ Maillart et al.,"After the approval of natalizumab for relapsingâ€“remitting multiple sclerosis (MS),1â€“3 it has been extensively used, mainly as a second line therapy, with very good results.4 However, in 2005, it was voluntarily withdrawn from the market after the appearance of two cases of progressive multifocal leukoencephalopathy (PML), a rare infection of the central nervous system (CNS) caused by the John Cunningham virus (JCV), which may have fatal consequences in 20% of those affected, or lead to serious disability in 40% of survivors.5 Although natalizumab was reintroduced in 2006, its use has been limited due to the appearance of PML which has been associated with natalizumab treatment duration longer than two years, presence of antibodies against JCV, and a prior history of immunosuppression.5 Yet when natalizumab is discontinued, either due to the presence of PML signs or to a high PML risk, an immune reconstitution inflammatory syndrome (IRIS) may appear in a third of the patients, sometimes causing severe disability or even death.6 In this issue of the journal, Maillart et al. describe two cases of MS patients who withdrew from natalizumab after showing signs of PML and who, after being treated with plasmapheresis, developed IRIS. Afterwards, they started fingolimod, showing a favourable clinical and magnetic resonance imaging (MRI) evolution, from both the IRIS and the PML points of view. Three points arise with these two cases. First, despite all of the risk stratification algorithms published so far, it is not possible to predict which individual patients will develop PML. Furthermore, there is no treatment to prevent its appearance. Of note, at the last meeting of the European Neurological Societies, it was suggested that the titres of anti-JCV antibodies could be used as better markers of PML risk than just the presence of anti-JCV antibodies, especially if they had not received prior immunosuppression (IS).7 Thus, should the accuracy of the titres of antiJCV antibodies in predicting PML be confirmed, the current risk stratification algorithms â€“and therefore the decision making processesâ€“surely need to be improved. Second, it is not possible to predict which patients will develop IRIS after natalizumab withdrawal. More studies in this direction are urgently needed but some degree of IRIS seems to be desirable in order to effectively attack the virus. Finally, there are no clear guidelines as to which is the best diseasemodifying treatment after natalizumab withdrawal, especially if discontinuation occurs due to the presence of PML signs. Maillart et al. suggest that fingolimod may be a safe option. As regards the two cases described by them, both MS and PML remained stable. Along these lines, fingolimod has recently been evaluated as a post-natalizumab MS treatment within the TOFINGO trial.8 Interestingly, this showed that the earlier fingolimod started after natalizumab discontinuation, the lower the risk of IRIS was. Nonetheless, the relative immunosuppression within the CNS caused by fingolimod,9 which hypothetically could worsen a case of PML, should also make clinicians be cautious when prescribing fingolimod after natalizumab treatment. In sum, prediction and management of both natalizumab-associated PML and natalizumab withdrawalassociated IRIS are unresolved issues. In addition, treatment strategies after natalizumab withdrawal need to be investigated. Yet, as Maillart et al. suggest, fingolimod might well be an option for those patients who discontinue natalizumab in the context of PML.",2014,Multiple Sclerosis Journal
A lava attack on the recovery of sums of dense and sparse signals,"Common high-dimensional methods for prediction rely on having either a sparse signal model, a model in which most parameters are zero and there are a small number of non-zero parameters that are large in magnitude, or a dense signal model, a model with no large parameters and very many small non-zero parameters. We consider a generalization of these two basic models, termed here a â€œsparse + denseâ€ model, in which the signal is given by the sum of a sparse signal and a dense signal. Such a structure poses problems for traditional sparse estimators, such as the lasso, and for traditional dense estimation methods, such as ridge estimation. We propose a new penalization-based method, called lava, which is computationally efficient. With suitable choices of penalty parameters, the proposed method strictly dominates both lasso and ridge. We derive analytic expressions for the finite-sample risk function of the lava estimator in the Gaussian sequence model. We also provide a deviation bound for the prediction risk in the Gaussian regression model with fixed design. In both cases, we provide Stein's unbiased estimator for lava's prediction risk. A simulation example compares the performance of lava to lasso, ridge, and elastic net in a regression example using data-dependent penalty parameters and illustrates lava's improved performance relative to these benchmarks.",2015,ArXiv
Transmission Line Fault Classification Based on Dynamic State Estimation and Support Vector Machine,"The transmission line is an essential part of the power system, while the faults in the transmission line are inevitable due to a number of reasons, such as lightning, tree limps, wind, etc. This paper presents a technique to classify the short circuit faults in transmission lines, which distinguishes fault phases and fault types, such as phase A to ground fault and phase A to phase B fault. The proposed method combines the dynamic state estimation (DSE) based protection technique and Support Vector Machine (SVM) to achieve an accurate classification model with physical foundation. DSE utilizes measurement data from merging units and the model of transmission line to obtain estimated states of the line. The differences of measurements and estimated values are referred as residuals. Different fault types possess different patterns of residuals and include features that can be used in a classification scheme. Therefore, these residuals are applied to SVM to set up classification models. A feature selection method based on Lasso regression is deployed to increase the training speed for SVM. The performance of the technique is evaluated using simulation test cases. Different fault types with different fault impedance and fault locations are included in the test cases. The test results show that the classifiers are able to accurately categorize the fault types, which is very useful for protection functions.",2018,2018 North American Power Symposium (NAPS)
Collagen formation and calcification in teleost scales,"SummaryElectron microscopy of scales from the marine teleost Hippoglossoides elassodon (Pleuronectidae) indicates a morphological and functional similarity to bone and teeth in that a cellular layer apparently deposits collagen fibers which increase in diameter in extracellular locations. The collagen fibers form layers with fiber axes alternating at approximately 90Â° in the plane of the scale so that the overall structure resembles plywood. The evidence suggests that the matrix between the fibers becomes more concentrated, finally crystallizing by the deposition of material resembling hydroxyapatite located between and within the collagen fibers.",2004,Zeitschrift fÃ¼r Zellforschung und Mikroskopische Anatomie
Bayesian statistics with a smile: A resampling-sampling perspective,In this paper we develop a simulation-based approach to sequential inference in Bayesian statistics. Our resamplingâ€“sampling perspective provides draws from posterior distributions of interest by exploiting the sequential nature of Bayes theorem. Predictive inferences are a direct byproduct of our analysis as are marginal likelihoods for model assessment. We illustrate our approach in a hierarchical normal-means model and in a sequential version of Bayesian lasso. This approach provides a simple yet powerful framework for the construction of alternative posterior sampling strategies for a variety of commonly used models.,2012,Brazilian Journal of Probability and Statistics
"The Conifer Frenelopsis ramosissima (Cheirolepidiaceae) in the Lower Cretaceous of Texas: Systematic, Biogeographical, and Paleoecological Implications","Until now, our knowledge of the Lower Cretaceous conifer Frenelopsis ramosissima was based exclusively on branches from a few sites in the Potomac Group of eastern Virginia and Maryland. Affinities with the important Mesozoic family Cheirolepidiaceae have been assumed despite the historical absence of diagnostic attached or associated Classopollisâ€producing pollen cones. This plant has been reconstructed as a small, stemâ€succulent shrub that inhabited diverse, mesic plant communities. Here, we present a reconsideration of F. ramosissima based on new fossils from the Jones Ranch sauropod dinosaur quarry site (Twin Mountains Formation) near Glen Rose, Texas, which represents a ca. 2100â€km range extension for this conifer. Compelling support for assignment to the Cheirolepidiaceae is provided by the first account of associated pollen cones with in situ Classopollisâ€type pollen. Features of associated remains are consistent with this determination, including ovulate cones with persistent bracts, cone scales w...",2005,International Journal of Plant Sciences
[Addiction in Old Age].,"
 SubstanzabhÃ¤ngigkeit steigt im Alter Ã¼berproportional anâ€‚Der missbrÃ¤uchliche oder abhÃ¤ngige Konsum von Substanzen durch Ã¤ltere Menschen wird in Zukunft nicht nur in absoluten Zahlen, sondern vermutlich auch Ã¼berproportional ansteigen. Dies erfordert eine bessere einschlÃ¤gige Qualifikation der beteiligten Berufsgruppen (Ã„rzte, PflegekrÃ¤fte usw.), aber auch einen Ausbau der heute bereits unzureichenden Versorgungsstrukturen. Alkoholmissbrauch und -abhÃ¤ngigkeitâ€‚Ã„ltere Menschen unterliegen einer Vielzahl psychosozialer Risikofaktoren fÃ¼r die Entwicklung einer manifesten AlkoholabhÃ¤ngigkeit bei gleichzeitig erhÃ¶hter VulnerabilitÃ¤t fÃ¼r alkoholassoziierte FolgeschÃ¤den. Die Behandlungsprognose ist jedoch bei gegebener Therapiemotivation gut und teilweise besser als bei jÃ¼ngeren Patienten. Dies gilt vor allem, wenn sich die AbhÃ¤ngigkeit erst im hÃ¶heren Lebensalter entwickelt hat (â€žLate-Onsetâ€œ-Alkoholismus). Benzodiazepine und andere Hypnotikaâ€‚Gerade unter hochbetagten Menschen und Heimbewohnern wird eine Dauerbehandlung mit Benzodiazepinen und Benzodiazepin-Analoga (â€žZ-Drugsâ€œ) immer noch erschreckend hÃ¤ufig durchgefÃ¼hrt und dabei das hohe Risiko einer AbhÃ¤ngigkeitsentwicklung in Kauf genommen. Neuere Befunde deuten darauf hin, dass dadurch auch die Entwicklung einer Demenz begÃ¼nstigt werden kann. Eine Langzeitbehandlung sollte daher zugunsten prÃ¤ventiver AnsÃ¤tze vermieden werden. Opiateâ€‚ZuverlÃ¤ssige Zahlen Ã¼ber die HÃ¤ufigkeit von AbhÃ¤ngigkeitsentwicklungen bei Ã¤lteren, nicht onkologischen Patienten, die unter einer Dauerbehandlung mit Opioidanalgetika stehen, liegen fÃ¼r Deutschland bislang nicht vor. Angesichts neuerer Erkenntnisse sollte das Risiko einer komplexen persistierenden AbhÃ¤ngigkeit gleichwohl nicht vernachlÃ¤ssigt und die Indikation sehr sorgfÃ¤ltig gestellt werden.
",2017,Deutsche medizinische Wochenschrift
Fluctuations in the meiofauna of the Aufwuchs community in a brackish-water lagoon,"Abstract The organization of the Aufwuchs community in a brackish-water lagoon (Swanpool, Falmouth, U.K.) is described. Changes in the population densities of encrusting bryozoans and mobile meiofauna are described for a period of 3 years. Most meiofaunal species reached peak densities in the spring (Januaryâ€“March). These included tardigrades ( Macrobiotus sp.), oligochaetes ( Nais elinguis, Chaetogaster diaphanus ), the harpacticoid copepod Schizopera clandestina , ostracods, the nematodes Dichromadora geophila and Theristus spp., and possibly the nematodes Chromadorina germanica and Atrochromadora microlaima . Other meiofaunal populations peaked in summer (Julyâ€“September), and these included the chironomid Chironomus salinarius , the harpacticoid copepod Nitocra spinipes and the nematode Adoncholaimus thalassophygas . Two further species, the mite Halacarus balticus and the nematode Aphelencoides sp., showed irregular bursts in numbers. It is concluded that the spring-peaking species increased in numbers dependent upon the growth of the Aufwuchs, and particularly of the surface film of diatoms, while the summer-peaking species may have been controlled more by limiting values of salinity and temperature. These conclusions are contrasted with the general view of salinity as the over-riding factor in brackish-water ecosystems.",1986,Estuarine Coastal and Shelf Science
LASSO DEA for small and big data,"In data envelopment analysis (DEA), the curse of dimensionality problem may jeopardize the accuracy or even the relevance of results when there is a relatively large dimension of inputs and outputs, even for relatively large samples. Recently, an approach based on the least absolute shrinkage and selection operator (LASSO) for variable selection was combined with SCNLS (a special case of DEA), and dubbed as LASSO-SCNLS, as a way to circumvent the curse of dimensionality problem. In this paper, we revisit this interesting approach, by considering various data generating processes. We also explore a more advanced version of LASSO, the so-called elastic net (EN) approach, adapt it to DEA and propose the EN-DEA. Our Monte Carlo simulations provide additional and to some extent, new evidence and conclusions. In particular, we find that none of the considered approaches clearly dominate the others. To circumvent the curse of dimensionality of DEA in the context of big data with high dimensions, we also propose a simplified two-step approach which we call LASSO+DEA. We find that the proposed simplified approach could be more useful than existing more sophisticated approaches for reducing very large dimensions into sparser, more parsimonious DEA models that attain greater discriminatory power and suffer less from the curse of dimensionality.",2020,
A escritura da natureza : derrida e o materialismo experimental,"A tese procura ler a obra de Jacques Derrida para, opondo-se a interpretacao correlacionista predominante, potencializar o aspecto especulativo desse pensamento. As principais chaves de leitura sao a escritura e a dyferenca. Para tanto, traco uma articulacao poligonal entre Derrida, Quentin Meillassoux, Sigmund Freud e Catherine Malabou, buscando reconstruir as posicoes do filosofo de forma afirmativa enquanto um materialismo. O efeito desse poliedro funciona por contrastes, refletindo (como um espelho invertido) sobre outros pensadores com os quais Derrida debateu ao longo da sua vida (em especial Kant, Hegel, Levinas, Husserl e Heidegger). A figura e construida em tres movimentos: comparativo, estrutural e experimental. A comparacao emerge a partir de uma genealogia do pensamento de Derrida a partir do que nomeio materialismo frances do seculo XX, procurando demonstrar que esse pensamento nunca se orientou pelas cisoes kantianas entre coisa em si e fenomeno, natureza e humano, empirico e transcendental. Ele emerge em um especifico contexto filosofico, cientifico, politico e cultural que apenas recentemente vem sendo reconstituido. Tecido esse primeiro fio, passo ao argumento estrutural. A partir da critica da ideia de totalidade (Livro), o pensamento da escritura aparece como grafematica que nao se detem no interior do espaco no qual a escritura esteve confinada, pensando antes a escritura como forma sulcada do real, teoria nao-hilemorfica - plastica - da forma. A essa grafematica soma-se a espectrologia, ciencia do virtual que pensa o real no modo da economia geral da dyferenca. Dessa economia geral inconsistente emergem economias restritas: economimesis e economia da vida_morte. Os grafemas inscrevem-se em uma superficie sem fundo, vazia e plastica, que Derrida nomeia, lembrando Platao, khora. Finalmente, o terceiro momento procura relacionar experimentalmente o pensamento de Derrida com as ciencias contemporÃ¢neas (neurociencias e biologia evolucionista), almejando borrar as fronteiras entre natureza, cultura e tecnologia, de um lado, e pensamento e real, de outro. A escritura e os espectros atravessam todas essas cisoes em um materialismo generalizado e hiper-historico.",2013,
Error modeling for surrogates of dynamical systems using machine learning,"Summary 
A machine-learning-based framework for modeling the error introduced by surrogate models of parameterized dynamical systems is proposed. The framework entails the use of high-dimensional regression techniques (e.g., random forests, LASSO) to map a large set of inexpensively computed â€˜error indicatorsâ€™ (i.e., features) produced by the surrogate model at a given time instance to a prediction of the surrogate-model error in a quantity of interest (QoI). This eliminates the need for the user to hand-select a small number of informative features. The methodology requires a training set of parameter instances at which the time-dependent surrogate-model error is computed by simulating both the high-fidelity and surrogate models. Using these training data, the method first determines regression-model locality (via classification or clustering), and subsequently constructs a â€˜localâ€™ regression model to predict the time-instantaneous error within each identified region of feature space. We consider two uses for the resulting error model: (1) as a correction to the surrogate-model QoI prediction at each time instance, and (2) as a way to statistically model arbitrary functions of the time-dependent surrogate-model error (e.g., time-integrated errors). We apply the proposed framework to model errors in reduced-order models of nonlinear oilâ€“water subsurface flow simulations, with time-varying well-control (bottom-hole pressure) parameters. The reduced-order models used in this work entail application of trajectory piecewise linearization in conjunction with proper orthogonal decomposition. When the first use of the method is considered, numerical experiments demonstrate consistent improvement in accuracy in the time-instantaneous QoI prediction relative to the original surrogate model, across a large number of test cases. When the second use is considered, results show that the proposed method provides accurate statistical predictions of the time- and well-averaged errors. This article is protected by copyright. All rights reserved.",2017,International Journal for Numerical Methods in Engineering
Global analysis of gene expression dynamics within the marine microbialcommunity during the VAHINE mesocosm experiment in the southwest Pacific,"Microbial gene expression was followed for 23 days within a mesocosm (M1) isolating 50m(3) of seawater and in the surrounding waters in the Noumea lagoon, New Caledonia, in the southwest Pacific as part of the VAriability of vertical and tropHIc transfer of diazotroph derived N in the south wEst Pacific (VAHINE) experiment. The aim of VAHINE was to examine the fate of diazotroph-derived nitrogen (DDN) in a low-nutrient, low-chlorophyll ecosystem. On day 4 of the experiment, the mesocosm was fertilized with phosphate. In the lagoon, gene expression was dominated by the cyanobacterium Synechococcus, closely followed by Alphaproteobacteria. In contrast, drastic changes in the microbial community composition and transcriptional activity were triggered within the mesocosm within the first 4 days, with transcription bursts from different heterotrophic bacteria in rapid succession. The microbial composition and activity of the surrounding lagoon ecosystem appeared more stable, although following similar temporal trends as in M1. We detected significant gene expression from Chromerida in M1, as well as the Noumea lagoon, suggesting these photoautotrophic alveolates were present in substantial numbers in the open water. Other groups contributing substantially to the metatranscriptome were affiliated with marine Euryarchaeota Candidatus Thalassoarchaea (inside and outside) and Myoviridae bacteriophages likely infecting Synechococcus, specifically inside M1. High transcript abundances for ammonium transporters and glutamine synthetase in many different taxa (e.g., Pelagibacteraceae, Synechococcus, Prochlorococcus, and Rhodobacteraceae) was consistent with the known preference of most bacteria for this nitrogen source. In contrast, Alteromonadaceae highly expressed urease genes; Rhodobacteraceae and Prochlorococcus showed some urease expression, too. Nitrate reductase transcripts were detected on day 10 very prominently in Synechococcus and in Halomonadaceae. Alkaline phosphatase was expressed prominently only between days 12 and 23 in different organisms, suggesting that the microbial community was not limited by phosphate, even before the fertilization on day 4, whereas the post-fertilization community was. We observed high expression of the Synechococcus sqdB gene, only transiently lowered following phosphate fertilization. SqdB encodes UDP-sulfoquinovose synthase, possibly enabling marine picocyanobacteria to minimize their phosphorus requirements by substitution of phospholipids with sulphur-containing glycerolipids. This result suggests a link between sqdB expression and phosphate availability in situ. Gene expression of diazotrophic cyanobacteria was mainly attributed to Trichodesmium and Richelia intracellularis (diatom-diazotroph association) in the Noumea lagoon and initially in M1. UCYN-A (Candidatus Atelocyanobacterium) transcripts were the third most abundant and declined both inside and outside after day 4, consistent with 16S- and nifH-based analyses. Transcripts related to the Epithemia turgida endosymbiont and Cyanothece ATCC 51142 increased during the second half of the experiment.",2016,Biogeosciences
