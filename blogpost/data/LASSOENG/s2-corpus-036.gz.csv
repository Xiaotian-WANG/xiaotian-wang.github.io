title,abstract,year,journal
"United Spates Uspartmmt of the Interior Geological Volcanic Debris in Uranieerojs Sandstones, and Its Possible Bearing Os the Origin and Precipitation of Uranium*'","The possible relationships between uranium and vanadium ore deposits on the Colorado Plateau and the volcanic material which, in part, makes up the host rocks were investigated in 1951 It is suggested that the uranium and vanadium ore deposits have a complex origin and history, and that they were emplaced during the structural deformation and igneous intrusion of early Tertiary time. Volcanic debris, now altered to clay minerals, has been recognized in the Salt Wash and Brushy Basin members of the Mbrrison formation and in the Shinarump conglomerate and Chinle formation. Held studies and microscopic examination of the ores indicate a relationship between the ore minerals and montmorillonite clay formed by devitrification of volcanic glasso The vanadium hydromica formerly called ""roseoelite"" is believed, to be derived from montmorillonite 0 $ A paragenetic sequence of events, shown by examination of thin sections of the ore-bearing sandstones, begins with cementation of the sand by calcite, followed by secondary enlargement of quartz grains* The new silica formed as overgrowths on the quartz grains was probably released by devjLtrification of the glassy volcanic material. At a later date solution of quartz grains and formation of vanadium hydromica and uranium bearing minerals occurred. Deposition of the ore minerals is probably related to a change in ground water conditions brought about by igneous intrusion.",2010,
A gene signature of chemo-immunization to predict outcome in patients with triple negative breast cancer treated with neoadjuvant chemotherapy.,"575Background: In patients with triple-negative breast cancer (TNBC), the extent of tumor-infiltrating lymphocytes (TILs) in the residual disease after anthracycline-based neoadjuvant chemotherapy (NACT) is associated with a better prognosis. We aimed to develop a genomic signature from pre-treatment samples to predict the extent of TILs after NACT, and then to test its prognostic value on survival. Methods: Using 99 pre-treatment samples (training set), we generated a four-gene signature that predicts post-NACT TILs using the LASSO technique. Prognostic value of the signature on survival was assessed on the training set (n=99) and then evaluated on an independent validation set including 185 patients with TNBC treated with NACT. Results: A four-gene signature, assessed on pre-treatment samples and combining the expression levels of HLF, CXCL13, SULT1E1, and GBP1 predicted the extent of lymphocytic infiltration after NACT. In a multivariate analysis performed on the training set, a one-unit increase in th...",2017,Journal of Clinical Oncology
Assessing the performance of hospitals at Kermanshah University of Medical Sciences by Pabon Lasso Model(2006-2011),"Background: Assessment of hospital performance plays an important role in improving the quantity and quality of services. The purpose of this study was to evaluate the performance of the teaching hospitals of Kermanshah University of Medical Sciences using Pabon Lasso model during 2006-2011. Methods : This descriptive-analytical study was carried out to assess the performance of six teaching hospitals of Kermanshah University of Medical Sciences during 2006-2011 using Pabon Lasso Model. This model uses three indexes of bed occupancy rate, bed turnover rate and the average length of stay, simultaneously. The data were collected using a standardized checklist, and Excel software was used for analyzing the data and charting Pabon Lasso. Results: The results showed that one of the studied hospitals had high bed occupancy rate and low turnover rate, two hospitals had high turnover rate and low bed occupancy rate, one hospital had high bed occupancy rate and high bed turnover rate, and two hospitals had low bed turnover rate and high bed occupancy rate. Conclusion: According to this study, about 85 percent of hospitals had low performance in indexes of bed occupancy rate, bed turnover rate or both. So, the reasons for the low performance must be evaluated and analyzed. Also, based on the characteristics of the hospitals, proper strategies can be applied to improve the performance of hospitals and increase the efficiency of resources.",2014,
Emigration from Nepal: some major issues.,This study examined emigration from Nepal during 1952-91. Data were obtained from census records decennially. Records indicate that the volume of emigration amounted to about 2.39% of total population in 1952-53 and 3.58% in 1991. The level of emigration rose from 198120 persons to 658290. Emigrants are persons who were absent from their home for more than 6 months due to tourism pilgrimage business trips studies employment or permanent migration. Most emigrants return home after several months or years. A recent survey finds that 14.1% returned after more than 5 years. The Nepal model of migration is different from conventional or Marxist models. For example landlessness or near landlessness are not the primary reasons for migration. The recent emigration to Arab countries is driven by the desire for better income. Emigrants pay handsomely to go abroad for work (Rs. 85000). Nepalese emigrate to Australia and the US for a better income and a better life. The proportion of female emigrants was 6.23% of total emigrants to Arab countries and 16.2% to India. 31% of emigrants were females who emigrated to North America and 29% emigrated to European countries. Emigrants to Arab countries were likely to return home. Emigrants to North America and Europe were likely to be permanent migrants. The author prefers Mellassouxs (1981) model that says that Nepal is losing manpower during their most productive years. Remittances do not offset the loss. Government costs are incurred for supporting education abroad benefits in old age and for youth and the spread of sexually transmitted diseases.,1997,
Blossom Tree Graphical Models,"We combine the ideas behind trees and Gaussian graphical models to form a new nonparametric family of graphical models. Our approach is to attach nonparanormal ""blossoms"", with arbitrary graphs, to a collection of nonparametric trees. The tree edges are chosen to connect variables that most violate joint Gaussianity. The non-tree edges are partitioned into disjoint groups, and assigned to tree nodes using a nonparametric partial correlation statistic. A nonparanormal blossom is then ""grown"" for each group using established methods based on the graphical lasso. The result is a factorization with respect to the union of the tree branches and blossoms, defining a high-dimensional joint density that can be efficiently estimated and evaluated on test points. Theoretical properties and experiments with simulated and real data demonstrate the effectiveness of blossom trees.",2014,
Efficacy of intervention strategies for bioremediation of crude oil in marine systems and effects on indigenous hydrocarbonoclastic bacteria.,"There is little information on how different strategies for the bioremediation of marine oil spills influence the key indigenous hydrocarbon-degrading bacteria (hydrocarbonoclastic bacteria, HCB), and hence their remediation efficacy. Therefore, we have used quantitative polymerase chain reaction to analyse changes in concentrations of HCB in response to intervention strategies applied to experimental microcosms. Biostimulation with nutrients (N and P) produced no measurable increase in either biodegradation or concentration of HCB within the first 5 days, but after 15 days there was a significant increase (29%; P < 0.05) in degradation of n-alkanes, and an increase of one order of magnitude in concentration of Thalassolituus (to 10(7) cells ml(-1)). Rhamnolipid bioemulsifier additions alone had little effect on biodegradation, but, in combination with nutrient additions, provoked a significant increase: 59% (P < 0.05) more n-alkane degradation by 5 days than was achieved with nutrient additions alone. The very low Alcanivorax cell concentrations in the microcosms were hardly influenced by addition of nutrients or bioemulsifier, but strongly increased after their combined addition, reflecting the synergistic action of the two types of biostimulatory agents. Bioaugmentation with Thalassolituus positively influenced hydrocarbon degradation only during the initial 5 days and only of the n-alkane fraction. Bioaugmentation with Alcanivorax was clearly much more effective, resulting in 73% greater degradation of n-alkanes, 59% of branched alkanes, and 28% of polynuclear aromatic hydrocarbons, in the first 5 days than that obtained through nutrient addition alone (P < 0.01). Enhanced degradation due to augmentation with Alcanivorax continued throughout the 30-day period of the experiment. In addition to providing insight into the factors limiting oil biodegradation over time, and the competition and synergism between HCB, these results add weight to the use of bioaugmentation in oil pollution mitigation strategies.",2007,Environmental microbiology
Sparse methods for Alzheimerâ€™s Disease classification,"The diagnosis of Alzheimerâ€™s disease (AD) using image biomarkers establishes a complex computational challenge. The high dimensionality of this problem is a consequence of the lack of catalogued patients in the databases compared to the number of variables from the images. Nowadays, most of the decisions are still made by physicians without the support of automatic diagnosis tools. The development of a framework able to help and expedite the medical specialists decisions is the main objective of the present study. In this tool, a series of sparse methods capable of dealing with high dimensional problems were used, inducing sparsity in the models created to automatically detect a patient with AD. The two sparse methods used are both based on L1âˆ’norm regularization parameter. The Lasso method, where the voxels from PET scans are used as an input, and the Group Lasso, where the spatial information between voxels, based on brain regions, is explored. The groups of voxels used in this study were based on the Atlas Oxford-Harvard brain segmentation and alternative regions based on Gaussian Mixture Models using cognitive normal patients. The experimental results with the Lasso achieved on the ADNI database were consistent when compared with the state-of-art. Furthermore, they improved the results with the introduction of groups by the Group Lasso when the Atlas and clustered regions were used. However, regions selected manually by experts remain to obtain better accuracy results, stating the need to improve how the regions are selected.",2018,
Measurement Error in LASSO - Analytical Results and a Simulation Study,"The LASSO (Tibshirani, 1996) is a powerful method which due to the fact that is uses a l 1-penalty allows for the estimation of regression coefficients and variable selection at the same time. An important property of the LASSO is that it can be applied even when the number of covariates p is larger than the number of observations n. This differs the LASSO from the popular OLS method which requires p < n. An assumption that is common to the vast majority of studies on the LASSO is that the design matrix X passed to the LASSO for performing linear regression contains perfect covariate measurements that do not suffer from additive measurement error. However, in practice where data corrupted by measurement errors or errors-invariable data are rather the norm than the exception, this assumption does not meet the truth. In this work, we studied the LASSO in the presence of additive measurement error in the design matrix. In doing so, we allowed for analytical results on the estimation and variable selection consistency of both the LASSO with perfect design and the naive LASSO with additive covariate measurement error. We performed a Monte Carlo simulation study to assess the finite sample performance of the OLS and the LASSO under matrix uncertainty. Thereby, we also computed the corresponding corrected estimates. In particular, we used the well-known reliability ratio (Fuller, 1987) for the OLS estimates and a reliability ratio-like factor according to SÃ¸rensen et al. (2014) for the naive LASSO estimates in the presence of measurement error. In summary, we found that the MSE values of both the naive LASSO and the naive OLS increase with growing measurement error variance and covariate correlation. With respect to the corrected LASSO and OLS estimates, our results suggest that there does not exist any overall evidence of the efficacy of the applied measurement error correction factors. Especially, the MSE values of the corrected estimates tend to be larger than the ones for the naive estimators. However, we found that the empirical averages of the MSE values were inflated by a few outliers and that the occurrence of outliers was due to the bad conditioning of a matrix which contributes to the correction factor. Moreover, our simulation results suggest that the coincidence of high covariate correlation and large measurement error variance leads the LASSO to be more or less unable to differ between important and unimportant â€¦",2015,
Consensus Ensemble System for Traffic Flow Prediction,"Traffic flow prediction is a key component of an intelligent transportation system. Accurate traffic flow prediction provides a foundation for other tasks, such as signal coordination and travel time forecasting. There are many known methods in literature for the short-term traffic flow prediction problem, but their efficacy depends heavily on the traffic characteristics. It is difficult, if not impossible, to pick a single method that works well over time. In this paper, we present an automated framework to address this practical issue. Instead of selecting a single method, we combine predictions from multiple methods to generate a consensus traffic flow prediction. We propose an ensemble learning model that exploits the temporal characteristics of the data, and balances the accuracy of individual models and their mutual dependence through a covariance-regularizer. We additionally use a pruning scheme to remove anomalous individual predictions. We apply our proposed model to multi-step-ahead arterial roadway flow prediction. In tests, our method consistently outperforms recently published ensemble prediction methods based on ridge regression and lasso. Our method also produces steady results even when the standalone models and other ensemble methods make wildly exaggerated predictions.",2018,IEEE Transactions on Intelligent Transportation Systems
Opinion polarity detection in Twitter data combining shrinkage regression and topic modeling,"We propose a method to analyze public opinion about political issues online by automatically detecting polarity in Twitter data. Previous studies have focused on the polarity classification of individual tweets. However, to understand the direction of public opinion on a political issue, it is important to analyze the degree of polarity on the major topics at the center of the discussion in addition to the individual tweets. The first stage of the proposed method detects polarity in tweets using the Lasso and Ridge models of shrinkage regression. The models are beneficial in that the regression results provide sentiment scores for the terms that appear in tweets. The second stage identifies the major topics via a latent Dirichlet analysis (LDA) topic model and estimates the degree of polarity on the LDA topics using term sentiment scores. To the best of our knowledge, our study is the first to predict the polarities of public opinion on topics in this manner. We conducted an experiment on a mayoral election in Seoul, South Korea and compared the total detection accuracy of the regression models with five support vector machine (SVM) models with different numbers of input terms selected by a feature selection algorithm. The results indicated that the performance of the Ridge model was approximately 7% higher on average than that of the SVM models. Additionally, the degree of polarity on the LDA topics estimated using the proposed method was compared with actual public opinion responses. The results showed that the polarity detection accuracy of the Lasso model was 83%, indicating that the proposed method was valid in most cases.",2016,J. Informetrics
Conditions for Posterior Contraction in the Sparse Normal Means Problem,"The first Bayesian results for the sparse normal means problem were proven for spike-and-slab priors. However, these priors are less convenient from a computational point of view. In the meanwhile, a large number of continuous shrinkage priors has been proposed. Many of these shrinkage priors can be written as a scale mixture of normals, which makes them particularly easy to implement. We propose general conditions on the prior on the local variance in scale mixtures of normals, such that posterior contraction at the minimax rate is assured. The conditions require tails at least as heavy as Laplace, but not too heavy, and a large amount of mass around zero relative to the tails, more so as the sparsity increases. These conditions give some general guidelines for choosing a shrinkage prior for estimation under a nearly black sparsity assumption. We verify these conditions for the class of priors considered in [12], which includes the horseshoe and the normal-exponential gamma priors, and for the horseshoe+, the inverse-Gaussian prior, the normal-gamma prior, and the spike-and-slab Lasso, and thus extend the number of shrinkage priors which are known to lead to posterior contraction at the minimax estimation rate.",2016,Electronic Journal of Statistics
Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD): The TRIPOD Statement,"Editors' Note: In order to encourage dissemination of the TRIPOD Statement, this article is freely accessible on the Annals of Internal Medicine Web site ( www.annals.org ) and will be also published in BJOG, British Journal of Cancer, British Journal of Surgery, BMC Medicine, British Medical Journal, Circulation, Diabetic Medicine, European Journal of Clinical Investigation, European Urology, and Journal of Clinical Epidemiology. The authors jointly hold the copyright of this article. An accompanying explanation and elaboration article is freely available only at www.annals.org ; Annals of Internal Medicine holds copyright for that article. In medicine, patients with their care providers are confronted with making numerous decisions on the basis of an estimated risk or probability that a specific disease or condition is present (diagnostic setting) or a specific event will occur in the future (prognostic setting) (Figure 1). In the diagnostic setting, the probability that a particular disease is present can be used, for example, to inform the referral of patients for further testing, initiate treatment directly, or reassure patients that a serious cause for their symptoms is unlikely. In the prognostic setting, predictions can be used for planning lifestyle or therapeutic decisions based on the risk for developing a particular outcome or state of health within a specific period (1, 2). Such estimates of risk can also be used to risk-stratify participants in therapeutic clinical trials (3, 4). Figure 1. Schematic representation of diagnostic and prognostic prediction modeling studies. The nature of the prediction in diagnosis is estimating the probability that a specific outcome or disease is present (or absent) within an individual, at this point in timethat is, the moment of prediction (T= 0). In prognosis, the prediction is about whether an individual will experience a specific event or outcome within a certain time period. In other words, in diagnostic prediction the interest is in principle a cross-sectional relationship, whereas prognostic prediction involves a longitudinal relationship. Nevertheless, in diagnostic modeling studies, for logistical reasons, a time window between predictor (index test) measurement and the reference standard is often necessary. Ideally, this interval should be as short as possible and without starting any treatment within this period. In both the diagnostic and prognostic setting, estimates of probabilities are rarely based on a single predictor (5). Doctors naturally integrate several patient characteristics and symptoms (predictors, test results) to make a prediction (see Figure 2 for differences in common terminology between diagnostic and prognostic studies). Prediction is therefore inherently multivariable. Prediction models (also commonly called prognostic models, risk scores, or prediction rules [6]) are tools that combine multiple predictors by assigning relative weights to each predictor to obtain a risk or probability (1, 2). Well-known prediction models include the Framingham Risk Score (7), Ottawa Ankle Rules (8), EuroScore (9), Nottingham Prognostic Index (10), and the Simplified Acute Physiology Score (11). Figure 2. Similarities and differences between diagnostic and prognostic prediction models. Prediction Model Studies Prediction model studies can be broadly categorized as model development (12), model validation (with or without updating) (13) or a combination of both (Figure 3). Model development studies aim to derive a prediction model by selecting the relevant predictors and combining them statistically into a multivariable model. Logistic and Cox regression are most frequently used for short-term (for example, disease absent vs. present, 30-day mortality) and long-term (for example, 10-year risk) outcomes, respectively (1214). Studies may also focus on quantifying the incremental or added predictive value of a specific predictor (for example, newly discovered) to a prediction model (18). Figure 3. Types of prediction model studies covered by the TRIPOD Statement. D = development data; V = validation data. Quantifying the predictive ability of a model on the same data from which the model was developed (often referred to as apparent performance) will tend to give an optimistic estimate of performance, owing to overfitting (too few outcome events relative to the number of candidate predictors) and the use of predictor selection strategies (19). Studies developing new prediction models should therefore always include some form of internal validation to quantify any optimism in the predictive performance (for example, calibration and discrimination) of the developed model. Internal validation techniques use only the original study sample and include such methods as bootstrapping or cross-validation. Internal validation is a necessary part of model development (2). Overfitting, optimism, and miscalibration may also be addressed and accounted for during the model development by applying shrinkage (for example, heuristic or based on bootstrapping techniques) or penalization procedures (for example, ridge regression or lasso) (20). After developing a prediction model, it is strongly recommended to evaluate the performance of the model in other participant data than was used for the model development. Such external validation requires that for each individual in the new data set, outcome predictions are made using the original model (that is, the published regression formula) and compared with the observed outcomes (13, 14). External validation may use participant data collected by the same investigators, typically using the same predictor and outcome definitions and measurements, but sampled from a later period (temporal or narrow validation); by other investigators in another hospital or country, sometimes using different definitions and measurements (geographic or broad validation); in similar participants but from an intentionally different setting (for example, model developed in secondary care and assessed in similar participants but selected from primary care); or even in other types of participants (for example, model developed in adults and assessed in children, or developed for predicting fatal events and assessed for predicting nonfatal events) (13, 15, 17, 21, 22). In case of poor performance, the model can be updated or adjusted on the basis of the validation data set (13). Reporting of Multivariable Prediction Model Studies Studies developing or validating a multivariable prediction model share specific challenges for researchers (6). Several reviews have evaluated the quality of published reports that describe the development or validation prediction models (2328). For example, Mallett and colleagues (26) examined 47 reports published in 2005 presenting new prediction models in cancer. Reporting was found to be poor, with insufficient information described in all aspects of model development, from descriptions of patient data to statistical modeling methods. Collins and colleagues (24) evaluated the methodological conduct and reporting of 39 reports published before May 2011 describing the development of models to predict prevalent or incident type 2 diabetes. Reporting was also found to be generally poor, with key details on which predictors were examined, the handling and reporting of missing data, and model-building strategy often poorly described. Bouwmeester and colleagues (23) evaluated 71 reports, published in 2008 in 6 high-impact general medical journals, and likewise observed an overwhelmingly poor level of reporting. These and other reviews provide a clear picture that, across different disease areas and different journals, there is a generally poor level of reporting of prediction model studies (6, 2327, 29). Furthermore, these reviews have shown that serious deficiencies in the statistical methods, use of small data sets, inappropriate handling of missing data, and lack of validation are common (6, 2327, 29). Such deficiencies ultimately lead to prediction models that are not or should not be used. It is therefore not surprising, and fortunate, that very few prediction models, relative to the large number of models published, are widely implemented or used in clinical practice (6). Prediction models in medicine have proliferated in recent years. Health care providers and policy makers are increasingly recommending the use of prediction models within clinical practice guidelines to inform decision making at various stages in the clinical pathway (30, 31). It is a general requirement of reporting of research that other researchers can, if required, replicate all the steps taken and obtain the same results (32). It is therefore essential that key details of how a prediction model was developed and validated be clearly reported to enable synthesis and critical appraisal of all relevant information (14, 3336). Reporting Guidelines for Prediction Model Studies: The TRIPOD Statement We describe the development of the TRIPOD (Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis) Statement, a guideline specifically designed for the reporting of studies developing or validating a multivariable prediction model, whether for diagnostic or prognostic purposes. TRIPOD is not intended for multivariable modeling in etiologic studies or for studies investigating single prognostic factors (37). Furthermore, TRIPOD is also not intended for impact studies that quantify the impact of using a prediction model on participant or doctors' behavior and management, participant health outcomes, or cost-effectiveness of care, compared with not using the model (13, 38). Reporting guidelines for observational (the STrengthening the Reporting of OBservational studies in Epidemiology [STROBE]) (39), tumor marker (REporting recommendations for tumour MARKer prognostic studies [REMARK]) (37), diagnostic accuracy (STAndards f",2015,Annals of Internal Medicine
Penalized Least Squares Methods for Latent Variables Models âˆ—,"In this note, we propose a least squares method with l1 penalty (based on the â€œLassoâ€) to estimate models with latent variables. Our approach addresses the high dimensionality of these models, due to the presence of unknown distribution functions. It builds on a recent proposal by Bunea, Tsybakov, Wegkamp and Barbu (2010, Annals of Statistics) that uses penalized least squares for density estimation. We apply the method to a simple measurement error model. The extension to more general latent variables models raises a number of issues that we briefly discuss. JEL codes: C13, C14.",2010,
Verfahren zur herstellung eines drahtes aus einem ersten metall mit einer mantelschicht aus einem zweiten metall,"Verfahren zur Beschichtung eines Drahtes aus einem Metall 1 ausgewahlt aus der Gruppe bestehend aus Kupfer, Silber, Gold, Nickel sowie Legierungen eines dieser Metalle mit mindestens einem anderen Metall mit einer Mantelschicht aus einem von Metall 1 verschiedenen Metall 2 ausgewahlt aus der Gruppe bestehend aus Nickel, Silber, Gold, Ruthenium, Platin, Palladium, Rhodium sowie Legierungen eines dieser Metalle mit mindestens einem anderen Metall, umfassend die Schritte: 
(a) Bereitstellung eines Drahtes mit einer Querschnittsflache im Bereich von 75 bis 200000 Âµm 2 aus einem Metall 1, 
(b) Bereitstellung eines Behalters mit einer Einlassoffnung fur den Draht, wobei der Umriss der Einlassoffnung dem des zu ummantelnden Drahtes entspricht oder einen bis zu 20 Âµm breiten wenigstens teilweise um den Drahtumriss umlaufenden Spalt bildet, 
(c) Einfuhren des Drahtes in die Einlassoffnung, 
(d) Einfullen einer zum Aufbringen der Mantelschicht aus dem von Metall 1 verschiedenen Metall 2 geeigneten flussigen Beschichtungszusammensetzung in den Behalter, 
(e) gerades Hindurchfuhren des Drahtes durch die flussige Beschichtungszusammensetzung und den Behalter und Verlassen des Behalters in beschichteter Form, und 
(f1) Trocknen des in Schritt (e) beschichteten Drahtes oder 
(f2) thermisches Behandeln des in Schritt (e) beschichteten Drahtes, 
wobei 
(i) es sich bei der flussigen Beschichtungszusammensetzung um eine eine ausenstromlose Applikation von Metall 2 auf ein Substrat aus dem Metall 1 erlaubende Zusammensetzung handelt oder 
(ii) der Draht als Kathode geschaltet ist und es sich bei der flussigen Beschichtungszusammensetzung um eine eine Elektroplattierung mit Metall 2 eines als Kathode geschalteten Substrates aus dem Metall 1 erlaubende Zusammensetzung handelt.",2015,
Sparse Direction-of-Arrival Estimation with Directive Coprime Arrays,"This paper proposes a sparse direction of arrival (DOA) estimation method for directive coprime arrays. The complex radiation patterns are extracted using an electromagnetic simulator and then incorporated in the DOA estimation. Three DOA algorithms are compared including Capon, MUSIC, and Lasso based on compressive sensing (CS). It is shown that when the DOA increases in the elevation plane, the performance degrades faster when using real antenna patterns.",2018,2018 IEEE International Symposium on Antennas and Propagation & USNC/URSI National Radio Science Meeting
The adaptive BerHu penalty in robust regression,"We intend to combine Huber's loss with an adaptive reversed version as a penalty function. The purpose is twofold: first we would like to propose an estimator that is robust to data subject to heavy-tailed errors or outliers. Second we hope to overcome the variable selection problem in the presence of highly correlated predictors. For instance, in this framework, the adaptive least absolute shrinkage and selection operator (lasso) is not a very satisfactory variable selection method, although it is a popular technique for simultaneous estimation and variable selection. We call this new penalty the adaptive BerHu penalty. As for elastic net penalty, small coefficients contribute through their norm to this penalty while larger coefficients cause it to grow quadratically (as ridge regression). We will show that the estimator associated with Huber's loss combined with the adaptive BerHu penalty enjoys theoretical properties in the fixed design context. This approach is compared to existing regularisation methods such as adaptive elastic net and is illustrated via simulation studies and real data.",2016,Journal of Nonparametric Statistics
[Quantitative analysis of hepatocellular carcinomas pathological grading in non-contrast magnetic resonance images].,"In order to solve the pathological grading of hepatocellular carcinomas (HCC) which depends on biopsy or surgical pathology invasively, a quantitative analysis method based on radiomics signature was proposed for pathological grading of HCC in non-contrast magnetic resonance imaging (MRI) images. The MRI images were integrated to predict clinical outcomes using 328 radiomics features, quantifying tumour image intensity, shape and text, which are extracted from lesion by manual segmentation. Least absolute shrinkage and selection operator (LASSO) were used to select the most-predictive radiomics features for the pathological grading. A radiomics signature, a clinical model, and a combined model were built. The association between the radiomics signature and HCC grading was explored. This quantitative analysis method was validated in 170 consecutive patients (training dataset: n = 125; validation dataset, n = 45), and cross-validation with receiver operating characteristic (ROC) analysis was performed and the area under the ROC curve (AUC) was employed as the prediction metric. Through the proposed method, AUC was 0.909 in training dataset and 0.800 in validation dataset, respectively. Overall, the prediction performances by radiomics features showed statistically significant correlations with pathological grading. The results showed that radiomics signature was developed to be a significant predictor for HCC pathological grading, which may serve as a noninvasive complementary tool for clinical doctors in determining the prognosis and therapeutic strategy for HCC.",2019,Sheng wu yi xue gong cheng xue za zhi = Journal of biomedical engineering = Shengwu yixue gongchengxue zazhi
Central line-associated bloodstream infection and application of high resolution melting to methicillin resistant Staphylococcus aureus and Shigella sonnei genotyping,"Effective infection prevention and control hospital program is essential for prevention hospital associated infections (HAIs). Central line-associated bloodstream infection (CLABSI) is one of the major threating patients in intensive care units (ICUs). However, CLABSIs can be prevented through proper prevention measures and guidelines information resources are free available in many national and international professional health agencies. Methicillin resistant Staphylococcus aureus (MRSA) is a major bacterial agent that causing community-and-hospital associated (CA/HA) infections and related to significant morbidity and mortality rates worldwide. Shigellosis is a highly infectious disease threating public health, especially with Shigella sonnei species in developed and developing countries. These two microorganisms have ability to develop resistance to many available antimicrobial agents and consequence successfully cloned and distributed globally. In 2011, the annual risk assessment of King Abdul Aziz Specialist hospital in Taif of Saudi Arabia has reported high incidence rate of CLABSI and the characteristic susceptibility patterns of communityassociated methicillin resistant Staphylococcus aureus (CA-MRSA) infections is different from the other locality in Saudi Arabia (data not published). High-resolution melting (HRM) has been used for MRSA spa typing in clinical diagnostic laboratories for epidemiological purposes as accurate, rapid and cost effective scheme method. Rotor gene 6000-system is excellent fully equipped for real-time amplification for HRMA. It is possible to introduce a hypothesis of HRM is accrete and rapid of MRSA spa-typing and S. sonnei genotyping method for epidemiological purposes. The hospital CLABSI prevention project was analyzed and extended to assess the susceptibility pattern, genotyping and virulence gene detection of MRSA infections in Saudi Arabia. Also, we tested the hypothesis of HRM genotyping by evaluating HRM of MRSA spa typing and identification of S. sonnei lineages and sub lineages using Rotor gene 6000-system among globally collected samples. There was about 60% reduction of CLABSIs after implementation of Society for Healthcare Epidemiology of America/Infectious Diseases Society of America (SHEA/IDSA) practice guidelines. HRM can distinguishable identification of MRSA spa types as well as S. sonnei lineages and sub lineages. Most of MRSA spa types were unambiguously typed. All S. sonnei lineages and sub lineages were identified using HRM real-time PCR. Also, the reproducibility was assessed and results revealed the same. We observed high prevalence of panton valentine leukocidine (PVL) positive related to hospital associated MRSA infections (HA-MRSA) is Saudi Arabia. The basic SHEA/IDSA practice recommendation is an effective prevention model for the reduction of CLABSI in the ICU. HRM-based is reproducible, simple, rapid and cost-effective for spa-typing and S. sonnei genotyping method. Emerging multi drug resistance S. aureus strains with PVL gene circulating within hospitals alarms the urgent need for continuous active surveillance and implementation prevention measures. LIST OF SCIENTIFIC PAPERS I. Waleed Mazi, Zikra Begum, Diaa Abdullah, Ahmed Hesham, Sami Maghari, Abdullah Assiri and Abiola Senok. Central line-associated bloodstream infection in a trauma intensive care unit: Impact of implementation of Society for Healthcare Epidemiology of America/Infectious Diseases Society of America practice guidelines. American Journal of Infection Control, 2014; 42:865-7. II. Waleed Mazi, Jun Yu, Gunnar SandstrÃ¶m and Amir Saeed. Emerging PVLpositive and multidrug-resistant Staphylococcus aureus in hospitalassociated infections in Taif, Saudi Arabia. (Manuscript). III. Waleed Mazi, Vartul Sangal, Gunnar SandstrÃ¶m, Amir Saeed and Jun Yu. Evaluation of spa-typing of methicillinâ€“resistant Staphylococcus aureus using high-resolution melting analysis. International Journal of Infectious Diseases, 2015; 38: 125-8. IV. Waleed Mazi, Vartul Sangal, Amir Saeed, Gunnar SandstrÃ¶m, FrancoisXavier Weill and Jun Yu. Rapid genotyping of Shigella sonnei by use of multiplex high-resolution melting. Journal of Clinical Microbiology, 2015; 53:2389-1. CONTENTS ABSTRACT .......................................................................................................................... 1",2016,
Quantitative Inferences from the Lung Microbiome,"Within the last decade, we have progressed from the belief that the healthy human lung is a sterile environment to attempts to study inter-kingdom interactions between microbial residents of the lungs. It has been repeatedly confirmed that the lungs contain both bacteria, predominantly from the Streptococcus, Veillonella, and Prevotella genera, and fungi, predominantly from the Cladosporium, Eurotium, Penicillium, and Aspergillus genera. The community composition as a whole undergoes shifts in every lung disease and condition that has been studied, including asthma, chronic obstructive pulmonary disorder, and cystic fibrosis. The studies that have observed these shifts have largely been descriptive, comparing the taxonomies present in healthy lungs to taxonomies in diseased lungs. Here we investigated the lung microbiome and relationships within the microbial community and between microbes and the host in a more quantitative and inferential manner. First, we introduced the lasso-penalized generalized linear mixed model (LassoGLMM) for microbiomes. LassoGLMM was applied to a short time-course study of the human oral bacterial microbiome with standard blood chemical measurements and to repeated measurements of the human lung bacterial microbiome and fungal mycobiome with local and systemic markers of inflammation. We sought to show that increased inflammation and other continuous clinical variables in human hosts are associated with distinct microbes present in the lung or oral microbiomes. Then, we examined cross-domain interactions between bacteria and fungi. Ecological interaction networks were inferred for the human lung and skin micro- and myco-biomes. Networks limited to a single domain of life were compared with those that include both bacteria and fungi to identify important components of the microbial community that would be overlooked in a single domain study. Finally, we explored the metabolism of the bacteria within the human lung using three different â€œ-omicsâ€ datasets: taxonomic assignments from 16S rRNA gene sequences, gene families from metatranscriptomic sequences, and mass-to-charge ratio (m/z) features from metabolomics. Correlations were examined between pairs of datasets and all three datasets were integrated to identify bacteria contributing metabolic processes that may have otherwise gone unnoticed, resulting in the first complete characterization of the metabolism of the human lung bacterial microbiome.",2017,
"On the larval genus Problemacaris Stebbing, and its probable identity (Crustacea, Decapoda)","INTRODUCTION After the manuscript of my paper on Problemacaris (Gordon, 1960), had gone to press, Dr. R. B. Pike sent me notes and drawings of a larva that had been obtained by the ""Sarsia"" on 14 November 1957 and which he and Dr. D. I. Williamson had examined. When I told these two zoologists that this larva was apparently an older stage of one that I had just described, they decided not to proceed any further with their joint paper, and sent the larva for inclusion in the British Museum Collection. However, Dr. Williamson and I did have some correspondence relating to the possible identity of the larva and we thought we had got a clue to the real adult. But it was hoped that an older larva might be found which could be quite conclusive, and I only added a note to some of the reprints of my paper that I sent to individuals likely to be interested in the question. Then on December 12, 1962 Dr. Vagn Hansen of Copenhagen came to see me and informed me that Problemacaris larvae were moderately common and that he had seen specimens from as far afield as New Zealand. He also assured me that the larva has the curious habit of constructing ""nests"" from a radiolarian belonging to the family Thalassothamnidae (cf. Haecker, 1908). I told him what I thought was the probable adult genus to which this larval genus was referable, and asked him if he had seen an older stage than the ""Sarsia"" larva. He promised to send me the specimens that he had for study. However, he had to go to New Delhi; when he returned to Denmark on a rather brief visit, he looked out ten tubes of supposed larvae. But, when I came to examine these tubes, I found that only six of them had each a Problemacaris larva. Another tube had what may be a ""nest"" but",1964,Zoologische Mededelingen
The Phylogeny and Classification of the Pseudoscorpionida (Chelicerata : Arachnida),"A new pseudoscorpion classification is proposed with two new suborders, Epiocheirata and Iocheirata, based upon a cladistic analysis of relationships within the order. The Epiocheirata contains two super- families: Chthonioidea for Chthoniidae, Tridenchthoniidae and Lechytiidae, stat. nov. (for Lechytia), and Feaelloidea for Feaellidae and Pseudogarypidae. The Iocheirata is divided into two infraorders: Hemictenata Balzan and Panctenata Balzan. The Hemictenata contains a single superfamily, Neobisioidea for Bochicidae, Gymnobisiidae, Hyidae, Ideoroncidae, Neobisiidae, Parahyidae, fam. nov. (for Parahya) and Syarinidae. The Panctenata contains two microorders: Mestommatina, nov, with Garypoidea for Cheiridiidae, Garypidae, Geogarypidae, Larcidae, fam. nov. (for Archeolarca and Larca) and Pseudochiridiidae, and Olpioidea for Menthidae and Olpiidae; and Elassommatina, nov. with Sternophoroidea, stat. nov, for Sternophoridae, and Cheliferoidea for Atemnidae, Cheliferidae, Chernetidae and Withiidae. The Vachoniidae is synonymised with the Bochicidae, and the Cheiridioidea is treated as a synonym of Garypoidea. Philomaoria Chamberlin and Philomaoriini are transferred from the Withiidae to the Cheliferidae. The chthoniid tribe Pseudotyrannochthoniini is elevated to subfamily rank, and the systematic position of the Devonian family Dracochelidae is discussed.",1992,Invertebrate Systematics
Quantum theory of measurement without wave packet collapse,"SummaryA schematization of the measurement process in quantum mechanics is presented leading to a unified treatment both of measurements performed by means of polarized counters and of measurements made with Stern-Gerlach-like set-ups. In this way it is shown that the so-called wave packet collapse is not an absolute postulate which should be added from outside to the laws of quantum mechanics, but rather a consequence â€”though not an exact one but valid to a very high degree of accuracyâ€” of these laws. The limits of the deviations from exact collapse are expressed explicitly in terms of quantities related to the macroscopic character of the experimental device. The relationship between irreversibility and this (pseudo) collapse is discussed and shown to arise from their common origin represented by the large numbers implied in this macroscopic character. However, one can have collapse without irreversibility, although not viceversa. It is shown that all the so-called paradoxical features of the measurement problem stem from the confusion between the level of small quantum numbers and the level of very large ones. It is only at this latter level that the equivalence between the pure state vector of the total system Â«object+apparatusÂ» and the statistical matrix representing the possible outcomes of their interaction ensures that the Â«observerÂ» does not have any power of Â«creatingÂ» reality, but merely obtains from an objective, although probabilistic, representation of reality all the statistical information available.RiassuntoSi presenta una schematizzazione del processo di misura in meccanica quantistica che permette un trattamento unificato sia delle misure effettuate per mezzo di contatori polarizzati, sia di quelle compiute con dispositivi del tipo di Stern-Gerlach. Si dimostra in questo modo che il cosiddetto collasso della funzione dâ€™onda non Ã¨ un postulato di validitÃ  assoluta che deve essere aggiunto dallâ€™esterno alle leggi della meccanica quantistica, ma piuttosto una conseguenzaâ€”non esatta ma valida a un grado di approssimazione elevatissimoâ€”di queste stesse leggi. I limiti delle deviazioni da un processo di collasso rigoroso possono essere espressi in termini di quantitÃ  esplicitamente dipendenti dal carattere macroscopico del dispositivo sperimentale. Si discute inolter la relazione tra irreversibilitÃ  e (pseudo) collasso e si mostra che ambedue discendono dai grandi numeri connessi con questo carattere macroscopico. Ãˆ possibile tuttavia avere collasso senza irreversibilitÃ , ma non il viceversa. Si mostra cosÃ¬ che tutti gli aspetti apparentemente paradossali del problema della misura nascono dalla confusione fra il livello dei piccoli numeri quantici e quello dei numeri quantici elevati. Soltanto a questâ€™ultimo livello lâ€™equivalenza fra il vettore di stato puro del sistema totale Â«apparato+oggettoÂ» e la matrice statistica che rappresenta i possibili risultati della loro interazione garantisce che l'Â«osservatoreÂ» non ha alcun potere di Â«creareÂ» la realtÃ , ma semplicemente ottiene da una rappresentazione oggettiva, anche se probabilistica, di questa realtÃ , tutte le informazioni statistiche possibili.",1983,Il Nuovo Cimento B (1971-1996)
The Control of Mammalian DNA Replication A Brief History of Space and Timing,"The existence of G1 steps at which origin choice and replication timing are programmed in mammalian nuclei was demonstrated using a heterologous system based on Xenopus extracts. In this system, the origin decision point correlates with ORC assembly on chromatin, and the temporal decision point coincides with the postmitotic repositioning of chromosomal domains in the nucleus. It is likely that these control steps identified in vitro reflect regulatory events in living cells. However, although we do not yet have a complete picture, potential differences among metazoan replication control mechanisms are already apparent. For example, the number and spatial arrangement of replication foci differs between mammalian primary cells and cell lines (Kennedy et al., 2000xKennedy, B.K., Barbie, D.A., Classon, M., Dyson, N., and Harlow, E. Genes Dev. 2000; 14: 2855â€“2868Crossref | PubMed | Scopus (212)See all References(Kennedy et al., 2000), and different profiles of Orc protein expression during the cell cycle are evident among metazoans (Natale et al., 2000xNatale, D.A., Li, C.-J., Sun, W.-H., and DePamphilis, M.L. EMBO J. 2000; 19: 2728â€“2738Crossref | PubMedSee all ReferencesNatale et al., 2000 and references therein), suggesting different replication control mechanisms may exist. These differences emphasize the need for caution when extrapolating results from one organism or experimental system to another. The identification of further similarities and the reconciliation of differences among these diverse systems will be important for refining models of replication control in higher eukaryotes.",2001,Cell
"Nuclear Progesterone Receptor ( PR ) A and B Isoforms in Mouse Fallopian Tube and Uterus : Implications for Expression , Regulation and Cellular Function Abbreviated Title : nuclear PR isoforms in mouse Fallopian tube and uterus","Progesterone and its interaction with nuclear progesterone receptors (PR), PR-A and PR-B, play a critical role in the regulation of female reproductive function in all mammals. However, our knowledge of the regulation and possible cellular function of PR protein isoforms in the Fallopian tube and uterus in vivo is still very limited. In the present study, we revealed that equine gonadotropin (eCG) treatment resulted in a timedependent increase in expression of both isoforms, reaching a maximal level at 48 h in the Fallopian tube. Regulation of PR-A protein expression paralleled that of PR-B protein expression. However, in the uterus, PR-B protein levels increased and peaked earlier than PR-A protein levels after eCG treatment. With prolonged exposure to eCG, PR-B protein levels decreased whereas PR-A protein levels continued to increase. Furthermore, subsequent treatment with human chorionic gonadotropin (hCG) decreased the levels of PR protein isoforms in both tissues in parallel with increased endogenous serum progesterone levels. To further elucidate whether progesterone regulates PR protein isoforms, we demonstrated that a time-dependent treatment with P4 decreased the expression of PR protein isoforms in both tissues, whereas decreases in p27, cyclin D2 and proliferating cell nuclear antigen protein levels were only observed in uterus. To define the potential PR-mediated effects on apoptosis, we demonstrated that the PR antagonist treatment increased the levels of PR protein isoforms, induced mitochondrialassociated apoptosis, and decreased in epidermal growth factor (EGF) and EGF receptor protein expression in both tissues. Interestingly, immunohistochemistry indicated that the induction of apoptosis by PR antagonists was predominant in the epithelium, whereas increase in PR protein expression was observed in stromal cells of both tissues. Taken together, these observations suggest that (1) the tissue-specific and hormonal regulation of PR isoform expression in mouse Fallopian tube and uterus, where they are potentially involved in regulation of mitochondrial-mediated apoptosis depending on the cellular compartment; (2) a possible interaction between functional PR protein and growth factor signaling may have a coordinated role for regulating apoptotic process in both tissues in vivo.",2006,
Identifying strategies to control anemia among women of reproductive age: findings of an in-depth study in Bobo-Dioulasso Burkina Faso.,"In African countries the prevention and control of anemia are essential to reducing maternal mortality. To provide information for the development of an anemia control program among women of reproductive age a survey of 251 women was conducted in Bobo-Dioulasso Burkina Fasos second largest town. The survey was supplemented by 37 in-depth interviews with herbalists and government health workers. Anemia control activities in this area consisted of an examination of the conjunctiva of pregnant women attending antenatal care facilities. The prescription of iron and folate supplements was uncommon. Measurement of hemoglobin levels revealed an overall prevalence of anemia exceeding 50%; among pregnant respondents the rate was over 70%. 80% of women with hemoglobin levels below 9 grams/dl had contact with government health services in the three months preceding the survey. Although health is perceived as being dependent on the quantity and quality of blood in the body dietary practices during pregnancy especially cultural restrictions against the consumption of fruits rich in ascorbic acid and avoidance of meat foster low levels of iron absorption. Given the high prevalence of anemia detected in this study the provision of iron-folate tablets (and possibly vitamin C) to all pregnant women in Burkina Faso is urged. The prevention and treatment of malaria (another major cause of anemia) are also recommended. The interviews indicated that ""medicines"" would be more acceptable to this population than dietary advice alone.",1994,
62 Predictors of Tardive Dyskinesia in Psychiatric Patients Taking Concomitant Antipsychotics.,"BACKGROUND
Tardive dyskinesia (TD) is typically caused by exposure to antipsychotics, is often irreversible, and can be debilitating. TD symptoms can increase the social stigma of patients with comorbid psychiatric disorders, negatively impact quality of life, and potentially increase medical morbidity and mortality. An increased risk of developing TD has been associated with factors such as older age, female sex, underlying mental illness, and long-term use and higher doses of antipsychotics. The association of TD with the use of typical versus atypical antipsychotics has also been evaluated, with mixed results. To date, predictive models assessing the joint effect of clinical characteristics on TD risk have not been developed and validated in the US population.Study ObjectiveTo develop a prediction model to identify patient and treatment characteristics associated with the occurrence of TD among patients with psychiatric disorders taking antipsychotic medications, using a retrospective database analysis.


METHODS
Adult patients with schizophrenia, major depressive disorder, or bipolar disorder who were taking oral antipsychotics, and who had 6months of data prior to the index date were identified from Medicaid claims from six US states. The index date was defined as the date of the first claim for an antipsychotic drug after a claim for the underlying disorder but before TD diagnosis. A multivariate Cox prediction model was developed using a cross-validated version of the least absolute shrinkage and selection operator (LASSO) regression method to improve prediction accuracy and interpretability of the model. The predictive performance was assessed in a separate validation set via model discrimination (concordance) and calibration.


RESULTS
A total of 189,415 patients were identified: 66,723 with bipolar disorder, 68,573 with depressive disorder, and 54,119 with schizophrenia. The selected prediction model had a clinically meaningful concordance of 70% and was well calibrated (P=0.46 for Hosmer-Leme show goodness-of-fit test). Patient's age at index date (hazard ratio [HR]: 1.03), diagnosis of schizophrenia (HR: 1.73), dosage of antipsychotic at index date (up to 100mg/day chlorpromazine equivalent; HR: 1.40), and presence of bipolar and related disorders (HR: 1.16) were significantly associated with an increased risk of TD diagnosis. Use of atypical antipsychotics at index date was associated with a modest reduction in the risk of TD (HR=0.94).


CONCLUSIONS
This study identified a group of factors associated with the development of TD among patients with psychiatric disorders treated with antipsychotics. This may allow physicians to better monitor their patients receiving antipsychotics, allowing for the prompt identification and treatment of TD to help maintain quality of life.Presented at: American Psychiatric Association Annual Meeting; May 5-9, 2018, New York, New York, USAFunding Acknowledgements: This study was supported by Teva Pharmaceuticals, Petach Tikva, Israel.",2019,CNS spectrums
Post selection shrinkage estimation for high-dimensional data analysis,"In high-dimensional data settings where pï¾¿ï¾¿ï¾¿n, many penalized regularization approaches were studied for simultaneous variable selection and estimation. However, with the existence of covariates with weak effect, many existing variable selection methods, including Lasso and its generations, cannot distinguish covariates with weak and no contribution. Thus, prediction based on a subset model of selected covariates only can be inefficient. In this paper, we propose a post selection shrinkage estimation strategy to improve the prediction performance of a selected subset model. Such a post selection shrinkage estimator PSE is data adaptive and constructed by shrinking a post selection weighted ridge estimator in the direction of a selected candidate subset. Under an asymptotic distributional quadratic risk criterion, its prediction performance is explored analytically. We show that the proposed post selection PSE performs better than the post selection weighted ridge estimator. More importantly, it improves the prediction performance of any candidate subset model selected from most existing Lasso-type variable selection methods significantly. The relative performance of the post selection PSE is demonstrated by both simulation studies and real-data analysis. Copyright Â© 2016 John Wiley & Sons, Ltd.",2016,Applied Stochastic Models in Business and Industry
"Myconian Imperial Resort & Thallaso Center, Mykonos - Cuba Holidays","The elegant Myconian Imperial Resort & Thalasso Centre rests on peaceful Elia Beach overlooking the sapphire blue Aegean Sea on the island paradise of Mykonos. Perfect for romantic escapism, soothing getaways, honeymoons, memorable weddings and high-end..",2015,
Variable Selection by Lasso-Type Methods,"Variable selection is an important property of shrinkage methods. The adaptive lasso is an oracle procedure and can do consistent variable selection. In this paper, we provide an explanation that how use of adaptive weights make it possible for the adaptive lasso to satisfy the necessary and almost sufcient condition for consistent variable selection. We suggest a novel algorithm and give an important result that for the adaptive lasso if predictors are normalised after the introduction of adaptive weights, it makes the adaptive lasso performance identical to the lasso.",2011,Pakistan Journal of Statistics and Operation Research
Lasso penalized model selection criteria for high-dimensional multivariate linear regression analysis,"This paper proposes two model selection criteria for identifying relevant predictors in the high-dimensional multivariate linear regression analysis. The proposed criteria are based on a Lasso type penalized likelihood function to allow the high-dimensionality. Under the asymptotic framework that the dimension of multiple responses goes to infinity while the maximum size of candidate models has smaller order of the sample size, it is shown that the proposed criteria have the model selection consistency, that is, they can asymptotically pick out the true model. Simulation studies show that the proposed criteria outperform existing criteria when the dimension of multiple responses is large.",2014,J. Multivar. Anal.
Core psychopathology of treatment-seeking patients with binge-eating disorder: a network analysis investigation.,"BACKGROUND
Mental disorders may emerge as the result of interactions between observable symptoms. Such interactions can be analyzed using network analysis. Several recent studies have used network analysis to examine eating disorders, indicating a core role of overvaluation of weight and shape. However, no studies to date have applied network models to binge-eating disorder (BED), the most prevalent eating disorder.


METHODS
We constructed a cross-sectional graphical LASSO network in a sample of 788 individuals with BED. Symptoms were assessed using the Eating Disorders Examination Interview. We identified core symptoms of BED using expected influence centrality.


RESULTS
Overvaluation of shape emerged as the symptom with the highest centrality. Dissatisfaction with weight and overvaluation of weight also emerged as highly central symptoms. On the other hand, behavioral symptoms such as binge eating, eating in secret, and dietary restraint/restriction were less central. The network was stable, allowing for reliable interpretations (centrality stability coefficient = 0.74).


CONCLUSIONS
Overvaluation of shape and weight emerged as core symptoms of BED. This trend is consistent with past network analyses of eating disorders more broadly, as well as literature that suggests a primary role of shape and weight concerns in BED. Although DSM-5 diagnostic criteria for BED does not currently include a cognitive criterion related to body image or shape/weight overvaluation, our results provide support for including shape/weight overvaluation as a diagnostic specifier.",2018,Psychological medicine
Hip Fracture Discrimination Based on Statistical Multi-parametric Modeling (SMPM),"Studies using quantitative computed tomography (QCT) and data-driven image analysis techniques have shown that trabecular and cortical volumetric bone mineral density (vBMD) can improve the hip fracture prediction of dual-energy X-ray absorptiometry areal BMD (aBMD). Here, we hypothesize that (1) QCT imaging features of shape, density and structure derived from data-driven image analysis techniques can improve the hip fracture discrimination of classification models based on mean femoral neck aBMD (Neck.aBMD), and (2) that data-driven cortical bone thickness (Ct.Th) features can improve the hip fracture discrimination of vBMD models. We tested our hypotheses using statistical multi-parametric modeling (SMPM) in a QCT study of acute hip fracture of 50 controls and 93 fragility fracture cases. SMPM was used to extract features of shape, vBMD, Ct.Th, cortical vBMD, and vBMD in a layer adjacent to the endosteal surface to develop hip fracture classification models with machine learning logistic LASSO. The performance of these classification models was evaluated in two aspects: (1) their hip fracture classification capability without Neck.aBMD, and (2) their capability to improve the hip fracture classification of the Neck.aBMD model. Assessments were done with 10-fold cross-validation, areas under the receiver operating characteristic curve (AUCs), differences of AUCs, and the integrated discrimination improvement (IDI) index. All LASSO models including SMPM-vBMD features, and the majority of models including SMPM-Ct.Th features performed significantly better than the Neck.aBMD model; and all SMPM features significantly improved the hip fracture discrimination of the Neck.aBMD model (Hypothesis 1). An interesting finding was that SMPM-features of vBMD also captured Ct.Th patterns, potentially explaining the superior classification performance of models based on SMPM-vBMD features (Hypothesis 2). Age, height and weight had a small impact on model performances, and the model of shape, vBMD and Ct.Th consistently yielded better performances than the Neck.aBMD models. Results of this study clearly support the relevance of bone density and quality on the assessment of hip fracture, and demonstrate their potential on patient and healthcare cost benefits.",2019,Annals of Biomedical Engineering
Regularized Estimation and Feature Selection in Mixtures of Gaussian-Gated Experts Models,"Mixtures-of-Experts models and their maximum likelihood estimation (MLE) via the EM algorithm have been thoroughly studied in the statistics and machine learning literature. They are subject of a growing investigation in the context of modeling with high-dimensional predictors with regularized MLE. We examine MoE with Gaussian gating network, for clustering and regression, and propose an $\ell_1$-regularized MLE to encourage sparse models and deal with the high-dimensional setting. We develop an EM-Lasso algorithm to perform parameter estimation and utilize a BIC-like criterion to select the model parameters, including the sparsity tuning hyperparameters. Experiments conducted on simulated data show the good performance of the proposed regularized MLE compared to the standard MLE with the EM algorithm.",2019,ArXiv
Je ne menge poinct de porcq: zgodnja parodiÄna maÅ¡a Orlanda di Lassa,"One of the most remarkable 16th-century composers was Orlando di Lasso (1530/1532â€“1594), perhaps the most prominent musician of his time. In the second half of the 16th and the early 17th centuries, his works were widespread across Europe, especially in its central and western part. Some of the surviving contemporary sources of Lassoâ€™s music â€“ both printed and manuscript â€“ are preserved in Slovenian libraries and archives. Among them are two incompletely preserved manuscripts, dating from ca. 1600, today kept at the National and University Library in Ljubljana (Ms 232 and Ms 285). They both contain Lassoâ€™s Missa super Je ne menge poinct de porcq , first published in Lassoâ€™s second book of Masses, Quinque missae , by Claudio Merulo in 1570. Interestingly, this early Munich-period Mass is based on a Parisian chanson by Claudin de Sermisy (ca. 1490â€“1562), whose content is unequivocally scatological. It was quite common for 16th-century composers to base their settings of the Mass Ordinary on pre-existent polyphonic compositions, whether sacred or secular. One of the rare descriptions of this technique â€“ widely known as parody technique â€“ is given in Pietro Ceroneâ€™s El melopeo y maestro (1613). It can serve as the basis for an elementary analysis of how Lasso employed Sermisyâ€™s chanson Je ne menge point de porc . The analysis shows that Lasso, for various reasons, does not always follow the established practices as they can be observed from Ceroneâ€™s treatise. Nevertheless he demonstrates significant skill in utilising borrowed material to compose his parody Mass. Lassoâ€™s Missa super Je ne menge poinct de porcq is particularly intriguing due to its use of Sermisyâ€™s chanson; what could be the reason for Lassoâ€™s decision to use Sermisyâ€™s profoundly secular chanson in order to compose a Mass setting? Although the answer can be multifaceted (such as an intention to establish a special textual relation between the Mass and the model), the principal reason seems to be the musical qualities of the chanson, which proved to be a very convenient and worthy source for composing a short Mass.",2013,Keria: Studia Latina et Graeca
Stability in disjunctive optimization II:continuity of the feasible and optimal set,"A disjunctive linear optimization problem is to minimize a function over a feasible set which is the union of (perhaps infinitely many) convex sets. The classofdisjunctiveoptimization problems contains many classes of optimization problems which look at the first sight very different from their structure (f.e. semi-infinite and mixed-integer linear optimization problems, certain non-linear approximation problems, fractional proÂ¬gramming, linear complementary problems). Our purpose in this paper is to investigate the disjunctive linear optimization problem in dependence on the involved mappings. Especially, we establish necessary and sufficient conditions for the upper and lower semicontinuity of the feasible and optimal set mapping. Examples will illustrate the difficulties and characteristics to derive such conditions in parametric disjunctive programming",1994,Optimization
Ichthyofauna of the Village Creek System,"Village creek is a lowland stream lying in the Mississippi Embayment in Randolph, Lawrence and Jackson counties in northeastern Arkansas. The stream has been channelized in Randolph and Lawrence counties as have most of its tributaries. The Jackson County portion of the stream has not been channelized. Twelvesites were sampled seasonally by seining along Village Creek and its tributaries. In addition to seasonal work, six sites were sampled from one to three times each by several methods. A total of 8000 specimens was collected by all means used (7754 at seasonal sites and 246 at supplemental sites). Forty-two species were collected from 16 families. Twospecies not previously reported from the System were collected in this study namely Hiodonalosoides and Pimephalesvigilax. All 42 of the species collected in the study were represented in Jackson County whileonly 24 species were collected in Lawrence and Randolph counties. Members of the family Centrarchidae were the most commonly collected group (44% of specimens) whereas the most commonly collected species was Gambusiaaffinis (29.6% of specimens). Some of the fish species in the Systemhave shown resilience to stream alteration, domestic sewage, industrial and agricultural runoff and dumping of refuse. However, the future success of some species (e.g., Opsopoeodus emiliae, Notropismaculatus, Notropis texanus, Lythrurus fumeus,Elassoma zonatum and Etheostoma gracile) willdepend on the protection of and sustainable use of the natural resources in the watershed.",1993,Journal of the Arkansas Academy of Science
Bayesian analysis of definitive screening designs when the response is nonnormal,"Definitive screening designs DSDs are a class of experimental designs that allow the estimation of linear, quadratic, and interaction effects with little experimental effort if there is effect sparsity. The number of experimental runs is twice the number of factors of interest plus one. Many industrial experiments involve nonnormal responses. Generalized linear models GLMs are a useful alternative for analyzing these kind of data. The analysis of GLMs is based on asymptotic theory, something very debatable, for example, in the case of the DSD with only 13 experimental runs. So far, analysis of DSDs considers a normal response. In this work, we show a five-step strategy that makes use of tools coming from the Bayesian approach to analyze this kind of experiment when the response is nonnormal. We consider the case of binomial, gamma, and Poisson responses without having to resort to asymptotic approximations. We use posterior odds that effects are active and posterior probability intervals for the effects and use them to evaluate the significance of the effects. We also combine the results of the Bayesian procedure with the lasso estimation procedure to enhance the scope of the method. Copyright Â© 2016 John Wiley & Sons, Ltd.",2016,Applied Stochastic Models in Business and Industry
Prevalence using standardized definitions,"Objective: The San Antonio Lupus Study of Neuropsychiatric Disease is a longitudinal study designed to characterize the spectrum of and important risk factors for specific neuropsychiatric systemic lupus erythematosus (NPSLE) syndromes. Methods: Subjects must meet criteria for SLE and must be at least 18 years of age. A standardized medical history, neurologic, rheumatologic, and psychiatric examinations, computerized neuropsychological evaluation, and serologic testing are performed. Results: This report is based on the first 128 subjects (120 women and 8 men) who completed the initial study visit. Data from this initial study visit were evaluated for the prevalence of NPSLE using the American College of Rheumatology case definitions for 19 NPSLE syndromes. One or more NPSLE syndromes were present in 80% of subjects: cerebrovascular disease (2, 2%; ischemic stroke); headaches (73, 57%); mononeuropathy (9, 8%; median 8, ulnar 1); movement disorder (1, 1%; chorea); neuropathy, cranial (2, 2%; trigeminal); polyneuropathy (29, 22%; sensorimotor); seizures (21, 16%; partial); anxiety disorder (27, 24%); major depressive-like episode (37, 28%); mood disorder with depressive features (21, 19%); mood disorder with manic features (3, 3%); mood disorder with mixed features (1, 1%); psychosis (6, 5%). In a subset of 67 patients who received standardized neuropsychological testing, 21% had normal results. In the remainder, the following levels of impairment were seen: 43% mild, 30% moderate, and 6% severe. Conclusions: The prevalence of NPSLE was high in this cohort of unselected patients with SLE. Headaches, cognitive dysfunction, and psychiatric disorders were the most common NPSLE syndromes seen. These results will be easily comparable to other studies also using standardized diagnostic criteria. However, the lack of ethnicity and languagematched normative neuropsychological data may make comparisons of cognitive dysfunction in SLE populations difficult. NEUROLOGY 2002;58:1214â€“1220 Systemic lupus erythematosus (SLE) is an inflammatory disease affecting many organ systems with prevalence rates as high as 51 per 100,000 population in the United States.1 Females are affected three to five times more frequently than males.2 Blacks and Hispanics are affected much more frequently than whites. These groups also appear to have a higher disease morbidity.3-6 Estimations from community-based studies suggest that the number of patients in the United States with definite SLE is approximately 131,000.7 An equal number have suspected or â€œlupus-likeâ€ disease and will likely receive a diagnosis of SLE with continued observation.8 Although SLE-related morbidity remains high, the prognosis for survival has improved in recent years, from a 5-year survival of 51% in the 1950s to 90% in recent studies.3 A bimodal pattern in the mortality has been described in which early deaths are due to SLE disease activity or infections and later deaths are due primarily to vascular causes.9 In a multicenter study evaluating cause of death in 222 patients with SLE, 31% of deaths were attributed to active organ involvement and 33% to infection. Active disease in the kidney and the CNS were the most frequently observed primary causes of death.10 Nervous system dysfunction occurs in 50 to 90% of patients with SLE11-21 depending on the sampling procedures and diagnostic criteria used. Despite its frequency and severity, nervous system involvement is underdiagnosed and poorly understood. SLErelated nervous system involvement encompasses a wide spectrum of overt neurologic and psychiatric features ranging from strokes, seizures, peripheral neuropathy, chorea, dementia, psychosis, anxiety, and depression16 to more subtle cognitive abnormalities such as attention, memory, and visuospatial abnormalities.17-20 Seizures and psychosis are the only nervous system manifestations that are part of the American College of Rheumatology diagnostic criteria for SLE.22 From the Department of Medicine, Divisions of Neurology (Drs. Brey, Navarrete, and Hermosilloâ€“Romo, and A. Saklad, C. Stallworth, C. Valdez, C. Rhine, and P. Padilla) and Clinical Immunology (Drs. Escalante and del RincÃ³n); Audie L. Murphy Veterans Association Hospital (Dr. Holliday), San Antonio, TX; Willford Hall United States Air Force Medical Center (Dr. Gronseth and D. McGlasson), Lackland Air Force Base, TX. Supported by a grant from the National Institute of Neurologic Disorders and Stroke (NS35477) and the National Center for Research Resources General Clinical Research Center Program (MO1 RR01346â€“19), where the study is conducted, and R.L.B. and A.E are Associate Program Directors. Received October 24, 2001. Accepted in final form December 24, 2001. Address correspondence and reprint requests to Dr. Robin L. Brey, Department of Medicine, Division of Neurology, 7703 Floyd Curl Drive #7883, San Antonio, TX 78229-3900; e-mail: brey@uthscsa.edu 1214 Copyright Â© 2002 by AAN Enterprises, Inc. Standardized case definitions for 19 neuropsychiatric syndromes associated with SLE (NPSLE) have recently been established.16 The purpose of this report is to evaluate the prevalence of each of these syndromes at the baseline evaluation in the first 128 subjects enrolled into a longitudinal cohort study of clinical and serologic predictors for NPSLE. Materials and methods. Patient population. Patients 18 years of age with the diagnosis of SLE were recruited to participate in the study from patients with SLE seen at several hospitals and clinics in the greater San Antonio area. No effort was made to either include or exclude patients with neurologic, cognitive, or psychiatric illness. Informed consent was obtained from all study participants. Study procedures. Patients were seen for a study visit every 4 months. Scripted monthly telephone follow-up calls were made to identify new illnesses, medication changes, and the possible occurrence of NPSLE events between visits. Demographic data, including age, sex, ethnicity, education, employment status, and preferred language were collected at study entry. Neurologic and cardiovascular assessments. Risk factor information was obtained at each study visit that assessed for the presence of cardiovascular risk factors (hypertension, diabetes, coronary artery disease, cigarette smoking, hypercholesterolemia or hyperlipidemia, thrombotic events), episodes of fetal loss, or neurologic symptoms. Current medications, including corticosteroid dose, were ascertained at each study visit. Annual fasting serum glucose levels and a lipid profile were performed. A diagnosis of diabetes mellitus was based on medical history or on the use of insulin or oral hypoglycemic medication. A diagnosis of hypertension was made when a systolic blood pressure was 140 mm Hg, a diastolic blood pressure was 95 mm Hg, or when the subject was receiving medication for high blood pressure. A diagnosis of coronary artery disease was based on medical history. The current and past cigarette use was obtained and the total lifetime number of cigarettes smoked was calculated. The diagnosis of hypercholesterolemia and hyperlipidemia was based on medical history or when the subject was taking lipid-lowering medications. A diagnosis of thrombotic events prior to study entry was made by history and confirmation by medical record review. A standard, complete neurologic examination was performed at every study visit by a neurologist. The diagnosis of specific NPSLE manifestations was made using the American College of Rheumatology consensus criteria.16 SLE-related disease activity assessments. Current SLE disease activity and cumulative SLE-related damage were measured at each study visit using the SLE Disease Activity Index23 and SLE Damage Index.24 A urinalysis, complete blood count, antiâ€“double-stranded DNA levels, and complement levels were obtained at each visit and reviewed by one of the study rheumatologists to complete the laboratory portion of the SLE Disease Activity Index. Cognitive assessment. Cognitive assessments were made using Automated Neuropsychological Assessment Metrics, Version 3.11 (ANAM).25 ANAM is a set of computer-administered neuropsychological performance tests selected from a larger battery developed by the Department of Defense specifically designed for repeated testing. ANAM tests use a pseudorandomization procedure to generate an infinite number of alternate versions of the tests; i.e., a new version is generated for each test session but all patients take the same version for that visit number. All ANAM tests produce data characterizing performance with respect to both accuracy and efficiency of performance. ANAM tests have been shown to be reliable and stable over repeated measures and are sensitive to diffuse brain impairment caused by head injury, extreme environmental stress from fatigue, and heat and drug effects.26,27 ANAM tests for this study included: Simple Reaction Time, Continuous Performance (vigilance/sustained attention), Code Substitution and Delayed Memory (visual scanning and nonverbal memory), Simultaneous Spatial Processing (visual perception and mental rotation), Sternberg Task (working memory and memory), Digit Span (working memory/span of attention), and Matching to Sample Test (visuospatial perception and working memory). The ANAM tests selected did not require English language proficiency or literacy as instructions were given in the patientâ€™s preferred language and no reading is required. Each test was preceded by practice items to ensure comprehension of test instructions. The ANAM tests use the two computer mouse buttons for responding, decreasing reaction time artifact from unfamiliarity with the computer keyboard or problems with joint mobility. The battery takes 30 to 40 minutes for administration. ANAM was administered on Dell laptop computers (Round Rock, TX) operating in DOS mode. Each ANAM test is computer scored for four measures: mean reaction time for ",2002,
Ergebnisse der Helio- und Thalassotherapie bei Psoriasis,"Der Einflus der geographischen und biometeorologischen Faktoren auf die Haufigkeit und den Verlauf der Psoriasis ist schon seit langem bekannt. In letzter Zeit wird immer ofter von gunstigen therapeutischen Erfahrungen mit der Photochemotherapie und selektierten Phototherapie berichtet [6, 10, 12, 19, 20]. Angesichts dieser Erfahrungen und der modernen Ansichten uber die Reaktion der Psoriasis auf die Einwirkung aktivischer Faktoren kommt die Bedeutung der systematischen und sachverstandigen Anwendung der Heliound Thalassotherapie am Meer heutzutage voll zum Ausdruck. In letzterer Zeit wurde in mehreren Publikationen uber die erfolgreichen Ergebnisse bei der Behandlung dieser Patienten in Sonderanstalten an Meerkasten, wie am Adriatischen Meer [4, 9, 11], an der Nordsee [13, 15, 16, 17], am Toten Meer [1, 5, 8] und am Schwarzen Meer [14] berichtet.",1981,
MLGL: An R package implementing correlated variable selection by hierarchical clustering and group-Lasso,"The MLGL R-package, standing for Multi-Layer Group-Lasso, implements a new procedure of variable selection in the context of redundancy between explanatory variables, which holds true with high dimensional data. A sparsity assumption is made that is, only a few variables are assumed to be relevant for predicting the response variable. In this context, the performance of classical Lasso-based approaches strongly deteriorates as the redundancy strengthens. The proposed approach combines variables aggregation and selection in order to improve interpretability and performance. First, a hierarchical clustering procedure provides at each level a partition of the variables into groups. Then, the set of groups of variables from the different levels of the hierarchy is given as input to group-Lasso, with weights adapted to the structure of the hierarchy. At this step, group-Lasso outputs sets of candidate groups of variables for each value of regularization parameter. The versatility offered by MLGL to choose groups at different levels of the hierarchy a priori induces a high computational complexity. MLGL however exploits the structure of the hierarchy and the weights used in group-Lasso to greatly reduce the final time cost. The final choice of the regularization parameter â€“ and therefore the final choice of groups â€“ is made by a multiple hierarchical testing procedure.",2018,
Evaluation of K-SVD with different embedded sparse representation algorithms,"The K-SVD algorithm is a powerful tool in finding an adaptive dictionary for a set of signals via using the sparse representation optimization and constrained singular value decomposition. In this paper, we first review the original K-SVD algorithm as well as some sparse representation algorithms including OMP, Lasso and recently proposed IITH. Secondly, we embed the Lasso and IITH sparse representation algorithms into the K-SVD process and establish two new different K-SVD algorithms. Finally, we have done extensive experiments to evaluate the performances of these derived K-SVD algorithms with different pursuit methods and these experiments show that the K-SVD with IITH has distinctive advantages in computational cost and signal recovery performance while the K-SVD with Lasso is not sensitive to initial conditions.",2016,"2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)"
Identification of a Five-Pseudogene Signature for Predicting Survival and Its ceRNA Network in Glioma,"Background: Glioma is the most common primary brain tumor with a dismal prognosis. It is urgent to develop novel molecular biomarkers and conform to individualized schemes. Methods: Differentially expressed pseudogenes between low grade glioma (LGG) and glioblastoma multiforme (GBM) were identified in the training cohort. Least absolute shrinkage and selection operator (LASSO) regression and multivariate Cox proportional hazards regression analyses were used to select pseudogenes associated with prognosis of glioma. A risk signature was constructed based on the selected pseudogenes for predicting the survival of glioma patients. A pseudogene-miRNA-mRNA regulatory network was established and visualized using Cytoscape 3.5.1. Gene Oncology (GO) and signaling pathway analyses were performed on the targeted genes to investigate functional roles of the risk signature. Results: Five pseudogenes (ANXA2P2, EEF1A1P9, FER1L4, HILS1, and RAET1K) correlating with glioma survival were selected and used to establish a risk signature. Time-dependent receiver operating characteristic (ROC) curves revealed that the risk signature could accurately predict the 1, 3, and 5-year survival of glioma patients. GO and signaling pathway analyses showed that the risk signature was involved in regulation of proliferation, migration, angiogenesis, and apoptosis in glioma. Conclusions: In this study, a risk signature with five pseudogenes was constructed and shown to accurately predict 1-, 3-, and 5-year survival for glioma patient. The risk signature may serve as a potential target against glioma.",2019,Frontiers in Oncology
Multiple Kernel Learning in the Primal for Multimodal Alzheimerâ€™s Disease Classification,"To achieve effective and efficient detection of Alzheimer's disease (AD), many machine learning methods have been introduced into this realm. However, the general case of limited training samples, as well as different feature representations typically makes this problem challenging. In this paper, we propose a novel multiple kernel-learning framework to combine multimodal features for AD classification, which is scalable and easy to implement. Contrary to the usual way of solving the problem in the dual, we look at the optimization from a new perspective. By conducting Fourier transform on the Gaussian kernel, we explicitly compute the mapping function, which leads to a more straightforward solution of the problem in the primal. Furthermore, we impose the mixed L21 norm constraint on the kernel weights, known as the group lasso regularization, to enforce group sparsity among different feature modalities. This actually acts as a role of feature modality selection, while at the same time exploiting complementary information among different kernels. Therefore, it is able to extract the most discriminative features for classification. Experiments on the ADNI dataset demonstrate the effectiveness of the proposed method.",2014,IEEE Journal of Biomedical and Health Informatics
El alma es el espejo de la cara : de Kafka y el judaÃ­smo,"TESIS DOCTORAL: CARLOS CONCHILLO
RESUMEN, OBJETIVOS, METODOLOGIA, CONCLUSIONES.
 Se hace una lectura de la obra de Kafka resaltando sus dimensiones judias. Para ello se pondran de manifiesto las similitudes de sus escritos con Don Quijote, un caballero unido a los libros, como el judaismo. El estudio de los Aforismos estara basado, fundamentalmente, en la felix culpa, la separacion del hombre respecto de la divinidad. Ha de estudiarse lo que significa la literalidad, tanto para la Cabala (Kafka la entiende historicamente pero con ojos del siglo XX) como en la obra del escritor, para quien el uso literal y el figurado es el mismo cuando la realidad no es independiente. Se tratara el tema del tiempo, congelado en su obra, lo cual hace que, como en el judaismo, no se vea ni como algo lineal ni como algo circular. Se trata la figura del tzadik desde el convencimiento de que el hombre ha de verselas con intermediarios, ya que la realidad en si es inaccesible; ello explica la importancia de la figura del ayudante. Como piensa la Cabala, hemos de entender los descensos estudiando el fenomeno de la teurgia, pues el unico acceso a aquello de lo que todo depende ha de iniciarse abajo. Veremos que el humor es muy importante para Kafka, y para un pueblo, el judio, que ha de convivir cerca de la desgracia, y las contradicciones y paradojas que de ello se derivan. Trataremos la naturaleza individual del mesianismo, asi como la importancia de los seres hibridos -para el escritor y para los judios-, y las ausencias: la de tierra sera capital. Veremos que el papel de las artimanas imposibilita interpretar a Kafka de una vez por todas. Tambien se lo compara con el modo como Wittgenstein tiene de entender el lenguaje, la diferencia entre el decir y el mostrar, la intersubjetividad y la dimension objetiva de las cosas.
Se destaca la importancia que la mistica judia tiene en virtud de las siguientes categorias: quijotismo, Dios, pecado, imaginacion, interpretacion, fundamento, legalidad y literalidad, humor, tiempo, intermediacion, individualismo, lo mesianico, lo hibrido, y el lenguaje. Es cierto que un conocimiento de las raices judias de Kafka ayuda a comprender el universo de un gran escritor que tiene tanto que decir en relacion a los problemas del siglo XX. 
Por consistir la tesis en la interpretacion de un corpus literario paradojico, la metodologia aplicable al trabajo doctoral ha de ser hermeneutica.
De ahi se sigue una orientacion metodica segun la cual la atencion a la literalidad de la produccion kafkiana es estricta, revisando los principales hitos interpretativos de la literatura kafkiana, entre los que se encuentran autores como Brod, Blanchot, Arendt, Benjamin, Scholem, Calasso, Robert, Anders, Baioni, Citati, Hoffmann, Laenen, Wiesel, Elior, Moses. Todo ello ha de articular una lectura de Kafka con el objetivo de estudiar la importancia de la tradicion judia.
Hay mas de un Kafka en Kafka: la tesis asume ese axioma y, haciendolo, reconoce por adelantado las limitaciones de su propio rendimiento exegetico.
La tesis concluye la importancia del judaismo a la hora de acercarnos a las creaciones de Kafka, aun convencidos de que su autentica vocacion era la de escritor. Pretendemos exponer los rasgos comunes que hay entre lo que Kafka escribio y la imagineria judia, concluyendo que el tema central del trabajo tiene que ver con la centralidad del lenguaje, acaso la preocupacion mayor del pensamiento contemporaneo.
 A reading of Kafka's work is done highlighting his jewish dimensions. With this aim the similarities of his writings to Don Quijote, a knight very close to books, as it is the case with Judaism, will be revealed. The study of Aphorism will be basically founded on the felix culpa, the separation of man with respect to divinity, which justifies the existence of the former. The meaning of literality has to be studied not only for the Kabala (Kafka understands it historically, but with eyes of the xx century) but also in the writer's work, for whom the literal and figurative sense is the same when reality is not independent. The subject of time will be dealt, frozen in his work, which makes that, as in Judaism, it is not seen neither as something lineal nor something circular. The figure of tzadik is dealt with from the conviction that man has to be in touch with intermediaries, as reality in itself is inaccessible; this explains the importance of the figure of the assistant. In the same same way as the Kabala thinks, we have to understand the descents studying the phenomenon of the teurgia, as the only access to that from which everything depends on has to begin from beneath. We will see that humours is very important to Kafka and to some people, the jews, that have to coexist with misfortune, and contradictions, and paradoxes that arise from them. We will also deal with the individual nature of mesianism, as well as with the importance of the hybrid beings -not only for the writer but also for the jews-, and the absences: the one of the land will be of a major importance. We will see that the role of the tricks will make it impossible to interpret Kafka once and for all. It is also compared to the way Wittgenstein has of understanding languaje, the difference between saying and showing, the intersubjectivity and the objective dimensions of things.
 The importance of the jewish mysticism is higlighted, by virtue of the following characteristics: quixotic nature, God, sin, imaginations, interpretation, fundamentals, legality and literality, humour, time, intermediation, individualism, the messianic, the hybrid, and the languaje. It is true that a knowledge of Kafka's jewish roots helps to understand the universe of a great writer that has so much to say about the problems of the xx century.
 As the thesis consists in a paradoxical literary corpus, the methodology applicable to the doctoral work has to be hermeneutics.
 From this follows that a methodical orientation according to which the attention to the literality of the Kafkian production is strict, reviewing the main interpretative milestone of the Kafkian literature, among whom authors such as Brod, Blanchot, Arendt, Benjamin, Scholem, Calasso, Robert, Anders, Baioni, Citati, Hoffmann, Laenen, Wiesel, Elior, Moses are included. All this has to draw together a reading of Kafka with the aim of studying the importance of the jewish tradition.
 There is more than one Kafka in Kafka: the thesis assumes that axiom and, in doing so, it acknowledges in advance the limitations of its own exegetical performance.
 The thesis concludes the importance of judaism when we come close to Kafka's works, even though we are convinced that his real vocation was to became a writer. We are trying to put forward the common characteristics that exists between what Kafka wrote and the jewish imagery, to conclude that the central theme of this work is related to the centrality of languaje, perharps the major concern of contemporary thought.",2015,
Sparse Point Estimation for Bayesian Regression via Simulated Annealing,"In the context of variable selection in a regression model, the classical Lasso based optimization approach provides a sparse estimate with respect to regression coefficients but is unable to provide more information regarding the distribution of regression coefficients. Alternatively, using a Bayesian approach is more advantageous since it gives direct access to the distribution which is usually summarized by estimating the expectation (not sparse) and variance. Additionally, to support frequent application requirements, heuristics like thresholding are generally used to produce sparse estimates for variable selection purposes. In this paper, we provide a more principled approach for generating a sparse point estimate in a Bayesian framework. We extend an existing Bayesian framework for sparse regression to generate a MAP estimate by using simulated annealing. We then justify this extension by showing that this MAP estimate is also sparse in the regression coefficients. Experiments on real world applications like the splice site detection and diabetes progression demonstrate the usefulness of the extension.",2012,
"Une Ã©ruption papulo-nodulaire, en zone tropicale (maladie de Hansen)","A papulo-nodular rash in a tropical area Despite the success of multidrug therapy and dire c t l y observed therapy (DOT) in reducing the overall incidence of leprosy, this mycobacterial disease remains a public health concern in many areas of Africa. Case finding and treatment remain the most efficient way to c o n t rol the disease. We re p o rt one case of advanced lepromatous leprosy diagnosed at the internal medicine ward of Bobo-Dioulasso Hospital (Burkina Faso). This case is symptomatic of the increasing difficulty to detect the last cases of an endemic disease. Epidemiology, diagnosis, and treatment issues are discussed with a brief review of the literature. Key-words: Lepromatous leprosy, Bacteriology, Case finding, Multidrug therapy, Burkina Faso.",1999,
Sharp oracle inequalities in aggregation and shape restricted regression,"This PhD thesis studies two fields of Statistics: Aggregation of estimatorsand shape constrained regression.Shape constrained regression studies the regression problem (find a function that approximates well a set of points) with an underlying shape constraint, that is, the function must have a specific ""shape"". For instance, this function could be nondecreasing of convex: These two shape examples are the most studied. We study two estimators: an estimator based on aggregation methods and the Least Squares estimator with a convex shape constraint. Oracle inequalities are obtained for both estimators, and we construct confidence sets that are adaptive and honest.Aggregation of estimators studies the following problem. If several methods are proposed for the same task, how to construct a new method that mimics the best method among the proposed methods? We will study these problems in three settings: aggregation of density estimators, aggregation of affine estimators and aggregation on the regularization path of the Lasso.",2016,
Feature Selection using Stochastic Gates,"Feature selection problems have been extensively studied for linear estimation, for instance, Lasso, but less emphasis has been placed on feature selection for non-linear functions. In this study, we propose a method for feature selection in high-dimensional non-linear function estimation problems. The new procedure is based on minimizing the $\ell_0$ norm of the vector of indicator variables that represent if a feature is selected or not. Our approach relies on the continuous relaxation of Bernoulli distributions, which allows our model to learn the parameters of the approximate Bernoulli distributions via gradient descent. This general framework simultaneously minimizes a loss function while selecting relevant features. Furthermore, we provide an information-theoretic justification of incorporating Bernoulli distribution into our approach and demonstrate the potential of the approach on synthetic and real-life applications.",2019,arXiv: Learning
Factors affecting fish assemblages associated with gas platforms in the Mediterranean Sea,"Abstract Understanding the role played by offshore platforms in marine ecosystems is acquiring increasing importance worldwide. In this work, underwater visual census techniques were applied to describe spatial and temporal patterns of fish assemblages associated with extractive platforms. Data were collected during three seasons according to the following spatial factors: Location (Adriatic and Ionian Seas), Depth (0â€“6Â m and 12â€“18Â m) and Distance from the platform (external and internal). Both univariate and multivariate analyses showed highly significant differences for each factor assessed in this study, as well as for the interaction among said factors. Results indicated that artificial structures in both the Adriatic and Ionian Seas act as artificial reefs attracting reef-dwelling or partially reef-dwelling species, which are not present far from the platforms in open waters. Results also showed significant differences between Ionian and Adriatic fish assemblages, with a higher mean density of fish and a greater mean number of species in the latter basin. Boops boops , Chromis chromis and several species belonging to the Blennidae family most contributed to these differences. This is likely due to the eutrophication that involves the coast of the northern and central Adriatic, allowing a high production of fish, especially planctivorous. Thanks to the eutrophication, platforms located in this basin are characterized by a greater abundance of fouling organisms which offer a perfect habitat for cryptobenthic species, such as Blennids. Moreover, Thalassoma pavo and Scorpaena maderensis , thermophilic species, were more abundant in the Ionian platforms than in the Adriatic ones thus contributing to the dissimilarities between these two basins. Present results could bear strong implications for the environmental management of drilling and production activities in different basins. Assessing biodiversity in these highly complex contexts is a challenge for the near future, and the existence of a reliable method such as UVC would affect international research in this field.",2013,Journal of Sea Research
Genome-Wide Association Mapping of Starch Pasting Properties in Maize Using Single-Locus and Multi-Locus Models,"Maize starch plays a critical role in food processing and industrial application. The pasting properties, the most important starch characteristics, have enormous influence on fabrication property, flavor characteristics, storage, cooking, and baking. Understanding the genetic basis of starch pasting properties will be beneficial for manipulation of starch properties for a given purpose. Genome-wide association studies (GWAS) are becoming a powerful tool for dissecting the complex traits. Here, we carried out GWAS for seven pasting properties of maize starch with a panel of 230 inbred lines and 145,232 SNPs using one single-locus method, genome-wide efficient mixed model association (GEMMA), and three multi-locus methods, FASTmrEMMA, FarmCPU, and LASSO. We totally identified 60 quantitative trait nucleotides (QTNs) for starch pasting properties with these four GWAS methods. FASTmrEMMA detected the most QTNs (29), followed by FarmCPU (19) and LASSO (12), GEMMA detected the least QTNs (7). Of these QTNs, seven QTNs were identified by more than one method simultaneously. We further investigated locations of these significantly associated QTNs for possible candidate genes. These candidate genes and significant QTNs provide the guidance for further understanding of molecular mechanisms of starch pasting properties. We also compared the statistical powers and Type I errors of the four GWAS methods using Monte Carlo simulations. The results suggest that the multi-locus method is more powerful than the single-locus method and a combination of these multi-locus methods could help improve the detection power of GWAS.",2018,Frontiers in Plant Science
"Thalassomonhystera traesti n.sp., Eumonhystera andrassyi and three Monhystrella species (Monhysteridae: Nematoda) from Li River, China","A new Thalassomonhystera species, i.e. T. traesti n.sp., and a new subspecies, Monhystrella lepidura chinensis n. subsp., together with Eumonhystera andrassyi (BirÃ³, 1969) AndrÃ¡ssy, 1981, Monhystrella macrura (de Man, 1880) AndrÃ¡ssy, 1981 and Monhystrella iranica Schiemer, 1965 are described from Li River at Guiling, China. Thalassomonhystera traesti n.sp. is characterised by a combination of the following characters: expanded lip region, large and anteriorly situated amphids, prominent inner labial sensilla, and slender spicules and tube-like gubernaculum in males. Monhystrella lepidura chinensis n. subsp. belongs to Monhystrella lepidura (AndrÃ¡ssy, 1963) AndrÃ¡ssy, 1968 but differs from the three hitherto described subspecies in its possession of a pharynx that posteriorly expands into a double bulb. Monhystrella macrura, M. iranica and Eumonhystera andrassyiare reported here for the first time from China.",2004,Hydrobiologia
Sequential parallel LASSO models for eQTL analysis,"The availability of large-scale genomic and transcriptomic data on populations makes it necessary to perform computationally intensive expression quantitative trait locus (eQTL) analysis. Modeling in a sparse learning framework, LASSO based tools are powerful for eQTL analysis. However, classical LASSO becomes limited for big genomic data. We thus propose two novel methods, namely sequential LASSO and parallel LASSO, to conduct eQTL analysis for datasets of ultra-high dimension. We theoretically prove the consistency of our methods under mild conditions and perform extensive simulations on synthetic data to validate our methods. We also apply our methods to a real human genomics database demonstrate the application of our method.",2015,
Comparison of predictive modeling approaches for 30-day all-cause non-elective readmission risk,"BackgroundThis paper explores the importance of electronic medical records (EMR) for predicting 30-day all-cause non-elective readmission risk of patients and presents a comparison of prediction performance of commonly used methods.MethodsThe data are extracted from eight Advocate Health Care hospitals. Index admissions are excluded from the cohort if they are observation, inpatient admissions for psychiatry, skilled nursing, hospice, rehabilitation, maternal and newborn visits, or if the patient expires during the index admission. Data are randomly and repeatedly divided into fitting and validating sets for cross validations. Approaches including LACE, STEPWISE logistic, LASSO logistic, and AdaBoost, are compared with sample sizes varying from 2,500 to 80,000.ResultsOur results confirm that LACE has moderate discrimination power with the area under receiver operating characteristic curve (AUC) around 0.65-0.66, which can be improved to 0.73-0.74 when additional variables from EMR are considered. These variables include Inpatient in the last six months, Number of emergency room visits or inpatients in the last year, Braden score, Polypharmacy, Employment status, Discharge disposition, Albumin level, and medical condition variables such as Leukemia, Malignancy, Renal failure with hemodialysis, History of alcohol substance abuse, Dementia and Trauma. When sample size is small (â‰¤5000), LASSO is the best; when sample size is large (â‰¥20,000), the predictive performance is similar. The STEPWISE method has a slightly lower AUC (0.734) comparing to LASSO (0.737) and AdaBoost (0.737). More than one half of the selected predictors can be false positives when using a single method and a single division of fitting/validating data.ConclusionsTrue predictors can be identified by repeatedly dividing data into fitting/validating subsets and referring the final model based on summarizing results. LASSO is a better alternative to the STEPWISE logistic regression, especially when sample size is not large. The evidence for adequate sample size can be explored by fitting models on gradually reduced samples. Our model comparison strategy is not only good for 30-day all-cause non-elective readmission risk predictions, but also applicable to other types of predictive models in clinical studies.",2016,BMC Medical Research Methodology
Compressive sensing radar imaging with perturbations,"Applying the theory of Compressive Sensing (CS) in radar always take kinds of perturbations into consideration, such as measurement noise, channel inference and radar system accuracy error. However, the performance of traditional Compressive Sensing Radar (CSR) is sensitivity to the above perturbations, which may make the performance of target information vector recovery degrade considerably. To solve the above problem, an iteration algorithm based on basis pursuit denoising (BPDN) and least-absolute shrinkage and selection operator (Lasso) is introduced. Firstly, the completely perturbed model of CSR is derived by considering the perturbations both in non-adaptive random measurement and sensing matrix. Secondly the corresponding optimization function is constructed. Since the above optimization problem is nonconvex, it is converted into two convex suboptimization functions to obtain the estimation of target information vector and perturbation vector. Simulations experimental results show that the proposed method performs better than classical CSR recovery approaches with smaller estimation error and better robustness against perturbation. (4 pages)",2013,
The biomechanical role of extra-axonemal structures in shaping the flagellar beat of Euglena,"We propose and discuss a model for flagellar mechanics in Euglena gracilis. We show that the peculiar non-planar shapes of its beating flagellum, dubbed â€œspinning lassoâ€, arise from the mechanical interactions between two of its inner components, namely, the axoneme and the paraflagellar rod. The spontaneous shape of the axoneme and the resting shape of the paraflagellar rod are incompatible. The complex non-planar configurations of the coupled system emerge as the energetically optimal compromise between the two antagonistic components. The model is able to reproduce the experimentally observed flagellar beats and their characteristic spinning lasso geometric signature, namely, travelling waves of torsion with alternating sing along the length of the flagellum.",2020,bioRxiv
Identification of the Statue near Potgul Vihara at Polonnaruva as Amoghapasa Avalokiteshvara Bodhisattva,"The statue near the Potgul Vihara at Polonnaruva has been considered as an excellent work of art. However, the identification of the statue has hitherto been ambiguous though it has been attempted to identify either as a king or a sage by various scholars with different perspectives. The traditional belief is that the statue is a depiction of the king Parakramabahu the Great who ruled the Island from the Polonnaruva kingdom. The object held on both hands of the statue has been considered as an ola book and the name assigned to the nearby monastery, Potgul Vihara (Monastic Library) is taken to reinforce this popular belief. Paranavitana argued in length in support of the popular belief, but interpreted the object held on hands as an â€˜inverted yokeâ€™ to symbolize the sovereignty. Some other scholars attempted to identify the statue as sages Pulasthi, Agasthi , Kapila and Karuvar Thevar with different arguments. The present writer understood that the statue must be understood in its Buddhist context and identified the statue as Amogapasa Avalokiteshvara Bodhisattva. The main point of this identification is that the object on the hand as a representation of the â€˜Pasaâ€™( Lasso) which is the principal symbol of the particular Bodhisattva. The miniature statue found at Panduvas Nuvara having a rope on both hands and later period statue at Urulevewatta Temple have been taken to support this identification. The mark behind the left shoulder of the statue is also identified as the lotus stroke which is a distinct mark of this Bodhisattva. The nearby monastery, Pothgul Vihara has been identified as a Mahayana Mandala with its unique plan and it possibly symbolizes the Pothalaka mountain where Avalokitheshvara abodes. Oral traditions related to Polonnaruva as a place associated with serpents has also been considered here as reminiscent of popular stories associated with Amogapasa .",2015,
InÃ©galitÃ© intra-mÃ©nage et genre au Burkina Faso: un test Ã©conomÃ©trique,"Based on the estimate of demand functions for adult goods and the evaluation of outlay equivalents, the present study suggests that, contrary to what is sometimes asserted, the hypothesis of a gender bias within the household - so that girls receive less than boys - seems more probable in Africa. Indeed, using the data from the 1994_95 household survey of the Burkina Faso, it is found that, for the whole of the goods consumed by the adults and whatever the demographic group considered, the equivalence ratios are largely more negative than those of the women. In this respect, disrimination is probably the most obvious story, considering of the differential of schooling according to the gender, the greatest precariousness of female labour market and the organisation of the burkinabe social system. Nevertheless, this aggregateed conclusion must be moderate. First of all, although the intrahousehold inequality can prevail independently of the sector, it couldbe more accentuated in countryside that in cities. Then, the analysis tends to show the presence of a gender bias in favor of boys, especially in northern regions and the West, and in a lesser extent, to Ouagadougou and Bobo_Dioulasso, zones that precisely shelter the most important proportions of Moslem population. Lastly, the observation of outlay equivalents shows that girls get less than boys in groups managed by the men. This phenomenon could be explained by the role of the head of household at the time of the decision-making, the demographic composition of female households favorable to the women and the role of old women whose proportion is important within the latter. Such results encourage to relativize the identification of the well_being of the individuals on the average standard of living of the household to which they belong, and could weaken the efficiency of poverty alleviation policies, based on the effective increase in the resources of the poorest households, independently of the intrahousehold allocation of resources. (Full text in French)",1998,
Research on Bayesian Model Averaging for Lasso Based on Analysis of Scientific Materials,"The Lasso (least absolute shrinkage and selection operator) estimates a vector of regression coeï¬ƒcients by minimizing the residual sum of squares subject to a constraint on the -norm of coeï¬ƒcient vector, which has been an attractive technique for regularization and variable selection. In this paper, we study the Bayesian Model Averaging(BMA) for Lasso, which accounts for the uncertainty about the best model to choose by averaging over multiple models. Experimental results on simulated data show that BMA has signiï¬cant advantage over the model selection method based on Bayesian information criterion (BIC).",2011,Advanced Materials Research
MATHEMATICAL ENGINEERING TECHNICAL REPORTS An Estimation Procedure for Contingency Table Models Based on the Nested Geometry,"We propose a geometrical method for estimating the parameters of contingency tables. Our methodâ€“bisector regression for contingency tablesâ€“is based on a nested structure of models. The nested structure represents the variables that are independent. This means that a model includes smaller models allowing stronger independence, which also means that more parameters are eliminated in smaller models. Our method estimates parameters corresponding to the interactions of lower orders after those of higher orders are estimated or eliminated. Bisector regression generates a sequence of parameter estimates, each element of which represents a model and an estimate. The length of the sequence is much smaller than the total number of models. We describe the algorithm and show examples. In this paper, contingency tables are considered. We introduce parametrization of multinomial distributions and propose an algorithm for estimating parameters. The proposed algorithm is bisector regression for contingency tables (BRCT). The main idea of BRCT comes from our previous works. In [6, 7], we proposed the bisector regression algorithm, which is an extension of least angle regression [4]. Least angle regression is an algorithm for parameter estimation, which is related to the l1-regularization method (lasso, [3, 5, 11, 12]). In problems of contingency tables, our interest is to estimate parameters corresponding to interactions between factors. Factors, or random variables, are qualitative variables. Parameters are separated into groups depending on how many factors are involved. We apply the main idea of bisector regression for generalized linear regression ([6]) and Gaussian graphical models [7] to these parameter groups. We provide âˆ—hirose@stat.t.u-tokyo.ac.jp",2012,
Robust Elastic-Net Subspace Representation,"Recently, finding the low-dimensional structure of high-dimensional data has gained much attention. Given a set of data points sampled from a single subspace or a union of subspaces, the goal is to learn or capture the underlying subspace structure of the data set. In this paper, we propose elastic-net subspace representation, a new subspace representation framework using elastic-net regularization of singular values. Due to the strong convexity enforced by elastic-net, the proposed method is more stable and robust in the presence of heavy corruptions compared with existing lasso-type rank minimization approaches. For discovering a single low-dimensional subspace, we propose a computationally efficient low-rank factorization algorithm, called FactEN, using a property of the nuclear norm and the augmented Lagrangian method. Then, ClustEN is proposed to handle the general case, in which the data samples are drawn from a union of multiple subspaces, for joint subspace clustering and estimation. The proposed algorithms are applied to a number of subspace representation problems to evaluate the robustness and efficiency under various noisy conditions, and experimental results show the benefits of the proposed method compared with existing methods.",2016,IEEE Transactions on Image Processing
Smooth-Threshold Multivariate Genetic Prediction with Unbiased Model Selection.,"We develop a new genetic prediction method, smooth-threshold multivariate genetic prediction, using single nucleotide polymorphisms (SNPs) data in genome-wide association studies (GWASs). Our method consists of two stages. At the first stage, unlike the usual discontinuous SNP screening as used in the gene score method, our method continuously screens SNPs based on the output from standard univariate analysis for marginal association of each SNP. At the second stage, the predictive model is built by a generalized ridge regression simultaneously using the screened SNPs with SNP weight determined by the strength of marginal association. Continuous SNP screening by the smooth thresholding not only makes prediction stable but also leads to a closed form expression of generalized degrees of freedom (GDF). The GDF leads to the Stein's unbiased risk estimation (SURE), which enables data-dependent choice of optimal SNP screening cutoff without using cross-validation. Our method is very rapid because computationally expensive genome-wide scan is required only once in contrast to the penalized regression methods including lasso and elastic net. Simulation studies that mimic real GWAS data with quantitative and binary traits demonstrate that the proposed method outperforms the gene score method and genomic best linear unbiased prediction (GBLUP), and also shows comparable or sometimes improved performance with the lasso and elastic net being known to have good predictive ability but with heavy computational cost. Application to whole-genome sequencing (WGS) data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) exhibits that the proposed method shows higher predictive power than the gene score and GBLUP methods.",2016,Genetic epidemiology
Absolute penalty and shrinkage estimation strategies in linear and partially linear models with correlated errors,"In this dissertation we propose shrinkage estimators and absolute penalty estimators (APEs) in linear models, partially linear models (PLM) and quasi-likelihood models. We study the asymptotic properties of shrinkage estimators both analytically and through simulation studies, and compare their performance with APEs. In Chapter 2, we propose shrinkage estimators for a multiple linear regression with first order random coefficient autoregressive (RCAR(1)) error term. We also present two APEs for this models which are modified versions of lasso and adaptive lasso estimators. We compare the performance of shrinkage estimators and APEs through the mean squared error criterion. Monte Carlo studies were conducted to compare the estimators in two situations: when p > n and when p < n. A data example is presented to illustrate the usefulness of the suggested methods. In Chapter 3, we develop shrinkage estimators for a PLM with RCAR(1) error term. The nonparametric function is estimated using a kernel function. We also compare the performance of shrinkage estimators with a modified version of lasso for correlated data. Monte Carlo studies were conducted to compare the behavior of the proposed estimators. A data example is presented to illustrate the application of the suggested methods. In Chapter 4, we propose pretest and shrinkage estimators for quasi-likelihood models. We investigate the asymptotic properties of these estimators both analytically and through simulation studies. We also apply a lasso estimator and compare its performance with the other proposed estimators.",2013,
The Strong Screening Rule for SLOPE,"Extracting relevant features from data sets where the number of observations (n) is much smaller then the number of predictors (p) is a major challenge in modern statistics. Sorted L-One Penalized Estimation (SLOPE)â€”a generalization of the lassoâ€”is a promising method within this setting. Current numerical procedures for SLOPE, however, lack the efficiency that respective tools for the lasso enjoy, particularly in the context of estimating a complete regularization path. A key component in the efficiency of the lasso is predictor screening rules: rules that allow predictors to be discarded before estimating the model. This is the first paper to establish such a rule for SLOPE. We develop a screening rule for SLOPE by examining its subdifferential and show that this rule is a generalization of the strong rule for the lasso. Our rule is heuristic, which means that it may discard predictors erroneously. We present conditions under which this may happen and show that such situations are rare and easily safeguarded against by a simple check of the optimality conditions. Our numerical experiments show that the rule performs well in practice, leading to improvements by orders of magnitude for data in the p n domain, as well as incurring no additional computational overhead when n p. We also examine the effect of correlation structures in the design matrix on the rule and discuss algorithmic strategies for employing the rule. Finally, we provide an efficient implementation of the rule in our R package SLOPE.",2020,
Attribute Efficient Linear Regression with Distribution-Dependent Sampling,"We consider a budgeted learning setting, where the learner can only choose and observe a small subset of the attributes of each training example. We develop efficient algorithms for Ridge and Lasso linear regression, which utilize the geometry of the data by a novel distribution-dependent sampling scheme, and have excess risk bounds which are better a factor of up to O(âˆšd/k) over the state-of-the-art, where d is the dimension and k + 1 is the number of observed attributes per example. Moreover, under reasonable assumptions, our algorithms are the first in our setting which can provably use less attributes than full-information algorithms, which is the main concern in budgeted learning. We complement our theoretical analysis with experiments which support our claims.",2015,
A weighted nearest mean classifier for sparse subspaces,"In this paper we focus on high dimensional data sets for which the number of dimensions is an order of magnitude higher than the number of objects. From a classifier design standpoint, such small sample size problems have some interesting challenges. First, in any subspace with as many dimensions as objects the data set can be separated with an almost arbitrary linear hyperplane. Second, another important issue is to determine which features are responsible for the phenomenon under consideration. This problem comes down to finding as few features as possible that still can discriminate the classes involved. To attack these problems, we propose the LESS (lowest error in a sparse subspace) classifier. The LESS classifier is a weighted nearest mean classifier that efficiently finds linear discriminants in sparse subspaces, where the subspace is found automatically. In the experiments we compare LESS to related state-of-the-art classifiers like among others linear ridge regression with the LASSO and the support vector machine. It turns out that LESS performs competitively while it uses the fewest features.",2005,2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)
Directing Power Towards Subspaces of the Alternative Hypothesis,"This paper treats two problems in high-dimensional testing that have received attention in the recent literature. The first problem is that tests based on a quadratic statistic (such as the Wald statistic) lose power against subspaces of the alternative hypothesis as the dimension of the parameter vector of interest increases. The second problem is that the Wald statistic is not defined in high-dimensional settings, as it requires an invertible sample covariance matrix. I simultaneously address these issues by generalizing the Wald statistic to a statistic that is large in a subspace of the alternative hypothesis chosen by the econometrician. The existence of the statistic depends on a restricted eigenvalue condition that is tied directly to the size of the subspace. I show that if the conventional sample covariance matrix is used, then the statistic can be computed using linear regression with a constant dependent variable, where coefficient vector is restricted to the subspace of interest. As a demonstration, I consider subspaces that contain sparse or nearly-sparse vectors. For these cases, the computation reduces to $\ell_0$-regularized regression (best subset selection) and $\ell_1$-regularized regression (Lasso), respectively.",2019,
The Graphical Lasso: New Insights and Alternatives,"The graphical lasso [5] is an algorithm for learning the structure in an undirected Gaussian graphical model, using â„“1 regularization to control the number of zeros in the precision matrix Î˜ = Î£-1 [2, 11]. The R package GLASSO [5] is popular, fast, and allows one to efficiently build a path of models for different values of the tuning parameter. Convergence of GLASSO can be tricky; the converged precision matrix might not be the inverse of the estimated covariance, and occasionally it fails to converge with warm starts. In this paper we explain this behavior, and propose new algorithms that appear to outperform GLASSO. By studying the ""normal equations"" we see that, GLASSO is solving the dual of the graphical lasso penalized likelihood, by block coordinate ascent; a result which can also be found in [2]. In this dual, the target of estimation is Î£, the covariance matrix, rather than the precision matrix Î˜. We propose similar primal algorithms P-GLASSO and DP-GLASSO, that also operate by block-coordinate descent, where Î˜ is the optimization target. We study all of these algorithms, and in particular different approaches to solving their coordinate sub-problems. We conclude that DP-GLASSO is superior from several points of view.",2012,Electronic journal of statistics
"Structure, bioactivity, and resistance mechanism of streptomonomicin, an unusual lasso Peptide from an understudied halophilic actinomycete.","Natural products are the most historically significant source of compounds for drug development. However, unacceptably high rates of compound rediscovery associated with large-scale screening of common microbial producers have resulted in the abandonment of many natural product drug discovery efforts, despite the increasing prevalence of clinically problematic antibiotic resistance. Screening of underexplored taxa represents one strategy to avoid rediscovery. Herein we report the discovery, isolation, and structural elucidation of streptomonomicin (STM), an antibiotic lasso peptide from Streptomonospora alba, and report the genome for its producing organism. STM-resistant clones of Bacillus anthracis harbor mutations to walR, the gene encoding a response regulator for the only known widely distributed and essential two-component signal transduction system in Firmicutes. To the best of our knowledge, Streptomonospora had been hitherto biosynthetically and genetically uncharacterized, with STM being the first reported compound from the genus. Our results demonstrate that understudied microbes remain fruitful reservoirs forÂ the rapid discovery of novel, bioactive natural products.",2015,Chemistry & biology
Human intention recognition for robot walking helper using ANFIS,"In this paper, upon a passive robot walking helper developed in our laboratory, referred to as i-go, we attach the force-sensing grips to its two handles, which are used to effectively recognize the intention of the user. We use the Lasso model for user intention recognition, so that we can infer the relationship between the user' intention and measured pushing-pulling force. We also use the PCA algorithm to obtain the weighting for each intention. With the intention weighting identified, we then propose a fuzzy controller to generate proper braking force for i-go. In addition, to adapt to different users, we apply the ANFIS to tune the parameters of the fuzzy controller to achieve more accurate assistance.",2011,2011 8th Asian Control Conference (ASCC)
Selection and Fusion of Categorical Predictors with L0-Type Penalties:,"In regression modelling, categorical covariates have to be coded. Depending on the number of categorical covariates and on the number of levels they have, the number of coefficients can become huge. To reduce the model complexity, coefficients of similar categories should be fused and coefficients of non-influential categories should be set to zero. To this end, Lasso-type penalties on the differences of coefficients are a standard approach. However, the clustering/selection performance of this approach is sometimes poorâ€“especially when the adaptive weights are badly conditioned or not existing. In some situations, there is no incentive to cluster similar categories. To overcome this, a L0 penalty on the differences of coefficients is proposed, whereby the L0 â€˜normâ€™ is defined as the number of non-zero entries in a vector. The proposed penalty favours to find clusters of categories that share the same effect on the response variable while the estimation accuracy is comparable to Lasso-type penalties. Numerical experiments within the framework of generalized linear models are promising. For illustration, data on the unemployment rates in Germany is analyzed.",2015,Statistical Modelling
Deducing Kurdyka-{\L}ojasiewicz exponent via inf-projection,"Kurdyka-{\L}ojasiewicz (KL) exponent plays an important role in estimating the convergence rate of many contemporary first-order methods. In particular, a KL exponent of $\frac12$ is related to local linear convergence. Nevertheless, KL exponent is in general extremely hard to estimate. In this paper, we show under mild assumptions that KL exponent is preserved via inf-projection. Inf-projection is a fundamental operation that is ubiquitous when reformulating optimization problems via the lift-and-project approach. By studying its operation on KL exponent, we show that the KL exponent is $\frac12$ for several important convex optimization models, including some semidefinite-programming-representable functions and functions that involve $C^2$-cone reducible structures, under conditions such as strict complementarity. Our results are applicable to concrete optimization models such as group fused Lasso and overlapping group Lasso. In addition, for nonconvex models, we show that the KL exponent of many difference-of-convex functions can be derived from that of their natural majorant functions, and the KL exponent of the Bregman envelope of a function is the same as that of the function itself. Finally, we estimate the KL exponent of the sum of the least squares function and the indicator function of the set of matrices of rank at most $k$.",2019,arXiv: Optimization and Control
NetelomerickÃ© funkce ochrannÃ½ch proteinovÃ½ch komplexÅ¯ telomer,"This bachelorâ€™s thesis concentrates on the study of interaction partners and non-telomeric functions of the human shelterin complex. The human shelterin complex consists of six proteins which shape and safeguard telomeres through DNA binding. Shelterin binds telomeres, the natural chromosome ends, and forms them into lasso-like structures called T-loops. Shelterin maintains continuous replication of telomeres and protects telomeric ends from DNA repair mechanisms via multiple interactions with nuclear proteins. The first section of the thesis focuses on DNA damage response pathways and their inhibition on telomeres by the shelterin complex. Next part is dedicated to selected proteins cooperating with the shelterin complex on replication of telomeres. One chapter focuses on TERRA, Telomeric Repeat Containing RNA. The final part of this thesis describes non-telomeric functions of shelterin proteins, specifically TRF2 and Rap1. This bachelor thesis sums up the current state of knowledge about non-telomeric functions of proteins, which primarily take part in the regulation of telomere length.",2012,
Der Alkoholkranke als Patient,"SummaryChronic alcohol abuse is of significant clinical and economic relevance. A major part of internal medical pathology is associated with chronic alcoholism. 50% of all accidents with subsequent traumatic injuries are related to alcohol intake. Patients who are chronic alcohol abusers have prolonged hospital stays and substantial increases in postoperative morbidity.A sophisticated diagnosis of alcoholism within standard clinical routine is often difficult, and in most cases the treatment of alcohol-related diseases and complications is protracted and requires increased energy expenditure by the treating physicians. In surgical patients, chronic alcohol abuse is associated with a 3-to 4-fold risk of infections, sepsis, cardiac and bleeding complications. Therefore, the patients themselves, along with the general practitioner and an in-hospital interdisciplinary team should cooperate in medical and operative treatment in order to attain better clinical outcome. Each patient history should include a detailed assessment of the quantity of daily alcohol intake. Alcoholic diagnostic regimens including questionnaires (i.e. CAGE, AUDIT) in combination with specific laboratory markers (CDT, GGT, MCV), if implemented, could prove valuable, especially in cases where major surgical procedures are considered.Strict abstinence by alcoholic patients with organ pathology in medical and elective surgical settings as well as the prophylactic treatment of pre-operative alcohol withdrawal appear to be useful strategies to reduce the risk of complications. Short-term interventions are associated with reduced alcohol intake and decreased incidence of re-trauma.Considering the clinical relevance of alcohol abuse, sufficient screening, interventions, and open approaches to address alcohol problems should be important components of the daily clinical routine in outpatient clinics, emergency rooms, in GPsâ€™ offices and in general hospitals.ZusammenfassungDie Alkoholkrankheit hat eine hohe klinische und Ã¶konomische Relevanz fÃ¼r alle Disziplinen. Ein GroÃŸteil internistischer Krankheitsbilder ist alkoholassoziiert. Die HÃ¤lfte aller UnfÃ¤lle mit Traumafolgen sind bedingt durch Alkohol. Alkoholkranke Patienten haben eine verlÃ¤ngerte Krankenhausverweildauer und eine signifikant hÃ¶here postoperative MorbiditÃ¤t.Eine differenzierte Diagnose im klinischen Alltag gestaltet sich oft schwierig und die Behandlung der alkoholassoziierten Erkrankungen sowie Komplikationen sind langwierig und mit erhÃ¶htem Aufwand verbunden. In der operativen Medizin treten in Zusammenhang mit chronischem Alkoholmissbrauch Infektionen, Sepsis, kardiale Komplikationen und Blutungen 3â€“4-fach hÃ¤ufiger auf. Insbesondere gilt daher, durch suffiziente prÃ¤operative Vorbereitung unter Einbeziehung des Patienten, des Hausarztes und eines interdisziplinÃ¤ren Teams im stationÃ¤ren Bereich die Versorgung Alkoholkranker zu verbessern. Eine sorgfÃ¤ltige Erhebung des Alkoholkonsumverhaltens sollte wichtiger Teil einer jeden Anamnese sein. Der Einsatz von FragebÃ¶gen (CAGE, AUDIT) hat sich in Kombination mit Alkohollabormarkern (CDT, GGT, MCV) in der klinischen Routine bewÃ¤hrt.Eine strikte Abstinenz bei OrganschÃ¤den in der Inneren Medizin sowie vor elektiven, chirurgischen Eingriffen und die entzugsprophylaktische Behandlung von alkoholkranken Patienten mit Operationen scheinen sinnvolle prÃ¤ventive MaÃŸnahmen zur Reduktion des Risikos zu sein. Kurzinterventionen sind mit einer Reduktion des Alkohokonsums assoziiert und senken die HÃ¤ufigkeit eines erneuten Traumas.In Anbetracht der Relevanz von Alkoholmissbrauch sollten gezieltes Screening, Interventionen und das bewusste Thematisieren des Alkoholproblems tÃ¤gliche Routine in Ambulanzen, Notaufnahmen, bei niedergelassen Kollegen und in AllgemeinkrankenhÃ¤usern sein.",2009,Wiener Klinische Wochenschrift
Building a Domain Knowledge Base from Wikipedia: a Semi-supervised Approach,"Knowledge bases are becoming indispensable to software engineering and knowledge engineering. However, the existing domain knowledge bases are always artificially construct- ed and small-scale. In this paper, we propose a semi-supervised approach to domain concepts detection and software engineering knowledge base construction from Wikipedia. First, the approach selects domain relevant tags from Stackoverflow. Then, it matches Wikipedia entities and expands the concept set through an improved label propagation algorithm. A rule-based method is designed to discover semantic relations including relate, subclassOf and equal by analyzing structural information of Wikipedia. A relation derivation mechanism is presented to optimize the relation set. We finally construct SEBase, a domain- specific knowledge base of software engineering. Experimental results show the high accuracy of the integrated concepts and relations. Compared with other knowledge bases, SEBase has the widest coverage of concepts and relations in software engineering.",2016,
Control of Large-Scale Systems through Dimension Reduction,"Automated physical resource management of large-scale Internet Technology (IT) systems requires dynamic configuration of both application-level and system-level parameters. The existence of large number of tunable parameters makes it difficult to design a feedback controller that adjusts these parameters effectively in order to achieve application-level performance targets. In this paper, we introduce a new approach for simplified control architecture of large-scale IT systems based on dimension reduction techniques. It combines online selection of critical control knobs through LASSO-a powerful L1-constrained fitting method/Compressive Sensing (CS)-a L1-optimization method, and adaptive control of the identified knobs. The latter relies on the online estimation of the input-output model with the selected control knobs using the recursive least square (RLS) method and a self-tuning linear quadratic (LQ) optimal controller for output regulation. The results of both a numerical simulation in Matlab and a realistic case are presented to demonstrate the effectiveness of our approach.",2015,IEEE Transactions on Services Computing
Generation of disease-specific induced pluripotent stem cells from Alzheimer's disease patients,"s / Neuroscience Research 68S (2010) e223â€“e334 e305 own. We previouy reported that two types of AICD were existed. One was soluble and easily degraded form, and the other was membrane associated form. Therfore, we speculate that the accumulation of membrane associated AICD including APP C-terminal fragments may be toxic. In this study, to clear the relationship between the accumulation of AICD and toxic effects, we analzed the metabolism of AICD and the affect of AICD accumulation in cultured cells using proteomic methods. We found that APP C-terminal fragments was degraded in both gamma-secretase pathway and lysosomal pathway. On the proteomic analysis of cultured cells expressing AICDs or cultured cells with gamma-secretase inhibitor treatment, we found that nuclear-related proteins and vesicular trafficking-related proteins reduced in cultured cells expressing membrane-asscociated AICD. We will report and discuss the influence of AICDs accumulation in cultured cells. doi:10.1016/j.neures.2010.07.1352 P2-n12 Generation of disease-specific induced pluripotent stem cells from Alzheimerâ€™s disease patients Naoki Yahata 1 , Harushisa Inoue 1,2, Shiho Kitaoka 1,2, Kayoko Tsukita 1,2, Takayuki Kondo 3, Naohiro Egawa 1,3, Isao Asaka 1,2, Kazutoshi Takahashi 1,2, Tatsutoshi Nakahata 1, Shinobu Kawakatsu 4, Ryosuke Takahashi 3, Takashi Asada 2,5, Shinya Yamanaka 1 1 CiRA, iCeMS, Kyoto University 2 JST-CREST 3 Graduate School of Med., Kyoto University 4 Department of Psychiatry, Yamagata University School of Medicine 5 Department of Neuropsychiatry, University of Tsukuba Alzheimerâ€™s disease (AD) is a neurodegenerative disorder of the central nervous system which causes progressive memory and cognitive decline during middle to late adult life. The cell death mechanisms and therapeutic intervention for AD have been tested by transgenic rodent models. However, these models not fully represent the human condition. Induced pluripotent stem (iPS) cells, which show striking similarities to embryonic stem cells, can now be derived from human adult somatic tissues and have the capacity to be lineage restricted into various neuronal subtypes. Furthermore, establishment of disease-specific human cortical neurons and human cell-based AD model in vitro is crucial for investigation of the disease mechanism and drug discovery. We generated disease-specific iPS cells from patients with AD. Dermal fibroblasts from the patients were transduced with either four or three reprogramming factors, followed by emergence of putative iPS cell colonies after a few weeks. We evaluated their similarity to ES cells by checking the expression of the ES cellassociated antigens. Next, we examined the pluripotency of iPS cells by teratoma formation and embryoid body (EB) differentiation in vitro. Disease-specific iPS cells from AD patients possess properties of ES cells with patient-specific genetic information and may contribute to explore the pathogenesis of AD. doi:10.1016/j.neures.2010.07.1353 P2-n13 Microarray profiling of gene expression in the aging monkey brain Sayuri Higaki 1 , Akira Sato 2, Toshio Kojima 2,3, Takao Oishi 1 1 Sect Systems Neurosci, Primate Res Inst, Kyoto Univ, Inuyama 2 Computational Systems Biol Res Group, RIKEN, Yokohama 3 Res Equipment Center, Hamamatsu Univ Sch of Med, Hamamatsu Aging of the primate proceeds slowly and is characterized by prominent senescence, i.e., prolonged survival after reproductive years. To further our understanding of the characteristic aging process of the primate brain, we conducted DNA microarray analysis of Brodmannâ€™s area 46 (A46) and hippocampus in aged monkeys, because these areas are thought to be important for the process of learning and memory. Monkeys (n = 24) were assigned into 4 groups based on age (young; mean age 10.0 and aged; mean age 26.3) and sex (female and male). RNA isolated from 48 brain tissues was applied to the 4 Ã— 44K Rhesus Monkey Oligo Microarrays (Agilent). For 1205 genes expressed differentially more than 1.5 fold between young and aged monkey hippocampus or A46, we employed GSEA (Gene Set Enrichment Analysis) to evaluate whether pre-defined set of genes shows statistically significant, concordant differences. In aged female hippocampus but not male hippocampus, homeostasis-related gene sets were significantly upregulated (FDR q-value < 0.25). The hyper-expression of genes encoding chemokine and complement proteins engaged in immunoregulatory and anti-inflammatory activity implies age-related inflammation or disease progression. Moreover, in aged female hippocampus and A46, gene set involved in neurological system process was significantly downregulated (FDR q-value < 0.25). The decreased expression of genes encoding neuropeptide Y, somatostatin, cortistatin, corticotropin releasing hormone and 5HT2A receptor may lead to neuronal hypofunction in these regions. On the other hand, male hippocampus and A46 did not present significant age-related differences in any gene sets. These sex differences in brain aging process may result from molecular and cellular deterioration caused by drastic change in hormonal dynamics in aged female monkeys. doi:10.1016/j.neures.2010.07.1354 P2-n14 tert-Butylhydroquinone protects dopaminergic neurons from MPP+ cytotoxicity primarily via normalization of glutathione levels in midbrain slice cultures Yukie Sato , Akinori Hisatsune, Yoichiro Isohama, Hiroshi Katsuki Dept Chemico-pharmacol Sci, Grad Sch Pharm Sci, Kumamoto Univ, Kumamoto Parkinson disease is characterized by selective loss of dopaminergic neurons in the midbrain, which leads to severe motor deficits including tremors and inability to initiate movement. Oxidative stress is implicated in the pathogenic events in this neurodegenerative disorder. Under conditions of increased oxidative stress, a transcription factor NF-E2-related factor (Nrf2) binds to antioxidant response element to induce expression of enzymes related to phase II detoxification and antioxidative defense. Thus, promotion of recruitment of Nrf2 can be a target of neuroprotective therapy that confers resistance to a variety of oxidative stress-related insults on neurons. Here we examined the effect of tert-butylhydroquinone (tBHQ), an activator of Nrf2, against of MPP+ cytotoxicity in rat midbrain slice cultures. Immunohistochemical examinations on tyrosine hydroxylase revealed that tBHQ (5â€“40 M) inhibited dopaminergic neuron loss induced by 48-h application of 30 M MPP+, in a concentration-dependent manner. Because Nrf2 activation leads to its translocation to the nucleus, we examined Nrf2 levels in nuclear fractions obtained from midbrain slice homogenates after drug treatment, by western blotting. tBHQ treatment increased Nrf2 accumulation in the nucleus in a concentration-dependent manner, which was accelerated in the presence of MPP+. We next examined possible involvement of glutathione synthesis and heme oxygenase-1 expression, two major pathways downstream of Nrf2 activation, in the neuroprotective effect of tBHQ. We found that tBHQ significantly increased glutathione content in midbrain slices, and that depletion of glutathione by buthionine sulfoximine abolished the protective effect of tBHQ against MPP+ cytotoxicity. On the other hand, inhibition of heme oxygenase by zinc protoporphyrin IX did not suppress the protective effect of tBHQ. These results suggest that tBHQ protects midbrain dopaminergic neurons via increase in glutathione synthesis. doi:10.1016/j.neures.2010.07.1355 P2-n17 Human DJ-1-specific transcriptional activation of the tyrosine hydroxylase gene Shizuma Ishikawa 1 , Takahiro Taira 2, Kazuko Takahashi-Niki 3, Takeshi Niki 1, Hiroyoshi Ariga 3, Sanae M.M. Iguchi-Ariga 1 1 Grad. Agr. Hokkaido University 2 Grad. Med. Yamanashi. University 3 Grad. Pharm. Sci. Hokkaido University Loss-of-functional mutation in the DJ-1 gene causes a subset of familial Parkinson disease. The mechanism underlying DJ-1-related selective vulnerability in the dopaminergic pathway is, however, not resolved. DJ-1 has multiple functions, including transcriptional regulation, and one of the transcriptional target genes for DJ-1 is the tyrosine hydroxylase (TH) gene whose product is a key enzyme for dopamine biosynthesis. It has been reported that DJ-1 is a neuroprotective transcriptional co-activator that sequesters a transcriptional co-repressor pyrimidine tract-binding protein associated splicing factor (PSF) from the TH gene promoter. In this study, we found that knockdown of human DJ-1 by small interference RNA in human dopaminergic cell lines attenuated the TH gene expression and L-DOPA production but that knockdown or knockout of mouse DJ-1 in mouse cell lines or in DJ-1 knockout mice did not affect such expression and activity of TH. Reporter assays using the human TH gene promoter linked to the luciferase gene showed that stimulation of TH promoter activity was observed in human but not mouse cells transfected with DJ-1. Although human and mouse DJ-1 were associated either with human or with mouse PSF, TH promoter activity inhibited by PSF was restored by human DJ-1 but not mouse DJ-1. Chromatin immunoprecipitation assays revealed that the complex of PSF with DJ-1 bound to the human but not mouse TH gene promoter. These results suggest a novel",2010,Neuroscience Research
Variable selection approach for zero-inflated count data via adaptive lasso,"This article proposes a variable selection approach for zero-inflated count data analysis based on the adaptive lasso technique. Two models including the zero-inflated Poisson and the zero-inflated negative binomial are investigated. An efficient algorithm is used to minimize the penalized log-likelihood function in an approximate manner. Both the generalized cross-validation and Bayesian information criterion procedures are employed to determine the optimal tuning parameter, and a consistent sandwich formula of standard errors for nonzero estimates is given based on local quadratic approximation. We evaluate the performance of the proposed adaptive lasso approach through extensive simulation studies, and apply it to analyze real-life data about doctor visits.",2014,Journal of Applied Statistics
Sparse Predictive Modeling for Bank Telemarketing Success Using Smooth-threshold Estimating Equations,"In this paper, we attempt to build and evaluate several predictive models to predict success of telemarketing calls for selling bank long-term deposits using a publicly available set of data from a Portuguese retail bank collected from 2008 to 2013 (Moro et al., 2014, Decision Support Systems). The data include multiple predictor variables, either numeric or categorical, related with bank client, product and social-economic attributes. Dealing with a categorical predictor variable as multiple dummy variables increases model dimensionality, and redundancy in model parameterization must be of practical concern. This motivates us to assess prediction performance with more parsimonious modeling. We apply contemporary variable selection methods with penalization including lasso, elastic net, smoothly-clipped absolute deviation, minimum concave penalty as well as the smooth-threshold estimating equation. In addition to variable selection, the smooth-threshold estimating equation can achieve automatic grouping of predictor variables, which is an alternative sparse modeling to perform variable selection and could be suited to a certain problem, e.g., dummy variables created from categorical predictor variables. Predictive power of each modeling approach is assessed by repeating cross-validation experiments or sample splitting, one for training and another for testing.",2015,Journal of the Japanese Society of Computational Statistics
Stable inversion-based multitrace deabsorption method for spatial continuity preservation and weak signal compensation,"ABSTRACTNonstationary seismic data can be expressed using a linear matrix-vector multiplication system derived from wave theory when anelastic effects of the earth can be quantified by the intrinsic quality factor (or Q) and Q is frequency independent in the seismic bandwidth. On the basis of the linear modeling system and singular value decomposition, we have assessed the stability using weights associated with the left singular vectors, data, and singular values, and we assessed the compensation/resolution limitation of inversion-based deabsorption using the right singular vectors. In addition, a stable inversion-based multitrace deabsorption method was developed by minimizing the l1-norm of coefficients in the frequency-wavenumber (f-k) domain of reflectivity subject to the time-domain nonstationary data misfit. The optimum deabsorption result can be obtained by sequentially solving a series of lasso subproblems until the stopping condition is reached. As the number of solving lasso subproblems increas...",2016,Geophysics
Robust PCA as Bilinear Decomposition With Outlier-Sparsity Regularization,"Principal component analysis (PCA) is widely used for dimensionality reduction, with well-documented merits in various applications involving high-dimensional data, including computer vision, preference measurement, and bioinformatics. In this context, the fresh look advocated here permeates benefits from variable selection and compressive sampling, to robustify PCA against outliers. A least-trimmed squares estimator of a low-rank bilinear factor analysis model is shown closely related to that obtained from an â„“0-(pseudo)norm-regularized criterion encouraging sparsity in a matrix explicitly modeling the outliers. This connection suggests robust PCA schemes based on convex relaxation, which lead naturally to a family of robust estimators encompassing Huber's optimal M-class as a special case. Outliers are identified by tuning a regularization parameter, which amounts to controlling sparsity of the outlier matrix along the whole robustification path of (group) least-absolute shrinkage and selection operator (Lasso) solutions. Beyond its ties to robust statistics, the developed outlier-aware PCA framework is versatile to accommodate novel and scalable algorithms to: i) track the low-rank signal subspace robustly, as new data are acquired in real time; and ii) determine principal components robustly in (possibly) infinite-dimensional feature spaces. Synthetic and real data tests corroborate the effectiveness of the proposed robust PCA schemes, when used to identify aberrant responses in personality assessment surveys, as well as unveil communities in social networks, and intruders from video surveillance data.",2012,IEEE Transactions on Signal Processing
Local Linear Convergence of ISTA and FISTA on the LASSO Problem,"We use a model LASSO problem to analyze the convergence behavior of the ISTA and FISTA iterations, showing that both iterations satisfy local linear convergence rate bound when close enough to the solution. Using the observation that FISTA is an accelerated ISTA process, and a spectral analysis of the associated matrix operators, we show that FISTA's convergence rate can slow down as it proceeds, eventually becoming slower than ISTA. This observation leads to a proposed heuristic algorithm to take an ISTA step if it shows more progress compared to FISTA, as measured by the decrease in the objective function. We illustrate the results with some synthetic numerical examples.",2016,SIAM Journal on Optimization
Quantile regression and variable selection for the single-index model,"In this paper, we propose a new full iteration estimation method for quantile regression (QR) of the single-index model (SIM). The asymptotic properties of the proposed estimator are derived. Furthermore, we propose a variable selection procedure for the QR of SIM by combining the estimation method with the adaptive LASSO penalized method to get sparse estimation of the index parameter. The oracle properties of the variable selection method are established. Simulations with various non-normal errors are conducted to demonstrate the finite sample performance of the estimation method and the variable selection procedure. Furthermore, we illustrate the proposed method by analyzing a real data set.",2014,Journal of Applied Statistics
"Response of N, P and K on the growth and flowering of hippeastrum (Hippeastrum hybridum Hort.)","An experiment was conducted at the Horticultural Research Field of Bangabandhu Sheikh Mujibur Rahman Agricultural University (BSMRAU), Salna, Gazipur during September 2008 to May 2009 to determine the response of hippeastrum (cu. â€˜Apple Blassom) to different combinations of nitrogen, phosphorus and potassium levels. There were 14 treatment combinations comprising four levels of nitrogen viz. 0, 100, 200, and 300 kgha -1 ; five levels of phosphorus viz. 0, 200,300, 400 and 500 kgha -1 and five levels of potassium viz. 0, 100, 200, 300 and 400 kgha -1 with an exclusively Cowdung treatment at the rate of 10 tha -1 . The experiment was laid out in a Randomized Complete Block Design with three replications. The growth and flowering parameter of hippeastrum were significantly influenced by combined application of N, P & K.The highest values in respect of leaves per plant (8.6), leaf breadth (5.4 cm), number of plants per bulb (3.07), flower scape per plant (2.07), flowers per scape (4.2), length and diameter of flower (14 cm x 13.83 cm), flower scape (43.33 cm x 29.37 cm) and flowering duration (10.7 days) were observed with N 200 P 400 K 300 . The same treatment showed earliness in days to flower scape emergence (172.3 days), days to flower bud appearance (185.3 days) and days to first flower open (189.3 days). The biggest flower (14.00 cm x 13.83 cm), longest flower scape (43.33 cm), maximum number of flowers per scape (4.20), and maximum flowering duration (11.5 days) were also exhibited by the treatment N 200 P 400 K 300 .The control treatment (N 0 P 0 K 0 ) recorded the lowest values except days to first leaf emergence, days to flower scape emergence, days to flower bud appearance and days to first flower open. Bangladesh J. Agril. Res. 41(1): 91-101, March 2016",2016,Bangladesh Journal of Agricultural Research
Probabilistic fiber tracking using a modified Lasso bootstrap method,"Diffusion MRI (dMRI) provides a noninvasive tool for investigating white matter tracts. Probabilistic fiber tracking has been proposed to represent the fiber structures as 3D streamlines while taking the uncertainty introduced by noise into account. In this paper, we propose a probabilistic fiber tracking method based on bootstrapping a multi-tensor model with a fixed tensor basis. The fiber orientation (FO) estimation is formulated as a Lasso problem. Then by resampling the residuals calculated using a modified Lasso estimator to create synthetic diffusion signals, a distribution of FOs is estimated. Probabilistic fiber tracking can then be performed by sampling from the FO distribution. Experiments were performed on a digital crossing phantom and brain dMRI for validation.",2015,2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)
Clinical Results Obtained by the Use of My Instrument for Collecting the Urine Separately from the Two Kidneys.,"ABSTRACT A description of my instrument for obtaining the urine separately from the two kidneys was published first in the Journal of the American MedicalAssociation, Jan. 29, 1898, and again in Medicine in April, 1898. The object of the present paper is to present a few clinical facts obtained by the use of the instrument, which demonstate its advantages, applicability and reliability,Case 1. â€”Mrs. D., age 31 years, American, without particular hereditary tendency. Except for present trouble she has always been a strong, active, healthy woman. About four years ago she began to have pain in the lumbar region. The pain was dull and intermittent and increased by violent exercise such as dancing, driving or riding in the cars. The attacks of pain increased in frequency and severity and in a year or two the urine after exercise, particularly dancing, was very dark in color and there would be",1898,JAMA
"Locally epistatic genomic relationship matrices for genomic association, prediction and selection","As the amount and complexity of genetic information increases it is necessary that we explore some efficient ways of handling these data. This study takes the ""divide and conquer"" approach for analyzing high dimensional genomic data. Our aims include reducing the dimensionality of the problem that has to be dealt one at a time, improving the performance and interpretability of the models. We propose using the inherent structures in the genome; to divide the bigger problem into manageable parts. In plant and animal breeding studies a distinction is made between the commercial value (additive + epistatic genetic effects) and the breeding value (additive genetic effects) of an individual since it is expected that some of the epistatic genetic effects will be lost due to recombination. In this paper, we argue that the breeder can take advantage of some of the epistatic marker effects in regions of low recombination. The models introduced here aim to estimate local epistatic line heritability by using the genetic map information and combine the local additive and epistatic effects. To this end, we have used semi-parametric mixed models with multiple local genomic relationship matrices with hierarchical testing designs and lasso post-processing for sparsity in the final model and speed. Our models produce good predictive performance along with genetic association information.",2013,arXiv: Applications
Sparse calibration of an extreme Adaptive Optics system,"Adaptive optics systems are extensively used in astronomy to obtain high resolution pictures of stars and galaxies with ground telescopes. The crucial point is to shape deformable mirrors in order to compensate for the incoming wave distorted by the atmospheric turbulence. The calibration of the system is the cornerstone to obtain good performance. The next generation of adaptive optics system, eXtreme Adaptive Optics (XAO), will have a very large number of actuators and sensors (âˆ¼ 104) in order to guarantee high Strehl ratio and contrast levels; as such computational burden could become a serious bottleneck. For this reason several iterative methods have been proposed in the last decade. Since convergence and computational complexity of these methods depend on the sparsity of the interaction matrix (matrix projecting commands into measurements), the problem of calibrating an XAO system forcing the interaction matrix to be as sparse as possible is clearly important. In this paper we propose a method based on the LASSO regression algorithm that solves efficiently this problem.",2010,49th IEEE Conference on Decision and Control (CDC)
"Once MRSA, always MRSA? Setting up a hospital preadmission questionnaire.","Escherichia coli (4%). There were three cases of nosocomial infection due to group B streptococcus (3%): ventilator-associated pneumonia at the age of 30 days and BSIs at the ages of 15 and 25 days. Risk factors associated with nosocomial infection were birth weight ^1,000 g (ELBW), gestational age <30 weeks, prolonged hospital stay, use of umbilical or central line (UCL), administration of parenteral nutrition, and endotracheal intubation. Parenteral nutrition and use of UCL were independently associated with a higher risk of BSI. Prolonged endotracheal intubation was the only independent risk factor for ventilator-associated pneumonia (VAP). The Table shows the risk factors associated with nosocomial infection. UCLassociated BSI occurred only in ELBW infants. The UCLassociated BSI rate was 16.0 per 1,000 UCLdays, with a UCL utilization ratio of 0.06. Although ventilator use was more common and of longer duration among ELBW infants compared to VLBW infants, the VAP rate in both groups was similar: 9.0 and 8.7 per 1,000 ventilator days in ELBW and VLBW infants, respectively. The ventilator utilization rate was 0.28 (0.37 in ELBWs and 0.1 in VLBWs; P<.01). Mortality occurred in 16 (27%) of infected infants compared to 8 (8%) of noninfected infants. This study shows that nosocomial infection remains a cause of morbidity and mortality in infants weighing <1,500 g admitted to our HRN. The device-associated infection rates in our HRN were higher than the 50th percentile reported by NNIS, whereas the device-utilization ratios were lower. The UCLassociated BSI infection rate of 16.0 and VAP rate of 9.0 in ELBW infants in this study were s=75th percentile of the NNIS data, whereas the non-occurrence of UCL associated infection in VLBW infants fell at the 10th percentile. These observations suggest that the high infection rates may have been related more to infection control measures than device utilization. It is necessary to educate medical personnel on infection control and prevention. Infection control should be made part of the hospital orientation program for new residents, nurses, and other hospital employees. Infection control measures should continue to be monitored and discussed periodically with staff. There should also be an infection control nurse or officer who directly oversees the NICU. Isolation procedures also need to be followed strictly.",2000,Infection control and hospital epidemiology
"Microbial diversity of the hypersaline and lithium-rich Salar de Uyuni, Bolivia.","Salar de Uyuni, situated in the Southwest of the Bolivian Altiplano, is the largest salt flat on Earth. Brines of this athalassohaline hypersaline environment are rich in lithium and boron. Due to the ever- increasing commodity demand, the industrial exploitation of brines for metal recovery from the world's biggest lithium reservoir is likely to increase substantially in the near future. Studies on the composition of halophilic microbial communities in brines of the salar have not been published yet. Here we report for the first time on the prokaryotic diversity of four brine habitats across the salar. The brine is characterized by salinity values between 132 and 177 PSU, slightly acidic to near-neutral pH and lithium and boron concentrations of up to 2.0 and 1.4g/L, respectively. Community analysis was performed after sequencing the V3-V4 region of the 16S rRNA genes employing the Illumina MiSeq technology. The mothur software package was used for sequence processing and data analysis. Metagenomic analysis revealed the occurrence of an exclusively archaeal community comprising 26 halobacterial genera including only recently identified genera like Halapricum, Halorubellus and Salinarchaeum. Despite the high diversity of the halobacteria-dominated community in sample P3 (Shannon-Weaver index H'=3.12 at 3% OTU cutoff) almost 40% of the Halobacteriaceae-assigned sequences could not be classified on the genus level under stringent filtering conditions. Even if the limited taxonomic resolution of the V3-V4 region for halobacteria is considered, it seems likely to discover new, hitherto undescribed genera of the family halobacteriaceae in this particular habitat of Salar de Uyuni in future.",2017,Microbiological research
An integrated mRNA-lncRNA signature for relapse prediction in laryngeal cancer.,"Patients with laryngeal cancer with early relapse usually have a poor prognosis. In this study, we aimed to identify a multi-gene signature to improve the relapse prediction in laryngeal cancer. One microarray data set GSE27020 (training set, Nâ€‰=â€‰109) and one RNA-sequencing data set (validation set, Nâ€‰=â€‰85) were included into the analysis. In the training set, the microarray expression profile was re-annotated into an mRNA-long noncoding RNA (lncRNA) biphasic profile. Then, LASSO Cox regression model identified nine relapse-related RNA (eight mRNA and one lncRNA), and a risk score was calculated for each sample according to the model coefficients. Patients with high-risk showed poorer relapse-free survival than patients with low risk (hazard ratios (HR): 6.189, 95% confidence interval (CI): 3.075-12.460, Pâ€‰<â€‰0.0001). The risk score demonstrated good accuracy in predicting the relapse (area under time-dependent receiver-operating characteristic (AUC): 0.859 at 1 year, 0.822 at 3 years, and 0.815 at 5 years). The results were validated in the validation set (HR: 3.762, 95% CI: 1.594-8.877, Pâ€‰=â€‰0.011; AUC: 0.770 at 1 year, 0.769 at 3 years, and 0.728 at 5 years). The multivariate analysis reached consistent results after adjustment by multiple confounders. When compared with a 27-gene signature, a 2-lncRNA signature, and Tumor-Node-Metastasis stage, the risk score also showed better performance (Pâ€‰<â€‰0.05). In conclusion, we successfully developed a robust mRNA-lncRNA signature that can accurately predict the relapse in laryngeal cancer.",2019,Journal of cellular biochemistry
Combat and communication in the Everglades pygmy sunfish,"Abstract Changes in population density and resource patterning affect the aggressive behaviour of pygmy sunfish ( Elassoma everglaidei ) in many ways. Increases in density significantly reduced the proportion of fights directly over clumped prey, the likelihood of initiators winning contests or acquiring clumped prey, and the length of contests. Increases in prey dispersion also reduce the proportion of resource fights in low-and high-density populations, the greater tendency for subordinates to initiate fights directly over resources, the likelihood of initiators acquiring a contested prey item in lowdensity populations, and the length of contests. Such increases, however, increase the likelihood of initiators winning contests at moderate competitive levels, and increase the effectiveness of rapid sequential communication in populations that abandon territoriality. In addition, some of these findings, such as the inverse relationship between contest length and both prey dispersion and rank differential, are consistent with predictions of cost-benefit models of fighting behaviour, namely, that escalated contests become more likely as asymmetries in fighting ability decrease and asymmetries in resource valuation simultaneously increase.",1981,Animal Behaviour
"The sexual division of foraging labor : Biology, taboo, and gender politics","If women's biology is their economic destiny, nowhere is this destiny more inexorable than in anthropological representations of the sexual division of foraging labor. Physically weak, immobilized by nursing children, engrossed in the provisioning of reliable plant foods, redolent with odors that drive away the game, and subject finally to the axiom that specialization everywhere increases productivity, the foraging woman who gathers but does not hunt seems multiply inevitable, the product at once of logistical necessity and evolutionary selection. This essay develops a contrasting perspective, one consonant with Claude Meillassoux's (1981:20-21) observation that ""nothing in nature explains the sexual division of labor, nor such institutions as marriage, conjugality, or paternal filiation. All are imposed on women by constraint, all are therefore facts of civilization which must be explained, not used as explanations."" The first section of the essay questions both the inevitability of the sexual division of foraging labor and the logical and empirical adequacy of the existing physiological theories of it. Although they account persuasively for the relative non-viability of an exclusively female labor force of hunters, such theories explain absolutely nothing about why categorial divisions of foraging labor exist at all, why they are predicated on gender, or why women's hunting is almost universally either marginalized or proscribed. The second section relates the exclusion of women's hunting to taboos on women's use of hunting weapons and to a more general ideology of metaphysical antipathy between femaleness and the hunting profession in foraging societies. The third section considers the effects of these taboos and of the division of labor in producing asymmetric distributions of prestige and authority between the sexes. The",1996,Comparative Studies in Society and History
Constructions dÃ©terministes pour la rÃ©gression parcimonieuse,"Dans cette these nous etudions certains designs deterministes pour la regression parcimonieuse. Notre problematique est largement inspiree du "" Compressed Sensing "" ou l'on cherche a acquerir et compresser simultanement un signal de grande taille a partir d'un petit nombre de mesures lineaires. Plus precisement, nous faisons le lien entre l'erreur d'estimation et l'erreur de prediction des estimateurs classiques (lasso, selecteur Dantzig et basis pursuit) et la distorsion (qui mesure l'"" ecart "" entre la norme 1 et la norme Euclidienne) du noyau du design considere. Notre etude montre que toute construction de sous-espaces de faibles distorsions (appeles sous-espaces "" presque ""- Euclidiens) conduit a de "" bons "" designs. Dans un second temps, nous nous interessons aux designs construits a partir de graphes expanseurs desequilibres. Nous en etablissons de maniere precise les performances en termes d'erreur d'estimation et d'erreur de prediction. Enfin, nous traitons la reconstruction exacte de mesures signees sur la droite reelle. Nous demontrons que tout systeme de Vandermonde generalise permet la reconstruction fidele de n'importe quel vecteur parcimonieux a partir d'un tres faible nombre d'observations. Dans une partie independante, nous etudions la stabilite de l'inegalite isoperimetrique sur la droite reelle pour des mesures log-concaves.",2011,
Stranded and submerged sea-beach systems of southeast South Australia and the aeolian desert cycle,"Abstract The Late Cainozoic Era, as it affected much of continental Australia and its surrounding shelves, was pre-eminently a time of alternately intensifying and ameliorating â€˜aeolianâ€™ desert cycles. The successive windy desert phases correlate directly with repeated global low sea levels, which, in turn, relate to repeatedly culminating continental glaciations in the northern hemisphere. During the â€˜glacialâ€™ low sea-level phases, equatorward migration and intensification of the mid-latitudinal atmospheric low-pressure, cyclonic, zonal wind systems moving east along the southern Australian coast, overprinted themselves strongly upon the successively peaking aeolian desert dune-forming cycles. Along with comparably strengthened prevailing easterly winds in northern Australia, these resulted in an overall anticlockwise, and whorl-like pattern of the overall mass of longitudinal dunes about central Australia. The desert dunes are now extensively â€˜fixedâ€™ and sub-fossil. An equatorward shift of more than five degrees is apparent in the southerly stream of dune-forming prevailing winds as compared with those of the present â€˜interglacialâ€™ phase. Stratified â€˜loessial-limeâ€™, in wind-deposited calcrete soils, is distributed widely across southern Australia. It is the product of intensified desert wind-ablation when sea floors and beach deposits were widely exposed during repeated episodes of glacial low sea level. The spectacular Australia-wide lunette-lake systems with their characteristic, sub-fossil, down-wind mounds, also had their maximum development during these same windier, dune-forming, episodes at times of low sea level. Similar lunettes are also a feature of the Alaskan arctic coasts. Submerged lunettes are also readily visible on the sea floor, well below sea level, off Kingston, southeast South Australia. They hug the lee of a group of submerged aeolianite dunes in fashion characteristic of those preserved inland. During the windy desert phases, fluctuating sea level registered minima as revealed by aeolianite back-shore dune-drifts common to both systems. By contrast, the modern coastal dune-drifts in southeast South Australia cut obliquely across the direction of the foregoing aeolianite fossil drifts and belong to a modified â€˜interglacialâ€™ wind system. The successively peaking Australian desert dune cycles accordingly were, Pleistocene â€˜periglacialâ€™ phenomena in a broad, global, application of the term. During the glacial low sea-level phases, massive sea beach and back-shore dune deposits were emplaced and consolidated respectively as calcarenite beach-rock and â€˜aeolianiteâ€™. They were preserved serially about the existing southeast coast of South Australia by virtue of progressive regional arch uplift and an almost complete absence of surface drainage across a Tertiary limestone, karst, topography. At higher elevations, a parallel sequence of â€˜interglacialâ€™ sea beaches was stranded still further inland. Their back-shore dunes have cores of aeolian sands. Altitudinal separation between the foregoing two sequences averages 100â€“120 m. Back from southern coasts, and generally across the continent, multilayered aeolianites, shelly calcarenites and calcrete to podsolic soils built up thick accumulations that attest repeated climatic fluctuations. These, along with the foregoing remarkable, dual sequences of stranded and/or submerged coastal sea-beaches and the thalassostatic sedimentary deposits of the lower Murray River Basin, and elsewhere, confirm repeated sea-level oscillations of approximately 100â€“120 m amptitude. Together, they provide an almost continuous â€˜Pleistoceneâ€™ record. In all, approximately 30 major, Quaternary, sea-level oscillations are recorded in southeastern South Australia. They indicate a major and continuing cyclic control that acted throughout the Pleistocene Ice Age. Astronomic cycles, dominated particularly by the varying obliquity of the eclyptic (earth's axial tilt), and the precession of the equinoxes, appear primarily responsible. Milankovitch-type astronomic curves almost certainly apply. Time separation of the principal coasts accordingly approximate 20,000 year intervals, and the system as a whole spans approximately 900,000 years. Presumably, this represents the whole of the Pleistocene Ice Age.",1979,Sedimentary Geology
"Seroprevalence of syphilis among women attending urban antenatal clinics in Burkina Faso, 1995-8. The DITRAME Study Group. DIminunation de la TRAnsmission MÃ¨re-Enfant.","OBJECTIVES
To describe annual trends in syphilis seroprevalence and to identify risk factors of syphilis among pregnant women receiving antenatal care in Bobo-Dioulasso, Burkina Faso.


METHODS
Women were recruited between January 1995 and July 1998 in three antenatal clinics where counselling and HIV testing services had been established in the context of a trial evaluating a short course of zidovudine to reduce mother to child transmission of HIV (ANRS 049 trial). Sociodemographic variables were collected during HIV pretest counselling sessions. Syphilis diagnosis was considered when serum was positive with both rapid plasma reagin and Treponema pallidum haemagglutination assay (TPHA) tests.


RESULTS
Overall, 10,980 pregnant women were screened. Syphilis seroprevalence was 0.24% (95% confidence interval (CI): 0.15-0.35) without changes over time. HIV prevalence was 8.8% (CI: 8.3-9.3). In a multivariable analysis, having casual sex partners (odds ratio (OR) = 4.48; CI: 1.62-12.38), being HIV seropositive (OR = 2.62; CI: 1.02-6.74), and being illiterate (OR = 3.78; CI: 1.24-11.48) were independent risk factors for syphilis infection.


CONCLUSIONS
This study suggests low syphilis seroprevalence in this city of Burkina Faso. Sexually transmitted disease programmes should be reinforced to offer free access to syphilis screening and treatment in order to eliminate this disease, in coordination with HIV prevention and care.",2000,Sexually transmitted infections
Bayesian generalized fused lasso modeling via NEG distribution,"Abstract The fused lasso penalizes a loss function by the L1 norm for both the regression coefficients and their successive differences to encourage sparsity of both. In this paper, we propose a Bayesian generalized fused lasso modeling based on a normal-exponential-gamma (NEG) prior distribution. The NEG prior is assumed into the difference of successive regression coefficients. The proposed method enables us to construct a more versatile sparse model than the ordinary fused lasso using a flexible regularization term. Simulation studies and real data analyses show that the proposed method has superior performance to the ordinary fused lasso.",2016,Communications in Statistics - Theory and Methods
Locating mental toughness in factor models of personality,"Abstract We examined the degree to which two factor models of personality capture mental toughness. We focused on item and facet-level correlates of mental toughness in three widely used personality inventories â€“ HEXACO and Hogan Personality Inventory (bright side personality) and Hogan Development Survey (dark side personality). US-based college students and NCAA athletes (Sample 1; Nâ€¯=â€¯285) and working adults (Sample 2; Nâ€¯=â€¯218) took the Sports Mental Toughness Questionnaire and the HEXACO-60 (Sample 1) and the HPI and HDS (Sample 2). We used lasso regression with cross-validation to identify the HEXACO-60's items and HPI and HDS' facets predicting mental toughness. In Study 1 the strongest predictors of mental toughness were 12 items coming from the eXtraversion, Emotionality, and Conscientiousness scales. Item content examinations indicated that people scoring high on mental toughness tended to endorse items related to pushing for results, having elevated energy levels, and a high degree of self-confidence. In Study 2, emotional control, ambition, self-efficacy, creativity, and low anxiety emerged as the strongest facet correlates of mental toughness. Mental toughness is located between factors of the HEXACO model, but much more squarely aligned with Ambition in the HPI inventory.",2019,Personality and Individual Differences
Terrible Engines: A Speculative Turn in Recent Poetry and Fiction,"This article describes the emergence across several genresâ€”poetry, fiction, and the recently coined â€œconceptual writingâ€â€”of a â€œspeculativeâ€ subgenre that forgoes conventional literary content in favor of executing highly complex literary forms characterized by a preoccupation with number, the use of word sets, and a high degree of recursion in syntax and narrative structure. To this degree, these works are intent to expose the mathematical properties of language above aspiring to conventional realism and spontaneous expression. Nonetheless, through the frame of the philosophy of Quentin Meillassoux, a form of realism can be discerned in these writings, if only of a highly â€œspeculativeâ€ sort that wishes to limn the â€œunkthinkableâ€ in which a unique form of contingency (as opposed to the classical notion of necessity ) in a primary feature in the apparent coherence and orderliness of our present state of the universe.",2014,Comparative Literature Studies
"Gene expression and viral prodution in latently infected , resting CD 4 T cells in viremic versus aviremic HIV-infected individuals","The presence of HIV-1 in latently infected, resting CD4 T cells has been clearly demonstrated in infected individuals; however, the extent of viral expression and the underlying mechanisms of the persistence of HIV-1 in this viral reservoir have not been fully delineated. Here, we show that resting CD4 T cells from the majority of viremic patients are capable of producing cell-free HIV-1 spontaneously ex vivo. The levels of HIV-1 released by resting CD4 T cells were not significantly reduced in the presence of inhibitors of cellular proliferation and viral replication. However, resting CD4 T cells from the majority of aviremic patients failed to produce virions, despite levels of HIV-1 proviral DNA and cellassociated HIV-1 RNA comparable to viremic patients. The DNA microarray analysis demonstrated that a number of genes involving transcription regulation, RNA processing and modification, and protein trafficking and vesicle transport were significantly upregulated in resting CD4 T cells of viremic patients compared to those of aviremic patients. These results suggest that active viral replication has a significant impact on the physiologic state of resting CD4 T cells in infected viremic patients and, in turn, allows release of HIV-1 without exogenous activation stimuli. In addition, given that no quantifiable virions were produced by the latent viral reservoir in the majority of aviremic patients despite the presence of cell-associated HIV-1 RNA, evidence for transcription of HIV-1 RNA in resting CD4 T cells of aviremic patients should not necessarily be taken as direct evidence for ongoing viral replication during effective therapy.",2003,
Blue Flag Beaches-Bathers at Risk for Thalassogenic Diseases,"If beaches and water are polluted by wastewater, bathers are at risk for thalassogenic diseases such as diarrhea, skin infection, respiratory tract infection and hepatitis. The coastal water around the Cape Peninsula in South Africa is affected by polluted rivers that flow into the ocean, major shipping routes and wastewater outlets of human settlements. With high tide the water from offshore is brought onto the beach area and towards the coastline. Results: Sea water was collected from the eco-labeled Blue Flag beach, Clifton, Cape Town, during peak season in February and March 2013 at high tide to culture E. coli. The tested water quality was between 104 and 106, indicating that Clifton Blue Flag beach is affected by waste water. Foam and yellowish coloring of sand was associated with elevated E. coli counts. Data of water analysis are only displayed at Blue Flag beaches with a delay of two to three weeks. Conclusions: Swimming on a Blue Flag beach does not exclude time limited waste water pollution. Regular external and independent quality surveillance of Blue Flag beaches is mandatory, besides more rapid measurement and timely display of water analysis. Especially infants and people with HIV and/or Tb infections are at risk for health hazards as they are immune compromised. Swimmers should be aware of the risk they are taking when bathing in polluted water and know the signs of waste water pollution. Due to the high burden of HIV and Tb infection, further large scale studies are needed to evaluate the health effects for bathers besides the economic impact of improved wastewater treatment in South Africa.",2014,
Variational Inference for Quantile Rgression,"of the Thesis Variational Inference for Quantile Rgression by Bufei Guo A.M. in Statistics Washington University in St. Louis, 2019. Professor Nan Lin, Chair Quantile regression (QR) (Koenker and Bassett, 1978), is an alternative to classic linear regression with extensive applications in many fields. This thesis studies Bayesian quantile regression (Yu and Moyeed, 2001) using variational inference, which is one of the alternative methods to the Markov chain Monte Carlo (MCMC) in approximating intractable posterior distributions. The lasso regularization is shown to be effective in improving the accuracy of quantile regression (Li and Zhu, 2008). This thesis developed variational inference for quantile regression and regularized quantile regression with the lasso penalty. Simulation results show that variational inference is a computationally more efficient alternative to the MCMC, while providing a comparable accuracy.",2019,
Invited Commentary to Indirect Inguinal Hernia: Towards Less Invasive Surgery in Rural Conditions,"Leaving an indirect hernia sac in situ has long been an accepted practice in the repair of inguinal hernias and was advocated, for example, in the papers of Glassow and Wantz, among others. It is also a common practice among pediatric surgeons. The rationale is to avoid a potential injury to the vasculature that might cause testicular atrophy or chronic ischemic pain. Why not leave the distal sac in situ in all hernia repairs? There seems to be no adverse consequence to doing so and, in addition to the reasons cited above, leaving the sac behind would save some time during the operation. There may be a lesson for all of us in the practice of a rural surgeon in Africa. My first caveat is that rubbing the interior of the sac is unnecessary, provided the sac is opened on its anterior aspect. The peritoneal serosa of the sac is unlikely to be functional and, even if it were to secrete some fluid, the secretion would be absorbed by the surrounding tissues. A second caveat: The use of absorbable suture for the repair is a potential hazard. Success in a hernia repair depends both on the nature of the hernia and on the technique and the suture used for repair. A small to medium indirect hernia needs only high ligation of the sac. A larger indirect hernia, one involving much of the posterior wall of the inguinal canal, depends for a successful repair on persistence of sutures holding strong tissue margins together until ongoing healing is able to withstand the strain of sedentary activities (about 3 weeks) or greater physical exertion (about 6 weeks). It would have been helpful if the author had specified the â€˜â€˜resorbableâ€™â€™ suture material used, because there are considerable differences in maintenance of strength between the various absorbable sutures available today. Plain catgut holds only for a day or so, chromic catgut for perhaps a week, while complex glycopeptide sutures may persist for weeks to months. Use of the latter sutures would have a potential for success, but use of catgut might lead to recurrence. There are no follow-up data in this report, something perhaps difficult to arrange in rural Africa, but needed to evaluate this aspect of the authorâ€™s practice. In my view, braided nylon suture is better than silk or any of the slowly absorbed sutures, such as PDS, for repair of a groin hernia. Braided nylon causes less inflammation and maintains its strength in tissue longer than other sutures. For hospitals on a tight budget, spools of this thread are cheap and available in the nearest notions shop.",2006,World Journal of Surgery
Big Data as a Source of Statistical Information,"Big Data is an extremely interesting data source for statistics. Since more and more data is generated in our modern world and is digitally stored, it could certainly be used to replace traditional sources or provide additional information for official statistics. Especially given declines in survey response rates, information gathered from Big Data is an interesting addition. However, extracting statistically-relevant information from Big Data sources is not an easy task. In this paper the current state of the art of research on the use of Big Data for official statistics at Statistics Netherlands is described. The paper is based on the real world experiences of the authors obtained during these studies. The topics discussed are related to Big Data methodology, privacy and security concerns and the skills required for successfully employing Big Data. Introduction Big Data is a term that one hears more and more often at conferences, meetings and seminars. Since its first introduction in 1997, in a conference paper by Cox and Ellsworth (1997), it has really become a hot topic. This is understandable if one realizes that between the introduction of the term Big Data and the present, the world has changed from a â€˜data-poorâ€™ environment to a world in which data is abundant (Global Pulse, 2012). This is mainly due to the fact that during this period increasing amounts of data have been generated on the web and by sensors in the ever growing number of electronic devices surrounding us. Because of the ongoing decline in the costs of disk storage this data is no longer thrown away but remains stored. As such, Big Data has the potential to provide information on statisticallyrelevant populations at high frequency, at a high degree of granularity, and from a wide range of angles, narrowing both time and knowledge gaps. This enables the production of more relevant and timely statistics and can result in proxy indicators that enable richer, deeper insights into human experience than traditional sources of official statistics can (Glasson et al., 2013; Global Pulse, 2012). Anyone who is able to access and analyze Big Data could â€“ potentially â€“ extract meaning from them and gain a competitive edge. This realization has prompted many commercial companies to write white papers and blogs on the huge potential of Big Data. These stories, however, do not always withstand a rigorous scientific analysis and â€“ unfortunately â€“ tend to place the use and potential of Big Data near the edge of the scientific realm. We agree with Glasson et al. (2013), that Big Data has serious potential as it is a very interesting (secondary) data source for official 1 The views expressed in this paper are those of the authors and do not necessarily reflect the policies of Statistics Netherlands.",2014,
"Fossil record of Ephedra in the Lower Cretaceous (Aptian), Argentina","Fossil plants from the Lower Cretaceous (upper Aptian) of the La Cantera Formation, Argentina, are described. The fossils studied represent a leafy shooting system with several orders of articulated and striated axes and attached leaves with unequivocal ephedroid affinity. We also found associated remains of ovulate cones with four whorls of sterile bracts, which contain two female reproductive units (FRU). Ovulate cone characters fit well within the genus Ephedra. Special characters in the ovulate cones including an outer seed envelope with two types of trichomes, allowed us to consider our remains as a new Ephedra species. Abundant dispersed ephedroid pollen obtained from the macrofossil-bearing strata also confirms the abundance of Ephedraceae in the basin. The co-occurrence of abundant fossil of Ephedra (adapted to dry habitats) associated with thermophilic cheirolepideacean conifer pollen (Classopollis) in the unit would suggest marked seasonality at the locality during the Early Cretaceous. Furthermore, the floristic association is linked to dry sensitive rocks in the entire section. The macro- and microflora from San Luis Basin are similar in composition to several Early Cretaceous floras from the Northern Gondwana floristic province, but it may represent one of the southernmost records of an arid biome in South America.",2017,Journal of Plant Research
An expectationâ€“maximization algorithm for the Lasso estimation of quantitative trait locus effects,"The least absolute shrinkage and selection operator (Lasso) estimation of regression coefficients can be expressed as Bayesian posterior mode estimation of the regression coefficients under various hierarchical modeling schemes. A Bayesian hierarchical model requires hyper prior distributions. The regression coefficients are parameters of interest. The normal distribution assigned to each regression coefficient is a prior distribution. The variance parameter in the normal prior distribution is further assigned a hyper prior distribution so that the variance parameter can be estimated from the data. We developed an expectationâ€“maximization (EM) algorithm to estimate the variance parameter of the prior distribution for each regression coefficient. Performance of the EM algorithm was evaluated through simulation study and real data analysis. We found that the Jeffreysâ€™ hyper prior for the variance component usually performs well with regard to generating the desired sparseness of the regression model. The EM algorithm can handle not only the usual regression models but it also conveniently deals with linear models in which predictors are defined as classification variables. In the context of quantitative trait loci (QTL) mapping, this new EM algorithm can estimate both genotypic values and QTL effects expressed as linear contrasts of the genotypic values.",2010,Heredity
Electrical isolation of big veins by radiofrequency catheter ablation for the treatment of paroxysmal atrial fibrillation,"Objective The purpose of this study was to assess the methods and effects of radiofrequency catheter ablation(RFCA)on paroxysmal atrial fibrillation(PAF).Methods Thirty-six patients[male 24,famale 12,mean age(42.5Â±13.2)years]with PAF underwent RFCA.All patients underwent routine electrophysiological study,adopted one transseptal procedure,and Lasso mapping catheter and ablation catheter were positioned into target pulmonary vein ostium or superior vena cava.The earliest activation potential of pulmonary vein or caval vein during sinus rhythm and/or the shortest period between left or right atrium and pulmonary or caval vein potential during atrial pacing were the target point for ablation.Results Thirty-six patients with PAF were performed with RFCA.A total of 115 pulmonary or caval viens were ablated,including 34 left superior pulmonary veins,30 right superior pulmonary veins,22 left inferior pulmonary veins,17 right inferior pulmonary veins and 12 superior caval viens.Successful electrical isolation was obtained at the end of ablation procedure in 110 veins(95.6%),during follow-up of 3 to 22 months,27 patients(75.0%)were remained free of PAF or less recurrence without medication.Conclusion 95.6% big veins of the heart can be electrically disconnected from atria by RFCA in patients with PAF,the success rate is relatively high.",2005,Chinese Journal of Cardiac Arrhythmias
â€˜strange architectureâ€™: Ciaran Carson's Until Before After,"Ciaran Carson's Until Before After (2010), like many of Carson's recent books of poetry and prose, has an elaborate structure which does not obviously relate to the meaning and nature of the poetry in the volume. This essay suggests that it may be possible to â€˜unlockâ€™ meanings from the â€˜strange architectureâ€™ of Until Before After. Quentin Meillassoux's Le Nombre et La Sirene (2011) offers an example of a type of critical reading which pays attention to the intricacies (and numbers) of poetic form, in Meillassoux's case in a reading of Mallarmeâ€™s Coup de Des. Carson's Until Before After, in its unusual page constructions, use of partial sonnets, and potential hints at numerology, along with its allusions to Biblical and philosophical texts, can be read as being built around a pyramidal, mathematical form, which in turn is appropriate to its themes of death and resurrection.",2013,Irish University Review
Prediction of cardiac death after adenosine myocardial perfusion SPECT based on machine learning,"BackgroundWe developed machine-learning (ML) models to estimate a patientâ€™s risk of cardiac death based on adenosine myocardial perfusion SPECT (MPS) and associated clinical data, and compared their performance to baseline logistic regression (LR). We demonstrated an approach to visually convey the reasoning behind a patientâ€™s risk to provide insight to clinicians beyond that of a â€œblack box.â€MethodsWe trained multiple models using 122 potential clinical predictors (features) for 8321 patients, including 551 cases of subsequent cardiac death. Accuracy was measured by area under the ROC curve (AUC), computed within a cross-validation framework. We developed a method to display the modelâ€™s rationale to facilitate clinical interpretation.ResultsThe baseline LR (AUCâ€‰=â€‰0.76; 14 features) was outperformed by all other methods. A least absolute shrinkage and selection operator (LASSO) model (AUCâ€‰=â€‰0.77; pâ€‰=â€‰.045; 6 features) required the fewest features. A support vector machine (SVM) model (AUCâ€‰=â€‰0.83; pâ€‰<â€‰.0001; 49 features) provided the highest accuracy.ConclusionsLASSO outperformed LR in both accuracy and simplicity (number of features), with SVM yielding best AUC for prediction of cardiac death in patients undergoing MPS. Combined with presenting the reasoning behind the risk scores, our results suggest that ML can be more effective than LR for this application.",2018,Journal of Nuclear Cardiology
Support Localization and the Fisher Metric for off-the-grid Sparse Regularization,"Sparse regularization is a central technique for both machine learning (to achieve supervised features selection or unsupervised mixture learning) and imaging sciences (to achieve super-resolution). Existing performance guaranties assume a separation of the spikes based on an ad-hoc (usually Euclidean) minimum distance condition, which ignores the geometry of the problem. In this article, we study the BLASSO (i.e. the off-the-grid version of $\ell^1$ LASSO regularization) and show that the Fisher-Rao distance is the natural way to ensure and quantify support recovery, since it preserves the invariance of the problem under reparameterization. We prove that under mild regularity and curvature conditions, stable support identification is achieved even in the presence of randomized sub-sampled observations (which is the case in compressed sensing or learning scenario). On deconvolution problems, which are translation invariant, this generalizes to the multi-dimensional setting existing results of the literature. For more complex translation-varying problems, such as Laplace transform inversion, this gives the first geometry-aware guarantees for sparse recovery.",2019,ArXiv
