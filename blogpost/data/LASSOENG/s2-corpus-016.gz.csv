title,abstract,year,journal
The DFS Fused Lasso: Linear-Time Denoising over General Graphs,"The fused lasso, also known as (anisotropic) total variation denoising, is widely used for piecewise constant signal estimation with respect to a given undirected graph. The fused lasso estimate is highly nontrivial to compute when the underlying graph is large and has an arbitrary structure. But for a special graph structure, namely, the chain graph, the fused lasso---or simply, 1d fused lasso---can be computed in linear time. In this paper, we establish a surprising connection between the total variation of a generic signal defined over an arbitrary graph, and the total variation of this signal over a chain graph induced by running depth-first search (DFS) over the nodes of the graph. Specifically, we prove that for any signal, its total variation over the induced chain graph is no more than twice its total variation over the original graph. This connection leads to several interesting theoretical and computational conclusions. Denoting by $m$ and $n$ the number of edges and nodes, respectively, of the graph in question, our result implies that for an underlying signal with total variation $t$ over the graph, the fused lasso achieves a mean squared error rate of \smash{$t^{2/3} n^{-2/3}$}. Moreover, precisely the same mean squared error rate is achieved by running the 1d fused lasso on the induced chain graph from running DFS. Importantly, the latter estimator is simple and computationally cheap, requiring only $O(m)$ operations for constructing the DFS-induced chain and $O(n)$ operations for computing the 1d fused lasso solution over this chain. Further, for trees that have bounded max degree, the error rate of \smash{$t^{2/3} n^{-2/3}$} cannot be improved, in the sense that it is the minimax rate for signals that have total variation $t$ over the tree.",2017,J. Mach. Learn. Res.
Bayesian sparse graphical models and their mixtures using lasso selection priors,"We propose Bayesian methods for Gaussian graphical models that lead to sparse and adaptively shrunk estimators of the precision (inverse covariance) matrix. Our methods are based on lasso-type regularization priors leading to parsimonious parameterization of the precision matrix, which is essential in several applications involving learning relationships among the variables. In this context, we introduce a novel type of selection prior that develops a sparse structure on the precision matrix by making most of the elements exactly zero, in addition to ensuring positive definiteness -- thus conducting model selection and estimation simultaneously. We extend these methods to finite and infinite mixtures of Gaussian graphical models for clustered data using Dirichlet process priors. We discuss appropriate posterior simulation schemes to implement posterior inference in the proposed models, including the evaluation of normalizing constants that are functions of parameters of interest which result from the restrictions on the correlation matrix. We evaluate the operating characteristics of our method via several simulations and in application to real data sets.",2013,arXiv: Methodology
"InfÃ©rence statistique en grande dimension pour des modÃ¨les structurels. ModÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s parcimonieux, mÃ©thode PLS et polynÃ´mes orthogonaux et dÃ©tection de communautÃ©s dans des graphes.","Cette these s'inscrit dans le cadre de l'analyse statistique de donnees en grande dimension. Nous avons en effet aujourd'hui acces a un nombre toujours plus important d'information. L'enjeu majeur repose alors sur notre capacite a explorer de vastes quantites de donnees et a en inferer notamment les structures de dependance. L'objet de cette these est d'etudier et d'apporter des garanties theoriques a certaines methodes d'estimation de structures de dependance de donnees en grande dimension.La premiere partie de la these est consacree a l'etude de modeles parcimonieux et aux methodes de type Lasso. Apres avoir presente les resultats importants sur ce sujet dans le chapitre 1, nous generalisons le cas gaussien a des modeles exponentiels generaux. La contribution majeure a cette partie est presentee dans le chapitre 2 et consiste en l'etablissement d'inegalites oracles pour une procedure Group Lasso appliquee aux modeles lineaires generalises. Ces resultats montrent les bonnes performances de cet estimateur sous certaines conditions sur le modele et sont illustres dans le cas du modele Poissonien. Dans la deuxieme partie de la these, nous revenons au modele de regression lineaire, toujours en grande dimension mais l'hypothese de parcimonie est cette fois remplacee par l'existence d'une structure de faible dimension sous-jacente aux donnees. Nous nous penchons dans cette partie plus particulierement sur la methode PLS qui cherche a trouver une decomposition optimale des predicteurs etant donne un vecteur reponse. Nous rappelons les fondements de la methode dans le chapitre 3. La contribution majeure a cette partie consiste en l'etablissement pour la PLS d'une expression analytique explicite de la structure de dependance liant les predicteurs a la reponse. Les deux chapitres suivants illustrent la puissance de cette formule aux travers de nouveaux resultats theoriques sur la PLS . Dans une troisieme et derniere partie, nous nous interessons a la modelisation de structures au travers de graphes et plus particulierement a la detection de communautes. Apres avoir dresse un etat de l'art du sujet, nous portons notre attention sur une methode en particulier connue sous le nom de spectral clustering et qui permet de partitionner les noeuds d'un graphe en se basant sur une matrice de similarite. Nous proposons dans cette these une adaptation de cette methode basee sur l'utilisation d'une penalite de type l1. Nous illustrons notre methode sur des simulations.",2015,
A least square kernel machine with box constraints,"In this paper, we present a least square kernel machine with box constraints (LSKMBC). The existing least square machines assume Gaussian hyperpriors and subsequently express the optima of the regularized squared loss as a set of linear equations. The generalized LASSO framework deviates from the assumption of Gaussian hyperpriors and employs a more general Huber loss function. In our approach, we consider uniform priors and obtain the loss functional for a given margin considered to be a model selection parameter. The framework not only differs from the existing least square kernel machines, but also it does not require Mercer condition satisfiability. Experimentally we validate the performance of the classifier and show that it is able to outperform SVM and LSSVM on certain real-life datasets.",2008,2008 19th International Conference on Pattern Recognition
Peptide rope tricks,"Lariat or lasso peptides are a structurally unique family of ribosomally synthesized bioactive peptides produced by microbes. They range from 16 to 21 residues in size and are characterized by a post-translational modification in the form of a lactam bond between a conserved aspartic or glutamic acid and the peptide N-terminus, resulting in an 8 or 9 residue macrocycle, which is threaded by the C-terminal part of the peptide chain. This noose-like feature results in unique properties, including remarkable chemical and biological stability, suggesting that this bacterial rope trick may well provide an ideal new framework for the design of peptide based pharmaceuticals.",2010,Chimica Oggi-chemistry Today
The Comparasion of Total Tannins Containing of 8 Species Geranium of Dongbei,"Objective: Through this experiment,we will compare total tannins containing of 8 kind plants of Geranium of Dongbei.Method: Utilize HPLC to caculate total tannins containing of Geranium.Result: The total tannins containing of G.wilfordii is 1.71%;G.sibiricum is 0.71%;G.krameri is 1.57%;G.wlassowianum is 0.62%;G.eriostemon is 0.88%;G.paishanense is 0.029%;G.erianthum is 0.019%;G.dahuricum is 0.038%.Conclution: This optimized process is simple,stable,efficient and operate rational,it lay solid foundation for developing and utiliziung medical resource of Geranium.",2007,Chinese Archives of Traditional Chinese Medicine
"Utilisation de lâ€™analyse palynologique pour la reconstitution palÃ©oenvironnementale et palÃ©oclimatique des dÃ©pÃ´ts de lâ€™Albien des puits Offshore du bassin sÃ©dimentaire de CÃ´te dâ€™Ivoire, marge dâ€™Abidjan","This work presents the results of palynological analysis of the Albo-Cenomanian interval of two wells located on the Abidjan margin in the offshore sedimentary basin of Cote d'Ivoire. 
It aims to reconstruct deposition environments during this interval coinciding with the oceanic anoxic event (EAO1) recorded in the Atlantic. After classical chemical attacks with strong acids, the palynomorphs extracted from 114 cuttings samples were identified and counted. The results show that out of 9786 registered palynomorphs 5108 belong to the Y-3M well and 4678 to the Y-4M well. 
Quantitative analysis of spore groups, pollen grains (Classopollis, Ephedripites, Araucariacites), elateres and dinocysts revealed a predominantly continental (littoro-deltaic) depositional environment with marine incursions. This sedimentation occurred under a predominantly arid to semi-arid palaeoclimate under relatively humid conditions in some places. 
These palynological quantitative approaches will help to refine the deposit environment of the Albian in Ivory Coast.",2019,International journal of innovation and scientific research
The Exploited Child,"* 1. General Introduction - Bernard Schlemmer * Part 1: The Economic and Social Context of Child Labour * 2. Introduction: A History of Exploited Children in Europe - Alessandro Stella * Child Labour in the Current Economic System * 3. The Economy and Child Labour: An Overview - Claude Meillassoux * 4. Child Labour and the Export Sector in the Indian Carpet Industry - Mohini Gulrajani * 5. Growing up in Ghana: Deregulaton and the Employment of Children - Martin Verlet * 6. Living and Working Conditions: Child Labour in the Coal Mines of Colombia - Beatriz S. Cespedes Sastre and Maria-Isabel Zarama V Meyer * 7. Stigmatisation versus Identity: Child Street Workers in Mexico - Elvira Taracena and Maria-Luisa Tavera * Child Labour in Society * 8. Public Policy, Society and Child Labour - Francis Gendreau * 9. Why is Child Labour Tolerated? The Case of Brazil - Lia Fukui * 10. The Social Exclusion of Children in circumstances of Rapid Economic Growth: Working Children in Thailand - Chantana Banpasirichote * 11. The Public Policy Problem: Child Labour and the Law in India - Usha Ramanathan * 12. Debates on Poor Children in Brazil: Between Marginalisation and Premature Labour - Rosilene Alvim * Part 2: The Structure and Dynamics of Exploitation * 13. Introduction: Child Labour in the light of Bonded Labour - Michel Bonnet * The Domination of Fathers as the Typical Social Relationship * 14. Paternal Domination: The Typical Relationship Conditioning the Exploitation of Children - Alain Morice * 15. Child Employment in a Capitalist Labour Market: The British Case - Michael Lavalette * 16. Coffee Beans and the Seeds of Labour: Child Labour on Guatemalan Plantations - Charles-Edouard de Suremain * 17. The Exploitation of Apprentices in Togo - Yves Marguerat * 18. Apprenticeship in France: A Parallel Case in an Industrialised Society - Bernard Garet * From Socialisation through Work to Exploitation for a Profit * 19. Family versus the Logic of the Market - Robert Cabanes * 20. The Demand for Labour within the Household: Child Labour in Togo - Marie-France Lange * 21. The Household Economy and Commercial Exploitation of Children's Work: the Case of Kerala - Olga Nieuwenhuys * 22. The Disintegrating Social Fabric: Child Labour and Socialisation in Senegal - Serigne Mor Mbaye and Abdou Salam Fall * 23. 'Unexploited' Labour: Social Transition in Madagascar - Bodo Ravololomanga and Bernard Schlemmer * 24. Looking Ahead: A General Conclusion - Claude Meillassoux",2000,
Higher Order Refinements by Bootstrap in Lasso and other Penalized Regression Methods,"Selection of important covariates and to drop the unimportant ones from a high-dimensional regression model is a long standing problem and hence have received lots of attention in the last two decades. After selecting the correct model, it is also important to properly estimate the existing parameters corresponding to important covariates. In this spirit, Fan and Li (2001) proposed Oracle property as a desired feature of a variable selection method. Oracle property has two parts; one is the variable selection consistency (VSC) and the other one is the asymptotic normality. Keeping VSC fixed and making the other part stronger, Fan and Lv (2008) introduced the strong oracle property. In this paper, we consider different penalized regression techniques which are VSC and classify those based on oracle and strong oracle property. We show that both the residual and the perturbation bootstrap methods are second order correct for any penalized estimator irrespective of its class. Most interesting of all is the Lasso, introduced by Tibshirani (1996). Although Lasso is VSC, it is not asymptotically normal and hence fails to satisfy the oracle property.",2019,arXiv: Statistics Theory
Developing and validating a multivariable prediction model for in-hospital mortality of pneumonia with advanced chronic kidney disease patients: a retrospective analysis using a nationwide database in Japan,"The prognosis of pneumonia in patients with advanced stage chronic kidney disease (CKD) remains unimproved for years. We attempt to develop a simple and more useful scoring system for predicting in-hospital mortality for advanced CKD patients with pneumonia. Using the Diagnosis Procedure Combination database, we identified the in-hospital adult patients both with a record of pneumonia and stage 5 or 5D CKD as a comorbidity on admission between April 1, 2012 and March 31, 2016. Predictive variable selection was analyzed by multivariable logistic regression analysis, stepwise method, LASSO method and random forest method, and then develop a new simple scoring system seeking for highest c-statistics combination of variables in one sample data set for model development. Finally, we compared c-statistics of univariate logistic regression about new scoring system with c-statistics about â€œA-DROPâ€ in the other sample data set. We identified 8402 patients in 707 hospitals, and the total in-hospital mortality was 11.0% (437 patients) in development data set. Seven variables were selected, which includes age (maleâ€‰â‰¥â€‰70 years, femaleâ€‰â‰¥â€‰75 years), respiratory failure, orientation disturbance, low blood pressure, the need of assistance in feeding or bowel control, severe or moderate thinness and CRP 200 mg/L or extent of consolidation on chest X-rayâ€‰â‰¥â€‰2/3 of one lung. The c-statistics of univariate logistic regression was 0.8017 using seven variables, while that was 0.7372 using â€œA-DROPâ€ In advanced CKD patients, if we select appropriate variables for predicting in-hospital mortality, simple scoring system may have better discrimination than â€œA-DROPâ€.",2020,Clinical and Experimental Nephrology
Aptian marine ingression in the Araripe Basin: Implications for paleogeographic reconstruction and evaporite accumulation,"Abstract Integrated sedimentologic and palynological analysis of four outcrops in the Aptian succession of the Araripe Basin provides information on the earliest marine connection of this basin. Palynological samples revealed well-preserved palynomorphs with diverse assemblages composed of pteridophyte spores and gymnospermic pollen grains, especially Classopollis, besides phytoclasts and abundant amorphous organic matter. Microforaminiferal linings were retrieved from two samples, both from the Santana Formation, immediately underlying the â€œIpubi Layersâ€. The few specimens recognized are well preserved, very similar to each other in size and shape (trochospiral morphology), and usually embedded within amorphous organic matter. These records indicate that the lower Crato Member was deposited in a marine environment. The increasing marine influence in the Araripe Basin, coupled with increasing aridity, allowed the accumulation of evaporites (â€œIpubi Layersâ€) in restrict portions of the basin. The small size of the inferred marine connection is probably why it has been so difficult to identify its precise geographic location.",2019,Marine and Petroleum Geology
A six-gene prognostic model predicts overall survival in bladder cancer patients,"BackgroundThe fatality and recurrence rates of bladder cancer (BC) have progressively increased. DNA methylation is an influential regulator associated with gene transcription in the pathogenesis of BC. We describe a comprehensive epigenetic study performed to analyse DNA methylation-driven genes in BC.MethodsData related to DNA methylation, the gene transcriptome and survival in BC were downloaded from The Cancer Genome Atlas (TCGA). MethylMix was used to detect BC-specific hyper-/hypo-methylated genes. Metascape was used to carry out gene ontology (GO) enrichment and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analyses. A least absolute shrinkage and selection operator (LASSO)-penalized Cox regression was conducted to identify the characteristic dimension decrease and distinguish prognosis-related methylation-driven genes. Subsequently, we developed a six-gene risk evaluation model and a novel prognosis-related nomogram to predict overall survival (OS). A survival analysis was carried out to explore the individual prognostic significance of the six genes.ResultsIn total, 167 methylation-driven genes were identified. Based on the LASSO Cox regression, six genes, i.e., ARHGDIB, LINC00526, IDH2, ARL14, GSTM2, and LURAP1, were selected for the development of a risk evaluation model. The Kaplanâ€“Meier curve indicated that patients in the low-risk group had considerably better OS (Pâ€‰=â€‰1.679eâˆ’05). The area under the curve (AUC) of this model was 0.698 at 3Â years of OS. The verification performed in subgroups demonstrated the validity of the model. Then, we designed an OS-associated nomogram that included the risk score and clinical factors. The concordance index of the nomogram was 0.694. The methylation levels of IDH2 and ARL14 were appreciably related to the survival results. In addition, the methylation and gene expression-matched survival analysis revealed that ARHGDIB and ARL14 could be used as independent prognostic indicators. Among the six genes, 6 methylation sites in ARHGDIB, 3 in GSTM2, 1 in ARL14, 2 in LINC00526 and 2 in LURAP1 were meaningfully associated with BC prognosis. In addition, several abnormal methylated sites were identified as linked to gene expression.ConclusionWe discovered differential methylation in BC patients with better and worse survival and provided a risk evaluation model by merging six gene markers with clinical characteristics.",2019,Cancer Cell International
Grundlagen der Schalentheorie,"Die Berechnungsgrundlage fur die Schalen nach der mathematischen Elastizitatstheorie ist bei Love [92.1] zu finden. Die praktische Anwendung der Elastizitatstheorie fur die Berechnung zylindrischer Schalen ist in erster Linie Finsterwalder [33.1], Donnell [33.2, 34.2], FLUgge [34.3] und Dischinger [35.1] zu verdanken, deren Arbeiten fur die Entwicklung der Schalentheorie von grundlegender Bedeutung gewesen sind. Eine Reihe von Verfassern hat die Theorie der Zylinderschalen bearbeitet, um zu vereinfachten Berechnungsmethoden zu gelangen. Die wichtigsten Beitrage dieser Art sind von Valette [34.4], Schorer [35.5], Aas-Jakobsen [39.2, 55.1], Wlassov [44.2], Jenkins [47.8], Lundgren [49.5], Olsen [51.8], Parme [52.1], Gibson and Cooper [54.3], Tottenham [54.8], Rabich [55.4, 56.4], RUdiger und Urban [55.5] und Holand [56.2] gebracht worden. Diese und auch andere Arbeiten sollen in den folgenden Abschnitten getrennt behandelt werden. Es sollen in diesem Abschnitt nur die grundlegenden Arbeiten besprochen werden.",1958,
Flower Basket Retrieval: Utilization of a Device with a Unique Design for Endoscopic Rescue in Cases Involving Proximal Migration of Pancreatic Duct Stents,"The use of pancreatic stents has become a powerful ancillary strategy in post-endoscopic retrograde cholangiopancreatography (ERCP) pancreatitis (PEP) prophylaxis. The myriad of rescue approaches for difficult biliary access, such as transpancreatic sphincterotomy or needle-knife precut, rely on tangible competency associated with pancreatic stenting. However, despite the obvious overall benefits, the risk of proximal migration is estimated to be about 5%, posing different levels of complexity for retrieval as determined by duct width, depth of proximal migration, and most critical, downstream strictures. While the distinct mechanisms of proximal stent migration remain elusive in many circumstances, anatomical factors and/or biliary instrumentation, such as that after complex biliary duct access following pancreatic duct stenting, appear to represent key factors. For example, stent insertion beyond the pancreatic genu and/or accross an ansa pancreatica is not recommended when using short straight stents because the related traction forces may favor proximal migration. Reported extraction techniques are broadly categorized into over-the-wire (Soehendra retriever, the so-called Lasso technique using mini snares, etc.) or â€œfreehandâ€ approaches, using, for example, Dormia baskets or alongside-the-stent balloon inflation. Various ancillary devices have been used in individual case reports, including a grasping tripod or modified snare with a cut plastic sheath. In addition, in some instances, delayed extraction of migrated stents has been described, implementing a bridging concept by first inserting another pancreatic duct stent alongside the migrated stent to reduce the risk of post-ERCP PEP. Such a concept may be reasonable to gain time in, for example, critically ill patients and/or when referral to a higher-level center is considered. From this perspective, a novel variant extraction technique is presented utilizing a specifically designed 20-mm, 8-wire basket initially devised for grasping small, floating biliary stones (FlowerBasket; Olympus, Hamburg, Germany). In the past 3 months, this â€œflower basket retrievalâ€ technique was successfully applied in 2 consecutive patients with short straight, double-flapped 5-Fr stents (MTW, Wesel, Germany) as our standard stent type for PEP. In normal pancreatic duct anatomy, a conventional basket cannot be fully deployed; thus, the chance of successful extraction decreases tremendously. In contrast, the unique design of the FlowerBasket (Fig. 1A; left) relative to that of the conventional 4-wire basket (right) may be superior for limited-space instrumentation in small-caliber pancreatic ducts as assessed by initial judicious contrast application as an anatomical roadmap. After successful grasping of the distal end during forward movements of the partially opened basket with the small proximal wire mesh (Fig. 1B), the stent was extracted (Fig. 1C) Finally, a single pigtail pancreatic drainage is reinserted to reduce the manipulation-associated risk of PEP and remigration (Fig. 1D). Likewise, in patient 2, Flower basket capture (Fig. 2A) and transpapillary extraction (Fig. 2B) of Received: February 23, 2019 Revised: March 31, 2019 Accepted: April 1, 2019 Correspondence: Vincent Zimmer Department of Medicine, Marienhausklinik St. Josef Kohlhof, Klinikweg 1-5, 66539 Neunkirchen, Germany Tel: +49-6821-3632070, Fax: +49-6821-3632624, E-mail: vincent.zimmer@gmx.de ORCID: https://orcid.org/0000-0002-6298-4717",2019,Clinical Endoscopy
"Measuring social media influencer index- insights from facebook, Twitter and Instagram","Abstract The growth of social media has completely revamped the way people interact, communicate and engage. These platforms play a key role in facilitating greater outreach and influence. This study proposes a mechanism for measuring the influencer index across popular social media platforms including Facebook, Twitter, and Instagram. A set of features that determine the impact on the consumers are modelled using a regression approach. The underlying machine learning algorithms including Ordinary Least Squares (OLS), K-NN Regression (KNN), Support Vector Regression (SVR), and Lasso Regression models are adapted to compute a cumulative score in terms of influencer index. Findings indicate that engagement, outreach, sentiment, and growth play a key role in determining the influencers. Further, the ensemble of the four models resulted in the highest accuracy of 93.7% followed by the KNN regression with 93.6%. The study has implications across various domains of e-commerce, viral marketing, social media marketing and brand management wherein identification of key information propagators is essential. These influencer indices may further be utilized by e-commerce portals and brands for the purpose of social media promotion and engagement for larger outreach.",2019,Journal of Retailing and Consumer Services
Experimental Validation of Genomic Selection in Sugarcane,"Sugarcane cultivars (Saccharum spp.) are interspecific hybrids characterized by highly heterozygous and polyploid genome. Genomic selection (GS) approach is believed to be well suited for complex traits by including all markers in prediction models. Our objective was to test the GS approach in a complex polyploid crop. Predictions of genetic values were carried out on two independent panels, each composed of 167 cultivars and breeding materials covering the worldwide diversity. Accessions were genotyped using 1499 DArT. Phenotyping was carried out in Reunion for one panel and in Guadeloupe for the other one. We considered ten traits relative to sugar and fiber contents, digestibility and composition of the bagasse, plant morphology and disease resistances. We used seven predictive models: Bayesian Regression, Bayesian LASSO, Ridge-regression, BayesA, BayesB, Reproducing Kernel Hilbert Space and Partial Least Square Regression. Accuracies of predictions were assessed through correlations between observed and predicted genetic values, firstly by using a cross-validation within each panel, and secondly by using a cross-validation between panels. Accuracies of predictions were of similar value between the seven GS models for a given trait, while differences were observed among traits. Depending on the trait considered, the average GS accuracy values related to within-panel prediction ranged from 0.29 to 0.61 in the Reunion panel and from 0.13 to 0.5 in the Guadeloupe panel. GS accuracy values based on cross-validations between the two independent panels ranged from 0.13 (smut resistance) to 0.55 (brix). This study represents the first validation of GS approach in sugarcane with experimental data. (Resume d'auteur)",2013,
Agreement between clinical estimation and a new quantitative analysis by Photoshop software in fundus and angiographic image variables,"Purpose To evaluate the validity of a new method for the quantitative analysis of fundus or angiographic images using Photoshop 7.0 (Adobe, USA) software by comparing with clinical evaluation. Methods Four hundred and eighteen fundus and angiographic images of diabetic patients were evaluated by three retina specialists and then by computing using Photoshop 7.0 software. Four variables were selected for comparison: amount of hard exudates (HE) on color pictures, amount of HE on red-free pictures, severity of leakage, and the size of the foveal avascular zone (FAZ). Results The coefficient of agreement (Kappa) between the two methods in the amount of HE on color and red-free photographs were 85% (0.69) and 79% (0.59), respectively. The agreement for severity of leakage was 72% (0.46). In the two methods for the evaluation of the FAZ size using the magic and lasso software tools, the agreement was 54% (0.09) and 89% (0.77), respectively. Agreement in the estimation of the FAZ size by the lasso magnetic tool was excellent and was almost as good in the quantification of HE on color and on red-free images. Conclusion Considering the agreement of this new technique for the measurement of variables in fundus images using Photoshop software with the clinical evaluation, this method seems to have sufficient validity to be used for the quantitative analysis of HE, leakage, and FAZ size on the angiograms of diabetic patients.",2008,International Ophthalmology
MOTS-c: an equal opportunity insulin sensitizer,"MOTS-c is a 16-amino acid peptide encoded from 12S rRNA region of the mitochondrial DNA [1]. Multiple publications support the notion that MOTS-c plays an important role in regulating metabolism and insulin action and it has been suggested that MOTS-c exerts exercise mimetic effects in rodents [2]. In this issue of the Journal of Molecular Medicine, Lu et al. [3] revealed an important new role of MOTS-c as a hormone capable of preventing negative metabolic effects associated with menopause in an ovariectomized mouse model. These investigators found that MOTS-c treatment reduced both the weight gain as well as the insulin resistance associated with experimental menopause. Furthermore, they found that MOTS-c also suppressed the increase in inflammatory markers such as IL-1ÃŸ and IL-6 in adipose tissue. This antiinflammatory effect may be a key in the health-promoting effects of MOTS-c. It is well known that postmenopausal women exhibit physiological alterations including weight gain, changes in adipose tissue distribution, and deterioration of insulin secretion, and sensitivity [4, 5]. These changes predispose them to develop type 2 diabetes [4]. Furthermore, decreased levels of estrogen are associated with non-alcoholic steatohepatitis, osteoporosis, and cardiovascular diseases [6â€“8]. These menopausalassociated metabolic abnormalities and health problems can be alleviated by exercise, whose benefits are obtained via diverse mechanisms including decreased inflammatory mediators, increased activity of antioxidants, and improved endothelial function [9, 10]. A recent meta-analysis on the effects of programmed exercise on insulin sensitivity-related outcomes in postmenopausal women revealed that exercising for 3 to 4 months significantly lowers insulin levels, and improves HOMA-IR, BMI, waist circumference, and body fat mass [11]. Exercise, which induces muscle remodeling, is beneficial not only for menopause but also for multiple other chronic diseases. Previous studies have shown that regular aerobic exercise such as walking, running, or high physical fitness has protective effects against obesity, type 2 diabetes, and cardiovascular disease [12â€“14]. Given the sedentary lifestyle in western societies, developing exercise mimetics offers a promising therapeutic strategy for chronic diseases [15]. The development of such exercise mimetic drugs requires a better understanding of the molecular mechanisms involved in exercise-induced muscle remodeling. Muscle is not only a locomotive organ but also an endocrine organ. Muscle releases multiple myokines during exercise, and these myokines likely mediate many of the systemic effects of exercise [16]. Mitochondria not only provide muscle with the necessary fuel, but also release and integrate exercise-induced signaling. AMPK, SIRT1, and PGC1Î± are central to exercise-induced signaling and are activated in skeletal muscles during exercise, leading to fatty acid oxidation and mitochondrial biogenesis [17]. These processes are followed by muscle remodeling that leads to exercise endurance and metabolic improvements. Indeed, small molecules and naturally occurring compounds that activate AMPK and SIRT1 exert exercise mimetic effects including insulin sensitization protect against diet-induced metabolic dysfunction in mice [18]. MOTS-c has been proposed to be a mitochondrial-derived exercise mimetic myokine [1]. MOTS-c is expressed in skeletal muscles and other tissues and is detected in plasma. MOTS-c increases endogenous AICAR levels and activates AMPK [1]. In addition, MOTS-c increases NAD+ levels, and SIRT1 is partially involved in MOTS-c actions [1]. MOTS-c also increases insulin sensitivity in skeletal muscle from aged, and high-fat fed, mice [1]. Furthermore, MOTS-c dramatically decreases weight gain during high-fat-diet-induced obesity in mice, and prevents fat accumulation in liver, making it a potential target in NASH (Fig. 1) [1, 19]. The paper by Lu and colleagues suggests that brown adipose tissue (BAT) may also be a direct target of MOTS-c, affecting mitochondrial number and function in this tissue [3]. Lu et al. also show that MOTS-c administration also prevents ovariectomy-induced obesity and insulin resistance in mice via the AMPK pathway. Previous studies revealed that MOTS-c prevents ovariectomy-induced * Pinchas Cohen hassy@usc.edu",2019,Journal of Molecular Medicine
Contribution Ã  la sÃ©lection de modÃ¨le via pÃ©nalisation Lasso en Ã‰pidÃ©miologie,"Mes travaux portent principalement sur le developpement, lâ€™adaptation, lâ€™implementation et lâ€™application de methodes statistiques de selection de modele. Ma principale contribution consiste a adapter des methodes de l'apprentissage statistique supervise qui sont devenues tres populaires lors de la derniere decennie, les regressions penalisees de type Lasso, a l'analyse de donnees issues d'etudes epidemiologiques. L'enjeu est de s'attaquer aux problemes des donnees volumineuses (\textit{Big Data}) tout en respectant les objectifs et specificites de la discipline. Le volume important se refere ici au fait que le nombre d'observations et/ou le nombre de variables est bien plus important que celui qui etait classique dans le domaine, sans exclure le cas ou le nombre de variables est superieur au nombre d'observations (donnees de grande dimension). 
 
Le contexte de la pratique epidemiologique est en plein changement avec les evolutions technologiques et la consequente disponibilite croissante des Big Data. Le Systeme National des Donnees de Sante (SNDS), regroupant les principales bases de donnees de sante publique existantes en France, constitue un exemple de Big Data en sante. Le donnees ``omiques'' (genomiques, transcriptomiques, proteomiques, metabolomiques, microbiomiques, mycobiomiques, viromiques,$\ldots$) issues des avancees des techniques de sequencage a haut debit constituent un autre exemple de Big Data en sante. Enfin, les mesures de l'\textit{exposome} (par opposition aux facteurs genetiques), qui designe en epidemiologie lâ€™ensemble des expositions environnementales que subit un individu au long de sa vie peut egalement constituer une source de Big Data. 
 
Ce document s'articule autour de trois chapitres. Il resume mon activite de recherche depuis 2005, soit depuis mon recrutement a lâ€™Universite de Bordeaux apres ma these. 
Le premier chapitre est une introduction generale dans laquelle je contextualise, motive et enonce la problematique abordee tout au long de mes recherches. Le deuxieme chapitre est consacre a mes travaux en lien avec les etudes sur les traumatismes accidentels et expositions medicamenteuses a partir des donnees du SNDS. Le troisieme chapitre est consacre a mes travaux en lien avec des etudes biomedicales: la prediction de la charge virale censuree par un seuil de detection a partir des mutations du VIH, d'une part, et l'automatisation de la detection des seuils d'anomalie des hemogrammes en population generale, d'autre part.",2018,
Materials Informatics for Process and Material Co-Optimization,"In semiconductor manufacturing, fabrication processes and their materials should be properly co-optimized to achieve required processing results within reasonable development duration and acceptable cost. Unfortunately, it is a very time-consuming procedure, because the number of possible combinations of process/material candidates is very large. Here, we develop a methodology for co-optimization of processes and their materials. We successfully constructed a prediction model for dry-etching of high- ${k}$ materials (R2 = 0.65). Also, it was proven that considering both the materials and processes is needed for accurate prediction of etching rates. By trying only <0.00001% of all possible process/material candidates with this model and Bayesian optimization, we can find new combinations of gasses and their processes for more than 100 times higher etching rates than that with a traditional gas/process condition. Furthermore, we discussed that accurate prediction can be made by using a combination of the Bayesian optimization with LASSO and materials knowledge from related scientific papers. Future work will focus on validating the versatility of our methodology by applying it to other development items.",2019,IEEE Transactions on Semiconductor Manufacturing
New Wearable Computers Move Ahead,"Sony Corporation announced in November 2013 receipt of a US patent for a wig that is a wearable computing device.1 This system, which is not being produced, consists of: (1) a wig made of hair that covers at least part of the head of the wearer, (2) 1 or more sensors for providing input data, (3) a processing control unit coupled to the sensors for processing input data, and (4) a communication interface that is coupled to the processing unit to communicate with a second computing device. The sensors, control unit and communication interface would be hidden and the second computing device would be remotely separated from the wearable computing device. The wig could also contain actuators to receive input from the processing unit and provide tactile feedback signals to the user. The wig could contain such sensors as a GPS, an ultrasound to detect objects near the wig, a camera to detect objects near the wig, an accelerometer to detect head motion, and a laser pointer. All these inputs could be transmitted to a second computing device that can control or be controlled by the wig system. 
 
The Sony wearable computer wig can contain an actuator vibration motor device or a device that can generate a small electric shock in extreme situations to provide feedback signals or warnings. This could include warnings about hypoglycemia or hyperglycemia if the device was connected to real time glucose information. The vibration devices situated in 4 different directions on the head could be used to provide information to the wearer about which direction to walk. Motion, pressure, or strain gauges embedded in the wig could measure head motion and measure gestures such that the user could control a remote computer or smartphone by way of facial gestures. 
 
Patients with diabetes were the first to use wearable medical devices for real-time health assessment, called continuous glucose monitors. We are now seeing introduction of many types of wearable computers which can monitor physiologic processes or disease treatments.2 One of the closest to widespread distribution is Google Glass. The Google Glass system is a wearable Android-powered computer with an optical head-mounted display that displays information in a smartphone-like hands-free format in oneâ€™s field of vision, takes pictures with a camera built into spectacle frames, and communicates with the Internet via voice commands, head tilts, and a touchpad on the side. It can make video calls, facilitate hands-free web searching, and run special apps. Eventually this wearable computer will likely be designed to accommodate wirelessly transmitted data from blood glucose (BG) monitors, continuous glucose monitors (CGMs), and insulin pumps. The computing portion of the device will be ready to take autonomous actions because of decision support software. 
 
The term â€œglassomicsâ€ has been created to describe a branch of medical informatics concerned with the study and development of in vivo, ex vivo, and in silico applications for Google Glass, smart watches, and sensors. Qualcomm Life, Inc and Palomar Health in Escondido California have announced the launch of the Glassomics incubator to promote innovation in this area of medicine. The goal will be to develop Google Glass applications, or â€œglassware,â€ for such areas as augmented reality guided clinical applications, physiological monitoring, genomic information mapping, and consumer health and wellness. Many applications for diabetes will be possible with the use of Google Glass.3 
 
The most important metric for diabetes that benefits from real-time alerts to patients is hypoglycemia. A wig or another type of wearable computer, such as Google Glass, can receive information from a BG monitor that transmits wirelessly and automatically and notifies the wearer through sensory stimulation. The wig can contain a vibrating motor or an electroshock generating device pressing on the scalp. Google Glass contains a visual projection that can be programmed to present warning alert messages. 
 
Another device that uses vibration to indicate a message is the SurroGait Rx system by Orpyx in Canada. This device under development contains a pressure-sensing insert for a shoe that can accurately detect pressure.4 It also consists of a low-profile, ergonomic back pad. Pressure information collected in the shoe is sent wirelessly to the back display. The back display is an actuator that transposes sensation (that would otherwise be felt on a foot) onto the back, so that users can â€œfeelâ€ their feet through the back. The idea is to use the principle of neuroplasticity to rewire the brain to interpret the feeling on the back as corresponding to pressure against the feet. 
 
BG monitors and CGMs will eventually routinely transmit data wirelessly to smartphones, the Internet, and receivers in wearable computers. At that point, quantitative measures of hypoglycemia will be able to trigger alerts in wearable computer systems. These systems will also receive and send alerts in response to signals from physiological qualitative hypoglycemia monitors. 
 
Abnormal EKGs and abnormal EEGs are associated with hypoglycemia and the type of information that can be gleaned from sensors and software that can identify hypoglycemia form these measurements will become incorporated into wearable sensors. I expect that we will eventually see sophisticated actuator responses to hypoglycemic signals generating tactile alerts and if the response is managed by a smart computer worn as an actuator, the software controller for a closed loop system could end up having to justify its niche in the marketplace. Better sensors are coming. Better actuators that will provide tactile and auditory alerts are starting to appear. 
 
Activity tracker wearable devices are becoming more sophisticated and useful for people with diabetes who want to keep track of exercise related data. These devices count the number of steps one takes, and some also keep track of distance traveled and calories burned. Activity trackers can contain hardware for tracking heart rate and in some cases can link with Wi-Fi-enabled scales, blood pressure monitors, and other devices to provide assist a patient with self-management. Paired with a companion web account or mobile app, they can provide insight into the habits that make up a patientâ€™s lifestyle. 
 
These portable wearable sensors and actuators are mHealth devices, representing the use of mobile communications devices for health services and information. Mobile phones, patient monitoring devices, implanted or worn sensors, tablets, personal digital assistants, and other wireless devices can be part of mHealth systems. A smartphone is a cellular phone that can also perform many functions of a computer by running applications (apps) including Internet accessing, emailing, and text messaging. A smartphone provides instant access to information and instant capacity to communicate (Figure 1). Since the original smartphone, the iPhone, was launched in 2007, these devices have attained overwhelming popularity. Currently there are approximately 150 million smartphone users in the United States5 and 1.5 billion users worldwide.6 
 
 
 
Figure 1. 
 
Features of a Smartphone. 
 
 
 
Diabetes is a disease of numbers and smartphones are an excellent tool for storing, managing, and transmitting blood glucose, dietary, and exercise data. See Figure 1 for features of most smartphones. Mobile applications for smartphones have been developed for diabetes self-management and can track self-monitoring of blood glucose data, calculate insulin dosages, track doses of insulin or other diabetes medications, or track other data related to diabetes such as weight, diet, activity, or blood pressure.7 One of the limitations of using smartphones for diabetes data tracking is the need for patients to manually enter BG data into their smartphone. New technologies are now being developed that can transform this data entry process into automatic transfer of data into a smartphone (via cable or wirelessly) or directly to the cloud for web storage. 
 
As wearable continuous real-time CGM systems become more popular, we will see increasing numbers of patients wearing computers and using them to help manage their diabetes. Wearable computers are moving ahead for diabetes.",2014,Journal of Diabetes Science and Technology
Profit or Loss: A Long Short Term Memory based model for the Prediction of share price of DLF group in India,"Presently, the prediction of share is a challenging issue for the research community as share market is a chaotic place. The reason behind it, there are several factors such as government policies, international market, weather, performance of company. In this article, a model has been developed using long short term memory (LSTM) to predict the share price of DLF group. Moreover, for the experimental purpose the data of DLF group has been taken from yahoo financial services in the time duration of 2008 to 2018 and the recurrent neural network (RNN) model has been trained using data ranging from 2008 to 2017. This RNN based model has been tested on the data of year 2018. For the performance comparison purpose, other linear regression algorithms i.e. k-nn regression, lasso regression, XGboost etc has been executed and the proposed algorithm outperforms with 2.6% root mean square error.",2019,2019 IEEE 9th International Conference on Advanced Computing (IACC)
"LiteMat: A scalable, cost-efficient inference encoding scheme for large RDF graphs","The number of linked data sources and the size of the linked open data graph keep growing every day. As a consequence, semantic RDF services are more and more confronted with various ""big data"" problems. Query processing in the presence of inferences is one them. For instance, to complete the answer set of SPARQL queries, RDF database systems evaluate semantic RDFS relationships (subPropertyOf, subClassOf) through time-consuming query rewriting algorithms or space-consuming data materialization solutions. To reduce the memory footprint and ease the exchange of large datasets, these systems generally apply a dictionary approach for compressing triple data sizes by replacing resource identifiers (IRIs), blank nodes and literals with integer values. In this article, we present a structured resource identification scheme using a clever encoding of concepts and property hierarchies for efficiently evaluating the main common RDFS entailment rules while minimizing triple materialization and query rewriting. We will show how this encoding can be computed by a scalable parallel algorithm and directly be implemented over the Apache Spark framework. The efficiency of our encoding scheme is emphasized by an evaluation conducted over both synthetic and real world datasets.",2015,2015 IEEE International Conference on Big Data (Big Data)
Analysis of Energy Consumption Influencing Factors in China Based on the Lasso Method,"éšç€ç»æµŽå‘å±•çš„åŠ å¿«å’Œèµ„æºéœ€æ±‚é‡çš„åŠ å¤§ï¼Œèƒ½æºæ¶ˆè´¹å‘ˆçŽ°å‡ºè¿žå¹´æ”€å‡çš„æ€åŠ¿ï¼Œèƒ½æºæ¶ˆè´¹å½±å“å› ç´ çš„ç ”ç©¶åŠèƒ½æºæ¶ˆè´¹éœ€æ±‚çš„åˆç†é¢„æµ‹ï¼Œå¯¹ä¿è¯æˆ‘å›½ç»æµŽå¹³ç¨³æŒç»­å¥åº·å‘å±•æ˜¯ååˆ†å¿…è¦çš„ã€‚ç›®å‰å­¦è€…ä»¬åˆ†åˆ«ç”¨è¿‡ç®€å•çº¿æ€§å›žå½’æ³•ã€ä¸»æˆåˆ†å›žå½’æ³•åŠå²­å›žå½’æ³•å¯¹æˆ‘å›½èƒ½æºæ¶ˆè´¹å½±å“å› ç´ è¿›è¡Œåˆ†æžï¼Œä½†è¿™äº›ç ”ç©¶å¾—åˆ°çš„æ¨¡åž‹å¯èƒ½å¤ªè¿‡ç²¾ç®€è€Œæœªèƒ½è¾ƒä¸ºå…¨é¢åœ°æ‰¾å‡ºèƒ½æºæ¶ˆè´¹çš„ä¸»è¦å½±å“å› ç´ ã€‚è€Œæœ¬æ–‡ä¾æ®2000å¹´~2012å¹´æˆ‘å›½èƒ½æºæ¶ˆè´¹æ€»é‡çš„ç›¸å…³æ•°æ®ï¼Œé’ˆå¯¹å˜é‡åå¤šï¼Œè§‚æµ‹æ•°æ®å°‘çš„ç‰¹ç‚¹é€‰ç”¨äº†Lassoæ–¹æ³•å¯¹æˆ‘å›½èƒ½æºæ¶ˆè´¹å½±å“å› ç´ å»ºç«‹äº†å›žå½’æ¨¡åž‹ï¼Œå¾—åˆ°äº†å½±å“æˆ‘å›½èƒ½æºæ¶ˆè´¹çš„ä¸»è¦å› ç´ æœ‰ç»æµŽå¢žé•¿å› ç´ ã€äººå£å¢žé•¿å› ç´ ã€äº§ä¸šç»“æž„å› ç´ ã€æŠ€æœ¯è¿›æ­¥å› ç´ ã€èƒ½æºåˆ©ç”¨æ•ˆçŽ‡å› ç´ ä»¥åŠèƒ½æºä»·æ ¼å› ç´ ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬å¯ä¸»è¦ä»Žè¿™äº›å› ç´ å…¥æ‰‹ï¼Œå¯¹èƒ½æºæ¶ˆè´¹åŠ ä»¥ç®¡ç†å’ŒæŽ§åˆ¶ã€‚åŒæ—¶æˆ‘ä»¬è¿˜ç”¨é€æ­¥å›žå½’æ³•å’Œå²­å›žå½’æ³•åˆ†åˆ«å»ºç«‹äº†å›žå½’æ¨¡åž‹ï¼Œå¹¶å°†Lassoæ–¹æ³•å¾—åˆ°çš„ç»“æžœä¸Žå…¶è¿›è¡Œæ¯”è¾ƒï¼Œç»“æžœè¡¨æ˜ŽLassoæ–¹æ³•åœ¨èƒ½æºæ¶ˆè´¹å½±å“å› ç´ çš„é€‰æ‹©æ–¹é¢ï¼Œæ¯”å…¶ä»–ä¸¤ç§æ–¹æ³•æ›´ä¸ºå…¨é¢åœ°æ‰¾å‡ºèƒ½æºæ¶ˆè´¹çš„ä¸»è¦å½±å“å› ç´ ï¼Œåœ¨å¯¹2013å¹´åŠ2014å¹´èƒ½æºæ¶ˆè´¹æ€»é‡é¢„æµ‹æ–¹é¢ï¼ŒLassoæ–¹æ³•æ¯”å…¶ä»–ä¸¤ç§æ–¹æ³•æ›´ä¸ºç²¾ç¡®ã€‚ With the acceleration of economic development and the increasing demand for resources, energy consumption shows a rising trend in recent years. To ensure the stable, sustainable and healthy development of Chinaâ€™s economy, it is necessary to study on consumption factors and to forecast energy consumption demand reasonably. As so far, scholars have used simple linear regression, principal component regression and ridge regression method for analyzing Chinaâ€™s energy consumption factors, but models achieved from these studies may be too lean to find more comprehensive energy consumption factors. While according to the related data of domestic energy consumption during 2000-2012, this paper chooses a new methodâ€”Lasso method to make regression model for domestic energy consumption, and then we get the main energy consumption effecting factors: economic development, demographic factor, industrial structure, technological progress, energy consumption efficiency and energy price factor, so we can control energy consumption through these main factors. Additionally, we use stepwise regression and ridge regression to make regression models, the results got from the Lasso, stepwise regression and ridge regression are compared, the study shows the Lasso method is better than the other methods in terms of variable selection, because it could find more comprehensive energy consumption factors; for predictions of 2013 and 2014, Lasso method is more accurate than the other two methods.",2017,
Performance-Based Prediction of Chronic Kidney Disease Using Machine Learning for High-Risk Cardiovascular Disease Patients,"People at high-risk of cardiovascular disease are most likely vulnerable to chronic kidney diseases, and historical medical records can help avert complicated kidney problems. In this paper, 12 supervised machine learning algorithms were used to analyses a retrospective electronic medical data on chronic kidney disease. The study targeted 544 outpatients although 48 failed to meet the inclusion criteria and some other 21 cases had missing values and were excluded from the study. The profiling and the preliminaries result established that 88.5% of the cases were labeled as advance CKD while 11.5% were labelled as early-stage CKD cases. The classification task and the subsequent evaluation of the models were based on the correct classification of the two groups. Of the evaluated algorithms, decision tree boosted decision tree, and CN2 rule induction was the least accurate ones. However, logistic regression (Ridge and Lasso), neural network (logistic and stochastic gradient descent), and support vector machine (Radial Basis Function and Polynomial) had very high accuracies and efficiency. With an efficiency of 93.4% and a classification accuracy of 91.7%, Polynomial Support Vector Machine algorithm was the most efficient and accurate. The model suggested 253 2-dimensional combinations of factors with a history of vascular diseases and smoking as the most influential factors. The other combinations can provide information that can be used to predict or detect chronic kidney disease based on historical records. Future research prospects should consider using discretized Glomerular Filtration Rate to ensure that the classification integrates the five stages of the CKD.",2020,
Meta_LASH Tree: Bagging at Meta Level Using LASSO Regression Hoeffding Tree for Streaming Data,"Building predictive model for streaming data is a major challenge as it involves high speed and huge amount of data stream which is impossible to store and process the entire data. Since the distribution of streaming data changes over time, the traditional static model is not suitable for streaming data. Nowadays most of the streaming data solutions have been centered around ensembles, which integrates predictive responses from multiple homogeneous or heterogeneous base learning algorithms. In this paper a novel, memory efficient and practically useful Ensemble Bagging at Meta level Framework denoted as Meta_LASH Tree is proposed which comprises of two phases. In the first phase a memory efficient base learner named as LASSO Regression Hoeffding Tree (LASH Tree) is constructed, which incorporates Hoeffding Tree and LASSO Regression, that produces better predictions and better insights than using both the models separately. This hybrid model is highly interpretable and can have an insights of both linear and non linear relationship of the data. In the second phase, the predictive responses from the previously constructed LASH Tree are collected using Ensemble Bagging approach, and the dominant base learner is selected by the Meta Learner. The proposed frame work is designed in such a way to reduce the memory usage and overfitting issue of the existing algorithms. It is also designed to enhance the prediction accuracy.",2019,2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI)
"Terrains, je vous aime: In Search of a Thesis Topic in the Field in Burkina Faso","Armelle Faure is completing a thesis at the Ecole des Hautes Etudes en Sciences Sociales, Paris. This article was written in July 1987, before the recent death of Captain Sankara. As she nears the end of writing up her thesis, she is now concentrating on the application of her ethnographic field experience to engage with the work of French specialists in development and aid. It was first published in French in L'ethnologue et son terrain. II: Les cadets published as Bulletin no. 31, January-March 1988, of the Association Fran,aise des Anthropologues (clo EHESS, 1 rue du 11 novembre, 92120 Montrouge, France). It is one of a number of articles on fieldwork by young French social anthropology students, who also replied to a questionnaire. MichelAghassian comments in his introduction to the collection that the articles are united by a (presumably transient) lack of interest in theory; by critical comment on the inadequacies of university teaching and especially training in research techniques; by a wish to reconcile personal commitments with the demands of research; and by reflection on the nature offieldwork. Aghassian also notes the sometimes painful economic uncertainty in which these students have to work, despite which many of them show great dedication to the subject. Whereas in some ways British and American experience may be differentfrom the French, e.g. students usually receive more methodical training It all started with a storm. The wind bent the trees, lightning flashed over the countryside, goats ran to their shelters. Night was falling, we would have no time to get to Tenkodogo, we would sleep in a Bisa village near the track. A child guided our vehicle to the house of the village head-man. We went through to the farm, crossing a maze of little alleys, circular huts, low walls, yards. In the head-man's courtyard, there was a lively meeting going on. Men, sitting down on the tamped earth, spoke with animation. The young head-man was introduced to us, and a lovely woman brought us water. I noticed the pebble-dashed walls that separated the series of little yards from one another, out of which there rose evening noises, kitchen fires, the shouts of children. What intense liveliness in this immense roofless house, directly under the stars! I was not yet aware that this farm was going to become the main centre of my activities for the five following years. I went to Africa, to look for a place to do anthropological field research. After two months spent in Mali, Togo and different places in Upper Volta, I chose to come back to this Bisa village in Upper Volta (now Burkina Faso since 1984). I began my first field study in December 1982. A few weeks before, I had written to the village head-man, explaining my intentions. The reply was favourable. At university, I had specially worked on the different systems of divination in black Africa, and this theme had imposed itself on my first programme of study. My preoccupation seemed absurd to the villagers, all the more because a French woman anthropologist had taken an interest in the local diviners and healers the year before. Did white women follow one another? Would they all resemble each other? On my return to France, the editing of a DEA1 showed up distressing gaps relating to social organization. My presentation of the society was too reduced to introduce any kind of written study, and the bibliography on the Bisa was too thin. Perhaps I was looking for intellectual pretexts to go back to a world about which I knew too little and which had seemed to me accessible. After three months of work in Paris to earn money for the journey, I went back. I was brimming with desire to be present at a festival which takes place every three years on the sacred pond of the Bisa, and which an old blacksmith had told me about. A woman friend accompanied me and the villagers welcomed 'their' nasara (white people). The Bisa and Garango villages were twinned to the French town of Laval, which tried to bring them help in the form of social infrastructure. The work to be done was enormous, and the villages were quarreling about aid. A white person coming back stood first and foremost for hope of material assistance. I continued my investigations, dropping the diviners to concentrate on the head-men and the blacksmiths, on the social and political organization of the village. During these two stays, I knew and learnt nothing about national political life in Upper Volta. Only village life mattered to me, outside any historical and national context. However, I was at Ouagadougou, the capital, at the time of the coup on 7 November 1982, and I was still there on 17 May 1983, when, after the speech of BoboDioulasso and the visit of Qadhafi, Captain Sankara was put under lock and key at the instigation of France. The Revolution came on 4 August 1983. At Paris, the elders, the anthropologists of Upper Volta, divided into those 'for' and those 'against' the new regime. As an heir to post-1968 trends in Paris, a lover of great street processions and egalitarian ideals, I didn't ask myself questions but stuck firmly to the 'yes' given by the young people of Burkina. I spent the year 1984 looking for funding and for a supervisor for my thesis, and training myself in social anthropology. This was another 'fieldwork', that of analysis of the Parisian jungle, the race for information which is handed out thriftily by those who are in the know. The students, faced with the patchiness of training, the dispersal of anthropology's institutions and themes, the divisions of masters and chapels, were organized into groups of kindred spirits. Good company was all-important: we would meet in cafes after seminars to tell the latest adventures of the week. Our group was united by an ide information circulated by telephone. At the end of a year, nothing. We had had a good time, but it was back to square one. Individualism staked its claim again, and I went back to work with a financial company for six months, having made up my mind to go back to Garango. It was Year 2 of the Revolution in Burkina Faso. As on previous trips, I went to the village after two days spent in Ouagadougou. The CDR (Comites de Defense de la Revolution), armed with Kalashnikovs and Chinese sub-machine-guns, were everywhere. At Garango, my landlady had turned CDR. She was however a girl from the family of the head-men of Waregu, the village where I did my study. She was called 'Mrs Fatherland-ordeath'. I went off with her to all the meetings and we shouted 'Down with imperialism! down with neo-colonialism! down with feudalism! health to the people! education for the people!' The CDR were visibly nonplussed: could one have a white skin and shout 'Down with imperialism'? I arrived at the village and greeted the 'comrade head-man'. The head-man's yard was desolate, deserted. The head-man was alone drinking his dolo (millet beer) and his horse was dead. The members of the Council of Elders came to say good morning to me, one by one. According to their accounts, the previous year had been hard: 'The harvest has been disastrous, the granaries were empty, we set off to do farm-work with only water in our stomachs, the old women died in the fields...You must help us'. Still having no firm plan for my research, I extended my scope of investigation to include the villages in the south, Zabre and Gombusugu, in order to complete a",1988,Anthropology Today
Enhanced crude oil biodegradative potential of natural phytoplanktonâ€associated hydrocarbonoclastic bacteria,"Phytoplankton have been shown to harbour a diversity of hydrocarbonoclastic bacteria (HCB), yet it is not understood how these phytoplankton-associated HCB would respond in the event of an oil spill at sea. Here, we assess the diversity and dynamics of the bacterial community associated with a natural population of marine phytoplankton under oil spill-simulated conditions, and compare it to that of the free-living (non phytoplankton-associated) bacterial community. While the crude oil severely impacted the phytoplankton population and was likely conducive to marine oil snow formation, analysis of the MiSeq-derived 16S rRNA data revealed dramatic and differential shifts in the oil-amended communities that included blooms of recognized HCB (e.g., Thalassospira, Cycloclasticus), including putative novel phyla, as well as other groups with previously unqualified oil-degrading potential (Olleya, Winogradskyella, and members of the inconspicuous BD7-3 phylum). Notably, the oil biodegradation potential of the phytoplankton-associated community exceeded that of the free-living community, and it showed a preference to degrade substituted and non-substituted polycyclic aromatic hydrocarbons. Our study provides evidence of compartmentalization of hydrocarbon-degrading capacity in the marine water column, wherein HCB associated with phytoplankton are better tuned to degrading crude oil hydrocarbons than that by the community of planktonic free-living bacteria.",2017,Environmental Microbiology
Linear Convergence of the Alternating Direction Method of Multipliers for a Class of Convex Optimization Problems,"The numerical success of the alternating direction method of multipliers (ADMM) inspires much attention in analyzing its theoretical convergence rate. While there are several results on the iterative complexity results implying sublinear convergence rate for the general case, there are only a few results for the special cases such as linear programming, quadratic programming, and nonlinear programming with strongly convex functions. In this paper, we consider the convergence rate of ADMM when applying to the convex optimization problems that the subdifferentials of the underlying functions are piecewise linear multifunctions, including LASSO, a well-known regression model in statistics, as a special case. We prove that due to its inherent polyhedral structure, a recent global error bound holds for this class of problems. Based on this error bound, we derive the linear rate of convergence for ADMM. We also consider the proximal based ADMM and derive its linear convergence rate.",2016,SIAM J. Numerical Analysis
An Evaluation of Health Centers and Hospital Efficiency in Kampala Capital City Authority Uganda; Using Pabon Lasso Technique,"The Pabon Lasso Model is one of the most important and suitable techniques applied in evaluating the performance of hospitals. The visual representation standardizes the comparative accomplishments of hospitals which information is used by planners in effort to improve productivity of the health care system by use of three pointers namely: (i) Average Length of Stay (ALS); (ii) Bed Occupancy Rate (BOR); (iii) Bed Turnover (BTO). The purpose of this study is to evaluate performance of wards in health centers affiliated to Kampala Capital City Authority (KCCA) and Ministry of Health (MOH) during the financial year 2012-2013 constructed on Pabon Lasso Model. Data for the nine health centers and two referral hospitals was taken by the nursing sisters who were in charge. To ensure accuracy, a weekly standard report was submitted to head office and the data included: a list of wards, number of beds, admissions, deaths, discharges and inpatient days. For all government health centers and hospitals, overall, the average indicators ALS=3.63 days, BTO= 74.0 times per year and BOR=49.3% were obtained. Based on the Pabon Lasso graph, two wards are in Zone 3, two wards in Zone 4, one ward in Zone 2 and five wards in Zone 1. The performance of health centers and hospitals in Kampala were somehow poor. This represented unacceptable levels of technical deficiency.",2015,Journal of Health and Translational Medicine
Peningkatan Aktivitas Pembelajaran Matematika Dengan Media Realistik Pada Peserta Didik Sekolah Dasar,"Faktor penyebab peserta didik kurang menguasaidan menerima materi pelajaran matematika di kelas II SDN 32 Pontianak Tenggara karena penjelasan guru bersifat abstrak. penjelasan guru terlalu cepat dan tidak memperhatikan kemampuan peserta didik. Tujuan dalam penelitian ini adalah untuk mengetahui dan mendapatkan kejelasan penggunaan media realistik untuk peningkatan aktivitas pembelajaran. Metode penelitian yang digunakan metode deskriptif dengan bentuk penelitian tindakan kelas. Dari hasil penelitian memperlihatkan Perencanaan penggunaan media realistik dapat meningkatkan aktivitas pembelajaran Matematika dengan menggunakan media realistik pada peserta didik kelas II SDN 32 Pontianak Tenggara, yaitu skor yang diperoleh pada tiap-tiap aspek mengalami peningkatan dan Siklus I dengan skor rata-rata sebesar 60,29%, dan meningkat pada Siklus II menjadi 92,63%. Kata Kunci: Peningkatan, Aktivitas Pembelajaran, Matematika, Media Realistik Abstract: The factor which causing the student less mastering and acceptingmathematic lesson at class II SDN 32 South East Pontianak because of the teachers explanation is abstrac, teachers explanation is too fast and does not give ettention to students alility. The purpose of this reaserch is for knowing and getting the clarity of realistic media to increase learning activity. The research which is used is desciptive method in the form of Classoom Action Research. From the research result shows the use of realistic media plan is able to increase mathematic learning activity by using realistic media to class II student SDN 32 South East Pontianak, that is, the score which is acquired in each aspect in each aspect increase and Cycle I wich the average score 60,29%, and increase in Cycle II Into 92,63%.",2013,
Akupunktur-Fortbildungswochen an der tÃ¼rkischen Riviera und auf der Insel Kos â€” Berichte,"Lernen dort, wo andere Urlaub machen, unter diesem Motto fand erstmalig eine Fortbildungswoche im fÃ¼r uns bestens geeignetem 5-Sterne all inclusive Evren BeachHotel in Side an der tÃ¼rkischen Riviera vom 21. bis 28. Mai 2016 unter der Kursleitung von Dr. med. JÃ¶rg Reibig statt. Den Schwerpunkt bildete das Thema: NatÃ¼rlich heilen bei Stress â€“ ErschÃ¶pfung â€“ Burn-out. Das GefÃ¼hl, stÃ¤ndig unter Stress zu stehen, nimmt zu, Stress und ErschÃ¶pfung entwickeln sich zum Dauerzustand. Ziel dieser Woche war es, multimodale Behandlungsprogramme bei diesen Erkrankungen fÃ¼r die tÃ¤gliche Praxis mittels Akupunktur, Neuraltherapie, Biologischer und Manueller Medizin gemeinsam zu erarbeiten. Nach dem morgendlichen Qigong, Yoga oder der Thalassotherapie am Strand gab es an den Vormittagen interessante VortrÃ¤ge in dem groÃŸzÃ¼gig ausgestatteten Seminarraum, wie z. B. â€žWie kann ich dem Stress rechtzeitig vorbeugen? Wie stelle ich die richtige Diagnose? Wie gefÃ¤hrdet bin ich selbst, und welche Therapien sind mÃ¶glich und sinnvoll? Welche Regeln muss ich fÃ¼r ein lÃ¤ngeres Leben einhalten? Welche Rolle spielen Infusionen, HomÃ¶opathie oder Meditation?â€œ. Einige TherapiemÃ¶glichkeiten konnten mittels Videofi lmen und Ãœbungen vertieft werden, z. B. beim Lachyoga oder bei der Zen-Meditation. Peter Sprenger von der Firma â€žschwa-medicoâ€œ stellte entsprechende Produkte seiner Firma, wie z. B. die Stimawellâ€“Matte vor. An den Nachmittagen konnte in den Workshops und QualitÃ¤tszirkeln geÃ¼bt werden, und es gab eine interessante EinfÃ¼hrung in die arabische Heilkunst Ã¼ber besondere Entspannungstechniken, Ã–lund Wasseranwendungen, Hamam oder Hotstone-Massagen durch den Leiter der medizinischen Abteilung des Hotels. NatÃ¼rlich gab es auch eine Fachexkursion, die unsere 15-kÃ¶pfi ge Gruppe nach Antalya zur Expo 2016 fÃ¼hrte, wo wir vielfÃ¤ltige EindrÃ¼cke mitnahmen. In den gemÃ¼tlichen abendlichen GesprÃ¤chsrunden konnten die gewonnenen Erkenntnisse und EindrÃ¼cke ausgetauscht und vertieft werden. Hier bot das Hotel viele MÃ¶glichkeiten. Insgesamt, so die EinschÃ¤tzung der Teilnehmer, die sogar auch aus Island kamen, war dies eine sehr gelungene Fortbildungswoche, die unbedingt einer Wiederholung bedarf.",2017,Deutsche Zeitschrift fÃ¼r Akupunktur
Astronomical Topics,"A New Algol-Variable in Andromeda.?Astr. Nach. 5877 contains a paper on this star by its discoverer, Herr K. Lassovszky. He found it on a plate that he took at Neubabelsberg on April 27, 1931? its position for the equinox of 1855 is 23h 42m 18s, N. Decl. 44Â° 58?4', and its designation 381, 1931 Andromeda. He took a series of plates on fifteen nights between July 23 and Aug. 21, 1931, to study the light curve? the period is 0?79365d or about 19 hours. The magnitude is 11?26 at maximum, and falls to 11?87 at minimum; the duration of eclipse is 0?160d? the light-curve appears pointed at minimum, showing that the eclipses are not annular, as in that case the curve is flat at minimum. The observations do not show any trace of a secondary minimum, such as occurs in Algol? it may be concluded that the eclipsing star is much fainter than the other. The star is less than 2Â° distant from ''Selected Area No. 43?? Herr Lassovszky utilised this fact to obtain the magnitudes of his comparison stars by comparing them with stars in that well-surveyed region. It reflects credit on a single observer to have both discovered the star's variability and deduced an accurate light-curve in the course of a year.",1932,Nature
Longâ€distance dispersal syndromes matter: diasporeâ€“trait effect on shaping plant distribution across the Canary Islands,"Oceanic islands emerge lifeless from the seafloor and are separated from continents by long stretches of sea. Consequently, all their species had to overcome this stringent dispersal filter, making these islands ideal systems to study the biogeographic implications of long-distance dispersal (LDD). It has long been established that the capacity of plants to reach new islands is determined by specific traits of their diaspores, historically called dispersal syndromes. However, recent work has questioned to what extent such dispersal-related traits effectively influence plant distribution between islands. Here we evaluated whether plants bearing dispersal syndromes related to LDD â€“ i.e. anemochorous (structures that favour wind dispersal), thalassochorous (sea dispersal), endozoochorous (internal animal dispersal) and epizoochorous (external animal dispersal) syndromes â€“ occupy a greater number of islands than those with unspecialized diaspores by virtue of their increased dispersal ability. We focused on the native flora of the lowland xeric communities of the Canary Islands (531 species) and on the archipelago distribution of the species. We controlled for several key factors likely to affect the role of LDD syndromes in inter-island colonization, namely: island geodynamic history, colonization time and phylogenetic relationships among species. Our results clearly show that species bearing LDD syndromes have a wider distribution than species with unspecialized diaspores. In particular, species with endozoochorous, epizoochorous and thalassochorous diaspore traits have significantly wider distributions across the Canary archipelago than species with unspecialized and anemochorous diaspores. All these findings offer strong support for a greater importance of LDD syndromes on shaping inter-island plant distribution in the Canary Islands than in some other archipelagos, such as Galapagos and Azores. 
 
This article is protected by copyright. All rights reserved.",2018,Ecography
Which environmental factors are associated with performance when controlling for capacity?,"OBJECTIVE
To determine which environmental factors are associated with performance when controlling for capacity, using the International Classification of Functioning, Disability and Health (ICF).


METHODS
A psychometric study using a sample of 296 persons with musculoskeletal health conditions as a case in point. The following steps were carried out: (i) Rasch analyses created 2 interval measurement scales, capacity and performance, based on 22 Activities and Participation ICF categories that had been rated as capacity and performance. Capacity and performance scores, ranging from 0 (low level) to 100 (high level) were calculated; (ii) group lasso regression was used to identify the environmental factors associated with a person's performance when controlling for capacity. Gender, age and health condition were forced to remain in the model.


RESULTS
A capacity scale based on 16 ICF categories (rated as capacity) and a performance scale based on 18 categories (rated as performance) were created. Thirteen environmental factors ICF categories covering the physical, social, attitudinal and political environment were identified as highly associated with patient's performance.


CONCLUSION
Using an exclusively statistical approach this study identified environmental factors associated with a person's performance.",2014,Journal of rehabilitation medicine
Classifying Big Data Over Networks Via The Logistic Network Lasso,We apply network Lasso to solve binary classification and clustering problems on network structured data. In particular we generalize ordinary logistic regression to non-Euclidean data defined over a complex network structure. The resulting logistic network Lasso classifier amounts to solving a convex optimization problem. A scalable classification algorithm is obtained by applying the alternating direction methods of multipliers.,2018,"2018 52nd Asilomar Conference on Signals, Systems, and Computers"
Online learning for linearly parametrized control problems,"In a discrete-time online control problem, a learner makes an effort to control the state of an initially unknown environment so as to minimize the sum of the losses he suffers, where the losses are assumed to depend on the individual state-transitions. Various models of control problems have been topic of intensive research for more than 50 years. Despite this, theoretical results for the online variant of the problem remain limited. In this thesis, we study several online control problems, ranging from the simplest state-less problems, also known as bandits, through classical control problems where the system dynamics is linear and the cost is quadratic in the state and the control, to more complex non-linear problems. The main topic is the design of algorithms for these problems and the development of finite-time performance guarantees for the algorithms proposed. 
A common theme of the problems is that they assume a linear parametric uncertainty. Accordingly, our methods employ a linear-in-the-parameters predictor and construct a confidence set that contains the true unknown parameter with sufficiently high probability. In particular, following the ""optimism in the face of uncertainty"" principle, the algorithms always use the parameter that gives rise to the lowest expected loss. In this framework, a tighter confidence set immediately results in a better performing online learning method. 
The first main contribution of the thesis is the construction of smaller confidence sets for the least-squares estimate. To arrive at these confidence sets, we derive a novel tail inequality for vector-valued martingales. Based on this new confidence set, we modify and, consequently, improve the analysis of the algorithm for the linear stochastic bandit problem studied by Auer (2002), Dani et al. (2008), and Rusmevichientong and Tsitsiklis (2010). Our modification improves the regret bound by a logarithmic factor, though experiments show a vast improvement. 
The second main contribution is the introduction of a novel technique to construct confidence sets, which we call online-to-confidence-set conversion. The technique allows us to construct high-probability confidence sets for linear prediction with correlated inputs given the predictions of any algorithm (e.g., online LASSO, exponentiated gradient algorithm (Kivinen and Warmuth, 1997), online least-squares (Lai et al., 1979, Auer et al., 2002b, Vovk, 2001), p-norm algorithms (Grove et al., 2001, Gentile and Littlestone, 1999)); in general, any algorithm whose objective is to achieve low regret with respect to the quadratic loss while using linear predictors. By construction, the size of the confidence set is directly governed by the regret of the online learning algorithm. As a result of this ""reductionist"" approach, progress in constructing better algorithms for online prediction problems directly translates into tighter confidence sets. 
As a demonstration of this new approach to constructing confidence sets, we introduce the sparse variant of linear stochastic bandits and show that a recent online algorithm together with our online-to-confidence-set conversion allows one to derive algorithms that can exploit if the unknown parameter vector determining the expected loss of actions is sparse. 
In the second part of the thesis, we study the average loss linear quadratic (LQ) control problem with unknown model parameters, also known as the LQ adaptive control problem in the control community. We design an algorithm and prove that its regret up to time T, apart from logarithmic factors, is O( T ). To the best of our knowledge, this is the first time that an algorithm designed for this problem is shown to enjoy a sublinear finite-time regret bound. We also show that similar techniques can be employed to design and analyze an algorithm for a more general problem with nonlinear dynamics but linear parametric uncertainty. To the best of our knowledge this is the first time that regret bounds are derived for these classes of control problems.",2012,
The Development of the English Language Teaching in the High Schools of Ecuador during the last two decades,"espanolAntes del ano 1912, la ensenanza del idioma ingles en las escuelas secundarias de Ecuador era completamente extrana. Fue despues de ese ano que este idioma comenzo a ensenarse en muchas escuelas de este pais. Se convirtio en obligatorio en todo Ecuador en 1950, bajo el gobierno de Galo Plaza Lasso. Al principio habia menos horas de ensenanza de ingles y no habia suficientes profesores de ingles, pero con el transcurso del tiempo esta situacion cambio favorablemente. Hace veinte anos, la ensenanza del idioma ingles en Ecuador mejoro gracias al proyecto CLADLE, implementado por el Ministerio de Educacion de Ecuador. Mas tarde, la educacion experimento cambios positivos cuando Rafael Correa se convirtio en el nuevo presidente de Ecuador en 2007. Su gobierno tambien hizo algunos cambios con respecto a los derechos de maestros y estudiantes. Ahora los profesores de ingles tienen que tomar un examen TOEFL y obtener un certificado de nivel B2 o superior. Afortunadamente, en los ultimos veinte anos, la ensenanza del idioma ingles en Ecuador se ha desarrollado gradualmente, hasta tal punto que ahora se ensena en todas las escuelas, ya sean publicas, privadas o parroquiales. portuguesOs Antes de 1912, o ensino da lingua inglesa nas escolas secundarias do Equador era completamente estranho. Foi depois daquele ano que esse idioma comecou a ser ensinado em muitas escolas deste pais. Tornou-se obrigatorio em todo o Equador em 1950, sob o governo do Galo Plaza Lasso. No inicio, havia menos horas de ensino de ingles e nao havia professores de ingles suficientes, mas com o tempo essa situacao mudou favoravelmente. Vinte anos atras, o ensino da lingua inglesa no Equador melhorou gracas ao projeto CLADLE,implementado pelo Ministerio da Educacao do Equador. Mais tarde, a educacao sofreu mudancas positivas quando Rafael Correa se tornou o novo presidente do Equador em 2007. Seu governo tambem fez algumas mudancas em relacao aos direitos dos professores e dos alunos. Agora, os professores de ingles precisam fazer um teste TOEFL e obter um certificado de nivel B2 ou superior. Felizmente, nos ultimos vinte anos, o ensino da lingua inglesa no Equador se desenvolveu gradualmente, a tal ponto que agora e ensinado em todas as escolas, publicas, particulares ou paroquiais. EnglishBefore the year 1912, the English Language Teaching in high schools of Ecuador was completely strange. It was after that year that this language started to be taught in many schools of this country. It became mandatory all over in Ecuador in 1950, under the government of Galo Plaza Lasso. At first, there were fewer hours of English teaching and there were not enough English teachers, but with the course of time, this situation changed favorably. Twenty years ago, the English Language Teaching in Ecuador improved thanks to the project CLADLE, implemented by the Ministry of Education of Ecuador. Later on, the education experienced positive changes when Rafael Correa became the new president of Ecuador in 2007. His government also made some changes regarding teacher and student rights. Now English teachers have to take a TOEFL test and get a B2 level certificate or higher. Fortunately, over the last twenty years, the English Language Teaching in Ecuador has gradually developed, to such an extent that it is now taught in every school, either public, private or parochial schools.",2019,
Peningkatan Kemampuan Membaca Pemahaman Dengan Menggunakan Media Komik Di Sekolah Dasar,"Abstrak: Penelitian ini bertujuan untuk mendeskripsikan peningkatan kemampuan membaca pemahaman dengan menggunakan media komik di kelas VB SDN 24 Pontianak Tenggara Provinsi Kalimantan Barat. metodeÂ  penelitian yang digunakan adalah deskriptif. Bentuk penelitian yaitu survey. Sifat penelitian adalah Penelitian Tindakan Kelas ( Classroom Action Research ) serta bersifat kolaboratif. Tempat penelitian berlangsung di SDN 24 Pontianak Tenggara, subyek penelitian adalah siswaÂ  kelas VB yang berjumlah 32 orang dan guru mata pelajaran bahasa Indonesia. Hasil analisis data pada tahap baseline menunjukan bahwa ketuntasan belajar siswa hanya mencapai 43,75%, sehingga diberikan tindakan dengan menggunakan media komik untuk meningkatkan kemampuan membaca pemahaman siswa. Kata kunci: Peningkatan , Kemampuan , Membaca Pemahaman . Abstract: This study aims to describe the increase in the ability of reading comprehension by using media of comic in the classoom VB grade studentâ€™s in SDN 24 Pontianak Tenggara West Borneo provinci. The research method used is descriptive. The research survey form. Nature of the research is action research and collaborative. Where the research took place in SDN 24 Pontianak Tenggara, the subjects were students in the class VB totaling 32 people and Â the bahasa Indonesia teacher. The result of the data analys showed that baseline stage of mastery learning students only reaches 43.75%, so that given an action using the comic medium to improve studentâ€™s comprehension. Keywords: Writing of poetry, environment, learning resource.",2014,
Heterogeneous feature selection by group lasso with logistic regression,"The selection of groups of discriminative features is critical for image understanding since the irrelevant features could deteriorate the performance of image understanding. This paper formulates the selection of groups of discriminative features by the extension of group lasso with logistic regression for high-dimensional feature setting, we call it as the heterogeneous feature selection by Group Lasso with Logistic Regression (GLLR). GLLR encodes a sparse grouping prior to seek after a more interpretable model for feature selection and can identify most of discriminative groups of homogeneous features. The utilization of GLLR for image annotation shows the proposed GLLR achieves a better performance.",2010,
GRB10 and E2F3 as Diagnostic Markers of Osteoarthritis and Their Correlation with Immune Infiltration,"This study aimed to find potential diagnostic markers for osteoarthritis (OA) and analyze the role of immune cells infiltration in this pathology. We used OA datasets from the Gene Expression Omnibus database. First, R software was used to identify differentially expressed genes (DEGs) and perform functional correlation analysis. Then least absolute shrinkage and selection operator (LASSO) logistic regression and support vector machine-recursive feature elimination algorithms were used to screen and verify the diagnostic markers of OA. Finally, CIBERSORT was used to evaluate the infiltration of immune cells in OA tissues, and the correlation between diagnostic markers and infiltrating immune cells was analyzed. A total of 458 DEGs were screened in this study. GRB10 and E2F3 (AUC = 0.962) were identified as diagnostic markers of OA. Immune cell infiltration analysis found that resting mast cells, T regulatory cells, CD4 memory resting T cells, activated NK cells, and eosinophils may be involved in the OA process. In addition, GRB10 was correlated with NK resting cells, naive CD4 + T cells, and M1 macrophages, while E2F3 was correlated with resting mast cells. In conclusion, GRB10 and E2F3 can be used as diagnostic markers of osteoarthritis, and immune cell infiltration plays an important role in the occurrence and progression of OA.",2020,Diagnostics
Words of wisdom. Re: Video technique for human robot-assisted microsurgical vasovasostomy.,"[1] Morgan VA, Riches SF, Thomas K, et al. Diffusion-weighted magnetic resonance imaging for monitoring prostate cancer progression in patients managed by active surveillance. Br J Radiol 2011;84:31â€“7. [2] Giannarini G, Petralia G, Thoeny HC. Potential and limitations of diffusion-weighted magnetic resonance imaging in kidney, prostate, and bladder cancer including pelvic lymph node staging: a critical analysis of the literature. Eur Urol 2012;61:326â€“40. [3] Engelhard K, Hollenbach HP, Kiefer B, et al. Prostate biopsy in the supine position in a standard 1.5-T scanner under real time MR-imaging control using a MR-compatible endorectal biopsy device. Eur Radiol 2006;16:1237â€“43. [4] Singh AK, Kruecker J, Xu S, et al. Initial clinical experience with realtime transrectal ultrasonography-magnetic resonance imaging fusion-guided prostate biopsy. BJU Int 2008;101:841â€“5. [5] Xu H, Lasso A, Vikal S, et al. MRI-guided robotic prostate biopsy: a clinical accuracy validation. Med Image Comput Comput Assist Interv 2010;13:383â€“91.",2012,European urology
Development of a Predictive Model of Difficult Hemostasis following Endobronchial Biopsy in Lung Cancer Patients,"Endobronchial biopsy (EBB)-induced bleeding is fairly common; however, it can be potentially life-threatening due to difficult hemostasis following EBB. The aim of this study was to develop a predictive model of difficult hemostasis post-EBB. A total of 620 consecutive patients with primary lung cancer who had undergone EBB between 2014 and 2018 in a large tertiary hospital were enrolled in this retrospective single-center cohort study. Patients were classified into the difficult hemostasis group and the nondifficult hemostasis group according to hemostatic measures used following EBB. The LASSO regression method was used to select predictors and multivariate logistic regression was applied to develop the predictive model. The area under the curve (AUC) of the model was calculated. Bootstrapping method was applied for internal validation. Calibration curve analysis and decision curve analysis (DCA) were also performed. A nomogram was constructed to display the model. The incidence of difficult hemostasis post-EBB was 11.9% (74/620). Eight variables were selected by the LASSO regression analysis and seven (histological type of cancer, lesion location, neutrophil percentage, activated partial thromboplastin time, low density lipoprotein cholesterol, apolipoprotein-E, and pulmonary infection) of them were finally included in the predictive model. The AUC of the model was 0.822 (95% CI, 0.777-0.868), and it was 0.808 (95% CI, 0.761-0.856) in the internal validation. The predictive model was well calibrated and DCA indicated its potential clinical usefulness, which suggests that the model has great potential to predict lung cancer patients with a more difficult post-EBB hemostasis.",2019,BioMed Research International
Soluble intercellular adhesion molecule-1 is associated with hepatocellular carcinoma risk: multiplex analysis of serum markers,"Individualized assessment of hepatocellular carcinoma (HCC) risk in chronic liver disease remains challenging. Serum biomarkers including cytokines may offer helpful adjuncts to standard parameters for risk prediction. Our aim was to identify markers associated with increased HCC incidence. This was a prospective cohort study of 282 patients with both viral or non-viral chronic liver disease. Baseline serum cytokines and other markers were measured in multiplex with a commercially-available Luminex-based system. Patients were followed until death or HCC diagnosis. We performed Lasso-based survival analysis to determine parameters associated with HCC development. Cytokine mean florescence intensity (MFI) was the primary predictor and HCC development the primary outcome. 25 patients developed HCC with total follow-up of 1,363 person-years. Parameters associated with increased HCC incidence were cirrhosis, hepatic decompensation, and soluble serum intercellular adhesion molecule 1 (sICAM-1) MFI. No other molecules increased predictive power for HCC incidence. On univariate analysis, the parameters associated with HCC incidence in patients with cirrhosis were age, antiviral treatment, and high sICAM-1 MFI; on multivariate analysis, sICAM-1 remained associated with HCC development (adjusted HRâ€‰=â€‰2.75). On unbiased screening of serum cytokines and other markers in a diverse cohort, baseline sICAM-1 MFI is associated with HCC incidence.",2017,Scientific Reports
"Contemporary meanings of female circumcision / female genital mutilation (FC/FGM) in Bobo-Dioulasso, Burkina Faso","Diese Dissertation beschaftigt sich mit der aktuellen Bedeutung von weiblicher Genitalverstummelung/ weiblicher Beschneidung (FC/FGM) in Bobo-Dioulasso, Burkina Faso, wo seit der Kolonialzeit in der einen oder anderen Form Kampagnen gegen FC/FGM durchgefuhrt werden. In Bobo-Dioulasso scheinen lokale Umstande und globale Prozesse in Kontext von FC/FGM in einer Form einer â€žglobalem Assemblageâ€œ ineinanderzugreifen. Die Anwendung des Konzepts der â€žglobalen Assemblageâ€œ in diesem thematischen Kontext erlaubt die Komplexitat des Phanomens einer â€žglobalen anti-FC/FGM Formationâ€œ zu beleuchten, und wie lokale und globale Ansichten zu FC/FGM aufeinandertreffen und interagieren. Mit einem Fokus auf das Lokale rekonstruiert diese Dissertation wie globale und lokale Narrative uber FC/FGM hinsichtlich Moralitat, Sexualitat, Korper und Gesundheit, sowie Reinheit, miteinander verflochten sind.",2014,
Large-Scale Directed Model Checking LTL,"To analyze larger models for explicit-state model checking, directed model checking applies error-guided search, external model checking uses secondary storage media, and distributed model checking exploits parallel exploration on multiple processors. 
 
In this paper we propose an external, distributed and directed on-the-fly model checking algorithm to check general LTL properties in the model checker SPIN. Previous attempts are restricted to checking safety properties. The worst-case I/O complexity is bounded by $O(\mbox{\em sort}(|{\cal F}||{\cal R}|)/p+ l \cdot \mbox{\em scan}(|{\cal F}||{\cal S}|))$, where ${\cal S}$ and ${\cal R}$ are the sets of visited states and transitions in the synchronized product of the Buchi automata for the model and the property specification, ${\cal F}$ is the number of accepting states, l is the length of the shortest counterexample, and p is the number of processors. The algorithm we propose returns minimal lasso-shaped counterexamples and includes refinements for property-driven exploration.",2006,
Spa Bodywork: A Guide for Massage Therapists,SPA FOUNDATIONS Overview of the Spa Industry Preparation for Spa Treatment Delivery Foundation Skills for Spa Treatment Delivery Water Therapies Introduction to Aromatherapy for Spa TREATMENTS Exfoliation Treatments Body Wraps Spa Foot Treatments Fangotherapy Thalassotherapy Ayurveda for Spa: An Introduction Stone Massage PUTTING IT ALL TOGETHER Treatment Design and the Signature Spa Treatment Careers in Spa Appendix A: Master List of Essential Oils and Botanical Names Appendix B: Resources Appendix C: Ready to Copy Forms Appendix D: Answers to Chapter Review Questions Glossary Index,2006,
Fistula-first and catheter-last: fading certainties and growing doubts.,"vation in childhood steroid-sensitive nephrotic syndrome. Clin Nephrol 2003; 60: 242â€“247 31. Sfikakis PP, Boletis JN, Lionaki S et al. Remission of proliferative lupus nephritis following B cell depletion therapy is preceded by down-regulation of the T cell costimulatory molecule CD40 ligand: an open-label trial. Arthritis Rheum 2005; 52: 501â€“513 32. Fervenza FC, Abraham RS, Erickson SB et al. Rituximab therapy in idiopathic membranous nephropathy: a 2-year study. Clin J Am Soc Nephrol 2010; 5: 2188â€“2198 33. Hultin LE, Hausner MA, Hultin PM et al. CD20 (pan-B cell) antigen is expressed at a low level on a subpopulation of human T lymphocytes. Cytometry 1993; 14: 196â€“204 34. Sahali D, Pawlak A, Le Gouvello S et al. Transcriptional and post-transcriptional alterations of IkappaBalpha in active minimal-change nephrotic syndrome. J Am Soc Nephrol 2001; 12: 1648â€“1658 35. Martin F, Chan AC. Pathogenic roles of B cells in human autoimmunity; insights from the clinic. Immunity 2004; 20: 517â€“527 36. Ishimoto T, Shimada M, Araya CE et al. Minimal change disease: a CD80 podocytopathy? Semin Nephrol 2011; 31: 320â€“325 37. Fornoni A, Sageshima J, Wei C et al. Rituximab targets podocytes in recurrent focal segmental glomerulosclerosis. Sci Translat Med 2011; 3: 85ra46 38. Calabrese LH, Molloy ES, Huang D et al. Progressive multifocal leukoencephalopathy in rheumatic diseases: evolving clinical and pathologic patterns of disease. Arthritis Rheum 2007; 56: 2116â€“2128 39. Glassock RJ. Therapy of relapsing minimal-change disease in adults: a new approach? Kidney Int 2013; 83: 343â€“345",2014,"Nephrology, dialysis, transplantation : official publication of the European Dialysis and Transplant Association - European Renal Association"
Automated clear cell renal carcinoma grade classification with prognostic significance,"We developed an automated 2-tiered Fuhrman's grading system for clear cell renal cell carcinoma (ccRCC). Whole slide images (WSI) and clinical data were retrieved for 395 The Cancer Genome Atlas (TCGA) ccRCC cases. Pathologist 1 reviewed and selected regions of interests (ROIs). Nuclear segmentation was performed. Quantitative morphological, intensity, and texture features (n = 72) were extracted. Features associated with grade were identified by constructing a Lasso model using data from cases with concordant 2-tiered Fuhrman's grades between TCGA and Pathologist 1 (training set n = 235; held-out test set n = 42). Discordant cases (n = 118) were additionally reviewed by Pathologist 2. Cox proportional hazard model evaluated the prognostic efficacy of the predicted grades in an extended test set which was created by combining the test set and discordant cases (n = 160). The Lasso model consisted of 26 features and predicted grade with 84.6% sensitivity and 81.3% specificity in the test set. In the extended test set, predicted grade was significantly associated with overall survival after adjusting for age and gender (Hazard Ratio 2.05; 95% CI 1.21-3.47); manual grades were not prognostic. Future work can adapt our computational system to predict WHO/ISUP grades, and validating this system on other ccRCC cohorts.",2019,PLoS ONE
Multivariate Probabilistic Analysis and Predictability of Medium-Range Ensemble Weather Forecasts,"AbstractEnsemble weather forecasting has been operational for two decades now. However, the related uncertainty analysis in terms of probabilistic postprocessing still focuses on single variables, grid points, or stations. Inevitable dependencies in space and time and between variables are often ignored. To address this problem, two probabilistic postprocessing methods are presented, which are multivariate versions of Gaussian fit and kernel dressing, respectively. The multivariate case requires the estimation of a full rank, invertible covariance matrix. For this purpose, a Graphical Least Absolute Shrinkage and Selection Operators (GLASSO) estimator has been employed that is based on sparse undirected graphical models regularized by an L1 penalty term in order to parameterize the full rank inverse covariance. In all cases, the result is a multidimensional probability density. The forecasts used to test the approach are station forecasts of 2-m temperature and surface pressure from four main global ensem...",2014,Monthly Weather Review
Application of lasso technique for laparoscopic distal pancreatectomy,"Objective To explore the clinical application of lasso technique for laparoscopic distal pancreatectomy. Methods From Sept. 2005 to Sept. 2009,14 patients underwent laparoscopic distal pancreatectomy by using lasso techinique in our department. Results The laparoscopic procedures were successfully completed in all the 14 cases, with an average operation time of 222.5 (ranging 120-360) min and a median intraoperative blood loss of 300 (ranging 100-1 200) mL. The mean postoperative hospitalization was 17 (ranging 9-51) days. There were one minor pancreatic leak, one sinus tract hemorrhage, and one pleural fluid collection; all of them were resolved conservatively. One patient experienced an incisional hernia 4 months after operation. Conclusion The lasso technique simplifies intraoperative manipulation of the pancreas during laparoscopic distal pancreatectomy, allowing for safe, gentle manipulation; it expands the indications for this approach to pancreatic resection; and the method is worth popularizing.",2010,Shanghai Medical Journal
Quantifying the Link between Employee Engagement and Customer Satisfaction in the Car Rental Industry,"In the retail service industry, employee engagement may play an important role in customer relationship management, as employees often interact directly with customers. This paper investigates the link between employee engagement and customer satisfaction. We analyze this potential link using a unique data set from a large car rental company. Our analysis accounts for the possibility that employee engagement is endogenously determined. To address potential endogeneity of employee engagement, we make use of instrumental variables based on location and time varying employee composition. Our analysis confirms that there is a positive effect of employee engagement on customer satisfaction, which can in turn increase customer loyalty. The causal link between employee engagement and customer satisfaction is especially important, as our analysis using LASSO (for variable subset selection) highlights that customer satisfaction is among the most important predictors of customer loyalty. Ultimately, our findings have implications not just for customer targeting but also firm resource allocation decisions regarding employee motivation.",2018,
Abstract A030: Biomarker study of vantictumab plus paclitaxel in HER2- breast cancer patients,"Introduction: We have developed a monoclonal antibody, vantictumab, that blocks canonical Wnt/Î²-catenin signaling through binding of five FZD receptors (1, 2, 5, 7, and 8). This antibody inhibits the growth of several tumor types, including breast. Vantictumab reduces tumor-initiating cell frequency and exhibits synergistic activity with standard-of-care (SOC) agents (Gurney et al., 2012). To confirm the mechanism of action and to potentially target breast cancer patients most likely to respond to vantictumab, we undertook a biomarker study. Methods: We previously identified a 6-gene Wnt pathway-related signature, FBXW2, CCND2, RHOU, CTBP2, WIF1, and DKK1, based on microarray gene expression data from 8 BC patient-derived xenograft (PDX) models with established in vivo response to vantictumab plus SOC. This signature successfully predicted the response of 8 additional and independent PDX breast tumors. We further developed a qPCR Research Use Only (RUO) assay for the 6 genes for use on FFPE human breast tumor samples. This assay was evaluated in the phase 1b study of vantictumab in combination with paclitaxel in locally recurrent or metastatic HER2- breast cancer (NCT01973309) and the signature was refined using a Lasso model with overall survival as the outcome. A repeated 10 fold cross-validation was used to evaluate the performance of the gene signature. The association of the signature with progression-free survival (PFS) and overall survival (OS) was examined (n=40 patients). Furthermore, pharmacodynamic (PD) biomarker analyses were performed on tumor biopsies and hair follicles by comparing gene expression data from post-treatment time points versus baseline data (Affymetrix U133 plus 2 Microarrays). Results: A potential predictive 6-gene Wnt pathway biomarker was identified based on preclinical data and the biomarker was evaluated and refined in a phase 1b study of vantictumab in combination with paclitaxel in HER2- breast cancer. In the phase 1b study, AUC = 75% with repeated 10 fold cross-validation measuring the performance of the gene signature. Based on this analysis, two genes, RHOU and DKK1, were dropped from the preclinical gene signature, which was consistent with the feature ranking in the preclinical qPCR data. The refined 4-gene signature was significantly associated with both PFS and OS at a 50% percentile cut-off. In addition, analysis of PD biomarkers demonstrated that Wnt pathway target genes including AXIN2, LEF1, and CTNNB1 were downregulated while differentiation markers, e.g., KRT19 and Wnt pathway inhibitors, e.g., SFRP1, DKK3 were upregulated by vantictumab plus paclitaxel. Conclusions: We developed a 4-gene signature as a potential predictive biomarker for the response to vantictumab plus paclitaxel in HER2- breast cancer. PD biomarker analysis in tumors and hair follicles confirmed the mechanism of action of vantictumab in patient samples. Preliminary efficacy of vantictumab plus paclitaxel in the phase 1b study was encouraging, particularly in breast cancer patients positive for the 4-gene signature. Updated biomarker and PK/PD data from the phase 1b trial (NCT01973309) will also be presented. Citation Format: Chun Zhang, William R. Henner, Min Wang, Fiore Cattaruzza, Pete Yeung, Gilbert O9Young, Yuwang Liu, Gretchen Argast, Lu Xu, Shailaja Uttamsingh, John Lewicki, Ann M. Kapoun. Biomarker study of vantictumab plus paclitaxel in HER2- breast cancer patients [abstract]. In: Proceedings of the AACR-NCI-EORTC International Conference: Molecular Targets and Cancer Therapeutics; 2017 Oct 26-30; Philadelphia, PA. Philadelphia (PA): AACR; Mol Cancer Ther 2018;17(1 Suppl):Abstract nr A030.",2018,Biomarkers
Evaluation de l'efficacitÃ© de la lutte chimique contre Helicoverpa armigera sur le cotonnier durant la campagne agricole 1996 au Burkina Faso,"ln 1996, the cotton subsector in Burkina Faso experienced a great crisis which was drama-like here and there. An exceptionally high infestation of cotton plants by the main pest, Helicoverpa armigera (a density of 167n500 worms par hectare) on treated plots whereas the theoretical intervention threshold is ranging from 5,000 to 12,500 Army-worms per hectare could not be controlled by the released insecticides. This year, the infestation intensity was at least sirnilar with the one of the year 1991 in which harvest losses had been estimated at 50,000 tons of seed cotton (NIBOUCHE 1994), i.e. a loss of about 20 billion francs CFA. The aftermath was really heavy for the productucers, SOFITEX and the Burkina state. Four years later, well-informed and well-advised experts take into consideration the natural factors and hurnan opcrational factors that are the source of this economie drarna : findings from two independent expert reports produced according to Laboratory Good Pratices (GLP) at the request of civil society on sorne pesticides, highlited concordantly their poor quality (low active ingredient. content, poor quality of formulations). This work, whilst restoring truth in a fair and unbiased way, states the reasons for our past and current failures as weil as the reasons for our future suc cesses. By proposing a new approach to studies on the efficacy of cotton insecticides, tbis work contributes to the seeking of a better phytosanitary protection for cotton in the countries of the sub-region. Key-Works : Helicoverpa armigera ; insecticide; formulation; resistance (1) 1. Institut de Recherches en Sciences dela SantÃ© (IRSS), DÃ©lÃ©gation RÃ©gionale de l'Ouest SIC Centre Muraz OP 153 Fax : 97 28 24 E-m:lil : :lls:lnou@f:lSoncl.bfl3obo-Dioul:lSso 2.INERA-Programme Coton BP 208, TÃ©l. : 97-21-<l5 F:lX 97-<l1Â·59 Evrnail : ohcm:I@f:lSOnel.bf Bobo-Dioulasso 3. UniversitÃ© de Chimie analytique et Phytopharmacie, Fac. Univ. des Sciences Agronomiques de Gembloux (FUSAGX), 2, passage des DÃ©portÃ©s 8-5030 Gembloux, TÃ©l. : +32 (0) 81 6222 15 F:I!t +32 (0) 81 6222 16 E-m:lil : schifTers.b@fSllgx.:lc.be Etudes t'( recherches suhÃ©licnnrs N"".4-5 janvier dÃ©cembre 2000",2000,
Un sÃ©lecteur de Dantzig pour l'apprentissage par diffÃ©rences temporelles,"En apprentissage par renforcement, LSTD est l'un des algorithmes d'approximation de la fonction de valeur les plus populaires. Lorsqu'il y a plus de fonctions de base que d'exemples, un probleme se pose, qui peut etre traite en combinant LSTD avec une forme de regularisation. En particulier, les methodes de regularisation 1 tendent a selectionner les fonctions de base (en favorisant la parcimonie des solutions) et sont donc particulierement adaptees pour les problemes de grande dimension. Toutefois, LSTD n'est pas un simple algorithme de regression ; il resout un probleme de point fixe, l'integration d'une regularisation 1 n'est pas evidente et peut entrainer certains inconvenients (comme l'hypothese de P-matrice pour LASSO-TD). Cette contribution introduit un nouvel algorithme qui integre LSTD au selecteur de Dantzig, generalisant ce dernier a l'apprentissage par differences temporelles. En particulier, nous etudions les performances de l'algorithme propose ainsi que son lien avec les approches de l'etat de l'art, notamment la facon dont il surmonte certains inconvenients des solutions existantes.",2012,
Deep Learning-based Radiomic Features for Improving Neoadjuvant Chemoradiation Response Prediction in Locally Advanced Rectal Cancer,"PURPOSE
Radiomic features achieve promising results in cancer diagnosis and treatment response prediction. The goal of this study is to compare the handcrafted, or explicitly designed, radiomic features and deep learning (DL)-based radiomic features extracted from pre-treatment diffusion-weighted magnetic resonance images (DWIs) for predicting neoadjuvant chemoradiation treatment (nCRT) response in patients with locally advanced rectal cancer (LARC).


MATERIALS AND METHODS
43 patients receiving nCRT were included. All patients underwent DWIs before nCRT and total mesorectal excision surgery after nCRT. Gross tumor volume (GTV) contours were drawn by an experienced radiation oncologist on DWIs. The patient-cohort was split into the responder group (n=22) and the non-responder group (n=21) based on the post-nCRT response assessed by postoperative pathology, MRI or colonoscopy. Handcrafted and DL-based features were extracted from the apparent diffusion coefficient (ADC) map of the DWI using conventional computer-aided diagnosis methods and a pre-trained convolution neural network, respectively. Least absolute shrinkage and selection operator (LASSO)-logistic regression models were constructed using extracted features for predicting treatment response. The model performance was evaluated with repeated 20 times stratified 4-fold cross-validation using receiver operating characteristic (ROC) curves and compared using the corrected resampled t-test.


RESULTS
The model built with handcrafted features achieved the mean area under the ROC curve (AUC) of 0.64, while the one built with DL-based features yielded the mean AUC of 0.73. The corrected resampled t-test on AUC showed P-value < 0.05.


CONCLUSION
DL-based features extracted from pre-treatment DWIs achieved significantly better classification performance compared with handcrafted features for predicting nCRT response in LARC patients.",2020,Physics in medicine and biology
Sparse Tensor Graphical Model: Non-convex Optimization and Statistical Inference,"We consider the estimation and inference of sparse graphical models that characterize the dependency structure of high-dimensional tensor-valued data. To facilitate the estimation of the precision matrix corresponding to each way of the tensor, we assume the data follow a tensor normal distribution whose covariance has a Kronecker product structure. A critical challenge in the estimation and inference of this model is the fact that its penalized maximum likelihood estimation involves minimizing a non-convex objective function. To address it, this paper makes two contributions: (i) In spite of the non-convexity of this estimation problem, we prove that an alternating minimization algorithm, which iteratively estimates each sparse precision matrix while fixing the others, attains an estimator with the optimal statistical rate of convergence. Notably, such an estimator achieves estimation consistency with only one tensor sample, which was not observed in the previous work. (ii) We propose a de-biased statistical inference procedure for testing hypotheses on the true support of the sparse precision matrices, and employ it for testing a growing number of hypothesis with false discovery rate (FDR) control. The asymptotic normality of our test statistic and the consistency of FDR control procedure are established. Our theoretical results are further backed up by thorough numerical studies. We implement the methods into a publicly available R package Tlasso.",2016,arXiv: Machine Learning
The â€œatrial arrhythmic stormâ€ phenomenon after segmental pulmonary veins isolation in patients with paroxysmal atrial fibrillation,"Objective The aim of this study was to investigate the mechanisms and the possible treatment of early and frequent recurrence of atrial fibrillation after segmental pulmonary veins isolation (PVI) in patients with paroxysmal atrial fibrillation (AF). Methods and Results Guided by Lasso mapping catheter, segmental pulmonary veins isolation was performed using radiofrequency energy in 54 consecutive patients (mean age 53Â±15 years) with recurrent documented symptomatic paroxysmal AF. Early recurrence of AF and rapid atrial arrhythmia occurred in 10 out of 54 patients (18.5%) within two weeks after PVI. 4 out of 10 patients (7.4 %) experienced early and frequent recurrence of atrial fibrillation and atrial tachyarrhythmia, which we termed as â€œatrial arrhythmic storm"". The 4 patients were treated with class â…  and â…¢ antiarrhythmic drugs for 3 months. The â€œatrial arrhythmic storm"" subided apparently and disappeared within two weeks after antiarrhythmic drug therapy. Only 1 patient still suffered from paroxysmal AF after drug control at mean follow-up of 3 months. After repeat ablation, there was no occurrence of AF and atrial arrhythmia in this patient.Conclusion A few paroxysmal atrial fibrillation patients experienced â€œatrial arrhythmic storm"" after segmental pulmonary veins isolation. It is suggested that â€œatrial arrhythmic storm"" after PVI may due to a lot of factors and combined antiarrhythmic drug therapy may be feasible. Early repeat ablation in patients with â€œatrial arrhythmic storm"" may not be necessary.",2005,Chinese Journal of Interventional Cardiology
TRB 6 / 18 Differential Privacy for Regularised Linear Regression,"Recent attacks on machine learning models such as membership inference attacks increase the concern for privacy. Linear regression is such an essential statistical machine learning model at risk. For a given dataset, linear regression determines the parameters of the linear equation connecting the predictor variables to the response variable. As such linear regression yields a set of unstable and overfitted parameters. Regularisation terms are added to the loss function of linear regression in order to avoid overfitting. LASSO, ridge, and elastic net are three variants of regularised linear regression. We present an -differentially private functional mechanism for the aforementioned variants of regularised linear regression. We empirically and comparatively analyze its effectiveness. A functional mechanism achieves differential privacy for linear regression by adding noise to the loss function. We empirically show that an -differentially private functional mechanism causes more error than the non-private linear regression models whereas their performances are comparable. We also discuss caveats in the functional mechanism, such as non-convexity of the noisy loss function, which causes instability in the results of differentially private linear regression models. This discussion puts forth the need of designing a differentially private mechanism that produces a noisy loss function that is convex.",2018,
P608: Ultrasound as a novel instrument for tremor evaluation and intervention,"s of Poster Presentations / Clinical Neurophysiology 125, Supplement 1 (2014) S1â€“S339 S213 P605 Peroneal nerve damage after knee dislocation. Clinic, neurophysiology and ultrasound in diagnosis, prognosis, treatment and rehabilitation D. Coraci1, V. Santilli1, G. Granata2, I. Paolasso2, H. Tsukamoto3, L. Padua2,4 1Sapienza University, Board of Physical Medicine and Rehabilitation, Rome, Italy; 2UniversitÃ  Cattolica del Sacro Cuore, Institute of Neurology, Rome, Italy; 3Teikyo University, Institute of Neurology, Tokyo, Japan; 4Don Gnocchi ONLUS Foundation, Milan, Italy Question: Peroneal nerve palsy may occur after a close traumatic knee dislocation. Ultrasound shows its usefulness in traumatic nerve injures. Methods: We present 5 patients with a history of knee dislocation associated with peroneal nerve damage, evaluated by clinical, neurophysiologic and ultrasonographic (US) examination. All the patients were examined in follow-up. At the first evaluation, the patients presented a severe clinic and neurophysiologic damage of peroneal nerve. US showed an increase of the cross sectional area (CSA) of the involved peroneal nerve, between popliteal fossa and fibular head. Results: Among these, 4 subjects presented a CSA four-seven times larger than normal, while one subject had the damaged nerve CSA only double compared to the other side. The first 4 patients did not present improvement in clinical, neurophysiologic and ultrasonographic follow-up. The latter one showed a general improvement in the later evaluations. Conclusions: This observation let us consider that larger is the CSA of the involved peroneal nerve and worse is the prognosis for the patient. Associating neurophysiology to US evaluation, we can obtain a guide for diagnosis, treatment and rehabilitation. In fact this combined evaluation gives data about the specific details and the changes over the time of the condition. This allow us to perform the best management for every individual case. P606 Ultrasonic evaluation as a method for determining diagnosis underlying clinical symptoms of carpal tunnel syndrome N. Wolfram, U. van Deurs, M. Lauritzen Glostrup Hospital, Department of Clinical Neurophysiology, Glostrup, Denmark Background: High resolution ultrasound (HRUS) was used to differentiate carpal tunnel syndrome (CTS) from other pathologies in the media nerve. Materials and methods: Forty-one patients, referred for diagnosis of CTS, were examined with HRUS supplemental to electrodiagnostic (EDX) evaluation when the medical history gave suspicion of polyneuropathy, cervical root affection on MRI scans, trauma or EDX changes not typical for CTS. Results: Twelve patients showed CTS in both EDX (29%) and HRUS, two patients had a bifid median nerve, one was supplemental investigated for HNPP. Seventeen patients had normal EDX (42%). Eight had normal findings by HRUS, five had CTS in HRUS, whereas four patients showed other pathologies including neurovascular contacts, bifid median nerve, partial nerve compression under the flexor retinaculum, palmaris muscle contacts and arthritis. Twelve patients showed atypical changes in EDX (29%). In this group, eight patients showed CTS in HRUS, four patients showed other pathologies including fibrolipomatous harmatoma, intraneural venous congestion, partial traumatic neuroma and flexor muscle compression under the flexor retinaculum. Conclusion: HRUS is not only relevant in confirming the diagnosis of CTS but also to reveal other clinical relevant pathologies when electrodiagnostic evaluation is normal or atypical. P607 Intraneural collateral circulation in the median nerve after radiocephalic fistula N. Wolfram, U. van Deurs, M. Lauritzen Glostrup Hospital, Clinical Neurophysiology, Glostrup, Denmark Introduction: Carpaltunnel Syndrome (CTS) is a known complication to chronic renal failure and radiocephalic fistula for hemodialysis, but the cause of median nerve affection is unknown. Case report: A 61 year old male with chronic renal failure, hemodialysis and radiocephalic fistula in the left forearm was referred for CTS, because of pain in the left thumb, progressive in flexion of the wrist and parestesia in finger 1 + 2. Electrodiagnostic (EDX) evaluation showed normal distal motor latency and motor velocity in the forearm, but reduced motor amplitude from the elbow. Normal sensory velocity from finger 2 and palm to wrist, with reduced sensory amplitudes. High resolution ultrasound (HRUS) (Esaote MyLAb Twice, 6-18 MHz) revealed intraneural arterial blood flow, presumably located in the intraneural venous plexus of the left median nerve at the level of the radiocephalic fistula, as well as hypo-eccogenic changes in the nerve fascicles. Discussion: Clinically, CTS may be mimicked by proximal nerve damage followed by intraneural collateral circulation in patients with radiocephalic fistula. This condition can easily and non-invasively be visualized using HRUS of the median nerve. P608 Ultrasound as a novel instrument for tremor evaluation and intervention S. Kim1, S. Ahn2, J.-H. Shin2 1Hanyang University, Seoul, Republic of Korea; 2National Rehabilitation Center, Rehabilitation, Seoul, Republic of Korea Question: Tremor is a common movement disorder, as which a varied neurological disorders can be presented and pharmacological treatment was firstly tried. Botulinum toxin type A (BoNT-A) has been adopted as another treatment method, and recently ultrasonography-guided injection has been emphasized for accuracy. We hypothesized ultrasonography could takes another role as an objective indicator for tremor. Methods: We report two case studies in which tremor were the chief complaint. Case 1. A 29-year-old male patient with a postural and rest tremor of right hand consistent with Holmes tremor secondary to left pontine hemorrhage visited. His tremor gradually spread to wrist and elbow with the characteristics of 1.4-2 Hz, irregular flexion-extension oscillation being present at rest. Ultrasonography-guided BoNT-A injections were administered at extensor pollicis longus (40 U) muscles, and flexor digitorum superficialis 2nd, 3rd and 4th digits (20 U, each), which showed plainest contraction in real time ultrasonography. Ultrasonography revealed the frequency of tremor decreased from 1.4-2 Hz (baseline) to 0-0.5 Hz (2 weeks after injection), as calculated by each muscle contraction. Case 2. A 30-year-old female patient with bilateral tremor secondary to hypoxic brain damage visited. Her muscle contraction was 0.2-0.4 Hz at her left extensor carpi radialis, extensor policis longus, flexor carpi ulnaris muscles with the help of ultrasonography. BoNT-A injections were administered at extensor carpi radialis (20 U), extensor policis longus (15 U), and flexor carpi ulnaris (20 U) muscles with ultrasonography. The frequency of muscle contraction decreased to 0.1-0.2 Hz at 2 weeks after injection. Conclusion: Ultrasonography has an advantage of objective evaluation of tremor as well as selecting the target muscles. We regard ultrasonography as a novel tool in increasing the accuracy of evaluation and intervention. LP36 Intraoperative high-resolution ultrasound in the managment of traumatic nerve lesions: a new technique K. Scheglmann1, M.-T. Pedro2, R. Koenig2 1Klinikum Augsburg, Neurology, Augsburg, Germany; 2University Ulm, Neurosurgery, Guenzburg, Germany Introduction: Surgical treatment of nerve lesion in continuity remains difficult even in the most experienced hands. Their regenerative potential is evaluated either by intraoperative electrophysiology and/or intraneural dissection. The values of preoperative ultrasound is often hampered due to low tissue penetration and trauma related artifacts. Therefore the present study for the first time examines feasibility and value of intraoperative high-frequency ultrasound as an imaging tool in the management of traumatic nerve lesions in continuity. Material and methods: After development of intraoperative application of high-frequency ultrasound we examined 19 traumatic or iatrogenic nerve lesions of different extent. The information obtained was correlated to intraoperative electrophysiology, the findings of microsurgical intraneural dissection and histopathology of the resected nerve segments. Results: The intraoperative application of high-frequency ultrasound enabled morphological ultrastructural examination of traumatic nerve lesions with excellent imaging quality. The assessment of the severity of the",2014,Clinical Neurophysiology
Remote sensing of seagrasses in a patchy multi-species environment,"We tested the utility of IKONOS satellite imagery to map seagrass distribution and biomass in a 4.1 km2 area around Chumbe Island, Zanzibar, Tanzania. Considered to be a challenging environment to map, this area is characterized by a diverse mix of inter- and subtidal habitat types. Our mapped distribution of seagrasses corresponded well to field data, although the total seagrass area was underestimated due to spectral confusion and misclassification of areas with sparse seagrass patches as sparse coral and algae-covered limestone rock. Seagrass biomass was also accurately estimated (r 2 = 0.83), except in areas with Thalassodendron ciliatum (r 2 = 0.57), as the stems of T. ciliatum change the relationship between light interception and biomass from that of other species in the area. We recommend the use of remote sensing over field-based methods for seagrass mapping because of the comprehensive coverage, high accuracy and ability to estimate biomass. The results obtained with IKONOS imagery in our complex study area are encouraging, and support the use of this data source for seagrass mapping in similar areas.",2011,International Journal of Remote Sensing
Sparsity Oracle Inequalities for Lasso and Dantzig Selector in High-Dimensional Nonparametric Regression,"Regularity conditions, such as the incoherence condition, restricted isometry property, compatibility condition and restricted eigenvalue assumption, play a pivotal role in high-dimensional regression and compressed sensing. Under these conditions, some interesting results for the Lasso and Dantzig selectors are derived. In this paper, we propose a modification of the compatibility condition, which is called modified compatibility condition. We show the oracle inequalities under the new condition and the methods which avoid using the sparsity condition. As a comparison with the results by Bickel et al. (2009) in high-dimensional nonparametric regression, more precise oracle inequalities for the prediction risk and bounds on the estimation loss are derived when the number of variables can be much larger than the sample size.",2013,International journal of applied mathematics and statistics
The Influence of the Jesuits on the Passion Music of Orlando di Lasso,"Title of Thesis: THE INFLUENCE OF THE JESUITS ON T HE PASSION MUSIC OF ORLANDO DI LASSO Nicholas Dean Johnson, Master of Arts, 2006 Thesis Directed by: Professor Richard Wexler School of Music This study explores the four Passion settings of Orlan do di Lasso, composed between 1575 and 1582, which have largely been ignored by music sc holar . Scholars have recognized that a dramatic compositional shift occurr ed between the second and third settings, but have provided no cogent explanation fo r the change. Most reasons given revolve around the Council of Trent, which held it s final session in 1563. However, a consideration of the history and religious contexts of the works discloses other, possibly better explanations. I propose that the primary influence leading to Lassoâ€™s c mpositional shift was the liturgical reform initiated by his employer, Duke Wilhe lm V, and enforced by the Jesuit priest Walram Tumler. These reforms had a prof ound effect on all facets of worship in Bavaria, most notably music. Recognizing the infl uence of the Jesuits on Lassoâ€™s music makes it possible to understand the composerâ€™ s dramatic change in style. THE INFLUENCE OF THE JESUITS ON THE PASSION MUSIC OF ORLANDO DI LASSO",2006,
EEG UNDER ANESTHESIA A general method for calculation of depth of anesthesia,"This paper investigated the problem of automatic depth of anesthesia (DOA) estimation from electroencephalogram (EEG) recordings. Compared with the Bispectral Index (BIS), time-frequency domain signal processing technique and nonlinear dynamical analysis were combined for DOA assessment, multiple features were extracted from EEG, Lasso and Logistic regression were used to classify and calculate the index of DOA and evaluate its relationship with EEG features. In emulation and clinical practice, the index of DOA is very close to BIS. This method can enhance existing monitoring devices and work as a general method to find effective features for calculation of DOA. Â© 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of ICESB 2011",2011,
Bayesian Sparsity-Path-Analysis of Genetic Association Signal using Generalized t Priors,"We explore the use of generalized t priors on regression coefficients to help understand the nature of association signal within Â“hit regionsÂ” of genome-wide association studies. The particular generalized t distribution we adopt is a Student distribution on the absolute value of its argument. For low degrees of freedom, we show that the generalized t exhibits Â“sparsity-priorÂ” properties with some attractive features over other common forms of sparse priors and includes the well known double-exponential distribution as the degrees of freedom tends to infinity. We pay particular attention to graphical representations of posterior statistics obtained from sparsity-path-analysis (SPA) where we sweep over the setting of the scale (shrinkage/precision) parameter in the prior to explore the space of posterior models obtained over a range of complexities, from very sparse models with all coefficient distributions heavily concentrated around zero, to models with diffuse priors and coefficients distributed around their maximum likelihood estimates. The SPA plots are akin to LASSO plots of maximum a posteriori (MAP) estimates but they characterise the complete marginal posterior distributions of the coefficients plotted as a function of the precision of the prior. Generating posterior distributions over a range of prior precisions is computationally challenging but naturally amenable to sequential Monte Carlo (SMC) algorithms indexed on the scale parameter. We show how SMC simulation on graphic-processing-units (GPUs) provides very efficient inference for SPA. We also present a scale-mixture representation of the generalized t prior that leads to an expectation-maximization (EM) algorithm to obtain MAP estimates should only these be required.",2012,Statistical Applications in Genetics and Molecular Biology
A model-free approach for detecting interactions in genetic association studies,"Over the past few decades, genome-wide association studies analyzed by efficient statistical procedures have successfully identified single-nucleotide polymorphisms (SNPs) that are associated with complex traits or human diseases. However, due to the overwhelming number of SNPs, most approaches have focused on additive genetic model without genome-wide SNP-SNP interactions. In this study, we propose an efficient statistical procedure in a genetic model-free framework for detecting SNPs exhibiting main genetic effects as well as epistatic interactions. Specifically, the association between phenotype and genotype is characterized by an unknown function to be estimated using nonparametric techniques, and a two-stage non-parametric independence screening procedure is proposed to sequentially identify potentially important main genetic effects and interactions. Finally, the subset of genetic predictors implied by two-stage non-parametric independence screening is analyzed by penalized regressions such as LASSO, and a final model is identified. In this framework, specific genetic model is not assumed and interactions are not only among marginally important SNPs. Therefore, SNPs that are involved in genetic regulatory networks but missed by previous studies are expected to be recognized. In simulation studies, we show that the procedure is computationally efficient and has an outstanding finite sample performance in selecting potential SNPs as well as SNP-SNP interactions. A real data analysis further indicates the importance of epistatic interactions in explaining body mass index.",2014,Briefings in bioinformatics
La Â« thalassocratie Â» : mythes et rÃ©alitÃ© historique (Ã  propos de Â« la liste dâ€™EusÃ¨be Â»),"The Â«Â List of ThalassocraciesÂ Â» in Eusebius is the subject of learned debates for more than one century. Two currents of thought emerge: the proponents of a strange document without great historical value and those who wanted to prove at all costs its documentary quality, convinced that the List is an old and solid inventory illuminating the mastery of the sea in the dark ages. Here, the document is firstly reviewed in the light of the main arguments of each other. The examination is shown to be inconclusive: in practice, the List strangely comes to an end at the beginning of the 5th cent. bc, has no firm ancestry and does not match with what is formally found in Diodorus' books, the source yet claimed in the first introductory line. Secondly, in front of this inconclusive approach, a new proposal is set out. The working-out of the List could be attributed to Eusebius himself: he would have freely drawn up the List from the historical material collected in Diodorus and have stopped on a fact finding echo in a major contemporary event. The bishop of Caesarea, very involved in the debates of his time, was always anxious to please Constantine. In his Chronicle reissued for Vicennalia of the Emperor, Eusebius probably wanted to celebrate the heroic exploit recently accomplished by his eldest son Crispus now fit for an imperial destiny: the Prince had just beaten the Constantine's rival, Licinius Augustus, in a great naval joust in the same area where Xerxes had crossed the Hellespont on two decks of ships bound with cables afterwards recovered and consecrated at Delphi by the Athenians. The brutal subsequent elimination and condemnation to oblivion of Crispus obliged Eusebius to quickly remove any explicit reference to the fallen son in his works. In his Chronicle , this ultimate Â«Â correctionÂ Â» has hidden the raison d'etre for a list not implausible but of later conception.",2016,Historika : Studi di Storia Greca e Romana
The geometry of off-the-grid compressed sensing,"This paper presents a sharp geometric analysis of the recovery performance of sparse regularization. More specifically, we analyze the BLASSO method which estimates a sparse measure (sum of Dirac masses) from randomized sub-sampled measurements. This is a ""continuous"", often called off-the-grid, extension of the compressed sensing problem, where the $\ell^1$ norm is replaced by the total variation of measures. This extension is appealing from a numerical perspective because it avoids to discretize the the space by some grid. But more importantly, it makes explicit the geometry of the problem since the positions of the Diracs can now freely move over the parameter space. On a methodological level, our contribution is to propose the Fisher geodesic distance on this parameter space as the canonical metric to analyze super-resolution in a way which is invariant to reparameterization of this space. Switching to the Fisher metric allows us to take into account measurement operators which are not translation invariant, which is crucial for applications such as Laplace inversion in imaging, Gaussian mixtures estimation and training of multilayer perceptrons with one hidden layer. On a theoretical level, our main contribution shows that if the Fisher distance between spikes is larger than a Rayleigh separation constant, then the BLASSO recovers in a stable way a stream of Diracs, provided that the number of measurements is proportional (up to log factors) to the number of Diracs. We measure the stability using an optimal transport distance constructed on top of the Fisher geodesic distance. Our result is (up to log factor) sharp and does not require any randomness assumption on the amplitudes of the underlying measure. Our proof technique relies on an infinite-dimensional extension of the so-called ""golfing scheme"" which operates over the space of measures and is of general interest.",2020,arXiv: Information Theory
Building quantitative prediction models for tissue residue of two explosives compounds in earthworms from microarray gene expression data.,"Soil contamination near munitions plants and testing grounds is a serious environmental concern that can result in the formation of tissue chemical residue in exposed animals. Quantitative prediction of tissue residue still represents a challenging task despite long-term interest and pursuit, as tissue residue formation is the result of many dynamic processes including uptake, transformation, and assimilation. The availability of high-dimensional microarray gene expression data presents a new opportunity for computational predictive modeling of tissue residue from changes in expression profile. Here we analyzed a 240-sample data set with measurements of transcriptomic-wide gene expression and tissue residue of two chemicals, 2,4,6-trinitrotoluene (TNT) and 1,3,5-trinitro-1,3,5-triazacyclohexane (RDX), in the earthworm Eisenia fetida. We applied two different computational approaches, LASSO (Least Absolute Shrinkage and Selection Operator) and RF (Random Forest), to identify predictor genes and built predictive models. Each approach was tested alone and in combination with a prior variable selection procedure that involved the Wilcoxon rank-sum test and HOPACH (Hierarchical Ordered Partitioning And Collapsing Hybrid). Model evaluation results suggest that LASSO was the best performer of minimum complexity on the TNT data set, whereas the combined Wilcoxon-HOPACH-RF approach achieved the highest prediction accuracy on the RDX data set. Our models separately identified two small sets of ca. 30 predictor genes for RDX and TNT. We have demonstrated that both LASSO and RF are powerful tools for quantitative prediction of tissue residue. They also leave more unknown than explained, however, allowing room for improvement with other computational methods and extension to mixture contamination scenarios.",2012,Environmental science & technology
Lasso variable selection in predictive mixed-frequency model,"In short-term forecasting, it is essential to take into account all available information on the current state of the economic activity. Yet, the fact that various time series are sampled at different frequencies prevents an efficient use of available data. In this respect, the Mixed-Data Sampling (MIDAS) model has proved to outperform existing tools by combining data series of different frequencies. However, a major issue remain regarding the choice of explanatory variables. The paper addresses this point by developing MIDAS based dimension reduction techniques and by introducing a novel approach based on a method of penalized variable selection, the Lasso. This feature integrates a cross-validation procedure that allows automatic in-sample selection based on forecasting performances. Then the developed technique is assessed with regards to its forecasting power of US economic growth during the period 1990-2015 using an augmented version of the Stock and Watson database jointly involving daily, weekly, monthly, and quarterly data as the real-time economic data-flow. Our model succeeds in identifying leading indicators and constructing an objective variable selection with broad applicability.",2016,
Sparse lexical representation for semantic entity resolution,"This paper addresses the problem of semantic entity resolution (SER), which aims to determine whether some or none of the entities in a knowledge base is mentioned in a given web document. The lexical features, e.g., words and phrases, which are critical to the resolution of the semantic entities are typically of a small amount compared to all lexical features in the web document, and therefore can be modeled as sparse signals. Two techniques leveraging the principles of sparse signal recovery are proposed to identify the sparse, salient lexical features: one technique, based on the Lasso algorithm with the l2-norm distance metric, attempts to recover all the salient lexical features at once; the other technique, namely Posterior Probability Pursuit (PPP), sequentially identifies salient features one after one using the negative log posterior probability as the distance metric. Using a knowledge base consisting of about 100 million entities, we show that the proposed techniques exploiting the sparsity nature underlying SER deliver substantial performance improvement over baseline methods without sparsity consideration, demonstrating the potentials of sparse signal techniques in entity-centric web information processing.",2013,"2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
Stable expression of mutated and non-mutated mouse NOTCH3 in C2C12 mouse myoblast,"Background and aim: Notch signaling pathway is important for the regulation of cell fate decisions and cellular differentiation in many organs. NOTCH3 belongs to a family of single-pass transmembrane receptors. In response to interaction with ligands, it undergoes a set of proteolytic events releasing a signaling molecule to the nucleus where it interacts with the DNA-binding protein RBP-Jk. Point mutations in NOTCH3 lead to a disorder called CADASIL, resulting in adult onset of migraine, recurrent strokes and vascular dementia in humans. Our objective is to create transgenic cell lines that stably express CADASILassociated mutations to induce higher production of NOTCH3 proteins. Methods: CADASIL mutations, R142C and C456R, were introduced using site-directed mutagenesis into mouse NOTCH3 (mN3). Different mN3 constructs were transfected into C2C12 mouse myoblast cell line to induce high NOTCH3 expression. The entire gene was sequenced and immonublotting was carried out to verify expression of the protein. Real-time RT-PCR was conducted to determine level of expression before clones were selected. Results:We have established transgenic lines of C2C12 cells expressingmN3 with CADASILmutations, R142C andC456R.R142C is amutation locatedonexon 4 of mN3 gene corresponding to CADASIL mutation R141C in human NOTCH3 (hN3), whereas C456R is a mutation on exon 8 corresponding to CADASIL mutation C455R in hN3. We have chosen several lines that showed higher expression compared to the endogenous expression of mN3 in C2C12. Conclusion: Thus far, studies showing that NOTCH signaling pathway is impaired in cells carrying a typical CADASIL mutation have been inconclusive. Wepostulate thatCADASILmutationshave adirect consequenceon theNOTCH3 protein foldingmachinery as a result of the loss or gain of cysteine residues. Our present plan is to harvest NOTCH3 proteins from the transgenic cell lines for protein chemistry analyses and protein expression studies.",2009,Journal of the Neurological Sciences
Impact-Based Search in Constraint-based Scheduling,"Abstract: Anoveladaptationofimpact-basedsearchstrategiesforconstraint-basedresourceschedulingispresented. SearchbasedonimpactsappliesageneralpurposesearchstrategyoriginallyfromLinearIntegerProgrammingandrecentlyadaptedtoConstraint Programming. To my knowledge it is shown for the ï¬rst time that thisstrategyisproperlyapplicabletoconstraint-basedschedulingandperformswellontheclassofjob-shopschedulingproblems. Evidenceisgivenempiricallybycomparisonwithaproblem-speciï¬candarandomstrategy. 1Introduction InConstraintProgramming(CP)oneoftheessentialstobesuccessfulinproblemsolvingistheabilitytodesignanaccordingsearchstrategy.Mostly,thereareproblemspeciï¬cstrategies,especiallyinconstraint-basedscheduling.Schedulingofactivitiesonresourcesare in general NP-hard problems (cf. [BlPN01]), especially if theymust be scheduledoptimallywithrespecttoanobjectivefunctionliketheirminimalmake-span. Neverthe-less, beyondpolynomialalgorithmsforpruningthesearchspace(e.g.[BlPN01,BC01,Vil04,Vil07,Wol03])specialized,highlysophisticatedsearchstrategies(cf.[BL00,Vil05,Wol04,Wol05])havebeenappliedsuccessfully.Incontrasttothesespecial-purposeap-proaches,thisarticlefollowstheideapresentedin[Ref04]: ageneral-purpose,impact-based searchstrategy.However,in[Ref04]thisstrategyinspiredfromLinearIntegerPro-grammingisappliedtoproblemslikemultiknapsackandmagicsquareproblemswherethevariablesâ€™domainarerathersmall. Duetotheuseoftheimpacts ofvariable-valueassignmentsthestrategyrequiresapproximationsforproblemswithlargervariablesâ€™do-mainsasshownin[Ref04],e.g.forLatinsquarecompletionproblems.Withinthispaperanovelapproachispresentedsuchthatimpact-based searchisappli-cableandperformswellinconstraint-basedschedulingwherethevariableshavelargeorevenhugedomains. Here,theimpacts areindependentfromvariable-valueassignmentsbecausetheyarecomputedfororderdecisions.",2008,
"Depth and substrate as determinants of distribution of juvenile flathead sole (Hippoglossoides elassodon) and rock sole (Pleuronectes bilineatus), in Kachemak Bay, Alaska","Abstract Three transects in Kachemak Bay, Alaska, were sampled in September 1994, May and August 1995, and February, May, and August 1996. Juvenile flathead sole, Hippoglossoides elassodon , and rock sole, Pleuronectes bilineatus , were the most abundant flatfishes, comprising 65â€“85% of all flatfishes captured at any period. Collections of fish and sediments were made at regular depth contour intervals of 10 m. Habitat distribution was described by depth at 10 m increments and sediment percent weights of gravel, sand, and mud. Year-round habitat of flathead sole age-0 was primarily from 40 to 60 m, and age-1 habitat was primarily from 40 to 80 m. Summer habitat of rock sole age-0 and -1 was from 10 to 30 m, and in winter they moved offshore to depths of up to 150 m. Both age classes of flathead sole were most abundant on mixed mud sediments, while age-1 were also in high abundance on muddy sand sediments. Rock sole age-0 and-1 were most abundant on sand, though age-1 were also found on a variety of sediments both finer and coarser grained than sand. Flathead sole and rock sole had distinctive depth and sediment habitats. When habitat overlap occurred between the species, it was most often due to rock sole moving offshore in the winter. Abundances were not significantly different among seasons for age-1 flatfishes.",1998,Journal of Sea Research
"HIV Infection among Pregnant Women in Bobo-Dioulasso, Burkina Faso: Comparison of Voluntary and Blinded Seroprevalence Estimates","The objective of our study was to estimate the prevalence of HIV infection among pregnant women in Bobo-Dioulasso (Burkina Faso) according to 2 survey methods. Unlinked anonymous HIV screening was performed among women attending 2 antenatal clinics. Voluntary and confidential HIV counselling and testing were offered to women attending 2 other antenatal clinics in the same time period, September-October 1996. Voluntary HIV testing was performed in the context of a clinical trial on mother-to-child transmission of HIV (ANRS 049 clinical trial) with an acceptance rate of HIV testing of 93%. The first survey recruited 200 women and the second, 424. The mean age (24.6 years vs 24.8 years) and the mean number of pregnancies (3.1 vs 3.3) of women were comparable, in the 2 studies (P=0.69 and P=0.26, respectively). Prevalence of HIV infection in the blinded survey was estimated at 10.0% (95% confidence interval (CI): 6.4â€“15.2), while it was 9.4% (95% CI: 6.9â€“12.7) in the voluntary HIV screening programme. These 2 estimates were not statistically different (P=0.82). In the voluntary screening study, the prevalence of HIV infection was significantly different between age groups 15â€“24 years and 25â€“49 years (13.9% vs 4.5%, P < 0.001). In the age group 25â€“49 years, the prevalence of HIV infection estimated in the blinded study and in the voluntary screening study were significantly different (10.5% vs 4.5%, P=0.04) suggesting a potential participation bias among pregnant women of older age in the voluntary, confidential HIV screening group. In conclusion, for the purpose of HIV surveillance, the most reliable method for HIV prevalence remains the unlinked, anonymous testing.",1999,International Journal of STD & AIDS
Predictive versus prognostic value of lung adenocarcinoma classification.,"TO THE EDITOR: Hung et al recently investigated the pattern of recurrence and the predictive value of the new International Association for the Study of Lung Cancer/American Thoracic Society/ European Respiratory Society histologic classification for lung adenocarcinoma in 573 patients who had been treated primarily by surgical resection. In this classification, nonmucinous invasive adenocarcinoma was classified into five categories on the basis of the presence of predominant histological patterns. The authors reported that among all 573 patients, those with micropapillary/solid predominant pattern adenocarcinoma had higher extrathoracic versus intrathoracic recurrence than patients with lepidic/acinar/papillary predominant pattern tumors. Micropapillary/solid predominant pattern had poorer overall survival (OS), freedom from recurrence, and disease-specific survival compared with lepidic/acinar/papillary predominant patients. Importantly, they reported that among 215 of 573 patients who received adjuvant chemotherapy, solid-predominant adenocarcinoma was also a significant predictive factor for OS (P .04) and tended to be significant for freedom from recurrence (P .08). The authors concluded that in lungadenocarcinoma,theInternationalAssociationfortheStudyofLung Cancer/American Thoracic Society/European Respiratory Society classification system has significant prognostic and predictive value regarding death and recurrence. Solid-predominant adenocarcinoma was also a significant predictor in patients undergoing adjuvant chemotherapy. It is generally accepted that prognostic markers are patient/tumor factors that affect patient outcome (usually survival) independently of treatment administered, whereas predictive markers are factors that predict response of the tumor to the treatment, either in terms of tumor shrinkage or survival benefit from the treatment. In patients with early-stage resectable nonâ€“small-cell lung cancer, the term â€œpredictiveâ€ should be reserved for survival benefit from adjuvant chemotherapy. In the absence of a randomized trial with a notreatment control arm, a differential survival benefit from therapy cannot be determined, as the prognostic role of the marker may exert similar effects in both the treated and nontreated arms. This is the case in this report by Hung et al as shown clearly in Figures 1G to I, where OS and disease-specific survival were poorer for patients with solidpredominant compared with nonsolid histology, regardless of whether they received or did not receive adjuvant chemotherapy. In fact, nowhere in the manuscript or in the Data Supplement was significant interaction between chemotherapy and histologic subtype reported by comparing the hazard ratios for survival benefit in treated and nontreated patients in the two histologic groups, and by applying an interaction P value. Therefore, we believe the use of term â€œpredictiveâ€ was inappropriate and misleading, and that this retrospective study was neither designed nor powered to be able to demonstrate significant treatment by histology interaction. Note: A reply to this Correspondence was not provided.",2015,Journal of clinical oncology : official journal of the American Society of Clinical Oncology
Tomorrow's Teachers Engaging in Unprotected Text,"This study combines data from transcribed book discussions, interviews, and student writings to illustrate one preservice teacher's transformative journey while studying children's literature.RECENTLY, OUR TOWN, which is approximately 1,500 miles from the Texas border, lassoed and hogtied a cowboy. While in the midst of innocently bathing, the unsuspecting fellow was scooped up and plastered on our newspaper's front page (Elias, 2012). The accompanying article chronicled a local school board's decision (8-0) to remove The Dirty Cowboy by Amy Timberlake (2003) from the school library after parents of a kindergarten student lodged a complaint about obscene illustrations. Timberlake indicated the book was based on a family story. In her great-grandfather's tale, once reported in a New Mexico newspaper in the 19th century, a dirty cowboy finds a watering hole, takes off his clothes, and bathes. His ever-loyal dog, with his keen sense of smell, refuses to allow the cowboy back into his master's clothing because the cowboy's recognizable stench is gone. Amy's family story, like all tall tales, originates in the oral tradition and often details a truth. This narrative illustrates the intensity of the sense of smell in canines. As expected in the genre of tall tales, there is exaggeration. The cranky cowboy and his furry friend spend a majority of the story tussling over the filthy clothes. The illustrator cleverly obscures the cowboy's private parts with various items, such as the dog's tail. This recent uproar is unsurprising. Male private parts have a history of problems in children's books (e.g., In the Night Kitchen by Maurice Sendak, 1970; The Higher Power of Lucky by Susan Patron, 2006). The recurring nature of this and other controversial issues, such as violence and inappropriate language, in children's books substantiates the need for preservice teachers to consider their own engagement with text (visual and print) before they arrive at the classroom door. As a teacher educator drawn to this quandary, I offer insights gained from instituting an apprenticeship model for preservice teachers and the book selection process. My findings are revealed through a literacy portrait of Cecile (all names are pseudonyms), a preservice teacher enrolled in my children's literature course. Cecile's portrait outlines the benefits of engaging tomorrow's teachers with unprotected text. The term unprotected text is admittedly cheeky but aligns with Harste's ""risky text"" (2008, p. 70), or a quality text worth talking about. At its core, risky/unprotected text is the ""imaginative shaping of life and thought into the forms and structures of language"" (Kiefer & Tyson, 2010, p. 3). It has the child's eye at the center and is circumscribed by the child's experience. This definition works in tandem with Bishop's (1990) oft-quoted metaphor of children's literature as ""mirrors, windows, and sliding doors"" (p. ix). Such texts are unflinchingly honest portrayals of life.Book Selection Dilemmas for Preservice TeachersBook selection is a ubiquitous dilemma for teachers, but it is especially difficult for inexperienced preservice teachers. Lacking confidence, preservice teachers often depend on experienced cooperating teachers or professors. By relying on someone in authority, preservice teachers deny themselves opportunities to struggle with issues that enhance their efficacy in the book decision process. In addition to lacking confidence, these teachers often defer because they fear controversy- and rightly so. Controversy, like lightning, never has the courtesy to tell where it will strike. The lightning analogy plays out often when parents question a teacher's choice of text. Like a bolt of lightning on a sultry summer night, controversy electrifies the air. Formerly prosaic words or images appear surreal. As Jenkins (2011) explains, ""If a community's laws or school code of conduct prohibit particular actions or behaviors by young people, so the reasoning goes, those actions or behaviors should not appear in the books of that community's public or school libraries"" (p. â€¦",2013,Journal of Childrenâ€™s Literature
Large-scale sparse regression models under weak assumptions,"Author(s): Raskutti, Garvesh | Advisor(s): Yu, Bin; Wainwright, Martin J | Abstract: Many modern problems in science and other areas involve extraction of useful information from so-called 'big data.' However, many classical statistical techniques are not equipped to meet with the challenges posed by big data problems. Furthermore, existing statistical methods often result in intractable algorithms. Consequently the last $15-20$ years has seen a flurry of research on adapting existing methods and developing new methods that overcome some of the statistical and computational challenges posed by problems involving big data. Regression is one of the oldest statistical techniques. For many modern regression problems involving big datasets, the number of predictors or covariates $\pdim$ is large compared the number of samples $n$, causing significant computational and statistical challenges. To overcome these challenges, many researchers have proposed imposing sparsity on the vector of regression co-efficients $\beta \in \mathbb{R}^{\pdim}$. Furthermore, researchers have proposed using $\ell_1$-based convex penalties for estimating $\beta$ under the sparsity assumption since they yield implementable algorithms with desirable performance guarantees. While there was already an established body of work on developing procedures for sparse regression models, most existing results rely on very restrictive model assumptions. These assumptions are often not satisfied for many scientific problems. In this thesis, we relax $3$ restrictive model assumptions that are commonly imposed in the literature for estimating sparse regression models. The $3$ assumptions are: (1) Strict sparsity, that is the vector of regression co-efficients $\beta$ contains only a small number of non-zeros; (2) The covariates or predictors are independent; (3) Response depends linearly on covariates. Given that these $3$ model assumptions are often not satisfied for many practical settings, it is important to understand whether existing theoretical results exhibit robustness to these assumptions. In Chapter 2, we impose a weaker notion of sparsity known as $\ell_q$-ball sparsity on $\beta$ which ensures the vector of regression co-efficients lies in an $\ell_q$ ball, but need not have any non-zeros. We prove that under the weaker $\ell_q$-ball sparsity assumption, it is possible to develop estimators with desirable mean-squared error behavior, even in the regime where $\pdim \gg n$.The weakest known condition under which the Lasso achieves optimal mean-squared error rate is the restricted eigenvalue condition~\cite{vandeGeer07,BicRitTsy08, Negahban09}. Existing results prove that in cases when the covariates are independent, the restricted eigenvalue condition is satisfied. However, the setting when predictors or covariates are correlated are also of interest and there was considerably less work dealing with this case. In Chapter 3, we prove that the restricted eigenvalue condition is satisfied for various correlated Gaussian designs, including time series models, spiked covariance models and others.Finally, in Chapter 4 we analyze sparse additive models, a non-parametric analog of sparse linear models, in which each component function lies in an ellipsoid or more formally a Reproducing kernel Hilbert space $\Hil$. Hence we weaken the assumption that our response depends on the covariate via a linear function. A new $\ell_1$-based polynomial-time method is developed and we prove that this method has desirable mean-squared error performance, even when $\pdim \gg n$. Furthermore, we prove lower bounds on the mean-squared error for estimating sparse additive models that match the upper bounds for our method. Hence our algorithm is optimal in terms of mean-squared error rate.",2012,
Genotype-phenotype association study via new multi-task learning model,"Research on the associations between genetic variations and imaging phenotypes is developing with the advance in high-throughput genotype and brain image techniques. Regression analysis of single nucleotide polymorphisms (SNPs) and imaging measures as quantitative traits (QTs) has been proposed to identify the quantitative trait loci (QTL) via multi-task learning models. Recent studies consider the interlinked structures within SNPs and imaging QTs through group lasso, e.g. â„“2, 1-norm, leading to better predictive results and insights of SNPs. However, group sparsity is not enough for representing the correlation between multiple tasks and â„“2, 1-norm regularization is not robust either. In this paper, we propose a new multi-task learning model to analyze the associations between SNPs and QTs. We suppose that low-rank structure is also beneficial to uncover the correlation between genetic variations and imaging phenotypes. Finally, we conduct regression analysis of SNPs and QTs. Experimental results show that our model is more accurate in prediction than compared methods and presents new insights of SNPs.",2018,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
Regularising the Factor Zoo with OWL : A Correlation-Robust Machine Learning Approach,"Cochrane (2011) points out that the burgeoning characteristic-related â€factor zooâ€ to explain the average returns in equity market are in disarray. This paper introduces a newly developed machine learning tool, ordered and weighted L1 norm regularisation (OWL) to â€regulariseâ€ this chaotic â€factor zooâ€. OWL permits high correlations among explanatory variables, which is novel in the finance literature and of great importance. Factor correlation prevails in high dimensionality (factor zoo) and distorts standard estimators such as Fama-MacBeth (FM) regression, LASSO, etc. I show OWL estimator is consistent with finite factors and derive the convergence rate with infinite factors. I also derive conditions that OWL groups highly correlated variables, while shrinks off useless/redundant variables simultaneously. Monte Carlo experiments show OWL outperforms LASSO, adaptive LASSO and Elastic Net (EN) in various settings, particularly when factors are highly correlated. Empirical evidence suggests that liquidity related factors are primary to drive asset prices. Following Freyberger et al. (2017), out-of-sample Sharpe ratio of hedge portfolios, formed using OWL selected factors as predictors are considerably larger than that of LASSO, EN and FM.",2019,
Group Fused Lasso,"We introduce the Group Total Variation (GTV) regularizer, a modification of Total Variation that uses the l2,1 norm instead of the l1 one to deal with multidimensional features. When used as the only regularizer, GTV can be applied jointly with iterative convex optimization algorithms such as FISTA. This requires to compute its proximal operator which we derive using a dual formulation. GTV can also be combined with a Group Lasso (GL) regularizer, leading to what we call Group Fused Lasso (GFL) whose proximal operator can now be computed combining the GTV and GL proximals through Dykstra algorithm. We will illustrate how to apply GFL in strongly structured but ill-posed regression problems as well as the use of GTV to denoise colour images.",2013,
A Two-Stage Penalized Least Squares Method for Constructing Large Systems of Structural Equations,"We propose a two-stage penalized least squares method to build large systems of structural equations based on the instrumental variables view of the classical two-stage least squares method. We show that, with large numbers of endogenous and exogenous variables, the system can be constructed via consistent estimation of a set of conditional expectations at the first stage, and consistent selection of regulatory effects at the second stage. While the consistent estimation at the first stage can be obtained via the ridge regression, the adaptive lasso is employed at the second stage to achieve the consistent selection. The resultant estimates of regulatory effects enjoy the oracle properties. This method is computationally fast and allows for parallel implementation. We demonstrate its effectiveness via simulation studies and real data analysis.",2018,J. Mach. Learn. Res.
Graphical Models for Zero-inflated Single Cell Gene Expression.,"Bulk gene expression experiments relied on aggregations of thousands of cells to measure the average expression in an organism. Advances in microfluidic and droplet sequencing now permit expression profiling in single cells. This study of cell-to-cell variation reveals that individual cells lack detectable expression of transcripts that appear abundant on a population level, giving rise to zero-inflated expression patterns. To infer gene co-regulatory networks from such data, we propose a multivariate Hurdle model. It is comprised of a mixture of singular Gaussian distributions. We employ neighborhood selection with the pseudo-likelihood and a group lasso penalty to select and fit undirected graphical models that capture conditional independences between genes. The proposed method is more sensitive than existing approaches in simulations, even under departures from our Hurdle model. The method is applied to data for T follicular helper cells, and a high-dimensional profile of mouse dendritic cells. It infers network structure not revealed by other methods; or in bulk data sets. An R implementation is available at https://github.com/amcdavid/HurdleNormal.",2019,The annals of applied statistics
Path consistent model selection in additive risk model via Lasso.,"As a flexible alternative to the Cox model, the additive risk model assumes that the hazard function is the sum of the baseline hazard and a regression function of covariates. For right censored survival data when variable selection is needed along with model estimation, we propose a path consistent model selector using a modified Lasso approach, under the additive risk model assumption. We show that the proposed estimator possesses the oracle variable selection and estimation property. Applications of the proposed approach to three right censored survival data sets show that the proposed modified Lasso yields parsimonious models with satisfactory estimation and prediction results.",2007,Statistics in medicine
Prolegomena to a Materialist Humanism,"Abstract This article sets the agenda for a new materialist humanism through a critique and analysis of theories of materialist subjectivity in recent French philosophy. I begin with a critique of the lack of a properly internal account of the human subject in the work of Alain Badiou, arguing that his disavowal of any sort of humanism and a dismissal of the natural sciences leaves him without a way to conceptualize the internal activity of the human subject. I then consider the neurological account of human subjectivity offered in Catherine Malabou's recent materialist articulation of human consciousness and consider how this internal theory of human subjectivity can supplement the wholly external account offered by Badiou. I conclude the article with a consideration of Quentin Meillassoux's speculative materialism to show the manner in which at the ontological level he offers a materialist account of human thought as contingently emerging from wholly material processes. Building upon this, I point towards the possibility of a non-hierarchical form of materialist humanism that is wholly immanent in its affirmation of the unique capacities of human thought and activity without claiming any special metaphysical significance for human beings.",2014,Angelaki
The prediction of live weight of hair goats through penalized regression methods: LASSO and adaptive LASSO,"The least absolute selection and shrinkage operatorÂ (LASSO) and adaptive LASSO methods have become a popular model in the last decade, especially for data with a multicollinearity problem. This study was conducted to estimate the live weightÂ (LW) of Hair goats from biometric measurements and to select variables in order to reduce the model complexity by using penalized regression methods: LASSO and adaptive LASSO for Î³ = 0.5 and Î³ = 1 . The data were obtained from 132Â adult goats in Honaz district of Denizli province. Age, gender, forehead width, ear length, head length, chest width, rump height, withers height, back height, chest depth, chest girth, and body length were used as explanatory variables. The adjusted coefficient of determinationÂ ( R adj 2 ), root mean square errorÂ (RMSE), Akaike's information criterionÂ (AIC), Schwarz Bayesian criterionÂ (SBC), and average square errorÂ (ASE) were used in order to compare the effectiveness of the methods. It was concluded that adaptive LASSO ( Î³ = 1 ) estimated the LW with the highest accuracy for both male ( R adj 2 = 0.9048 ; RMSEâ€¯ = â€¯3.6250; AICâ€¯ = â€¯79.2974; SBCâ€¯ = â€¯65.2633; ASEâ€¯ = â€¯7.8843) and female ( R adj 2 = 0.7668 ; RMSEâ€¯ = â€¯4.4069; AICâ€¯ = â€¯392.5405; SBCâ€¯ = â€¯308.9888; ASEâ€¯ = â€¯18.2193) Hair goats when all the criteria were considered.",2018,Archives Animal Breeding
Circadian and circatidal locomotory rhythms in the intertidal beetle Thalassotrechus barbarae (Horn): Carabidae,"Abstract Thalassotrechus barbarae (Horn) is a member of the intertidal crevice fauna. It forages and mates at night outside the crevice but only during periods of low water. Exogenous stimuli probably inhibit emergence and activity when conditions are not favourable but the main timing of activity is endogenously controlled. Under a LD 15:9 regime (270 lux, tungsten light) the insects were active only during the dark period. Under constant conditions (15â€“16 Â°C, 0.05 lux) the beetles showed a circatidal and circadian rhythm of locomotory activity. The circadian rhythm, which has an estimated period of 23.9 h, is quite stable, persisting for at least 7 days. The circatidal rhythm persists for 3 days suggesting that it is subordinate to the dominant circadian rhythm; it probably modifies the latter by inhibiting activity during periods of nocturnal high tides. A possible Zeitgeber for the circatidal rhythm is water movement which, like the probable stimulus entraining the circadian rhythm (light), is capable of being perceived by the eyes of this insect.",1976,Journal of Experimental Marine Biology and Ecology
Differences in interspecific associations of initial and terminal phase parrotfish in north-eastern Brazil,"This study compared the frequency with which different parrotfish individualsâ€”initial (IP) and terminal (TP)â€”of three species associate with cleaner and follower species at Fernando de Noronha Archipelago. Only TP individuals posed at bottom-based cleaning stations. IP individuals were followed more often by the Noronha wrasse (Thalassoma noronhanum) than TP parrotfish. When following parrotfish, the Noronha wrasse capitalized upon drifting particles and occasionally cleaned them â€˜on the moveâ€™ when they momentarily interrupted their feeding. Probably IP individuals were followed more often by the Noronha wrasse because they forage more often than the TP and thus make more drifting particles available to the wrasse. Since the IP individuals were cleaned by T. noronhanum while foraging, they visit cleaning stations less often than TP individuals.",2008,Marine Biodiversity Records
Compressed Sparse Linear Regression,"High-dimensional sparse linear regression is a basic problem in machine learning and statistics. Consider a linear model $y = X\theta^\star + w$, where $y \in \mathbb{R}^n$ is the vector of observations, $X \in \mathbb{R}^{n \times d}$ is the covariate matrix and $w \in \mathbb{R}^n$ is an unknown noise vector. In many applications, the linear regression model is high-dimensional in nature, meaning that the number of observations $n$ may be substantially smaller than the number of covariates $d$. In these cases, it is common to assume that $\theta^\star$ is sparse, and the goal in sparse linear regression is to estimate this sparse $\theta^\star$, given $(X,y)$. 
In this paper, we study a variant of the traditional sparse linear regression problem where each of the $n$ covariate vectors in $\mathbb{R}^d$ are individually projected by a random linear transformation to $\mathbb{R}^m$ with $m \ll d$. Such transformations are commonly applied in practice for computational savings in resources such as storage space, transmission bandwidth, and processing time. Our main result shows that one can estimate $\theta^\star$ with a low $\ell_2$-error, even with access to only these projected covariate vectors, under some mild assumptions on the problem instance. Our approach is based on solving a variant of the popular Lasso optimization problem. While the conditions (such as the restricted eigenvalue condition on $X$) for success of a Lasso formulation in estimating $\theta^\star$ are well-understood, we investigate conditions under which this variant of Lasso estimates $\theta^\star$. 
As a simple consequence, our approach also provides a new way for estimating $\theta^\star$ in the traditional sparse linear regression problem setting, which operates (even) under a weaker assumption on the design matrix than previously known, albeit achieving a weaker convergence bound.",2017,ArXiv
Joint testing and false discovery rate control in highâ€dimensional multivariate regression,"&NA; Multivariate regression with highâ€dimensional covariates has many applications in genomic and genetic research, in which some covariates are expected to be associated with multiple responses. This paper considers joint testing for regression coefficients over multiple responses and develops simultaneous testing methods with false discovery rate control. The test statistic is based on inverse regression and biasâ€corrected group lasso estimates of the regression coefficients and is shown to have an asymptotic chiâ€squared null distribution. A rowâ€wise multiple testing procedure is developed to identify the covariates associated with the responses. The procedure is shown to control the false discovery proportion and false discovery rate at a prespecified level asymptotically. Simulations demonstrate the gain in power, relative to entrywise testing, in detecting the covariates associated with the responses. The test is applied to an ovarian cancer dataset to identify the microRNA regulators that regulate protein expression.",2018,Biometrika
A Combined PLS and Negative Binomial Regression Model for Inferring Association Networks from Next-Generation Sequencing Count Data,"A major challenge of genomics data is to detect interactions displaying functional associations from large-scale observations. In this study, a new cPLS-algorithm combining partial least squares approach with negative binomial regression is suggested to reconstruct a genomic association network for high-dimensional next-generation sequencing count data. The suggested approach is applicable to the raw counts data, without requiring any further pre-processing steps. In the settings investigated, the cPLS-algorithm outperformed the two widely used comparative methods, graphical lasso, and weighted correlation network analysis. In addition, cPLS is able to estimate the full network for thousands of genes without major computational load. Finally, we demonstrate that cPLS is capable of finding biologically meaningful associations by analyzing an example data set from a previously published study to examine the molecular anatomy of the craniofacial development.",2018,IEEE/ACM Transactions on Computational Biology and Bioinformatics
Sparse Covariance Estimation from Quadratic Measurements: A Precise Analysis,"We study the problem of estimating a high-dimensional sparse covariance matrix, Î£0, from a finite number of quadratic measurements, i.e., measurements ${\text{a}}_i^T{\Sigma _0}{{\text{a}}_i}$ which are quadratic forms in the measurement vectors ai resulting from the covariance matrix, Î£0. Such a problem arises in applications where we can only make energy measurements of the underlying random variables. We study a simple LASSO-like convex recovery algorithm which involves a squared 2-norm (to match the covariance estimate to the measurements), plus a regularization term (that penalizes the â„“1âˆ’norm of the non-diagonal entries of Î£0 to enforce sparsity). When the measurement vectors are i.i.d. Gaussian, we obtain the precise error performance of the algorithm (accurately determining the estimation error in any metric, e.g., 2-norm, operator norm, etc.) as a function of the number of measurements and the underlying distribution of Î£0. In particular, in the noiseless case we determine the necessary and sufficient number of measurements required to perfectly recover Î£0 as a function of its sparsity. Our results rely on a novel comparison lemma which relates a convex optimization problem with ""quadratic Gaussian"" measurements to one which has i.i.d. Gaussian measurements.",2019,2019 IEEE International Symposium on Information Theory (ISIT)
"A study of changes in groundfish trawl catching efficiency due to differences in operating width, and measures to reduce width variation","Abstract The influence of trawl width on the ability of a survey trawl to capture groundfish was tested by comparing catch rates between paired tows with and without a constraint line that reduced the operating width of the trawl. The vertical distribution of fish near and above the seafloor was recorded with an echo sounder to test for the incidence of fish diving into the path of the trawl during the tows. Arrowtooth flounder (Atheresthes stomias), flathead sole (Hippoglossoides elassodon) and walleye pollock (Theragra chalcogramma) were captured at higher rates (fish per area swept) by a survey trawl fished in the restricted (narrow) configuration. The greatest difference occurred for pollock. The difference in catch rates was consistent across size groups within each species. Correlations detected between catch rates of pollock and echo-integration values for targets well above the trawl height indicated that some of these fish may have been diving from midwater into the path of the trawl. Differences between the correlation patterns with and without constraint lines indicate that the diving behavior may be affected by the presence of the line.",1998,Fisheries Research
High-Dimensional Additive Hazards Regression for Oral Squamous Cell Carcinoma Using Microarray Data: A Comparative Study,"Microarray technology results in high-dimensional and low-sample size data sets. Therefore, fitting sparse models is substantial because only a small number of influential genes can reliably be identified. A number of variable selection approaches have been proposed for high-dimensional time-to-event data based on Cox proportional hazards where censoring is present. The present study applied three sparse variable selection techniques of Lasso, smoothly clipped absolute deviation and the smooth integration of counting, and absolute deviation for gene expression survival time data using the additive risk model which is adopted when the absolute effects of multiple predictors on the hazard function are of interest. The performances of used techniques were evaluated by time dependent ROC curve and bootstrap .632+ prediction error curves. The selected genes by all methods were highly significant (P < 0.001). The Lasso showed maximum median of area under ROC curve over time (0.95) and smoothly clipped absolute deviation showed the lowest prediction error (0.105). It was observed that the selected genes by all methods improved the prediction of purely clinical model indicating the valuable information containing in the microarray features. So it was concluded that used approaches can satisfactorily predict survival based on selected gene expression measurements.",2014,BioMed Research International
Tight performance bounds on the performance of a new compressed sensing algorithm,"Compressed sensing refers to the recovery of high-dimensional but sparse vectors from a small number of measurements. The original and popular approach to compressed sensing is based on li-norm, popularly referred to as the LASSO formulation. A recent paper gives the ""best possible"" bounds on when the LASSO formulation is able to achieve compressed sensing. Over the years, the traditional LASSO formulation has been extended to others, such as the Sparse Group LASSO (SGL). In another paper, a special case of SGL called CLOT (Combined L-One and Two) was introduced, which in turn contains LASSO as a special case. It was shown that CLOT combines the best features of both LASSO and another popular approach called Elastic Net (EN). In the present paper, we analyze both the SGL and CLOT formulations, and derive sufficient conditions under which these formulations are able to achieve compressed sensing. When the sufficient conditions for CLOT are specialized to the LASSO formulation, we recover the known ""best possible"" bounds.",2017,2017 Indian Control Conference (ICC)
Photo of the tall man,"This series includes a range of titles suitable for children, teenagers and adults. ""Longman Structural Readers"" is divided into six stages and is graded both by structure and vocabulary, from beginner to intermediate. Within each stage the readers cover different subject matter - crime, romance, adventure, famous people and places etc in a variety of genres: short stories, fiction, non-fiction and plays. The majority of the titles are original pieces written specially for the series, but some simplified versions of existing works of literature are also included. Most of the books include comprehension exercises and a number are recorded either singly or with other titles on an accompanying cassette. This title is an elementary text which is part of Stage 2 of the series. The text and illustrations are designed so that together they help the reader to understand the meaning of the words. Stage 2 texts are designed to familiarize readers with the present, past, future and present perfect tenses and contain a basic vocabulary of about 500 words. The story concerns the Tall Man, who, whenever he commits a crime leaves behind a small card with the initials TM on it. Nobody knows who he is, or what he looks like - except that he is over two metres tall. Kelly Logan reads about him in the newspaper on her way to London, but her thoughts are much more concerned with whether she will find a job and how she will get on with her cousin Adam and uncle Max...The author Stephen Rabley is also author of ""Customs and Traditions in Britain"" and ""The Gold Lasso"" which are also in this series.",1988,
Quality of Life in Patients Undergoing Combined Climatotherapy and Phototherapy,"Background. Psoriasis impairs the quality of life (QoL) of patients as is in such severe diseases as cardiac failure or some malignant diseases. The aim of the study was to assess the QoL of Bulgarian psoriasis patients and its dynamics after different treatment approaches. Matherial and methods. The study was conducted in 93 patients (55 men and 38 women), mean age 45 years. The patients were divided in 3 groups: group of patients with psoriasis placata and group of patients with psoriasis palmoplantaris, both undergoing combined climatotherapy and a control group of patients with psoriasis placata undergoing Narrow Band Ultraviolet B phototherapy (NB UVB). The combined climatotherapy was performed in the â€œTuzlataâ€ rehabilitation hospital, Balchik, Bulgaria and included thalassotherapy, peloidotherapy and balneotherapy. We used the Dermatology Quality of Life Index (DQLI) questionnaire to assess the QoL of the patients before and after the treatment. Results. The improvement of the QoL in patients with psoriasis placata undergoing combined climatotherapy was statistically higher compared to the patients undergoing NB UVB phototherapy. The improvement in the QoL of the patients with psoriasis placata undergoing combined climatotherapy was statistically signifi cant compared to the patients with psoriasis palmoplantaris undergoing the same treatment. There was no statistically signifi cant difference in the improvement of the QoL between the patients with and without comorbidities. Conclusion. Ðžur results suggest that the combined climatotherapy has better benefi cial effect on the QoL of the patients with psoriasis.",2012,
Pitfalls in Prediction Modeling for Normal Tissue Toxicity in Radiation Therapy: An Illustration With the Individual Radiation Sensitivity and Mammary Carcinoma Risk Factor Investigation Cohorts.,"PURPOSE
To identify the main causes underlying the failure of prediction models for radiation therapy toxicity to replicate.


METHODS AND MATERIALS
Data were used from two German cohorts, Individual Radiation Sensitivity (ISE) (n=418) and Mammary Carcinoma Risk Factor Investigation (MARIE) (n=409), of breast cancer patients with similar characteristics and radiation therapy treatments. The toxicity endpoint chosen was telangiectasia. The LASSO (least absolute shrinkage and selection operator) logistic regression method was used to build a predictive model for a dichotomized endpoint (Radiation Therapy Oncology Group/European Organization for the Research and Treatment of Cancer score 0, 1, or â‰¥2). Internal areas under the receiver operating characteristic curve (inAUCs) were calculated by a naÃ¯ve approach whereby the training data (ISE) were also used for calculating the AUC. Cross-validation was also applied to calculate the AUC within the same cohort, a second type of inAUC. Internal AUCs from cross-validation were calculated within ISE and MARIE separately. Models trained on one dataset (ISE) were applied to a test dataset (MARIE) and AUCs calculated (exAUCs).


RESULTS
Internal AUCs from the naÃ¯ve approach were generally larger than inAUCs from cross-validation owing to overfitting the training data. Internal AUCs from cross-validation were also generally larger than the exAUCs, reflecting heterogeneity in the predictors between cohorts. The best models with largest inAUCs from cross-validation within both cohorts had a number of common predictors: hypertension, normalized total boost, and presence of estrogen receptors. Surprisingly, the effect (coefficient in the prediction model) of hypertension on telangiectasia incidence was positive in ISE and negative in MARIE. Other predictors were also not common between the 2 cohorts, illustrating that overcoming overfitting does not solve the problem of replication failure of prediction models completely.


CONCLUSIONS
Overfitting and cohort heterogeneity are the 2 main causes of replication failure of prediction models across cohorts. Cross-validation and similar techniques (eg, bootstrapping) cope with overfitting, but the development of validated predictive models for radiation therapy toxicity requires strategies that deal with cohort heterogeneity.",2016,"International journal of radiation oncology, biology, physics"
Development of a multivariable prediction model for identification of patients at risk for medication transfer errors at ICU discharge,"INTRODUCTION
Discharge from the intensive care unit (ICU) is a high-risk process, leading to numerous potentially harmful medication transfer errors (PH-MTE). PH-MTE could be prevented by medication reconciliation by ICU pharmacists, but resources are scarce, which renders the need for predicting which patients are at risk for PH-MTE. The aim of this study was to develop a prognostic multivariable model in patients discharged from the ICU to predict who is at increased risk for PH-MTE after ICU discharge, using predictors of PH-MTE that are readily available at the time of ICU discharge.


MATERIAL AND METHODS
Data for this study were derived from the Transfer ICU Medication reconciliation study, which included ICU patients and scored MTE at discharge of the ICU. The potential harm of every MTE was estimated with a validated score, where after MTE with potential for harm were indicated as PH-MTE. Predictors for PH-MTE at ICU discharge were identified using LASSO regression. The c statisticprovided a measure of the overall discriminative ability of the prediction model and the prediction model was internally validated by bootstrap resampling. Based on sensitivity and specificity, the cut-off point of the prediction model was determined.


RESULTS
The cohort contained 258 patients and six variables were identified as predictors for PH-MTE: length of ICU admission, number of home medications and patient taking one of the following medication groups at home: vitamin/mineral supplements, cardiovascular medication, psycholeptic/analeptic medication and medication for obstructive airway disease. The c of the final prediction model was 0.73 (95%CI 0.67-0.79) and decreased to 0.62 according to bootstrap resampling. At a cut-off score of two the prediction model yielded a sensitivity of 70% and a specificity of 61%.


CONCLUSIONS
A multivariable prediction model was developed to identify patients at risk for PH-MTE after ICU discharge. The model contains predictors that are available on the day of ICU discharge. Once external validation and evaluation of this model in daily practice has been performed, its incorporation into clinical practice could potentially allow institutions to identify patients at risk for PH-MTE after ICU discharge, on the day of ICU discharge, thus allowing for efficient, patient-specific allocation of clinical pharmacy services.


TRIAL REGISTRATION
Dutch trial register: NTR4159, 5 September 2013, retrospectively registered.",2019,PLoS ONE
Classification of spectral data using fused lasso logistic regression,"Abstract Spectral data contain powerful information that can be used to identify unknown compounds and their chemical structures. In this paper, we study fused lasso logistic regression (FLLR) to classify the spectral data into two groups. We show that the FLLR has a grouping property on regression coefficients, which simultaneously selects a group of highly correlated variables together. Both the sparsity and the grouping property of the FLLR provide great advantages in the analysis of the spectral data. In particular, it resolves the well-known peak misalignment problem of the spectral data by providing data dependent binning, and provides a better interpretable classifier than other l 1 -regularization methods. We also analyze the gas chromatography/mass spectrometry data to classify the origin of herbal medicines, and illustrate the advantages of the FLLR over other existing l 1 -regularized methods.",2015,Chemometrics and Intelligent Laboratory Systems
Privacy-preserving indoor localization via light transport analysis,"We propose a system for indoor localization using intensity-controllable LED light fixtures and light sensors mounted on the ceiling. While providing accurate location estimates, our approach preserves user privacy and is robust to ambient light conditions. We develop a LASSO algorithm and a localized ridge regression algorithm for locating a single object. In synthetic experiments, our localized ridge regression algorithm achieves an average localization error ranging from 0.24in to 1.39in, for different object sizes, in a 7Ã—12-foot room. The localized ridge regression algorithm also shows the ability to locate multiple objects in experiments with a real-world occupancy scenario.",2017,"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
On multiply-exponential write-once Turing machines,"AbstractInthisworkweanalyzethemultiply-exponentialcomplexityclassesforwrite-onceTuringmachines,i.e. machinesthatcanwritetoagiventapecellatmostonce. We show that kâ€“DExpWOSpace = kâ€“DExpWOTime = kâ€“ExpTimeandthenondeterministiccounterpart. Foralternatingmachinesweshowthatkâ€“AExpWOTime = kâ€“AExpTime = k-1â€“ExpSpace.Keywords: computationalcomplexity,write-onceTuringmachine1. IntroductionTheideaofwrite-oncemachineswasï¬rststudiedbyHaoWang[1]in1957.ThosemachinesareanalogoustotheTuringmachines,withtheexceptionthatwriting is possible only to blank spaces; this model ï¬ts manytypes of storagewhichareusedbothtodayandhistorically,forexamplepunchcardsandtapesand recordable optical discs (CD-R, DVD-R etc.). Those machines are equiv-alent to Turing machines with respect to the languages they accept. In thispaperwecharacterizesomecomplexityclassesofwrite-oncemachinesandshowwhat are the corresponding complexity classes for the usual Turing machines.Additionally,weconsiderafurtherrestrictionofwrite-oncemachines,thatareallowedtowriteonlyattheendofthetape,andshowthatthisclassofmachinesisnotuniversal.2. KnownresultsIn 1960 Lee [2] has shown many useful conversions of programs for usualTuring machines to programs for write-only machines with their complexities.SubsequentlyRivestandShamir[3]haveshownacodingschemewhichallowsfor eï¬ƒcient simulation of updates; one of their most important results is thata value can be stored in a way which permits t updates at the expense ofincreasing the storage size asymptotically t=logt times. We will be using this",2014,ArXiv
Yeast heat shock transcription factor N-terminal activation domains are unstructured as probed by heteronuclear NMR spectroscopy.,"The structure and dynamics of the N-terminal activation domains of the yeast heat shock transcription factors of Kluyveromyces lactis and Saccharomyces cerevisiae were probed by heteronuclear 15N[1H] correlation and 15N[1H] NOE NMR studies. Using the DNA-binding domain as a structural reference, we show that the protein backbone of the N-terminal activation domain undergoes rapid, large-amplitude motions and is therefore unstructured. Difference CD data also show that the N-terminal activation domain remains random-coil, even in the presence of DNA. Implications for a ""polypeptide lasso"" model of transcriptional activation are discussed.",1996,Protein science : a publication of the Protein Society
"Elections, Appointments, and Human Capital: The Case of Russian Mayors","Are officials chosen through elections more likely to make good public policy than those who are appointed or anointed? Implicitly or explic- itly, this is the key question in debates about the effects of democracy on political and economic development.1 Most research attempts to answer this question by pointing to the career incentives that elected offices create. In order to be re-elected, elected officials must be responsive to voters, in turn making it more likely that policy outcomes will approximate the preferences of the median voter.2 Such accountability mechanisms have been associated with a range of positive outcomes in political economy, such as economic growth,3 public goods provision,4 and constraints on corruption and patronage.5 At the same time, some work points to ways that competitive elections can stymie economic development. Voters, it is argued, may demand policies that are inflationary, inefficient, and focused on narrow constituencies.6 According to this logic, unelected technocrats are better positioned to constrain government spending and make growth- oriented economic policy.A much smaller strain of literature focuses not on the incentives created by elections, but on the quality of officials selected. Arguments in this vein rest on two propositions. First, the intrinsic traits or characteris- tics of officials affect political and economic outcomes. Second, officials selected under elections are of a higher quality than those selected via non-democratic selection rules, such as appointment, inheritance, tradi- tion, or force.There is ample evidence in political science for the first proposition. Theorists of descriptive representation have long argued that representa- tives who are similar to their constituents will be more likely to govern in their interest,7 and empirical scholars have confirmed that descriptive simi- larities between elector and elected increases the chances that the latter will represent the former.8 Characteristics of public officials have been shown to matter in other ways as well. Carnes finds that businessman legislators are more politically conservative.9 Both Besley et al. and Congleton and Zhang find that educated heads of state are associated with higher growth rates.10 Similarly, bureaucrats with technocratic backgrounds are thought to be better at generating good governance than unskilled political cronies.11 In the business world, older CEOs are found to be more conservative.12 In China, regional party secretaries with ties to their home region have been found to be superior at providing public goods and are less predatory toward business.13 Glynn and Sen show that among judges with one child, those with a daughter are more likely to rule in favour of women's issues than judges with a son.14Evidence for the second proposition is both more limited and more contradictory. On the one hand political thinkers from Harrington to Madison have argued that voters will naturally select those with wisdom and virtue. In support of this argument, Besley et al. find that demo- cratically elected heads of state have higher levels of education than heads of state in autocracies.15 At lower levels of government, Galasso and Nannicini, and Veronese both find that political competition leads to the selection of candidates with higher levels of education and more govern- ing experience.16 In China, Luo finds that elected village heads have more years of schooling than appointed village heads.17 In Russia, Shurchkov finds that regions where ""new-elite"" governors came to power via central- ized appointments had less small business development than regions with ""old-elites"" who won power through elections.18On the other hand, other scholars have pointed out that democracy may in fact lead to the selection of unqualified officials. Scholars of populism and nationalism point to a strong ""anti-elite"" sentiment in most electorates, which can sometimes result in the election of outsiders or demagogues. â€¦",2014,Demokratizatsiya
[The value of analysis of quantitative radiomics based on DTI in predicting astrocytoma IDH1 mutation].,"Objective: Non-invasive prediction of IDH1 mutations by establishing a quantitative radiographic model based on DTI-based whole-tumor texture analysis. Methods: Preoperative MRI images of patients with surgically confirmed astrocytoma were collected in the First Affiliated Hospital of Soochow University from February 2016 to June 2019, including T(1)WI, T(2)WI, DTI, and T(1)-contrast enhancement images.A total of 38 patients were included, consisting of 12 mutants and 26 wilds, 20 males and 18 females, the average age was (49Â±15) years old.The ROIs were drawn on each level of the T(2)WI image using MaZda software and copied to the ADC and FA maps to extract texture feature parameters. The LASSO regression was used to determine the best radiomics features, radiological scores were calculated, and binary Logistic regression was used to construct a prediction model, then the ROC curve was used to analyze the diagnostic efficiency and the calibration curve was used to evaluate model prediction performance. Results: The four most valuable radiomics features were determined by LASSO regression, and then the radiomics scores and Logistic regression models of each patient were established. The radiomics scores of the wild and mutant groups were 2.3Â±0.3 and 1.8Â±0.4. There were significant differences between the groups (P<0.05). The ROC curve analysis showed an AUC of 0.837 with sensitivity and specificity of 91.7% and 61.5%, respectively. The Logistic regression model had good predictive performance with AUC of 0.907, sensitivity and specificity of 91.7% and 84.6%. Conclusions: DTI-based whole tumor radiomics model is benefit for predicting astrocytoma IDH1 mutations.",2020,Zhonghua yi xue za zhi
[The modern trends in the treatment and prevention of lymphedema of the lower extremities].,"This article was designed to describe the main pathogenetic factors underlying the development of lymphedema of the lower extremities, the social implications of this condition, its prevalence throughout the world, and the impact of this disease on the quality of life of patients. In addition, the review presents the modern data on the management of patients with chronic lymphatic edema of the lower extremities. Special attention is given to the principles and methods of its combined conservative treatment, including the use of medications, compression therapy, physiotherapy, thalassotherapy, and balneotherapy. Moreover, the results of the analysis of the effectiveness of the treatment as a whole and of the individual methods, such as intermittent pneumatic compression (SPC), electrical myostimulation, laser therapy, magnetic-laser therapy (MLT) are reported with special reference to their outcomes when applied as isolated interventions and the components of the combined therapy. The review is devoted to the systematization of information about the currently available methods for the prevention and treatment of lymphadema of the lower extremities and the evaluation of the treatment regimens applied in this country and leading foreign clinical centres. Also considered are both the classical scheme of the combined treatment of lymphedema of the lower extremities and the schemes including novel therapeutic modalities. The most promising methods for the treatment of this condition including those proposed during a few recent years (such as kinesiotaping, LPG-engineering, and gravity therapy) are highlighted, and their influence on the generally accepted schemes of the combined treatment of lymphedema of the lower extremities is evaluated. The basic principles of modern pharmacotherapy and its role in the system of methods for the treatment of lymphedema of the lower extremities including phlebotomies, lymphokinesia, antibacterial drugs are considered.",2018,"Voprosy kurortologii, fizioterapii, i lechebnoi fizicheskoi kultury"
Efficient Process Monitoring via the Integrated Use of Markov Random Fields Learning and the Graphical Lasso,"Process monitoring is an important aspect of safe operation of process plants. Various methods exist that monitor the process using data-driven methods, but they all have certain limitations. For instance, most of the fault detection methods are not able to detect the fault propagation path, and some methods require a priori knowledge on the faults, or the relationships between the monitored variables. In this study, a monitoring method for accurately detecting the faults and analyzing the fault propagation path is proposed. Named the Glasso-MRF monitoring framework, this method integrates the use of the graphical lasso algorithm (G-lasso) and the Markov random field (MRF) modeling framework to divide the monitored variables into relevant groups and then detect the faults separately for each of the groups. Graphical lasso uses the lasso constraint on the inverse covariance matrix of variables within the maximum likelihood estimation problem, driving it to be of sparse form. The use of graphical lasso down...",2018,Industrial & Engineering Chemistry Research
