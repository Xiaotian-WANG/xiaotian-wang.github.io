title,abstract,year,journal
Design and Analysis of Clinical Trials with Time to Event Endpoints,"Overview of Time-to-Event Endpoint Methodology Karl E. Peace Design (and Monitoring) of Clinical Trials with Time-to-Event Endpoints Michael W. Sill and Larry Rubinstein Overview of Time-to-Event Parametric Methods Karl E. Peace and Kao-Tai Tsai Overview of Semiparametric Inferential Methods for Time-to-Event Endpoints Jianwen Cai and Donglin Zeng Overview of Inferential Methods for Categorical Time-to-Event Data Eric V. Slud Overview of Bayesian Inferential Methods Including Time-to-Event Endpoints Laura H. Gunn An Efficient Alternative to the Cox Model for Small Time-to-Event Trials Devan V. Mehrotra and Arthur J. Roth Estimation and Testing for Change in Hazard for Time-to-Event Endpoints Rafia Bhore and Mohammad Huque Overview of Descriptive and Graphical Methods for Time-to-Event Data Michael O'Connell and Bob Treder Design and Analysis of Analgesic Trials Akiko Okamoto, Julia Wang, and Surya Mohanty Design and Analysis of Analgesic Trials with Paired Time-to-Event Endpoints Zhu Wang and Hon Keung Tony Ng Time-to-Event Endpoint Methods in Antibiotic Trials Karl E. Peace Design and Analysis of Cardiovascular Prevention Trials Michelle McNabb and Andreas Sashegyi Design and Analysis of Antiviral Trials Anthony C. Segreti and Lynn P. Dix Cure Rate Models with Applications to Melanoma and Prostate Cancer Data Ming-Hui Chen and Sungduk Kim Parametric Likelihoods for Multiple Nonfatal Competing Risks and Death, with Application to Cancer Data Peter F. Thall and Xuemei Wang Design, Summarization, Analysis, and Interpretation of Cancer Prevention Trials Matthew C. Somerville, Jennifer B. Shannon, and Timothy H. Wilson LASSO Method in Variable Selection for Right-Censored Time-to-Event Data with Application to Astrocytoma Brain Tumor and Chronic Myelogenous Leukemia Lili Yu and Dennis Pearl Selecting Optimal Treatments Based on Predictive Factors Eric C. Polley and Mark J. van der Laan Application of Time-to-Event Methods in the Assessment of Safety in Clinical Trials Kelly L. Moore and Mark J. van der Laan Design and Analysis of Chronic Carcinogenicity Studies of Pharmaceuticals in Rodents Mohammad Atiar Rahman and Karl K. Lin Design and Analysis of Time-to-Tumor Response in Animal Studies: A Bayesian Perspective Steve Thomson and Karl K. Lin Index",2009,
An empirical investigaton of political economy factors behind structural reforms in OECD countries,"This paper was originally prepared for the OECD Working Party No. 1 under the authority of the OECDâ€™s Economic Policy Committee. Jens Hoj and Giuseppe Nicoletti work for the OECD Economics Department as a senior economist in the Country Studies Branch and as Head of the Structural Policy Analysis Division 1, respectively. Vincenzo Galasso is an Associate Professor of Economics at Universita Bocconi in Italy and Thai-Thang Dang is a private sector consultant. The authors wish to thank Jean Philippe Cotis, Jorgen Elmeskov, Michael P. Feiner, Christopher Heady, Nick Johnstone and many other colleagues in the OECD Economics Department as well as representatives from OECD member countries for useful comments on a previous version of the paper.",2007,Oecd Economic Studies
Competitive hierarchies among three species of juvenile coral reef fishes,"Interspecific competition is often asymmetric, and it can limit the spatial distributions of competitively inferior species within a community. When asymmetric competition involves 2 or more component species, the ranking of species' competitive abilities may form competitive hier- archies (all species of higher rank out-compete all species of lower rank) or competitive networks (at least 1 species of lower rank out-competes â‰¥1 species of higher rank). Expectations of resource monopolization and patterns of distribution and abundance among species in competitive net- works are expected to differ from those in competitive hierarchies. We conducted a field experi- ment to evaluate the relative competitive abilities of juveniles of 3 closely related species of reef fish (bird wrasse Gomphosus varius, fivestripe wrasse Thalassoma quinquevittatum and the sixbar wrasse T. hardwicke) on Moorea, French Polynesia. We controlled for intrinsic variation in sur- vivorship among species and found that competition among these 3 species was highly asymmet- ric, resulting in a simple competitive hierarchy (sequence of competitive ability from superior to inferior competitors): fivestripe wrasse > bird wrasse > sixbar wrasse. We surveyed densities of the 3 reef fish species on 55 patch reefs and observed significant negative spatial covariation between superior and inferior competitors, consistent with competitive hierarchies that limit the spatial dis- tributions of the inferior species (sixbar wrasse). Our work demonstrates that intense asymmetric competition and the formation of competitive hierarchies may be an important determinant of resource monopolization and patterns of distribution and abundance in reef fishes.",2013,Marine Ecology Progress Series
[Mansonelliasis identified by a cervicovaginal smear at the university hospital center of Bobo-Dioulasso (Burkina Faso)].,"INTRODUCTION
Mansonella perstans is a genus of filaria that is often asymptomatic or responsible for unspecific symptoms. M. perstans microfilariae are uncommon on cervicovaginal smears.


CASE
We report the case of a woman with pruritis and eosinophilia. Microfilariae of M. perstans were observed on both cervicovaginal and blood smears. The patient was successfully treated with a combined single dose of 400 mg of albendazole and ivermectin (150 Î¼g/kg).


CONCLUSION
We described here an atypical and rare localization of M. perstans. The routine examination of cervicovaginal smears of women admitted to Bobo-Dioulasso Hospital for screening of cervical neoplasia should allow us to determine the frequency of this parasitosis and propose appropriate treatment.",2012,Medecine et sante tropicales
"Untersuchungen zur Struktur und StabilitÃ¤t neuer, durch Genome Mining identifizierter Lassopeptide","Das zunehmende Auftreten
 multiresistenter Bakterien macht die Suche nach neuen
 antibakteriellen Wirkstoffen notwendiger denn je. Naturstoffe
 stellen dabei eine sehr reichhaltige Quelle dar, da sie uber
 strukturelle und chemische Diversitat verfugen, die teilweise
 nicht oder nur unter grosem Aufwand synthetisch zuganglich
 ist. Fur die Identifikation neuer Naturstoffe kann dabei
 besonders die Methode des Genome Minings genutzt werden, da
 durch die stark gesunkenen Kosten von Sequenzierungen immer
 mehr Komplettgenome in den Datenbanken zur Verfugung stehen.
 Eine spezielle Familie der ribosomal synthetisierten und
 post-translational modifizierten Peptide (RiPPs) sind die
 Lassopeptide, die ihren Namen ihrer besonderen
 dreidimensionalen Faltung verdanken. Diese zeigen trotz
 geringer chemischer Modifikation thermische und
 proteolytische Stabilitat und teilweise interessante
 Bioaktivitaten. In dieser Arbeit konnten mit dem Genome
 Mining Ansatz fast 100 potentielle
 Lassopeptidbiosynthesegencluster identifiziert werden. Als
 Beweis der Funktionalitat des Genome Minings wurde ein
 Cluster ausgewahlt und das hitzelabile Lassopeptid Astexin-1
 in verschiedenen Verkurzungsvarianten isoliert, auf
 thermische und proteolytische Stabilitat hin untersucht und
 seine 3D-Struktur mittels NMR-Spektroskopie aufgeklart. Eine
 extensive Mutagenesestudie wurde zur Untersuchung der
 Spezifitat der Biosynthesemaschinerie, sowie zur
 Identifikation wichtiger Reste fur die Stabilitat der
 Lassofaltung durchgefuhrt. Dabei konnte durch rationale
 Inkorporation einer Mutation der nativ hitzelabile Naturstoff
 in ein hitzestabiles Lassopeptid transformiert werden. Im
 zweiten Teil der Arbeit wurden zwei Biosynthesegencluster aus
 Caulobacter sp. K31, die durch Genome Mining identifiziert
 worden sind, ausgewahlt und es konnten vier neue
 Lassopeptide, die Caulonodine IV â€“ VII, isoliert werden.
 Diese vier Caulonodine tragen Serin bzw. Alanin an Position 1
 der Lassopeptidsequenz und definieren damit die Klasse II der
 Lassopeptide neu, da vorher nur Peptide mit Glycin an dieser
 Position bekannt waren. Die Caulonodine wurden auf ihre
 thermische und proteolytische Stabilitat hin untersucht und
 offenbarten sich als hitzelabile Lassopeptide. Die
 anschliesende Mutagenesestudie zeigte die veranderte
 Spezifitat der Biosynthesemaschinerie fur Position 1 und
 ermoglichte die Postulierung der Stopselaminosauren fur alle
 vier Caulonodine. Diese Vorhersage wurde fur Caulonodin V
 durch Aufklarung der 3D Struktur mittels NMR-Spektroskopie
 bestatigt. Eine Mutagenesestudie des Leaderpeptids konnte
 bestatigen, dass im Leaderpeptid weitere Reste neben Thr-2
 fur die Prozessierung durch die Biosynthesemaschinerie
 wichtig sind.%%%%The increasing occurrence of
 multi-resistant bacteria makes it moreâ€¦",2013,
Forecasting Real House Price of the U.S.: An Analysis Covering 1890 to 2012,"This paper evaluates the ability of Bayesian shrinkage-based dynamic predictive regression models estimated with hierarchical priors (Adaptive Jefferys, Adaptive Student-t, Lasso, Fussed Lasso and Elastic Net priors) and non-hierarchical priors (Gaussian, Lasso-LARS, Lasso-Landweber) in forecasting the U.S. real house price growth. We also compare results with forecasts from bivariate OLS regressions and principal component regression. We use annual dataset on 10 macroeconomic predictors spanning the period 1890 to 2012. Using an out-of-sample period of 1917 to 2012, our results based on MSE and McCracken (2007) MSE-F statistic, indicate that in general, the non-hierarchical Bayesian shrinkage estimators perform better than their hierarchical counterparts as well as the least square estimators. The Bayesian shrinkage estimated with Lasso-Landweber is the best-suited model for forecasting the U.S. real house price. Among the least square models, the individual regression with house price regressed on the fiscal policy variable outperforms the rest. Also results from Lasso-Landweber portray the fiscal policy variable as the best predictor of the U.S. house prices especially in the recent times while the short-term interest rate and real construction cost also did well at the beginning and middle of the sample.",2013,
RI20 Retrait percutane des corps etrangers intra-vasculaires : indications et techniques,"Objectifs Les CEIV sont une complication iatrogenique de plus en plus frequente. Le but de ce travail est de rappeler les indications du retrait de corps etrangers intra-vasculaires (CEIV), decrire le principe du retrait percutane, preciser les specificites techniques en fonction de la nature du CEIV. Materiels et methodes Les CEIV peuvent etre de nature variable : catheters ou fragments de catheter, guides, coils, filtre cave, dispositif de fermeture de communication inter-atrialeâ€¦ Base sur notre experience et les donnees de la litterature, tout corps etranger mobilisable doit etre retire en raison des risques de complications associes a sa presence. Une seule voie dâ€™abord percutanee est en regle suffisante pour le retrait complet du CEIV. Resultats Les CEIV veineux sont les plus frequents. A travers de multiples observations, les techniques de retrait sont illustrees incluant lâ€™adhesiolyse mecanique, la mobilisation du CIEV, le repositionnement, le retrait par lasso, le retrait par pince ou filet. Le taux de succes du retrait est > 95 %. Un geste chirurgical complementaire est rarement necessaire. Le taux de complications majeures liees au geste est Conclusion Le retrait percutane des CEIV est indique chaque fois quâ€™il est techniquement faisable. La technique du lasso, la plus repandue, est facilement accessible, rapide et a tres faible morbidite.",2006,Journal De Radiologie
On the determinants of bitcoin returns: A LASSO approach,"We examine the significance of twenty-one potential drivers of bitcoin returns for the period 2010 to 2017 (2,533 daily observations). Within a LASSO framework, we examine the effects of factors such as stock market returns, exchange rates, gold and oil returns, FEDâ€™s and ECBâ€™s rates and internet trends on bitcoin returns for alternate time periods. Search intensity and gold returns emerge as the most important variables for bitcoin returns.",2018,Finance Research Letters
Pivotal estimation via square-root lasso in nonparametric regression,"We propose a self-tuning v Lasso method that simultaneiously resolves three important practical problems in high-dimensional regression analysis, namely it handles the unknown scale, heteroscedasticity, and (drastic) non-Gaussianity of the noise. In addition, our analysis allows for badly behaved designs, for example perfectly collinear regressors, and generates sharp bounds even in extreme cases, such as the infinite variance case and the noiseless case, in contrast to Lasso. We establish various non-asymptotic bounds for v Lasso including prediction norm rate and sharp sparcity bound. Our analysis is based on new impact factors that are tailored to establish prediction rates. In order to cover heteroscedastic non-Gaussian noise, we rely on moderate deviation theory for self-normalized sums to achieve Gaussian-like results under weak conditions. Moreover, we derive bounds on the performance of ordinary least square (ols) applied to the model selected by v Lasso accounting for possible misspecification of the selected model. Under mild conditions the rate of convergence of ols post v Lasso is no worse than v Lasso even with a misspecified selected model and possibly better otherwise. As an application, we consider the use of v Lasso and post v Lasso as estimators of nuisance parameters in a generic semi-parametric problem (nonlinear instrumental/moment condition or Z-estimation problem).",2013,Annals of Statistics
BLK-REW: A Unified Block-based DNN Pruning Framework using Reweighted Regularization Method,"Accelerating DNN execution on various resource-limited computing platforms has been a long-standing problem. Prior works utilize l1-based group lasso or dynamic regularization such as ADMM to perform structured pruning on DNN models to leverage the parallel computing architectures. However, both of the pruning dimensions and pruning methods lack universality, which leads to degraded performance and limited applicability. To solve the problem, we propose a new block-based pruning framework that comprises a general and flexible structured pruning dimension as well as a powerful and efficient reweighted regularization method. Our framework is universal, which can be applied to both CNNs and RNNs, implying complete support for the two major kinds of computation-intensive layers (i.e., CONV and FC layers). To complete all aspects of the pruning-for-acceleration task, we also integrate compiler-based code optimization into our framework that can perform DNN inference in a real-time manner. To the best of our knowledge, it is the first time that the weight pruning framework achieves universal coverage for both CNNs and RNNs with real-time mobile acceleration and no accuracy compromise.",2020,ArXiv
Canonical density matrix perturbation theory.,"Density matrix perturbation theory [Niklasson and Challacombe, Phys. Rev. Lett. 92, 193001 (2004)] is generalized to canonical (NVT) free-energy ensembles in tight-binding, Hartree-Fock, or Kohn-Sham density-functional theory. The canonical density matrix perturbation theory can be used to calculate temperature-dependent response properties from the coupled perturbed self-consistent field equations as in density-functional perturbation theory. The method is well suited to take advantage of sparse matrix algebra to achieve linear scaling complexity in the computational cost as a function of system size for sufficiently large nonmetallic materials and metals at high temperatures.",2015,"Physical review. E, Statistical, nonlinear, and soft matter physics"
Selection of classification boundaries using the logistic regression,"We propose the method for selecting classification boundaries for the logistic regression model, by applying the sparse regularization. We can investigate which combination of classification boundaries are truly necessary for the multinomial logistic model by encouraging some of coefficient parameters themselves or their differences toward exactly zeros. The model is estimated by the maximum penalized likelihood method with the fused lasso type penalty. We also introduce some model selection criteria for evaluating models estimated by the penalized likelihood method. Simulation and real data analysis show insights that the proposed method goes well.",2013,
Image quality assessment with lasso regression and pairwise score differences,"The reception of multimedia applications often depends on the quality of processed and displayed visual content. This is the main reason for the development of automatic image quality assessment (IQA) techniques which try to mimic properties of human visual system and produce objective scores for evaluated images. Most of them require a training step in which subjective scores, obtained in tests with human subjects, are used for parameters tuning. In this paper, it is shown that pairwise score differences (PSD) can be successfully used for training a full-reference hybrid IQA measure based on the least absolute shrinkage and selection operator (lasso) regression. The results of extensive experimental evaluation on four largest IQA benchmarks show that the proposed IQA technique is statistically better than its version trained using raw scores, and both approaches are statistically better than state-of-the-art full-reference IQA measures. They are also better than other hybrid approaches. In the paper, the evaluation protocol is extended with tests using PSD.",2016,Multimedia Tools and Applications
Plate Tectonics and the Structural Evolution of the Aleutianâ€“Bering Sea Region,"The general aspects of the structural evolution of the Aleutian-Bering Sea region can be described in terms of plate tectonics. Involved in this model is the formation of the Aleutian Ridge in latest Cretaceous or earliest Tertiary time. The ridge is presumed to have formed in response to a southward relocation in the convergence zone of the Pacific oceanic plate, a shift away from the Beringian continental margin connecting Alaska and Siberia to an oceanic location at the Aleutian Trench. Prior to the formation of the ridge, Pacific crust is presumed to have directly underthrust the northeast-trending Koryak-Kamchatka coast. The middle and late Mesozoic eugeosynclinal or thalassogeosynclinal masses that underlie this segment of the Pacific fold belt are highly deformed, thrust faulted, and intruded by ultramafic bodies-characteristics that can be ascribed to the mechanical and magmatic consequence of plate underthrusting. This model implies a similar orogenic process for the formation of the stratigraphically and structurally similar Mesozoic rocks underlying the northeast-trending continental margin of southern Alaska. Less intense underthrusting may have occurred along the northwest-trending Pribilof segment of the Beringian margin connecting Alaska and Siberia. This margin may have been more parallel to the approximate direction of relative motion between the oceanic and continental plates. Nonetheless, fold belts, possibly intruded by ultramafic masses, formed along this segment of the Beringian continental margin in Late Cretaceous and perhaps earliest Tertiary time. The folds have since subsided below sea level-their eroded tops presently underlying as much as 3 km of virtually undeformed Cenozoic deposits. Our model relates pre- and postorogenic deposits underlying the Beringian margin and adjacent coast to the time of formation of the Aleutian Ridge, which marked the cessation of continental underthrusting and the beginning of island-arc underthrusting. Our model also implies that the ridge formed near or at its present location and that oceanic crust of late Mesozoic age underlies the Aleutian Basin of the Bering Sea. Since formation of the ridge this basin has received from 2 to 10 km of sedimentary fill. Although the model we suggest broadly explains the observed changes in tectonic style, magmatic history, and sedimentation for the Aleutian-Bering Sea region, it also implies that thousands of kilometers of oceanic crust underthrust the Kamchatka, Beringian, and Alaskan margins between Late Triassic and Late Cretaceous time, and hundreds of kilometers underthrust the Aleutian Ridge in Cenozoic time. The enormous masses of pelagic and volcanic offscrapings that would be indicative of extensive or long-term crustal underthrusting are not apparent as mappable units. Thus, while our model may be stylistically adequate, it paradoxically predicts quantities of rocks and structures that we are not able to find. Presumably they have been subducted.",1975,
"Characterisation of high-altitude Artemia populations from the Qinghai-Tibet Plateau, PR China","The brine shrimp Artemia was discovered in a number of saline lakes on the Qinghai-Tibet Plateau, widely diverging in chemical composition. Several lakes were athalassohaline, with relatively high amounts of trace elements. Common environmental factors are their high altitude (exceeding 4500 m) and the low average annual temperatures. A number of Artemia populations in this area were analysed to assess their preference for low temperatures and an athalassohaline medium. Furthermore, their characteristics were compared with Artemia tibetiana, the species recently described for one lake in this area. All samples contained a variable mixture of parthenogenetic and bisexual individuals. A cross-breeding test of the sample from Jingyu Lake showed cross-fertility both with A. tibetiana and A. sinica. All populations showed similarities to A. tibetiana: a large cyst diameter and naupliar length, high HUFA content and a high tolerance to low temperatures, as compared to the control A. franciscana samples. These can thus be considered as recurrent characteristics of the populations from the high-altitude lowtemperature environment on the Qinghai-Tibet Plateau, although further research is needed to identify their exact species status.",2003,Hydrobiologia
Regularized Estimation in High Dimensional Time Series under Mixing Conditions,"The Lasso is one of the most popular methods in high dimensional statistical learning. Most existing theoretical results for the Lasso, however, require the samples to be iid. Recent work has provided guarantees for the Lasso assuming that the time series is generated by a sparse Vector Auto-Regressive (VAR) model with Gaussian innovations. Proofs of these results rely critically on the fact that the true data generating mechanism (DGM) is a finite-order Gaussian VAR. This assumption is quite brittle: linear transformations, including selecting a subset of variables, can lead to the violation of this assumption. In order to break free from such assumptions, we derive nonasymptotic inequalities for estimation error and prediction error of the Lasso estimate of the best linear predictor without assuming any special parametric form of the DGM. Instead, we rely only on (strict) stationarity and mixing conditions to establish consistency of the Lasso in the following two scenarios: (a) alpha-mixing Gaussian processes, and (b) beta-mixing sub-Gaussian random vectors. Our work provides an alternative proof of the consistency of the Lasso for sparse Gaussian VAR models. But the applicability of our results extends to non-Gaussian and non-linear times series models as the examples we provide demonstrate. In order to prove our results, we derive a novel Hanson-Wright type concentration inequality for beta-mixing sub-Gaussian random vectors that may be of independent interest.",2016,ArXiv
Endoloop application for the removal of a self-expandable metallic stent (SEMS) in an esophagocolonic anastomotic stricture.,"Anastomotic strictures occur in 3%â€“46.2% of patients after colonic reconstruction of the esophagus [1]. Self-expanding metal stents (SEMS) are increasingly considered for refractory or complex benign strictures of the esophagus [2]. Migration is a common complication and the stent should be removed to avoid gastrointestinal complications. A 54-year-old manwas referred to our department for dysphagia following esophagectomy with colonic interposition to treat an esophageal adenocarcinoma. On esophagoscopy, a 5-mm wide and 3-cm long stricture, corresponding to the esophagocolonic anastomosis at 25cm from the incisors, could not be traversed. After five dilation sessions at 2-week intervals the patient was still dysphagic and a fully covered stent (HanaroStent, 80mm in length, 18mm in diameter; MI Tech, Seoul, Korea) was positioned. The patient reported clinical improvement for 2weeks but then the dysphagia recurred. Radiographic examination disclosed stent migration. Endoscopy confirmed its location at the distal part of the colonic segment, proximal to the cologastric anastomosis, and the persistence of the proximal anastomotic stenosis. We decided to re-dilate the stenosis up to 15mm (â—"" Video 1), and mobilize the stent proximally and try to remove it using endoloops to reduce the stent diameter. With the stent positioned in the colonic segment, four detachable ligating devices (MAJ 254; Olympus, Tokyo, Japan) were applied. Because of the eversion of its distal edge and the risk of the stent getting caught in the tissue, it was rotated and then retrieved by utilizing the â€œlassoâ€ stitch at thestentedgeandpulling it against the endoscope. The whole assembly was subsequently removed under fluoroscopic control through the stricturewithout complications. The removal of migrated SEMS is technically challenging and different methods have been reported, including the use of endoloops [3â€“5]. To our knowledge this is the first video report of a stent retrieved from an esophagocolonic anastomosis.",2013,Endoscopy
In This Issue,"Telomeric DNA forms a lasso-like structure, or T loop, that has been proposed to protect the chromosome end from degradation. Vannier et al. show that the helicase RTEL1 promotes genome stability by both dismantling T loops and unraveling telomeric quadruplex DNA structures to permit DNA replication. In the absence of RTEL1, T loops are cleaved and resolved as circular telomere fragments, resulting in ectopic recombination and telomere length instability.",2012,Cell
ModÃ¨les de prÃ©diction pour l'Ã©valuation gÃ©nomique des bovins laitiers franÃ§ais : application aux races Holstein et MontbÃ©liarde,"L'evolution rapide des techniques de sequencage et de genotypage soulevent de nouveaux defis dans le developpement des methodes de selection pour les animaux dâ€™elevage. Par comparaison de sequences, il est a present possible d'identifier des sites polymorphes dans chaque espece afin de baliser le genome par des marqueurs moleculaires appeles SNP (Single Nucleotide Polymorphism). Les methodes de selection des animaux a partir de cette information moleculaire necessitent une representation complete des effets genetiques. Meuwissen et al. (2001) ont introduit le concept de selection genomique en proposant de predire simultanement tous les effets des regions marquees puis de construire un index ""genomique"" en sommant les effets de chaque region. Le challenge dans lâ€™evaluation genomique est de disposer de la meilleure methode de prediction afin dâ€™obtenir des valeurs genetiques precises pour une selection efficace des animaux candidats. Lâ€™objectif general de cette these est d'explorer et dâ€™evaluer de nouvelles approches genomiques capables de predire des dizaines de milliers d'effets genetiques, sur la base des phenotypes de centaines d'individus. Elle sâ€™inscrit dans le cadre du projet ANR AMASGEN dont le but est dâ€™etendre la selection assistee par marqueurs, utilisee jusquâ€™a lors chez les bovins laitiers francais, et de developper une methode de prediction performante. Pour cela, un panel varie de methodes est explore en estimant leurs capacites predictives. Les methodes de regression PLS (Partial Least Squares) et sparse PLS, ainsi que des approches bayesiennes (LASSO bayesien et BayesCÏ€) sont comparees a deux methodes usuelles en amelioration genetique : le BLUP base sur lâ€™information pedigree et le BLUP genomique base sur lâ€™information des SNP. Ces methodologies fournissent des modeles de prediction efficaces meme lorsque le nombre dâ€™observations est tres inferieur au nombre de variables. Elles reposent sur la theorie des modeles lineaires mixtes gaussiens ou les methodes de selection de variables, en resumant lâ€™information massive des SNP par la construction de nouvelles variables. Les donnees etudiees dans le cadre de ce travail proviennent de deux races de bovins laitiers francais (1 172 taureaux de race Montbeliarde et 3 940 taureaux de race Holstein) genotypes sur environ 40 000 marqueurs SNP polymorphes. Toutes les methodes genomiques testees ici produisent des evaluations plus precises que la methode basee sur la seule information pedigree. On observe un leger avantage predictif des methodes bayesiennes sur certains caracteres mais elles sont cependant trop exigeantes en temps de calcul pour etre appliquees en routine dans un schema de selection genomique. Lâ€™avantage des methodes de selection de variables est de pouvoir faire face au nombre toujours plus important de donnees SNP. De plus, elles sont capables de mettre en evidence des ensembles reduits de marqueurs, identifies sur la base de leurs effets estimes, câ€™est-a-dire ayant un impact important sur les caracteres etudies. Il serait donc possible de developper une methode de prediction des valeurs genomiques sur la base de QTL detectes par ces approches.",2012,
Regression Phalanxes,"Tomal et al. (2015) introduced the notion of â€œphalanxesâ€ in the context of rareclass detection in two-class classification problems. A phalanx is a subset of features that work well for classification tasks. In this paper, we propose a different class of phalanxes for application in regression settings. We define a â€œRegression Phalanxâ€ â€“ a subset of features that work well together for prediction. We propose a novel algorithm which automatically chooses Regression Phalanxes from high-dimensional data sets using hierarchical clustering and builds a prediction model for each phalanx for further ensembling. Through extensive simulation studies and several real-life applications in various areas (including drug discovery, chemical analysis of spectra data, microarray analysis and climate projections) we show that an ensemble of Regression Phalanxes improves prediction accuracy when combined with effective prediction methods like Lasso or Random Forests.",2017,
Genomic Selection for Yield and Seed Protein Content in Soybean: A Study of Breeding Program Data and Assessment of Prediction Accuracy,"Soybean [Glycine max (L.) Merr.] is a major crop with high seed protein content. Genomic selection is expected to be a valuable tool in improving the efficiency of breeding programs, especially for complex traits such as yield. This study aimed to evaluate the accuracy of genomic selection for yield and seed protein content in a soybean breeding population. Having a structured population, we compared genomic prediction accuracy obtained using models calibrated across or within two subpopulations: early lines and late lines. Calibrations within subpopulations were more efficient. Using a medium density of markers and genomic best linear unbiased prediction(GBLUP) model, which assumes an additive polygenic architecture, we predicted ~32 and39% of phenotypic variation among late lines for seed protein content and yield, respectively. Prediction accuracy was further improved by including epistasis in the GBLUP model. Further, we assessed accuracies obtained using several Bayesian models that assume different distributions for marker effects: Bayesian ridge regression, Bayesian LASSO, Bayes Cp, and Bayes R. Overall, these approaches did not improve prediction accuracy. In this study, were ported preliminary results relevant to the study of the efficiency of genomic selection use in a breeding program.",2017,Crop Science
Size matters: observations regarding the sonographic double contour sign in different joint sizes in acute gouty arthritis,"ObjectiveIn distinguishing urate arthritis (UA) from non-crystal-related arthritides, joint sonography including the detection of the double contour sign (DCS) and hypervascularization using power Doppler ultrasound (PDUS) is an important step in the diagnostic process. But are these sonographic features equally reliable in every accessible joint under real-life conditions?MethodsWe retrospectively analyzed 362Â patients with acute arthritis and evaluated the DCS and the degree of PDUS hypervascularization in patients with gout and in those with arthritis other than urate arthritis (non-UA). We classified all joints into the groups small, medium, and large. Sensitivities, specificities, positive and negative predictive values (PPV/NPV), and aÂ binary regression model were calculated. We also evaluated the influence of serum uric acid levels (SUA) on the presence of aÂ DCS in each joint category.ResultsSensitivity of the DCS in gout was 72.5% in the entire cohort, 66.0% in large, 78.8% in medium, and 72.3% in small joints. In wrist joints the DCS sensitivity maxed at 83.3%, with aÂ specificity of 81.8%. The lowest rates of DCS sensitivity were found in gout patients with elbow joint involvement (42.9%). In all joints except metatarsophalangeal jointÂ 1 (MTP-1), the incidence of aÂ DCS increased by the increment of SUA levels above 7.5â€¯mg/dl (pâ€¯<â€‰0.001). PDUS signals were most commonly found in medium and small joints and were only scarce in large joints, independent of the underlying diagnosis.ConclusionsIn our study we detected different rates of accuracy regarding DCS and PDUS in patients with acute arthritis. The best results were seen in medium-size joints, especially wrists.ZusammenfassungZielBei der Unterscheidung zwischen Gichtarthritis und nichtkristallassoziierten Arthritiden ist die Arthrosonographie zur Detektion des Doppelkonturzeichens (DCS) und der Hypervaskularisation im Power-Doppler-Ultraschall (PDUS) ein wichtiger Schritt im diagnostischen Prozess. Aber sind diese sonographischen Zeichen unter Alltagsbedingungen gleichsam zuverlÃ¤ssig in allen untersuchbaren Gelenken?MethodenRetrospektiv wurden die Daten von 362 Patienten mit akuter Arthritis und das DCS analysiert sowie die Hypervaskularisation im PDUS bei FÃ¤llen mit Uratarthritis (UA) vs. Nichturatarthritis (non-UA) ausgewertet. Alle Gelenke wurden der GrÃ¶ÃŸe nach in klein, mittel und groÃŸ eingeordnet. Es wurden SensitivitÃ¤ten, SpezifitÃ¤ten, positive und negative prÃ¤diktive Werte und eine binÃ¤re Regression kalkuliert. AuÃŸerdem werteten die Autoren den Einfluss der SerumharnsÃ¤ure auf die Detektierbarkeit eines DCS in jeder Gelenkkategorie aus.ErgebnisseDie SensitivitÃ¤t des DCS bei Gicht in der gesamten Kohorte lag bei 72,5â€¯%, bei groÃŸen Gelenken bei 66,0â€¯%, bei mittleren betrug sie 78,8â€¯% und bei kleinen 72,3â€¯%. Die beste SensitivitÃ¤t war bei Handgelenken mit 83,3â€¯% bei einer SpezifitÃ¤t von 81,8â€¯% zu verzeichnen. Die niedrigste SensitivitÃ¤t fanden die Autoren bei Ellbogenmanifestation (42,9â€¯%). Bei allen Gelenken auÃŸer dem MetatarsophalangealgelenkÂ 1 (MTP-1) war die Inzidenz eines DCS bei SerumharnsÃ¤urewerten >7,5â€¯mg/dl signifikant erhÃ¶ht (pâ€¯<â€‰0,001). PDUS-Signale wurden unabhÃ¤ngig von der Diagnose am hÃ¤ufigsten bei mittleren und kleinen, dagegen kaum bei groÃŸen Gelenken gefunden.SchlussfolgerungenIn der vorliegenden Studie war die Genauigkeit der Vorhersage einer Gichtarthritis durch das DCS sowie das Auftreten von PDUS-HypervaskularitÃ¤t je nach Gelenk unterschiedlich. Die besten Ergebnisse wurden in mittelgroÃŸen Gelenken, insbesondere Handgelenken, erzielt.",2018,Zeitschrift fÃ¼r Rheumatologie
Econometric Game 2013: Forecasting Spanish GDP in a Rich Data Environment,"Recently, there is some evidence that the effectiveness of fiscal policies is not independent of the economic situations. Hence, being able to provide real GDP growth forecasts using all the available information is crucially important for economic authorities. In this paper, using a dataset of 70 different variables for the period 1970-2012 at quarterly frequency, we employ dynamic factors models and LASSO regression techniques to provide different forecasts for the Spanish quarterly GDP growth in 2013. We conclude that these techniques have a better predictive ability than a simple AR(4) model. Nonetheless, we find superiority of combined forecasts over single-model based predictions. With our preferred model, we forecast Spanish 2013 yearly GDP growth to be 0.08%.",2013,
Oracle inequalities for the Lasso in the high-dimensional multiplicative Aalen intensity model,"We consider the problem of obtaining a prognostic on the survival time adjusted on covariates in a high-dimensional setting. Towards this end, we construct an estimator of the conditional intensity function that does not rely on an underlying model. We estimate it by the best Cox proportional hazards model given two dictionaries of functions. The first dictionary is used to construct an approximation of the logarithm of the baseline hazard function and the second to approximate the relative risk. As we are in high-dimension, we consider the Lasso procedure to estimate the unknown parameters of the best Cox model approximating the conditional hazard rate function. We provide non-asymptotic oracle inequalities for the Lasso estimator of the conditional hazard risk function. Our results rely on an empirical Bernstein's inequality for martingales with jumps.",2012,arXiv: Statistics Theory
Regularized Skew-Normal Regression,This paper considers the impact of using the regularisation techniques for the analysis of the extended skew-normal distribution. The approach is estimated using a number of techniques and compared to OLS based LASSO and ridge regressions in addition to non- constrained skew-normal regression.,2013,
"Top predators in relation to bathymetry, ice and krill during austral winter in Marguerite Bay, Antarctica","Abstract A key hypothesis guiding the US Southern Ocean Global Ocean Ecosystems Dynamics (US SO GLOBEC) program is that deep across-shelf troughs facilitate the transport of warm and nutrient-rich waters onto the continental shelf of the Western Antarctic Peninsula, resulting in enhanced winter production and prey availability to top predators. We tested aspects of this hypothesis during austral winter by assessing the distribution of the resident pack-ice top predators in relation to these deep across-shelf troughs and by investigating associations between top predators and their prey. Surveys were conducted Julyâ€“August 2001 and Augustâ€“September 2002 in Marguerite Bay, Antarctica, with a focus on the main across-shelf trough in the bay, Marguerite Trough. The common pack-ice seabird species were snow petrel (Pagodroma nivea, 1.2Â individualsÂ kmâˆ’2), Antarctic petrel (Thalassoica antarctica, 0.3Â individualsÂ kmâˆ’2), and Adelie penguin (Pygoscelis adeliae, 0.5Â individualsÂ kmâˆ’2). The most common pack-ice pinniped was crabeater seal (Lobodon carcinophagus). During both winters, snow and Antarctic petrels were associated with low sea-ice concentrations independent of Marguerite Trough, while Adelie penguins occurred in association with this trough. Krill concentrations, both shallow and deep, also were associated with Adelie penguin and snow petrel distributions. During both winters, crabeater seal occurrence was associated with deep krill concentrations and with regions of lower chlorophyll concentration. The area of lower chlorophyll concentrations occurred in an area with complex bathymetry close to land and heavy ice concentrations. Complex or unusual bathymetry via its influence on physical and biological processes appears to be one of the keys to understanding how top predators survive during the winter in this Antarctic region.",2008,Deep-sea Research Part Ii-topical Studies in Oceanography
"Bargaining in Bobo-Dioulasso clothing stores : structure, rules and discourse strategies","RESEARCH PAPER: Bargaining in Bobo-Dioulasso Clothing Stores: Structure, Rules, and Discourse Strategies STUDENT: Ritassida Mamadou Djiguimde DEGREE: Master of Arts COLLEGE: Sciences and Humanities DATE: May 2014 PAGES: 72 This study examines bargaining exchanges in the clothing stores of Bobo-Dioulasso, Burkina Faso, West Africa. Bargaining, an alternative pricing strategy to fixed prices and a process in which vendor and customer dispute the price of goods to eventually come to an agreement, is highly characteristic of Bobo-Dioulassoâ€™s commercial transactions. For purposes of a detailed description and a thorough analysis, 30 bargaining exchanges, involving male and female adult interactants from the Bobo-Dioulasso speech community, are audio recorded and transcribed. Utilizing Hasanâ€™s (1989) Generic Structure Potential (GSP), Ventolaâ€™s (1987) Flowchart Theory, and Orrâ€™s (2007) set of illocutionary forces predictably produced and interpreted during price negotiation, the study unveils the stages of bargaining and proposes a formula that accounts for the dynamic nature of the exchanges. As components of the global structure of bargaining, the study identifies four functionally different elements â€“ establishing communion, item selection, price negotiation, and leave taking â€“ that are performed one at a time in a linear sequencing order. The analysis of its local structure allows the identification of price talk, product talk, person talk, and time/weather talk as the topics elaborated upon. Though the quantification of the types of talk reveals that price negotiation is dominated by price talk, it also demonstrates that the production and interpretation of all kinds of talk align with the basic features of negotiation which are soliciting, making, and evaluating an offer. This finding not only shows the formulaic and rule-governed nature of the exchanges, but also demonstrates the degree to which linguistic elements work conjointly with socio-cultural elements in the production and interpretation of discourse. The analysis of the identified set of illocutionary forces reveals that the double-intent negative evaluation/offer solicitation move dominates price negotiation, has the most dynamic nature, and incorporates the most discourse strategies. The description of the bargaining greeting, leave-taking, person talk, time/weather talk, and solidarity and power terms of address illustrates the importance of interpersonal relationships in bargaining in the Bobo-Dioulasso context. The study of bargaining, as a cultural artifact, is a potent method to track social changes within the Bobo-Dioulasso community. As a spoken genre, its description and analysis permit language learners to better decipher the meaning of texts in this genre and to foster their integration in discourse communities where this genre is prevalent.",2014,
Comment Prediction in Facebook Pages using Regression Techniques,"Data in Social Networks is increasing day by day. It requires highly managing service to handle the large amount of data towards it. This work is about to study the user activity patterns in Social Networks. So, concentrated on active social Networks which is â€œFacebookâ€ especially in Facebook Page. Here, user comment volume prediction is made based on page category i.e., for a particular category of pageâ€™s post will get certain amount of comments. In order to predict the comment volume for each page and to find which page category getting the highest comment. In preliminary work, it has been concluded with decision tree. So, In Further Study, have analyzed with some more Regression Techniques to make the prediction Effective. In this work, modelled the user comment pattern with respect to Page Likes and Popularity, Page Category and Time. Here Decision Tree, LASSO, K-Nearest Neighbor (KNN), Random Forest, and Leaner Regression Techniques are used. The error is found by Root Mean Square Error (RMSE) Metrics. Then, concluded that K-Nearest Neighbor Algorithm performing well and giving the effective prediction.",2018,
Generalizing matrix factorization through flexible regression priors,"Predicting user ""ratings"" on items is a crucial task in recommender systems. Matrix factorization methods that computes a low-rank approximation of the incomplete user-item rating matrix provide state-of-the-art performance, especially for users and items with several past ratings (warm starts). However, it is a challenge to generalize such methods to users and items with few or no past ratings (cold starts). Prior work [4][32] have generalized matrix factorization to include both user and item features for performing better regularization of factors as well as provide a model for smooth transition from cold starts to warm starts. However, the features were incorporated via linear regression on factor estimates. In this paper, we generalize this process to allow for arbitrary regression models like decision trees, boosting, LASSO, etc. The key advantage of our approach is the ease of computing --- any new regression procedure can be incorporated by ""plugging"" in a standard regression routine into a few intermediate steps of our model fitting procedure. With this flexibility, one can leverage a large body of work on regression modeling, variable selection, and model interpretation. We demonstrate the usefulness of this generalization using the MovieLens and Yahoo! Buzz datasets.",2011,
Radiomics study for predicting the expression of PD-L1 in non-small cell lung cancer based on CT images and clinicopathologic features.,"PURPOSE
To predict programmed death-ligand 1 (PD-L1) expression of tumor cells in non-small cell lung cancer (NSCLC) patients by using a radiomics study based on CT images and clinicopathologic features.


MATERIALS AND METHODS
A total of 390 confirmed NSCLC patients who performed chest CT scan and immunohistochemistry (IHC) examination of PD-L1 of lung tumors with clinic data were collected in this retrospective study, which were divided into two cohorts namely, training (nâ€Š=â€Š260) and validation (nâ€Š=â€Š130) cohort. Clinicopathologic features were compared between two cohorts. Lung tumors were segmented by using ITK-snap kit on CT images. Total 200 radiomic features in the segmented images were calculated using in-house texture analysis software, then filtered and minimized by least absolute shrinkage and selection operator (LASSO) regression to select optimal radiomic features based on its relevance of PD-L1 expression status in IHC results and develop radiomics signature. Radiomics signature and clinicopathologic risk factors were incorporated to develop prediction model by using multivariable logistic regression analysis. The receiver operating characteristic (ROC) curves were generated and the areas under the curves (AUC) were reckoned to predict PD-L1 expression in both training and validation cohorts.


RESULTS
In 200 extracted radiomic features, 9 were selected to develop radiomics signature. In univariate analysis, PD-L1 expression of lung tumors was significantly correlated with radiomics signature, histologic type, and histologic grade (pâ€Š< â€Š0.05, respectively). However, PD-L1 expression was not correlated with gender, age, tumor location, CEA level, TNM stage, and smoking (pâ€Š> â€Š0.05). For prediction of PD-L1 expression, the prediction model that combines radiomics signature and clinicopathologic features resulted in AUCs of 0.829 and 0.848 in the training and validation cohort, respectively.


CONCLUSION
The prediction model that incorporates the radiomics signature and clinical risk factors has potential to facilitate the individualized prediction of PD-L1 expression in NSCLC patients and identify patients who can benefit from anti-PD-L1 immunotherapy.",2020,Journal of X-ray science and technology
Araucariaceae as indicators of climate and paleolatitudes,"Mesozoic Araucariaceae dominated in the low-latitude (15â€“20Â°N) belt of summer-dry climate. It is suggested, that araucarian forests were the most thermophilous Mesozoic assemblages. There were no equivalents of the modern tropical rain forest. In the middle latitudes, Araucariaceae shared dominance with Elatides and Classopollis-producing plants. The northernmost Triassic records of Arauariaceae on both eastern and western Pacific coasts are at 35Â°N; in the Jurassic and Cretaceous time they are constantly at about 50Â°N. These climatically controlled chrological features are oblique to the paleolatitudes inferred from paleomagnetic data. 
 
On the basis of material from the Jurassic of Mali, a new species of Araucaria is described, viz. Araucaria africana sp. nov.",1978,Review of Palaeobotany and Palynology
[Left atrium linear lesion encircling pulmonary veins guided by EnSite-NavX and double-Lasso technique for paroxysmal atrial fibrillation].,"OBJECTIVE
To evaluate the efficacy of left atrium linear lesion encircling pulmonary veins (PV) guided by EnSite-NavX and double-Lasso technique for paroxysmal atrial fibrillation (PAF).


METHODS
Twenty-two patients (male 19, mean age of 48.5 years +/- 11.4 years) with symptomatic PAF were enrolled. After a geometry of the left atrium was reconstructed by EnSite-NavX system, PV ostia were marked on the map based on venography. Two Lasso catheters were placed within the ipsilateral superior and inferior PVs. Irrigated radiofrequency energy was applied at 0.5-1.0 cm of distance from the PV ostia. Continuous linear lesion was done to obtain the disappearance of pulmonary vein potentials. Patients were on propafenone and perindopril for three months after the procedure.


RESULTS
The endpoint for ablation was reached in 21 Patients and 1 patient was not successful because of cardiac tamponade. The mean procedure time was 6.6 h +/- 1.3 h and the mean X-ray exposure time was 56.1 min +/- 18.0 min. After a mean 5.3 months +/- 2.7 months of follow-up, 10 patients were free of symptoms. Two patients had no PAF recurrence after the second procedure. Three patients had clinical recurrence of PAF in the first month. The total success rate in this study was 81% (17/21). Mortality was 0% and the overall complication rate was about 9% (2/22).


CONCLUSION
Left atrium circumferential linear ablation surrounding PV ostia guided by EnSite-NavX and double-Lasso technique is effective in PAF, but some patients will need more than one procedure in order to achieve a success.",2005,Zhonghua xin xue guan bing za zhi
Relevance to Antioxidative Function,"Objectiveâ€”Recent proteomic studies have identified multiple proteins that coisolate with human HDL. We hypothesized that distinct clusters of protein components may distinguish between physicochemically-defined subpopulations of HDL particles, and that such clusters may exert specific biological function(s). Methods and Resultsâ€”We investigated the distribution of proteins across 5 physicochemically-defined particle subpopulations of normolipidemic human HDL (HDL2b, 2a, 3a, 3b, 3c) fractionated by isopycnic density gradient ultracentrifugation. Liquid chromatography/electrospray mass spectrometry identified a total of 28 distinct HDLassociated proteins. Using an abundance pattern analysis of peptide counts across the HDL subfractions, these proteins could be grouped into 5 distinct classes. A more in-depth correlational network analysis suggested the existence of distinct protein clusters, particularly in the dense HDL3 particles. Levels of specific HDL proteins, primarily apoL-I, PON1, and PON3, correlated with the potent capacity of HDL3 to protect LDL from oxidation. Conclusionsâ€”These findings suggest that HDL is composed of distinct particles containing unique (apolipo)protein complements. Such subspeciation forms a potential basis for understanding the numerous observed functions of HDL. Further work using additional separation techniques will be required to define these species in more detail. (Arterioscler Thromb Vasc Biol. 2009;29:870-876.)",2009,
Habitat complexity modifies the impact of piscivores on a coral reef fish population,"Abstract Patterns in juvenile mortality rates can have a profound affect on the distribution and abundance of adult individuals, and may be the result of a number of interacting factors. Field observations at Lizard Island (Great Barrier Reef, Australia) showed that for a coral reef damselfish, Pomacentrus moluccensis, juvenile mortality (over 1 year) varied between 20 and almost 100% among sites. Correlative data showed that juvenile mortality increased as a function of initial densities (recruitment), predator densities and the availability of preferred coral substrata. A multiple regression showed that these three variables together did not explain significantly more variation in mortality than the single factor showing the strongest relationship. This appeared to be because recruitment, predator densities and preferred coral substrata were all highly correlated, suggesting that one, two or all of these factors may be influencing juvenile mortality rates. One hypothesis was that density-dependent mortality in juveniles was the result of an interaction between predators (which appear to aggregate at high-recruitment sites) and the availability of preferred substrata (predator refuges). We tested this hypothesis by using both laboratory and field experiments to see whether fish predation could significantly alter survivorship of this damselfish, and whether this impact was dependent upon the coral substratum. The laboratory experiment was designed to test the effects of three common predators (Pseudochromis fuscus, Cephalopholis boenak and Thalassoma lunare) and three different coral substrata that varied in their complexity (Pocillopora damicornis, Acropora nasuta and A. nobilis) on the survival of juvenile Pomacentrus moluccensis. There was a significant interaction between predator species and microhabitat in determining survival. Pseudochromis fuscus and C. boenak were both significantly better at capturing juvenile damselfish than T. lunare. Juvenile survivorship was significantly better when they were given the more complex corals, Pocillopora damicornis and A. nasuta, compared with those given the open-structured species A. nobilis. This pattern reflects habitat selection in the field. Predators differed in their strike rates and the proportion of strikes that were successful, but all exhibited greater success at prey capture where A. nobilis was provided as shelter. The interaction between the effect of predator species and microhabitat structure on damselfish survival was tested in the field for a cohort of juvenile Pomacentrus moluccensis. We examined juvenile survival in the presence and absence of two predators that co-occur on natural patch reefs (C. boenak and Pseudochromis fuscus). The experimental patch reefs we used for this purpose were constructed from both high complexity (Pocillopora damicornis) and low complexity (A. nobilis) coral substrata. Both juveniles and predators were translocated to reefs at natural densities. The effects of predation were clearly dependent upon the microhabitat. Reefs of the high-complexity coral with predators supported the same high numbers of Pomacentrus moluccensis as the reefs with no resident predators. However, damselfish abundance was significantly lower on low-complexity reefs with resident predators, relative to the other treatments. Background rates of loss were high, even on preferred coral in the absence of the manipulated predator, suggesting that transient predators may be even more important than the residents. We suggest that adult abundances in this species were strongly influenced by the densities of different predators and the availability of preferred refuges.",1998,Oecologia
A Practical Scheme and Fast Algorithm to Tune the Lasso With Optimality Guarantees,"We introduce a novel scheme for choosing the regularization parameter in high-dimensional linear regression with Lasso. This scheme, inspired by Lepski's method for bandwidth selection in non-parametric regression, is equipped with both optimal finite-sample guarantees and a fast algorithm. In particular, for any design matrix such that the Lasso has low sup-norm error under an ""oracle choice"" of the regularization parameter, we show that our method matches the oracle performance up to a small constant factor, and show that it can be implemented by performing simple tests along a single Lasso path. By applying the Lasso to simulated and real data, we find that our novel scheme can be faster and more accurate than standard schemes such as Cross-Validation.",2016,J. Mach. Learn. Res.
Minimum dietary diversity among women of reproductive age in urban Burkina Faso.,"Micronutrient malnutrition is a challenge for women of reproductive age, who are particularly vulnerable due to greater micronutrient needs. The minimum dietary diversity for women (MDD-W) indicator is a micronutrient adequacy's proxy for those women, but little is known about its relation to other dimensions. We assessed MDD-W and its association with other socioeconomic, food security and purchasing practices in urban Burkina Faso. We conducted multi-stage cluster sampling in two main cities of Burkina Faso, stratified by type of district, and interviewed 12 754 women in the 2009-2011 period. We obtained food consumption data through unquantified 24 hour recalls and computed MDD-W as consuming at least five out of ten predefined food groups. We constructed multivariable regression models with sociodemographic and food security covariates. MDD-W in urban Burkina Faso was 31%, higher in Ouagadougou (33%) than in Bobo-Dioulasso (29%), and lower in unstructured districts. The most frequently consumed food groups were 'all starchy', 'vitamin A rich dark green leafy vegetables' and 'other vegetables'. Household's expenses were associated with higher likelihood of MDD-W, while the association with household food security indicators varied by year and type of district. Purchasing foods in markets and choosing the place of purchase based on large choice rather than proximity showed a positive association with the MDD-W. Only one in three women in urban Burkina Faso reached the minimum dietary diversity, and although socioeconomic and food security variables had the greatest effect on MDD-W, purchasing practices, like going to the market, also showed a positive effect.",2019,Maternal & child nutrition
Effects of Pranlukast on Vascular Endothelial Growth Factor Levels in Asthma,"We thank Dr. Medford for an interest regarding our study.1 There has been a clinical interest in the use of leukotriene receptor antagonists (LTRAs) in asthmatic patients who have already been treated with inhaled corticosteroids. However, a further benefit in symptoms and lung function from therapy combining LTRAs and inhaled corticosteroids is contrary to this finding. In this study, we found that pranlukast administration added little efficacy to inhaled corticosteroid therapy for reduction in vascular endothelial growth factor (VEGF) levels in induced sputum from asthmatic patients. However, it is possible that the trends toward reduction in airway VEGF levels after pranlukast administration in steroid-treated asthmatic patients might have reached statistical significance if more patients had been included in our study. The mechanism of the reduction in airway VEGF levels in asthma induced by pranlukast administration is unclear. One report2 has indicated that asthmatic patients exhibited a greater expression of VEGF receptors (flt-1 and flk-1) in the airway mucosa. Moreover, increased VEGF expression in asthmatic patients were identified by infiltrating inflammatory cells in the submucosa in order of abundance as CD34 cells3 eosinophils3macrophages3 T cells3 mast cells. Therefore, one possible explanation is that pranlukast administration decreased airway VEGF levels via the reduction of infiltrating inflammatory cells. We also think that analysis of cellassociated VEGF isoform (VEGF189 and VEGF206) expression is important to understand VEGF bioactivity in asthma. Though the results were not shown in our study, we examined cell-associated VEGF isoform expression by immunohistochemical analysis. On the basis of these results, we found a significant correlation between the expression of free VEGF and that of cell-associated VEGF. In our recent study,3 we determined that the interaction between airway microcirculation and VEGF may be a key element in the pathophysiology of asthma. Therefore, pranlukast administration might decrease airway microvascular permeability through, at least in part, a decrease in airway VEGF levels in asthmatic patients.",2005,
Jurassic Biostratigraphic Sequence in the Middle of Northern Tibet,"Through the study of characteristics of Jurassic biofossils found at Shuanghu, Tanggula Mountain and Baqing Area in the middle of north Tibet and their assemblages, Jurassic biostratigraphic sequence is established firstly. Six types of biofossils discovered include bivalve, brachiopod, stromatoporoids, ammonites, sporopollen and Ostracoda, and 14 fossil assemblages(zones) are established. Among the found fossils, stromatoporoids, sporopollen and Ostracoda are discovered firstly and 5 fossil assemblages(zones) are established, of which they are sporopollen neoraistrickia assemblage, Cyathidites-Osmundacidites-Deltoidospora assemblage and Classopollis-Cycadopites assemblage, Ostracoda Darwinula-Metacypris assemblage and stromatoporoids Cladocoropsis mirabilis zone. Based on analysis of the components and distribution characters of these fossil assemblages, geological chron and their correlations are elucidated.",2004,Journal of Jianghan Petroleum Institute
Distributed Sparse Linear Regression,"The Lasso is a popular technique for joint estimation and continuous variable selection, especially well-suited for sparse and possibly under-determined linear regression problems. This paper develops algorithms to estimate the regression coefficients via Lasso when the training data are distributed across different agents, and their communication to a central processing unit is prohibited for e.g., communication cost or privacy reasons. A motivating application is explored in the context of wireless communications, whereby sensing cognitive radios collaborate to estimate the radio-frequency power spectrum density. Attaining different tradeoffs between complexity and convergence speed, three novel algorithms are obtained after reformulating the Lasso into a separable form, which is iteratively minimized using the alternating-direction method of multipliers so as to gain the desired degree of parallelization. Interestingly, the per agent estimate updates are given by simple soft-thresholding operations, and inter-agent communication overhead remains at affordable level. Without exchanging elements from the different training sets, the local estimates consent to the global Lasso solution, i.e., the fit that would be obtained if the entire data set were centrally available. Numerical experiments with both simulated and real data demonstrate the merits of the proposed distributed schemes, corroborating their convergence and global optimality. The ideas in this paper can be easily extended for the purpose of fitting related models in a distributed fashion, including the adaptive Lasso, elastic net, fused Lasso and nonnegative garrote.",2010,IEEE Transactions on Signal Processing
Mitogenomic Phylogenetic Analysis Supports Continental-Scale Vicariance in Subterranean Thalassoid Crustaceans,"Many continental subterranean water crustaceans (""stygobionts"") display extreme disjunct distributions, where different species in the same genus are isolated on continents or islands separated by broad oceanic expanses. Despite their freshwater habitat, most of these taxa appear to be most closely related to typical marine groups (""thalassoid"" origin). Among the hadzioids-thalassoid amphipods including the stygobiont families Hadziidae, Pseudoniphargidae, and Metacrangonyctidae-several genera are restricted to inland groundwaters ranging from the Caribbean region to the Mediterranean and Middle East, including interspersed oceanic islands. This distribution might have arisen from Tethyan vicariance triggered by the sequential occlusion of the former Tethys Sea, a vast circumtropical ocean existing from the Middle Jurassic up to 20 million years ago (mya). Previous studies have been based on morphological analyses or limited DNA sequence data, making it difficult to test this hypothesis. We used complete mitochondrial protein-coding gene sequences, mainly obtained by next-generation sequencing methods and a nuclear ribosomal gene to resolve the phylogeny and to establish a time frame for diversification of the family Metacrangonyctidae (Amphipoda). The results were consistent with the plate tectonics vicariance hypothesis, with major diversifications occurring between 96 and 83 mya.",2012,Current Biology
(18)F-Fluorodeoxyglucose Positron Emission Tomography Can Quantify and Predict Esophageal Injury During Radiation Therapy.,"PURPOSE
We sought to investigate the ability of mid-treatment (18)F-fluorodeoxyglucose positron emission tomography (PET) studies to objectively and spatially quantify esophageal injury inÂ vivo from radiation therapy for non-small cell lung cancer.


METHODS AND MATERIALS
This retrospective study was approved by the local institutional review board, with written informed consent obtained before enrollment. We normalized (18)F-fluorodeoxyglucose PET uptake to each patient's low-irradiated region (<5Â Gy) of the esophagus, as a radiation response measure. Spatially localized metrics of normalized uptake (normalized standard uptake value [nSUV]) were derived for 79 patients undergoing concurrent chemoradiation therapy for non-small cell lung cancer. We used nSUV metrics to classify esophagitis grade at the time of the PET study, as well as maximum severity by treatment completion, according to National Cancer Institute Common Terminology Criteria for Adverse Events, using multivariate least absolute shrinkage and selection operator (LASSO) logistic regression and repeated 3-fold cross validation (training, validation, and test folds). This 3-fold cross-validation LASSO model procedure was used to predict toxicity progression from 43 asymptomatic patients during the PET study. Dose-volume metrics were also tested in both the multivariate classification and the symptom progression prediction analyses. Classification performance was quantified with the area under the curve (AUC) from receiver operating characteristic analysis on the test set from the 3-fold analyses.


RESULTS
Statistical analysis showed increasing nSUV is related to esophagitis severity. Axial-averaged maximum nSUV for 1 esophageal slice and esophageal length with at least 40% of axial-averaged nSUV both had AUCs of 0.85 for classifying grade 2 or higher esophagitis at the time of the PET study and AUCs of 0.91 and 0.92, respectively, for maximum grade 2 or higher by treatment completion. Symptom progression was predicted with an AUC of 0.75. Dose metrics performed poorly at classifying esophagitis (AUC of 0.52, grade 2 or higher mid treatment) or predicting symptom progression (AUC of 0.67).


CONCLUSIONS
Normalized uptake can objectively, locally, and noninvasively quantify esophagitis during radiation therapy and predict eventual symptoms from asymptomatic patients. Normalized uptake may provide patient-specific dose-response information not discernible from dose.",2016,"International journal of radiation oncology, biology, physics"
Lassoing the Determinants of Retirement,"This article uses Danish register data to explain the retirement decision of workers in 1990 and 1998. Many variables might be conjectured to influence this decision such as demographic, socioeconomic, financial, and health related variables as well as all the same factors for the spouse in case the individual is married. In total, we have access to 399 individual specific variables that all could potentially impact the retirement decision. We use variants of the least absolute shrinkage and selection operator (Lasso) and the adaptive Lasso applied to logistic regression in order to uncover determinants of the retirement decision. To the best of our knowledge, this is the first application of these estimators in microeconometrics to a problem of this type and scale. Furthermore, we investigate whether the factors influencing the retirement decision are stable over time, gender, and marital status. It is found that this is the case for core variables such as age, income, wealth, and general health. We also point out the most important differences between these groups and explain why these might be present.",2013,Econometric Reviews
Quantification of toxic metallic elements using machine learning techniques and spark emission spectroscopy,"Abstract. The United States Environmental Protection Agency (US EPA) list of Hazardous Air Pollutants (HAPs) includes metal elements suspected or associated with development of cancer. Traditional techniques for detecting and quantifying toxic metallic elements in the atmosphere are either not real time, hindering identification of sources, or limited by instrument costs. Spark emission spectroscopy is a promising and cost effective technique that can be used for analyzing toxic metallic elements in real time. Here, we have developed a cost-effective spark emission spectroscopy system to quantify the concentration of toxic metallic elements targeted by US EPA. Specifically, Cr, Cu, Ni, and Pb solutions were diluted and deposited on the ground electrode of the spark emission system. Least Absolute Shrinkage and Selection Operator (LASSO) was optimized and employed to detect useful features from the spark-generated plasma emissions. The optimized model was able to detect atomic emission lines along with other features to build a regression model that predicts the concentration of toxic metallic elements from the observed spectra. The limits of detections (LOD) were estimated using the detected features and compared to the traditional single-feature approach. LASSO is capable of detecting highly sensitive features in the input spectrum; however for some elements the single-feature LOD marginally outperforms LASSO LOD. The combination of low cost instruments with advanced machine learning techniques for data analysis could pave the path forward for data driven solutions to costly measurements.",2019,Atmospheric Measurement Techniques Discussions
Etude architecturale et modÃ¨lisation des structures au temple d''Hathor Ã‹ Dendera,"Une etude architecturale devrait permettre d'apprehender sous l'angle des techniques de construction, du vocabulaire d'architecture et de la composition spatiale la pensee des concepteurs, faconnee par l'histoire de leur civilisation, qui a genere les evolutions technologiques, stylistiques et typologiques. En Egypte pharaonique, l'evolution de l'architecture cultuelle monumentale manifeste une permanente recherche de durabilite qui est fort logique si l'on considere que l'art religieux transpose au niveau de la construction des elements du present et du mythe d'origine dans une structure pour l'eternite 1. D'une architecture des premiers temps de cette culture, conditionnee par son milieu, faite de limon et de vegetaux, on evolua vers une construction de brique et de pierre conservant, dans un registre ornemental, les elements caracteristiques et structurels de la phase primitive. Les mastabas, les forteresses de Nubie et les pyramides du Fayoum et de Dahchour montrent assez tot une grande maitrise de la brique pour l'edification de vastes programmes, et les vestiges de palais royaux du Nouvel Empire attestent que ce materiau n'etait pas incompatible avec la realisation de projets nobles et grandioses. De fait, la pierre appareillee est reservee a l'architecture cultuelle et funeraire, a l'exception d'ouvrages en relation avec l'eau du Nil et ceux que nous classons aujourd'hui dans le genie hydraulique comme le barrage de retenue d'eau construit a l'Ancien Empire au ouadi Gerawi 2. Toutefois si la pierre est destinee aux programmes religieux, la brique de limon fut tres largement employee pour des chapelles urbaines ou des temples plus modestes. Dans ces derniers cas, l'argument economique est certainement l'hypothese la plus appropriee en faveur de ce choix d'un materiau disponible sur place et au travail facile.",1997,
"Rejoinder to Cain: Widows, Sons, and Old-Age Security in Rural Maharashtra: A Comment on Vlassoff",Carol Vlassoff comments on Mead T. Cains critique of her critique of Cains recent article on the importance of sons to their parents for old-age security in South India. The author opens by explaining to the reader that her initial critique of Cain was prompted by what she considered to be their common substantive and geographical interests. Vlassoff did not single him out as an adversary. 1st summarizing her argument Vlassoff returns to her case studies of village widows. She restates that the value of sons to widows can not be measured in purely economic terms in rural Maharashtra and clarifies her view that sons are also desired to provide emotional security and a sense of personal fulfillment. Vlassoff then moves on to respond to those of Cains comments which most misrepresent her views. Her response includes reaffirmation of the integrity and validity of her case studies clarification of her description of widows property rights and inheritance discussion of the income of individuals in a village and consideration of fertility motivations. Minor points of dissension from Cains response are finally addressed.,1991,Population Studies-a Journal of Demography
Constructing large scale surrogate models from big data and artificial intelligence,"Abstract EnergyPlus is the U.S. Department of Energyâ€™s flagship whole-building energy simulation engine and provides extensive simulation capabilities. However, the computational cost of these capabilities has resulted in annual building simulations that typically requires 2â€“3Â min of wall-clock time to complete. While EnergyPlusâ€™s overall speed is improving (EnergyPlus 7.0 is 25â€“40% faster than EnergyPlus 6.0), the overall computational burden still remains and is the top user complaint. In other engineering domains, researchers substitute surrogate or approximate models for the computationally expensive simulations to improve simulation and reduce calibration time. Previous work has successfully demonstrated small-scale EnergyPlus surrogate models that use 10â€“16 input variables to estimate a single output variable. This work leverages feed forward neural networks and Lasso regression to construct robust large-scale EnergyPlus surrogate models based on 3 benchmark datasets that have 7â€“156 inputs. These models were able to predict 15-min values for most of the 80â€“90 simulation outputs deemed most important by domain experts within 5% (whole building energy within 0.07%) and calculate those results within 3Â s, greatly reducing the required simulation runtime for relatively close results. The techniques shown here allow any software to be approximated by machine learning in a way that allows one to quantify the trade-off of accuracy for execution time.",2017,Applied Energy
Enforcing Co-expression in Multimodal Regression Framework,"We consider the problem of multimodal data integration for the study of complex neurological diseases (e.g. schizophrenia). Among the challenges arising in such situation, estimating the link between genetic and neurological variability within a population sample has been a promising direction. A wide variety of statistical models arose from such applications. For example, Lasso regression and its multitask extension are often used to fit a multivariate linear relationship between given phenotype(s) and associated observations. Other approaches, such as canonical correlation analysis (CCA), are widely used to extract relationships between sets of variables from different modalities. In this paper, we propose an exploratory multivariate method combining these two methods. More Specifically, we rely on a 'CCA-type' formulation in order to regularize the classical multimodal Lasso regression problem. The underlying motivation is to extract discriminative variables that display are also co-expressed across modalities. We first evaluate the method on a simulated dataset, and further validate it using Single Nucleotide Polymorphisms (SNP) and functional Magnetic Resonance Imaging (fMRI) data for the study of schizophrenia.",2017,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
Temporal prediction of future state occupation in a multistate model from high-dimensional baseline covariates via pseudo-value regression,"ABSTRACT In many complex diseases such as cancer, a patient undergoes various disease stages before reaching a terminal state (say disease free or death). This fits a multistate model framework where a prognosis may be equivalent to predicting the state occupation at a future time t. With the advent of high-throughput genomic and proteomic assays, a clinician may intent to use such high-dimensional covariates in making better prediction of state occupation. In this article, we offer a practical solution to this problem by combining a useful technique, called pseudo-value (PV) regression, with a latent factor or a penalized regression method such as the partial least squares (PLS) or the least absolute shrinkage and selection operator (LASSO), or their variants. We explore the predictive performances of these combinations in various high-dimensional settings via extensive simulation studies. Overall, this strategy works fairly well provided the models are tuned properly. Overall, the PLS turns out to be slightly better than LASSO in most settings investigated by us, for the purpose of temporal prediction of future state occupation. We illustrate the utility of these PV-based high-dimensional regression methods using a lung cancer data set where we use the patientsâ€™ baseline gene expression values.",2017,Journal of Statistical Computation and Simulation
"Investigation of prediction accuracy and the impact of sample size, ancestry, and tissue in transcriptome-wide association studies.","In transcriptome-wide association studies (TWAS), gene expression values are predicted using genotype data and tested for association with a phenotype. The power of this approach to detect associations relies, at least in part, on the accuracy of the prediction. Here we compare the prediction accuracy of six different methods-LASSO, Ridge regression, Elastic net, Best Linear Unbiased Predictor, Bayesian Sparse Linear Mixed Model, and Random Forests-by performing cross-validation using data from the Geuvadis Project. We also examine prediction accuracy (a) at different sample sizes, (b) when ancestry of the prediction model training and testing populations is different, and (c) when the tissue used to train the model is different from the tissue to be predicted. We find that, for most genes, the expression cannot be accurately predicted, but in general sparse statistical models tend to outperform polygenic models at prediction. Average prediction accuracy is reduced when the model training set size is reduced or when predicting across ancestries and is marginally reduced when predicting across tissues. We conclude that using sparse statistical models and the development of large reference panels across multiple ethnicities and tissues will lead to better prediction of gene expression, and thus may improve TWAS power.",2020,Genetic epidemiology
Study on degradation characteristics and bacterial community structure changes of immobilized cells in straw-alginate beads in marine environment,"Abstract Immobilized bioremediation technology is widely used in treating oil-contaminated seas, but changes of bacterial community during treatment were rarely known. In this study, two diesel-degrading strains were embedded in straw-alginate beads to form immobilized cells. Diesel degradation properties and morphological characteristics of the immobilized cells were obtained by gas chromatographyâ€“mass spectrometry (GCâ€“MS) and scanning electron microscope (SEM). Bacterial community structure was observed by high-throughput sequencing. The results indicated that C11~C17 was more degraded by immobilized cells, and straw-alginate beads had appropriate pore structure. Higher bacterial diversity was observed in the bioremediated seawater. Pseudoalteromonas (26.41%), became the most dominant species after oil spills, and Thalassospira was enriched to 25.89% after bioremediation. Concentration of oil degradation related genes was predicted to be higher in the bioremediated seawater. Hence, immobilized cells in straw-alginate beads were suitable for degradation diesel. This study was expected to improve the actual repair effect of oil spills.",2020,Bioresource Technology Reports
Meine dritte Tirol-Fahrt,"Am 4. August gab es denn zun~chst Krieg. Ich beschwerto reich und wollto ein anderes Zimmor; die Wirthin vortriistete mich. Ich wanderte aber aus und zwar wollte ich ontweder nach Suldeu odor Franzenshiihe odor Sa. Maria iibersiedeln, nut fort aus diesem, so unnachahmlich geleiteten Hauso. Zuerst probirto ich es aber noch in Trafoi selbst, denn ich erinnerto reich an der ,Sch~inen Aussicht"" voriiber gewandort zu sein. So stieg ich denn die fiinfzig Meter tiefer, zu diesom Gasthause, das wenigstens don Vorzug hat, oinen wirklich prlichtigen Ausblick auf don Madatsch-Glotschor und die Trafoier Eiswand zu gewiihren. Und sieho da, in der ,,SchSnen Aussicht"" t raf ich es auch ganz gut und dot Besitzer, sowie seine Leute waron sofort bestrebt, Rath zu schaffen. Da ich hie Schlafkameraden mag, musste ich reich zwar mit einem winzigen Ki~mmorchon bognfigen, zum Pflanzentrocknen bekam ich aber ein teerstehendes Bauernhaus mit gewaltigem, gemauerten 0fen. Das war moin Fall. Ich richtote reich sofort hiiuslich oin und betrieb die Geschichte nun im Grossen, d. h. mit kfinstlicher Trocknung des Papiors und der Pfianzen. Zwischen der ,,SchSnen Aussicht"" und dem Bauernhauso fand ich dabei in Gesellschaft yon Hieracium tr i dentatum F t . das ochre H. lanceolatum Vill. Herr h r t z t besuchto reich und zeigte sich sehr erfreut, dass ich es so gut getroffen hatte. Boi diesen giinstigen Aspecten bummelto ich Nachmittags, nach beendetem Pflanzeneinlegen rasch noch zu den ,,Heiligen drei Brunnon""; denn die dortsoitigo Thalwand ist Kalk, die hierseitige allerhand Schiofergestein. Ich kann abet mi~nniglich nur rathen, den Spaziergang bleiben zu lasson. Botanisch interessirte mich nur E u phrasia variabilis Freyn, die hier fast so fief herab geht, wie im",2005,Ã–sterreichische botanische Zeitschrift
Robust Bayesian inference under model misspecification,"Bayesian inference is considered one of the best statistical methods available when the model is correctly specified. On the other hand, when this is not the case, and model assumptions do not hold, it can lead to suboptimal results. Equipping the likelihood with a learning rate parameter protects against this. In this thesis the performances of various more robust Bayesian approaches, that differ in the way the learning rate parameter is chosen, are compared to standard Bayes in a variety of situations. Results for various classification problems (with simulated data) and Lasso-type regression problems (with real-world data) indicate that the robust forms of Bayes outperform standard Bayes when the model is incorrect, and donâ€™t perform much worse when the model is correct. Especially the robust Bayesian method with learning rate parameter estimated by k-fold cross-validation achieves good results.",2013,
Structured association analysis leads to insight into Saccharomyces cerevisiae gene regulation by finding multiple contributing eQTL hotspots associated with functional gene modules,"BackgroundAssociation analysis using genome-wide expression quantitative trait locus (eQTL) data investigates the effect that genetic variation has on cellular pathways and leads to the discovery of candidate regulators. Traditional analysis of eQTL data via pairwise statistical significance tests or linear regression does not leverage the availability of the structural information of the transcriptome, such as presence of gene networks that reveal correlation and potentially regulatory relationships among the study genes. We employ a new eQTL mapping algorithm, GFlasso, which we have previously developed for sparse structured regression, to reanalyze a genome-wide yeast dataset. GFlasso fully takes into account the dependencies among expression traits to suppress false positives and to enhance the signal/noise ratio. Thus, GFlasso leverages the gene-interaction network to discover the pleiotropic effects of genetic loci that perturb the expression level of multiple (rather than individual) genes, which enables us to gain more power in detecting previously neglected signals that are marginally weak but pleiotropically significant.ResultsWhile eQTL hotspots in yeast have been reported previously as genomic regions controlling multiple genes, our analysis reveals additional novel eQTL hotspots and, more interestingly, uncovers groups of multiple contributing eQTL hotspots that affect the expression level of functional gene modules. To our knowledge, our study is the first to report this type of gene regulation stemming from multiple eQTL hotspots. Additionally, we report the results from in-depth bioinformatics analysis for three groups of these eQTL hotspots: ribosome biogenesis, telomere silencing, and retrotransposon biology. We suggest candidate regulators for the functional gene modules that map to each group of hotspots. Not only do we find that many of these candidate regulators contain mutations in the promoter and coding regions of the genes, in the case of the Ribi group, we provide experimental evidence suggesting that the identified candidates do regulate the target genes predicted by GFlasso.ConclusionsThus, this structured association analysis of a yeast eQTL dataset via GFlasso, coupled with extensive bioinformatics analysis, discovers a novel regulation pattern between multiple eQTL hotspots and functional gene modules. Furthermore, this analysis demonstrates the potential of GFlasso as a powerful computational tool for eQTL studies that exploit the rich structural information among expression traits due to correlation, regulation, or other forms of biological dependencies.",2012,BMC Genomics
Coincidence Theorems for Noncompact â„œâ„­-maps in Abstract Convex Spaces with Applications,"Abstract. In this paper, a coincidence theorem for a compact RC-mapis proved in an abstract convex space. Several more general coincidencetheorems for noncompact RC-maps are derived in abstract convex spaces.Some examples are given to illustrate our coincidence theorems. As ap-plications, an alternative theorem concerning the existence of maximalelements, an alternative theorem concerning equilibrium problems anda minimax inequality for three functions are proved in abstract convexspaces. 1. IntroductionMany problems in nonlinear analysis can be solved by showing the intersec-tion of certain family of subsets of an underlying set is nonempty. The ï¬rstremarkable result on the nonempty intersection was the celebrated Knaster-Kuratowski-Mazurkiewicz theorem (simply, the KKM principle) in 1929 [11],which concerns with certain types of maps called KKM maps later.At the beginning, the KKM theory was mainly devoted to the study ofconvex subsets of topological vector spaces. Later it has been extended toconvex spaces by Lassonde [12], to C-spaces (or H-spaces) by Horvath [8, 9],and to generalized convex (G-convex) spaces by Park and Kim [24] and Park[21, 22, 23]. Recently, Park [16] introduced a new concept of abstract convexspaces which include convex subsets of topological vector spaces, convex spaces,C-spacesand G-convexspacesasspecialcases. Park[16] alsointroducedcertainbroad classes ROand RCof maps (having the KKM property), which includesthe well-known classKKM(X,Y) introduced by Chang and Yen [5] as a specialcase. With these new concepts, some coincidence theorems and ï¬xed point",2012,Bulletin of The Korean Mathematical Society
Multiblock ADMM in Machine Learning,"In this article we consider using modern fast alternation direction optimization methods for cancer diagnostics. During last years the number of people that suffer from cancer significantly increased. The aim of this work was to make research and to determine the most important factors that influence durability of life after surgery and to predict this durability. We collect data from a group of people with melanoma, define 36 characteristics that can influence durability of life and with help of LASSO problem and multiblock ADMM with Nesterov acceleration we determine the most important characteristics, f in d life expectancy and calculate the difference between real life durability and predicted values. Multiblock ADMM with Nesterov acceleration is an optimization method, based on combination of two approaches â€“ splitting of original optimiza problem into N subproblems and finding Nesterov acceleration step on each iteration.",2019,2019 IEEE International Conference on Advanced Trends in Information Theory (ATIT)
Network exploration via the adaptive LASSO and SCAD penalties,"Graphical models are frequently used to explore networks, such as genetic networks, among a set of variables. This is usually carried out via exploring the sparsity of the precision matrix of the variables under consideration. Penalized likelihood methods are often used in such explorations. Yet, positive-definiteness constraints of precision matrices make the optimization problem challenging. We introduce nonconcave penalties and the adaptive LASSO penalty to attenuate the bias problem in the network estimation. Through the local linear approximation to the nonconcave penalty functions, the problem of precision matrix estimation is recast as a sequence of penalized likelihood problems with a weighted L 1 penalty and solved using the efficient algorithm of Friedman et al. [Biostatistics 9 (2008) 432â€•441]. Our estimation schemes are applied to two real datasets. Simulation experiments and asymptotic theory are used to justify our proposed methods.",2009,The Annals of Applied Statistics
Thalassogenus shamimi n. sp. (Nematoda: Thalassogeneridae) a nematode predator from India.,"Thalassogenus shamimi n. sp. is described and illustrated. Tt has 1.5-2.3 mm long body, a = 22-32; b = 3.9-5.4; c = 19-31; V = 56-67, buccal cavity 39-58 !-lm long and 18-27 !J.ffi wide and is ciosely related ta the rwo previously described species. However, it differs from T paradoxus Andrassy, 1973 in having slit-like amphidial aperture, smaller buccal cavity, presence of four cardiac glands and a Jonger tail. It differs from T archaeops Orton Williams & Jairajpuri, 1984 in the shape of lip region and longer tail. Observations made on the gut contents suggest that it possesses a high predatory potential.",1992,Fundamental and applied nematology
"Intrinsic hand muscle function, part 2: kinematic comparison of 2 reconstructive procedures.","PURPOSE
Reconstruction of grasp is a high priority for tetraplegic patients. Restoration of finger flexion by surgical activation of flexor digitorum profundus can result in roll-up finger flexion, interphalangeal (IP) joint before metacarpophalangeal (MCP) joint flexion, which can be improved by restoring intrinsic function. This study compares grasp kinematics between 2 intrinsic balancing procedures-Zancolli-lasso and House.


METHODS
The intrinsic muscles of 12 cadaver hands were reconstructed by either the Zancolli-lasso or the House procedure (nÂ = 6 each) and tested by deforming the flexor digitorum profundus (FDP) with a motor to simulate hand closure. Results were compared with 5 control hands. All 17 hands were studied by video analysis. Kinematics were characterized by the order of MCP joint and IP joint flexion. Optimal grasp was defined as the maximal fingertip-to-palm distance during the arc of finger closure.


RESULTS
Kinematics differed between the 2 procedures. The Zancolli-lasso reconstructed hands flexed first in the IP joints, and then in MCP joints, resembling an unreconstructed intrinsic-minus hand whereas the House reconstructed hands flexed first in the MCP joints and then in the IP joints, resembling an intrinsic-activated hand. Maximal fingertip-to-palm distance did not differ significantly between the 2 procedures, and both showed improvement over unreconstructed controls.


CONCLUSIONS
Both intrinsic balancing techniques improved grasp. Only the House procedure restored hand kinematics approximating those of an intrinsic-activated hand. Improvement in fingertip-to-palm distance in Zancolli-lasso hands resulted primarily from the initial resting MCP joint flexion of 40Â°. We therefore advocate the more physiological House procedure for restoration of intrinsic function in tetraplegic patients.


CLINICAL RELEVANCE
This study provides a rationale for advocacy of 1 reconstructive procedure over another.",2013,The Journal of hand surgery
Circulating MicroRNAs as Non-Invasive Biomarkers for Early Detection of Non-Small-Cell Lung Cancer,"BACKGROUND
Detection of lung cancer at an early stage by sensitive screening tests could be an important strategy to improving prognosis. Our objective was to identify a panel of circulating microRNAs in plasma that will contribute to early detection of lung cancer.


MATERIAL AND METHODS
Plasma samples from 100 early stage (I to IIIA) non-small-cell lung cancer (NSCLC) patients and 100 non-cancer controls were screened for 754 circulating microRNAs via qRT-PCR, using TaqMan MicroRNA Arrays. Logistic regression with a lasso penalty was used to select a panel of microRNAs that discriminate between cases and controls. Internal validation of model discrimination was conducted by calculating the bootstrap optimism-corrected AUC for the selected model.


RESULTS
We identified a panel of 24 microRNAs with optimum classification performance. The combination of these 24 microRNAs alone could discriminate lung cancer cases from non-cancer controls with an AUC of 0.92 (95% CI: 0.87-0.95). This classification improved to an AUC of 0.94 (95% CI: 0.90-0.97) following addition of sex, age and smoking status to the model. Internal validation of the model suggests that the discriminatory power of the panel will be high when applied to independent samples with a corrected AUC of 0.78 for the 24-miRNA panel alone.


CONCLUSION
Our 24-microRNA predictor improves lung cancer prediction beyond that of known risk factors.",2015,PLoS ONE
Decentralized support detection of multiple measurement vectors with joint sparsity,"This paper considers the problem of finding sparse solutions from multiple measurement vectors (MMVs) with joint sparsity. The solutions share the same sparsity structure, and the locations of the common nonzero support contain important information of signal features. When the measurement vectors are collected from spatially distributed users, the issue of decentralized support detection arises. This paper develops a decentralized row-based Lasso (DR-Lasso) algorithm for the distributedMMVproblem. A penalty term on row-based total energy is introduced to enforce joint sparsity for the MMVs, and consensus constraints are formulated such that users can consent on the total energy, and hence the common nonzero support, in a decentralized manner. As an illustrative example, the problem of cooperative spectrum occupancy detection is solved in the context of wideband cognitive radio networks.",2011,"2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
"Combining Optical, Fluorescence, Thermal Satellite, and Environmental Data to Predict County-Level Maize Yield in China Using Machine Learning Approaches","Maize is an extremely important grain crop, and the demand has increased sharply throughout the world. China contributes nearly one-fifth of the total production alone with its decreasing arable land. Timely and accurate prediction of maize yield in China is critical for ensuring global food security. Previous studies primarily used either visible or near-infrared (NIR) based vegetation indices (VIs), or climate data, or both to predict crop yield. However, other satellite data from different spectral bands have been underutilized, which contain unique information on crop growth and yield. In addition, although a joint application of multi-source data significantly improves crop yield prediction, the combinations of input variables that could achieve the best results have not been well investigated. Here we integrated optical, fluorescence, thermal satellite, and environmental data to predict county-level maize yield across four agro-ecological zones (AEZs) in China using a regression-based method (LASSO), two machine learning (ML) methods (RF and XGBoost), and deep learning (DL) network (LSTM). The results showed that combining multi-source data explained more than 75% of yield variation. Satellite data at the silking stage contributed more information than other variables, and solar-induced chlorophyll fluorescence (SIF) had an almost equivalent performance with the enhanced vegetation index (EVI) largely due to the low signal to noise ratio and coarse spatial resolution. The extremely high temperature and vapor pressure deficit during the reproductive period were the most important climate variables affecting maize production in China. Soil properties and management factors contained extra information on crop growth conditions that cannot be fully captured by satellite and climate data. We found that ML and DL approaches definitely outperformed regression-based methods, and ML had more computational efficiency and easier generalizations relative to DL. Our study is an important effort to combine multi-source remote sensed and environmental data for large-scale yield prediction. The proposed methodology provides a paradigm for other crop yield predictions and in other regions.",2020,Remote Sensing
Postprandial metabolite profiles associated with type 2 diabetes clearly stratify individuals with impaired fasting glucose,"IntroductionFasting metabolite profiles have been shown to distinguish type 2 diabetes (T2D) patients from normal glucose tolerance (NGT) individuals.ObjectivesWe investigated whether, besides fasting metabolite profiles, postprandial metabolite profiles associated with T2D can stratify individuals with impaired fasting glucose (IFG) by their similarities to T2D.MethodsThree groups of individuals (age 45â€“65Â years) without any history of IFG or T2D were selected from the Netherlands Epidemiology of Obesity study and stratified by baseline fasting glucose concentrations (NGT (nâ€‰=â€‰176), IFG (nâ€‰=â€‰186), T2D (nâ€‰=â€‰171)). 163 metabolites were measured under fasting and postprandial states (150Â min after a meal challenge). Metabolite profiles specific for a high risk of T2D were identified by LASSO regression for fasting and postprandial states. The selected profiles were utilised to stratify IFG group into high (T2D probabilityâ€‰â‰¥â€‰0.7) and low (T2D probabilityâ€‰â‰¤â€‰0.5) risk subgroups. The stratification performances were compared with clinically relevant metabolic traits.ResultsTwo metabolite profiles specific for T2D (nfastingÂ =Â 12 metabolites, npostprandialÂ =Â 4 metabolites) were identified, with all four postprandial metabolites also being identified in the fasting state. Stratified by the postprandial profile, the high-risk subgroup of IFG individuals (nâ€‰=â€‰72) showed similar glucose concentrations to the low-risk subgroup (nâ€‰=â€‰57), yet a higher BMI (difference: 3.3Â kg/m2 (95% CI 1.7â€“5.0)) and postprandial insulin concentrations (21.5Â mU/L (95% CI 1.8â€“41.2)).ConclusionPostprandial metabolites identified T2D patients as good as fasting metabolites and exhibited enhanced signals for IFG stratification, which offers a proof of concept that metabolomics research should not focus on the fasting state alone.",2017,Metabolomics
Identification of miRNA-Based Signature as a Novel Potential Prognostic Biomarker in Patients with Breast Cancer,"To identify the novel, noninvasive biomarkers to assess the outcome and prognosis of breast cancer (BC), patients with high sensitivity and specificity are greatly desired. Herein, the miRNA expression profile and matched clinical features of BC patients were extracted from The Cancer Genome Atlas (TCGA) database. The preliminary candidates were screened out by the univariate Cox regression test. Then, with the help of LASSO Cox regression analysis, the hsa-let-7b, hsa-mir-101-2, hsa-mir-135a-2, hsa-mir-22, hsa-mir-30a, hsa-mir-31, hsa-mir-3130-1, hsa-mir-320b-1, hsa-mir-3678, hsa-mir-4662a, hsa-mir-4772, hsa-mir-493, hsa-mir-556, hsa-mir-652, hsa-mir-6733, hsa-mir-874, and hsa-mir-9-3 were selected to construct the overall survival (OS) predicting signature, while the hsa-mir-130a, hsa-mir-204, hsa-mir-217, hsa-mir-223, hsa-mir-24-2, hsa-mir-29b-1, hsa-mir-363, hsa-mir-5001, hsa-mir-514a-1, hsa-mir-624, hsa-mir-639, hsa-mir-659, and hsa-mir-6892 were adopted to establish the recurrence-free survival (RFS) predicting signature. Referring to the median risk scores generated by the OS and RFS formulas, respectively, subgroup patients with high risk were strongly related to a poor OS and RFS revealed by Kaplan-Meier (K-M) plots. Meanwhile, receiver operating curve (ROC) analysis validated the accuracy and stability of these two signatures. When stratified by clinical features, such as tumor stage, age, and molecular subtypes, we found that the miRNA-based OS and RFS classifiers were still significant in predicting OS/RFS and showed the best predictive values than any other features. Besides, functional prediction analyses showed that these targeted genes of the enrolled miRNAs were enriched in cancer-associated pathways, such as MAPK/RTK, Ras, and PI3K-Akt signaling pathways. In summary, our observations demonstrate that the novel miRNA-based OS and RFS signatures are independent prognostic indicators for BC patients and worthy to be validated by further prospective studies.",2019,Disease Markers
Robust Online Multi-Task Learning with Correlative and Personalized Structures,"Multi-Task Learning (MTL) can enhance a classifierâ€™s generalization performance by learning multiple related tasks simultaneously. Conventional MTL works under the offline or batch setting, and suffers from expensive training cost and poor scalability. To address such inefficiency issues, online learning techniques have been applied to solve MTL problems. However, most existing algorithms of online MTL constrain task relatedness into a presumed structure via a single weight matrix, which is a strict restriction that does not always hold in practice. In this paper, we propose a robust online MTL framework that overcomes this restriction by decomposing the weight matrix into two components: The first one captures the low-rank common structure among tasks via a nuclear norm and the second one identifies the personalized patterns of outlier tasks via a group lasso. Theoretical analysis shows the proposed algorithm can achieve a sub-linear regret with respect to the best linear model in hindsight. Even though the above framework achieves good performance, the nuclear norm that simply adds all nonzero singular values together may not be a good low-rank approximation. To improve the results, we use a log-determinant function as a non-convex rank approximation. The gradient scheme is applied to optimize log-determinant function and can obtain a closed-form solution for this refined problem. Experimental results on a number of real-world applications verify the efficacy of our method.",2017,IEEE Transactions on Knowledge and Data Engineering
Vacuum energy-momentum tensors in Schwarzschild-De Sitter space-time,"SummaryWe deal with a quantum, massless, scalar field, minimally coupled to the Schwarzschild-De Sitter metric. In this system we study the thermal radiation by a collapsing shell. In both two and four dimensions, Hawking radiation is found. In this system but without the shell and therefore with the past event horizon, the quantized energymomentum tensor is constructed with respect to the inequivalent vacuum states. The fluxes and energy distributions are studied and they are given the physical meaning. The results are consistent with other models for this problem.RiassuntoSi considera un campo quantizzato, scalare, senza massa, accoppiato minimamente alla metrica di Schwarzschild-De Sitter. In questo sistema si studia la radiazione termica prodotta da uno strato in collasso. Sia in due che in quattro dimensioni, si trova una radiazione alla Hawking. In questo sistema ma senza lo strato, e quindi con un orizzonte di eventi passato, si ricava il tensore energia-impulso, quantistico, rispetto ai vari stati di vuoto inequivalenti. I flussi e le distribuzioni di energia sono studiate e interpretate fisicamente. I risultati sono consistenti con altri modelli per questo problema.Ð ÐµÐ·ÑŽÐ¼ÐµÐœÑ‹ Ñ€Ð°ÑÑÐ¼Ð°Ñ‚Ñ€Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð¾Ðµ, Ð±ÐµÐ·Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ðµ, ÑÐºÐ°Ð»ÑÑ€Ð½Ð¾Ðµ Ð¿Ð¾Ð»Ðµ, Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÑÐ²ÑÐ·Ð°Ð½Ð½Ð¾Ðµ Ñ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¾Ð¹ Ð¨Ð²Ð°Ñ€Ñ†ÑˆÐ¸Ð»ÑŒÐ´Ð°-Ð´Ðµ Ð¡Ð¸Ñ‚Ñ‚ÐµÑ€Ð°. Ð’ ÑÑ‚Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ Ð¼Ñ‹ Ð¸ÑÑÐ»ÐµÐ´ÑƒÐµÐ¼ Ñ‚ÐµÐ¿Ð»Ð¾Ð²Ð¾Ðµ Ð¸Ð·Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð»Ð»Ð°Ð¿ÑÐ¸Ñ€ÑƒÑŽÑ‰ÐµÐ¹ Ð¾Ð±Ð¾Ð»Ð¾Ñ‡ÐºÐ¸. Ð’ ÑÐ»ÑƒÑ‡Ð°Ðµ Ð´Ð²ÑƒÑ… Ð¸ Ñ‡ÐµÑ‚Ñ‹Ñ€ÐµÑ… Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ð¹ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ÑÑ Ð¸Ð·Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¥Ð°Ð²ÐºÐ¸Ð½Ð°. Ð’ ÑÑ‚Ð¾Ð¹ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ, Ð½Ð¾ Ð±ÐµÐ· Ð¾Ð±Ð¾Ð»Ð¾Ñ‡ÐºÐ¸ Ð¸, ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾, Ñ Ð³Ð¾Ñ€Ð¸Ð·Ð¾Ð½Ñ‚Ð¾Ð¼ Ð¿Ñ€Ð¾ÑˆÐ»Ñ‹Ñ… ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹, ÐºÐ¾Ð½ÑÑ‚Ñ€ÑƒÐ¸Ñ€ÑƒÐµÑ‚ÑÑ ÐºÐ²Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐ½Ð·Ð¾Ñ€ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸-Ð¸Ð¼Ð¿ÑƒÐ»ÑŒÑÐ° Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÑŒ Ð½ÐµÑÐºÐ²Ð¸Ð²Ð°Ð»ÐµÐ½Ñ‚Ð½Ð¾Ð³Ð¾ Ð²Ð°ÐºÑƒÑƒÐ¼Ð°. Ð˜ÑÑÐ»ÐµÐ´ÑƒÑŽÑ‚ÑÑ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¸ Ð¸ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸. ÐžÐ±ÑÑƒÐ¶Ð´Ð°ÐµÑ‚ÑÑ Ð¸Ñ… Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÐ¼Ñ‹ÑÐ». ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ð³Ð»Ð°ÑÑƒÑŽÑ‚ÑÑ Ñ Ð´Ñ€ÑƒÐ³Ð¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ð´Ð»Ñ ÑÑ‚Ð¾Ð¹ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹.",1980,Il Nuovo Cimento B (1971-1996)
Verfahren und vorrichtung zur plastifizierung von kunststoffmaterial,"Bei einem Verfahren zur Plastifizierung von Kunststoffmaterial mittels eines von einem Zahnradextruder oder einer Zahnradpumpe gebildeten Plastifizierorganes wird das thermoplastische Kunststoffmaterial in einem Behalter (1) durch in diesem befindliche bewegte Werkzeuge (12) bearbeitet und auf eine unterhalb der Plastifizierungstemperatur liegende Temperatur erwarmt und dadurch erweicht. Erst in diesem erweichten Zustand wird das Material in das Plastifizierungsorgan (19) eingefuhrt und erst dort plastifiziert. Eine Vorrichtung zur Durchfuhrung dieses Verfahrens hat ein Zahnrader (20, 21, 41, 42, 44, 45) aufweisendes Gehause (31) eines Plastifizierorganes (19), dessen Einlassoffnung (18) mit der Austragsoffnung (17) eines Behalters (1) in Stromungsverbindung steht. Im Behalter (1) sind durch zumindest einen Motor (14) bewegte Werkzeuge (12) angeordnet, die das Kunststoffmaterial bearbeiten und auf eine unterhalb der Plastifizierungstemperatur liegende Temperatur erwarmen und dadurch erweichen.",2004,
Extending nuXmv with Timed Transition Systems and Timed Temporal Properties,"nuXmv is a well-known symbolic model checker, which implements various state-of-the-art algorithms for the analysis of finite- and infinite-state transition systems and temporal logics. In this paper, we present a new version that supports timed systems and logics over continuous super-dense semantics. The system specification was extended with clocks to constrain the timed evolution. The support for temporal properties has been expanded to include \(\textsc {MTL}_{0,\infty }\) formulas with parametric intervals. The analysis is performed via a reduction to verification problems in the discrete-time case. The internal representation of traces has been extended to go beyond the lasso-shaped form, to take into account the possible divergence of clocks. We evaluated the new features by comparing nuXmv with other verification tools for timed automata and \(\textsc {MTL}_{0,\infty }\), considering different benchmarks from the literature. The results show that nuXmv is competitive with and in many cases performs better than state-of-the-art tools, especially on validity problems for \(\textsc {MTL}_{0,\infty }\).",2019,
Patient safety at 10 years: how far have we come? What's next?,"Patient safety at 10 years: How far have we come? Whatâ€™s next? If you were to give patient safety a grade on progress over the past 5 or 10 years, what would it be? OR leaders and their colleagues have participated in an array of initiatives since the Institute of Medicine published its well-known 1999 report, To Err is Human. They include the Joint Commissionâ€™s Universal Protocol, the WHO Surgical Safety Checklist, and the Surgical Care Improvement Project (SCIP), to name a few. Is it making a difference? Are patients safer than they were a decade ago? Robert Wachter, MD, a leading patient safety expert, thinks the movement is bringing up its grade. He gives patient safety an overall Bup from the C+ he awarded 5 years ago, and a big jump over the D he says he would have assigned in 1999. In a recent review in the journal Health Affairs, he grades the field of patient safety in 10 domains, such as regulation and accreditation, information technology, and workplace and training issues. OR Manager talked with Dr Wachter about where we stand and what comes next. He is a founder of the hospitalist movement and Anew study in the New England Journal of Medicine finds that treating patients who are Staphylococcus aureus nasal carriers with mupirocin nasal ointment and chlorhexidine gluconate soap for 5 days reduces hospitalassociated postoperative S aureus infection by 60%. â€œThis well-designed, well-executed study contributes more to our knowledge that screening is effective,â€ says Stephen Streed, MS, CIC, system director for epidemiology for Lee Memorial Health System in Fort Myers, Florida. â€œSeveral other studies have shown reduced infection rates, but some had equivocal results, so this study adds strength for doing nasal screening.â€ Nasal carriers of S aureus are at higher risk for infection, so a preoperative screening program makes sense. But which patients should be screened, and how does such a program fit into the complicated world of surgery schedules?",2010,OR manager
MAGMA: inference of sparse microbial association networks,"Microorganisms often live in symbiotic relationship with their environment and they play a central role in many biological processes. They form a complex system of interacting species. Within the gut micro-biota these interaction patterns have been shown to be involved in obesity, diabetes and mental disease. Understanding the mechanisms that govern this ecosystem is therefore an important scientific challenge. Recently, the acquisition of large samples of microbiota data through metabarcoding or metagenomics has become easier. Until now correlation-based network analysis and graphical modelling have been used to identify the putative interaction networks formed by the species of microorganisms, but these methods do not take into account all features of microbiota data. Indeed, correlation-based network cannot distinguish between direct and indirect correlations and simple graphical models cannot include covariates as environmental factors that shape the microbiota abundance. Furthermore, the compositional nature of the microbiota data is often ignored or existing normalizations are often based on log-transformations, which is somewhat arbitrary and therefore affects the results in unknown ways. We have developed a novel method, called MAGMA, for detecting interactions between microbiota that takes into account the noisy structure of the microbiota data, involving an excess of zero counts, overdispersion, compositionality and possible covariate inclusion. The method is based on Copula Gaus-sian graphical models whereby we model the marginals with zero-inflated negative binomial generalized linear models. The inference is based on an efficient median imputation procedure combined with the graphical lasso. We show that our method beats all existing methods in recovering microbial association networks in an extensive simulation study. Moreover, the analysis of two 16S microbial data studies with our method reveals interesting new biology. MAGMA is implemented as an R-package and is freely available at https://gitlab.com/arcgl/rmagma, which also includes the scripts used to prepare the material in this paper.",2019,bioRxiv
Variable Selection in Frailty Models using FrailtyHL R Package: Breast Cancer Survival Data,"Abstract Determining relevant variables for a regression model is important in regression analysis. Recently, a variableselection methods using a penalized likelihood with various penalty functions (e.g. LASSO and SCAD) havebeen widely studied in simple statistical models such as linear models and generalized linear models. Theadvantage of these methods is that they select important variables and estimate regression coeï¬ƒcients,simultaneously; therefore, they delete insigniï¬cant variables by estimating their coeï¬ƒcients as zero. Westudy how to select proper variables based on penalized hierarchical likelihood (HL) in semi-parametricfrailty models that allow three penalty functions, LASSO, SCAD and HL. For the variable selection wedevelop a new function in the â€œfrailtyHLâ€ R package. Our methods are illustrated with breast cancersurvival data from the Medical Center at Chonnam National University in Korea. We compare the resultsfrom three variable-selection methods and discuss advantages and disadvantages.Keywords: frailty models, H-likelihood, LASSO, SCAD, Variable selection",2015,
Meilensteine der Bach-Interpretation 1750-2000: Eine Werkgeschichte im Wandel (review),"research collection on those subjects. Admirers of Lasso may regret so much attention to what might easily be regarded as distortions of his music, but the contrafacta have their place in history, and Freedman has provided what appears to be a definitive study of them. Perhaps we may hope that in the future he will give us a study simply of Lassoâ€™s chansons, about which he is so well informed and perceptive.",2002,Notes
On a Semiparametric Dataâ€Driven Nonlinear Model with Penalized Spatioâ€Temporal Lag Interactions,"To study possibly nonlinear relationship between housing price index (HPI) and consumer price index (CPI) for individual states in the USA, accounting for the temporal lag interactions of the housing price in a given state and spatioâ€temporal lag interactions between states could improve the accuracy of estimation and forecasting. There lacks, however, methodology to objectively identify and estimate such spatioâ€temporal lag interactions. In this article, we propose a semiparametric dataâ€driven nonlinear time series regression method that accounts for lag interactions across space and over time. A penalized procedure utilizing adaptive Lasso is developed for the identification and estimation of important spatioâ€temporal lag interactions. Theoretical properties for our proposed methodology are established under a general near epoch dependence structure and thus the results can be applied to a variety of linear and nonlinear time series processes. For illustration, we analyze the US housing price data and demonstrate substantial improvement in forecasting via the identification of nonlinear relationship between HPI and CPI as well as spatioâ€temporal lag interactions.",2019,Journal of Time Series Analysis
AIC for the non-concave penalized likelihood method,"Non-concave penalized maximum likelihood methods are widely used because they are more efficient than the Lasso. They include a tuning parameter which controls a penalty level, and several information criteria have been developed for selecting it. While these criteria assure the model selection consistency, they have a problem in that there are no appropriate rules for choosing one from the class of information criteria satisfying such a preferred asymptotic property. In this paper, we derive an information criterion based on the original definition of the AIC by considering minimization of the prediction error rather than model selection consistency. Concretely speaking, we derive a function of the score statistic that is asymptotically equivalent to the non-concave penalized maximum likelihood estimator and then provide an estimator of the Kullbackâ€“Leibler divergence between the true distribution and the estimated distribution based on the function, whose bias converges in mean to zero.",2015,Annals of the Institute of Statistical Mathematics
Stratification of endometrioid endometrial cancer patients into risk levels using somatic mutations.,"OBJECTIVE
Patients with endometrioid endometrial cancer are stratified as high risk and low risk for extrauterine disease by surgical staging. Since patients with low-grade, minimally invasive disease do not benefit from comprehensive staging, pre-surgery stratification into a risk category may prevent unnecessary surgical staging in low risk patients. Our objective was to develop a predictive model to identify risk levels using somatic mutations that could be used preoperatively.


METHODS
We classified endometrioid endometrial cancer patients in The Cancer Genome Atlas (TCGA) dataset into high risk and low risk categories: high risk patients presented with stage II, III or IV disease or stage I with high-intermediate risk features, whereas low risk patients consisted of the remaining stage I patients with either no myometrial invasion or low-intermediate risk features. Three strategies were used to build the prediction model: 1) mutational status for each gene; 2) number of somatic mutations for each gene; and 3) variant allele frequencies for each somatic mutation for each gene.


RESULTS
Each prediction strategy had a good performance, with an area under the curve (or AUC) between 61% and 80%. Analysis of variant allele frequency produced a superior prediction model for risk levels of endometrial cancer as compared to the other two strategies, with an AUC=91%. Lasso and Ridge methods identified 53 mutations that together had the highest predictability for high risk endometrioid endometrial cancer.


CONCLUSIONS
This prediction model will assist future retrospective and prospective studies to categorize endometrial cancer patients into high risk and low risk in the preoperative setting.",2016,Gynecologic oncology
Direct effects testing: a two-stage procedure to test for effect size and variable importance for correlated binary predictors and a binary response.,"In applications such as medical statistics and genetics, we encounter situations where a large number of highly correlated predictors explain a response. For example, the response may be a disease indicator and the predictors may be treatment indicators or single nucleotide polymorphisms (SNPs). Constructing a good predictive model in such cases is well studied. Less well understood is how to recover the 'true sparsity pattern', that is finding which predictors have direct effects on the response, and indicating the statistical significance of the results. Restricting attention to binary predictors and response, we study the recovery of the true sparsity pattern using a two-stage method that separates establishing the presence of effects from inferring their exact relationship with the predictors. Simulations and a real data application demonstrate that the method discriminates well between associations and direct effects. Comparisons with lasso-based methods demonstrate favourable performance of the proposed method.",2010,Statistics in medicine
Generalized Lassoë¥¼ ì´ìš©í•œ ê³µê°„ êµ°ì§‘ ê¸°ë²•,"ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì§ˆë³‘ê³¼ ì—°ê´€ì„±ì„ ê°–ëŠ” êµ­ì†Œ ê³µê°„ êµ°ì§‘ì„ ê²€ì¶œí•  ìˆ˜ ìžˆëŠ” ë²Œì¹™ ê°€ëŠ¥ë„ ë°©ë²•ì„ ì œì•ˆí•œë‹¤. í•µì‹¬ì ì¸ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ì€ Tibshiraniì™€ Taylor (2011)ì— ì˜í•´ ì œì•ˆëœ ì¼ë°˜í™”ëœ ë¼ì†Œ(generalized lasso)ì— ê¸°ë°˜í•œë‹¤. ì œì•ˆëœ ë°©ë²•ì€ í˜„ìž¬ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìžˆëŠ” êµ­ì†Œ ê³µê°„ êµ°ì§‘ ë°©ë²•ì¸ Kulldorffì˜ ê¸°ë²•ì— ë¹„í•´ ë‘ê°€ì§€ ì£¼ìš” ìž¥ì ì„ ê°€ì§€ê³  ìžˆë‹¤. ì²«ì§¸ë¡œ, ì œì•ˆëœ ë°©ë²•ì€ ì‚¬ì „ì— êµ°ì§‘ì˜ í¬ê¸°ë¥¼ ë¯¸ë¦¬ ê²°ì •í•´ ì¤„ í•„ìš”ê°€ ì—†ë‹¤. ë‘˜ì§¸ë¡œ, ìž„ì˜ì˜ ì„¤ëª…ë³€ìˆ˜ë¥¼ ê³µê°„ êµ°ì§‘ íƒìƒ‰ ê¸°ë²•ì— ê³ ë ¤í•  ìˆ˜ ìžˆê¸° ë•Œë¬¸ì— ì¸êµ¬í•™ì ì¸ ë³€ìˆ˜ë¥¼ ë³´ì •í•˜ì˜€ì„ ë•Œ ë‚˜íƒ€ë‚˜ëŠ” êµ­ì†Œ ê³µê°„ êµ°ì§‘ì„ ì°¾ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë‹¤. ìš°ë¦¬ëŠ” ì œì•ˆëœ ë°©ë²•ì„ ì„œìš¸ì‹œ ê²°í•µ ìžë£Œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ëª…í•œë‹¤. ã€In this paper, we propose a penalized likelihood method to detect local spatial clusters associated with disease. The key computational algorithm is based on genlasso by Tibshirani and Taylor (2011). The proposed method has two main advantages over Kulldorff's method which is popoular to detect local spatial clusters. First, it is not needed to specify a proper cluster size a priori. Second, any type of covariate can be incorporated and, it is possible to find local spatial clusters adjusted for some demographic variables. We illustrate our proposed method using tuberculosis data from Seoul.ã€‘",2014,
Diagnostic value of interferon-Î³ in the peripheral blood and the saliva of patients with oral lichen planus,"Journal of the Egyptian Womenâ€™s Dermatologic Society 2014, 11:24â€“27 Background The exact etiology of oral lichen planus (OLP) remains obscure. T helper 1 cellassociated cytokines and chemokines have been implicated in the pathogenesis. Among these cytokines, interferon-g (IFN-g) has been studied more extensively. Objective The purpose of this study was to measure the level of IFN-g in peripheral blood and whole unstimulated saliva (WUS) of OLP patients to assess their diagnostic value. Patients and methods IFN-g was measured simultaneously in serum and salivary (WUS) samples of 30 OLP patients and 30 healthy control individuals using enzyme-linked immunosorbent assay technique. Results A significantly higher mean IFN-g in the saliva was found among OLP cases compared with healthy control individuals, and the mean salivary IFN-g was significantly higher than that in the peripheral blood of cases. Conclusion IFN-g in WUS has a diagnostic value in OLP lesions.",2014,Journal of the Egyptian WomenÊ¼s Dermatologic Society
Systematic Review of Omalizumab for the Treatment of Chronic Rhinosinusitis,"S A T U R D A Y 174 Omalizumab for the Treatment of Chronic Rhinosinusitis: A Multi-Disciplinary Practice Review Shaun Kilty, MD, FRCSC, Andrea Lasso, Stephanie Santucci, RN, William H. Yang, MD; Ottawa Hospital Research Institute, Ottawa, ON, Canada, Division of Otolaryngology-Head and Neck Surgery, The University of Ottawa, The Ottawa Hospital, Ottawa, ON, Canada, Allergy and Asthma Research Centre, Ottawa, ON, Canada, University of Ottawa Medical School, Ottawa, ON, Canada. RATIONALE: Recently, anti-IgE monoclonal antibody has emerged as a potential therapy for CRS. However, to date evidence for its efficacy in this patient population is sparse. The purpose of this study is to evaluate the clinical treatment effect of omalizumab therapy for patients with recalcitrant CRS treated in a multi-disciplinary clinic. METHODS: The charts of 194 patients on omalizumabwere reviewed. 21 patients diagnosed with CRS and having failed surgical and/or medical therapy were identified. Data extraction was performed and targeted demographic details, asthma, environmental allergy and CRS specific disease related data including self-reported major symptom improvement. Nonparametric data was analysed with the Mann-Whitney test and binary data was analysed with Fisherâ€™s exact test. RESULTS: Themean treatment durationwas17months.Themost common skin test positive environmental allergens were dust mites (100%) and cats (65%). 75% of the cohort had CRS with polyps. Six patients (30%) had AERD.Themeanpolyp score decreased from1.8 to 1.0 (p50.106). From the time of treatment initiation to the last omalizumab treatment dose, patients reported a mean 59% improvement in their olfaction, a mean 70.4% improvement in facial pain, a mean 78.2% improvement in nasal obstruction and a mean 68.1% improvement in the symptom of rhinorrhea. Patients reported a mean overall improvement in their sinus symptoms of 74.1%. CONCLUSIONS: Omalizumab therapy provided a substantial improvement in the self-reported major symptom control for patients with recalcitrant CRS and asthma. Awell-designed comparative study is needed to further assess its effectiveness in the CRS population.",2015,The Journal of Allergy and Clinical Immunology
Lasso-Path and Taut String Algorithm for One-Dimensional Total Variation Regularization,"In this thesis, we consider the minimization problem arising from a linear operator equation when applying Tikhonov regularization. In particular, we study the one-dimensional case with total variation penalization. We present two numerical methods for the reconstruction of the original function, both of which give exact results. The first is the taut string algorithm, for which we assume no linear transformation of the data. The second is a modified lasso-path algorithm, derived for the total variation regularization. The thesis focuses on the derivation of these algorithms. The taut string algorithm is of lower complexity than the lasso-path algorithm, but the trade off is that it is only applicable on non-transformed data and only computes the solution for a single regularization parameter. The lasso-path is applicable on all linear transformations, and computes the solution simultaneously for all regularization parameters in a given range. Finally, we test both of the algorithms with a few numerical experiments. We test the taut string algorithm for a block signal, and for moderate amount of noise we are able to reconstruct the signal. We test the lasso-path algorithm on the same block signal for different linear operator equations, in particular for moving averages and for random measurements. In general, when not too much noise is added, we are able to reconstruct the significant jumps of the original signal, although not exactly. For the random matrices, with fewer measurements than unknowns, the problem is more difficult, but we were able to find a good reconstruction if the number of jumps in the original signal were small enough.",2017,
Online robust dictionary learning with density-based outlier weighing,"Online outlier detection is fundamental for expediting the processing of data and focusing processing resources on portions of data that may be most informative. This work develops online robust dictionary learning algorithms that are able to identify outliers in the training data. The algorithms are based on lasso updates for computing the vector of expansion coefficients for a new training vector and gradient descent updates for updating the dictionary. An outlier is identified based on the so-called outlier vector. The weight associated with the group lasso regularizer that encourages an outlier vector to be set to zero is computed based on the outlierness score of the corresponding training data vector. Outlier vectors are thus more likely to be nonzero if they feature a high outlierness score. Outlierness scores are obtained from density-based outlier detection algorithms and help to enhance the selection of outliers. Both soft and hard outlier removal algorithms are developed. In the latter case, outliers are identified and a residual obtained after removing the outlier contribution is used to update the dictionary. The performance of the proposed algorithms is illustrated via numerical experiments on real video data.",2016,OCEANS 2016 MTS/IEEE Monterey
Learning to Rank for Blind Image Quality Assessment,"Blind image quality assessment (BIQA) aims to predict perceptual image quality scores without access to reference images. State-of-the-art BIQA methods typically require subjects to score a large number of images to train a robust model. However, subjective quality scores are imprecise, biased, and inconsistent, and it is challenging to obtain a large-scale database, or to extend existing databases, because of the inconvenience of collecting images, training the subjects, conducting subjective experiments, and realigning human quality evaluations. To combat these limitations, this paper explores and exploits preference image pairs (PIPs) such as the quality of image Ia is better than that of image Ib for training a robust BIQA model. The preference label, representing the relative quality of two images, is generally precise and consistent, and is not sensitive to image content, distortion type, or subject identity; such PIPs can be generated at a very low cost. The proposed BIQA method is one of learning to rank. We first formulate the problem of learning the mapping from the image features to the preference label as one of classification. In particular, we investigate the utilization of a multiple kernel learning algorithm based on group lasso to provide a solution. A simple but effective strategy to estimate perceptual image quality scores is then presented. Experiments show that the proposed BIQA method is highly effective and achieves a performance comparable with that of state-of-the-art BIQA algorithms. Moreover, the proposed method can be easily extended to new distortion categories.",2015,IEEE Transactions on Neural Networks and Learning Systems
Total synthesis of bioactive peptides and whole proteins,"Total chemical synthesis is an essential tool for the validation of natural product structures and the discovery and elaboration of novel therapeutic scaffolds. Chapter 1 (Part I) surveys existing treatments for trypanosomatid neglected tropical diseases, and the synthesis of a novel class of antiparasitic cyclic depsipeptides is reported (Chapter 2) alongside a full NMR assignment and structure calculation using NMR-derived distance restraints. The synthetic peptides exhibit activity profiles in agreement with published results, and a series of ester-to-amide substitution analogues also synthesized show similar low micromolar potency. Chapter 3 describes the synthesis of lassomycin, a tuberculocidal lasso peptide reported to exhibit a unique unthreaded topology. The naturally occurring peptide was synthesized alongside C-terminally amidated and truncated analogues, but none were biologically active. Given clear differences observed in the two-dimensional NMR data for synthetic lassomycin, it is suggested that the reported natural product in fact exists in the threaded form. The chemical synthesis of whole proteins is addressed in Part II, and current progress in the field is reviewed (Chapter 4). Work towards the total chemical synthesis of acyl carrier protein using a two fragment approach is described in Chapter 5. The N-terminal fragment was synthesized using the sulfonamide linker, and while the C-terminal fragment presented difficulties due to extremely low solubility, solubilization using backbone protection was demonstrated. The development of a modified Dawson linker for the synthesis of peptide N-acylureas without overacylation is also described. Finally, Part III details the synthesis of tumor targeting peptides used for imaging and inhibition of cancer cell growth, and which cause tumor size reduction in vivo. A novel web utility used for the automated assignment of peptide mass spectra throughout this thesis is also presented.",2016,
Asymmetric Effect with Quantile Regression for Interval-Valued Variables,"In this paper, we propose a quantile regression with interval valued data using a convex combination method. The model we propose generalizes series of existing models, say typically with the center method. Three estimation techniques consisting EM algorithm, Least squares, Lasso penalty are presented to estimate the unknown parameters of our model. A series of Monte Carlo experiments are conducted to assess the performance of our proposed model. The results support our theoretical properties. Finally, we apply our model to empirical data in order to show the usefulness of the proposed model. The results imply that the EM algorithm provides a best fit estimation for our data set and captures the effect of oil differently across various quantile levels.",2018,
"Born at the right time? A conceptual framework linking reproduction, development, and settlement in reef fish.","Parents are expected to make decisions about reproductive timing and investment that maximize their own fitness, even if this does not maximize the fitness of each individual offspring. When offspring survival is uncertain, selection typically favors iteroparity, which means that offspring born at some times can be disadvantaged, while others get lucky. The eventual fate of offspring may be further modified by their own decisions. Are fates of offspring set by birthdates (i.e., determined by parents), or can offspring improve upon the cards they've been dealt? If so, do we see adaptive plasticity in the developmental timing of offspring? We evaluate these questions for a coral reef fish (the sixbar wrasse, Thalassoma hardwicke) that is characterized by extreme iteroparity and flexible larval development. Specifically, we monitored larval settlement to 192 small reefs over 11 lunar months and found that most fish settled during new moons of a lunar cycle (consistent with preferential settlement on dark nights). Settlement was significantly lower than expected by chance during the full moon and last quarter of the lunar cycle (consistent with avoidance of bright nights). Survival after settlement was greatest for fish that settled during times of decreasing lunar illumination (from last quarter to new moon). Fish that settled on the last quarter of the lunar cycle were ~10% larger than fish that settled during other periods, suggesting larvae delay settlement to avoid the full moon. These results are consistent with a numerical model that predicts plasticity in larval development time that enables avoidance of settlement during bright periods. Collectively, our results suggest that fish with inauspicious birthdates may alter their developmental trajectories to settle at better times. We speculate that such interactions between parent and offspring strategies may reinforce the evolution of extreme iteroparity and drive population dynamics, by increasing the survival of offspring born at the ""wrong"" time by allowing them to avoid the riskiest times of settlement.",2018,Ecology
Bayesian hierarchical structured variable selection methods with application to MIP studies in breast cancer.,"The analysis of alterations that may occur in nature when segments of chromosomes are copied (known as copy number alterations) has been a focus of research to identify genetic markers of cancer. One high-throughput technique recently adopted is the use of molecular inversion probes (MIPs) to measure probe copy number changes. The resulting data consist of high-dimensional copy number profiles that can be used to ascertain probe-specific copy number alterations in correlative studies with patient outcomes to guide risk stratification and future treatment. We propose a novel Bayesian variable selection method, the hierarchical structured variable selection (HSVS) method, which accounts for the natural gene and probe-within-gene architecture to identify important genes and probes associated with clinically relevant outcomes. We propose the HSVS model for grouped variable selection, where simultaneous selection of both groups and within-group variables is of interest. The HSVS model utilizes a discrete mixture prior distribution for group selection and group-specific Bayesian lasso hierarchies for variable selection within groups. We provide methods for accounting for serial correlations within groups that incorporate Bayesian fused lasso methods for within-group selection. Through simulations we establish that our method results in lower model errors than other methods when a natural grouping structure exists. We apply our method to an MIP study of breast cancer and show that it identifies genes and probes that are significantly associated with clinically relevant subtypes of breast cancer.",2014,"Journal of the Royal Statistical Society. Series C, Applied statistics"
Second order Stein: SURE for SURE and other applications in high-dimensional inference.,"Stein's formula states that a random variable of the form $z^\top f(z) - {\rm{div}} f(z)$ is mean-zero for all functions $f$ with integrable gradient. Here, ${\rm{div}} f$ is the divergence of the function $f$ and $z$ is a standard normal vector. A Second Order Stein formula is proposed to characterize the variance of such random variables. 
In the Gaussian sequence model, a remarkable consequence of Stein's formula is Stein's Unbiased Risk Estimate (SURE) of the mean square risk of almost any given estimator $\hat\mu$ for the unknown mean vector. A first application of the Second Order Stein formula is an Unbiased Risk Estimate of the risk of SURE itself (SURE for SURE): a simple unbiased estimate provides information about the squared distance between SURE and the squared estimation error of $\hat\mu$. SURE for SURE has a simple form and can be computed explicitly for differentiable $\hat\mu$, for example the Lasso and the Elastic Net. 
Other applications of the Second Order Stein formula are provided in high-dimensional regression. This includes novel bounds on the variance of the size of the model selected by the Lasso, and a general semi-parametric scheme to de-bias an almost differentiable initial estimator in order to estimate a low-dimensional projection of the unknown regression coefficient vector.",2018,arXiv: Statistics Theory
A Dirty Model for Multiple Sparse Regression,"The task of sparse linear regression consists of finding an unknown sparse vector from linear measurements. Solving this task even under â€œhigh-dimensionalâ€ settings, where the number of samples is fewer than the number of variables, is now known to be possible via methods such as the LASSO. We consider the multiple sparse linear regression problem, where the task consists of recovering several related sparse vectors at once. A simple approach to this task would involve solving independent sparse linear regression problems, but a natural question is whether one can reduce the overall number of samples required by leveraging partial sharing of the support sets, or nonzero patterns, of the signal vectors. A line of recent research has studied the use of â„“1/â„“q norm block-regularizations with q > 1 for such problems. However, depending on the level of sharing, these could actually perform worse in sample complexity when compared to solving each problem independently. We present a new â€œadaptiveâ€ method for multiple sparse linear regression that can leverage support and parameter overlap when it exists, but not pay a penalty when it does not. We show how to achieve this using a very simple idea: decompose the parameters into two components and regularize these differently. We show, theoretically and empirically, that our method strictly and noticeably outperforms both â„“1 or â„“1/â„“q methods, over the entire range of possible overlaps (except at boundary cases, where we match the best method), even under high-dimensional scaling.",2013,IEEE Transactions on Information Theory
Improving predictive models for Alzheimer's disease using GWAS data by incorporating misclassified samples modeling.,"Late-onset Alzheimer's Disease (LOAD) is the most common form of dementia in the elderly. Genome-wide association studies (GWAS) for LOAD have open new avenues to identify genetic causes and to provide diagnostic tools for early detection. Although several predictive models have been proposed using the few detected GWAS markers, there is still a need for improvement and identification of potential markers. Commonly, polygenic risk scores are being used for prediction. Nevertheless, other methods to generate predictive models have been suggested. In this research, we compared three machine learning methods that have been proved to construct powerful predictive models (genetic algorithms, LASSO, and step-wise) and propose the inclusion of markers from misclassified samples to improve overall prediction accuracy. Our results show that the addition of markers from an initial model plus the markers of the model fitted to misclassified samples improves the area under the receiving operative curve by around 5%, reaching ~0.84, which is highly competitive using only genetic information. The computational strategy used here can help to devise better methods to improve classification models for AD. Our results could have a positive impact on the early diagnosis of Alzheimer's disease.",2020,PloS one
Online-to-Confidence-Set Conversions and Application to Sparse Stochastic Bandits,"We introduce a novel technique, which we call online-to-confidence-set conversion. The technique allows us to construct highprobability confidence sets for linear prediction with correlated inputs given the predictions of any algorithm (e.g., online LASSO, exponentiated gradient algorithm, online least-squares, p-norm algorithm) targeting online learning with linear predictors and the quadratic loss. By construction, the size of the confidence set is directly governed by the regret of the online learning algorithm. Constructing tight confidence sets is interesting on its own, but the new technique is given extra weight by the fact having access tight confidence sets underlies a number of important problems. The advantage of our construction here is that progress in constructing better algorithms for online prediction problems directly translates into tighter confidence sets. In this paper, this is demonstrated in the case of linear stochastic bandits. In particular, we introduce the sparse variant of linear stochastic bandits and show that a recent online algorithm together with our online-to-confidence-set conversion allows one to derive algorithms that can exploit if the reward is a function of a sparse linear combination of the components of the chosen action. Appearing in Proceedings of the 15 International Conference on Artificial Intelligence and Statistics (AISTATS) 2012, La Palma, Canary Islands. Volume XX of JMLR: W&CP XX. Copyright 2012 by the authors.",2012,
Cysteine conjugate Î²-lyase and the thiomethyl shunt,"specificity of transferases from different species is not conserved with respect to xenobiotics or artificial substrates (Lee et al., 1981). One of the known examples is lactate dehydrogenase from different species. The purified form of this enzyme exhibits quite similar specific activity among different species, when L-lactate and the natural coenzyme, NAD+, are used for the enzyme assay. However, when the coenzyme analogue thionicotinamide-adenine dinucleotide is used as the coenzyme for activity assay, great species variations of enzyme activity are observed (Anderson, 1982). Therefore, from the enzymological point of view, it is apparent that enzyme activities are conserved through the species evolution only for their natural substrates, but not for xenobiotics (Lee et al., 1981). In view of this consideration, it remains an open question regarding the natural substrates of glutathione S-transferases and their additional biological functions in vivo. Since the artificial electrophiles were used for the initial identification of this detoxification enzyme system, one would expect great species variations in terms of their multiple forms and their specificity to artificial substrates. Such a commonly observed phenomenon may become an important concern in choosing a proper animal species for the evaluation of biochemical transformation and toxicity (or carcinogenesis) of numerous xenobiotics (Lee et al., 1981). From the study of microsomal transferases from mouse liver, we have demonstrated that increased microsomalassociated transferases have complete immunological identity with cytosolic liver transferases (Lee & McKinney, 1982). This implies that microsomal transferases share the same or closely related structural origins with those of soluble transferases. However, by gel-filtration chromatography, we also demonstrated some non-covalent associations between the microsomal membranes and glutathione S-transferases which may be of cytosolic origin (Lee & McKinney, 1982). This observation was consistent with the previous reports that glutathione S-transferase activity in microsomal fractions represents a stable and controlled localization of these enzymes in microsomal membranes, even though they are cytosolic in nature (Friedberg et al., 1979). The appearance of such associations between microsomal membranes and cytosolic transferases may have an unequivocal biological implication in terms of the detoxification of xenobiotics. When the activated metabolites of xenobiotics are generated proximally by other microsomal detoxification enzyme systems, the membraneassociated transferases may play an important role in the detoxification of these metabolites. Such a design is similar to other detoxification enzymes in microsomal fractions, such as epoxide hydratase (Oesch et al., 1971) and related enzyme systems.",1984,Biochemical Society Transactions
A Unified Robust Regression Model for Lasso-like Algorithms,"We develop a unified robust linear regression model and show that it is equivalent to a general regularization framework to encourage sparse-like structure that contains group Lasso and fused Lasso as specific examples. This provides a robustness interpretation of these widely applied Lasso-like algorithms, and allows us to construct novel generalizations of Lasso-like algorithms by considering different uncertainty sets. Using this robustness interpretation, we present new sparsity results, and establish the statistical consistency of the proposed regularized linear regression. This work extends a classical result from Xu et al. (2010) that relates standard Lasso with robust linear regression to learning problems with more general sparse-like structures, and provides new robustness-based tools to to understand learning problems with sparse-like structures.",2013,
Broad Learning for Optimal Short-Term Traffic Flow Prediction,"In this work, we explore the use of a Broad Learning System (BLS) as a way to replace deep learning architectures for traffic flow prediction. BLS is shown to not only outperforms standard learning algorithms (Least absolute shrinkage and selection operator (LASSO), shallow and deep neural networks, stacked autoencoders) in terms of training time, but also in terms of testing accuracy.",2019,
Multiplex quantitation of 270 plasma protein markers to identify a signature for early detection of colorectal cancer.,"Blood-based protein biomarker signatures might be an alternative or supplement to existing methods for early detection of colorectal cancer (CRC) for population-based screening. The objective of this study was to derive a protein biomarker signature for early detection of CRC and its precursor advanced adenoma (AA). In a two-stage design, 270 protein markers were measured by liquid chromatography/multiple reaction monitoring/mass spectrometryÂ in plasma samples of discovery and validation sets. In the discovery set consisting of 100 newly diagnosed CRC cases and 100 age- and sex-matched controls free of neoplasm at screening colonoscopy, the algorithms predicting the presence of early- or late-stage CRC were derived by Lasso regression and .632Â +Â bootstrap. The prediction algorithms were then externally validated in an independent validation set consisting of participants of screening colonoscopy including 56 participants with CRC, 99 with AA and 99 controls without any colorectal neoplasms. Three different signatures for all-, early- and late-stageÂ CRC consisting of five-, three- and eight-protein markers were obtained in the discovery set with areas under the curves (AUCs) after .632Â +Â bootstrap adjustment of 0.85, 0.83 and 0.96, respectively. External validation in the representative screening population yielded AUCs of 0.79 (95% CI, 0.70-0.86), 0.79 (95% CI, 0.66-0.89) and 0.80 (95% CI, 0.70-0.89) for all-, early- and late-stage CRCs, respectively. The three-marker early-stage algorithm yielded an AUC of 0.65 (95% CI, 0.56-0.73) for detection of AA in the validation set. Although not yet competitive with available stool-based tests for CRC early detection, the identified proteins may contribute to the development of powerful blood-based tests for early detection of CRC and its precursors AAs.",2020,European journal of cancer
Covariance structure approximation via gLasso in high-dimensional supervised classification,"Recent work has shown that the Lasso-based regularization is very useful for estimating the high-dimensional inverse covariance matrix. A particularly useful scheme is based on penalizing the â„“1 norm of the off-diagonal elements to encourage sparsity. We embed this type of regularization into high-dimensional classification. A two-stage estimation procedure is proposed which first recovers structural zeros of the inverse covariance matrix and then enforces block sparsity by moving non-zeros closer to the main diagonal. We show that the block-diagonal approximation of the inverse covariance matrix leads to an additive classifier, and demonstrate that accounting for the structure can yield better performance accuracy. Effect of the block size on classification is explored, and a class of asymptotically equivalent structure approximations in a high-dimensional setting is specified. We suggest a variable selection at the block level and investigate properties of this procedure in growing dimension asymptotics. We present a consistency result on the feature selection procedure, establish asymptotic lower an upper bounds for the fraction of separative blocks and specify constraints under which the reliable classification with block-wise feature selection can be performed. The relevance and benefits of the proposed approach are illustrated on both simulated and real data.",2012,Journal of Applied Statistics
Performance of Tunisian Public Hospitals: A Comparative Assessment Using the PabÃ³n Lasso Model,"Background and Objectives: Constant monitoring of healthcare organizationsâ€™ performance is an integral part of informed health policy-making. Several hospital performance assessment methods have been proposed in the literature. Pabon Lasso Model offers a fast and convenient method for comparative evaluation of hospital performance. This study aimed to evaluate the relative performance of hospitals in Tunisia, using Pabon Lasso Model. . Methods: A cross-sectional descriptive study was conducted during 2011-2012 to measure the hospitals performance in Tunisia. A sample of 40 public hospitals was surveyed. The assessed hospital performance indicators included Bed Occupation Rate (BOR), Bed Turnover Ratio (BTR), Average Length of Stay (ASL). The relevant data were collected using a standard forms approved by the Tunisian Ministry of Health. For each hospital the data were extracted from the Hospital Information Systems. The data were plotted on Pabon Lasso diagram and the performance of each hospital was analyzed by visual inspection. The data were summarized using descriptive statistical methods. Findings: Average values of 62.3, 58.1% and 3.8 days, was observed for the BTR, BOR, and ALS, respectively. While nineteen hospitals (47.5%) were located in zone 1 of the Pabon Lasso diagram, three (7.5%) were located in zone 2, eleven (27.5%) in zone 3, and seven (17.5%) in zone 4. In addition, 50% of the studied hospitals had low performance in terms of either bed occupancy rate or bed turnover ratio or both. Conclusions: This study ranked the surveyed hospitals of Tunisia with respect to their overall performance and reveals the relative strength and weakness of each hospital. The speed and convenience of Pabon Lasso measurement method facilitate constant monitoring of overall hospital performance. Moreover, large-scale application of this method, can offer an overall view of the health system performance, which could be used by policy-makers in future plantings.",2014,international journal of hospital research
Long non-coding RNA identification over mouse brain development by integrative modeling of chromatin and genomic features,"In silico prediction of genomic long non-coding RNAs (lncRNAs) is prerequisite to the construction and elucidation of non-coding regulatory network. Chromatin modifications marked by chromatin regulators are important epigenetic features, which can be captured by prevailing high-throughput approaches such as ChIP sequencing. We demonstrate that the accuracy of lncRNA predictions can be greatly improved when incorporating high-throughput chromatin modifications over mouse embryonic stem differentiation toward adult Cerebellum by logistic regression with LASSO regularization. The discriminating features include H3K9me3, H3K27ac, H3K4me1, open reading frames and several repeat elements. Importantly, chromatin information is suggested to be complementary to genomic sequence information, highlighting the importance of an integrated model. Applying integrated model, we obtain a list of putative lncRNAs based on uncharacterized fragments from transcriptome assembly. We demonstrate that the putative lncRNAs have regulatory roles in vicinity of known gene loci by expression and Gene Ontology enrichment analysis. We also show that the lncRNA expression specificity can be efficiently modeled by the chromatin data with same developmental stage. The study not only supports the biological hypothesis that chromatin can regulate expression of tissue-specific or developmental stage-specific lncRNAs but also reveals the discriminating features between lncRNA and coding genes, which would guide further lncRNA identifications and characterizations.",2013,Nucleic Acids Research
the absolute outside,"Presented at SPOR KLUBU, Berlin, this exhibition features five artists from Berlin and the UK: 
Marie von Heyl, TC McCormack, Matthew Noel Tod, Richard Sides & Oliver Zwink. Group exhibition curated by TC McCormack. The absolute outside, is a term coined by Quentin Meillassoux to describe a space that exists beyond the limits of our thoughts, of being genuinely elsewhere. He argues that thought â€˜can never get outside itself to encounter the world as it really isâ€™. All we can ever know is â€˜how the world is for us, not how it is in itself.â€™ The potential to entertain this speculative exteriority can be glimpsed in the selected work of the exhibiting artists; though their practices each have distinct concerns, all have strayed onto this speculative territory. In this spirit of being genuinely elsewhere, there is the hope that this exhibition can offer the viewer a moment of self-doubt; to see the viewer ask a simple question; where should-I-stand-in-here?",2015,
Double shrunken selection operator,"ABSTRACT The least absolute shrinkage and selection operator (LASSO) is a prominent estimator which selects significant (under some sense) features and kills insignificant ones. Indeed the LASSO shrinks features larger than a noise level to zero. In this article, we force LASSO to be shrunken more by proposing a Stein-type shrinkage estimator emanating from the LASSO, namely the Stein-type LASSO. The newly proposed estimator proposes good performance in risk sense numerically. Variants of this estimator have smaller relative MSE and prediction error, compared to the LASSO, in the analysis of prostate cancer dataset.",2019,Communications in Statistics - Simulation and Computation
Posibilidades y limites de los proveedores privados de agua : los operadores independientes en el Africa francofona,"This paper on the potential and limits of private water providers in Francophone Africa introduces the theme of the role of the private sector in service provision for the poor. In this case the private sector does not refer to large scale concessions, management contracts and mergers, themes which have recently predominated in discussions of water provision worldwide. The author focuses instead on the informal sector and on the small scale providers who have perhaps played a far more important role in service delivery, but who have rarely merited consideration from analysts and stakeholders in the water and sanitation sector. Whereas analysts in England and other first world countries are suggesting that an open market in water and sanitation service delivery might not only be possible but might also offer comparative advantages to the traditional monopolistic model, this work goes one important step further in demonstrating that the open market is a reality. Beginning with an analysis of the financial viability of umbrella or national water operations, the paper suggests that the small scale operator may enjoy an advantage when it comes to providing services in smaller settlements where the national operator with a single service delivery system rarely breaks even. The author goes on to describe the nature and types of informal water servers based on studies in Nouakchott, Mauritania; Port au Prince, Haiti; Kayes, Mali; Dakar, Senegal; Niangologo and Bobo Dioulasso in Burkina Faso. The cities studied range from populations of 12,000 to 2,000,000. The study helps us to appreciate the important role which the informal sector plays in serving poor people and brings out a final recommendation, always to carry out a careful study of the existing services systems offered by the private and informal sector before new service systems are to be offered.",1999,
Long distance transport of irradiated male Glossina palpalis gambiensis pupae and its impact on sterile male yield,"BackgroundThe application of the sterile insect technique (SIT) requires mass-production of sterile males of good biological quality. The size of the project area will in most cases determine whether it is more cost effective to produce the sterile flies locally (and invest in a mass-rearing facility) or import the sterile flies from a mass-rearing facility that is located in another country. This study aimed at assessing the effect of long distance transport of sterile male Glossina palpalis gambiensis pupae on adult male fly yield.MethodsThe male pupae were produced at the Centre International de Recherche-DÃ©veloppement sur lâ€™Elevage en zone Subhumide (CIRDES), Bobo-Dioulasso, Burkina Faso, and shipped with a commercial courier service in insulated transport boxes at a temperature of Â±10Â°C to Senegal (Â±36Â h of transport). Upon arrival in the insectary in Dakar, the pupae were transferred to an emergence room and the flies monitored for 3â€“6 days.ResultsThe results showed that the used system of isothermal boxes that contained phase change material packs (S8) managed to keep the temperature at around 10Â°C which prevented male fly emergence during transport. The emergence rate was significantly higher for pupae from batch 2 (chilled at 4Â°C for one day in the source insectary before transport) than those from batch 1 (chilled at 4Â°C for two days in the source insectary before transport) i.e. an average (Â±sd) of 76.1â€‰Â±â€‰13.2% and 72.2â€‰Â±â€‰14.3%, respectively with a small proportion emerging during transport (0.7â€‰Â±â€‰1.7% and 0.9â€‰Â±â€‰2.9%, respectively). Among the emerged flies, the percentage with deformed (not fully expanded) wings was significantly higher for flies from batch 1 (12.0â€‰Â±â€‰6.3%) than from batch 2 (10.7â€‰Â±â€‰7.5%). The amount of sterile males available for release as a proportion of the total pupae shipped was 65.8â€‰Â±â€‰13.3% and 61.7â€‰Â±â€‰14.7% for batch 1 and 2 pupae, respectively.ConclusionsThe results also showed that the temperature inside the parcel must be controlled around 10Â°C with a maximal deviation of 3Â°C to maximize the male yield.",2015,Parasites & Vectors
The Minoan Thalassocracy,"(See also References and Notes, pp. 24-25) Origin of the Minotaur 4 The Labyrinth Built to House the Minotaur 4 The Tribute Levied to Feed the Minotaur 4 The Rest of the Legend 4 The Palace at Knossos Maze-Like 5 Bull-Leaping in the Palace Courtyard?the Minotaur in the Labyrinth 5 ""Labyrinth"" Means ""Place of the Double Axe"" 6 The Legend Not Made Up from the Ruins 7 The Name Minos Absent from the Tablets 7 II. The Minoan Thalassocracy",2007,
From one crisis to another : the Swedish model in turbulent times revisited,"In the mid-2000s, my colleague Harald Niklasson and I published an article, â€˜The Swedish Model in Turbulent Timesâ€™, retracing the main developments of the Swedish model since its inception in the early 1950s up to the early 2000s (Anxo and Niklasson 2006). Our main conclusion was that, at the turn of the century, the Swedish model appeared more in line with the core components of the original Swedish model1 than during the decades 1970â€“1980, which constituted, in our views, a clear deviation. During the 1990s, the economic policy modifications towards more restrictive and anti-inflationary macroeconomic policies, the re-orientation of active labour market policies towards supply-oriented measures and the structural reforms undertaken in wage formation, tax and social protection systems suggested a revival of the Swedish model. After a period of turbulence related to the early 1990s economic crisis, the Swedish economy underwent particularly favourable economic development. Up to the current global recession, unemployment oscillated between 5 and 6 per cent, inflation was curbed and current account and public finances were restored.",2012,
RiskAnalytics: an R package for real time processing of Nasdaq and Yahoo finance data and parallelized quantile lasso regression methods,"In order to integrate and facilitate the research, calculation and analysis methods around the Financial Risk Meter (FRM) project, the R package RiskAnalytics has been developed. Its main goal is to provide data processing and parallelized quantile lasso regression methods for risk analysis based on NASDAQ data, Yahoo Finance data and some macro variables. The derived â€œRisk Analyticsâ€ can help to forecast and evaluate the systemic risk for the corresponding markets. The visualization and the up-to-date FRM can be found on http://frm.wiwi.hu-berlin.de. Supplementary R codes are published on www.quantlet.de with the keyword FRM. The RiskAnalytics package is a convenient tool with the purpose of integrating lasso penalized quantile regression methods with full solution paths and cluster computing support around the topic â€œRisk Analytics and FRMâ€.",2017,
Using LASSO to Model Interactions and Nonlinearities in Survey Data,"The LASSO and its variants have become a core part of the machine learning toolkit. Similar to OLS and logistic regression, the LASSO can be applied to continuous or binary data. The LASSO is a form of penalized regression, shrinking some coefficients exactly to zero. Because of that, it is especially useful for variable selection â€” for example, in situations where there are many potential covariates, only a few of which are likely relevant. In this article, we introduce the LASSO (and Adaptive LASSO) and show how it can be applied in situations where the researcher thinks the outcome variable is a nonlinear and/or interacted function of the covariates. Our motivating example is survey response. We provide an example showing how to model survey response using the LASSO and a polynomial expansion of the covariates. Our resulting model has better out-of-sample prediction for survey response than does a traditional logistic regression model. Example R code is provided in the supplemental materials.",2018,Survey practice
A Simulation Study to Evaluate Bayesian LASSOâ€™s Performance in Zero-Inflated Poisson (ZIP) Models,"When modelling count data, it is possible to have excessive zeros in the data in many applications. My thesis concentrates on the variable selection in zero-inflated Poisson (ZIP) models. This thesis work is motivated by Brown et al. (2015), who considered the excessive amount of zero in their data structure and the site-specific random effects, and used Bayesian LASSO method for variable selection in their post-fire tree recruitment study in interior Alaska, USA and north Yukon, Canada. However, the above study has not carried out systematic simulation studies to evaluate Bayesian LASSOâ€™s performance under different scenarios. Therefore, my thesis conducts a series of simulation studies to evaluate Bayesian LASSOâ€™s performance with respect to different setting of some simulation factors. My thesis considers three simulation factors: the number of subjects (N), the number of repeated measurements (R) and the true values of regression coefficients in the ZIP models. With different settings of the three factors, the proposed Bayesian LASSOâ€™s performance would be evaluated using three indicators: the sensitivity, the specificity and the exact fit rate. For applied practitioners, my thesis would be a useful example demonstrating under what circumstances one can expect Bayesian LASSO to have good performance in ZIP models. After sorting out the simulation results, we can find that Bayesian LASSOâ€™s performance is jointly affected by all the three simulation factors, while this method of variable selection is more reliable when the true coefficients are not close to zero. My thesis also has some limitations. Primarily, with the time limitation of my thesis, it is impossible to consider all the factors that can potentially affect the simulation results, and using other penalty forms other than L1 penalty is also left for future researchers to work on. Moreover, the current variable selection method is only for fixed effects selection while the variable selection for the mixed effect selection in ZIP models can be a direction for future work.",2016,
"Primorskyibacter sedentarius gen. nov., sp. nov., a novel member of the class Alphaproteobacteria from shallow marine sediments.","Two gram-negative, aerobic, non-pigmented, non-motile, rod-shaped bacteria, strains KMM 9015 and KMM 9018(T), were isolated from a sample of shallow sediment collected from the Sea of Japan. An analysis of the nearly complete 16S rRNA gene sequences showed that the isolates were very close to each other phylogenetically (99.9â€Š% sequence similarity) and their close relatives were Marinovum algicola FF3(T) (95.8 and 95.9â€Š%, respectively) and members of the genera Leisingera (95.7-95.1 and 95.8-95.2â€Š%), Phaeobacter (95.0-94.2 and 95.1-94.2â€Š%) and Thalassobius (96.3-94.8 and 96.2-94.7â€Š%) of the class Alphaproteobacteria. In phylogenetic trees based on 16S rRNA gene sequences, strains KMM 9015 and KMM 9018(T) were positioned as a distinct phylogenetic line adjacent to Marinovum algicola. The major isoprenoid quinone was Q-10, the polar lipids consisted of phosphatidylcholine, phosphatidylethanolamine, phosphatidylglycerol, diphosphatidylglycerol and an unknown lipid and the major fatty acid was C(18â€Š:â€Š1)Ï‰7c, followed by 11-methyl C(18â€Š:â€Š1)Ï‰7c, in both strains. The DNA G+C contents of strains KMM 9015 and KMM 9018(T) were 60.2 and 61.9 mol%, respectively. Based on distinctive phenotypic characteristics and phylogenetic analysis, strains KMM 9015 and KMM 9018(T) represent a novel species in a novel genus, for which the name Primorskyibacter sedentarius gen. nov., sp. nov. is proposed. The type strain of Primorskyibacter sedentarius is strain KMM 9018(T) (â€Š=â€ŠNRIC 0784(T) â€Š=â€ŠJCM 16874(T)).",2011,International journal of systematic and evolutionary microbiology
Two-dimensional dynamic batch processes modelling and monitoring,"Dynamics are inherent characteristics of batch processes, and the dynamic behavior may exist not only within a batch run, but also from batch to batch. Recently, a two-dimensional (2D) autoregressive model has been used to formulate the dynamic batch processes framework. For such two-dimensional (2D) dynamic batch monitoring, a statistical online process monitoring scheme is presented in this paper. The proposed method consists of two phase: on-line two-dimensional (2D) autoregressive model building and process monitoring via SPC. In the model building phase, an adaptive lasso method is used to identify the order and coefficients of this 2D autoregressive model. In the process monitoring phase, a fault can be detected by applying SPC to the model coefficients. The simulation results show that the coefficients of 2D autoregressive model are sensitive to the faults in batch processes, verifying the effectiveness of the statistical online process monitoring scheme.",2014,Proceedings of the 33rd Chinese Control Conference
Characterisation of local inflammatory response induced by Thalassophryne nattereri fish venom in a mouse model of tissue injury.,"The Thalassophryne nattereri fish venom induces a severe burning pain, oedema, and necrosis observed both clinically and experimentally. The present study was carried out in order to describe the pattern of local acute inflammatory response after T. nattereri venom injection. Our findings show that the edematogenic response induced by T. nattereri venom in footpad of mice was dose- and time dependent, and remained significantly elevated over 48 h after injection. Analysis of footpad homogenates were tested for the presence of TNF-alpha, IL-1beta and IL-6, and demonstrated augmented levels of these cytokines. Our results showed that the injection of venom developed an inadequate cellular inflammatory response evidenced by poor infiltration of mononuclear cells, preceded by decreased number of these cells in peripheral blood. In contrast, we observed an early intense recruitment of neutrophil to peritoneal cavity, accompanied by a significant decrease in the number of mononuclear cells. A drastic increase in the total amount of cells, mainly in neutrophils, followed by mononuclear cell recruitment was observed 24 h. In addition, we also demonstrated that T. nattereri venom affects the viability of mononuclear cells (J774A1) in culture. We conclude that the scarcity of inflammatory cellular influx into local lesions (intraplantar) induced by T. nattereri venom could be a consequence of an impaired blood flow in venules at injured tissue and cytotoxic effect of the venom on inflammatory cells can contribute to this impairment.",2003,Toxicon : official journal of the International Society on Toxinology
An empirical approach to model selection through validation for censored survival data,"Medical prognostic models can be designed to predict the future course or outcome of disease progression after diagnosis or treatment. The existing variable selection methods may be precluded by full model advocates when we build a prediction model owing to their estimation bias and selection bias in right-censored time-to-event data. If our objective is to optimize predictive performance by some criterion, we can often achieve a reduced model that has a little bias with low variance, but whose overall performance is enhanced. To accomplish this goal, we propose a new variable selection approach that combines Stepwise Tuning in the Maximum Concordance Index (STMC) with Forward Nested Subset Selection (FNSS) in two stages. In the first stage, the proposed variable selection is employed to identify the best subset of risk factors optimized with the concordance index using inner cross-validation for optimism correction in the outer loop of cross-validation, yielding potentially different final models for each of the folds. We then feed the intermediate results of the prior stage into another selection method in the second stage to resolve the overfitting problem and to select a final model from the variation of predictors in the selected models. Two case studies on relatively different sized survival data sets as well as a simulation study demonstrate that the proposed approach is able to select an improved and reduced average model under a sufficient sample and event size compared with other selection methods such as stepwise selection using the likelihood ratio test, Akaike Information Criterion (AIC), and lasso. Finally, we achieve better final models in each dataset than their full models by most measures. These results of the model selection models and the final models are assessed in a systematic scheme through validation for the independent performance.",2011,Journal of biomedical informatics
Instance-Dependent Cost-Sensitive Learning for Detecting Transfer Fraud,"Card transaction fraud is a growing problem affecting card holders worldwide. Financial institutions increasingly rely upon data-driven methods for developing fraud detection systems, which are able to automatically detect and block fraudulent transactions. From a machine learning perspective, the task of detecting fraudulent transactions is a binary classification problem. Classification models are commonly trained and evaluated in terms of statistical performance measures, such as likelihood and AUC, respectively. These measures, however, do not take into account the actual business objective, which is to minimize the financial losses due to fraud. Fraud detection is to be acknowledged as an instance-dependent cost-sensitive classification problem, where the costs due to misclassification vary between instances, and requiring adapted approaches for learning a classification model. In this article, an instance-dependent threshold is derived, based on the instance-dependent cost matrix for transfer fraud detection, that allows for making the optimal cost-based decision for each transaction. Two novel classifiers are presented, based on lasso-regularized logistic regression and gradient tree boosting, which directly minimize the proposed instance-dependent cost measure when learning a classification model. The proposed methods are implemented in the R packages cslogit and csboost, and compared against state-of-the-art methods on a publicly available data set from the machine learning competition website Kaggle and a proprietary card transaction data set. The results of the experiments highlight the potential of reducing fraud losses by adopting the proposed methods.",2020,
Chase Decode All Constituent Codewords 405 of a Product Code in One Dimension Find All Valid Soft Output Values in the Entire Product Code 41,"(76) Inventors: Vipul A. Desai, Palatine, IL (US); (57) ABSTRACT Yufei W. Blankenship, Streamwood, IL (US); Brian K. Classon, Palatine, IL (US) This abstract is not to be considered limiting, Since other embodiments may deviate from the features described in this abstract. A method and Structure of processing Soft infor mation in a block code decoder, includes a Soft-input Soft C d Address: MSSROA. Nes output decoder (910) receiving a length n soft input vector, LA, creating a binary vector Y corresponding to the length in Soft E.it."" ALGONQUINROAD input vector, hard decoding each linear function X of Y and SCHAUMBURG IL 60196 a test pattern Z of one or more test patterns, wherein if the 9 hard decoding is Successful a codeword produced by the (21) Appl. No.: 10/899,376 hard decoding of the linear function X is added to a Set S, removing redundant codewords in S to form a reduced set S (22) Filed: Jul. 26, 2004 (520), and an extrinsic value estimator (1140) generating in Soft outputs based on c estimated Soft output values and Publication Classification (n-c) non-estimated soft output values (530) wherein the c estimated Soft output values are computed from one or more (51) Int. Cl. positions of the length in Soft input vector and one or more H03M I3/00 (2006.01) codewords in the set S"".",2017,
Alcoholconsumptionand the riskof myocardial infarction inwomen,"Study objective-Toinvestigate the relationship betweenalcohol consumption andtheriskofacutemyocardial infarction in women. Design-Thiswas a hospital based,casecontrol studycarried outbetween1983and 1990. Mainoutcomemeasureswereaverage daily numberofdrinksofvarious alcoholic beveragesconsumedand corresponding multivariate relative riskestimates and95% confidence intervals (CI) Setting-A network including majorteaching andgeneral hospitals innorthern Italy. Subjects-Cases were298womenwithacute myocardial infarction but no historyof ischaemic heartdisease and controls 685 womenadmitted tohospital foracuteconditions, unrelated toalcohol consumption orto knownorsuspected riskfactors forischaemic heartdisease. Measurements and main resultsComparedwithnon-drinkers, theestimated relative risks (RR)were0-7(95%CI0-5,1.0) foronedrinkorless perday,0-8(95%CI0-6, 1-2)formorethanonetotwodrinks perday, 1-4(95%CI0-8, 23)formorethantwoto three, and2-6(95%CI15,46)formorethan threedrinksperday.Theseestimates were consistent across strataof selected covariates, including age,education, and smoking. Allowance formajoridentified risk factors formyocardial infarction didnot materially modifytheriskestimate forlight drinkers (RR 07,95% CI 05,1.1), but reduced theRR inheavydrinkers to1-8(95% CI0*9, 3-5). Conclusions-This studyindicatesthat women whodonotdrinkalcohol havearisk ofmyocardial infarction thatishigher than thatoflight drinkers, although theprotection oflight drinking wasnotsignificant. Among drinkers, however, therewas a significant direct trendinriskwithdose.Theraised risks inheavydrinkers mayreflect arealassociationorresult fromotherunfavourable characteristics or habitsassociated withhigh alcohol consumption.",1993,
Rhizome elongation and seagrass clonal growth,"A compilation of published and original data on rhizome morphometry, horizontal and vertical elongation rates and branching patterns for 27 seagrass species developing in 192 seagrass stands allowed an examination of the variability of seagrass rhizome and clonal growth programmes across and within species. Seagrass horizontal rhizomes extend at rates ranging between 1.2 and 574 cm yr(-1), develop a branch, with an angle from 19 to 72 degrees, for every 6 to 1800 horizontal internodes, and add a new shoot for every 1.1 to 7.5 cm of rhizome produced. Vertical rhizomes elongate at rates between 0.1 and 34 cm yr(-1) and the probability that they will branch varies over 3 orders of magnitude. Much (between 40 and 173%) of the variability of seagrass horizontal rhizome and clonal growth programmes is species-specific, largely (21 to 63% of the variance) associated with differences in size among species, although seagrasses also show important intraspecific variability. The broad repertoire of seagrass rhizome and clonal growth programmes explains the different rates and efficiency at which the species occupy space. The implications of specific growth programmes for space occupation were examined by simulating the development of seagrass rhizome networks of 3 seagrass species encompassing the range of horizontal rhizome growth (Halophila ovalis, Thalassodendron ciliatum, Posidonia oceanica). This exercice showed that small, fast-growing species achieve a much lower spread efficiency (m(2) of ground covered m(-1) of rhizome produced) than the large, slow-growing species. Differences in rhizome branching angles greatly constrained the form of rhizome networks. The results show that clonal growth patterns are a primary component of seagrass productivity and, therefore, the key to the development and maintenance of seagrass meadows. [KEYWORDS: seagrasses; clonal growth; plant allometry; rhizome diameter; spacer length; rhizome elongation; branching rate and angle Herb glechoma-hederacea; nodosa ucria ascherson; cymodocea- nodosa; thalassia-testudinum; posidonia-oceanica; syringodium- filiforme; population-dynamics; experimental burial; branching patterns; vertical growth]",1998,Marine Ecology Progress Series
Hedge Fund Replication Using Shrinkage Methodologies,"In this article, the authors replicate major Hedge Fund Research, Inc., style indexes using alternative methods. These methods include stepwise regression, ridge regression, the lasso method, the elastic net, dynamic linear regression, principal component regression, and partial least squares regression. They find generally that, across the major hedge fund style indexes, the best replication results are obtained with methods that employ shrinkage of parameters.",2014,The Journal of Alternative Investments
Lasso for hierarchical polynomial models.,"In a polynomial regression model, the divisibility conditions implicit in polynomial hierarchy give way to a natural construction of constraints for the model parameters. We use this principle to derive versions of strong and weak hierarchy and to extend existing work in the literature, which at the moment is only concerned with models of degree two. We discuss how to estimate parameters in lasso using standard quadratic programming techniques and apply our proposal to both simulated data and examples from the literature. The proposed methodology compares favorably with existing techniques in terms of low validation error and model size.",2020,arXiv: Computation
Dimension reduction of high-dimensional dataset with missing values,"Nowadays, datasets containing a very large number of variables or features are routinely generated in many fields. Dimension reduction techniques are usually performed prior to statistically analyzing these datasets in order to avoid the effects of the curse of dimensionality. Principal component analysis is one of the most important techniques for dimension reduction and data visualization. However, datasets with missing values arising in almost every field will produce biased estimates and are difficult to handle, especially in the high dimension, low sample size settings. By exploiting a Lasso estimator of the population covariance matrix, we propose to regularize the principal component analysis to reduce the dimensionality of dataset with missing data. The Lasso estimator of covariance matrix is computationally tractable by solving a convex optimization problem. To illustrate the effectiveness of our method on dimension reduction, the principal component directions are evaluated by the metrics of Frobenius norm and cosine distance. The performances are compared with other incomplete data handling methods such as mean substitution and multiple imputation. Simulation results also show that our method is superior to other incomplete data handling methods in the context of discriminant analysis of real world high-dimensional datasets.",2019,Journal of Algorithms and Computational Technology
Some Properties concerning Coefficients of Double Fourier Series,"Let f(x,y)be an integrable function,periodic with period 2Ï€ in eachvariable.The object of this paper is to discuss some properties concerningcoefficients of double Fourier series of the class of functions of boundedvariation in the sense of Hardy-Krause(c.f.Clarkson,J.A.and Adams,C.R.,Trans.of the Amer.Math.Soc.,35(1933),824â€”854),or of the classof absolutely continuous functions in the sense of Gergen(c.f.Gergen,J.J.,Trans.of the Amer.Math.Soc.,35(1933),27â€”63).We shall say func-tions of bounded variations or absolutely continuous functions for short.The following results have been established:Theorem 1.The function(?) (1)defined in the fundamental region[0,2Ï€;0,2Ï€]is continuous and of bound-ed variation,but it is not absolutely continuous.Theorem 2.The Fourier coefficients of a function which is continuousand of bounded variation should satisfy(?) (2)where(?).The fact that the condition(2)is not sufficient for a function ofbounded variation to be also continuous has been shown by an example.On the other hand,we have the following theorem:Theorem 3.If the Fourier coefficients of a function f(x,y)of boundedvariation satisfy(2),thenf(x+h,y+k)-f(x-h,y+k)-f(x+h,y-k)++f(x-h,y-k)â†’ (3)as hâ†’+0,kâ†’+0.",1957,Acta Mathematica Sinica
LinkProt: a database collecting information about biological links,"Protein chains are known to fold into topologically complex shapes, such as knots, slipknots or complex lassos. This complex topology of the chain can be considered as an additional feature of a protein, separate from secondary and tertiary structures. Moreover, the complex topology can be defined also as one additional structural level. The LinkProt database (http://linkprot.cent.uw.edu.pl) collects and displays information about protein links - topologically non-trivial structures made by up to four chains and complexes of chains (e.g. in capsids). The database presents deterministic links (with loops closed, e.g. by two disulfide bonds), links formed probabilistically and macromolecular links. The structures are classified according to their topology and presented using the minimal surface area method. The database is also equipped with basic tools which allow users to analyze the topology of arbitrary (bio)polymers.",2017,Nucleic Acids Research
