title,abstract,year,journal
The LASSO Risk for Gaussian Matrices,"We consider the problem of learning a coefficient vector xÎ¿ âˆˆ RN from noisy linear observation y = Axo + âˆˆ Rn. In many contexts (ranging from model selection to image processing), it is desirable to construct a sparse estimator xÌ‚. In this case, a popular approach consists in solving an â„“1-penalized least-squares problem known as the LASSO or basis pursuit denoising. For sequences of matrices A of increasing dimensions, with independent Gaussian entries, we prove that the normalized risk of the LASSO converges to a limit, and we obtain an explicit expression for this limit. Our result is the first rigorous derivation of an explicit formula for the asymptotic mean square error of the LASSO for random instances. The proof technique is based on the analysis of AMP, a recently developed efficient algorithm, that is inspired from graphical model ideas. Simulations on real data matrices suggest that our results can be relevant in a broad array of practical applications.",2012,IEEE Transactions on Information Theory
An Evaluation of Sustainable Seafood Guides: Implications for Environmental Groups and the Seafood Industry,"Cathy A. Roheim is a professor in the Department of Environmental and Natural Resource Economics at the University of Rhode Island, Kingston, RI 02881 USA (email: crw@uri.edu). The author acknowledges funding from Kingâ€™s Seafood Company and Rhode Island Sea Grant and assistance from Michelle Armsby, graduate research assistant and URI Sustainable Seafood Fellow, in the completion of this research. Thalassorama",2009,
A novel DNA damage response signature of IDH-mutant grade II and grade III astrocytoma at transcriptional level,"The WHO classification for IDH-mutant grade II and grade III astrocytoma may not be as prognostically meaningful as expected. We aimed to develop a novel classification system based on the DNA damage response signature. We developed the gene signature of DNA damage response with 115 samples from The Cancer Genome Atlas (TCGA) database. The dataset from Chinese Glioma Genome Atlas (CGGA) database with 41 samples was used as the validation set. Lasso Cox regression model was applied for selection of the best signature. Gene set enrichment analysis (GSEA) and gene ontology (GO) analysis were implemented to reveal its biological phenotype. A two-gene DNA damage response signature (RAD18, MSH2) was developed using the lasso Cox regression model based on the TCGA dataset. Its prognostic efficiency was validated in the CGGA cohort. The result of Cox regression analysis showed that the signature has a better predictive accuracy than the WHO grade. The risk score was an independent prognostic factor for the overall survival of the IDH-mutant grade II and grade III astrocytoma. GSEA and GO analysis confirmed enhanced processes related to DNA damage response in high-risk group. We developed a two-gene signature which can effectively predict the prognosis of patients with IDH-mutant grade II and grade III astrocytoma. It suggests a novel classification of astrocytoma with better prognostic accuracy based on the expression of DNA damage response genes.",2020,Journal of Cancer Research and Clinical Oncology
Bacteria on and within leaf blade epidermal cells of the seagrass Thalassodendron ciliatum (Forssk.) Den Hartog,A dense bacteria community covered the tips of mature green leaves of Thalassodendron ciliatum (Forssk.) Den Hartog. Epibacteria were often embedded in an amorphous matrix and were frequently arranged with their long axes at right angles to the leaf surface. Many epidermal cells at the leaf tip showed signs of decomposition. Parts of the outer wall and cuticle of these cells were disrupted and bacteria with marked cellulolytic activity could be seen penetrating into the walls. The invasive bacteria occurred within tunnels in the walls. Some degree of selective degradation occurred: an inner electron-dense wall layer not being as readily degraded as the rest of the wall.,1992,Aquatic Botany
Adaptive Estimation of Multivariate Regression with Hidden Variables.,"This paper studies the estimation of the coefficient matrix $\Ttheta$ in multivariate regression with hidden variables, $Y = (\Ttheta)^TX + (B^*)^TZ + E$, where $Y$ is a $m$-dimensional response vector, $X$ is a $p$-dimensional vector of observable features, $Z$ represents a $K$-dimensional vector of unobserved hidden variables, possibly correlated with $X$, and $E$ is an independent error. The number of hidden variables $K$ is unknown and both $m$ and $p$ are allowed but not required to grow with the sample size $n$. Since only $Y$ and $X$ are observable, we provide necessary conditions for the identifiability of $\Ttheta$. The same set of conditions are shown to be sufficient when the error $E$ is homoscedastic. Our identifiability proof is constructive and leads to a novel and computationally efficient estimation algorithm, called HIVE. The first step of the algorithm is to estimate the best linear prediction of $Y$ given $X$ in which the unknown coefficient matrix exhibits an additive decomposition of $\Ttheta$ and a dense matrix originated from the correlation between $X$ and the hidden variable $Z$. Under the row sparsity assumption on $\Ttheta$, we propose to minimize a penalized least squares loss by regularizing $\Ttheta$ via a group-lasso penalty and regularizing the dense matrix via a multivariate ridge penalty. Non-asymptotic deviation bounds of the in-sample prediction error are established. Our second step is to estimate the row space of $B^*$ by leveraging the covariance structure of the residual vector from the first step. In the last step, we remove the effect of hidden variable by projecting $Y$ onto the complement of the estimated row space of $B^*$. Non-asymptotic error bounds of our final estimator are established. The model identifiability, parameter estimation and statistical guarantees are further extended to the setting with heteroscedastic errors.",2020,arXiv: Statistics Theory
Using Supervised Machine Learning and Empirical Bayesian Kriging to reveal Correlates and Patterns of COVID-19 Disease outbreak in sub-Saharan Africa: Exploratory Data Analysis,"Introduction: Coronavirus disease 2019 (COVID-19) is an emerging infectious disease that was first reported in Wuhan, China, and has subsequently spread worldwide. Knowledge of coronavirus-related risk factors can help countries build more systematic and successful responses to COVID-19 disease outbreak. Here we used Supervised Machine Learning and Empirical Bayesian Kriging (EBK) techniques to reveal correlates and patterns of COVID-19 Disease outbreak in sub-Saharan Africa (SSA). Methods: We analyzed time series aggregate data compiled by Johns Hopkins University on the outbreak of COVID-19 disease across SSA. COVID-19 data was merged with additional data on socio-demographic and health indicator survey data for 39 of SSA 48 countries that reported confirmed cases and deaths from coronavirus between February 28, 2020 through March 26, 2020. We used supervised machine learning algorithm, Lasso for variable selection and statistical inference. EBK was used to also create a raster estimating the spatial distribution of COVID-19 disease outbreak. Results: The lasso Cross-fit partialing out predictive model ascertained seven variables significantly associated with the risk of coronavirus infection (i.e. new HIV infections among pediatric, adolescent, and middle-aged adult PLHIV, time (days), pneumococcal conjugate-based vaccine, incidence of malaria and diarrhea treatment). Our study indicates, the doubling time in new coronavirus cases was 3 days. The steady three-day decrease in coronavirus outbreak rate of change (ROC) from 37% on March 23, 2020 to 23% on March 26, 2020 indicates the positive impact of countries' steps to stymie the outbreak. The interpolated maps show that coronavirus is rising every day and appears to be severely confined in South Africa. In the West African region (i.e. Burkina Faso, Ghana, Senegal, CotedIviore, Cameroon, and Nigeria), we predict that new cases and deaths from the virus are most likely to increase. Interpretation: Integrated and efficiently delivered interventions to reduce HIV, pneumonia, malaria and diarrhea, are essential to accelerating global health efforts. Scaling up screening and increasing COVID-19 testing capacity across SSA countries can help provide better understanding on how the pandemic is progressing and possibly ensure a sustained decline in the ROC of coronavirus outbreak. Funding: Authors were wholly responsible for the costs of data collation and analysis.",2020,
Effects of the herbicide LASSO MTX (alachlor 42% W/V) on biometric parameters and liver biomarkers in the common carp (Cyprinus carpio),"Abstract The aim of the study was to evaluate the effect of subchronic exposure to the herbicide LASSO MTX (alachlor 42% W/V) on biometric parameters and important liver biomarkers in the common carp ( Cyprinus carpio ). One year old fish were exposed for 28 days to LASSO MTX added to the tank water at concentrations of 240 and 2400Â Î¼gÂ L âˆ’1 . The exposure did not affect fish biometric parameters. Glutathione- S -tranferase (GST) activity in liver (hepatopancreas) remained unchanged in exposed fish when compared to controls. However, significant induction of total cytochrome P 450 (CYP 450), ethoxyresorufin- O -deethylase (EROD) activity and elevated glutathione (GSH) in liver of exposed fish were detected.",2009,Pesticide Biochemistry and Physiology
Sparse Hilbert Schmidt Independence Criterion and Surrogate-Kernel-Based Feature Selection for Hyperspectral Image Classification,"Designing an effective criterion to select a subset of features is a challenging problem for hyperspectral image classification. In this paper, we develop a feature selection method to select a subset of class discriminant features for hyperspectral image classification. First, we propose a new class separability measure based on the surrogate kernel and Hilbert Schmidt independence criterion in the reproducing kernel Hilbert space. Second, we employ the proposed class separability measure as an objective function and we model the feature selection problem as a continuous optimization problem using LASSO optimization framework. The combination of the class separability measure and the LASSO model allows selecting the subset of features that increases the class separability information and also avoids a computationally intensive subset search strategy. Experiments conducted with three hyperspectral data sets and different experimental settings show that our proposed method increases the classification accuracy and outperforms the state-of-the-art methods.",2017,IEEE Transactions on Geoscience and Remote Sensing
Evaluation of genotoxic and cytotoxic properties of pesticides employed in Italian agricultural practices.,"In a program coordinated by the Italian Ministry of Works, we tested in vitro four pesticides widely employed in a developed agricultural region of central Italy. The four commercial agents were chosen on the basis of their diffusion in agricultural practice, knowledge of their active principle(s), and scant availability of data concerning their toxic and genotoxic activity. The agents were Cirtoxin, Decis, Tramat Combi (TC), and Lasso Micromix (LM). All substances were tested in three in vitro systems: Chinese hamster ovary (CHO) cells, a metabolically competent hamster cell line (Chinese hamster epithelial liver; CHEL), and root tips of Vicia faba (VF). The cytotoxic and genotoxic end points challenged were micronuclei and root tip length (RTL) in VF and mitotic index (MI), proliferation index (PI), cell survival (CS), cell growth (CG), cell cycle length (CCL), sister chromatid exchanges, chromosomal aberrations, and single-cell gel electrophoresis, or comet assay, in CHEL and CHO cells. Tested doses ranged from the field dose up to 200x the field dose to take into account accumulation effects. On the whole, tested agents appear to induce genotoxic damage only at subtoxic or toxic doses, indicating a low clastogenic risk. MI, PI, CS, CG, RTL, and CCL appear to be the less sensitive end points, showing no effects in the presence of a clear positive response in some or all of the other tests. Using cytogenetic tests, we obtained positive results for TC and LM treatments in CHO but not in CHEL cells. These data could be accounted for by postulating a detoxifying activity exerted by this cell line. However, cytogenetic end points appear to be more sensitive than those referring to cytotoxicity.",2000,Environmental research
Variable selection in rank regression for analyzing longitudinal data,"In this paper, we consider variable selection in rank regression models for longitudinal data. To obtain both robustness and effective selection of important covariates, we propose incorporating shrinkage by adaptive lasso or SCAD in the Wilcoxon dispersion function and establishing the oracle properties of the new method. The new method can be conveniently implemented with the statistical software R. The performance of the proposed method is demonstrated via simulation studies. Finally, two datasets are analyzed for illustration. Some interesting findings are reported and discussed.",2018,Statistical Methods in Medical Research
Factorization Machine Based Service Recommendation on Heterogeneous Information Networks,"With the wide adoption of SOA (Service Oriented Architecture), a massive amount of innovative applications emerge in the Internet. One of the popular representations is mashup. It is a new application created by combining different kinds of services. There exist multiple typed objects (e.g., mashup, service, category, tag, provider and description) and relations (e.g., compose and composed by relation between mashups and services, provide and provided by relation between services and providers), which constitute a heterogeneous information network (HIN) naturally. Several approaches already exist for recommending services for users but they are limited to consider only one or two kinds of relations between mashups and services. To apply the rich semantics and enhance recommendation performance, in this paper, we propose a Factorization Machine based service Recommendation approach, called FMRec, on HIN. Specifically, we firstly apply counting-based similarities for meta paths to capture the multiple semantic meanings between mashups and services. And then, we employ matrix factorization to the similarity matrices built by different kinds of meta paths to obtain the mashup latent features and service latent features. Finally, we leverage factorization machine model with a group lasso regularization term to learn the ratings between mashups and services. Comprehensive experiments are conducted on a real-world dataset, indicating that our proposed service recommendation approach significantly improves the quality of the recommendation results compared with existing methods.",2018,2018 IEEE International Conference on Web Services (ICWS)
Evaluation of machine learning algorithms and structural features for optimal MRI-based diagnostic prediction in psychosis,"A relatively large number of studies have investigated the power of structural magnetic resonance imaging (sMRI) data to discriminate patients with schizophrenia from healthy controls. However, very few of them have also included patients with bipolar disorder, allowing the clinically relevant discrimination between both psychotic diagnostics. To assess the efficacy of sMRI data for diagnostic prediction in psychosis we objectively evaluated the discriminative power of a wide range of commonly used machine learning algorithms (ridge, lasso, elastic net and L0 norm regularized logistic regressions, a support vector classifier, regularized discriminant analysis, random forests and a Gaussian process classifier) on main sMRI features including grey and white matter voxel-based morphometry (VBM), vertex-based cortical thickness and volume, region of interest volumetric measures and wavelet-based morphometry (WBM) maps. All possible combinations of algorithms and data features were considered in pairwise classifications of matched samples of healthy controls (N = 127), patients with schizophrenia (N = 128) and patients with bipolar disorder (N = 128). Results show that the selection of feature type is important, with grey matter VBM (without data reduction) delivering the best diagnostic prediction rates (averaging over classifiers: schizophrenia vs. healthy 75%, bipolar disorder vs. healthy 63% and schizophrenia vs. bipolar disorder 62%) whereas algorithms usually yielded very similar results. Indeed, those grey matter VBM accuracy rates were not even improved by combining all feature types in a single prediction model. Further multi-class classifications considering the three groups simultaneously made evident a lack of predictive power for the bipolar group, probably due to its intermediate anatomical features, located between those observed in healthy controls and those found in patients with schizophrenia. Finally, we provide MRIPredict (https://www.nitrc.org/projects/mripredict/), a free tool for SPM, FSL and R, to easily carry out voxelwise predictions based on VBM images.",2017,PLoS ONE
List of Contributors.,"Fabrizio Balassone, Bank of Italy, Rome, Italy Peter Bernholz, Centre of Economics and Business (WWZ), University of Basel, Switzerland Charles B. Blankart, Humboldt University, Berlin, Germany Geoffrey Brennan, RSSS, Australian National University, Canberra, Australia Giuseppe Eusepi, University of Rome â€˜La Sapienzaâ€™, Italy Daniele Franco, Bank of Italy, Rome, Italy Sergio Ginebri, University of Molise, Campobasso, Italy Bernard Grofman, University of California, Irvine, USA Barbara Krug, Erasmus University of Rotterdam, The Netherlands Luciano Marcello Milone, University of Rome â€˜La Sapienzaâ€™, Italy Dennis C. Mueller, University of Vienna, Austria Marcella Mulino, University of Lâ€™Aquila, Italy Pier Carlo Padoan, International Monetary Fund, Washington, DC, USA Martin Paldam, Aarhus University, Denmark Christoph A. Schaltegger, Swiss Federal Tax Administration, Bern, Switzerland Friedrich Schneider, Johannes Kepler University of Linz, Austria Rolf Strauch, European Central Bank, Frankfurt a.M., Germany Gordon Tullock, George Mason University, Arlington, VA, USA Giuseppe Vitaletti, University of Macerata, Italy",2016,The International journal of health planning and management
On the Q-linear Convergence of a Majorized Proximal ADMM for Convex Composite Programming and Its Applications to Regularized Logistic Regression,"This paper aims to study the convergence rate of a majorized alternating direction method of multiplier with indefinite proximal terms (iPADMM) for solving linearly constrained convex composite optimization problems. We establish the Q-linear rate convergence theorem for 2-block majorized iPADMM under mild conditions. Based on this result, the convergence rate analysis of symmetric Gaussian-Seidel based majorized ADMM, which is designed for solving multi-block composite convex optimization problems, are given. We apply the majorized iPADMM to solve three types of regularized logistic regression problems: constrained regression, fused lasso and overlapping group lasso. The efficiency of majorized iPADMM are demonstrated on both simulation experiments and real data sets.",2017,
"Energy-conserving , Linear-scaling Quantum Molecular Dynamics","Marc J. Cawkwell, Anders M. N. Niklasson, T-1 Molecular dynamics (MD) simulations are used heavily in materials science, chemistry, and biology to study the evolution of structures, defects, and non-equilibrium phenomena at the atomic scale. In an MD simulation atoms move over a number of finite time steps according to the force acting on them. These forces are computed from the interatomic potential that gives the potential energy of the system as a function of the relative positions of all of the atoms. The ability of a simulation to capture the system of interest with high fidelity is determined almost entirely by the physical accuracy of the interatomic potential. It is well established that explicitly quantum mechanical models provide the most accurate descriptions of bonding, but it is not possible to employ these methods in large-scale simulations owing to their prohibitive computational cost.",2012,
Differential dependency network analysis to identify condition-specific topological changes in biological networks,"MOTIVATION
Significant efforts have been made to acquire data under different conditions and to construct static networks that can explain various gene regulation mechanisms. However, gene regulatory networks are dynamic and condition-specific; under different conditions, networks exhibit different regulation patterns accompanied by different transcriptional network topologies. Thus, an investigation on the topological changes in transcriptional networks can facilitate the understanding of cell development or provide novel insights into the pathophysiology of certain diseases, and help identify the key genetic players that could serve as biomarkers or drug targets.


RESULTS
Here, we report a differential dependency network (DDN) analysis to detect statistically significant topological changes in the transcriptional networks between two biological conditions. We propose a local dependency model to represent the local structures of a network by a set of conditional probabilities. We develop an efficient learning algorithm to learn the local dependency model using the Lasso technique. A permutation test is subsequently performed to estimate the statistical significance of each learned local structure. In testing on a simulation dataset, the proposed algorithm accurately detected all the genes with network topological changes. The method was then applied to the estrogen-dependent T-47D estrogen receptor-positive (ER+) breast cancer cell line datasets and human and mouse embryonic stem cell datasets. In both experiments using real microarray datasets, the proposed method produced biologically meaningful results. We expect DDN to emerge as an important bioinformatics tool in transcriptional network analyses. While we focus specifically on transcriptional networks, the DDN method we introduce here is generally applicable to other biological networks with similar characteristics.


AVAILABILITY
The DDN MATLAB toolbox and experiment data are available at http://www.cbil.ece.vt.edu/software.htm.",2009,Bioinformatics
ImpactofHealthInsuranceonHealthCareTreatmentandCostin Vietnam:AHealthCapabilityApproachtoFinancialProtection,"Improvement Initiatives Should Be Con-sidered Research: Proposed Criteria andPotential Implications,â€ Journal of theAmericanMedicalAssociation283,no.17(2000): 2275---2280; Jeffrey Brainard,â€œWhen Is Research Really Research?â€Chronicle of Higher Education, November26, 2004, http://chronicle.com/weekly/v51/i14/14a02101.htm (accessed May2, 2012); M.A. Baily, â€œEthical QualityImprovement (QI) and IRB Review,â€ ab-stract for the American Public HealthAssociation 133rd Annual Meeting andExposition, November 5---9, 2005, NewOrleans, LA.19. Brainard, â€œWhen Is Research ReallyResearch?â€; Jeff Cohen, former OHRPofï¬cial, oral communication, August 1,2005.20. Mark B. McClellan and Sean R.Tunis, â€œMedicare Coverage of ICDs,â€ NewEngland Journal of Medicine 352, no. 3(2005): 222---224.21. Cohen, â€œQuestioning Privacy Pro-tections in Research.â€22. L. Shopes, 2004 Oral History Asso-ciation Meeting, Comments for Round-table on â€œOral History Ethics,â€ October 3,2004, Portland, Ore; Cary Nelson, â€œCanE.T. Phone Home? The Brave NewWorld of University Surveillance,â€ Aca-deme 89, no. 5 (2003): 210, availableat: http://aaup.org/AAUP/pubsres/academe/2003/SO/Feat/nels.htm,accessed May 2, 2012. For analogousarguments from journalism, see WaltHarrington, â€œWhat Journalism Can OfferEthnography,â€ Qualitative Inquiry 9, no. 1(2003): 100---101; American HistoricalAssociation, â€œStatement on Standards ofProfessional Conduct,â€ approved by Pro-fessional Division, December 2, 2004,and adopted by Council January 6, 2005,http://www.historians.org/pubs/Free/ProfessionalStandards.cfm (accessed June9, 2005).23. Christopher Shea, â€œDonâ€™t Talk to theHumans: The Crackdown on Social Sci-ence Research,â€ Lingua Franca (Septem-ber 2000): 34; Nelson, â€œCan E.T. PhoneHome?â€ 211, 216.24. Michael Frisch, University at Buffalo,State University of New York, GeneralComment on HHS-OPHS-2011-0005-0001, November 10, 2011, http://www.regulations.gov/#!documentDetail;D=HHS-OPHS-2011-0005-0751 (accessedMay 2, 2012).25. Fairchild et al., Searching Eyes,233---237.26. Marin Weiss, March of Dimes,Comments on NPRM: Standards forPrivacy of Individually Identiï¬ableHealth Information, use and Disclo-sures for Public Health Activities,Comment #17685, February 17,2000, as cited in Fairchild et al.,Searching Eyes, 321.27. M.A. Rothstein, â€œImproving Privacyin Research by Eliminating InformedConsent? IOM Report Misses the Mark,â€JournalofLaw,MedicineandEthics37,no.3 (2009): 507---512.",2012,
"Incidence, risk factors, and outcome of traumatic tricuspid regurgitation after percutaneous ventricular lead removal.","OBJECTIVES
This study sought to evaluate the incidence, risk factors, and outcome of traumatic tricuspid regurgitation (TTR) induced by percutaneous removal of chronically implanted transvenous leads.


BACKGROUND
Although lead removal using modern tools has been shown to be highly effective and safe, TTR has not been systematically evaluated.


METHODS
All patients undergoing ventricular lead removal at our center were studied. Lead removal was performed by simple traction, laser sheath, and/or lasso technique. Presence of a new TTR after removal was assessed by transthoracic echocardiography. Pre-defined clinical and technical parameters were studied for their association with TTR. Patients were followed up by outpatient visits.


RESULTS
We removed 237 ventricular leads in 208 patients. Median time from lead implantation was 46.4 months (range 0.7 to 260.5 months). A TTR occurred in 19 patients (9.1%), severe in 14. Three independent risk factors of TTR were found: use of laser sheath (p = 0.004), use of both laser sheath and lasso (p = 0.02), and female sex (p = 0.02). After a follow-up of 4,130 person-months (median 17.9 months), 5 TTR patients were medically treated for new right-sided heart failure symptoms, 2 had undergone surgical repair of the tricuspid valve, and 6 had died (2 from heart failure and 4 from noncardiac causes). Right-sided heart failure occurred only in patients with severe TTR.


CONCLUSIONS
This study found that TTR is not uncommon after percutaneous lead removal. It is strongly associated with the use of additional tools beyond simple traction and also with female sex. In the long term, right-sided heart failure is frequent in patients with severe TTR.",2009,Journal of the American College of Cardiology
Comparison of Regularized Regression Methods for ~Omics Data,"Background: In this study, we compare methods that can be used to relate a phenotypic trait of interest to an ~omics data set, where the number or variables outnumbers by far the number of samples. Methods: We apply univariate regression and different regularized multiple regression methods: ridge regression (RR), LASSO, elastic net (EN), principal components regression (PCR), partial least squares regression (PLS), sparse partial least squares regression (SPLS), support vector regression (SVR) and random forest regression (RF). These regression methods were applied to a data set from a potato mapping population, where we predict potato flesh colour from a metabolomics data set. Results: We compare the methods in terms of the mean square error of prediction of the trait, goodness of fit of the models, and the selection and ranking of the metabolites. In terms of the prediction error, elastic net performed better than the other methods. Different numbers of variables are selected by the methods that allow variable selection but seven variables were in common between LASSO, EN and SPLS. SPLS performed better than EN with respect to the selection of grouped correlated variables. Conclusions: Four out of these seven variables selected by LASSO, EN, SPLS were putatively identified as carotenoid derived compounds; since the carotenoid pathway is important for flesh colour of potato, this indicates that meaningful compounds are selected. We developed a web application that can perform all the described methods, and that includes a double cross validation for optimization of the methods and for proper estimation of the prediction error.",2012,Metabolomics
Variable selection in a class of single-index models,"In this paper we discuss variable selection in a class of single-index models in which we do not assume the error term as additive. Following the idea of sufficient dimension reduction, we first propose a unified method to recover the direction, then reformulate it under the least square framework. Differing from many other existing results associated with nonparametric smoothing methods for density function, the bandwidth selection in our proposed kernel function essentially has no impact on its root-n consistency or asymptotic normality. To select the important predictors, we suggest using the adaptive lasso method which is computationally efficient. Under some regularity conditions, the adaptive lasso method enjoys the oracle property in a general class of single-index models. In addition, the resulting estimation is shown to be asymptotically normal, which enables us to construct a confidence region for the estimated direction. The asymptotic results are augmented through comprehensive simulations, and illustrated by an analysis of air pollution data.",2011,Annals of the Institute of Statistical Mathematics
Nonparametric regression using needlet kernels for spherical data,"Needlets have been recognized as state-of-the-art tools to tackle spherical data, due to their excellent localization properties in both spacial and frequency domains. 
This paper considers developing kernel methods associated with the needlet kernel for nonparametric regression problems whose predictor variables are defined on a sphere. Due to the localization property in the frequency domain, we prove that the regularization parameter of the kernel ridge regression associated with the needlet kernel can decrease arbitrarily fast. A natural consequence is that the regularization term for the kernel ridge regression is not necessary in the sense of rate optimality. Based on the excellent localization property in the spacial domain further, we also prove that all the $l^{q}$ $(01\leq q < \infty)$ kernel regularization estimates associated with the needlet kernel, including the kernel lasso estimate and the kernel bridge estimate, possess almost the same generalization capability for a large range of regularization parameters in the sense of rate optimality. 
This finding tentatively reveals that, if the needlet kernel is utilized, then the choice of $q$ might not have a strong impact in terms of the generalization capability in some modeling contexts. From this perspective, $q$ can be arbitrarily specified, or specified merely by other no generalization criteria like smoothness, computational complexity, sparsity, etc..",2019,ArXiv
Identification of recurrence marker associated with immune infiltration in prostate cancer with radical resection and build prognostic nomogram,"BACKGROUND
Some historic breakthroughs have been made in immunotherapy of advanced cancer. However, there is still little research on immunotherapy in prostate cancer. We explored the relationship between immune cell infiltration and prostate cancer recurrence and tried to provide new ideas for the treatment of prostate cancer.


METHODS
Prostate cancer RNA-seq data and clinical information were downloaded from the TCGA database and GEO database. The infiltration of 24 immune cells in tissues was quantified by ssGSEA. Univariate Cox regression analysis was used to screen for immune cell types associated with tumor recurrence, weighted gene co-expression network analysis (WGCNA) and LASSO were used to identify hub genes which regulate prognosis in patients through immune infiltration. Then, the nomogram was constructed based on the hub gene to predict the recurrence of prostate cancer, and the decision curve analysis (DCA) was used to compare the accuracy with the PSA and Gleason prediction models.


RESULT
Analysis showed that Th2 cells and Tcm related to prostate cancer recurrence after radical prostatectomy, and they are independent protective factors for recurrence. Through WGCNA and Lasso, we identified that NDUFA13, UQCR11, and USP34 involved in the infiltration of Th2 cells and Tcm in tumor tissues, and the expression of genes is related to the recurrence of patients. Based on the above findings, we constructed a clinical prediction model and mapped a nomogram, which has better sensitivity and specificity for prostate cancer recurrence prediction, and performed better in comparison with PSA and Gleason's predictions.


CONCLUSION
The immune cells Th2 cells and Tcm are associated with recurrence of PCa. Moreover, the genes NDUFA13, UQCR11, and USP34 may affect the recurrence of PCa by affecting the infiltration of Th2 cells and Tcm. Moreover, nomogram can make prediction effectively.",2019,BMC Cancer
Tell Me What You Like and I'll Tell You What You Are: Discriminating Visual Preferences on Flickr Data,"The John Ruskin's 19th century adage suggests that personal taste is not merely an absolute set of aesthetic principles valid for everyone: actually, it is a process of interpretation which have also roots in one's life experiences. This aspect represents nowadays a major problem for inferring automatically the quality of a picture. In this paper, instead of trying to solve this age-old problem, we consider an intriguing, orthogonal direction, aimed at discovering how different are the personal tastes. Given a set of preferred images of a user, obtained from Flickr, we extract a pool of low- and high-level features; LASSO regression is then exploited to learn the most discriminative ones, considering a group of 200 random Flickr users. Such aspects can be easily recovered, allowing to understand what is the ""what we like"" which distinguish us from the others. We then perform multi-class classification, where a test sample is a set of preferred pictures of an unknown user, and the classes are all the users. The results are surprising: given only 1 image as test, we can match the user preferences definitely more than the chance, and with 20 images we reach an nAUC of 91%, considering the cumulative matching characteristic curve. Extensive experiments promote our approach, suggesting new intriguing perspectives in the study of computational aesthetics.",2012,
"Uncommon colour patterns of specimens from Acanthurus chirurgus ( Bloch , 1787 ) and Thalassoma noronhanum ( Boulenger , 1890 ) in Rocas atoll , Brazil","In this article we describe uncommon colour patterns of specimens from Acanthurus chirurgus and Thalassoma noronhanum for the first time. It may be relevant to explain it under different points of view, such as parasitosis, hybridism, skin cancer related diseases, or melanosis unrelated to diseases.",2017,
Confidence Sets Based on the Lasso Estimator,"In a linear regression model with fixed dimension, we construct confidence sets for the unknown parameter vector based on the Lasso estimator in finite samples as well as in an asymptotic setup, thereby quantifying estimation uncertainty of this estimator. In finite samples with Gaussian errors and asymptotically in the case where the Lasso estimator is tuned to perform conservative model-selection, we derive formulas for computing the minimal coverage probability over the entire parameter space for a large class of shapes for the confidence sets, thus enabling the construction of valid confidence sets based on the Lasso estimator in these settings. The choice of shape for the confidence sets and comparison with the confidence ellipse based on the least-squares estimator is also discussed. Moreover, in the case where the Lasso estimator is tuned to enable consistent model-selection, we give a simple confidence set with minimal coverage probability converging to one.",2015,arXiv: Statistics Theory
Adaptive fused LASSO in grouped quantile regression,"This article considers the quantile model with grouped explanatory variables. In order to have the sparsity of the parameter groups but also the sparsity between two successive groups of variables, we propose and study an adaptive fused group LASSO quantile estimator. The number of variable groups can be fixed or divergent. We find the convergence rate under classical assumptions and we show that the proposed estimator satisfies the oracle properties.",2016,Journal of Statistical Theory and Practice
Lifting high-dimensional non-linear models with Gaussian regressors,"We study the problem of recovering a structured signal $\mathbf{x}_0$ from high-dimensional data $\mathbf{y}_i=f(\mathbf{a}_i^T\mathbf{x}_0)$ for some nonlinear (and potentially unknown) link function $f$, when the regressors $\mathbf{a}_i$ are iid Gaussian. Brillinger (1982) showed that ordinary least-squares estimates $\mathbf{x}_0$ up to a constant of proportionality $\mu_\ell$, which depends on $f$.
Recently, Plan \& Vershynin (2015) extended this result to the high-dimensional setting deriving sharp error bounds for the generalized Lasso. Unfortunately, both least-squares and the Lasso fail to recover $\mathbf{x}_0$ when $\mu_\ell=0$. For example, this includes all even link functions. We resolve this issue by proposing and analyzing an alternative convex recovery method. In a nutshell, our method treats such link functions as if they were linear in a lifted space of higher-dimension. Interestingly, our error analysis captures the effect of both the nonlinearity and the problem's geometry in a few simple summary parameters.",2019,
ë‹¤ì¤‘ì„ í˜•íšŒê·€ëª¨í˜•ì—ì„œì˜ ë³€ìˆ˜ì„ íƒê¸°ë²• í‰ê°€,"The purpose of variable selection techniques is to select a subset of relevant variables for a particular learning algorithm in order to improve the accuracy of prediction model and improve the efficiency of the model. We conduct an empirical analysis to evaluate and compare seven well-known variable selection techniques for multiple linear regression model, which is one of the most commonly used regression model in practice. The variable selection techniques we apply are forward selection, backward elimination, stepwise selection, genetic algorithm (GA), ridge regression, lasso (Least Absolute Shrinkage and Selection Operator) and elastic net. Based on the experiment with 49 regression data sets, it is found that GA resulted in the lowest error rates while lasso most significantly reduces the number of variables. In terms of computational efficiency, forward/backward elimination and lasso requires less time than the other techniques.",2016,
A landscape-level analysis of yellow-cedar decline in coastal British Columbia,"Yellow-cedar (Chamaecyparis nootkatensis D. Don (Spach)) is currently undergoing a dramatic decline in western North America. Recent research suggests that site factors combined with a shift in climate have predisposed yellow-cedar trees to decline. We conducted the first landscape-level analysis of the decline in coastal British Columbia to assess relations between the decline and topographic variables. We used lasso-penalized logistic regression to model yellow-cedar decline presence and absence with topographic variables derived from a digital elevation model. Model results indicated that low el- evation sites close to the coast, which are more exposed and have more variation in elevation, are more likely to show evi- dence of decline. The logistic model fit the data well (Nagelkerke R 2 = 0.846) and had high predictive accuracy (AUC = 0.98). The topographic variables identified by the model influence degree of soil saturation, temperatures, and snowpack presence in a forest stand, supporting the proposed associations in the current decline hypothesis. The analysis also high- lighted the utility of the lasso logistic model for selecting significant variables and mapping areas at high risk for decline. Knowledge of the determinants of the spatial pattern of decline will improve predictability and provide critical information for conservation and management of yellow-cedar. Resume : Un deperissement spectaculaire frappe presentement le faux-cypres de Nootka (Chamaecyparis nootkatensis D. Don (Spach)) dans l'ouest de l'Amerique du Nord. Des travaux de recherche recents indiquent que des facteurs station- nels combines a une modification du climat auraient predispose le faux-cypres de Nootka au deperissement. Nous avons rea- lise la premiere analyse du deperissement a l'echelle du paysage dans la region cotiere de la Colombie-Britannique pour evaluer les relations entre le deperissement et les variables topographiques. Nous avons utilise la regression logistique pena- lisee de type Lasso pour modeliser la presence et l'absence de deperissement du faux-cypres de Nootka en fonction des va- riables topographiques derivees d'un modele digital d'altitude. Les resultats du modele indiquent que les stations situees a faible altitude pres de la cote, qui sont plus exposees et dont l'altitude est plus variable, ont plus de chance de montrer des signes de deperissement. Le modele logistique epouse bien les donnees (R 2 de Nagelkerke = 0,846) et genere des predic- tions d'une grande precision (ASC = 0,98). Les variables topographiques identifiees par le modele influencent le degre de saturation du sol, la temperature ainsi que la presence de la couverture nivale dans un peuplement forestier; ce qui supporte l'hypothese actuelle au sujet de la combinaison de facteurs associes au deperissement. L'analyse a egalement fait ressortir l'utilite du modele logistique de type Lasso pour choisir les variables importantes et cartographier les zones ou le risque de deperissement est eleve. La connaissance des facteurs qui determinent le patron spatial du deperissement va ameliorer la previsibilite et fournir une information cruciale pour la conservation et l'amenagement du faux-cypres de Nootka. (Traduit par la Redaction)",2011,Canadian Journal of Forest Research
Abstract B31: Establishing the use of genomic profiling on rare prostate cancer disseminated tumor cells,"Abstract Objective: Dissemination of prostate cancer tumor cells remains a critical challenge in understanding disease progression and effective long-term treatment of patients. Disseminated tumor cells (DTCs) from bone marrow are resistant to chemotherapy and radiation, and represent a potential long-lived source for lethal metastases. Quantification of disseminated and circulating tumor cells provides promise as a novel diagnostic in measuring tumor burden and assessing the risk of relapse. However, very limited knowledge exists about the biology of these rare cells, including the genomic aberrations associated with clinical outcome. Methods: DTCs are immunomagnetically enriched from bone marrow aspirates, then individually captured under the microscope based on immunofluorescent staining of EpCaM cell surface molecules. We have established use of whole genome amplification and high-density SNP-CGH arrays to genomically profile rare DTC populations (n=2-25 cells). Using Fused Lasso and Nexus Copy Number software, we quantify and characterize copy number alterations and loss-of-heterozygosity regions among samples isolated from 58 patients taken at the time of radical prostectomy and from 13 patients with advanced, metastatic or lethal prostate cancer. We classify DTC aberrations by tumor stage and compare to those aberrations identified in primary and metastatic tumors. Regions of interest are validated using a highly sensitive quantitative real-time PCR assay. In addition, we have completed extensive optimization of analysis parameters to handle the increased probe variation associated with low input DNA quantity and whole genome amplification. Results: DTCs isolated at the time of radical prostatectomy from early stage prostate cancer patients are generally heterogeneous and are marked with limited focal aberrations. Focal deletions of less than 100 kb are frequent events in these samples, as are focal gains of less than 500 kb, albeit less frequently. While many of these focal copy number changes are identified in regions of common copy number variation (CNV) within the population, a considerable number are rare and unique to DTCs. Cancer-specific alterations are observed in members of the cadherin family and transcription factors SIX3 , SOX4 , SOX17 and GATA6 . Because most abberations are patient-specific, bioinformatic analysis is used to illuminate commonly altered biological pathways. In contrast, DTCs from patients with advanced stages of prostate cancer typically show frequent and large (>1 Mb) clonal amplifications and deletions, suggesting a high degree of genomic instability that is common among these patients. Aberrant regions that are uniquely identified in DTCs from patients with advanced, metastatic and castrationresistant prostate cancers include gain of 1q43â€“q44 and 1q31.3â€“q41. In addition, several regions were found to be recurrent among at least 25% of metastatic tumors and DTCs from advanced stages, including in order of prevalence: +8q, âˆ’8p, +9q, âˆ’13, âˆ’22, âˆ’16q, âˆ’7q, âˆ’6q13â€“q22.31, +3q24â€“q26.1, +11q13.2â€“13.4, âˆ’17p13.3â€“p12 and +2p16.3â€“p16.2. Conclusions: We have established methods and quality control measures for genome-wide profiling of rare cell populations. These methods will be functionally useful to gain a new understanding of the genomic aberrations that drive DTC dissemination, dormancy, and metastatic reactivation in prostate cancer. Citation Format: Jamie R. Schoenborn, Jing Xia, Sandy Larson, Lisha Brown, Colm Morrissey, Paul Lange, Peter S. Nelson, Robert L. Vessella, Min Fang. Establishing the use of genomic profiling on rare prostate cancer disseminated tumor cells [abstract]. In: Proceedings of the AACR Special Conference on Advances in Prostate Cancer Research; 2012 Feb 6-9; Orlando, FL. Philadelphia (PA): AACR; Cancer Res 2012;72(4 Suppl):Abstract nr B31.",2012,Cancer Research
Techniques on semiautomatic segmentation using the Adobe Photoshop,"The purpose of this research is to enable anybody to semiautomatically segment the anatomical structures in the MRIs, CTs, and other medical images on the personal computer. The segmented images are used for making 3D images, which are helpful in medical education and research. To achieve this purpose, the following trials were performed. The entire body of a volunteer was scanned to make 557 MRIs. On Adobe Photoshop, contours of 19 anatomical structures in the MRIs were semiautomatically drawn using MAGNETIC LASSO TOOL and manually corrected using either LASSO TOOL or DIRECT SELECTION TOOL to make 557 segmented images. In a likewise manner, 13 anatomical structures in the 8,590 anatomical images were segmented. Also 12 anatomical structures in the 790 brain anatomical images and 10 anatomical structures in the 640 heart anatomical images were segmented. Proper segmentation was verified by making 3D images from the segmented images. The semiautomatic segmentation using Adobe Photoshop is expected to be widely used for segmentation of the anatomical structures in various medical images.",2005,Health
Sparse Modeling-Based Sequential Ensemble Learning for Effective Outlier Detection in High-Dimensional Numeric Data,"The large proportion of irrelevant or noisy features in reallife high-dimensional data presents a significant challenge to subspace/feature selection-based high-dimensional outlier detection (a.k.a. outlier scoring) methods. These methods often perform the two dependent tasks: relevant feature subset search and outlier scoring independently, consequently retaining features/subspaces irrelevant to the scoring method and downgrading the detection performance. This paper introduces a novel sequential ensemble-based framework SEMSE and its instance CINFO to address this issue. SEMSE learns the sequential ensembles to mutually refine feature selection and outlier scoring by iterative sparse modeling with outlier scores as the pseudo target feature. CINFO instantiates SEMSE by using three successive recurrent components to build such sequential ensembles. Given outlier scores output by an existing outlier scoring method on a feature subset, CINFO first defines a Cantelliâ€™s inequality-based outlier thresholding function to select outlier candidates with a false positive upper bound. It then performs lasso-based sparse regression by treating the outlier scores as the target feature and the original features as predictors on the outlier candidate set to obtain a feature subset that is tailored for the outlier scoring method. Our experiments show that two different outlier scoring methods enabled by CINFO (i) perform significantly better on 11 real-life high-dimensional data sets, and (ii) have much better resilience to noisy features, compared to their bare versions and three state-of-theart competitors. The source code of CINFO is available at https://sites.google.com/site/gspangsite/sourcecode.",2018,
Improving Culture Techniques for Village-based Farming of Giant Clams (tridacnidae),"Eight experiments aimed at improving methods for the village-based farming of giant clams were conducted in the Solomon Islands. The experiments focused on either improving the fitness of seed clams delivered to village farmers, assessing whether differential growth rates of seed clams in nursery tanks persisted during grow-out at farms, or testing the effects of alterations to the design of grow-out cages on the growth and survival of clams. We found that Tridacna squamosa (Lamarck) â€˜seedâ€™ transferred from land-based nursery tanks to a floating ocean nursery (FON) for â‰ˆÂ 3Â months at the end of the nursery phase were significantly larger than seed reared only in land-based nursery tanks. Similarly, T. maxima (Roding) placed in a FON for 2â€“5Â months generally grew at a significantly greater rate than tank-reared â€˜seedâ€™. However, the use of FONs did not improve survival. There were no consistent differences in the growth and survival of fast- and slow-growing seed of T. derasa (Roding) at village sites when slow-growing seed were retained in the nursery until reaching a larger size. The survival of T. maxima was enhanced significantly by placing an insert of smaller mesh (a â€˜settlement ringâ€™) in grow-out cages for the first 2Â months after delivery of seed to farmers. The settlement ring retained clams in cages until they found a suitable place to attach their byssal threads. Attempts to remove the sediment which impedes the attachment of T. maxima to the base of grow-out cages by perforating the substrate did not improve survival: the perforated substrate resulted in poor attachment of clams and harboured predators (Cymatium spp.). The survival of T. crocea (Lamarck) was not improved by â€˜softeningâ€™ the concrete base of grow-out cages to simulate dead coral rock and to encourage the clams to burrow in the substrate. The survival of T. crocea in grow-out cages was enhanced significantly by enclosing the cages in fine mesh after the delivery of the seed clams to prevent predation and disturbance by juvenile wrasse, Thalassoma spp. The experiments indicate that the critical stage for village farming of giant clams is during the initial weeks following distribution of seed. Further research is needed to improve the survival of T. crocea and T. maxima during this phase.",1999,Aquaculture Research
Fast and Effective Approximations for Summarization and Categorization of Very Large Text Corpora,"Author(s): Godbehere, Andrew B. | Advisor(s): El Ghaoui, Laurent | Abstract: Given the overwhelming quantities of data generated every day, there is a pressing need for tools that can extract valuable and timely information. Vast reams of text data are now published daily, containing information of interest to those in social science, marketing, finance, and public policy, to name a few. Consider the case of the micro-blogging website Twitter, which in May 2013 was estimated to contain 58 million messages per day: in a single day, Twitter generates a greater volume of words than the Encyclopedia Brittanica. The magnitude of the data being analyzed, even over short time-spans, is out of reach of unassisted human comprehension. This thesis explores scalable computational methodologies that can assist human analysts and researchers in understanding very large text corpora. Existing methods for sparse and interpretable text classification, regression, and topic modeling, such as the Lasso, Sparse PCA, and probabilistic Latent Semantic Indexing, provide the foundation for this work. While these methods are either linear algebraic or probabilistic in nature, this thesis contributes a hybrid approach wherein simple probability models provide dramatic dimensionality reduction to linear algebraic problems, resulting in computationally efficient solutions suitable for real-time human interaction. Specifically, minimizing the probability of large deviations of a linear regression model while assuming a $k$-class probabilistic text model yields a $k$-dimensional optimization problem, where $k$ can be much smaller than either the number of documents or features. Further, a simple non-negativity constraint on the problem yields a sparse result without the need of an $\ell_1$ regularization. The problem is also considered and analyzed in the case of uncertainty in the model parameters. Towards the problem of estimating such probabilistic text models, a fast implementation of Sparse Principal Component Analysis is investigated and compared with Latent Dirichlet Allocation. Methods of fitting topic models to a dataset are discussed. Specific examples on a variety of text datasets are provided to demonstrate the efficacy of the proposed methods.",2015,
BiokompatibilitÃ¤t Î²-stabilisierender Legierungselemente von Titanwerkstoffen,"Beta-ti tanium alloys have many advantageous mechanical properties in comparison to at the t ime used a+ÃŸt i t an ium alloys for biomedical apllications, such as an improved wear resistance, a high elasticty and an excellent cold and hot formability. This will lead to future increased application for orthopaedic jo in t replacements. Not all elements with ÃŸ-s ta bilizing properties in t i tanium alloys are suitable for b iomaterial applications. Corrosion and wear processes will cause a release from these alloying elements to the sur rounding tissue over a long t imespan. In this investigation, the biocompability of alloying elements for Î² and near ÃŸt i tanium alloys was tested in order to estimate their suitability as biomaterial components . As reference materials t i tanium (grade 2) and the implant steel X2CrNiMol8153 (AISI 316 L) were tested. The corrosion properties of the elements, the proliferation, metabolic activity, cell morphology and cell size of MC3T3-E1 cells and GM7373 cells af ter 7 days incubation in direct contact with polished slices of the metals were investigated. The biocompatibil i ty of the investigated metals can be brought in the fol lowing range (with decreasing biocompatibility): niobium tanta lum, t i tanium zirconium aluminium 316 L molybdenum. Danksagung Wir danken der DFG fÃ¼r die finanzielle UnterstÃ¼tzung in dem Projekt TH 438 16-2 + EI 438 2-2. Literatur [1] Black J.: Does corrosion matter? J Bone and Jt Surg 1988, 70B: 517-20 [2] Wapner K. L.: Implications of matallic corrosion in total knee arthoroplasty. Clin Orthop 1991, 271: 12-20 [3] Semlithsch Mâ€ž Staub F., Webber H.: Biomed. Technik 30 (1985) 334-339 [4] Zwicker R., Buehler K., Mueller R. et al.: Mechanical Properties and Tissue Reactions of a Titanium Alloy for Implant Material, Titanium 80. Science and Technology, In: H. Kimura, 0 . Izumi (Eds.) Proc. 4thlnt . Conf. on Titanium Kyoto, Japan, May, 19-22 The Met. Coc. AIME (1980) pp. 505-514] [5] Niinomi M., Kuroda D., Fukunaga K. et al.: Corrosion wear fracture of new Î¿ type biomedical t i tanium alloys Materails Science and Engineering A 263 (1999), 193-199 [6] Steinemann S. G.: Evaluation of Biomaterials Eds: G.D. Winter, J.L. Leray, K. de Goot Wiley, Chichester 1980, Ï 1 [7] Rosenberg H. W.: â€žTitanium Alloying in Theory andPractice"", The Science, Technology and Application of Titanium (Proc. 1st Int. Conf. on Titanium, London), R.I. Ja f fee and N.E. Promise, Ed, Pergamon Press 1970, 851-859) [8] Kobayashi E., Doi H., Yoneyama T., Hamanaka H., Gibson I.R., Best S.M., Shelton J.C., Bonfield W.: Influence of aging heat t reatment on mechanical properies of biomedical Ti-Zr based ternary alloys conta ining niobium Kluwer Academic Publishers, Journal of Materials Schience: Materials in Medicinie 9 (1998) 625-630 [9] Okazaki Yâ€ž Ito Y.: New Ti Alloy without Al and V for Medical Implants, Advanced engineering materials 2000, 2 No. 5, S. 278 [10] UngersbÃ¶ck Î‘., Perren S. Mâ€ž Pohler 0. : Journal of Material Science, Materials in Medicine 5 (1994), 788 [11] Nishiguchi S., Kato H., Fujita Hâ€ž Kim H., Miyaji F., Kokubo T., Nakamura T.: Journal of Biomedical Materials Research (Appl. Biomater.) 48 (1999), 689 [12] Trentani, Pelillo F., Pavesi F.C., Ceciliani L., Cetta G., Forlino Î‘.: Biomaterials 23 (2002) 2863-2869 [13] Wack T., Biehl V., Breme J., Schwanke C., Schaeffer L.: Adv. Pow. Techn. Mat. Sei For. 299 (3) (1999), 348 [14] Trillo Î•. Î‘., Ortiz Câ€ž Dickerson P., Villa R., Stafford S.W., Murr L.E.: Journal of Materials Science: Materials in Medicin 12 (2001) 283-292 [15] Yu S. Yâ€ž Scully J. R.: Corrosion 53 (12) (1997), 965 [16] Zitter H.: Corrosion behaviour and biocompatibil i ty of t i tanium alloys for implants Werkstoff und Korrosion 39, 1988, 574-582 [17] Brunette D. Mâ€ž Tengvall P., Textor Mâ€ž Thomsen P.: Titan ium in Medicine, Springer Berlin, Heidelberg, New York, 2001, 174-176 [18] Okazaki Î‘., Katsuda S., Furuki Y., Tateishi T.: Mater. Trans. JIM 1998, 39, 1063 [19] Pypen C. M., Dessein Kâ€ž Helsen J. Î‘.: Comparison of the cytotoxicity of molybdenum as powder and as al loying element in a n iob ium-molybdenum alloy Journal of mater ials schience: Materials in Medicine, 9 (1998) 761-765 [20] Collings E. Wâ€ž Boyer Râ€ž Welsch Gâ€ž Collings E. W. (Eds.): Titanium Alloys: Materials Properties Handbook, ASM International, Materials Park OH, (1994) 3 [21] Helsen J.A., Breme J.: Metals as Biomaterials, John Wiley Et Sons Ltd., Chichester, 1998, Ï 40 [22] Jonsson A. Kâ€ž Niklasson G. A, Veszelei M.: Electrical properties of Zr02 thin films, Thin Solid Films 402 (2002) 242-247",2003,BIOmaterialien
"The Lingshandao Formation:a New Lithostratigraphic Unit of the Early Cretaceous in Qingdao, Shandong, China","A new lithostratigraphic unit, the Lingshandao Formation, is established to represent a set of Early Cretaceous marine deposits in Lingshan Island, Qingdao, Shandong, China, which was previously considered to be the terrestrial Fajiaying Formation of the Laiyang Group. This formation, only distributed in Lingshan Island, is a set of marine flysch composed of grayish yellow thin-bedded fine sandstones or siltstones interbedded with black mudstones or shales. The flysch rhythmites consist of graded sand or silt intervals interbedded with black mudstones. It has an exposed thickness of over 100 m with the lower part submerged and the top unconformably overlain by a thick layer of rhyolite. Fossils from the Lingshandao Formation are represented by rare and poorly preserved spores and pollen, dominated by Classopollis and bisaccate pollen, as well as scarce fragments of marine dinoflagellate cysts and membranous algae. Biostratigraphic data and detrital zircon ages indicate that the Lingshandao Formation is most likely early-middle Early Cretaceous in age, although the possibility cannot be excluded that the lower Lingshandao Formation may be Late Jurassic in age. The overlying rhyolite is considered to roughly belong to the lower part of the Lower Cretaceous Qingshan Group.",2013,Journal of stratigraphy
Circulating stable antigens at higher levels down-regulate antibody responses toPlasmodium falciparum,"A study involving 169 schoolchildren (5â€“14 years old) living in Manarintsoa near Antananarivo (Madagascar, East Africa) was performed during the seasonal malaria transmission period. For the whole population examined, the prevalence ofPlasmodium falciparum and the rates of spleen enlargement and of circulating stable antigen (S-Ag) were found to be 60.9%, 71.7%, and 46,8%, respectively. The prevalence of IgG antibody to RESA (ring-infected erythrocyte surface antigen) was 42.7% and that of IgG and IgM antibodies to E-Ag (exoantigens) was 44.9% and 2.9%, respectively. The positive rates for IgG and IgM antibodies to Som-Ag (somatic antigen) were 48.5% and 5.9%, respectively. Concerning Sâˆ’Ag, no significant relationship was observed for parasitemia, spleen size, age, or IgM antibody responses to exoantigens (E-Ag) or to somatic antigen (Som-Ag). Levels of Sâˆ’Ag were found to be related to IgG antibodies to E-Ag. Our results suggest that Sâˆ’Ag at low levels may participate in the mechanisms involved in the development of the IgG antibody responses to E-Ag and to Som-Ag, whereas at a comparative population level, higher quantities of Sâˆ’Ag down-regulate antibody responses toP. falciparum. The data we obtained were compared with those gathered in another malaria mesoendemic area (Bobo-Dioulasso, Burkina Faso, West Africa), where lower levels of Sâˆ’Ag were found.",2004,Parasitology Research
Impact of alternative treatment approach for cerebral toxoplasmosis among HIV/AIDS patients from a resource-poor setting in Burkina Faso,"Cerebral toxoplasmosis is caused by the protozoan Toxoplasma gondii because of reactivation of latent tissue cysts in the Acquired Immunodeficiency Syndrome (AIDS) patients with severe immunosuppression. The objective of this study was to evaluate the benefit of co-trimoxazole in presumptive and prevention of cerebral
toxoplasmosis in Human Immunodeficiency Virus (HIV)/AIDS patients at Bobo-Dioulasso Hospital in Burkina Faso from June 2012 to October 2014. ELISA and ELFA were performed on serum for the quantitative determination of IgG and IgM anti-T. gondii, respectively. The seroprevalence of toxoplasmosis was 29.3%. No IgM antibodies for T. gondii were found. Six patients with Toxoplasma-specific antibodies presented cerebral toxoplasmosis. All patients were infected by HIV-1 with the median of CD4+ T lymphocytes at 141 cells/Î¼l. No patient was under antiretroviral therapy. No case of cerebral toxoplasmosis was noted in patients receiving co-trimoxazole in prevention. Presumptive treatment of cerebral toxoplasmosis with co-trimoxazole was effective in all patients with a significant clinical improvement in 83.3%. These results attest the benefit of cotrimoxazole in cerebral toxoplasmosis treatment in countries where drug resources are limited when sulfadiazine is not available. Ours finding highlight the importance of establishing toxoplasmosis chemoprophylaxis to HIV with severe immunosuppression patients and positive Toxoplasma serology.",2017,Annals of parasitology
Robust estimation with Lasso when outputs are adversarially contaminated,"We consider robust estimation when outputs are adversarially contaminated. Nguyen and Tran (2012) proposed an extended Lasso for robust parameter estimation and then they showed the convergence rate of the estimation error. Recently, Dalalyan and Thompson (2019) gave some useful inequalities and then they showed a sharper convergence rate than Nguyen and Tran (2012) . They focused on the fact that the minimization problem of the extended Lasso can become that of the penalized Huber loss function with $L_1$ penalty. The distinguishing point is that the Huber loss function includes an extra tuning parameter, which is different from the conventional method. However, there is a critical mistake in the proof of Dalalyan and Thompson (2019). We improve the proof and then we give a sharper convergence rate than Nguyen and Tran (2012) , when the number of outliers is larger. The significance of our proof is to use some specific properties of the Huber function. Such techniques have not been used in the past proofs.",2020,ArXiv
La Â«Crise du troisiÃ¨me jourÂ» en Chirurgie du cerveau,"RÃ©sumÃ©Les auteurs appellent Â«crise du 3Ã¨me jourÂ» un ensemble de signes quÃ­ expriment une aggravation de l'Ã©tat de l'opÃ©rÃ©. Cette aggravation est le plus souvent lÃ©gÃ¨re, passagÃ¨re, Ã  peine soupÃ‡onnÃ©e, parfois de moyenne importance et d'une durÃ©e de 2 Ã  5 jours, d'autrefois grave, inquiÃ©tante, faisant craindre une complication et envisager une rÃ©intervention.La crise du 3Ã¨me jour est l'expression d'un trouble purement rÃ©actionnel, donc rÃ©versible, le plus souvent d'une bouffÃ©e d'oedÃ¨me cÃ©rÃ©bral dÃ©veloppÃ© autour du foyer opÃ©ratoire, beaucoup plus rarement d'un collapsus cÃ©rÃ©bral. Elle relÃ¨ve gÃ©nÃ©ralement d'un traitement mÃ©dical.Les auteurs envisagent successivement les aspects cliniques, la pathogÃ©nie, le contexte biologique, les rapports susceptibles d'exister entre les troubles hydriques cÃ©rÃ©braux et les troubles hydro-ioniques de l'ensemble de l'organisme, le diagnostic et le traitement.ZusammenfassungDie Autoren bezeichnen als â€žKrise des 3. Tagesâ€œ ein Zusammentreffen von Zeichen, die auf eine Verschlechterung des Zustandes des Operierten hinweisen. Diese Verschlechterung ist oft gering, flÃ¼chtig, kaum merklich; manchmal ist sie von mittlerer Bedeutung und von 2 bis 5 Tagen Dauer; in anderen FÃ¤llen ist sie schwerwiegend, beunruhigend, lÃ¤ÃŸt eine Komplikation befÃ¼rchten und eine Wundrevision angezeigt erscheinen.Die Krise des 3. Tages ist Ausdruck einer rein reaktionellen und somit reversiblen StÃ¶rung, am hÃ¤ufigsten bedingt durch ein HirnÃ¶dem im Operationsbereich, viel seltener durch einen Kollaps des Gehirns (Unterdruck). Sie ist in der Regel durch entsprechende Behandlung zu beherrschen.Die Autoren beschreiben das klinische Bild, die Pathogenese, die biologischen ZusammenhÃ¤nge, die wahrscheinlich vorhandenen Beziehungen zwischen den WasserhaushaltsstÃ¶rungen des Gehirns und den StÃ¶rungen von Wasser- und Ionenhaushalt des gesamten Organismus, die Diagnostik und die Behandlung.SummaryThe authors christen â€œThe Crisis of the 3rd Dayâ€ a collection of signs which are revealed in a deterioration in the condition of the post-operative patient. This deterioration is usually slight, transient and scarcely detectable; sometimes it is of moderate severity and lasts 2 to 5 days; on other occasions it is severe and very worrying, suggesting that there is a complication for which re-exploration of the wound would be necessary.The crisis of the 3rd day is the expression of purely reactive phenomena which are thus reversible; most often due to cerebral oedema which has developed at the operation site, much more rarely due to a low pressure state. It responds as a rule to medical treatment.The authors describe the clinical aspects, the pathogenesis, the biological factors, the possible relationships between disorders of cerebral hydration and disturbances of water and electrolyte balance in the body as a whole, the diagnosis and treatment.RiassuntoGli autori chiamano â€žcrisi del 30 giornoâ€œ un insieme di sintomi che esprimono un aggravamento delle condizioni dell'operato.Questo aggravamento il piÃ¹ spesso Ã¨ di lieve entitÃ , passeggero, appena sospettato, talora Ã¨ di maggior importanza e di 2 a 5 giorni di durata, talora Ã¨ di notevole entitÃ , inquietante tanto da far temere delle complicazioni e da far prendere in considerazione un reintervento.La crisi del 30 giorno Ã¨ l'espressione di un disordine puramente reattivo, quindi reversibile, il piÃš spesso di una bouffÃ©e di edema cerebrale sviluppato attorno al focolaio operatorio, molto piÃ¹ raramente di un collasso cerebrale.Generaimente si giova di un trattamento medico.Gli autori prendono in considerazione sucessivamente gli aspetti clinici, la patogenesi, il substrato biologico, i rapporti verosimilmente esistenti tra disturbi idrici cerebrali e disordini idro-ionici del complesso dell'organismo, la diagnosi e la terapia di questa condizione.ResumenLos autores designan como Â«crisis del tercer diaÂ» a una reuniÃ³n de sÃ­ntomas que indican un empeoramiento del estado del operado.Este empeoramiento frecuentemente es escaso, fugaz, a penas perceptible, en ocasiones de mediana importancia y de una duraciÃ³n de 2 a 5 dias; en otros casos es peligroso, intranquilizante, puede hacer temer una complicaciÃ³n e indicar la conveniencia de una revisiÃ³n de la herida.La crisis del tercer dia, es expresiÃ³n de un trastorno purameute reactivo y reversible condicionado casi siempre por un edema cerebral de la zona operatoria, siendo determinado mÃ¡s rara vez por un colapso cerebral (hipopresiÃ³n). Generalmente se puede dominar con el oportuno tratamiento.Los autores describen el cuadro clinico, la patogenia, las dependencias biolÃ³gicas, las relaciones probablemente existentes entre los trastornos del contenido acuoso cerebral y los trastornos del equilibrio hidrosalino de todo el organismo, el diagnÃ³stico y tratamiento.",2005,Acta Neurochirurgica
Adaptive lasso in sparse vector autoregressive models,"Abstract This paper considers variable selection in the sparse vector autoregressive (sVAR) model where sparsitycomes from setting small coeï¬ƒcients to exact zeros. In the estimation perspective, Davis et al. (2015)showed that the lasso type of regularization method is successful because it provides a simultaneous variableselection and parameter estimation even for time series data. However, their simulations study reports thatthe regular lasso overestimates the number of non-zero coeï¬ƒcients, hence its ï¬nite sample performance needsimprovements. In this article, we show that the adaptive lasso signiï¬cantly improves the performance wherethe adaptive lasso ï¬nds the sparsity patterns superior to the regular lasso. Some tuning parameter selectionsin the adaptive lasso are also discussed from the simulations study.Keywords: sparse vector autoregressive model, adaptive lasso, high dimensional time series 1. ì„œë¡  í˜„ëŒ€ì˜ê¸‰ê²©í•œ ê³¼í•™ ê¸°ìˆ ì˜ë°œì „ì€ê¸°ì¡´ì—ëŠ” ìƒìƒí•  ìˆ˜ì¡°ì°¨ ì—†ëŠ” ë‹¤ì–‘í•˜ê³ ë„ ëŒ€ìš©ëŸ‰ì˜ë°ì´í„°ë¥¼ ìƒì‚°í•´ ë‚´ì—ˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ì‹œê°„ì— ë”°ë¼ ê´€ì¸¡ëœ ê³ ì°¨ì›ì˜ëŒ€ìš©ëŸ‰ ì‹œê³„ì—´ ìžë£Œë¥¼ ë§¤ìš° íš¨ê³¼ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ìžˆëŠ” ë²¡í„°ìžê¸°ìƒê´€íšŒê·€ ëª¨í˜•(vector autoregressive model; VAR)ì˜ì¶”ì •ì„ë‹¤ë£¬ë‹¤. VAR ëª¨í˜•ì€ë³€ìˆ˜ë“¤ ì‚¬ì´ì˜ì¢…ì†ê´€ê³„(interdependence)ë¥¼ ê³ ë ¤í•˜ì—¬ ì‹œê°„ì— ë”°ë¥¸ ì¢…ì†ê´€ê³„(temporal depen-dence)ë¥¼ ì„ í˜• ì¢…ì†ê´€ê³„ë¡œ ë‚˜íƒ€ë‚´ëŠ” ëª¨í˜•ì´ë‹¤. ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œ ë¨¼ì € ì°¨ì›ì´",2016,
"The tubificidae (Annelida, oligochaeta) of a louisiana estuary: Ecology and systematics, with the description of a new species","Spatial and temporal variations in the abundances and distributions of oligochaetes of a southwestern Louisiana estuary were examined as part of a long term study of community structure of benthic macroinvertebrates. Quantitative samples were collected at monthly intervals from nine stations for two years and an additional 17 stations were sampled once. A tubificid oligochaete,Tubificoides denouxi n. sp., is described from the five species collected. The two predominant oligochaetes,Tubificoides heterochaetus andT. denouxi, were congeneric and exhibited completely allopatric distributions. Two oligochaete species with-restricted distributions,Monopylephorus helobius andLimnodriloides sp., were sympatric withT. denouxi, whileThalassodrilides belli, although less abundant, was sympatric with bothT. denouxi andT. heterochaetus. Sexually mature specimens ofT. denouxi andT. belli were collected only in the summer,T. heterochaetus was sexually mature in both winter and summer collections, andMonopylephorus helobius was sexually mature in spring and summer collections. Many of the studies of Oligochaeta have concluded that correlation exists between sediment grain size and species demography. Our data demonstrate a strong relationship between salinity and the abundance and distribution of estuarine species.Tubificoides denouxi was found only within the salinity range of 14.8 to 22.0â€° salinity,T. heterochaetus was found only within the range of 2.3 to 14.1â€°, andT. belli had a salinity distribution intermediate between the previous species. No relationship was found between sediment grain-size analysis, water depth or hydrographic variables and species distribution.",1982,Estuaries
Robust k-means-based clustering for high-dimensional data,"We introduce a robust k-means-based clustering method for high-dimensional data where not only outliers but also a large number of noise variables are very likely to be present. Although Kondo et al. [2] already addressed such an application scenario, our approach goes even further. Firstly, the introduced method is designed to identify clusters, informative variables, and outliers simultaneously. Secondly, the proposed clustering technique additionally aims at optimizing required parameters, e.g. the number of clusters. This is a great advantage over most existing methods. Moreover, the robustness aspect is achieved through a robust initialization [3] and a proposed weighting function using the Local Outlier Factor [1]. The weighting function provides a valuable source of information about the outlyingness of each observation for a subsequent outlier detection. In order to reveal both clusters and informative variables properly, the approach uses a lasso-type penalty [4]. The method has thoroughly been tested on simulated as well as on real highdimensional datasets. The conducted experiments demonstrated a great ability of the clustering method to identify clusters, outliers, and informative variables.",2019,
The role of chemical alarm cues in risk assessment and predator recognition in coral reef fishes,"Through the removal of individuals, predation shapes the distribution and abundance of prey communities. Consequently, how prey species detect and respond to predation threats within their environment will determine survival and future fitness. The mere presence of predators in an environment has a significant effect on the life histories of prey individuals. The use of visual, olfactory and auditory cues allows prey to detect and learn about predators and their associated risks within their environment in a way that allows the development of predator specific antipredator responses. In complex environments, such as coral reefs, olfactory cues are thought to be especially important as increased complexity reduces access to visual cues. There is evidence to suggest that olfactory cues such as chemical alarm cues maybe used by a wide range of coral reef fishes, however there is lack of information regarding the role such cues play in risk perception and predator recognition. This study therefore investigates how coral reef fishes use chemical alarm cues to assess risk and learn to recognise predators and the risk they represent. 
 
To understand how fishes use chemical alarm cues to assess risk, there is a need to understand what cues they are able to detect. How juvenile coral reefs fishes use cues from heterospecific prey guild members is unclear but use of heterospecific cues should enhance risk assessment. Chapter 2 tested if naive juvenile fish have an innate recognition of heterospecific alarm cues and whether such recognition arises from phylogenetic conservation of chemical alarm cues. Naive juvenile Amphiprion percula were tested to see if they displayed antipredator responses to chemical alarm cues from four closely related heterospecific species (family Pomacentridae), a distantly related sympatric species (Asterropteryx semipunctatus; family Gobidae) and a saltwater control. Juveniles displayed significant reductions in foraging rate when exposed to all four confamilial species and the intensity of the response was strongly correlated to the extent to which species were related to A. percula. These findings demonstrate that chemical alarm cues are conserved within the Pomacentridae family, as predicted by the phylogenetic relatedness hypothesis. 
 
In the absence of innate predator recognition prey must learnt to recognise predators in an efficient manner, particularly when entering a novel environment. Predation pressure should therefore selectively promote mechanisms that enable the rapid identification of novel predators. Chapter 3 tested the ability of a juvenile marine fish, lemon damselfish (Pomacentrus moluccensis), to simultaneously learn the identity of multiple previously unknown predators. Individuals were conditioned with a â€žcocktailâ€Ÿ of novel odours (from two predators and two non-predators) paired with either a conspecific alarm cue or a saltwater control and then tested the following day for recognition of the four odours individually and two novel odours (one predator and one non-predator). Individuals conditioned with the â€˜cocktailâ€™ and alarm cue responded to the individual â€˜cocktailâ€™ odours with an antipredator response but not the controls. These results demonstrate the ability to of juvenile fishes to process multiple sources of information regarding predator identities simultaneously and still recognise predators individually. The ability to rapidly assimilate information regarding predator identities should significantly enhance risk assessment and their chances of survival. 
 
Learnt predator recognition, although potentially costly, provides animals with an adaptive mechanism to rapidly adjust to current levels of predation risk. Prey may reduce the costs associated with learning if they can use information learned about known predators to respond to cues from closely related predators with which they are unfamiliar. Chapter 4 demonstrated that, in a community where the ability to predict the predatory status novel species is low (i.e. high diversity of closely related predators and non-predators), prey fish generalise predator recognition to novel congeneric species but not confamilial species. P. moluccensis, conditioned to recognise the odour of a predatory moon wrasse, Thalassoma lunare, as a risky stimulus subsequently displayed antipredator responses not only to T. lunare odour, but also to the congeneric Thalassoma amblycephalum and Thalassoma hardwicke odours. Recognition was not extended to species beyond the genus level. Our results showed that P. moluccensis could not distinguish between predators and non-predators when generalising predator recognition. The extent to which prey generalise predator recognition appear to depend on the ability to accurately predict predator identities based on an innate knowledge of the functional diversity within the community to which previous generations have been exposed. 
 
In communities of high biodiversity, the ability to distinguish predators from non-predators is crucial for prey success. Coral reef fishes enter new environments apparently naive to the identity of both predators and non-predators. The remarkable efficiency of learning using chemical alarm cues means that recognition mistakes may occur if prey inadvertently learn that a species is a predator when it is not. Latent inhibition is a means by which prey that are pre-exposed to an unknown species in the absence of negative reinforcement can learn that the unknown animal is likely not a threat. Chapter 5 demonstrated that a common coral reef fish, P. moluccensis, can learn to recognize a predator as non-threatening through latent inhibition. Furthermore, we showed that we could override the latent inhibition effect by conditioning the prey to recognize the predator numerous times. These results highlight that prey fish are able to correct recognition mistakes by continually updating the information regarding the threat posed by other fishes in their vicinity. 
 
Fishes are exposed to different suits of predators throughout ontogeny and they should therefore respond to and learn about predators using cues that are most relevant to their current situation. Chapter 6 tested whether juvenile spiny chromis, Acanthochromis polyacanthus, could distinguish between chemical alarm cues originating from conspecifics of different ontogenetic stages and whether cue origin affected its efficacy when learning about predators. Juveniles displayed a significant antipredator response to juvenile chemical alarm cues and subsequently only learned to recognise the predator after being conditioned with juveniles alarm cues. Juveniles failed to respond and learn from chemical alarm cues from larger individuals. This demonstrates that prey are highly selective in how they use information about predation risks from conspecifics, responding to and learning from only those cues that are relevant to their current developmental stage.",2012,
Removal of a migrated biliary stent using new digital cholangioscopy retrieval devices in a transplant patient.,"A 51-year-old man who had undergone liver transplantation developed a symptomatic anastomotic biliary stricture 23 months after surgery. Endoscopic biliary therapy via endoscopic retrograde cholangiopancreatography (ERCP) was planned. Progressive biliary balloon dilation of the stenosis was performed, with placement of three coaxial plastic stents (8.5-Fr Ã— 12 cm, 8.5-Fr Ã— 9 cm, and 10-Fr Ã— 12 cm; Advanix, Boston Scientific, Natick, Massachusetts, USA). During an endoscopy to replace the stents, fluoroscopy revealed proximal migration of an 8.5-Fr plastic stent at the level of the cystic insertion (â–¶Fig. 1). Several failed extraction attempts were made using the standard ERCP techniques (i. e. extractor balloon, Lasso technique, and others) [1, 2]. Single-operator peroral intraductal cholangioscopy (SpyGlass DS direct visualization system, Boston Scientific) confirmed impaction of the distal end of the proximally migrated stent, located 3 cm proximally to the duodenal papilla. An attempt to mobilize the migrated stent was made using biopsy forceps (SpyBite, Boston Scientific), without success. Finally, use of the new intraductal cholangioscopy retrieval devices (basket and snare) (â–¶Fig. 2) allowed successful stent removal. Firstly, the stent was disimpacted using the new SpyBasket (Boston Scientific), then the distal end was wrapped E-Videos",2019,Endoscopy
Network Elastic Net for Identifying Smoking specific gene expression for lung cancer,"Survival month for non-small lung cancer patients depend upon which stage of lung cancer is present. Our aim is to identify smoking specific gene expression biomarkers in prognosis of lung cancer patients. In this paper, we introduce the network elastic net, a generalization of network lasso that allows for simultaneous clustering and regression on graphs. In network elastic net, we consider similar patients based on smoking cigarettes per year to form the network. We then further find the suitable cluster among patients based on coefficients of genes having different survival month structures and showed the efficacy of the clusters using stage enrichment. This can be used to identify the stage of cancer using gene expression and smoking behavior of patients without doing any tests.",2019,2019 New York Scientific Data Summit (NYSDS)
Acceptability of voluntary HIV testing by pregnant women in developing countries: an international survey. Ghent International Working Group on Mother-to-Child Transmission of HIV.,"OBJECTIVE
To evaluate acceptability of voluntary HIV counselling and testing (VCT) by pregnant women in the context of clinical trials assessing interventions to reduce mother-to-child transmission (MCT) of HIV in developing countries.


METHODS
During September-October 1997, 13 studies located in West (Abidjan, Bobo Dioulasso), East (Nairobi, Mombasa, Dar Es Salaam, Blantyre, Lusaka, Harare) and South Africa (Soweto, Durban), and Thailand (Bangkok) were included in a cross-sectional mailing survey about the acceptability of VCT in antenatal clinics. Acceptance rate, return rate, overall acceptability of VCT (acceptance of both pre- and post-VCT sessions) were obtained using a standardized questionnaire.


RESULTS
The median overall acceptability of VCT was 69% (range, 33-95%). Overall acceptability of VCT most frequently depended on return rates because acceptance rates were generally high. Where several studies were conducted in parallel in the same city or the same country, overall acceptability rates of HIV testing were generally comparable even if the intervention programmes differed. Overall acceptability rates of VCT were high in antenatal clinics where a particular effort in implementing VCT programmes had been made.


CONCLUSIONS
This international survey shows that despite many obstacles, VCT is feasible and acceptable for pregnant women aiming to reduce their risk of transmitting HIV to their children.",1998,AIDS
The Hierarchical Hybrid Fuzzy-Neural Network Based on Lasso Function and Its Application to Classification of Remote Sensing Images,"In this paper, a new algorithm for the hierarchical hybrid fuzzy-neural network model is proposed. The Takagi-Sugeno model and triangular membership function are adopted in the fuzzy system, and the Lasso function of the coefficient contraction method is used to reduce the strong interaction among discrete input variables. In the end, an experimental test on surface features classification by using LANDSAT ETM+ remote sensing image data of Zhangping and Anxi in Fujian Province is conducted. Compared with other neural networks, the classification result with the proposed approach is the most accurate, which proves its feasibility and validity, and can be used as a new classification method for surface features on remote sensing images.",2011,Chinese Journal of Geophysics
Multi Class Learning with Individual Sparsity,"Multi class problems are everywhere. Given an input the goal is to predict one of a few possible classes. Most previous work reduced learning to minimizing the empirical loss over some training set and an additional regularization term, prompting simple models or some other prior knowledge. Many learning regularizations promote sparsity, that is, small models or small number of features, as performed in group LASSO. Yet, such models do not always represent the classes well. In some problems, for each class, there is a small set of features that represents it well, yet the union of these sets is not small. We propose to use other regularizations that promote this type of sparsity, analyze the generalization property of such formulations, and show empirically that indeed, these regularizations not only perform well, but also promote such sparsity structure.",2013,
Feasibility and efficacy of highly active antiretroviral therapy among high-risk and marginalised HIV-1 infected women in West Africa.,"Feasibility and efficacy of highly active antiretroviral therapy among high-risk and marginalised HIV-1 infected women in West Africa C. Huet, A. Ouedraogo, I. KonatÃ©, I. TraorÃ©, F. Rouet, A. Ouiminga, A. Sanon, P. Mayaud, P. Van de Perre and N. Nagot, for the ANRS 1222 Yerelon Study Group 1 Centre Muraz, Bobo-Dioulasso, Burkina Faso 2 London School of Hygiene & Tropical Medicine (LSHTM), London, United Kingdom 3 UniversitÃ© Montpellier 1 and CHU Montpellier, Montpellier, France Objective To describe the feasibility and long-term clinical, immunological and virological outcomes of HAART among HIV-infected female sex workers (FSWs) in Burkina Faso. Methods Prospective study of FSWs and non-FSWs initiated on HAART according to WHO recommendations. Follow-up included monthly clinical visits, HAART adherence support and assessment, 6-monthly CD4 cell count and HIV-1 plasma viral load (PVL) measurements. Results 95 women, including 47 FSWs, were followed for a median of 32 months (interquartile range [IQR], 20â€“41 months). At HAART initiation, the median CD4 count was 147 cells/Î¼l (IQR, 79â€“183) and 144 (100â€“197) in FSWs and non-FSWs, respectively, and the median PVLs were 5.09 log10 copies/ml (IQR, 4.60â€“5.43) and 5.24 (4.73â€“5.61), respectively. 70% of FSWs and 69% of other women were at WHO clinical stages III/IV. Four women (all FSWs) died during follow-up (mortality rate: 1.7 per 100 person-years). At 36 months, the median increase in CD4+ count was 230 cells/Î¼l (IQR, 90â€“400) and HIV-1 PVL was undetectable for 81.8% (95%CI, 59.7â€“94.8) of FSWs. At least 95% adherence was reported by 83.3% (95% CI, 67.2â€“93.6) and 100.0% (54.1â€“100.0) of FSWs, at 6 and 36 months after HAART initiation, respectively. Conclusions This study showed the feasibility of HAART introduction and that the benefits of HAART can be sustained over the long term among FSWs in Africa. Therefore, increased efforts should be invested by national HAART treatment programmes to improve access to care for this high-risk but marginalised population.",2009,
Bayesian Two-Stage Biomarker-Based Adaptive Design for Targeted Therapy Development,"We propose a Bayesian two-stage biomarker-based adaptive randomization (AR) design for the development of targeted agents. The design has three main goals: (1) to test the treatment efficacy, (2) to identify prognostic and predictive markers for the targeted agents, and (3) to provide better treatment for patients enrolled in the trial. To treat patients better, both stages are guided by the Bayesian AR based on the individual patientâ€™s biomarker profiles. The AR in the first stage is based on a known marker. A Go/No-Go decision can be made in the first stage by testing the overall treatment effects. If a Go decision is made at the end of the first stage, a two-step Bayesian lasso strategy will be implemented to select additional prognostic or predictive biomarkers to refine the AR in the second stage. We use simulations to demonstrate the good operating characteristics of the design, including the control of per-comparison type I and type II errors, high probability in selecting important markers, and treating more patients with more effective treatments. Bayesian adaptive designs allow for continuous learning. The designs are particularly suitable for the development of multiple targeted agents in the quest of personalized medicine. By estimating treatment effects and identifying relevant biomarkers, the information acquired from the interim data can be used to guide the choice of treatment for each individual patient enrolled in the trial in real time to achieve a better outcome. The design is being implemented in the BATTLE-2 trial in lung cancer at the MD Anderson Cancer Center.",2016,Statistics in Biosciences
Modified Cross-Validation for Penalized High-Dimensional Linear Regression Models,"In this article, for Lasso penalized linear regression models in high-dimensional settings, we propose a modified cross-validation (CV) method for selecting the penalty parameter. The methodology is extended to other penalties, such as Elastic Net. We conduct extensive simulation studies and real data analysis to compare the performance of the modified CV method with other methods. It is shown that the popular K-fold CV method includes many noise variables in the selected model, while the modified CV works well in a wide range of coefficient and correlation settings. Supplementary materials containing the computer code are available online.",2013,Journal of Computational and Graphical Statistics
Fixed effects Selection in high dimensional Linear Mixed Models,"We consider linear mixed models in which the observations are grouped. A L1-penalization on the fixed effects coefficients of the log-likelihood obtained by considering the random effects as missing values is proposed. A multicycle ECM algorithm is used to solve the optimization problem; it can be combined with any variable selection method developed for linear models. The algorithm allows the number of parameters p to be larger than the total number of observations n; it is faster than the lmmLasso (Schelldorfer,2011) since no n*n matrix has to be inverted. We show that the theoretical results of Schelldorfer (2011) apply for our method when the variances of both the random effects and the residuals are known. The combination of the algorithm with a variable selection method (Rohart 2011) shows good results in estimating the set of relevant fixed effects coefficients as well as estimating the variances; it outperforms the lmmLasso both in the common case (p n).",2013,arXiv: Computation
Pharmacology and immuno-virologic efficacy of once-a-day HAART in African HIV-infected children: ANRS 12103 phase II trial.,"OBJECTIVE
To assess 12-month survival, pharmacokinetics, immunologic and virologic efficacy, tolerance, compliance and drug resistance in HIV-infected children in Bobo-Dioulasso, Burkina Faso, receiving once-daily highly-active antiretroviral therapy as a combination of didanosine (DDI), lamivudine (3TC) and efavirenz (EFV).


METHODS
In the ANRS 12103 open phase II trial, HIV-infected children were examined at inclusion and monthly thereafter. CD4+ T-lymphocyte (CD4) count, plasma concentration of ribonucleic acid (RNA) of human immunodeficiency virus type 1 (HIV-1) and haematologic and biochemical parameters were measured at baseline and every trimester. HIV-1 resistance testing was performed in case of viral escape. Drug plasma concentrations were determined with high-performance liquid chromatography.


FINDINGS
From February 2006 to November 2007, 51 children (39% girls) with a mean age of 6.8 years were enrolled and treated for 12 months. At baseline, Z scores for mean weight-for-age and mean height-for-age were -2.01 and -2.12, respectively. Mean CD4% was 9.0. Median plasma HIV-1 RNA viral load was 5.51 log(10) copies per millilitre (cp/ml). Two children (3.9%) died and another 11 (22%) suffered 13 severe clinical events. At month 12, mean WAZ had improved by 0.63 (Pâ€‰<â€‰0.001) and mean HAZ by 0.57 (Pâ€‰<â€‰0.001). Mean CD4% had risen to 24 (Pâ€‰<â€‰0.001). Viral load was below 300 RNA cp/ml in 81% of the children; HIV resistance mutations were detected in 11 (21.6%).


CONCLUSION
The once-a-day combination of DDI + 3TC + EFV is an alternative first-line treatment for HIV-1-infected children. Dose adjustment should further improve efficacy.",2011,Bulletin of the World Health Organization
Pretreatment risk management of a novel nomogram model for prediction of thoracoabdominal extrahepatic metastasis in primary hepatic carcinoma,"BackgroundExtrahepatic metastasis is the independent risk factor of poor survival of primary hepatic carcinoma (PHC), and most occurs in the chest and abdomen. Currently, there is still no available method to predict thoracoabdominal extrahepatic metastasis in PHC. In this study, a novel nomogram model was developed and validated for prediction of thoracoabdominal extrahepatic metastasis in PHC, thereby conducted individualized risk management for pretreatment different risk population.MethodsThe nomogram model was developed in a primary study that consisted of 330 consecutive pretreatment patients with PHC. Large-scale datasets were extracted from clinical practice. The nomogram was based on the predictors optimized by data dimension reduction through Lasso regression. The prediction performance was measured by the area under the receiver operating characteristic (AUROC), and calibrated to decrease the overfit bias. Individualized risk management was conducted by weighing the net benefit of different risk population via decision curve analysis. The prediction performance was internally and independently validated, respectively. An independent-validation study using a separate set of 107 consecutive patients.ResultsFour predictors from 55 high-dimensional clinical datasets, including size, portal vein tumor thrombus, infection, and carbohydrate antigen 125, were incorporated to develop a nomogram model. The nomogram demonstrated valuable prediction performance with AUROC of 0.830 (0.803 in internal-validation, and 0.773 in independent-validation, respectively), and fine calibration. Individual risk probability was visually scored. Weighing the net benefit, threshold probability was classified for three-independent risk population, which wasâ€‰<â€‰19.9%, 19.9â€“71.8% andâ€‰>â€‰71.8%, respectively. According to this classification, pretreatment risk management was based on a treatment-flowchart for individualized clinical decision-making.ConclusionsThe proposed nomogram is a useful tool for pretreatment risk management of thoracoabdominal extrahepatic metastasis in PHC for the first time, and may handily facilitate timely individualized clinical decision-making for different risk population.",2019,Journal of Translational Medicine
Generalized Bayesian Factor Analysis for Integrative Clustering with Applications to Multi-Omics Data,"Integrative clustering is a clustering approach for multiple datasets, which provide different views of a common group of subjects. It enables analyzing multi-omics data jointly to, for example, identify the subtypes of diseases, cells, and so on, capturing the complex underlying biological processes more precisely. On the other hand, there has been a great deal of interest in incorporating the prior structural knowledge on the features into statistical analyses over the past decade. The knowledge on the gene regulatory network (pathways) can potentially be incorporated into many genomic studies. In this paper, we propose a novel integrative clustering method which can incorporate the prior graph knowledge. We first develop a generalized Bayesian factor analysis (GBFA) framework, a sparse Bayesian factor analysis which can take into account the graph information. Our GBFA framework employs the spike and slab lasso (SSL) prior to impose sparsity on the factor loadings and the Markov random field (MRF) prior to encourage smoothing over the adjacent factor loadings, which establishes a unified shrinkage adaptive to the loading size and the graph structure. Then, we use the framework to extend iCluster+, a factor analysis based integrative clustering approach. A novel variational EM algorithm is proposed to efficiently estimate the MAP estimator for the factor loadings. Extensive simulation studies and the application to the NCI60 cell line dataset demonstrate that the propose method is superior and delivers more biologically meaningful outcomes.",2018,2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA)
Clinical Research of Catheter Ablation for 60 Patients with Paroxysmal Atrial Fibrillation,"Objective To investigate the effectiveness and safety of catheter ablation in the treatment of paroxysmal atrial fibrillation.Methods A total of 60 patients with paroxysmal atrial fibrillation during the period from July 2007 to August 2010 were selected,including 30 cases with circumferential pulmonary vein ablation guided by single Lasso and Carto technique(study group),30 cases with antiarrhythmic drugs(control group).Results During the 3ï½ž36 months of follow-up,in study group,atrial fibrillation recurred in 3 cases,the first clinic success rate was 90%.Complications occurred in 4 cases,including vagal reflex in 2 cases,femoral vein hematoma in 1 case and gastrointestinal bleeding in 1 case.In control group,the effective rate was 36.7%,complications occurred in 10 cases,including cerebral infarction in 4 cases(1 case of death,and 3 cases of hemiplegia),hemiplegia caused by cerebral hemorrhage in 1 case,subcutaneous hemorrhage in 2 cases and gastrointestinal bleeding in 1 case,abnormal thyroid function because of amiodarone in 2 cases.In all,serious complications occurred in 8 cases(26.6%).Conclusion Circumferential pulmonary vein ablation guided by single Lasso and Carto technique is more effective and safer than drug treatment.",2011,Journal of Kunming Medical University
Compressed Sensing using Generative Models,"The goal of compressed sensing is to estimate a vector from an underdetermined system of noisy linear measurements, by making use of prior knowledge on the structure of vectors in the relevant domain. For almost all results in this literature, the structure is represented by sparsity in a well-chosen basis. We show how to achieve guarantees similar to standard compressed sensing but without employing sparsity at all. Instead, we suppose that vectors lie near the range of a generative model G : â„k â†’ â„n. Our main theorem is that, if G is L-Lipschitz, then roughly O(k log L) random Gaussian measurements suffice for an l2/l2 recovery guarantee. We demonstrate our results using generative models from published variational autoencoder and generative adversarial networks. Our method can use 5-10x fewer measurements than Lasso for the same accuracy.",2017,
I Image-based 3d Recording 3d Recording for Archaeological Fieldwork 2,"n archaeology, measurement and documentation are both important, not only to record endangered archaeological sites, but also to record the excavation process itself. Annotation and precise documentation are important because evidence is actually destroyed during archaeological work. On most sites, archaeologists spend a large amount of time drawing plans, making notes, and taking photographs. Because of the publicity that accompanied some recent archaeological research projects , such as Stanford's Digital Michelangelo project 1 or IBM's Pieta project, 2 archaeologists are becoming aware of the advantages of using 3D visualization tools. Archaeologists can now use the data recorded during excavations to generate virtual 3D models suited for project report presentation, restoration planning, or even digital archiving, although many issues remain unresolved. Until recently, the cost in time and money to generate virtual reconstructions remained prohibitive for most archaeological projects. At a more modest level, some archaeologists use commercially available software, such as PhotoModeler (http://www.photo-modeler.com), to build simple virtual models. These models can suffice for some types of presentations, but typically lack the detail and accuracy needed for most scientific applications. Clearly, archaeologists need more flexible measurement techniques, especially for fieldwork. Archaeologists should be able to acquire their own measurements simply and easily. Our image-based 3D recording approach offers several possibilities. 3-8 To acquire a 3D reconstruction, our system lets archaeologists take several pictures from different viewpoints using a standard photo or video camera. In principle, using our system means that archaeologists need not take additional measurements of the scene to obtain a 3D model. However, a reference length can help in obtaining the recon-struction's global scale. Archaeologists can use the resulting 3D model for measurement and visualization purposes. Figure 1 shows an example of the types of pictures possible with a standard camera. In developing our system, we regularly visited Sagalassos, a site that is one of the largest archaeological projects in the Mediterranean. The site consists of elements from a Greco-Roman period spanning more than a thousand years from the 4th century BC to the 7th century AD. Sagalassos, one of the three great cities of ancient Pisidia, lies a few miles north of the village Aglassun in the province of Burdur, Turkey. The ruins of the city lie on the southern flank of the Aglassun mountain ridge (a part of the Taurus mountains) at an elevation of several thousand feet. Figure 2 shows Sagalassos against the mountains. A team â€¦",2003,
"Ultrastructural and immunohistochemical investigation on the gills of the teleost, Thalassoma pavo L., exposed to cadmium.","An investigation was conducted to determine the effects of the heavy metal, cadmium (Cd), on the gills of the teleost fish, Thalassoma pavo Linnaeus, 1758. The fishes were exposed to several sublethal concentrations of cadmium (10, 40, 60 and 120 Î¼M (mg/L)) for a period of 48, 96 and 192 h. The value of the LC50 after 96 h of cadmium exposure, determined using the System of Finney, was equal to 128.3 Î¼M. The gills of the fishes were examined by light and electron microscopy. Toxic, apoptotic and cadmium effects were analyzed using some neuropeptides, metallothioneins (MT), caspase 3, PCNA and calmodulin, as bioindicators, respectively. The results showed that the alterations in the gills were proportional to the exposure periods and concentrations of the metal, which were found to be both dose and time dependent. The biological responses in the gills of the tested animals are discussed in relation to results obtained by analysis of the biomarkers. These data may be used for the planning of a model to determine biological risk in the marine environment and may be particularly useful to investigate organisms exposed to cadmium.",2011,Acta histochemica
"Defective acidification ofendosomes inChinese hamster ovarycell mutants ""cross-resistant","ABSTRACT Like manyphysiological ligands, several virusesandtoxins entermammaliancells throughreceptor-mediateden-docytosis. Onceinternalized, the nucleic acids ofseveral virusesandthetoxic subunitofdiphtheriatoxin gainaccess to thecytosolof the host cell through anacidic intracellular compartment. Inthis report,wepresentevidencethatoneclassofmutantsofChinesehamsterovary (CHO)-K1 cells, whichis ""cross-resistant"" toPseu- domonas exotoxinA, diphtheria toxin, andseveralanimalviruses,hasadefect in acidification ofthe endosome. Cells wereallowedto internalize fluorescein isothiocyanate-conjugated dextran be-fore subcellular fractionation. Fluorescence measurements onsubcellular fractions permitted measurementof the internal pHof the isolated endosomes and lysosomes. Ourresults showthat(i) endosomes andlysosomes fromCHO-KIcells maintainanacidicpH, (ii) acidificationofbothendosomesand lysosomes is mediatedbya Mg2""/ATP-dependent process, (iii) GTPcansatisfytheATPrequirementforacidification of",1983,
Abrupt elastic-to-plastic transition in pentagonal nanowires under bending,"In this study, pentagonal Ag and Au nanowires (NWs) were bent in cantilever beam configuration inside a scanning electron microscope. We demonstrated an unusual, abrupt elastic-to-plastic transition, observed as a sudden change of the NW profile from smooth arc-shaped to angled knee-like during the bending in the narrow range of bending angles. In contrast to the behavior of NWs in the tensile and three-point bending tests, where extensive elastic deformation was followed by brittle fracture, in our case, after the abrupt plastic event, the NW was still far from fracture and enabled further bending without breaking. A possible explanation is that the five-fold twinned structure prevents propagation of critical defects, leading to dislocation pile up that may lead to sudden stress release, which is observed as an abrupt plastic event. Moreover, we found that if the NWs are coated with alumina, the abrupt plastic event is not observed and the NWs can withstand severe deformation in the elastic regime without fracture. The coating may possibly prevent formation of dislocations. Mechanical durability under high and inhomogeneous strain fields is an important aspect of exploiting Ag and Au NWs in applications like waveguiding or conductive networks in flexible polymer composite materials. Introduction Nanostructures comprised of noble metals with face centered cubic (FCC) crystal structure (Au, Ag and Cu according to the most common physical definition) prepared via soft chemical colloidal techniques often demonstrate a morphology with axes of five-fold (pentagonal) symmetry [1]. Depending on the synthesis conditions such structures can be synthesized in the form Beilstein J. Nanotechnol. 2019, 10, 2468â€“2476. 2469 of 0D nanoparticles or high-aspect ratio 1D nanowires (NWs) with pentagonal cross-section [2,3]. The pentagonal NWs can be considered as 1D materials consisting of five prismatic monocrystalline domains with a triangular cross-section rotated relative to each other by approximately 72Â°, as shown schematically in Figure 1. The crystalline domains are divided by twin boundaries [4,5]. Due to the fact that the five fcc equilateral triangular segments connected by twin boundaries cannot make 360Â°, such an exotic structure cannot exist without internal strain with corresponding mechanical stress and stored elastic energy proportional to the volume [6]. Figure 1: Schematic and SEM image of a pentagonal silver nanowire (Ag NW). SEM image adapted with permission from [28], copyright 2013 Elsevier. Inner stress and peculiar structure of the pentagonal materials is expected to lead to mechanical properties different from those of regular monocrystals [7]. This fact must be taken into account when considering applications in which nanocrystals are subjected to mechanical deformation, for example, NW-based nanoswitches [8], nanoresonators [9] and flexible electronics [10,11]. In the last case NWs are used as a conductive network in composition with flexible polymer materials such as polydimethylsiloxane (PDMS) [12,13]. The reliability of flexible devices in high-strain conditions will be governed by the mechanical reliability of the individual NWs inside the conductive network [14-16]. Ag NWs are a promising material for flexible transparent electrodes [17]. Plasmon propagation and the optical properties of Ag and Au NWs make them attractive for nanophotonics as waveguides for visible light [18-23]. In all these applications, NWs may experience severe and sometimes repeated bending deformations. Therefore, the proper understanding of the mechanical behaviour of NWs under bending deformation and the use of appropriate theoretical models is essential for the design and function of NW-based devices. The mechanical properties of pentagonal NWs were studied both theoretically and experimentally in different configurations, including uniaxial loading (tensile and compression tests) [24,25], three-point bending [26,27], cantilever beam bending [28,29] and nanoindentation [30]. Several interesting phenomena were reported that can be attributed to the peculiar inner structure of pentagonal NWs. Qin et al. reported on recoverable plasticity in penta-twinned Ag NWs [31] in tensile tests. The enhanced elasticity, exceptional strength and unexpected brittle failure of pentagonal Ag NWs were reported by Zhu et al. [25] in tensile tests and by Wu et al. [27] in three-point bending tests. According to the authors, the grain orientation and grainboundary arrangement within the NWs are responsible for their exceptional strength and brittle-like fracture. The slip directions in the grains intersect with the twin boundaries, resulting in uniform structure hardening. Five-fold grain boundaries intersect with all possible slip systems restricting the motion of dislocations along any slip direction by the twin boundaries that extend to the center of the wire preventing the initiation of plastic deformation. This makes five-fold twinned NW grainboundary-hardened material that sacrifices ductility for strength [27]. In both the tensile and three-point bending tests, the NW is rigidly fixed at both ends. Even though the NW is bent in the three-point bending test, the deflection of the NW before failure is relatively small in comparison to the so-called pure bending conditions when one of the NW ends is free. From the viewpoint of applications (e.g., waveguiding) the behavior of the NW under a pure bending condition, as opposed to tensile or three-point bending, is of great importance, as it is related to the ability of the NWs to form curved pathways for electromagnetic radiation. Any crack or other discontinuities that are introduced by bending can prevent plasmon propagation in the NW [19]. Pure bending conditions are realized in the cantilever beam bending configuration where the NW is fixed at one end and the free end is pushed by the probe. Such a configuration enables a high degree of bending. The behavior of the Ag NWs under pure bending conditions was studied experimentally by Vlassov et al. [28] in cantilever beam bending tests. Similar to Zhu and Wu [25,27], we noticed brittle-like fracture of the NWs in 1/3 of the cases. In 2/3 of the cases, plastic yield was reported. However, it should be noted that loading was applied in dynamic mode, i.e., the probe was oscillating at a frequency of Beilstein J. Nanotechnol. 2019, 10, 2468â€“2476. 2470 around 32 kHz and the amplitude of the oscillations was comparable to the diameter of the NWs. Therefore, it is difficult to exclude the possible fatigue effect, indicating the need to perform cantilever beam bending tests in continuous loading mode. In present work we performed bending tests on pentagonal Ag and Au NWs in a cantilever beam configuration inside a scanning electron microscope (SEM) for visual guidance. We demonstrate an unusual, abrupt elastic-to-plastic transition, observed as a sudden change of the NW profile from smooth arcshaped to angled knee-like during the bending in the narrow range of bending angles (critical bending angle). Moreover, we show that if the NWs are coated with alumina, an abrupt plastic event is not observed and the NWs can withstand severe deformation in the elastic regime without fracture. Materials and Methods Nanowires: Ag NWs were purchased from Blue Nano (USA). Au NWs were purchased from Smart Materials (Latvia) [32]. SEM and TEM characterization: The micrographs of the NWs were obtained with a high-resolution scanning electron microscope (HR-SEM, Helios Nanolab 600, FEI) and transmission electron microscope (TEM, Tecnai GF20, FEI). The NWs were drop-cast on either TEM grids with lacey carbon (Agar, UK) for TEM characterization, or on glassy carbon and silicon wafers (100, n/phosphorus doped, 3â€“6 Î©Â·cm, Mat-Technology) for SEM imaging. Experimental set-up for bending tests: The NWs were dropcast on TEM grids (Agar) so that some of the NWs were partially suspended over a hole. The bending tests were performed inside a HR-SEM (Helios Nanolab 600, FEI) with a cantilever beam-bending configuration in a similar manner as described in [33,34]. The NWs were bent in-plane with a substrate by an atomic force microscope (AFM) probe (ATECâˆ’CONT cantilevers, Nanosensor, Neuchatel, Switzerland, C = 0.2 NÂ·mâˆ’1) attached to a micromanipulator (MM3AEM, Kleindiek, Germany). FEM simulations: The cantilevered beam bending experiments were simulated using the finite element method (FEM) with COMSOL Multiphysics 5.2 solid mechanics module. For this the linear elastic material model from COMSOL was chosen. The simulations were based on a recently developed segmented pentagonal NW model [29]. In this model, the pentagonal NW was composed of five triangular prism-shaped domains with vertex angle of 72Â°. These domains represent the FCC single crystals. Each domain was assigned an elasticity matrix of Ag or Au corresponding to their crystal structure to account for structural anisotropy. The elasticity matrix independent parameters in Voigt notation for Ag were C11 = 124 GPa, C12 = 93.4 GPa, C44 = 46.1 GPa and for Au C11 = 190 GPa, C12 = 161 GPa, C44 = 42.3 GPa. The NW was fixed by a portion of the bottom facet at one end and pushed at the other end by applying gradually increasing force. The mesh used in these simulations is described in previous work [29]. The yield strength values were obtained from the FEM NW model by fitting its profile to the experimentally bent profiles of Ag or Au NWs at the critical bending angle, before the abrupt transition to plastic deformation. MD simulations: Classical molecular dynamics (MD) simulations were conducted to investigate the atomic deformation behavior of the penta-twinned Ag NW under bending. The largescale open-source molecular dynamics simulator, LAMMPS, developed by Sandia National Laboratories, was adopted [35]. The interatomic interactions are described by the widely used embedded atom method (EAM), and a potential for Ag is utiliz",2019,Beilstein Journal of Nanotechnology
New Advances of the Study of Cretaceous Strata in Southeastern China Based on Comprehensive Stratigraphy,"Some problems of Cretaceous strata in southeastern China especialy the key horizones which are still in controversy were studied based on comprehensive stratigraphy including basin analysis, tectono-sedimentology, event stratigraphy and sequence stratigraphy, and some new understandings were put forward through synthetic analysis and judge on their genetic mechanism. It is recognized that the formation and evolution of basins, tectono-sedimentary cycles, sedimentary facies sequences and stratigraphic sequences, geological events are mainly controlled by the same episodic tectonic movement, so all of them are the geological records resulting from the same cause and expressed in different styles. There are close genetic connections and corresponding relationships among them and can be examed and complemented by each other, thus deepening relevant studies. New ideas about the following problems were proposed: the age of ""Tangshang Formation"", the existence of ""Lishui Movement"",the horizonal relationship between Yongkang Group and ""Tiantai Group"", as well as a-mong the molassoid formations such as Fangyan Formation, Zhongdai Formation and ""Chichengshan Formation"". Eventually, a regional correlation scheme of Cretaceous strata in southeasthern China was suggested.",2001,Acta Geological Sinica
Endoscopic Gastrostomy Button With Double-Lasso U-Stitch in Children,"BACKGROUND AND OBJECTIVES
Placement of surgical gastric access is a common operative procedure, with multiple techniques. We describe a cost-effective, safe, and easy-to-perform primary endoscopic gastrostomy button placement in the pediatric population, using a novel double-transcutaneous lasso U-stitch push technique.


METHODS
This is a retrospective review of a single center's experience of 24 consecutively performed primary gastrostomy button placements in infants and children aged 3 weeks to 20 years, from October 2012 through October 2014.


RESULTS
The procedure was generally well tolerated, with no intraoperative complications. No conversions to laparoscopic or open procedures were necessary. There were no early tube dislodgements and no postoperative complications within the first 4 weeks.


CONCLUSION
The endoscopic primary gastrostomy button placement with a transcutaneous lasso U-stitch is a safe, fast, elegant, and cost-effective alternative to a standard percutaneous endoscopic gastrostomy placement.",2015,JSLS : Journal of the Society of Laparoendoscopic Surgeons
Granger Causality for Heterogeneous Processes,"Discovery of temporal structures and finding causal interactions among time series have recently attracted attention of the data mining community. Among various causal notions graphical Granger causality is well-known due to its intuitive interpretation and computational simplicity. Most of the current graphical approaches are designed for homogeneous datasets i.e. the interacting processes are assumed to have the same data distribution. Since many applications generate heterogeneous time series, the question arises how to leverage graphical Granger models to detect temporal causal dependencies among them. Profiting from the generalized linear models, we propose an efficient Heterogeneous Graphical Granger Model (HGGM) for detecting causal relation among time series having a distribution from the exponential family which includes a wider common distributions e.g. Poisson, gamma. To guarantee the consistency of our algorithm we employ adaptive Lasso as a variable selection method. Extensive experiments on synthetic and real data confirm the effectiveness and efficiency of HGGM.",2019,
"YM2:Continuum expectations, lattice convergence, and lassos","The two dimensional Yang-Mills theory (YM2) is analyzed in both the continuum and the lattice. In the complete axial gauge the continuum theory may be defined in terms of a Lie algebra valued white noise, and parallel translation may be defined by stochastic differential equations. This machinery is used to compute the expectations of gauge invariant functions of the parallel translation operators along a collection of curvesC. The expectation values are expressed as finite dimensional integrals with densities that are products of the heat kernel on the structure group. The time parameters of the heat kernels are determined by the areas enclosed by the collectionC, and the arguments are determined by the crossing topologies of the curves inC. The expectations for the Wilson lattice models have a similar structure, and from this it follows that in the limit of small lattice spacing the lattice expectations converge to the continuum expectations. It is also shown that the lasso variables advocated by L. Gross [36] exist and are sufficient to generate all the measurable functions on the YM2-measure space.",1989,Communications in Mathematical Physics
The role of scale insects as vectors of grapevine viruses in German viticulture,"Grapevine leafroll is one of the most widespread and economically important virus diseases of grapevine worldwide. It is caused by different Grapevine leafrollassociated viruses (GLRaV). Typically, symptomatic leaves of vines show a progressing interveinal discoloration and frequently roll downwards. Infected vines have often lower sugar content and the yield can be severely reduced. Scale insects are vectors of these viruses. The following species are known vectors and present in German viticulture: Phenacoccus aceris, Heliococcus bohemicus, Pulvinaria vitis and Parthenolecanium corni.",2017,
Proceedings of the 1993 Connectionist Models Summer School,"Contents: Part I:Neuroscience. T. Rebotier, J. Droulez, Sigma-Pi Properties of Spiking Neurons. H.S. Wan, D.S. Touretzky, A.D. Redish, Towards a Computational Theory of Rat Navigation. H.T. Blair, Evaluating Connectionist Models in Psychology and Neuroscience. Part II:Vision. J. Sirosh, R. Miikkulainen, Self-Organizing Feature Maps with Lateral Connections: Modeling Ocular Dominance. A.K. Bhattacharjya, B. Roysam, Joint Solution of Low, Intermediate, and High Level Vision Tasks by Global Optimization: Application to Computer Vision at Low SNR. T.B. Ghiselli-Crippa, P.W. Munro, Learning Global Spatial Structures from Local Associations. Part III:Cognitive Modeling. D. Ascher, A Connectionist Model of Auditory Morse Code Perception. V. Dragoi, J.E.R. Staddon, A Competitive Neural Network Model for the Process of Recurrent Choice. A.M. Lindemann, A Neural Network Simulation of Numerical Verbal-to-Arabic Transcoding. T. Lund, Combining Models of Single-Digit Arithmetic and Magnitude Comparison. I.E. Dror, Neural Network Models as Tools for Understanding High-Level Cognition: Developing Paradigms for Cognitive Interpretation of Neural Network Models. Part IV:Language. F.J. Eisenhart, Modeling Language as Sensorimotor Coordination. A. Govindjee, G. Dell, Structure and Content in Word Production: Why It's Hard to Say Dlorm. P. Gupta, Investigating Phonological Representations: A Modeling Agenda. H. Schutze, Y. Singer, Part-of-Speech Tagging Using a Variable Context Markov Model. M. Spivey-Knowlton, Quantitative Predictions from a Constraint-Based Theory of Syntactic Ambiguity Resolution. B.B. Tesar, Optimality Semantics. Part V:Symbolic Computation and Rules. K.G. Daugherty, M. Hare, What's in a Rule? The Past Tense by Some Other Name Might Be Called a Connectionist Net. A. Almor, M. Rindner, On the Proper Treatment of Symbolism -- A Lesson from Linguistics. L.F. Niklasson, Structure Sensitivity in Connectionist Models. M. Crucianu, Looking for Structured Representations in Recurrent Networks. I. Tchoumatchenko, Back Propagation with Understandable Results. M.W. Craven, J.W. Shavlik, Understanding Neural Networks via Rule Extraction and Pruning. A-H. Tan, Rule Learning and Extraction with Self-Organizing Neural Networks. Part VI:Recurrent Networks and Temporal Pattern Processing. J.F. Kolen, Recurrent Networks: State Machines or Iterated Function Systems? F. Cummins, R.F. Port, On the Treatment of Time in Recurrent Neural Networks. J.D. McAuley, Finding Metrical Structure in Time. C. Stevens, J. Wiles, Representations of Tonal Music: A Case Study in the Development of Temporal Relationships. M.A.S. Potts, D.S. Broomhead, J.P. Huke, Applications of Radial Basis Function Fitting to the Analysis of Dynamical Systems. M.E. Young, T.M. Bailey, Event Prediction: Faster Learning in a Layered Hebbian Network with Memory. Part VII:Control. S. Thrun, A. Schwartz, Issues in Using Function Approximation for Reinforcement Learning. P. Sabes, Approximating Q-Values with Basis Function Representations. K.L. Markey, Efficient Learning of Multiple Degree-of-Freedom Control Problems with Quasi-Independent Q-Agents. A.L. Tascillo, V.A. Skormin, Neural Adaptive Control of Systems with Drifting Parameters. Part VIII:Learning Algorithms and Architectures. R.C. O'Reilly, Temporally Local Unsupervised Learning: The MaxIn Algorithm for Maximizing Input Information. V.R. de Sa, Minimizing Disagreement for Self-Supervised Classification. S.N. Lindstaedt, Comparison of Two Unsupervised Neural Network Models for Redundancy Reduction. Z. Ghahramani, Solving Inverse Problems Using an EM Approach to Density Estimation. M. Finke, K-R. Muller, Estimating A-Posteriori Probabilities Using Stochastic Network Models. Part IX:Learning Theory. A.S. Weigend, On Overfitting and the Effective Number of Hidden Units. R. Dodier, Increase of Apparent Complexity Is Due to Decrease of Training Set Error. G.B. Orr, T.K. Leen, Momentum and Optimal Stochastic Search. R. Garces, Scheme to Improve the Generalization Error. M.P. Perrone, General Averaging Results for Convex Optimization. R.A. Caruana, Multitask Connectionist Learning. Z. Cataltepe, Y.S. Abu-Mostafa, Estimating Learning Performance Using Hints. Part X:Simulation Tools. A. Jagota, A Simulator for Asynchronous Hopfield Models. A. Linden, An Object-Oriented Dataflow Approach for Better Designs of Neural Net Architectures.",2014,
Integrating logic-based machine learning and virtual screening to discover new drugs,"Investigational Novel Drug Discovery by Example (INDDExâ„¢) is a technology developed to guide hit to lead discovery by learning rules from existing active compounds that link activity to chemical substructure. INDDEx is based on Inductive Logic Programming [1], which learns easily interpretable qualitative logic rules from active ligands that give an insight into chemistry, relate molecular substructure to activity, and can be used to guide the next steps of drug design chemistry. Support Vector Machines weight the rules to produce a quantitative model of structure-activity relationships. Whereas earlier testing [2,3] was performed on single dataset examples, this talk presents the largest and fullest test of the method. The method was benchmarked on the Directory of Useful Decoys (DUD) datasets [4], using the same methodology described in the paper on the assessment of LASSO [5] and DOCK. For each of the DUD datasets, the known active ligands were mixed with all the decoy compounds in DUD, and the retrieval rates of INDDEx and DUD were measured when they were trained on 2, 4, and 8 of the known active ligands (Figure 2). Early retrieved compounds showed high topological differences to molecules used as training data, showing the strength of this method for scaffold hopping. This work was supported by a BBSRC case studentship with Equinox Pharma Ltd (http://www.equinoxpharma.com). 
 
 
 
Figure 1 
 
Recovery of actives in each of the DUD datasets from all decoys in the DUD, averaged across all 40 datasets.",2012,Journal of Cheminformatics
Î ÎµÏÎ¹Î²Î±Î»Î»Î¿Î½Ï„Î¹ÎºÎ· Î”Î¹Î±Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ· Î‘ÏƒÏ„Î¹ÎºÏ‰Î½ Î£Ï„ÎµÏÎµÏ‰Î½ Î‘Ï€Î¿Î²Î»Î·Ï„Ï‰Î½ Î”Î·Î¼Î¿Ï… Î•Î»Î±ÏƒÏƒÎ¿Î½Î±Ï‚,"Waste management is one of the major problems worldwide. The formation of modern economic and social environment tends to address the issue of waste management not as a useless material from which should get rid with the least painful way for the environment, but as a resource that the management should be done through integrated systems aimed mainly to sustainability. The problem of waste management is particularly acute in developed countries where the production of waste through lifestyle and consumption patterns of the population is increasing. Of these countries begins the effords to manage waste through hierarchical, integrated, alternative management systems. 
In this paper, at the first part, regards to the municipal solid waste and their characteristics. Then presents the hierarchical methods of alternative management of municipal solid waste being promoted by the European Union and based on a reduction - prevention, reuse and recycling of waste. Follows the presentation of the current situation in Europe and Greece. 
In the second part is presented the situation of the management of municipal solid waste in the Municipality of Elassona and developed a local project management of municipal solid waste following the hierarchy management set by the European Union and fulfilling the objectives set out in the new National Waste Management Plan. Finally, presented the conclusions.",2016,
Essays on Structural Microeconometrics,"Author(s): Su, Jiun-Hua | Advisor(s): Powell, James | Abstract: This dissertation consists of three chapters studying microeconometric methods. The first two chapters focus on models with unobserved heterogeneity, and topics include testing shape restrictions imposed by economic theory and estimating counterfactual policy effects in duration analysis. In the last chapter, predictive methods in machine learning are adapted to study model selection within the framework of utility-maximizing binary decision-making. These proposed methods are described in greater detail below.Causal inference on the individual treatment effect is fundamental in econometric analysis. In Chapter 1, I develop the concept of structural monotonicity, that is, monotonicity of a structural function in a treatment given any observable covariates and unobserved heterogeneity. Different from regression monotonicity, in which heterogeneous factors average out, structural monotonicity emphasizes the sign of ceteris paribus individual treatment effect. Since economic theory may neither detail enough potential heterogeneous factors nor elaborate on parametric structures, I consider a two-period panel data model with nonseparable time-invariant heterogeneity, and avoid imposing restrictions on the dimensionality of heterogeneity and functional form of the structural function. Structural monotonicity in this setup implies shape constraints on the joint cumulative distribution function (CDF) of outcome variables conditional on the observable treatments and covariates over some regions. These regions are parameterized by a nuisance parameter, which can be consistently estimated. According to the shape constraints on the conditional joint CDF over the estimated regions, I propose a test for structural monotonicity and validate the empirical bootstrap method. Some Monte Carlo experiments show that the proposed test can detect departures from structural monotonicity, which are not revealed by some existing tests for regression monotonicity.The presence of unobserved heterogeneity is also essential for policy effects especially in duration analysis. In Chapter 2, I propose a counterfactual Kaplan-Meier estimator that incorporates time-invariant exogenous covariates and nonseparable heterogeneity in duration models with random censoring. The over-parameterization in traditional duration analysis can be avoided because distributional features of unobserved heterogeneity are unspecified. I establish the joint weak convergence of the proposed counterfactual Kaplan-Meier estimator and the traditional Kaplan-Meier estimator under some regularity conditions. Therefore, by comparing the estimated counterfactual and original unconditional distribution of the duration variable, we can evaluate the policy effects, for example the change of duration dependence in response to an exogenous manipulation of covariates.In addition to counterfactual analysis in policy research, a better prediction may improve policy-making. In Chapter 3, I show that in a model of binary decision-making based on the prediction of a binary outcome variable, the semiparametric maximum utility estimation can be viewed as cost-sensitive binary classification. Its in-sample overfitting issue is thus similar to that of perceptron learning in the machine learning literature. To alleviate the in-sample overfitting, I apply techniques in structural risk minimization to construct a utility-maximizing prediction rule. This proposed prediction rule, in comparison to the common machine learning Lasso-logit predictor, has larger relative expected utility in some simulation results when the conditional probability of the binary outcome is misspecified. The results show that a better prediction arising from the combination of machine learning techniques and economic theory can improve policy-making.",2018,
Impact of valacyclovir on genital and plasma HIV-1 RNA: a randomised controlled trial among women taking HAART (ANRS 1285b).,"Impact of valacyclovir on genital and plasma HIV-1 RNA: a randomised controlled trial among women taking HAART (ANRS 1285b) N. Nagot, A. Ouedraogo, I. Konate, L. Vergne, H. Weiss, M.-C. Defer, V. Foulongne, D. Djagbare, A. Sanon, J.-B. Andonaba, P. Becquart, A. Sawadogo, P. Van de Perre, P. Mayaud, ANRS 1285 study group London School of Hygiene and Tropical Medicine, Infectious and Tropical Diseases, London, United Kingdom, Centre Muraz, HIV, Bobo-Dioulasso, Burkina Faso, UMR 145 Montpellier, Virology, Montpellier, France, CHU Souro Sanou, Medecine, Bobo-Dioulasso, Burkina Faso Background: Epidemiological data suggest that HSV2 infection can increase HIV-1 genital shedding, but this causal relationship has never been proven in women taking HAART. Methods: We conducted a proof-of-concept randomised placebo-controlled trial of valacyclovir suppressive treatment (1g-daily for 3-months) among HIV-1/HSV2 coinfected women taking HAART in Burkina Faso. We evaluated the impact on genital and plasma HIV-1 RNA. Participants were followed bi-weekly for 3 months prior to, and 3 months after randomization (=12 visits). Cervico-vaginal lavages were collected for HIV-1 RNA quantitation by real time PCR. Plasma HIV-1 RNA was assessed at every other visit by PCR. For each woman, the difference in median quantity of virus between the 2 phases was calculated, and this difference was compared between arms with the Wilcoxon ranksum test. Results: 60 women were randomized to valacyclovir or placebo (mean CD4 count: 266 and 295/Î¼l, respectively). Women attended 97.5% of visits and their mean drug compliance was 99%. Four women in valacyclovir arm (13%) and six in placebo arm (20%) had detectable plasma HIV-1 RNA at least once during the baseline phase. There was no overall reduction in the proportion of women with at least one episode of detectable genital HIV-1 RNA (36.7% vs 40.0%, p=0.79), nor in the median quantity of genital HIV-1 RNA detected (p=0.38). There was a borderline significant reduction in the quantity of genital HIV-1 RNA in the subgroup of women shedding HIV-1 at baseline (p=0.09). There was also some evidence of a reduction in plasma HIV-1 RNA among the women on valacyclovir (p=0.06). Conclusions: Valacyclovir did not appear to have an impact on genital HIV-1 RNA beyond the levels afforded by HAART, but there was some evidence of a reduction in plasma HIV-1 RNA. This effect should be confirmed in larger trials.",2006,
"Thalassolituus marinus sp. nov., a hydrocarbon-utilizing marine bacterium.","Gram-negative strains, motile by a single polar flagellum, non-pigmented and with a curved rod-shaped morphology, designated IMCC1826(T) and IMCC1883, were isolated from a surface seawater sample from the Yellow Sea. The two strains shared 99.9% 16S rRNA gene sequence similarity and showed 92% DNA-DNA relatedness, suggesting that they belonged to the same genomic species. Phylogenetic analysis based on 16S rRNA gene sequences showed that the two isolates were related most closely to the type strain of Thalassolituus oleivorans with a sequence similarity of 96.4% and formed a robust phyletic lineage with T. oleivorans. DNA-DNA relatedness between the two strains and T. oleivorans DSM 14913(T) was 8.7-11.6%. A putative alkane hydroxylase (alkB) gene was detected in strain IMCC1826(T) by PCR, but the amino acid sequence of the gene was distantly related to that of the AlkB homologue of T. oleivorans DSM 14913(T). As expected from the presence of the alkB gene, the new strains utilized n-tetradecane and n-hexadecane as a carbon source. The DNA G+C content was 54.6-56.0 mol% and the main isoprenoid quinone detected was Q-9. Polar lipids of strain IMCC1826(T) included diphosphatidylglycerol, phosphatidylglycerol, phosphatidylethanolamine and amino-group-containing lipids. On the basis of taxonomic data obtained in this study, strains IMCC1826(T) and IMCC1883 represent a novel species of the genus Thalassolituus, for which the name Thalassolituus marinus sp. nov. is proposed, with IMCC1826(T) (=KCTC 23084(T)=NBRC 107590(T)) as the type strain.",2013,International journal of systematic and evolutionary microbiology
A Generally Efficient Targeted Minimum Loss Based Estimator,"Suppose we observe n independent and identically distributed observations of a finite dimensional bounded random variable. This article is concerned with the construction of an efficient targeted minimum loss-based estimator (TMLE) of a pathwise differentiable target parameter based on a realistic statistical model. The canonical gradient of the target parameter at a particular data distribution will depend on the data distribution through an infinite dimensional nuisance parameter which can be defined as the minimizer of the expectation of a loss function (e.g., log-likelihood loss). For many models and target parameters the nuisance parameter can be split up in two components, one required for evaluation of the target parameter and one real nuisance parameter. The only smoothness condition we will enforce on the statistical model is that these nuisance parameters are multivariate real valued cadlag functions and have a finite supremum and variation norm. We propose a general one-step targeted minimum loss-based estimator (TMLE) based on an initial estimator of the nuisance parameters defined by a loss-based super-learner that uses cross-validation to combine a library of candidate estimators. We enforce this library to contain minimum loss based estimators minimizing the empirical risk over the parameter space under the additional constraint that the variation norm is bounded by a set constant, across a set of constants for which the maximal constant converges to infinity with sample size. We show that this super-learner is not only asymptotically equivalent with the best performing algorithm in the library, but also that it always converges to the true nuisance parameter values at a rate faster than $n{-1/4}$. This minimal rate applies to each dimension of the data and even to nonparametric statistical models. We also demonstrate that the implementation of these constant-specific minimum loss-based estimators can be carried out by minimizing the empirical risk over linear combinations of basis functions under the constraint that the sum of the absolute value of the coefficients is smaller than the constant (e.g., Lasso regression), making our proposed estimators practically feasible. Based on this rate of the super-learner of the nuisance parameter, we can establish that this one-step TMLE is asymptotically efficient at any data generating distribution in the model, under very weak structural conditions on the target parameter mapping and model. We demonstrate our general theorems by constructing such a one-step TMLE of the average causal effect in a nonparametric model, and presenting the corresponding efficiency theorem.",2015,
Design and optimization of wireless sensor networks for localization and tracking,"Knowledge of the position of nodes in a WSN is crucial in most wireless sensor network (WSN) applications. The gathered information needs to be associated with a particular location in a specific time instant in order to appropiately control de surveillance area. Moreover, WSNs may be used for tracking certain objects in monitoring applications, which also requires the incorporation of location information of the sensor nodes into the tracking algorithms. These requisites make localizacion and tracking two of the most important tasks of WSN. Despite of the large research efforts that have been made in this field, considerable technical challenges continue existing in subjects areas like data processing or communications. This thesis is mainly concerned with some of these technical problems. Specifically, we study three different challenges: sensor deployment, model independent localization and sensor selection. The first part of the work is focused on the task of sensor deployement. This is considered critical since it affects cost, detection, and localization accuracy of a WSN. There have been significant research efforts on deploying sensors from different points of view, e.g. connectivity or target detection. However, in the context of target localization, we believe it is more convenient to deploy the sensors in views of obtaining the best estimation possible on the target positioning. Therefore, in this work we suggest an analysis of the deployment from the standpoint of the error in the position estimation. To this end, we suggest the application of the modified CramÂ´er-Rao bound (MCRB) in a sensor network to perform a prior analysis of the system operation in the localization task. This analysis provides knowledge about the system behavior without a complete deployment. It also provides essential information to select fundamental parameters properly, like the number of sensors. To do so, a complete formulation of the modified information matrix (MFIM) and MCRB is developed for the most common measurement models, such as received signal strength (RSS), time-of-arrival (ToA) and angle-of-arrival (AoA). In addition, this formulation is extended for heterogeneous models that combine different measurement models. Simulation results demonstrate the utility of the proposed analysis and point out the similarity between MCRB and CRB. Secondly, we address the problem of target localization which encompasses many of the challenging issues which commonly arise in WSN. Consequently, many localization algorithms have been proposed in the literature each one oriented towards solving these issues. Nevertheless, it have seen tahta the localization performance of above methods usually relies heavily on the availability of accurate knowledge regarding the observation model. When errors in the measurement model are present, their target localization accuracy is degraded significantly. To overcome this problem, we proposed a novel localization algorithm to be used in applications where the measurement model is not accurate or incomplete. The independence of the algorithm from the model provides robustness and versatility. In order to do so, we apply radial basis functions (RBFs) interpolation to evaluate the measurement function in the entire surveillance area, and estimate the target position. In addition, we also propose the application of LASSO regression to compute the weigths of the RBFs and improve the generalization of the interpolated function. Simulation results have demonstrated the good performance of the proposed algorithm in the localization of single or multiples targets. Finally, we study the sensor selection problem. In order to prolong the network lifetime, sensors alternate their state between active and idle. The decision of which sensor should be activated is based on a variety of factors depending on the algorithm or the sensor application. Therefore, here we investigate the centralized selection of sensors in target-tracking applications over huge networks where a large number of randomly placed sensors are available for taking measurements. Specifically, we focus on the application of optimization algorithms for the selection of sensors using a variant of the CRB, the Posterior CRB (PCRB), as the performance-based optimization criteria. This bound provides the performance limit on the mean square error (MSE) for any unbiased estimator of a random parameter, and is iteratively computed by a particle filter (in our case, by a Rao-Blackwellized Particle Filter). In this work we analyze, and compare, three optimization algorithms: a genetic algorithm (GA), the particle swarm optimization (PSO), and a new discrete-variant of the cuckoo search (CS) algorithm. In addition, we propose a local-search versions of the previous optimization algorithms that provide a significant reduction of the computation time. Lastly, simulation results demonstrate the utility of these optmization algorithm to solve a sensor selection problem and point out the reduction of the computation time when local search is applied. ---------------------------------------------------",2014,
Comparison of sparse Bayesian regularization methods for high-dimensional inverse problem,"Design of regularization term is an important part of solution of an ill-posed linear inverse problem. Another important issue is selection of tuning parameters of the regularization term. We address this problem using Bayesian approach which treats tuning parameters as unknowns and estimates them from the data. Specifically, we study regularization known as Automatic Relevance Determination (ARD) and several methods of its solution. The first approach is the conventional Variational Bayes method using the symmetrical factorization of the posterior of the vector of unknowns and the vector of tuning parameters. The second approach is based on the idea of marginalization over the vector of unknowns or the vector of tuning parameters, while the complementary vector is estimated using maximum likelihood. The resulting algorithm is thus an optimization task with non-convex objective function, which is solved using standard gradient methods. The proposed algorithms are tested on real tomographic X-ray data and the comparison with conventional regularization techniques (Tikhonov and Lasso) is performed. The algorithm using marginalization over the tuning parameter is found to be closest to the ground truth with acceptable computational cost. MATLAB Â© implementation of the reconstruction algorithms is freely available for download.",2017,
The Use of isometric transformations and bayesian estimation in compressive sensing for fMRI classification,"Compressive sensing (CS) is a popular technique used to reconstruct a signal from few training examples, a problem which arises in many machine learning applications. In this paper, we introduce a technique to guarantee that our data obeys certain isometric properties. In addition, we introduce a bayesian approach to compressive sensing, which we call ABCS, allowing us to obtain complete statistics for estimated parameters. We apply these ideas to fMRI classification and find that by isometrically transforming our data, significant improvements in classification accuracy can be achieved using the LASSO and Dantzig selector methods, two standard techniques used in CS. In addition, applying the ABCS method offers improvements in classification accuracy over both LASSO and Dantzig. Finally, we find that applying both the ABCS method together with isometric transformations, we are able to achieve an error rate of 0.0%.",2010,"2010 IEEE International Conference on Acoustics, Speech and Signal Processing"
"A new species of the ' marine' genus Thalassosmittia Strenzke & Remmert from Xizang (Tibet), China (Diptera: Chironomidae)","Thalassosmittia montana sp. n. from Xizang (Tibet) is described as male imago. A key to male imagines of the 6 known species of Thalassosmittia Strenzke & Remmert is presented. T. montana differs from the other species of Thalassosmittia, which are all marine, in having no anal lobe, retracted R 4+5 of the wing, R 2+3 running in the middle between R, and R 4+5 , very strong virga and heavily sclerotized, apically toothed phallapodeme.",1993,Insect Systematics & Evolution
New causes of disease.,"As a direct result of increased productivity by the rheumatology community, the number of pages of Arthritis and Rheumatism (A&R) devoted to original scientific research expanded dramatically between 1980 and 1985. The yearly volumes increased from 8 to 12; more pages were devoted to refereed articles, despite a falling acceptance rate; and less emphasis was placed on conference proceedings. To get a flavor of A&R from 1980 into 1985, all the original articles and brief reports were reviewed and tabulated. Articles were assigned to three disease categories: the rheumatoid arthritis (RA) group (RA/ juvenile rheumatoid arthritis/SjÃ¶grenâ€™s syndrome), the connective tissue diseases group (systemic lupus erythematosus [SLE]/scleroderma/myositis), and others (degenerative joint diseases/crystal arthropathies/infection and various infrequent diseases). The disease categories were subdivided into laboratory investigations, clinical investigations, and treatments. The assignments were complicated and often arbitrary, but the results were alike from volume to volume. Original research was usually disease-related, e.g., the description or relevance of a specific autoantibody or antibodies to disease â€œxâ€ or â€œy.â€ The juncture between clinical observations and treatment responses was not always clear, but overall the proportion of laboratory investigations in the major groups remained the same. A few purely clinical descriptions were included in the RA and SLE groups. Basic immunology papers favored humoral factors over cellular elementsâ€” at about two to one. Cytokines, per se, had not made their appearance as yet, but there were several mentions of interferons, albeit measured by bioassays, which complicated their interpretation (1). Animal models of arthritis and SLE were reported in every volume. Crystalassociated arthropathies and pyrophosphate metabolism were described frequently, reflecting the great activity of McCarty and his associates, and the â€œMilwaukee shoulderâ€ entered the medical literature (2â€“4). Publications on degenerative arthritis were scant (perhaps reflecting an editorial bias), but investigations of cartilage, bone, and connective tissue matrix were well represented. As the decade of the 1980s began, several agents of limited efficacy were available for managing RA. Injectable organic gold was still the standard of care. Trials of other approaches appeared in the pages of A&R, including parenteral gold thiomalate vs. oral gold (auranofin); hydroxychloroquine and D penicillamine alone or in combination; and azathioprine vs. D penicillamine in patients who failed crysotherapy. But frustration with the modest improvement in synovitis and little or no protection against bone erosions prompted more radical approaches to treatment. Based on an extensive experience with total lymphoid irradiation (TLI) in the treatment of lymphoproliferative disorders, rheumatologists at Stanford applied this modality to a small number of patients (13 subjects) with â€œintractableâ€ RA and noted a â€œsustained improvementâ€ in 5 of them (5). Longer term results in similar studies from Harvard (6) and Germany (7) were less encouraging. Perhaps better patient selection, combinations of TLI with other cytotoxic agents, or more careful monitoring for side effects would have made the treatment more generally acceptable. This proved unnecessary, however, because of the availability of a new, less toxic, more effective antirheumatic agentâ€”namely methotrexate. In 1947 the antifolate drug, aminopterin, was synthesized for the treatment of tumors, and one year later its derivative methotrexate was introduced. In early studies (1951), methotrexate produced improvement in Nathan J. Zvaifler, MD, FACP, MACR: University of California, San Diego (Editor, Arthritis & Rheumatism, 1980â€“1985). Address correspondence to Nathan J. Zvaifler, MD, University of California, San Diego, School of Medicine, 9500 Gilman Drive, La Jolla, CA 92093-0664. E-mail: nzvaifler@ucsd.edu. Submitted for publication June 27, 2007; accepted June 27, 2007.",2008,Arthritis and rheumatism
Size-selective predation by the cleaner fish Labroides dimidiatus,"A comparison of the size-frequency distribution of parasitic gnathiid isopod larvae in the diet of the cleaner fish Labroides dimidiatus and on six host fish species (Chlorurus sordidus, Ctenochaetus striatus, Hemigymnus melapterus, Scolopsis bilineatus, Siganus doliatus, Thalassoma lunare) was made on one occasion. The comparison was repeated with Hemigymnus melapterus on three occasions and between two islands in Australia. L. dimidiatus selected larger gnathiids at all times at Lizard Island but not at Heron Island. Size-selective predation by L. dimidiatus suggests any potential effect of cleaner fish on parasites may vary according to the size of parasite. However, this effect appears to Vary spatially. (C) 1997 The Fisheries Society of the British Isles.",1997,Journal of Fish Biology
Folded concave penalized learning in identifying multimodal MRI marker for Parkinsonâ€™s disease,"BACKGROUND
Brain MRI holds promise to gauge different aspects of Parkinson's disease (PD)-related pathological changes. Its analysis, however, is hindered by the high-dimensional nature of the data.


NEW METHOD
This study introduces folded concave penalized (FCP) sparse logistic regression to identify biomarkers for PD from a large number of potential factors. The proposed statistical procedures target the challenges of high-dimensionality with limited data samples acquired. The maximization problem associated with the sparse logistic regression model is solved by local linear approximation. The proposed procedures then are applied to the empirical analysis of multimodal MRI data.


RESULTS
From 45 features, the proposed approach identified 15 MRI markers and the UPSIT, which are known to be clinically relevant to PD. By combining the MRI and clinical markers, we can enhance substantially the specificity and sensitivity of the model, as indicated by the ROC curves.


COMPARISON TO EXISTING METHODS
We compare the folded concave penalized learning scheme with both the Lasso penalized scheme and the principle component analysis-based feature selection (PCA) in the Parkinson's biomarker identification problem that takes into account both the clinical features and MRI markers. The folded concave penalty method demonstrates a substantially better clinical potential than both the Lasso and PCA in terms of specificity and sensitivity.


CONCLUSIONS
For the first time, we applied the FCP learning method to MRI biomarker discovery in PD. The proposed approach successfully identified MRI markers that are clinically relevant. Combining these biomarkers with clinical features can substantially enhance performance.",2016,Journal of Neuroscience Methods
French beans for the masses: a modern historical geography of food in Burkina Faso,"Abstract Much of the literature on the modern history of food and diet in Africa focuses on material dearth and cultural loss, described in overarching terms such as â€˜urbanizationâ€™ and â€˜westernizationâ€™. Such generalizations do not capture the complexity of the dietary and culinary changes that have occurred there. This article shows how a geographic perspective enriches the historical analysis of food and foodways, by situating changing norms and practices in spatial and ecological contexts. It examines the twentieth-century history of food consumption in Burkina Faso, focusing on the region of Bobo-Dioulasso, the country's second largest city. It shows how the agricultural policies, dietary preferences, and health concerns of French colonialsâ€”all of which emphasized the need for fresh garden vegetablesâ€”helped to transform not just the regional diet but also the landscape and economy, and thus certain temporal and spatial patterns of daily life. The article also examines how, in recent history, Burkina Faso's incorporation into globalized markets and media networks has resulted in both unintended gluts of luxury food (French beans) as well as growing concerns about the safety and purity of everyday food.",2003,Journal of Historical Geography
Non-linear space-time Kalman filter for cooperative spectrum sensing in cognitive radios,"A cooperative spectrum-sensing problem for a cognitive radio (CR) system is investigated, where CR users collaborate to sense and track the primary usersâ€™ (PUs) activities in frequency-selective fading channels. To sense PUs activities, channel gain estimation is performed by CRs through spaceâ€“time extended Kalman filtering (STEKF). The STEKF method captures the channel gain from any point in space to each CR at each frame for a specific range of frequencies. The proposed channel gain tracking enables CRs to detect the transmit power, location and the number of active subcarriers of each PU via a time spatial weighted non-negative Lasso (TSWNL) algorithm. The TSWNL exploits the sparsity of the PUs activities in a geographical area to track PUs activities in frequency-selective fading channels. Numerical results indicate that the proposed spectrum sensing based on STEKF significantly improves the performance of CRs in tracking of PUs activities.",2014,IET Communications
"Explaining Change in Production and Distribution of Olivine-Tempered Ceramics in the Arizona Strip and Adjacent Areas in the American Southwest (Department of Anthropology, UCSB 2014) dataset","Author(s): Sakai, Sachiko | Advisor(s): Glassow, Michael | Abstract: The Arizona Strip and adjacent areas in Utah and Nevada are in a very marginal environment. This dissertation investigates how small-scale farmers who survived more than 1000 years in this area coped with the challenges of this marginal environment by examining how and why social interaction patterns varied over time in different parts of the region. Artifact assemblages from this area that date between A.D. 200 and 1350 are characterized by widely distributed ceramics tempered with olivine, a volcanic mineral. Sources of olivine lie in the vicinity of Mt. Trumbull and Tuweep, near the northwestern part of the Grand Canyon. The olivine-tempered ceramics were distributed mostly westward from Mt. Trumbull, up to 100 km to the lowland Virgin area in southern Nevada. Ultimately, the goal of this study is to understand why ceramic production and circulation patterns changed during the Ancestral Pueblo occupation of this peripheral area of the American Southwest. I hypothesize that ceramic production and regional interaction patterns were shaped in part by the need to minimize subsistence risk in this marginal agricultural environment. To reconstruct ceramic production and consumption pattern, laser-ablation inductively couple plasma mass spectrometry (LA-ICP-MS) was conducted on 1,069 sherds from the Mt. Trumbull/Tuweep and the lowland Virgin areas, along with source clay samples collected from the same areas. To examine how the use of clay resources changed over time, optically stimulated luminescence (OSL) dating was conducted on 113 sherd samples with compositional information. The data presented here suggest that different environmental conditions favored different social interaction and local ceramic production patterns. In Mt. Trumbull, under unstable climatic conditions and low population density, near the beginning of the Puebloan occupation, pots moved along with human migration. Later, when populations were higher and environmental conditions were equally unstable, pots were moved through interregional trade. In addition, clay resource specialization was favored early but was replaced later by exclusive use of optimal clays when population numbers were higher. In the lowland Virgin area, exchange played an important role as a risk minimization strategy throughout the Puebloan occupation, but clay-resource specialization gained importance later on, when populations increased.",2014,
Spatio-Temporal Spectrum Reuse based on Channel Gain Cartography,"During the last decade, the perceived scarcity of spectrum resources along with the proliferation of new wireless technologies have motivated a substantial research effort on dynamic spectrum management. Although a fixed frequency assignment policy has guiltily led to an alarming spectrum crowding belief, a noticeable underutilization of the allocated frequency bands has been revealed by extensive spectrum occupancy measurements. Therefore, a dynamic re-utilization of the licensed frequencies would be a breakthrough toward a mitigation of the troublesome inefficiency in the spectrum management, aggressively answering to the unceasing demand of resources for new wireless services. 
 
Prominent in this context is the hierarchical spectrum access, an emerging model that envisages secondary users (a.k.a. cognitive radios) aiming to access to the frequency bands of the licensed systems (a.k.a. primary users) in a dynamical and nonintrusive manner. Envisioned as autonomous entities endowed with learning and decisional capabilities, secondary devices accomplish spectrum sensing and dynamical radio resource allocation tasks, thus enabling an opportunistic access to portions of the spectrum under the primary-secondary hierarchy. 
 
The consequent continuous need for a concrete situational awareness required by the cognitive radios demands for innovative signal processing algorithms for high-resolution primary users' activity monitoring, efficient transmission opportunity exploitation and, most importantly, accurate characterization of the surrounding RF propagation environment. Due to the lack of explicit coordination between the two networks, as envisaged in the cognitive radio paradigm, learning the features of the propagation environment is conceivably critical for adaptation of operational system parameters and obligatory protection of the licensed primary system. 
 
To strike the foregoing sensing and control objectives reliably, a significant departure from a one-dimensional view of the RF environment, conventionally attained by point-to-point feedback strategies to acquire channel coefficients as well as interference levels on a per-link basis, is advocated. Toward this direction the present Thesis introduces the concept of channel gain cartography, a groundbreaking geostatistics-inspired application that enables a portrayal of the RF environment impinging upon arbitrary locations in space. The most appealing feature of the proposed tool consists in the non-trivial capability of inferring the channel gain between arbitrary transmitter-receiver locations, based on the only measurements taken among collaborating cognitive radios. Such ability in estimating any-to-any channel gains may open the door to aggressive resource allocation techniques, thus leading to markedly higher spectral efficiency - and finds well-motivated applications not only in the cognitive radio context. 
 
With an accurate RF environment description close at hand, the Thesis presents a primary system's state tracker based on a parsimonious model accounting for the reasonable sparse activity of the primary sources - due to well-known mutual interference concerns - in the monitored geographical area. Motivated by recent advances in sparse linear regression, where the $\ell_1$-norm places itself as a cornerstone for lassoing the non-zero support of the estimand, a sparsity-cognizant state tracker is developed in both centralized and distributed formats. As a byproduct ensued from the parsimonious model, the tracker possesses localization and primary transmission power estimation abilities, which lead to a capability of estimating the actual power spectral density map of the primary system, a continuously-updated portrayal of the aggregate primary power impinging upon the whole monitored geographical region. Detection of the so called spectrum spatial holes is efficiently attainable, thus enhancing the spatial re-use of the primary frequency bands. 
 
Due to the aforementioned lack of explicit support from the primary system, sensing algorithms often face difficulty in acquiring secondary-to-primary users channels. Moreover, the sensing algorithms cannot detect silent licensed receivers, which nevertheless have to be obligatorily protected. 
Based on primary coverage map and channel gain cartography, the approach pursued here is to exploit statistical knowledge of the secondary-to-primary channels, where the combined effect of shadow fading as well as small-scale fading is accounted for, to maximize a given secondary network utility function under chance constraints that ensure protection to any potential licensed user. Albeit a non-convex interference-constrained network utility maximization problem is derived, Karush-Kuhn-Tucker solutions are provably obtained by the proposed algorithms. 
 
Error-corrupted measurements and missing and/or outdated channel gain estimates may undoubtedly compromise the accomplishment of the power control task. To overcome this issue, a novel probabilistic approach encompassing channel knowledge uncertainty on both secondary-to-secondary and secondary-to-primary links is also presented. 
 
The foregoing technical findings are fully corroborated by numerical tests.",2011,
Golden Age PoesÃ­a de negros and Orlando di Lasso's Moresche: A Possible Connection,"THE moresca is a literary-musical form that appeared in 16th-century Naples as an offshoot of a genre variously called canzone villanesca, villotta, villanella or napolitana, all of these describing a secular song in the Neapolitan dialect (Cardamone, 25-27; 155). The first known collection to consist entirely of moresche was published in 1555 (Cardamone, 21; 158-59). The genre, whose protagonists are African slaves, was short-lived and never achieved wide popularity. The musicologist Alfred Einstein describes its essence as follows: ""it [the moresca] never has stanzaic form, but is rather a show piece for the entertainment of Neapolitan society and Venetian patricians. Musically speaking, it includes occasional parody of the madrigal, interspersed street ballads, African folklore, spoken gibberish (to add to the humorous element); the lewdness of the situation and the text is sometimes abysmal and diabolic"" (Einstein, vol. 1, p. 373; cited in Cardamone, 158). The immediate antecedents of the moresca are unknown. Cardamone (159) and Williams (24-26) have pointed to a possible connection between the moresca and a dance of the same name, also known as ballo alla maltese or ballo di sfessania, some of the characters of which are Moorish slaves. A connection with the commedia dell'arte and its stock characters has also been proposed (Williams 5; Katritzky 75-76). In this note, I suggest that the moresca may be connected to yet another source, namely, poesia de negros, which occupied a prominent place in the contemporary Spanish music, theater and letters. In 1581 Orlando di Lasso, a famous Belgian-born composer, published a collection of songs he had reportedly written in his youth, Libro de villanelle, moresche, et altre canzoni a 4, 5, 6, et 8 voci (Erb, 18-19; Williams, 3; 7). The collection consists of twenty-three songs, fifteen of which are written in Neapolitan, one is a todesca imitating the broken Italian of German mercenaries (no. 12), one a padovana (no. 17), and the remaining six moresche imitating the language of African slaves (nos. 8, 13, 16, 18, 19, 20 and part of 23) (Reese, 444; Williams, 4). The moresca of immediate interest to the argument of this paper is Canta, Giorgia, which is no. 20 in this collection; its full text is reproduced in the Appendix to this note. Canta, Giorgia consists of three loosely connected parts, in the first of which a white master or mistress--gente ianca--asks an African slave, Giorgio, to sing (""Canta, Giorgia, canta""); which he refuses saying: ""Giorgia non pote cantar!"" In the second part, Giorgio talks to his sweetheart Lucia, and in the third part of this composition he sings a lewd song, accompanying himself on the lute. The first part of Canta, Giorgia is strongly reminiscent of an old Spanish nursery rhyme (""un cantarcillo viejo, con que acallavan los ninos"") quoted under ""Argolla"" in Covarrubias's Tesoro de la lengua castellana o espanola: Canta, Jorgico, canta, no quere canta. Canta Jorge por tu fe, y veras que te dare: una argolla para el pie, y otra para la garganta; no quere canta. More significantly, Canta, Giorgia as a whole is reminiscent of the early 16th-century Verses of How a Lady Begs a Black Slave to Sing to Her, attributed to Rodrigo de Reinosa, that are based on the above nursery rhyme (Hill, 18). The fully descriptive title of the piece attributed to Reinosa is Coplas de como vna dama ruega a vn negro que cante en manera de requiebro: y como el negro se dexa rogar en fin la senora vencida de su gracia le offrece su persona (Rodriguez-Monino, Diccionario, no. 824). (2) The similarity between Canta, Giorgia and the above coplas goes beyond the merely textual correspondences (cf. ""Canta, Jorgico, canta,/no quere canta."" with ""Canta, Giorgio, canta"" and ""Giorgia non pote cantar!"") and includes the internal progression of each piece, in which the slave (Jorge or Giorgio), urged to sing by a female companion, at first refuses and then relents. â€¦",2012,Romance Notes
"Vaginal Discharge in the Prostitutes of the Group YÃ¨rÃªlon of Bobo-Dioulasso: Epidemiological, Clinical and Etiological Aspects","The authors report a cross-sectional descriptive 
study over 6 years, from December 8th, 2003 to October 27th, 
2009, involving 911 women involved in the sex trade within the Yerelon group in 
Bobo-Dioulasso. Objectives: To describe the epidemiological, clinical 
and etiological aspects of vaginal discharge in 
women in the Yerelon group of the city Bobo-Dioulasso. Results: Frequency 
of vaginal discharge was 48.89%. The mean age was 28.4 years with extremes of 
16 and 54 years. Single, divorced and widowed women accounted for 78.8% of the study population. Women who never 
attended school and those with primary 
education accounted for 74.3% of the study population. HIV serology was 
positive in 38.4% of cases. The main symptoms were genital itching, 
dyspareunia and urinary signs. The main germs identified in the laboratory were Candida albicans, Trichomonas vaginalis and Gardenerella vaginalis. Conclusion: 
vaginal discharge was found in 48.89% of women in the Yerelon group of 
Bobo-Dioulasso. The clinical study of the discharge and the laboratory results 
allowed a diagnosis and a better management of the leucorrhea in the group 
Yerelon.",2017,Open Journal of Obstetrics and Gynecology
Segregation and Cheap Labour,"The early 1970s saw the emergence of a series of influential studies emphasising â€˜classâ€™ rather than â€˜raceâ€™ as the appropriate analytical category by which to interpret South African history. Far from being an irrational and atavistic phenomenon, and therefore dysfunctional to South Africaâ€™s economic development, it was contended that racial discrimination had functioned to quicken the pace of capitalist accumulation. In a seminal article published in 1972 Harold Wolpe established a theoretical framework for the understanding of segregation. Drawing on the work of the Marxist anthropologist Claude Meillassoux, he declared that the policy of segregation was designed to maintain the productive capacity of the precapitalist economies in the reserves, so as to provide capitalist industry with a cheap supply of migrant labour.1",1989,
DEXA-Measured VAT Robustly Predicts Impaired Glucose Tolerance and Metabolic Syndrome in Obese Women,"Abdominal visceral adiposity (VAT) has been shown to be an independent risk factor for metabolic and cardiovascular disease. Using enCORE analysis version 13.6 on a GE Lunar iDXA, a new fully automated analysis software to measure VAT, we determined the strength of associations between DEXA-derived VAT and other known indicators for diabetes and cardiovascular disease risk in Caucasian and African American obese women. We collected anthropometrics, vital signs, lipid profile, and DXA whole body composition scan for 229 subjects with BMI 30.0 â€“ 49.9 kg/m2 & age 21 to 69 y. We then performed the non-parametric Spearman correlation analysis and found that in subjects overall, DEXA-VAT is positively associated with triglyceride, fasting glucose, fasting insulin, and HOMA-IR, and negatively associated with HDL. Among all anthropometric, body composition and cardiometabolic variables, DEXA-VAT was the most robust predictor of impaired glucose tolerance (IGT) and metabolic syndrome (MetSx) in binary regression analysis, even after adjusting for race. LASSO regression after adjusting for covariates that best predicted IGT and MetSx showed that HOMAIR and DEXA-VAT most significantly predicted IGT (p<0.001, p<0.001, respectively), and DEXA-VAT most significantly predicted MetSx (p<0.001). These observations have implications for VAT associated risk in diabetes and cardiovascular disease. INTRODUCTION â€¢  Abdominal obesity, especially the visceral component of adipose tissue (VAT), is strongly associated with metabolic and cardiovascular risk in humans (1-2). â€¢  The differences in sex and race with regard to body composition and metabolic risk have also been demonstrated with VAT associated risk. â€¢  Although CT and MRI are considered the â€œgold standardsâ€ in the measurement of type and distribution of body fat, dual energy X-ray absorptiometry (DEXA) can accurately measure body composition with high-precision, low X-ray exposure, and short-scanning time (3). â€¢  We previously showed strong correlations between DEXA and MRI whole body composition, with coefficients of variation of â‰¤ 2% for DEXAderived adiposity measures (4). â€¢  In addition to whole body composition, we now have a newly available software to estimate VAT area (cm3) and mass (g) using enCORE analysis version 13.6 (5) on a GE Lunar iDXA. METHODS Study: Cross-sectional design of subjects previously recruited for studies at the Vanderbilt Clinical Research Center. Subjects: 229 subjects with BMI 30.0 â€“ 49.9 kg/m2 & age 21 to 69 y. All records de-identified. Measures Anthropometrics Height, weight, BMI, Waist & hip circumference (WC & HC), waist-to-hip ratio (WHR), waist-toheight ratio (WHtR) Lipid profile Total cholesterol, HDL, LDL, triglyceride (TG) Fasting glucose, insulin, HOMA-IR DEXA whole body composition scan Metabolic disease states â€¢  Impaired Glucose tolerance (IGT): fasting glucose â‰¥100  mg/dL â€¢  Metabolic Syndrome defined as â‰¥ 3 of the following: 1. WC (>102 cm for , >88 cm for ); 2. TG (â‰¥150 mg/dl); 3. HDL (<40 mg/dl in , <50 mg/dl in ); 4. hypertension (â‰¥130/â‰¥85 mmHg); 5. impaired fasting glucose (â‰¥100 mg/dl). Analysis: R version 3.0.1 analyzed with nonparametric distribution. RESULTS DEXA-VAT Associations with Metabolic Risk Factors Overall, DEXA-VAT was positively associated with SBP, DBP, TG, fasting glucose & insulin, HOMA-IR, and negatively associated with HDL. DEXA-VAT was still associated with SBP, DBP, insulin, and HOMA-IR after adjusting for race, and associated with hsCRP after adjusting for the intâ€™n with race. RESULTS Multivariate LASSO Regression for IGT A: combination of anthropometric, body composition, and cardiometabolic variables guided by previous binary regressions presented with adjusted odds ratios (OR); B: ANOVA analysis of A adjusted for race; C: ANOVA analysis of A adjusted for interaction with race. Multivariate LASSO Regression for MetSx A: combination of anthropometric, body composition, and cardiometabolic variables guided by previous binary regressions presented with adjusted odds ratios (OR); B: ANOVA analysis of A adjusted for race; C: ANOVA analysis of A adjusted for interaction with race. CONCLUSION â€¢  DEXA-VAT was positively associated with TG, fasting glucose & insulin, and HOMA-IR, and negatively associated with HDL-C â€¢  In binary regression analysis, DEXA-VAT was a more robust predictor of IGT and MetSx than other anthropometric and body composition variables â€¢  In Mutivariate LASSO regression, the odds ratio for having IGT was most robustly predicted by HOMAIR and DEXA-VAT; the odds ratio for having MetSx was most robustly predicted by DEXA-VAT REFERENCES 1.  Canoy D. Distribution of body fat and risk of coronary heart disease in men and women. Curr Opin Cardiol. 2008 Nov;23(6):591-8. 2.  Shuster A, Patlas M, Pinthus JH, Mourtzakis M. The clinical importance of visceral adiposity: a critical review of methods for visceral adipose tissue analysis. Br J Radiol. 2012 Jan;85(1009):1-10. 3.  Direk K et al. The relationship between DXA-based and anthropometric measures of visceral fat and morbidity in women. BMC Cardiovasc Disord. 2013 Apr 3;13:25. 4.  Silver HJ et al. Comparison of gross body fat-water magnetic resonance imaging at 3 Tesla to dual-energy X-ray absorptiometry in obese women. Obesity. 2013 Apr;21(4): 765-74. 5.  Kaul S, et al. Dual-energy X-ray absorptiometry for quantification of visceral fat. Obesity (Silver Spring). 2012 Jun;20(6):1313-8. ACKNOWLEDGEMENT Research supported by multiple sources obtained by Silver, Buchowski, Shibao & NIH T35DK007383 DEXA-Measured VAT Robustly Predicts Impaired Glucose Tolerance and Metabolic Syndrome in Obese Women 1Bi X., 2Keil C.D., 2Seabolt L., 2Tyree R., 2Buchowski M., 2Kang H., 2Shibao C., 2Silver H.J. 1Jefferson Medical College of Thomas Jefferson University, Philadelphia, PA 2Department of Medicine, School of Medicine of Vanderbilt University, Nashville, TN",2018,
Experiment Design for Closed-loop System Identification with Applications in Model Predictive Control and Occupancy Estimation,"System identification concerns how to construct mathematical models ofdynamic systems based on experimental data. Typically, identification isfollowed by an application which makes use of the identified model. Forinstance, one important application of system identification is in model-basedcontrol design. In control applications it is often possible to externally excitethe system during the data collection experiment. The properties of theexciting input signal influence the quality of the identified model, and a welldesignedinput signal reduces both the required time and effort for doing theexperiment and improves the quality of the estimated model.The objective of this thesis is to develop algorithms and theory for minimumcost experiment design for system identification. In particular, anapplication-oriented framework for designing experiments is considered. Thisprocedure takes the intended model application into account when designingthe experiment. The main goal is to guarantee that the estimated modelresults in an acceptable performance for its intended application.This thesis is divided into two main parts. The first part considers thetheory of application-oriented input design, with special attention to ModelPredictive Control (MPC).We start by studying how to find a convex approximationof the set of models that results in acceptable control performance.The main contribution is using analytical methods to determine applicationsets for controllers with no closed-form control law, for instance MPC. Theapplication-oriented input design problem is then formulated in time domainto enable handling of signals constraints, which often comes from the physicallimitations on the plant and actuators. The framework is then extended toclosed-loop systems. Here two different cases are considered. The first caseassumes that the plant is controlled by a general (either linear or non-linear)but known controller. In the second case, the problem is studied for theparticular case of MPC. The main contribution here is a method to designan external stationary signal via graph theory such that the identificationrequirements and signal constraints are satisfied, simultaneously. There aredifferent sources of uncertainty in application-oriented input design. Thisproblem is investigated based on the results from risk theory and, the uncertaintyis measured, systematically. A new formulation of application-orientedinput design is proposed which is robust to available uncertainties.The second part of this thesis is devoted to study an application of systemidentification and input design in building automation. Monitoring thenumber of occupiers of a room or a building is important for more energyefficient control of Heating, Ventilation and Air Conditioning (HVAC) systems.There exists several issues with using dedicated people counters suchas Radio-Frequency Identifications (RFIDs) and cameras. For instance, installingcameras for monitoring people may raise privacy concerns. Hence,this thesis considers the problem of estimating occupancy based on the informationalready available to HVAC systems. The occupancy estimation is firstformulated as a two-tier problem. In the first tier, the room dynamic is identifiedusing a training dataset which makes use of temporary measurements ofoccupancy. In the second tier, the identified model is employed to formulatethe occupancy estimation problem as a fused-lasso problem. The obtainedivestimator is analyzed to provide conditions under which it results in correctestimates with a guaranteed probability. The proposed method is further developedto be used as a multi-room estimator. To this end, a physics-basedmodel is identified for one room. The identified model is then adjusted forother rooms invoking the physical properties of them such as room volumeand ventilation size. However, since it might not always be possible to collectmeasurements of occupancy for the training purposes, we proceed byproposing a blind identification algorithm which estimates the room dynamicand occupancy signal, simultaneously. Finally, the application-oriented inputdesign framework is employed to study the problem of how to collect datathat is informative enough for occupancy estimation purposes. We evaluatethe effectiveness of all the proposed algorithms either by a real dataset or by simulation examples.",2017,
Regularized extreme learning machine for regression problems,"Extreme learning machine (ELM) is a new learning algorithm for single-hidden layer feedforward networks (SLFNs) proposed by Huang et al. [1]. Its main advantage is the lower computational cost, which is especially relevant when dealing with many patterns defined in a high-dimensional space. This paper proposes an algorithm for pruning ELM networks by using regularized regression methods, thus obtaining a suitable number of the hidden nodes in the network architecture. Beginning from an initial large number of hidden nodes, irrelevant nodes are then pruned using ridge regression, elastic net and lasso methods; hence, the architectural design of ELM network can be automated. Empirical studies on several commonly used regression benchmark problems show that the proposed approach leads to compact networks that generate competitive results compared with the ELM algorithm.",2011,Neurocomputing
Marker-assisted prediction of non-additive genetic values,"It has become increasingly clear from systems biology arguments that interaction and non-linearity play an important role in genetic regulation of phenotypic variation for complex traits. Marker-assisted prediction of genetic values assuming additive gene action has been widely investigated because of its relevance in artificial selection. On the other hand, it has been less well-studied when non-additive effects hold. Here, we explored a nonparametric model, radial basis function (RBF) regression, for predicting quantitative traits under different gene action modes (additivity, dominance and epistasis). Using simulation, it was found that RBF had better ability (higher predictive correlations and lower predictive mean square errors) of predicting merit of individuals in future generations in the presence of non-additive effects than a linear additive model, the Bayesian Lasso. This was true for populations undergoing either directional or random selection over several generations. Under additive gene action, RBF was slightly worse than the Bayesian Lasso. While prediction of genetic values under additive gene action is well handled by a variety of parametric models, nonparametric RBF regression is a useful counterpart for dealing with situations where non-additive gene action is suspected, and it is robust irrespective of mode of gene action.",2011,Genetica
Incorporating grouping information in bayesian variable selection with applications in genomics,"In many applications it is of interest to determine a limited number of important explanatory factors (representing groups of potentially overlapping predictors) rather than original predictor variables. The often imposed require-ment that the clustered predictors should enter the model simultaneously may be limiting as not all the variables within a group need to be associated with the out-come. Within-group sparsity is often desirable as well. Here we propose a Bayesian variable selection method, which uses the grouping information as a means of in-troducing more equal competition to enter the model within the groups rather than as a source of strict regularization constraints. This is achieved within the context of Bayesian LASSO (least absolute shrinkage and selection operator) by allowing each regression coefficient to be penalized differentially and by considering an additional regression layer to relate individual penalty parameters to a group identification matrix. The proposed hierarchical model therefore enables inference simultaneously on two levels: (1) the regression layer for the continuous outcome in relation to the predictors and (2) the regression layer for the penalty param-eters in relation to the grouping information. Both situations with overlapping and non-overlapping groups are applicable. The method does not assume within-group homogeneity across the regression coefficients, which is implicit in many structured penalized likelihood approaches. The smoothness here is enforced at the penalty level rather than within the regression coefficients. To enhance the potential of the proposed method we develop two rapid computational procedures based on the expectation maximization (EM) algorithm, which offer substantial time savings in applications where the high-dimensionality renders Markov chain Monte Carlo (MCMC) approaches less practical. We demonstrate the usefulness of our method in predicting time to death in glioblastoma patients using pathways of genes.",2014,Bayesian Analysis
Comparing maternal genetic variation across two millennia reveals the demographic history of an ancient human population in southwest Turkey,"More than two decades of archaeological research at the site of Sagalassos, in southwest Turkey, resulted in the study of the former urban settlement in all its features. Originally settled in late Classical/early Hellenistic times, possibly from the later fifth century BCE onwards, the city of Sagalassos and its surrounding territory saw empires come and go. The Plague of Justinian in the sixth century CE, which is considered to have caused the death of up to a third of the population in Anatolia, and an earthquake in the seventh century CE, which is attested to have devastated many monuments in the city, may have severely affected the contemporary Sagalassos community. Human occupation continued, however, and Byzantine Sagalassos was eventually abandoned around 1200 CE. In order to investigate whether these historical events resulted in demographic changes across time, we compared the mitochondrial DNA variation of two population samples from Sagalassos (Roman and Middle Byzantine) and a modern sample from the nearby town of AÄŸlasun. Our analyses revealed no genetic discontinuity across two millennia in the region and Bayesian coalescence-based simulations indicated that a major population decline in the area coincided with the final abandonment of Sagalassos, rather than with the Plague of Justinian or the mentioned earthquake.",2016,Royal Society Open Science
"Redescription of the Brazilian Wrasse Thalassoma noronhanum (Boulenger, 1890) (Teleostei: Labridae)","Thalassoma noronhanum is a poorly known wrasse that inhabits tropical reefs of the western South Atlantic. This species is found from Parcel Manuel Luiz reefs to the coast of Sao Paulo, and at all Brazilian oceanic islands. It inhabits rocky and coralline algae reefs and was collected from the shore line to depths of 60m. Juveniles are known to clean other fish, and adult females form harems dominated by a few terminal males.",2001,
Classification of suspicious lesions on prostate multiparametric MRI using machine learning,"Abstract. We present a radiomics-based approach developed for the SPIE-AAPM-NCI PROSTATEx challenge. The task was to classify clinically significant prostate cancer in multiparametric (mp) MRI. Data consisted of a â€œtraining datasetâ€ (330 suspected lesions from 204 patients) and a â€œtest datasetâ€ (208 lesions/140 patients). All studies included T2-weighted (T2-W), proton density-weighted, dynamic contrast enhanced, and diffusion-weighted imaging. Analysis of the images was performed using the MIM imaging platform (MIM Software, Cleveland, Ohio). Prostate and peripheral zone contours were manually outlined on the T2-W images. A workflow for rigid fusion of the aforementioned images to T2-W was created in MIM. The suspicious lesion was outlined using the high b-value image. Intensity and texture features were extracted on four imaging modalities and characterized using nine histogram descriptors: 10%, 25%, 50%, 75%, 90%, mean, standard deviation, kurtosis, and skewness (216 features). Three classification methods were used: classification and regression trees (CART), random forests, and adaptive least absolute shrinkage and selection operator (LASSO). In the held out by the organizers test dataset, the areas under the curve (AUCs) were: 0.82 (random forests), 0.76 (CART), and 0.76 (adaptive LASSO). AUC of 0.82 was the fourth-highest score of 71 entries (32 teams) and the highest for feature-based methods.",2018,Journal of Medical Imaging
Evidence for Three Subpopulations of Globular Clusters in the Early-Type Poststarburst Shell Galaxy AM 0139-655,"We present deep Hubble Space Telescope ACS images of the poststarburst shell galaxy AM 0139ï¿½ 655. We find evidence for the presence of three distinct globular cluster (GC) subpopulations associatedwith this galaxy: a centrally concentrated young population (ï¿½ 0.4 Gyr), an intermediate-age population (ï¿½ 1G yr), and an old, metal-poor popu- lation similar to that seen around normal galaxies. The gI color distribution of the clusters is bimodal, with peaks at 0.85and 1.35. The redderpeakat gI Â¼ 1:35 isconsistentwiththe predicted color for anold,metal-poorpopulation. The clusters associated with the peak at gI Â¼ 0:85 are centrally concentrated and interpreted as a younger and more metal-rich population. We suggest that these clusters have an age of ï¿½ 0.4 Gyr and solar metallicity based on a comparisonwith populationsynthesis models. The luminosity functionof these ''blue'' clusters is well represented bya powerlaw, ï¿½ (L)dL / L ï¿½ 1:8 dL.Interestingly,thebrightestshellassociatedwiththegalaxyharborssomeoftheyoungest clustersobserved. This seems to indicatethatthesame merger eventwasresponsible fortheformationof both theshells andtheyoungclusters.Theredpartofthecolordistributioncontainsseveralverybrightclusters,whicharenotexpected for an old, metal-poor population. Furthermore, the luminosity function of the ''red'' GCs cannot be fit well by either a single Gaussian or a single power law. A composite (Gaussian + power law) fit to the luminosity function of the red clusters yields both a low rms and very plausible properties for an old population (with a Gaussian distribution), plus an intermediate-agepopulation(withapower-lawdistribution)ofGCs.Hence,wesuggestthattheredclustersinAM0139ï¿½ 655consistoftwodistinctGCsubpopulations,onebeinganold,metal-poorpopulationasseeninnormalgalaxiesandone havingformed during a recent dissipative galaxy merger (likely the same event that formed the ï¿½ 0.4 Gyr old clusters).",2007,The Astronomical Journal
Fused-MCP With Application to Signal Processing,"ABSTRACTFriedman etÂ al. proposed the fused lasso signal approximator (FLSA) to denoise piecewise constant signals by penalizing the l1 differences between adjacent signal points. In this article, we propose a new method, referred to as the fused-MCP, by combining the minimax concave penalty (MCP) with the fusion penalty. The fused-MCP performs better than the FLSA in maintaining the profile of the original signal and preserving the edge structure. We show that, with a high probability, the fused-MCP selects the right change-points and has the oracle property, unlike the FLSA. We further show that the fused-MCP achieves the same l2 error rate as the FLSA. We develop algorithms to solve fused-MCP problems, either by transforming them into MCP regression problems or by using an adjusted majorization-minimization algorithm. Simulation and experimental results show the effectiveness of our method. Supplementary material for this article is available online.",2018,Journal of Computational and Graphical Statistics
