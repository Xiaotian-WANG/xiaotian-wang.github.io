title,abstract,year,journal
A novel min-cost flow method for estimating transcript expression with RNA-Seq,"BackgroundThrough transcription and alternative splicing, a gene can be transcribed into different RNA sequences (isoforms), depending on the individual, on the tissue the cell is in, or in response to some stimuli. Recent RNA-Seq technology allows for new high-throughput ways for isoform identification and quantification based on short reads, and various methods have been put forward for this non-trivial problem.ResultsIn this paper we propose a novel radically different method based on minimum-cost network flows. This has a two-fold advantage: on the one hand, it translates the problem as an established one in the field of network flows, which can be solved in polynomial time, with different existing solvers; on the other hand, it is general enough to encompass many of the previous proposals under the least sum of squares model. Our method works as follows: in order to find the transcripts which best explain, under a given fitness model, a splicing graph resulting from an RNA-Seq experiment, we find a min-cost flow in an offset flow network, under an equivalent cost model. Under very weak assumptions on the fitness model, the optimal flow can be computed in polynomial time. Parsimoniously splitting the flow back into few path transcripts can be done with any of the heuristics and approximations available from the theory of network flows. In the present implementation, we choose the simple strategy of repeatedly removing the heaviest path.ConclusionsWe proposed a new very general method based on network flows for a multiassembly problem arising from isoform identification and quantification with RNA-Seq. Experimental results on prediction accuracy show that our method is very competitive with popular tools such as Cufflinks and IsoLasso. Our tool, called Traph (Transcrips in gRAPHs), is available at: http://www.cs.helsinki.fi/gsa/traph/.",2013,BMC Bioinformatics
"Response to Letter Regarding Article , â€œ High-Density Lipoproteins and Their Constituent , Sphingosine-1-Phosphate , Directly Protect the Heart Against Ischemia / Reperfusion Injury In Vivo via the S 1 P 3 Lysophospholipid Receptor","â€œHigh-Density Lipoproteins and Their Constituent, Sphingosine-1-Phosphate, Directly Protect the Heart Against Ischemia/Reperfusion Injury In Vivo via the S1P3 Lysophospholipid Receptorâ€ The question raised by Dr Xia is based on the hypothesis that plasma proteins â€œbufferâ€ the large amounts of sphingosine 1-phosphate (S1P) present in plasma to prevent it from erroneously activating S1P receptors.1 Although reconstituted high-density lipoprotein (HDL) that does not contain S1P has numerous biological effects when administered in vivo, it is unknown whether and how rapidly it may actually acquire S1P from the plasma once it enters the circulation. Subsequently, such â€œS1P-chargedâ€ HDL may be partially responsible for the effects attributed to the original reconstituted HDL. In fact, preparations of reconstituted HDL loaded with S1P, and not reconstituted HDL alone, potently induce endothelial tube formation; both are similarly effective in promoting cholesterol efflux.2 In our opinion, the main question is not whether HDL carries or scavenges S1P, but what the biological effects of HDLassociated S1P are and how they contribute to known HDL effects. This leads us to answering the raised questions as follows: (1) both S1P and HDL clearly have biological effects in vivo after a single administration, suggesting a long-enough biological half-life3,4; (2) HDL-associated S1P activates S1P3 directly, because approximately 50% of the vasodilatory and 100% of the cardioprotective effect of HDL, respectively, are absent in S1P3-deficient mice3,4; (3) S1P3 deficiency does not influence reperfusion injury per se4; and (4) the beneficial effect of both S1P and HDL against reperfusion injury is attributable to their antiinflammatory, vasoprotective, and myocardioprotective properties and is mediated by S1P3. The stimulatory effect of HDL on myocardial perfusion may also contribute to cardioprotection during ischemia/reperfusion injury, while the putatively detrimental decrease in myocardial perfusion by S1P may be overwhelmed by its numerous beneficial effects. Regarding the apparently divergent effects of S1P on arterial tone noted by Dr Xia, the particular arterial bed as well as its current tone are important: the same artery that contracts in response to S1P under basal conditions responds with vasodilation if precontracted by phenylephrine.3 Finally, the opposing effects of S1P on inflammation are attributable to the dual response of the endothelial cell: whereas proinflammatory effects have been observed at S1P concentrations 1000-fold higher than the Kd for its receptors and are not mediated by them, its antiinflammatory effects are elicited by physiological concentrations and are dependent on S1P receptors.6 Clearly, the cardiovascular effects of S1P in general and those of HDL-associated S1P in particular are a new and promising area of investigation, and they certainly bear many future surprises. Disclosures None.",2006,
Worst possible sub-directions in high-dimensional models,"We examine the rate of convergence of the Lasso estimator of lower dimensional components of the high-dimensional parameter. Under bounds on the ? 1 -norm on the worst possible sub-direction these rates are of order | J | log p / n where p is the total number of parameters, n is the number of observations and J ? { 1 , ? , p } represents a subset of the parameters. We also derive rates in sup-norm in terms of the rate of convergence in ? 1 -norm. The irrepresentable condition on a set J requires that the ? 1 -norm of the worst possible sub-direction is sufficiently smaller than one. In that case sharp oracle results can be obtained. Moreover, if the coefficients in J are small enough the Lasso will put these coefficients to zero. By de-sparsifying one obtains fast rates in supremum norm without conditions on the worst possible sub-direction. The results are extended to M-estimation with ? 1 -penalty for generalized linear models and exponential families. For the graphical Lasso this leads to an extension of known results to the case where the precision matrix is only approximately sparse. The bounds we provide are non-asymptotic but we also present asymptotic formulations for ease of interpretation.",2016,J. Multivar. Anal.
A prognostic signature for lower-grade gliomas based on expression of long noncoding RNAs,"Diffuse low-grade and intermediate-grade gliomas (together known as lower-grade gliomas, WHO grade II and III) develop in the supporting glial cells of brain and are the most common types of primary brain tumor. Despite a better prognosis for lower-grade gliomas, 70% of patients undergo high-grade transformation within 10 years, stressing the importance of better prognosis. Long non-coding RNAs (lncRNAs) are gaining attention as potential biomarkers for cancer diagnosis and prognosis. We have developed a computational model, UVA8, for prognosis of lower-grade gliomas by combining lncRNA expression, Cox regression and L1-LASSO penalization. The model was trained on a subset of patients in TCGA. Patients in TCGA, as well as a completely independent validation set (CGGA) could be dichotomized based on their risk score, a linear combination of the level of each prognostic lncRNA weighted by its multivariable cox regression coefficient. UVA8 is an independent predictor of survival and outperforms standard epidemiological approaches and previous published lncRNA-based predictors as a survival model. Guilt-by-association studies of the lncRNAs in UVA8, all of which predict good outcome, suggest they have a role in suppressing interferon stimulated response and epithelial to mesenchymal transition. The expression levels of 8 lncRNAs can be combined to produce a prognostic tool applicable to diverse populations of glioma patients. The 8 lncRNA (UVA8) based score can identify grade II and grade III glioma patients with poor outcome and thus identify patients who should receive more aggressive therapy at the outset.",2018,bioRxiv
To construct a ceRNA regulatory network as prognostic biomarkers for bladder cancer.,"Emerging evidence demonstrates that competing endogenous RNA (ceRNA) hypothesis has played a role in molecular biological mechanisms of cancer occurrence and development. But the effect of ceRNA network in bladder cancer (BC), especially lncRNA-miRNA-mRNA regulatory network of BC, was not completely expounded. By means of The Cancer Genome Atlas (TCGA) database, we compared the expression of RNA sequencing (RNA-Seq) data between 19 normal bladder tissue and 414 primary bladder tumours. Then, weighted gene co-expression network analysis (WGCNA) was conducted to analyse the correlation between two sets of genes with traits. Interactions between miRNAs, lncRNAs and target mRNAs were predicted by MiRcode, miRDB, starBase, miRTarBase and TargetScan. Next, by univariate Cox regression and LASSO regression analysis, the 86 mRNAs obtained by prediction were used to construct a prognostic model which contained 4 mRNAs (ACTC1Â +Â FAM129AÂ +Â OSBPL10Â +Â EPHA2). Then, by the 4 mRNAs in the prognostic model, a ceRNA regulatory network with 48 lncRNAs, 14 miRNAs and 4 mRNAs was constructed. To sum up, the ceRNA network can further explore gene regulation and predict the prognosis of BC patients.",2020,Journal of cellular and molecular medicine
A new nonparametric stability test with an application to major Chinese macroeconomic time series,"In this paper, we propose a new test for testing the stability in macroeconomic time series, based on the LASSO variable selection approach and nonparametric estimation of a time-varying model. The wild bootstrap is employed to obtain its data-dependent critical values. We apply the new method to test the stability of bivariate relations among 92 major Chinese macroeconomic time series. We find that more than 70% bivariate relations are significantly unstable.",2013,Applied Mathematics-A Journal of Chinese Universities
Case Complexity as a Guide for Psychological Treatment Selection,"Objective: Some cases are thought to be more complex and difficult to treat, although there is little consensus on how to define complexity in psychological care. This study proposes an actuarial, data-driven method of identifying complex cases based on their individual characteristics. Method: Clinical records for 1,512 patients accessing low- and high-intensity psychological treatments were partitioned in 2 random subsamples. Prognostic indices predicting post-treatment reliable and clinically significant improvement (RCSI) in depression (Patient Health Questionnaire-9; Kroenke, Spitzer, & Williams, 2001) and anxiety (Generalized Anxiety Disorder-7; Spitzer, Kroenke, Williams, & LÃ¶we, 2006) symptoms were estimated in 1 subsample using penalized (Lasso) regressions with optimal scaling. A PI-based algorithm was used to classify patients as standard (St) or complex (Cx) cases in the second (cross-validation) subsample. RCSI rates were compared between Cx cases that accessed treatments of different intensities using logistic regression. Results: St cases had significantly higher RCSI rates compared to Cx cases (OR = 1.81 to 2.81). Cx cases tended to attain better depression outcomes if they were initially assigned to high-intensity (vs. low intensity) interventions (OR = 2.23); a similar pattern was observed for anxiety but the odds ratio (1.74) was not statistically significant. Conclusions: Complex cases could be detected early and matched to high-intensity interventions to improve outcomes.",2017,Journal of Consulting and Clinical Psychology
"Optimal Scaling, A Wonderful Method for Analysing Clinical Trials with Imperfect Data","Context: In clinical trials the research question is often measured with multiple variables, and multiple regression is commonly used for analysis. The problem with multiple regression is that consecutive levels of the variables are assumed to be equal, while in practice this is virtually never true. Optimal scaling is a method designed to maximize the relationship between a predictor and an outcome variable by adjusting their scales. Aims: To assess the performance of optimal scaling in clinical research. Settings and design: A simulated example of a drug efficacy trial was used. The SPSS module Optimal Scaling with ridge regression, lasso and elastic net regression was used. Results: The ridge optimal scaling model produced eight p-values < 0.01, while traditional regression and unregularized optimal scaling produced only 3 and 2 p-values < 0.01. Lasso optimal scaling eliminated 4 of 12 predictors from the analysis, while, of the remainder, only two were significant at p < 0.01. Similarly elastic net optimal scaling did not provide additional benefit. Conclusions: 1/ Optimal scaling shows similarly sized effects compared to traditional regression. In order to benefit from optimal scaling a regularization procedure for the purpose of correcting overdispersion is needed. 2/ Ridge optimal scaling performed much better than did traditional regression giving rise to many more statistically significant predictors. 3/ Lasso optimal scaling shrinks some b-values to zero, and is particularly suitable if you are looking for a limited number of strong predictors. 4/ Elastic net optimal scaling works better than lasso if the number of predictors is larger than the number of observations.",2013,
Lp (pâ€‰â‰¤â€‰1) Norm Partial Directed Coherence for Directed Network Analysis of Scalp EEGs,"Partial directed coherence (PDC), which is capable of estimating directed brain networks in the frequency domain, has been widely used in various physiological recordings such as electroencephalograms (EEGs) and functional magnetic resonance imaging. However, clinical data from EEGs are inevitably contaminated with unexpected outlier artifacts. This will result in biased networks, which are different from the original physiological mechanism because of the L2 norm structure utilized in PDC to estimate the directed links. In this work, we define a new PDC model in the Lp norm (pâ€‰â‰¤â€‰1) space to restrict outlier influence and use a feasible iteration procedure to solve this model for directed network construction. The quantitative evaluation using a predefined simulation network demonstrates that Lp-PDC is more consistent with the predefined networks than LS-PDC and Lasso-PDC under various simulated outlier conditions. Applying the Lp-PDC model to resting-state EEGs with ocular artifacts also show that the proposed PDC can effectively restrict the ocular artifacts to recover the networks, which is also more consistent with the physiological basis. Both simulation and real-life EEG applications demonstrate the efficiency of the proposed PDC in suppressing the influence of outliers in EEG signals, and the proposed Lp-PDC may be helpful to capture reliable causal relationships for related studies contaminated with outlier artifacts.",2018,Brain Topography
Thermal performance of a novel ultrasonic evaporator based on machine learning algorithms,"Abstract Ultrasound is a promising method to enhance heat transfer in industrial evaporators. However, there are very limited studies on this topic. This paper explores thermal performance of a novel ultrasonic evaporator based on machine learning methods. The results indicate that the overall heat transfer coefficients can be increased by around 15â€“20% after adding ultrasound due to acoustic cavitation and acoustic streaming. Two machine learning-based global sensitivity analysis (treed Gaussian Process and polynomial chaos expansion) methods are used to identify important variables influencing overall heat transfer coefficients in the ultrasonic evaporator. It is found that the temperature difference between evaporation and heating steam is the dominant factor affecting thermal performance in this case study. Ultrasound has complicated interactions and non-linear effects in the ultrasonic evaporator. Seven machine learning algorithms are created to compare predictive thermal performance of this evaporator, including linear model, Lasso (least absolute shrinkage and selection operator), MARS (multivariate adaptive regression splines), NNet (averaging neural network), CB (Cubist model), GP (Gaussian process), and SVM (support vector machine). The SVM and NNet models among these seven models can provide accurate prediction of overall heat transfer coefficients in the ultrasonic evaporator.",2019,Applied Thermal Engineering
"Cleaning by the wrasse Thalassoma noronhanum, with two records of predation by its grouper client Cephalopholis fulva","The Noronha wrasse Thalassoma noronhanum was recorded cleaning 19 client fish species at Fernando de Noronha Archipelago, o. northâ€“eastern Brazil. The preferred clients were nonâ€“dangerous, mostly planktivorous species, whereas the potentially dangerous, predatory species were rarely cleaned. T. noronhanum acts as a cleaner in two distinct ecological situations, at and outside the cleaning stations, and attends different client species in each of them. Potentially dangerous clients were mostly attended outside the cleaning stations. Many attacks and two instances of predation on the cleaner wrasse by the grouper client Cephalopholis fulva were recorded. The attacks occurred on individual wrasses foraging near the bottom outside the cleaning stations.",2000,Journal of Fish Biology
Becoming a camorrista : criminal culture and life choices in Naples,"In 1992, Pasquale Galasso, a Camorra superboss, revealed many intricate secrets about the Neapolitan Camorra. This led to revelations from other pentiti (criminals turned state witnesses), allowing an insight for the first time into the Neapolitan Camorra from the insider's point of view. Understanding why individuals join a criminal organization, the Camorra in particular, is one of the questions addressed in this article. Using primary sources and an 'interaction model' based on the interplay of agency and structure, it studies the impact of Neapolitan criminal culture on an individual's life choices in the 1950s, and compares these with the 1980s and 1990s. It concludes that while in the 1950s criminal values were emerging as an ethos and had a somewhat limited impact on individuals, by the 1980s this ethos had become a clear 'subculture', an 'ideology' which had a pervasive influence on the life choices of many young Neapolitans. Nel 1992, Pasquale Galasso, super boss della Camorra, rivelÃ’ parecchi segreti sulle cosche napoletanc. La sua disponibilitÃ€ a collaborare spinse altri pentiti a seguire il suo csempio. CiÃ’ consentÃ¬ per la prima volta di conoscere in maniera piÃ¹ approfondita la Camorra tramite le rivelazioni di alcuni dei suoi membri. Pertanto, i motivi per cui si sceglie di entrare nella Camorra Ã¨ una fra le questioni analizzate nel presente articolo. Attraverso l'uso di fonti primarie e di un modello interattivo caratterizzato da una combinazione tra capacitÃ€ decisionale e struttura organizzativa, l'articolo sviluppa una analisi comparativa sull'impatto di una cultura criminale napoletana nei confronti delle scelte di singoli individui negli anni cinquanta, ottanta e novanta. Le conclusioni di questo studio sottolineano che, sebbene negli anni cinquanta una cultura criminale stava acquisendo un valore etico, essa aveva una influenza minima sulle scelte comportamentali dei singoli soggetti; mentre dagli anni ottanta era ormai divenuta una subcultura, una ideologia che aveva prodotto un impatto notevole sulle scelte di vita di molti giovani napoletani.",2001,Journal of Modern Italian Studies
The Analysis of Impact Factors of Foreign Investment Based on Relaxed Lasso,"Relaxed Lasso method is used for variable selection to 15 main economic factors affecting foreign investment. While Relaxed Lasso method, method of least squares and regression are compared, the result further reveals the main problem facing foreign investment at the present stage.",2017,Journal of Applied Mathematics and Physics
ProblÃ©mes du CrÃ©tacÃ© infÃ©rieur dans les PyrÃ©nÃ©es et le Nord de l'Espagne,"ZusammenfassungEs werden die Ergebnisse von Stratigraphie und PalÃ¤ogeographie der Unterkreide zusammengefaÃŸt. Das Ende des Juras (Post-Callovien) ist durch eine groÃŸe Emersion gekennzeichnet. Die Unterkreide besteht aus einem Wechsel von lokalen terrestrischen (Sande und Tone) und ausgedehnten marinen Ablagerungen (Rudistenkalke, Orbitolina-Serien). FÃ¼r die Ã„nderung der SedimentationsverhÃ¤ltnisse wird ein Klimawechsel verantwortlich gemacht.RÃ©sumÃ©A travers les publications rÃ©centes, on recherche les faits importants ou les orientations nouvelles pour la stratigraphie du CrÃ©tacÃ© infÃ©rieur.Le Jurassique terminal (post-callovien) a Ã©tÃ© marquÃ© par une extension considÃ©rable des surfaces Ã©mergÃ©es. C'est le dÃ©part d'une palÃ©ogÃ©ographie d'un style nouveau. On voit dÃ©sormais un conflit quasi permanent entre une sÃ©dimentation terrigÃ¨ne, argilo-sableuse, et une sÃ©dimentation thalassogÃ¨ne essentiellement calcaire. La premiÃ¨re est fortement dÃ©pendante des conditions locales. La seconde, identique Ã  elle-mÃªme pendant de longues durÃ©es dans tout le domaine mÃ©diterranÃ©en, exprime de vÃ©ritables constantes mÃ©sogÃ©ennes: calcaires Ã  Rudistes, sÃ©ries Ã  Orbitolines...Dans le dÃ©roulement historique, une sÃ©dimentation assez calme mais variÃ©e, lacustre, saumÃ¢tre ou mÃªme marine, a prÃ©cÃ©dÃ© en divers points la dÃ©charge terrigÃ¨ne massive du classique Â«WealdienÂ» grÃ©seux. Ailleurs la dÃ©couverte de NÃ©ocomien marin modifie les conceptions sur la transgression aptienne. Enfin l'Ã©pisode dÃ©tritique, albien, des couches d'Utrillas, apparaÃ®t comme un phÃ©nomÃ¨ne de vaste extension; une variation climatique pourrait en Ãªtre la cause. Pour chacune de ces Ã©tapes cependant, il reste encore beaucoup Ã  apprendre; ne serait-ce que pour obtenir des datations et des corrÃ©lations plus sÃ»res.AbstractThrough recent publications, the major facts or new trends in the stratigraphy of lower Cretaceous are examined.A considerable extension of emerged areas marks the Upper Jurassic (Post-Callovian). A new paleogeography is thus starting. Henceforth terrigenous deposits (clay and sand) are almost continuously conflicting with a mostly calcareous marine sedimentation. The former are highly dependent on local conditions; the latter, unchanging over long periods in all the Mediterranean areas, is the result of really uniform geographical factors: e.g. Rudist limestones, Orbitolina series.In the course of time, a rather quiet but varied sedimentation (lacustrian, brackish or even marine) precedes, in different places, the dumping of huge quantities of â€žWealdenâ€œ sandstones. Elsewhere the discovery of marine Neocomian changes our views on the aptien transgression. Lastly the detrital albian occurrence of Utrillas beds seems to be widely spread. A climatic change might be responsible for it.ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸ÐµÐ˜Ð·ÑƒÑ‡ÐµÐ½Ð° ÑÑ‚Ñ€Ð°Ñ‚Ð¸Ð³Ñ€Ð°Ñ„Ð¸ Ñ Ð½Ð¸Ð¶Ð½ÐµÐ³Ð¾ Ð¼ÐµÐ»Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ðµ Ñ€Ð¸Ð¾Ð´Ð°. ÐžÐ¿Ð¸ÑÐ°Ð½Ñ‹ Ð¿Ð¾Ñ€Ð¾Ð´Ñ‹ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚Ð°, ÐºÐ°Ðº ÐºÐ¾Ð½Ñ‚Ð¸Ð½ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ð³ Ð¾, Ñ‚Ð°Ðº Ð¸ Ð¼Ð¾Ñ€ÑÐºÐ¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð¶Ð´Ðµ Ð½Ð¸Ñ Ð² Ð´Ð°Ð½Ð½Ð¾Ð¼ Ñ€Ð°Ð¹Ð¾Ð½Ðµ.",1964,Geologische Rundschau
Estimating Global Bank Network Connectedness,"We use LASSO methods to shrink, select and estimate the high-dimensional network linking the publicly-traded subset of the world's top 150 banks, 2003-2014. We characterize static network connectedness using full-sample estimation and dynamic network connectedness using rolling-window estimation. Statically, we find that global bank equity connectedness has a strong geographic component, whereas country sovereign bond connectedness does not. Dynamically, we find that equity connectedness increases during crises, with clear peaks during the Great Financial Crisis and each wave of the subsequent European Debt Crisis, and with movements coming mostly from changes in cross-country as opposed to within-country bank linkages.",2015,National Bureau of Economic Research
Characterization of urban and peri-urban agroecosystems in three West African cities,"Systems of urban and peri-urban agriculture (UPA) take many forms in terms of integration of different activities, production intensities and production orientations. The present study is aimed at a refined characterization of the diversity in terms of production orientation, resource endowments and production strategies of the different types of farm households involved in urban and peri-urban agriculture in three West African cities. A total of 318 UPA households were surveyed using a standardized semi-structured questionnaire in the West African cities Kano (Nigeria), Bobo Dioulasso (Burkina Faso) and Sikasso (Mali). Through categorical principal component analysis and two-step cluster analysis, six distinct household clusters were identified based on resource endowments and the degree of integration of vegetable, field crop and animal production. Three clusters appeared in all three cities; the remaining three were specific for one of the cities each and comprised (i) commercial gardening plus field c...",2012,International Journal of Agricultural Sustainability
Hom-Lie-Yamaguti Structures on Hom-Leibniz Algebras,"AbstractEverymultiplicativeleftHom-LeibnizalgebrahasanaturalHom-Lie-Yamagutistruc-ture.AMSSubject Classiï¬cation (2010): 17A30, 17A32, 17D99Keywords: Leibnizalgebra,Lie-Yamagutialgebra(i.e. generalizedLietriplesystem,Lietriplealgebra),Hom-Leibnizalgebra,Hom-Lie-Yamagutialgebra. 1. Introduction and statement of resultA (left) Leibniz algebra is an algebra (L,Â·) satisfying the identityx Â· (y Â· z) = (x Â· y)Â·z +y Â· (x Â· z).Leibniz algebras were introduced by J.-L. Loday [15] (and so they are sometimes calledLoday algebras) as a noncommutative analogue of Lie algebras, in the study of some topicsin homological algebra and noncommutative geometry (see also [5], [20]). While earlier pa-pers on Leibniz algebras are concerned with some homological problems (see, e.g., [15], [20]),some structure theory of Leibniz algebras are proposed in, e.g., [2] and [3] (see also referencestherein). Classiï¬cation of low-dimensional Leibniz algebras could be found in, e.g., [2], [6],[15], [21].One of the problems in the general theory of a given class of (binary or binary-ternary)nonassociativealgebrasis the study of relationshipsbetween that classof algebrasand the oneof Lie algebras. In the same rule, the search of relationships between a class of nonassociative",2012,
Bayesian Models to Assess Risk of Corruption of Federal Management Units,"This paper presents a data mining project that generated Bayesian models to assess risk of corruption of federal management units. With thousands of extracted features related to corruptibility, the data were processed using techniques like correlation analysis and variance per class. We also compared two different discretization methods: Minimum Description Length Principle (MDLP) and Class-Attribute Contingency Coefficient (CACC). The feature selection process used Adaptive Lasso. To choose our final model we evaluated three different algorithms: NaÄ±Ìˆve Bayes, Tree Augmented NaÄ±Ìˆve Bayes, and Attribute Weighted NaÄ±Ìˆve Bayes. Finally, we analyzed the rules generated by the model in order to support knowledge discovery.",2016,
Economic Sustainability in Franchising: A Model to Predict Franchisor Success or Failure,"As a business model, franchising makes a major contribution to gross domestic product (GDP). A model that predicts franchisor success or failure is therefore necessary to ensure economic sustainability. In this study, such a model was developed by applying Lasso regression to a sample of franchises operating between 2002 and 2013. For franchises with the highest likelihood of survival, the franchise fees and the ratio of company-owned to franchised outlets were suited to the age of the franchise. Surviving franchises were those that opened franchised outlets at a sustainable pace, increased the franchise fee as intangible assets increased, and effectively managed profitability and efficiency.",2017,Sustainability
Sedimentary formations and main development stages of the western Transbaikal and southeastern Baikal regions in the late Cretaceous and Cenozoic,"Upper Cretaceous and Cenozoic formations of the western Transbaikal and southeastern Baikal regions are considered. Molasses and molassoids (molasse-type sediments) were included into these formations in previous works. In our opinion, the following formations are developed in these regions: plain fan formation divided into the terrigenous (Upper Cretaceous) and coaliferous (Upper Oligocene-Lower Pliocene) subformations; plain fine-clastic formation (Paleogene, except the Upper Oligocene); and orogenic molasse formation (Upper Pliocene-Holocene) divided into the lower red-colored and upper gray-colored subformations. Main textural features of these formations are considered. Paleogeographic and paleotectonic settings of their accumulation are reconstructed. It is shown that coarse-clastic sediments of fan formations accumulated in grabens among ancient denudation plains due to the destruction of rocks in near-wall benches. These plains probably hosted in some areas remnants of the mountainous relief. Origination and development of the Baikal rift zone was the main geological event in the Baikal region during the Late Cretaceous and Cenozoic. Based on study of the southeastern Baikal region with the thickest and most representative Cenozoic sections, the prerifting and rifting stages of this zone and correlative events in the adjacent (relatively stable) areas of the western Transbaikal region are characterized.",2007,Lithology and Mineral Resources
Ultimate load analysis of plate foundations,"SommarioSulla scorta di studi precedentemente svolti[6], [7], riguardanti lo stato limite delle piastre indefinite appoggiate su mezzo elasto-plastico e soggette a carichi diffusi, si indaga sul comportamento di piastre circolari, impiegate come elementi di fondazione isolate.Si perviene ad un procedimento di calcolo a rottura di facile impiego che consente, in relazione al diverso comportamento dei due elementi costitutivi del sistema, di determinare:--il carico limite per collasso contemporaneo della piastra e del mezzo di sostegno.--il carico limite per collasso del solo mezzo di sostegno. Alla fine si riportano alcuni esempi concreti di carattere applicativo.SummaryThe behaviour of circular plates used as isolated foundations is investigated on the basis of earlier studies[6], [7] of the limit state of indefinite plates resting on elastoplastic continua and subjected to distributed loads. The upshot is an easy-to-use procedure of ultimate load analysis that permits the determination of:--the limit load for simultaneous collapse of plate and continuum--and the limit load for collapse of the continuum only according to the different behaviour of the two elements constituting the system.
Some practical applications are exemplified.",1973,Meccanica
"Tertiary volcanism in the veneto: Magmatology, petrogenesis and geodynamic implications","ZusammenfassungDie magmatische AktivitÃ¤t im TertiÃ¤r Venetiens hÃ¤lt vom PaleozÃ¤n bis zum oberen OligozÃ¤n an. Charakteristisch sind basische bis ultrabasische Gesteine, lediglich in den Colli Euganei Ã¼berwiegen saure Vulkanite (Trachyte und Rhyolithe, untergeordnet Latite). Alkalischer Chemismus Ã¼berwiegt, nur in den letzten Phasen treten tholeiitische ErgÃ¼sse auf.Unter BerÃ¼cksichtigung der vulkanischen Abfolgen und der tektonischen Strukturen des Gebietees wurde untersucht, ob eine Verbindung der vulkanischen AktivitÃ¤t zu alpidischen SubduktionsvorgÃ¤ngen mÃ¶glich ist.Die enge Verwandtschaft der tertiÃ¤ren Vulkanite Venetiens zu solchen typisch anorogener Bereiche sowie strukturgeologische Ãœberlegungen zeigen, daÃŸ die alpidische Orogenese hier eine thermische Anomalie zur Folge hatte und so, in Verbindung mit einer Dehnungstektonik, SchmelzvorgÃ¤nge im Oberen Mantel auslÃ¶ste.AbstractThe magmatic activity of the Venetian Tertiary Volcanic Province took place between Paleocene and Upper Oligocene. It is characterized mainly by basic and ultrabasic products; only in the Euganean Hills can be found a magmatism predominantly of acidic-type (trachytes and rhyolites) and scarce latites be found.The whole of Venetian volcanism shows a mildly alkaline character, tholeiitic products have flowed only in the latest phases of activity.The possible link between Venetian volcanism and alpine subductive processes have been examined, taking into account the serial features and the structural setting of the region.The close affinity of the Venetian volcanics with those of typical anorogenic series, together with geo-structural considerations, suggest that, very probably, the â€œalpine orogenâ€ has suplied anomalous geothermal gradients which, in a severe extensive tectonic picture, have caused melting processes in the upper mantle.RÃ©sumÃ©Le volcanisme tertiaire vÃ©netien se dÃ©veloppe depuis le PalÃ©ocÃ¨ne jusqu'Ã  l'OligocÃ¨ne supÃ©rieur. Il est caracterisÃ© par des produits basiques et ultrabasiques; seulement dans les Colli Euganei prÃ©dominent des magmatites acides (trachytes et rhyolites) et de rares latites.L'entiÃ¨re province prÃ©sente un caractÃ¨re modÃ©rÃ©mment alcalin, avec seulement dans les derniÃ¨re phases, des termes tholÃ©iitiques.On analyse la possibilitÃ© d'une liaison entre l'activitÃ© volcanique et un processus de Â«subductionÂ» alpin, par rapport au caractÃ¨re de la sÃ©rie magmatique et Ã  la structure tectonique de la rÃ©gion.La province volcanique tertiaire de la VenÃ©tie montre une Ã©troite affinitÃ© avec les sÃ©ries typiquement anorogÃ©niques. De mÃªme sur la base de considÃ©rations gÃ©ologiques et tectoniques on peut penser que le magmatisme tertiaire est liÃ© Ã  la gÃ©odynamique alpine surtout dans un cadre de gradients gÃ©othermiques anormaux. L'anomalie gÃ©othermique aurait produit, dans des conditions de distension tectonique, un processus de fusion dans le manteau supÃ©rieur.RiassuntoL'attivitÃ  magmatica della Provincia Terziaria Veneta si Ã¨ esplicata durante un lasso die tempo che va dal Paleocene all'Oligocene superiore. Essa Ã¨ caratterizzata da prodotti prevalentemente basici ed ultrabasici; solo nei Colli Euganei sono riscontrabili magmatiti prevalentemente acide (trachiti e rioliti, e subordinate latiti).L'intera Provincia Veneta presenta un carattere moderatamente alcalino, solo nelle ultime fasi di attivitÃ  compaiono limitati termini tholeiitici.La possibilitÃ  di legare l'attivitÃ  vulcanica ad un processo di subduzione alpino viene analizzata in rapporto alle caratteristiche seriali ed all'assetto strutturale della zona.La stretta affinitÃ  dei prodotti della Provincia Vulcanica Terziaria Veneta con quelli di tipiche serie anorogeniche e considerazioni geologico-strutturali suggeriscono che la funzione dell'orogeno alpino deve essere stata quella di fornire gradienti geotermici anomali, che, in un quadro di intensa tettonica distensiva, hanno consentito processi di fusione del mantello superiore.ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸ÐµÐœÐ°Ð³Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð°ÐºÑ‚Ð¸Ð² Ð½Ð¾ÑÑ‚ÑŒ Ð² Ñ‚Ñ€ÐµÑ‚Ð¸Ñ‡Ð½Ð¾Ð¼ Ð¿ÐµÑ€ Ð¸Ð¾Ð´Ðµ Ð²ÐµÐ½ÐµÑ†Ð¸Ð¹ÑÐºÐ¾Ð³Ð¾ Ñ€Ð°Ð¹Ð¾Ð½Ð° Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°Ð»Ð°ÑÑŒ Ð¾Ñ‚ Ð¿Ð°Ð»ÐµÐ¾Ð·Ð¾Ñ Ð´Ð¾ Ð²ÐµÑ€Ñ…Ð½Ðµ Ð³Ð¾ Ð¾Ð»Ð¸Ð³Ð¾Ñ†ÐµÐ½Ð°. Ð¥Ð°Ñ€Ð°ÐºÑ‚Ðµ Ñ€Ð½Ñ‹Ð¼ ÑÐ²Ð»ÑÑŽÑ‚ÑÑ Ð·Ð´ÐµÑÑŒ Ð±Ð°Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ Ð°Ð»ÑŒÑ‚Ñ€Ð°Ð± Ð°Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ð¾Ñ€Ð¾Ð´Ñ‹ Ð¸ Ð¿Ñ€ ÐµÐ¾Ð±Ð»Ð°Ð´Ð°Ð½Ð¸Ðµ ÐºÐ¸ÑÐ»Ñ‹Ñ… Ð²ÑƒÐ»ÐºÐ°Ð½Ð¸Ñ‚Ð¾Ð² (Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ñ‚Ñ€Ð°Ñ…Ð¸Ñ‚Ñ‹ Ð¸ Ð¿ Ñ€Ð¸Ð¾Ð»Ð¸Ñ‚Ñ‹, Ð² ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ Ð²Ñ‚Ð¾Ñ€Ð¾ÑÑ‚ÐµÐ¿ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð¼Ð¸Ð½ ÐµÑ€Ð°Ð»Ð° Ð»Ð°Ñ‚Ð¸Ñ‚Ñ‹). ÐŸÑ€ÐµÐ¾Ð±Ð»Ð°Ð´Ð°ÐµÑ‚ Ñ‰ÐµÐ»Ð¾Ñ‡Ð½Ð¾ Ð¹ Ñ…Ð¸Ð¼Ð¸Ð·Ð¼ Ð¸ Ñ‚Ð¾Ð»ÐµÐ¸Ð¸Ñ‚Ð¸Ñ‡Ðµ ÑÐºÐ¸Ðµ Ð¸Ð·Ð»Ð¸ÑÐ½Ð¸Ñ Ð¿Ð¾ÑÐ²Ð»ÑÑŽÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð² Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ¹ Ñ„Ð° Ð·Ðµ.ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ð»Ð¸ â€” Ð¿Ñ€Ð¸ ÑƒÑ‡ÐµÑ‚Ðµ Ð²ÑƒÐ»ÐºÐ°Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑÐ²Ð¸Ñ‚ Ð¸ Ñ‚ÐµÐºÑ‚Ð¾Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑÑ‚Ñ€ÑƒÐº Ñ‚ÑƒÑ€ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ â€” Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð°-Ð»Ð¸ ÑÐ²ÑÐ·ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ Ð²ÑƒÐ»ÐºÐ°Ð½Ð¸Ñ‡ ÐµÑÐºÐ¾Ð¹ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¸ Ð¿Ñ€Ð¾Ñ†ÐµÑ ÑÐ°Ð¼Ð¸ Ð°Ð»ÑŒÐ¿Ð¸Ð¹ÑÐºÐ¾Ð³Ð¾ Ð·Ð°ÑÐ°ÑÑ‹Ð² Ð°Ð½Ð¸Ñ.Ð¢ÐµÑÐ½Ð¾Ðµ Ñ€Ð¾Ð´ÑÑ‚Ð²Ð¾ Ñ‚Ñ€ÐµÑ‚Ð¸ Ñ‡Ð½Ñ‹Ñ… Ð²ÑƒÐ»ÐºÐ°Ð½Ð¸Ñ‚Ð¾Ð² Ð¾Ð±Ð»Ð° ÑÑ‚Ð¸ Ñ Ñ‚Ð°ÐºÐ¾Ð²Ñ‹Ð¼Ð¸ Ñ‚Ð¸Ð¿Ð¸Ñ‡Ð½Ñ‹Ñ… Ð½Ðµ Ð¾Ñ€Ð¾Ð³ÐµÐ½Ð½Ñ‹Ñ… Ñ€Ð°Ð¹Ð¾Ð½Ð¾Ð², ÐºÐ°Ðº Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚Ñƒ Ñ€Ð½Ð¾-Ð³ÐµÐ¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð°Ð½ Ð°Ð»Ð¸Ð·Ñ‹ Ð¿Ð¾ÐºÐ°Ð·Ð°Ð»Ð¸, Ñ‡Ñ‚Ð¾ Ð°Ð»ÑŒÐ¿Ð¸Ð¹ÑÐºÐ¸Ð¹ Ð¾Ñ€Ð¾Ð³ÐµÐ½ÐµÐ· Ð²Ñ‹Ð·Ð²Ð°Ð» Ð·Ð´ÐµÑÑŒ Ñ‚ÐµÐ¿Ð»Ð¾Ð²Ñƒ ÑŽ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸ÑŽ Ð¸, Ñ‚Ð°ÐºÐ¸Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼, â€” Ð½Ð°Ñ€ÑÐ´Ñƒ Ñ Ñ‚ÐµÐºÑ‚Ð¾Ð½Ð¸ÐºÐ¾Ð¹ Ñ€Ð°ÑÑ‚ÑÐ¶ÐµÐ½Ð¸Ñ â€” Ñ‚Ð°ÐºÐ¶Ðµ Ð¸ Ð¿ Ñ€Ð¾Ñ†ÐµÑÑÑ‹ Ñ€Ð°ÑÐ¿Ð»Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð²ÐµÑ€Ñ…Ð½Ðµ Ð¹ Ð¼Ð°Ð½Ñ‚Ð¸Ð¸.",1976,Geologische Rundschau
Bridge regression: Adaptivity and group selection,"Abstract In high-dimensional regression problems regularization methods have been a popular choice to address variable selection and multicollinearity. In this paper we study bridge regression that adaptively selects the penalty order from data and produces flexible solutions in various settings. We implement bridge regression based on the local linear and quadratic approximations to circumvent the nonconvex optimization problem. Our numerical study shows that the proposed bridge estimators are a robust choice in various circumstances compared to other penalized regression methods such as the ridge, lasso, and elastic net. In addition, we propose group bridge estimators that select grouped variables and study their asymptotic properties when the number of covariates increases along with the sample size. These estimators are also applied to varying-coefficient models. Numerical examples show superior performances of the proposed group bridge estimators in comparisons with other existing methods.",2011,Fuel and Energy Abstracts
"Final Technical Report of project: ""Contactless Real-Time Monitoring of Paper Mechanical Behavior During Papermaking""","The early precursors of laser ultrasonics on paper were Prof. Y. Berthelot from the Georgia Institute of Technology/Mechanical Engineering department, and Prof. P. Brodeur from the Institute of Paper Science and Technology, both located in Atlanta, Georgia. The first Ph.D. thesis that shed quite some light on the topic, but also left some questions unanswered, was completed by Mont A. Johnson in 1996. Mont Johnson was Prof. Berthelot's student at Georgia Tech. In 1997 P. Brodeur proposed a project involving himself, Y. Berthelot, Dr. Ken Telschow and Mr. Vance Deason from INL, Honeywell-Measurex and Dr. Rick Russo from LBNL. The first time the proposal was not accepted and P. Brodeur decided to re-propose it without the involvement from LBNL. Rick Russo proposed a separate project on the same topic on his side. Both proposals were finally accepted and work started in the fall of 1997 on the two projects. Early on, the biggest challenge was to find an optical detection method which could detect laser-induced displacements of the web surface that are of the order of .1 micron in the ultrasonic range. This was to be done while the web was having an out-of-plane amplitude of motion in the mm range due to web flutter; while moving at 10 m/s to 30 m/s in the plane of the web, on the paper machine. Both teams grappled with the same problems and tried similar methods in some cases, but came up with two similar but different solutions one year later. The IPST, GT, INL team found that an interferometer made by Lasson Technologies Inc. using the photo-induced electro-motive force in Gallium Arsenide was able to detect ultrasonic waves up to 12-15 m/s. It also developed in house an interferometer using the Two-Wave Mixing effect in photorefractive crystals that showed good promises for on-line applications, and experimented with a scanning mirror to reduce motion-induced texture noise from the web and improve signal to noise ratio. On its side, LBNL had the idea to combine a commercial Mach-Zehnder interferometer to a spinning mirror synchronized to the web speed, in order to make almost stationary measurements. The method was demonstrated at up to 10 m/s. Both teams developed their own version of a web simulator that was driving a web of paper at 10 m/s or higher. The Department of Energy and members of the Agenda 2020 started to make a push for merging the two projects. This made sense because their topics were really identical but this was not well received by Prof. Brodeur. Finally IPST decided to reassign the direction of the IPST-INL-GT project in the spring of 1999 to Prof. Chuck Habeger so that the two teams could work together. Also at this time, Honeywell-Measurex dropped as a member of the team. It was replaced by ABB Industrial Systems whose engineers had extensive previous experience of working with ultrasonic sensors on paperboard. INL also finished its work on the project as its competencies were partly redundant with LBNL. From the summer of 1999, the IPST-GT and LBNL teams were working together and helped each other often by collaborating and visiting either laboratory when was necessary. Around the beginning of 2000, began an effort at IPST to create an off-line laser-ultrasonics instrument that could perform automated measurements of paper and paperboard's bending stiffness. It was widely known that the mechanical bending tests of paper used for years by the paper industry were very inaccurate and exhibited poor reproducibility; therefore the team needed a new instrument of reference to validate its future on-line results. In 1999-2000, the focus of the on-line instrument was on a pre-industrial demonstration on a pilot coater while reducing the damage to the web caused by the generation laser, below the threshold where it could be visible by the naked eye. During the spring of 2000 Paul Ridgway traveled to IPST and brought with him a redesigned system still using the same Mach-Zehnder interferometer as before, but this time employing an electric motor-driven spinning mirror instead of the previously belt-driven mechanical spinning mirror. For testing we chose to use a 1 foot-wide paper loop running on IPST's large scale web handler which could reach a web speed of 2,000 feet/min (10.16 m/s). This was more representative of the conditions encountered of a pilot coater, than on a table-top scale web simulator.",2005,
Effect of salt contents on enzymatic activities and halophilic microbial community structure during phenanthrene degradation,"The halophilic bacteria could be useful for bioremediation of polycyclic aromatic hydrocarbons (PAHs) pollution in hypersaline environments, which has posed a significant environmental problem. The effect of salt contents on a halophilic bacterial consortium, which was enriched from an oil-contaminated saline soil, was investigated. At 20 per cent salt contents, the consortium maintained lower PAHs dioxygenase (PDO), catechol 2, 3-dioxygenase (C23O) and catechol 1, 2-dioxygenase (C12O) activity than at 10 per cent salt contents before complete degradation. Pyrosequencing results indicated that the predominant bacteria were closely related to genera Thalassospira, Rhodobium, Mariprofundus and Psychroflexus at 10 per cent salt contents, while at 20 per cent salt contents, the dominant bacteria were Chromohalobacter and Methylohalomonas, suggesting some bacteria could not survive at higher salt contents. Increased salt contents decreased the diversity of the bacterial consortium and favored the growth of bacteria in class Gammaproteobacteria. Three-dimensional excitation-emission matrix fluorescence spectra (3DEEMs) showed that elevated salt contents also made some intermediate products accumulated during degradation and then lowered the phenanthrene degradation rate. This study extended the knowledge on decontamination of PAHs in saline environments by an applicable halophilic bacterial consortium.",2016,International Biodeterioration & Biodegradation
The Gamma Lasso,"This article describes a very fast algorithm for obtaining continuous regularization paths corresponding to cost functions spanning the range of concavity between L0 and L1 norms. The â€˜gamma lassoâ€™ heuristic does L1 (lasso) penalized regression estimation on a grid of decreasing penalties, but adapts coefficient-specific weights to decrease as a function of the estimated coefficient in the previous path segment. Our particular weight-updating scheme is motivated from a Bayesian model, and is related to estimation under log penalties. This very simple recipe is used to illustrate the large and difficult literature on concave penalization, with the hope that we can make the ideas more accessible to practitioners. The construction also leads us to a plug-in estimator for degrees of freedom; this is applied in model selection, and in experimentation our information criteria perform as well as cross-validation. The work is illustrated in linear regression simulations and in application of logistic regression to evaluate hockey players.",2013,
A Deep Learning Approach to Predict Parking Occupancy using Cluster Augmented Learning Method,"This paper proposes a deep learning model for block-level parking occupancy prediction. The proposed model leverages Convolutional Neural Nets (CNN) to extract spatial relations of traffic flow and stacked LSTM autoencoder to capture temporal correlations. The paper also introduces Clustering Augmented Learning Method (CALM) which is based on concept of simultaneous heterogeneous clustering and regression learning to learn deep feature representations of spatio-temporal data obtained using the proposed embedding. The regression model that is considered in this work has a Feedforward Neural Net(FNN) architecture. With the aim of improving the accuracy of the regression model, CALM iterates between clustering and learning to form robust clusters, thereby leveraging the learning process of the FNN. A dissimilarity measure is proposed based on the weights of each feature of input data in the regression model to form the clusters. During each iteration of learning and clustering, a classifier is used to predict the current cluster labels, and the cluster belonging probabilities are used to control the subsequent re-estimation of cluster centers. Computational experiments on San Francisco Parking data set reveals that proposed approach CALM outperforms other baseline methods including multi-layer LSTM and Lasso with testing MAPE of 7.8% when predicting block-level parking occupancies. The findings highlight that the way in which the spatio - temporal information is exploited in order to aggregate the analogous data into clusters makes a significant difference and demonstrate the effectiveness of the model in processing parking data.",2019,2019 International Conference on Data Mining Workshops (ICDMW)
Analysis of a multiclass classification problem by Lasso Logistic Regression and Singular Value Decomposition to identify sound patterns in queenless bee colonies,"Abstract This study presents an analysis of a multiclass classification problem to identify queenless states by monitoring bee sound in two possible cases; a strong and healthy colony that lost its queen and a reduced population queenless colony. The sound patterns were compared with patterns of healthy queenright colonies. Five colonies of Carniola honey bee were monitored by using a system based on a Raspberry Pi 2 and omnidirectional microphones placed inside the hives. Feature extraction was carried out by Mel Frequency Cepstral Coefficients (MFCCs) method. A multiclass model with three outcome variables was constructed. For feature selection and regularization, a Lasso logistic Regression model was used along with one vs all strategy. To provide visual evidence and examine the results, data was analyzed by scatter plots of Singular Value Decomposition (SVD). The results show that is possible to detect the queenless state in both cases. Queenless or healthy colonies can generate slightly different patterns and the data clusters of the same condition tend to be close. The proposed methodology can be applied for the analysis of more conditions in bee colonies.",2019,Comput. Electron. Agric.
Multivariate sparse group lasso for the multivariate multiple linear regression with an arbitrary group structure.,"We propose a multivariate sparse group lasso variable selection and estimation method for data with high-dimensional predictors as well as high-dimensional response variables. The method is carried out through a penalized multivariate multiple linear regression model with an arbitrary group structure for the regression coefficient matrix. It suits many biology studies well in detecting associations between multiple traits and multiple predictors, with each trait and each predictor embedded in some biological functional groups such as genes, pathways or brain regions. The method is able to effectively remove unimportant groups as well as unimportant individual coefficients within important groups, particularly for large p small n problems, and is flexible in handling various complex group structures such as overlapping or nested or multilevel hierarchical structures. The method is evaluated through extensive simulations with comparisons to the conventional lasso and group lasso methods, and is applied to an eQTL association study.",2015,Biometrics
Physiological feature analysis in Heart Rate Turbulence using LASSO model,"Heart Rate Turbulence (HRT) is a relevant cardiac risk stratification criterion. It is usually assess by means of turbulence slope (TS) and turbulence onset (TO) parameters. HRT is known to be affected by several physiological factors, mainly heart rate (HR) and coupling interval (CI). The physiological hypothesis accepted is the baroreflex source of the HRT. However, several studies showed different results about the relationship between CI and HRT parameters. Our aim was to propose a complete LASSO model using CI and sinus cardiac length (SCL), their powers and an interaction term as explanatory variables to account for the physiological dynamic of the TS parameter. We used a database of 61 recording holters from acute myocardial infarction (AMI) patients. The database was split into two groups; low-risk patients (TS> 2.5 & TO <; 0), and high-risk patients (TS <; 2.5 & TO> 0). We performed a feature analysis by means of the LASSO paths, in which the regularization parameter is changed from very high values, where all weights of the explanatory variables are zero, to small values were all the weights are different from zero. The first variable activated, with a coefficient different from zero, was SC L on low-risk patients and the two following where related to CI. Whereas the first variable activated on high-risk patient was CI and the two following were relate to SC L. Results from LASSO paths suggest that the influence of physiological variables on HRT is broken on AMI high-risk and completely different from low-risk. Also, the features selected by LASSO model on AMI low-risk are in agreement with the hypothesis of a baroreflex source of the HRT, in which SCL is the most important variable, and CI has a negative correlation with TS.",2013,Computing in Cardiology 2013
An overview of current microarray-based human globin gene mutation detection methods.,"The panoply of human globin gene mutation detection methods could become significantly enriched with the advent of microarray-based genotyping platforms. The aim of this article is to provide an overview of the current medium and high-throughput microarray-based globin gene mutation detection platforms, namely the microelectronic array, the ""thalassochip"" arrayed primer extension (APEX) technology and the single base extension methods. This article also outlines an emerging method based on multiple ligation probe amplification (MLPA) and discusses the implications of customized solutions for resequencing of genomic loci in relation to molecular genetic testing of hemoglobinopathies.",2007,Hemoglobin
"SABR: sparse, anchor-based representation of the speech signal","We present SABR (Sparse, Anchor-Based Representation), an analysis technique to decompose the speech signal into speaker-dependent and speaker-independent components. Given a collection of utterances for a particular speaker, SABR uses the centroid for each phoneme as an acoustic â€œanchor,â€ then applies Lasso regularization to represent each speech frame as a sparse non-negative combination of the anchors. We illustrate the performance of the method on a speaker-independent phoneme recognition task and a voice conversion task. Using a linear classifier, SABR weights achieve significantly higher phoneme recognition rates than Mel frequency Cepstral coefficients. SABR weights can also be used directly to perform accent conversion without the need to train a speakerto-speaker regression model.",2015,
Sparse Coding and Dictionary Learning for Symmetric Positive Definite Matrices: A Kernel Approach,"Recent advances suggest that a wide range of computer vision problems can be addressed more appropriately by considering non-Euclidean geometry. This paper tackles the problem of sparse coding and dictionary learning in the space of symmetric positive definite matrices, which form a Riemannian manifold. With the aid of the recently introduced Stein kernel (related to a symmetric version of Bregman matrix divergence), we propose to perform sparse coding by embedding Riemannian manifolds into reproducing kernel Hilbert spaces. This leads to a convex and kernel version of the Lasso problem, which can be solved efficiently. We furthermore propose an algorithm for learning a Riemannian dictionary (used for sparse coding), closely tied to the Stein kernel. Experiments on several classification tasks (face recognition, texture classification, person re-identification) show that the proposed sparse coding approach achieves notable improvements in discrimination accuracy, in comparison to state-of-the-art methods such as tensor sparse coding, Riemannian locality preserving projection, and symmetry-driven accumulation of local features.",2012,ArXiv
Identification of Geographical Segmentation of the Rental Apartment Market in the Tokyo Metropolitan Area (Short Paper),"It is often said that the real estate market is divided geographically in such a manner that the value of attributes of real estate properties is different for each area. This study proposes a new approach to the investigation of the geographical segmentation of the real estate market. We develop a price model with many regional explanatory variables, and implement the generalized fused lasso - a regression method for promoting sparsity - to extract the areas where the valuation standard is the same. The proposed method is applied to rental data of apartments in the Tokyo metropolitan area, and we find that the geographical segmentation displays hierarchal patterns. Specifically, we observe that the market is divided by wards, railway lines and stations, and neighbourhoods.",2018,
The walking estimated limitation stated by history (WELSH): a visual tool to self-reported walking impairment in a predominantly illiterate population.,"BACKGROUND
The prevalence of cardiovascular diseases is increasing in low-income countries. Various questionnaires to estimate walking capacity in patients are available in multiple languages but they are not suitable for illiterate patients.


OBJECTIVE
The walking estimated limitation stated by history (WELSH) tool aims at rating individual walking disability using only drawings and four items.


METHODS
A six-month prospective study was performed on new patients referred to the Department of Cardiology at the Centre Hospitalier Universitaire SourÃ´ Sanou in Bobo-Dioulasso, Burkina Faso. We administered the WELSH tool after a short oral presentation in the patient's language or dialect. Thereafter, patients performed a six-minute walking test in the hospital corridor under the supervision of a nurse who was blinded to the results of the WELSH score. We performed a step-by-step multilinear regression analysis to determine the factors predicting maximal walking distance (MWD).


RESULTS
There were 40 female and 10 male patients in this study. Their ages ranged from 54.8 Â± 10.7 years. Only 32% of the patients had attended primary school. Most patients were classified as stage I to III of the New York Heart Association (NYHA) classification. The objective measurement of MWD during a six-minute walking test showed no association with the subjects' educational level, body mass index, NYHA stage or gender, but a significant correlation with the WELSH scores. The Spearman r-value for the WELSH score-to-MWD relationship was 0.605 (p < 0.001).


CONCLUSIONS
The WELSH tool is feasible and correlated with measured MWD in a population of predominantly illiterate patients.",2019,Cardiovascular journal of Africa
Tristan Garcia and the Thing-in-itself,"It is a rare pleasure to have this exchange with Tristan Garcia, whose intriguing book Forme et objet will soon appear in English translation.1 Garcia has now written an amiable and insightful account of the similarities and differences between our philosophies, which in his words â€œprovide a rare example of ways of thinking that intersect and meet at certain places and concepts, even though they derive from very different traditions and aim at very distinct goals.â€ I find little to disagree with in his presentation of my ideasâ€” or of his own, for that matter. We still have ample disagreement when it comes to philosophical principles. Among other things, Garcia is right to note that my thinking is less dialectical than his. But my resistance to dialectic in ontology does not extend to its powerful presence in biography. We express our ideas best by contrast with those of neighboring thinkers, who force us to articulate what was previously left unsaid in our work. This can be a lengthy process, one that unfolds not just in conceptual space but also in biographical time: through personal meetings, series of ripostes, and even intervals of tension. I still learn much from disagreement after fourteen years of acquaintance with Bruno Latour and half as many with Quentin Meillassoux, and expect to learn no less during what I hope will be decades of communication with Garcia. The present response is merely the opening scene of a play whose end date remains unknown.",2013,
High-dimensional variable selection for Coxâ€™s proportional hazards model,"Variable selection in high dimensional space has challenged many contemporary statistical problems from many frontiers of scientific disciplines. Recent technological advances have made it possible to collect a huge amount of covariate information such as microarray, proteomic and SNP data via bioimaging technology while observing survival information on patients in clin- ical studies. Thus, the same challenge applies in survival analysis in order to understand the association between genomics information and clinical infor- mation about the survival time. In this work, we extend the sure screening procedure (6) to Cox's proportional hazards model with an iterative version available. Numerical simulation studies have shown encouraging performance of the proposed method in comparison with other techniques such as LASSO. This demonstrates the utility and versatility of the iterative sure independence screening scheme.",2010,arXiv: Machine Learning
Variable selection in regression using maximal correlation and distance correlation,"In most of the regression problems the first task is to select the most influential predictors explaining the response, and removing the others from the model. These problems are usually referred to as the variable selection problems in the statistical literature. Numerous methods have been proposed in this field, most of which address linear models. In this study we propose two variable selection criteria for regression based on two powerful dependence measures, maximal correlation and distance correlation. We focus on these two measures since they fully or partially satisfy the RÃ©nyi postulates for dependence measures, and thus they are able to detect nonlinear dependence structures. Therefore, our methods are considered to be appropriate in linear as well as nonlinear regression models. Both methods are easy to implement and they perform well. We illustrate the performances of the proposed methods via simulations, and compare them with two benchmark methods, stepwise Akaike information criterion and lasso. In several cases with linear dependence all four methods turned out to be comparable. In the presence of nonlinear or uncorrelated dependencies, we observed that our proposed methods may be favourable. An application of the proposed methods to a real financial data set is also provided.",2015,Journal of Statistical Computation and Simulation
Genomic transcription regulatory element location analysis via poisson weighted lasso,"The distances between DNA Transcription Regulatory Elements (TRE) provide important clues to their dependencies and function within the gene regulation process. However, the locations of those TREs as well as their cross distances between occurrences are stochastic, in part due to the inherent limitations of Next Generation Sequencing methods used to localize them, in part due to biology itself. This paper describes a novel approach to analyzing these locations and their cross distances even at long range via a Poisson random convolution. The resulting deconvolution problem is ill-posed, and sparsity regularization is used to offset this challenge. Unlike previous work on sparse Poisson inverse problems, this paper adopts a weighted LASSO estimator with data-dependent weights calculated using concentration inequalities that account for the Poisson noise. This method exhibits better squared error performance than the classical (unweighted) LASSO both in theoretical performance bounds and in simulation studies, and can easily be computed using off-the-shelf LASSO solvers.",2016,2016 IEEE Statistical Signal Processing Workshop (SSP)
Feature Selection Based on Structured Sparsity: A Comprehensive Study.,"Feature selection (FS) is an important component of many pattern recognition tasks. In these tasks, one is often confronted with very high-dimensional data. FS algorithms are designed to identify the relevant feature subset from the original features, which can facilitate subsequent analysis, such as clustering and classification. Structured sparsity-inducing feature selection (SSFS) methods have been widely studied in the last few years, and a number of algorithms have been proposed. However, there is no comprehensive study concerning the connections between different SSFS methods, and how they have evolved. In this paper, we attempt to provide a survey on various SSFS methods, including their motivations and mathematical representations. We then explore the relationship among different formulations and propose a taxonomy to elucidate their evolution. We group the existing SSFS methods into two categories, i.e., vector-based feature selection (feature selection based on lasso) and matrix-based feature selection (feature selection based on lr,p-norm). Furthermore, FS has been combined with other machine learning algorithms for specific applications, such as multitask learning, multilabel learning, multiview learning, classification, and clustering. This paper not only compares the differences and commonalities of these methods based on regression and regularization strategies, but also provides useful guidelines to practitioners working in related fields to guide them how to do feature selection.",2017,IEEE transactions on neural networks and learning systems
Oracle inequalities for the Lasso for the conditional hazard rate in a high-dimensional setting,"We aim at obtaining a prognostic on the survival time adjusted on covariates in a high-dimensional setting. Towards this end, we consider a conditional hazard rate function that does not rely on an underlying model and we estimate it by the best Cox's proportional hazards model given two dictionaries of functions. The first dictionary is used to construct an approximation of the logarithm of the baseline hazard function and the second to approximate the relative risk. Since we are in high-dimension, we consider the Lasso procedure to estimate the unknown parameters of the best Cox's model approximating the conditional hazard rate func- tion. We provide non-asymptotic oracle inequalities for the Lasso estimator of the conditional hazard risk function. Our results are mainly based on an empirical Bernstein's inequalities for martingales with jumps.",2012,
A regularization approach for estimation and variable selection in high dimensional regression models,"Model selection and estimation are important topics in econometric analysis which can become considerably complicated in high dimensional settings, where the set of possible regressors can become larger than the set of available observations. For large scale problems the penalized regression methods (e.g. Lasso) have become the de factor benchmark that can effectively trade off parsimony and fit. In this paper we introduce a regularized estimation and model selection approach that is based on sparse large covariance matrix estimation, introduced by Bickel and Levina (2008) and extended by Dendramis et al (2017). We provide asymptotic and small sample results that indicate that our approach can be an important alternative to the penalized regression. Moreover, we also introduce a number of extensions that can improve the asymptotic and small sample performance of the proposed method. The usefulness of what we propose is illustrated via Monte Carlo exercises and an empirical application in macroeconomic forecasting.",2018,
The Trouble with Chill Pills,"Andrea ToneBasic Books (2008)320 pp., $26.95 hardcover.In the early 1960s Hoffman La-Roche, a Swiss pharmaceuticalcompany, introduced Librium (chlordiazepoxide) and Valium(diazepam) for the treatment of anxiety. Members of a new classof drugs named benzodiazepines, they were immediate best-sellers. In The Age of Anxiety Andrea Tone (2008), a ProfessoroftheSocialHistoryofMedicineatMcGill,describesthepeople,the companies, and the cultural forces that brought us thesemedications and considers their societal impact. In telling thesestories Tone also helps us anticipate the reaction to the newdrugs for anxiety that are on the way.Benzodiazepines were not the ï¬rst antianxiety drugs to enjoyan enthusiastic reception. Tone starts the book by describingWallaceLaboratoriesâ€™discoveryoftheirimmediatepredecessor,meprobamate (Miltown), which was introduced in 1955 and re-vealed the unexpected demand for what the public called chillpills. Eager for a share of this huge new market, other drugcompanies rushed to compete. Some tried to make patentableknock-offs of meprobamate, a me-too approach that remainspopular, but they didnâ€™t get very far. Roche decided to takea much riskier approach by asking their chemists to hunt forsomething truly novel by trial and error.The leading advocate of the trial and error approach was LeoSternbach, a chemist whom Roche had rescued from the Nazisandwhohadestablishedhimselfasagiftedinnovator.Havingnoidea what kind of chemicals might reduce anxiety, Sternbachdecided to make a series of derivatives of a synthetic dye thathe had studied in the past and submitted them for behavioraltesting in mice. Amazingly, one of them worked: mice treatedwith the new compound were much easier to handle, a sign ofdecreased anxiety, yet were not as sedated as those who tookmeprobamate. The same was true in more sophisticated behav-ioral tests in animals and in anxious patients. Furthermore thisdrug, which became Librium, had very little toxicity. Tonedescribes how its usefulness was then quickly established inclinical trials that were far less stringent than those that arerequired today, and how its superiority to Miltown was subse-quently conï¬rmed.Having discovered the value of this new compound, Stern-bach continued his tinkering. He soon made Valium, whichwasmuchmorepotentthanLibriumandbecameanevenbiggerblockbuster.Overtheyearsotherpopularbenzodiazepinessuchas Klonopin (clonazepam) ï¬‚owed from his lab and their clinicalvalues were established by the rigorous criteria that the FDAhad by then put in place.Benzodiazepines were not only helpful for patients. They alsoturnedouttobevaluabletoolsforbasicneurobiologicalresearch.The ï¬rst breakthrough came in 1975 with the discovery thatbenzodiazepinesworkbyaugmentingtheactionsofGABA,whichmade them useful for studying inhibitory neurotransmission.Subsequent studies showed that these actions are somewhatselective because they only bind to regulatory sites on certainformsoftheGABA-Areceptor,andthisopenedupmanyproduc-tive lines of investigation.While these exciting discoveries were being made, the darkside of benzodiazepines was also becoming apparent, as Tonedescribes in considerable detail. One of their troublesomefeaturesisthatthedoserequiredtorelieveanxietyalsoproducessome sedation and slowing of cognition. They also have a muchbigger drawback: all of them are potentially habit forming.Althoughmostpeoplecanbetaughttousethesevaluabledrugswithout getting into trouble, some become physically andpsychologically dependent on them and may even becomeaddicted.Despitethesedrawbackssalesboomed.Fueledbyavigorousadvertising and marketing campaign that was an early exampleof those that are now all too familiar, physicians beganprescribing Valium for any sign of emotional distress and itbecame the number one prescription drug for a decade. Stay-at-home moms were Valiumâ€™s major consumers, but men alsobegan to rely on it to help them deal with the pressures of theirjobs. Forsomeitproved veryhelpful. Forthosewhowere simplyswept up by this latest fad it did more harm than good.Eventually there was public criticism of the overuse of thesemedications. Toneâ€™s most memorable example is the RollingStonesâ€™hitsong,Motherâ€™sLittleHelper,whichlamentedahouse-wifeâ€™s dependence on her little yellow pill. Public advocacygroups also joined in the attack and condemned what theyconsidered to be overzealous promotion of drugs to peoplewhodonâ€™treallyneedthem.Theircasewasgreatlystrengthenedby stories of the abuse of benzodiazepines by public ï¬guressuch as President Gerald Fordâ€™s wife, Betty Ford.All this negative publicity took its toll. Tone explains how theoutcry led to the FDAâ€™s classiï¬cation of benzodiazepines ascontrolled substances, which constrained their marketing andNeuron 62, May 28, 2009 a2009 Elsevier Inc. 461",2009,
Mill Load Parameter Forecasting Based on Multi-source Single-scale Mechanical Frequency Spectral Multiple feature Subsets,"Abstract Multi-source mechanical signals at different locations of the ball mill system have different contributions for constructing mill load parameter forecasting (MLPF) model. It is necessary to select suitable multi-source mechanical signals and their frequency spectral feature subsets. Aim at these problems, a new MLPF approach based on LASSO algorithm and selective ensemble (SEN) modeling strategy by using multi-source single-scale mechanical frequency spectrum is proposed. At first, Fast Fourier transformer (FFT) is used to obtain single-scale frequency spectrum of these multi-source (channel) mechanical signals. Then, SEN-LASSO modeling approach based on candidate regularization parameter set is used to obtain single-scale frequency spectral feature subsets and to build single-channel SEN MLPF model jointly. Finally, SEN strategy is employed again to construct the final MLPF model by selecting and combining these single-channel SEN MLPF models. Simulation results based on a laboratory-scale ball mill validate effectiveness of this approach.",2018,IFAC-PapersOnLine
Performance Analysis of LASSO-based Signal Parameter Estimation,"The Least Absolute Shrinkage and Selection Operator (LASSO ) has gained attention in a wide class of continuous parametric estimation problems with pr omising results. In these applications the desired information is given by the unknown support of a spar e vector represented by some continuous parameters. The objective of this work is to provide a theore tical analysis of such a LASSO-based estimator in terms of the classical statistical measures, i . . variance and bias. Employing LASSO, which only admits a discrete set of candidate regressors, to a cont inu us valued problem complicates the analysis significantly. We respond to this dilemma by introducing a ne w approach considering an intermediate sparse estimator over the continuum, which we show to be asym ptotically equivalent to LASSO but easier to analyze. This provides us theoretical expression for the LASSO-based estimation error in the asymptotic case of high SNR and dense grids. We specifically s how that beyond the RIP-based results, such an asymptotic case may be consistent in many individual cases of interest. Without loss of generality, we present the comparative numerical results in the context of Direction of Arrival (DOA) estimation using a sensor array. Index Terms Compressed Sensing, performance analysis, sparse estimat ion, sparse regression, continuous regression",2012,
Development of a Novel Prognostic Risk Score for Predicting Complications of Penectomy in the Surgical Management of Penile Cancer,"Introduction Penectomy for PC is useful in staging, disease prognosis, and treatment. Limited studies have evaluated its surgical complications. We sought to assess these complications and determine predictive models to create a novel risk score for penectomy complications. Patients and Methods A retrospective review of patients undergoing PC surgical management from the 2005â€2016 American College of Surgeons National Surgical Quality Improvement Program was performed. Data were queried for partial and total penectomy among those with PC. To develop predictive models of complications, we fit LASSO logistic, random forest, and stepwise logistic models to training data using crossâ€validation, demographic, comorbidity, laboratory, and wound characteristics as candidate predictors. Each model was evaluated on the test data using receiver operating characteristic curves. A novel risk score was created by rounding coefficients from the LASSO logistic model. Results A total of 304 cases met the inclusion criteria. Overall incidence of penectomy complications was 19.7%, where urinary tract infection (3.0%), superficial surgical site infection (3.0%), and bleeding requiring transfusion (3.9%) were most common. LASSO logistic, random forest, and stepwise logistic models for predicting complications had area under the curve (AUC) [95% confidence interval] values of 0.66 [0.52â€0.81], 0.73 [0.63â€0.83], and 0.59 [0.45â€0.74], respectively. Eleven variables were included in the risk score. The LASSO modelâ€“derived risk score had moderately good performance (area under the curve [95% confidence interval] 0.74 [0.66â€0.82]). Using a cutoff point of 6, the score attains sensitivity 0.58, specificity 0.74, and kappa 0.26. Conclusion PC management through penectomy is associated with appreciable complications rates. Predictive models of penectomy complications performed moderately well. Our novel prognostic risk score may allow for improved preoperative counseling and risk stratification of men undergoing surgical management of PC. Microâ€Abstract Limited studies exist on complications of penile cancer surgical treatment. We sought to create a novel risk score for penectomy. Using the American College of Surgeons National Surgery Quality Improvement Program database, we fit least absolute shrinkage and selection operator, random forest, and stepwise logistic models to training data and evaluated each model using receiver operating characteristic curves. Predictive models performed moderately well. Our novel prognostic risk score may allow for improved preoperative counseling.",2019,Clinical Genitourinary Cancer
A re-examination of a specimen of pterosaur soft tissue from the Cretaceous Santana formation of Brazil,"Multiple pterosaur specimens have revealed details of their soft tissue anatomy, including wing membranes supported internally by strengthening fibres (aktinofibrils), a hair-like integument across their bodies, necks and heads (pycnofibres), elaborate soft-tissue head crests, tail vanes and other structures. These have enabled a more comprehensive picture of them as living animals than skeletal remains alone could, though many aspects of the structure and composition of these soft tissues remain controversial. 
 
The histology of pterosaur wing membranes has been a particularly contentious issue, with much debate focused on an alleged portion of wing membrane (DGM 1475-R) from the Lower Cretaceous Santana Formation of northeast Brazil. Initially described as a portion of wing membrane from the proximal wing region by Martill and Unwin (1989), after re-examination of the same specimen Kellner (1996) argued that it represented a piece of body wall. With DGM 1475-R showing features not seen in other specimens of pterosaur wing membrane and being one of the few three-dimensionally preserved portions of pterosaur membrane known, resolving this controversy is key to understanding this important 
component of pterosaur flight anatomy. 
 
In this study, DGM 1475-R was re-examined in an attempt to clarify the identity of its soft-tissues. Interpretation of the humerus and several ribs associated with the soft-tissue tentatively suggests that the specimen represents a thalassodromid pterosaur. A new section was taken through the soft-tissues and acid etched to highlight histological features. Multiple layers were identified within the soft tissue, including an external epidermis and a layer of muscle. The structures between these layers - numerous objects that appear to be fibres larger than the undoubted muscle fibres - are more ambiguous. These were previously identified as aktinofibrils (Martill et al., 1990), but this is considered unlikely due to differences in the shape, density and distribution of the structures when compared to aktinofibrils in other pterosaur wings. Instead, it is tentatively suggested that they represent a further layer of muscle fibres, but this cannot be conclusively proven. Further comparisons were made between DGM 1475-R and a dissected bat wing to find additional diagnostic wing tissues, but they were found to have such fundamental histological differences that such comparisons were of little use. 
 
Aktinofibrils are the only known diagnostic features of pterosaur wings, suggesting that their absence in DGM 1475-R argues against the specimen stemming from the wing tissues. Interpretations of pterosaur wing membrane and flight based on DGM 1475-R being wing membrane are therefore suspect.",2011,
Regularization Parameter Selection in the Group Lasso ( ?,"This article discusses the problem of choosing a regularization parameter in the group Lasso proposed by Yuan and Lin (2006), an l1-regularization approach for producing a block-wise sparse model that has been attracted a lot of interests in statistics, machine learning, and data mining. It is important to choose an appropriate regularization parameter from a set of candidate values, because it affects the predictive performance of the fitted model. However, traditional model selection criteria, such as AIC and BIC, cover only models estimated by maximum likelihood estimation and can not be directly applied for regularization parameter selection. We propose an information criterion for regularization parameter selection in the group Lasso in the framework of maximum penalized likelihood estimation.",2006,
New data on the gold-antigorite association of the Urals,"Many placers of the Urals spatially associated withmassifs of serpentinized ultramaï¬c rocks contain goldâ€“magnetite associations [7]. The bedrock analogs of thisassociation are rare, small, and interpreted as deriva-tives of granitoid magmatism. Goldâ€“magnetite occur-rences in the Kagan alpinotype ultramaï¬c massif in theSouth Urals, for example, served as a basis for distin-guishing the Au-productive serpentinite (antigorite)metasomatic association [9]. In addition to the spatialassociation of gold mineralization with antigorite ser-pentinites, the existence of this association is substanti-ated by the fact of signiï¬cant redistribution and mobili-zation of Au during the development of antigorite,which allowed us to suggest that gold mineralization inthe antigorite serpentinites was formed during crustalregional or local metamorphism of the ultramaï¬c mas-sifs under crustal conditions [6]. The present study ofgoldâ€“magnetite ores and altered rocks of the Kaganmassif revealed mineralogical and isotopicâ€“geochemi-cal evidence for the metamorphic origin of mineraliza-tion. In this model, ï¬‚uid and ore components (Fe, Cu,and Au) were mobilized from ultrabasic rocks.The Kagan Massif is located in the Vishnevogorskâ€“Ilâ€™menogorsk metamorphic complex in the SouthUrals. Lenslike ultrabasic bodies of the complex arecontrolled by deep-seated faults and traditionallyascribed to the Riphean riftogenic ophiolites, whichunderwent Late Cambrian regional zoned metamor-phism and Early Paleozoic siliceous metasomatism [2].According to these concepts, the ultramaï¬c rockstogether with host volcanosedimentary rocks weretransformed with decreasing temperature into olivineâ€“enstatite, talcâ€“olivine, olivineâ€“antigorite, and antigoriteserpentinites during high-grade metamorphism, whilelater metasomatism was responsible for the formationof enstatite, anthophyllite, and talcâ€“carbonate rocks.According to Varlakov, rocks of the Kagan Massifunderwent zoned metamorphism. Its southern part iscomposed of talcâ€“olivine and olivineâ€“antigorite rocks,while the northern part consists of antigorite serpen-tinites with relicts of olivineâ€“antigorite rocks (Fig. 1).The silicic metasomatism is weak and manifested in thedevelopment of anthophyllite in talcâ€“olivine rocks andthe development of talc in olivineâ€“antigorite rocks andantigorite serpentinites. The occurrences of massiveand veinâ€“schlieren magnetite ores containing up to 2â€“3% sulï¬des are conï¬ned to the tectonic zone extendingover 2 km along the eastern contact of the northern partof the massif. Magnetite lenses up to 5â€“6 m long and0.2 m thick form chains rapidly pinching out along thetectonic zone. The ores are contained in reticulate ser-pentinite with abundant ï¬ne magnetite, which empha-sizes the afï¬liation of serpentine to chrysotile. In theimmediate contact with ore, the reticulate serpentinitecontains spots and veinlets of antigorite with large mag-netite, talc, chlorite, and amphibole.The goldâ€“magnetite ores were developed by twosmall mines in the mid 20th century. Gold assayaccounts for 0.2â€“1.2 g/t, sharply increasing in the areaswith visible gold particles. The chemicalâ€“spectral anal-ysis of individual samples showed that the magnetiteores contain Au (up to 160 mg/t), Pd (up to 770 mg/t),and Pt (up to 20 mg/t) [5]. The contents of Rh, Ir, Os,and Ru are less than 10â€“20 mg/t.Magnetite of massive and disseminated ores is char-acterized by a ubiquitous admixture of Mg (1.0â€“2.4 wt % MgO). Magnetite from the wall rocks, inaddition, contains 0.4â€“2.0 wt % Cr",2007,Doklady Earth Sciences
Adaptive and Behavioral Development in Children with Down Syndrome at School Age with Special Emphasis on Attention Deficit Hyperactivity Disorder (ADHD),"Down syndrome (DS) is the most common chromosomal anomaly occurring in live births (Capone et al, 2004; Menkes & Falk, 2005) and it has been described as a syndrome-complex of genetic origin with protean neurobiological consequences, and several characteristic neurodevelopmental and neuropsychological manifestations. Down syndrome is also considered to be the most common single cause of mild, moderate and severe mental retardation (MR) with over half of individuals with DS attaining an IQ of between 50 and 25 by the end of the first decade of life (Bittles & Glasson, 2004; Capone, 2004; Hanson, 2003; Menkes & Falk, 2005; Roubertoux & Kerdelhue, 2006; Van Cleve & Cohen, 2006; Vicari, 2006). Individuals with Down syndrome experience a reduced life expectancy, but within the DS population, life expectancy is increasing. Clinically, individuals with Down syndrome have typical physical and anatomical characteristics (Van Cleve &, Cohen, 2006). An issue of major medical importance is the participation and function on the health of individuals, communities and society. A holistic approach is now vital when assessing the individual, from body functions and IQ to learning abilities, attentional skills, daily activities and participation defined by the ICF as â€˜the execution of a task or actionâ€™ with involvement in a life situation (WHO, 2001). Despite these shifts, there is limited investigation into the activity performance, participation, learning and behavior of children with DS, as measured by their adaptive functioning. The cognitive limitations of individuals with Down syndrome have an important influence on the level of functioning attained and a significant correlation between IQ and all areas of function has been noted. Relatively preserved visualâ€“spatial and visualâ€“motor skills are often noted, yet the influence of these skills on the activity performance of the child with DS is unclear (Fiddler, et al 2005; Vicari 2006; Vicari & Carlesimo 2006).",2011,
Microcin J25 induces the opening of the mitochondrial transition pore and cytochrome c release through superoxide generation.,"Microcin J25, an antimicrobial lasso-structure peptide, induces the opening of mitochondrial permeability transition pores and the subsequent loss of cytochrome c. The microcin J25 effect is mediated by the stimulation of superoxide anion overproduction. An increased uptake of calcium is also involved in this process. Additional studies with superoxide dismutase, ascorbic acid and different specific inhibitors, such as ruthenium red, cyclosporin A and Mn(2+), allowed us to establish a time sequence of events starting with the binding of microcin J25, followed by superoxide anion overproduction, opening of mitochondrial permeability transition pores, mitochondrial swelling and the concomitant leakage of cytochrome c.",2008,The FEBS journal
"Profil des sensibilisations aux pneumallergÃ¨nes courants chez les patients asthmatiques Ã  Bobo-Dioulasso, Burkina Faso","Dans le but dâ€™ameliorer la qualite de la prise en charge des patients asthmatiques, nous avons etudie le profil des sensibilisations aux pneumallergenes courants chez les sujets asthmatiques recus en consultation de pneumologie a Bobo-Dioulasso, Burkina Faso. Nous avons realise une etude prospective portant sur 896 patients asthmatiques recus de janvier 2005 a decembre 2012. La recherche deÂ  sensibilisations a ete realisee grÃ¢ce aux prick-tests cutanes effectues sur lâ€™avant-bras avec des extraits allergeniques standardises des Laboratoires Stallergenes- France. Sept cent quatre vingt et un (781) patients, soit 87,1% des patients, ont presente des reactions positives aux pneumallergenes testes. Chez ces sujets atopiques, les sensibilisations aux allergenes dâ€™acariens ont ete les plus frequentes (87,3 %) dont 91 % a Dermatophagoides pteronyssinus, 89 % aÂ  Dermatophagoides farinae et 51 % a Blomia topicalis. Les sensibilisations aux allergenes de blattes germaniques ont ete de 38,1 %. Les moisissures ont ete responsables de sensibilisation chez 37 % des patients atopiques : Aspergillus 22 % et Alternaria, 15 %. Des reactions positives aux phaneres de chat (14 %), de chien (10,8 %), au latex (7,9 %) et de la souris (1,4 %) ont ete egalement rencontrees. Les sources allergeniques identifiees pourraient etre des facteurs declenchant ou aggravant lâ€™asthme en raison du lien demontre entre sensibilisations et risque dâ€™asthme dans plusieurs etudes. La mise en evidence de lâ€™atopie ouvre la voie a une meilleure prise en charge de ces patients. Mots-cles : Sensibilisation, Pneumallergenes perannuels, Asthme, Bobo-Dioulasso (Burkina Faso). In order to improve the quality of care for asthmatic patients, we studied the profile of sensitization to aeroallergens in asthmatic subjects received in the teaching hospital (pulmonology unit) of Bobo-Dioulasso, Burkina Faso. We performed a prospective study of 896 patients with asthma, received from January 2005 to December 2012. A skin prick test was performed. Seven hundred eighty-one patients (87.1%) showed positive reactions to aeroallergens tested. Among these atopic patients, sensitization to mite allergens was the most frequent (87.3%), followed by those to cockroach allergens (38.1%) and molds (37%). Positive reactions to cat allergen (14%), dog (10.8%), latex (7.9%) and mouse (1.4%) were also observed. The allergenic sources identified are factors triggering or aggravating asthma, as demonstrated by several studies. Identification of atopy is a great step of these patients asthma management. Keywords : Sensitization, per annual aeroallergens, asthma, Bobo-Dioulasso (Burkina Faso).",2014,
L21-iPaD: An efficient method for drug-pathway association pairs inference,"Pathway-based drug discovery overcomes the disadvantages of the â€œone drug-one targetâ€ method, which aims to find the effective drugs to act on single targets. The current method â€œiPaDâ€ identities the drug-pathway association pairs by taking the lasso-type penalty on the drug-pathway association matrix. In order to enhance the robustness of the methods and be more effective to find the novel drug-pathway association pairs, we introduce a new method named â€œL2,1-iPaDâ€. Compared with the iPaD method, we impose the L2,1-norm constraint on the drug-pathway association coefficient matrix. By applying our method to a real widely datasets (CCLE dataset), we demonstrate that our method is superior to the iPaD method. And our method can obtain the smaller P-values than the iPaD method by performing permutation test to assess the significance of the identified drug-pathway association pairs. More importantly, compared with the iPaD method, our method can identify larger numbers of validated drug-pathway association pairs. The experimental results on the real dataset demonstrate the effectiveness of our method.",2016,2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)
Indications and Results of Skin Flaps in Painful Digital Neuroma,"Of the many procedures for treating painful neuromas, resection and proximal translocation are the most usual techniques, but these can decrease distal sensibility increasing deafferentation pain. In cases of intricate pain (nociception plus deafferentation), certain types of flaps allow the treatment of both components of the pain. We have used 30 such flaps in 28 patients: local flaps (exchange, advancement or lasso island flaps) and distant flaps (free â€œcustom-madeâ€ toe flaps).The results of the different techniques provides 86.6% excellent or good results.",1991,Journal of Hand Surgery (British and European Volume)
Predicting Time to Treatment in Follicular Lymphoma Using Population-Based Data,"Introduction

Patients diagnosed with Follicular Lymphoma (FL) either require immediate immuno-chemotherapy or, may simply be observed until the development of symptoms suggests that treatment should be initiated. Although there is no evidence to indicate that early intervention in asymptomatic, stage II - IV disease improves outcomes, both doctors and patients find ""watch and wait"" (W+W) strategies difficult to accept as it leaves considerable uncertainty as to the future. The ability to predict the likely time to treatment (TTT) being required would be helpful, both to give reassurance in cases where the likelihood of therapy in the near future is low and to identify higher risk cases where close observation or early intervention might be justified. Prognostic indices are usually derived using data from clinical trials or institutional datasets where patients who do not require treatment tend to be underrepresented; accordingly we constructed an improved prognostic index for TTT for those patients initially on a W+W strategy in an unselected, population-based cohort.

Methods

This study was based on an established population-based cohort, which since 2004 has tracked all patients newly diagnosed with a haematological malignancy in a representative UK population of nearly 4 million people (www.hmrn.org). All diagnoses, including disease progressions and transformations, are made by a single specialist haematopathology laboratory (www.hmds.info), and clinical teams work to UK guidelines (www.bcshguidlines.com). Clinical and treatment information is systematically collected for all patients and survival data is acquired through links with national data sources.

All 296 out of 741 patients newly diagnosed with FL from 2004-2011 initially managed by a W+W approach were included in the analyses and these patients were followed up to February 2015. Prognostic indices for TTT were constructed using the components of the Follicular Lymphoma International Prognostic Index (FLIPI) and other routinely measured clinical variables. Modern machine learning techniques were used, in particular the LASSO applied to semiparametric survival regression, using bootstrapped model selection to confirm Lasso variable selection. The appropriate functional forms for individual variables were chosen on the basis of the Akaike Information Criterion. Predictive performance was measured using area under the ROC curve (AUC) and the concordance index (C).

Results

With a median age of 65.4 years (range 21-95), 42% of patients were male, 16% had B-symptoms and 37% had stage IV disease at presentation. Median follow-up was 6.4 years; 83 patients were subsequently treated for FL, a further 34 patients transformed to diffuse large B-cell lymphoma and 9 others died from disease progression prior to receiving chemotherapy for FL; median time to these events was 1.4 years. Whilst the FLIPI score for patients initially managed on W+W was predictive for TTT (Figure 1) - achieving an AUC=0.64 and C=0.61, as a result of the model building process a proposed new index for TTT achieved AUC=0.75 and C=0.70 retaining blood albumin, haemoglobin, presence/absence of bulky disease (1/0 respectively) and a score based on the number of nodal sites in the prognostic model (Risk\_Score = Albumin (g/dL) x 0.0412 + 0.719 * bulky\_disease - 0.102 x Hb (g/dL) + 0.159 x nodal_score). The relation between index value and expected time-to-event for TTT is shown in Figure 2.

Conclusion

Our population-based data demonstrates that the FLIPI can be used to predict TTT in patients diagnosed with FL and put onto a W+W strategy. By utilising all of the information contained in the components of the FLIPI and by adding additional routine clinical factors we show that the accuracy of prediction of TTT can be improved leading to the production of an accurate and simple TTT curve that can be used in routine clinical practice.

![Figure 1.][1] 

Figure 1. 
Time-to-treatment stratified by FLIPI (p = 0.0004 log-rank test)





![Figure 2.][1] 

Figure 2. 
Expected Probability of Not Having Received Chemotherapy at 5 years After Diagnosis by Time-to-Treatment Risk Score



Disclosures Patmore: Gilead: Honoraria; Janssen: Honoraria.

 [1]: pending:yes",2015,Blood
Price jump prediction in a limit order book,"A limit order book provides information on available limit order prices and their volumes. Based on these quantities, we give an empirical result on the relationship between the bid-ask liquidity balance and trade sign and we show that liquidity balance on best bid/best ask is quite informative for predicting the future market order's direction. Moreover, we de ne price jump as a sell (buy) market order arrival which is executed at a price which is smaller (larger) than the best bid (best ask) price at the moment just after the precedent market order arrival. Features are then extracted related to limit order volumes, limit order price gaps, market order information and limit order event information. Logistic regression is applied to predict the price jump from the limit order book's feature. LASSO logistic regression is introduced to help us make variable selection from which we are capable to highlight the importance of di erent features in predicting the future price jump. In order to get rid of the intraday data seasonality, the analysis is based on two separated datasets: morning dataset and afternoon dataset. Based on an analysis on forty largest French stocks of CAC40, we nd that trade sign and market order size as well as the liquidity on the best bid (best ask) are consistently informative for predicting the incoming price jump.",2012,Journal of Mathematical Finance
Supervised & unsupervised transfer learning,"This thesis investigates transfer learning in two areas of data analysis, supervised 
and unsupervised learning. We study multi-task learning on vectorial 
data in a supervised setting and multi-view clustering on pairwise distance 
data in a Bayesian unsupervised approach. The aim in both areas is to transfer 
knowledge over different related data sets as opposed to learning on single 
data sets separately. 
 
In supervised learning, not only the input vectors but also the corresponding target vectors are observed. The aim is to learn a mapping from the input 
space to the target space to predict the target values for new samples. In 
standard classification or regression problems, one data set at a time is considered 
and the learning problem for every data set is solved separately. In 
this work, we are looking at the non-standard case of learning by exploiting 
the information given by multiple related tasks. Multi-task learning is based 
on the assumption that multiple tasks share some features or structures. One 
well-known technique solving multi-task problems is the Group-Lasso with 
2-norm regularization. The motivation for using the Group-Lasso is to couple 
the individual tasks via the group-structure of the constraint term. Our main 
contribution in the supervised learning part consists in deriving a complete 
analysis of the Group-Lasso for all p-norm regularizations, including results 
about uniqueness and completeness of solutions and coupling properties of 
different p-norms. In addition, a highly efficient active set algorithm for all 
p-norms is presented which is guaranteed to converge and which is able to 
operate on extremely high-dimensional input spaces. For the first time, this 
allows a direct comparison and evaluation of all possible Group-Lasso methods 
for all p-norms in large scale experiments. We show that in a multi-task 
setting, both, tight coupling norms with p >>Â 2 and loose coupling norms 
with p <<Â 2 significantly degrade the prediction performance. Moderate coupling 
norms seem to be the best compromise between coupling 
strength and robustness against systematic differences between the tasks. 
 
The second area of data analysis we look at is unsupervised learning. In unsupervised 
learning, the training data consists of input vectors without any 
corresponding target vectors. Classical problems in unsupervised learning 
are clustering, density estimation or dimensionality reduction. As in the supervised 
scenario, we are not only considering single data sets independently 
of each other, but we want to learn over two or more data sets simultaneously. 
A problem that arises frequently is that the data is only available as 
pairwise distances between objects (e.g. pairwise string alignment scores from 
protein sequences) and a loss-free embedding into a vector space is usually 
not possible. We propose a Bayesian clustering model that is able to operate 
on this kind of distance data without explicitly embedding it into a vector 
space. Our main contribution in the unsupervised learning part is twofold. 
Firstly, we derive a fully probabilistic clustering method based on pairwise 
Euclidean distances, that is rotation-, translation-, and scale- invariant and 
uses the Wishart distribution in the likelihood term. On the algorithmic 
side, a highly efficient sampling algorithm is presented. Experiments indicate 
the advantage of encoding the translation invariance into the likelihood, 
and our clustering algorithm clearly outperforms several hierarchical clustering 
methods. Secondly, we extend this clustering method to a novel Bayesian 
multi-view clustering approach based on distance data. We show that the 
multi-view clustering method reveals shared information between different 
views of a phenomenon and we obtain an improved clustering compared to 
clustering on every view separately.",2013,
Treatment and prevention of antimicrobial agent-induced colitis and diarrhea,"Abstract Recent studies have shown that a toxin of Clostridium difficile is implicated as the cause of virtually all cases of antimicrobial agent-associated pseudomembranous colitis (PMC), 1 and of approximately one-fifth of cases of antimicrobial agent-associated diarrhea without colonic pseudomembrane. 1,2 Occasionally, PMC or diarrhea not related to antimicrobial exposure has also been attributed to C. diflicile . 2â€“6 A variety of modes of therapy for antimicrobialassociated diarrhea (AAD) have been employed including vancomycin, metronidazole, tetracycline, bacitracin, anion-binding resins, antiperistaltic agents, corticosteroids, and an oral Lactobacillus preparation. Although assessment of the efficacy of treatment is complicated by the variable course of AAD, 7,8 available data are sufficient to permit a rational approach.",1980,Gastroenterology
Sparse Topical Coding with Sparse Groups,"Learning a latent semantic representing from a large number of short text corpora makes a profound practical significance in research and engineering. However, it is difficult to use standard topic models in microblogging environments since microblogs have short length, large amount, snarled noise and irregular modality characters, which prevent topic models from using full information of microblogs. In this paper, we propose a novel non-probabilistic topic model called sparse topical coding with sparse groups (STCSG), which is capable of discovering sparse latent semantic representations of large short text corpora. STCSG relaxes the normalization constraint of the inferred representations with sparse group lasso, a sparsity-inducing regularizer, which is convenient to directly control the sparsity of document, topic and word codes. Furthermore, the relaxed non-probabilistic STCSG can be effectively learned with alternating direction method of multipliers (ADMM). Our experimental results on Twitter dataset demonstrate that STCSG performs well in finding meaningful latent representations of short documents. Therefore, it can substantially improve the accuracy and efficiency of document classification.",2016,
Breast Cancer Risk Prediction Using Electronic Health Records,"Electronic health records (EHRs) represent an underused data source that has great research and clinical potential. Our goal was to quantify the value of EHRs in breast cancer risk prediction. We conducted a retrospective case-control study, gathering patients' ICD-9 diagnosis codes from an existing EHR data repository. Based on the hierarchical structure of ICD-9 codes, which are composed of 3-5 digits, three levels of data representation were studied: level 0, using only the first 3 digits; level 1, using up to the first 4 digits; and level 2, using up to the full 5 digits of each code. We created two models to predict breast cancer one year in advance based on diagnosis codes in three levels of data representation: logistic regression (LR) and LASSO logistic regression (LR+Lasso). Area under the ROC curve (AUC) was used to assess model performance. The LR+Lasso model demonstrated significantly higher predictive performance than the LR model when using the level 2 feature representation (0.648 vs 0.603, p=0.013). For both the level 1 representation and the level 0 representation, the predictive difference between LR+Lasso and LR model was not significant, (0.634 vs 0.604, p=0.081) and (0.612 vs 0.603, p=0.523), respectively. For LR model, predictive performance changed modestly across three levels. For LR+Lasso model, predictive performance also changed modestly from the level 0 to the level 1representation (p=0.168) and from the level 1 to the level 2 representation (p=0.374). However, the level 2 representation provided significantly higher predictive performance than the level 0 representation (p=0.034). The unabridged level 2 representation of the diagnosis codes contains the most valuable information that may contribute to breast cancer risk prediction. The performance of these models demonstrates that EHR data can be used to predict breast cancer risk, which provides the possibility to personalize care in clinical practice. In the future, we will combine coded EHR data with demographic risk factors, genetic variants, and imaging features to improve breast cancer risk prediction.",2017,2017 IEEE International Conference on Healthcare Informatics (ICHI)
On Graphs with Equal Chromatic Transversal Domination and Connected Domination Numbers,"Abstract. Let G =(V,E)beagraphwithchromaticnumber Ï‡(G). Adominating set D of G is called a chromatic transversal dominating set(ctd-set) if D intersects every color class of every Ï‡-partitionof G. Theminimumcardinalityofactd-setofG iscalledthechromatictransversaldomination number of G and is denoted by Î³ ct (G). In this paper wecharacterizetheclassoftrees,unicyclicgraphsandcubicgraphsforwhichthe chromatic transversal domination number is equal to the connecteddominationnumber. 1. IntroductionAll the graphs considered in this paper unless otherwise speciï¬cally statedare ï¬nite, connected and simple and are consistent with the terminology usedin Harary [4]. Let G = (V,E) be a simple graph of order p. For a subset Sof V, N(S) denotes the set of all vertices adjacent to some vertex in S andN[S] = N(S) âˆªS.A vertex v of G is called a support if it is adjacent to a pendant vertex. Anyvertex of degree greater than one is called an internal vertex. A graph G iscalled a unicyclic graph, if G contains exactly one cycle.A subset D âŠ† V is a dominating set, if every v âˆˆ V âˆ’ D is adjacent tosome u âˆˆ D. The domination number Î³ = Î³(G) is the minimum cardinality ofa dominating set of G. A dominating set D is called a connected dominatingset if the induced subgraph hDi is connected. The minimum cardinality of aconnected dominating set is called the connected domination number and isdenoted by Î³",2012,Communications of The Korean Mathematical Society
Undulation frequency affects burial performance in living and model flatfishes.,"Flatfishes bury themselves under a thin layer of sand to hide from predators or to ambush prey. We investigated the role of undulation frequency of the body in burial in five species of flatfishes (Isopsetta isolepis, Lepidopsetta bilineata, Hippoglossoides elassodon, Parophrys vetulus, and Psettichthys melanostictus). High-speed videos show that undulations begin cranially and pass caudally while burying, as in forward swimming in many other fishes. The flatfishes also flick the posterior edge of their dorsal and anal fins during burial, which may increase the total surface area covered by substrate. We built a simple physical model - a flexible, oval silicone plate with a motorized, variable-speed actuator - to isolate the effect of undulation frequency on burial. In both the model and actuated dead flatfish, increased undulation frequency resulted in an increase in the area of sand coverage. Complete coverage required an undulation frequency of no more than 10Hz for our models, and that was also sufficient for live flatfishes. The model shows that undulation is sufficient to bury the animal, but live flatfishes showed a superior ability to bury, which we attribute to the action of the median fins.",2016,Zoology
The Bernstein and Byres Prize in Agrarian Change,"The Journal of Agrarian Change has established a prize named after the founding editors of the Journal, the â€˜Bernstein & Byres Prizeâ€™. The aim is to celebrate the outstanding contributions that we receive by awarding a prize of Â£500 donated by our publisher,Wiley-Blackwell, to the best article of the year.Through this, we also hope to reinforce the remit of the Journal in the field of agrarian political economy and to encourage scholarly work within this tradition._JOAC 299 The articles are judged on: (a) their quality as works of political economy; (b) their analytical power; (c) their originality; and (d) the quality of evidence presented and its deployment. The winner of the 2008 prize has been selected by a jury consisting of Terence Byres, Henry Bernstein and three members of the International Advisory Board of the Journal, based on a shortlist of articles selected by the JAC editors. All evaluators found the task extremely difficult because of the high quality of each of the shortlisted articles. We are pleased to announce that the winners of the Bernstein & Byres Prize for the best article published in JAC in 2008 are J.P. Chauveau and P. Richards, for â€˜West African Insurgencies in Agrarian Perspective: Cote dâ€™Ivoire and Sierra Leone Comparedâ€™ [ JAC, 8 (4): 515â€“52]. This article is an intellectually and empirically impressive, very ambitious and scholarly comparative analysis of two insurgencies in West Africa, examined through the lens of the agrarian roots of violence. The article lucidly explores â€˜different trajectories of agrarian social changeâ€™ (p. 515) as the matrix within which the West African insurgencies in question are to be analyzed. The insurgencies, resulting in civil wars in Sierra Leone (1991â€“2002) and the Cote dâ€™Ivoire (2002â€“7), were rooted in â€˜serious (and still unresolved) social tensions of an agrarian characterâ€™ (p. 537); an issue about which the literature on these countries and on conflicts has generally been silent.The level of empirical detail of the article is matched by an impressive effort to propose variants of an analytical tool rooted in agrarian political economy: the â€˜lineage mode of productionâ€™ developed by French Marxist anthropologists such as Meillassoux. The authors fill an important gap in the literature on conflict, a literature that has tended to focus on â€˜cultureâ€™ or ethnicity as identities, by offering â€˜an analysis linking organizational rivalries to the material struggles in which competing agrarian organizations engageâ€™ (p. 547). We, the editors, would like to congratulate J.P. Chauveau and P. Richards as the worthy winners of the 2008 Bernstein & Byres Prize.",2010,Journal of Agrarian Change
Model Selection and Multiple Testing - A Bayesian and Empirical Bayes Overview and some New Results,"We provide a brief overview of both Bayes and classical model selection. We argue tentatively that model selection has at least two major goals, that of finding the correct model or predicting well, and that in general both these goals may not be achieved in an optimum manner by a single model selection rule. We discuss, briefly but critically, through a study of well-known model selection rules like AIC, BIC, DIC and Lasso, how these different goals are pursued in each paradigm. We introduce some new definitions of consistency, results and conjectures about consistency in high dimensional model selection problems. Finally we discuss some new or recent results in Full Bayes and Empirical Bayes multiple testing, and cross-validation. We show that when the number of parameters tends to infinity at a smaller rate than sample size, then it is best from the point of view of consistency to use most of the data for inference and only a negligible proportion to make an improper prior proper.",2015,arXiv: Statistics Theory
Clinical-learning versus machine-learning for transdiagnostic prediction of psychosis onset in individuals at-risk,"Predicting the onset of psychosis in individuals at-risk is based on robust prognostic model building methods including a priori clinical knowledge (also termed clinical-learning) to preselect predictors or machine-learning methods to select predictors automatically. To date, there is no empirical research comparing the prognostic accuracy of these two methods for the prediction of psychosis onset. In a first experiment, no improved performance was observed when machine-learning methods (LASSO and RIDGE) were appliedâ€”using the same predictorsâ€”to an individualised, transdiagnostic, clinically based, risk calculator previously developed on the basis of clinical-learning (predictors: age, gender, age by gender, ethnicity, ICD-10 diagnostic spectrum), and externally validated twice. In a second experiment, two refined versions of the published model which expanded the granularity of the ICD-10 diagnosis were introduced: ICD-10 diagnostic categories and ICD-10 diagnostic subdivisions. Although these refined versions showed an increase in apparent performance, their external performance was similar to the original model. In a third experiment, the three refined models were analysed under machine-learning and clinical-learning with a variable event per variable ratio (EPV). The best performing model under low EPVs was obtained through machine-learning approaches. The development of prognostic models on the basis of a priori clinical knowledge, large samples and adequate events per variable is a robust clinical prediction method to forecast psychosis onset in patients at-risk, and is comparable to machine-learning methods, which are more difficult to interpret and implement. Machine-learning methods should be preferred for high dimensional data when no a priori knowledge is available.",2019,Translational Psychiatry
Non-convex Global Minimization and False Discovery Rate Control for the TREX,"The TREX is a recently introduced method for performing sparse high-dimensional regression. Despite its statistical promise as an alternative to the lasso, square-root lasso, and scaled lasso, the TREX is computationally challenging in that it requires solving a non-convex optimization problem. This paper shows a remarkable result: despite the non-convexity of the TREX problem, there exists a polynomial-time algorithm that is guaranteed to find the global minimum. This result adds the TREX to a very short list of non-convex optimization problems that can be globally optimized (principal components analysis being a famous example). After deriving and developing this new approach, we demonstrate that (i) the ability of the preexisting TREX heuristic to reach the global minimum is strongly dependent on the difficulty of the underlying statistical problem, (ii) the new polynomial-time algorithm for TREX permits a novel variable ranking and selection scheme, (iii) this scheme can be incorporated into a rule that controls the false discovery rate (FDR) of included features in the model. To achieve this last aim, we provide an extension of the results of Barber & Candes (2015) to establish that the knockoff filter framework can be applied to the TREX. This investigation thus provides both a rare case study of a heuristic for non-convex optimization and a novel way of exploiting non-convexity for statistical inference.",2016,ArXiv
Model Selection via Minimum Description Length,"The minimum description length (MDL) principle originated from data compression literature and has been considered for deriving statistical model selection procedures. Most existing methods utilizing the MDL principle focus on models consisting of independent data, particularly in the context of linear regression. The data considered in this thesis are in the form of repeated measurements, and the exploration of MDL principle begins with classical linear mixed-effects models. We distinct two kinds of research focuses: one concerns the population parameters and the other concerns the cluster/subject parameters. When the research interest is on the population level, we propose a class of MDL procedures which incorporate the dependence structure within individual or cluster with data-adaptive penalties and enjoy the advantages of Bayesian information criteria. When the number of covariates is large, the penalty term is adjusted by data-adaptive structure to diminish the under selection issue in BIC and try to mimic the behaviour of AIC. Theoretical justifications are provided from both data compression and statistical perspectives. Extensions to categorical response modelled by generalized estimating equations and functional data modelled by functional principle components are illustrated. When the interest is on the cluster level, we use group LASSO to set up a class of candidate models. Then we derive a MDL criterion for this LASSO technique in a group manner to selection the final model via the tuning parameters. Extensive numerical experiments are conducted to demonstrate the usefulness of the proposed MDL procedures on both population level and cluster level.",2012,
Clinical investigation of pulmonary vein potential in subjects without atrial fibrillation.,"Objective To study the characteristics of pulmonary vein potential(PVP) in subjects without atrial fibrillation(AF). Methods Patients undergoing transeptal radiofrequency catheter ablation(RFCA) for left atrioventricular reentrant tachycardia were selected to study. After successful RFCA procedure,Selective pulmonary vein (PV) venography through 8F-Swartz catheter allowed placement of an appropriate-size decapolar-performed circular catheter(Lasso) in the PVs, Bipolar electrogrames of PVs were recorded on a multichannel polygraphy with surface ECG,coronary-vena sinus atrial electrogrames. Result Forty-nine PVs were examed, whose PVPs were mono-morphogeny,regular electric-activity,order of PVP and A(far-field atrial potential) was variable,and most PVPs were slower than atrial potential in coronary sinus. Conclusion PVP can be recorded in every subjects without AF.",2007,The Chinese Journal of Cardiac Pacing and Electrophysiology
Multiple Changepoint Estimation in High-Dimensional Gaussian Graphical Models,"We consider the consistency properties of a regularised estimator for the simultaneous identification of both changepoints and graphical dependency structure in multivariate time-series. Traditionally, estimation of Gaussian Graphical Models (GGM) is performed in an i.i.d setting. More recently, such models have been extended to allow for changes in the distribution, but only where changepoints are known a-priori. In this work, we study the Group-Fused Graphical Lasso (GFGL) which penalises partial-correlations with an L1 penalty while simultaneously inducing block-wise smoothness over time to detect multiple changepoints. We present a proof of consistency for the estimator, both in terms of changepoints, and the structure of the graphical models in each segment.",2017,arXiv: Statistics Theory
Histological and ultrastructural evidence for the role of gonadal steroid hormones in sex change in the protogynous wrasse Thalassoma duperrey,"SynopsisThe process of sex change in the protogynous wrasse, Thalassoma duperrey, was investigated through histological and ultrastructural observations on the gonads of females changing sex to male. Changes in plasma steroid levels concomitant with structural changes were measured by radioimmunoassay. The process of sex change from ovary to testis was divided into six stages on the basis of changes in the structure of the germinal and somatic elements. Ovaries of females were filled with vitellogenic oocytes during the breeding season, but contained no spermatogenic tissue (Stage 1). At the commencement of sex change (Stage 2), vitellogenic oocytes began to degenerate, and were ingested by macrophagous cells. This stage was accompanied by a rapid drop in plasma levels of estradiol-17Î². Thereafter, previtellogenic oocytes (Stage 3) also began to degenerate, and aggregations of stromal tissue, and loose connective tissue were observed in the central region of the lamellae. Steroid producing cells (Leydig cells), developed at the border of this loose connective tissue. Presumed spermatogonia proliferated on the periphery of the lamellae, and Leydig cells increased in size and number (Stage 4). Spermatogonia formed cysts, and underwent spermatogenesis (Stage 5). Finally, sex change to male was considered complete, with the beginning of active spermatogenesis and spermiation (Stage 6). Plasma levels of testosterone remained low throughout the sex change, but a second androgen, 11-ketotestosterone increased gradually in parallel to the increased numbers of Leydig cells and spermatogonia. Preliminary in vitro incubation of gonads with salmon gonadotropin, revealed that sex-changed males had higher levels of 11-ketotestosterone production than did females, while females had higher levels of estradiol-17Î² production than did males. Production of both these steroids increased in a dose-related fashion with increasing doses of gonadotropin.",2004,Environmental Biology of Fishes
On Fundamental Limits of Joint Sparse Support Recovery Using Certain Correlation Priors,"This paper provides new probabilistic guarantees for recovering the common support of jointly sparse vectors in multiple measurement vector (MMV) models. In recent times, Bayesian approaches for sparse signal recovery (such as sparse Bayesian learning and correlation-aware LASSO) have shown preliminary evidence that under appropriate conditions (such as access to ideal covariance matrix of the measurements or certain restrictive orthogonality condition on the signals), it is possible to recover supports of size (<inline-formula><tex-math notation=""LaTeX"">$K$ </tex-math></inline-formula>) larger than the dimension (<inline-formula><tex-math notation=""LaTeX"">$M$</tex-math> </inline-formula>) of each measurement vector. However, no results exist that characterize the probability with which this can be achieved for a finite number of measurement vectors (<inline-formula><tex-math notation=""LaTeX"">$L$ </tex-math></inline-formula>). This paper bridges this gap by formulating the support recovery problem in terms of a multiple hypothesis testing framework. Chernoff-type upper bounds on the probability of error are established, and new sufficient conditions are derived that guarantee its exponential decay with respect to <inline-formula> <tex-math notation=""LaTeX"">$L$</tex-math></inline-formula> even when <inline-formula><tex-math notation=""LaTeX""> $K=O(M^2)$</tex-math></inline-formula>. Our sufficient conditions are based on the properties of the so-called Khatriâ€“Rao product of the measurement matrix and reveal the importance of a sampler design. Negative results are also established indicating that when <inline-formula><tex-math notation=""LaTeX"">$K$</tex-math></inline-formula> exceeds a certain threshold (in terms of <inline-formula><tex-math notation=""LaTeX"">$M$</tex-math></inline-formula>), there will exist a class of measurement matrices for which any support recovery algorithm will fail. Using results from the geometric probability, we characterize the probability with which a randomly generated measurement matrix will belong to this class and show that this probability tends to 1 asymptotically in the size (<inline-formula> <tex-math notation=""LaTeX"">$N$</tex-math></inline-formula>) of the sparse vectors.",2018,IEEE Transactions on Signal Processing
Collaborative and Privacy-Preserving Machine Teaching via Consensus Optimization,"In this work, we define a collaborative and privacy-preserving machine teaching paradigm with multiple distributed teachers. We focus on consensus super teaching. It aims at organizing distributed teachers to jointly select a compact while informative training subset from data hosted by the teachers to make a learner learn better. The challenges arise from three perspectives. First, the state-of-the-art pool-based super teaching method applies mixed-integer non-linear programming (MINLP) which does not scale well to very large data sets. Second, it is desirable to restrict data access of the teachers to only their own data during the collaboration stage to mitigate privacy leaks. Finally, the teaching collaboration should be communication-efficient since large communication overheads can cause synchronization delays between teachers.To address these challenges, we formulate the collaborative teaching as a consensus and privacy-preserving optimization process to minimize teaching risk. We theoretically demonstrate the necessity of collaboration between teachers for improving the learnerâ€™s learning. Furthermore, we show that the proposed method enjoys a similar property as the Oracle property of adaptive Lasso. Empirical study illustrates that our teaching method can deliver significantly more accurate teaching results with high speed, while the non-collaborative MINLP-based super teaching becomes prohibitively expensive to compute.",2019,2019 International Joint Conference on Neural Networks (IJCNN)
Assessing Prior Pain Visits and Medical History Risk Factors for Opioid Overdose,"Objective:Â  Identifying text features of emergency department visits associated with risk of future drug overdose. Introduction:Â  Opioid overdoses are a growing cause of mortality in the United States. 1 Â Medical prescriptions for opioids are a risk factor for overdose 2 . This observation raises concerns that patients may seek multiple opioid prescriptions, possibly increasing their overdose risk. One route for obtaining those prescriptions is visiting the emergency department (ED) for pain-related complaints. Here, two hypotheses related to prescription seeking and overdoses are tested. (1) Overdose patients have a larger number of prior ED visits than matched controls. (2) Overdose patients have distinct patterns of pain-related complaints compared to matched controls. Methods:Â  ED registrations were collected via the EpiCenter syndromic surveillance system. Regular expression searches on chief complaints identified overdose visits. Overdose visits were matched with control visits from the same facility with maximal similarity of gender, age, home location and arrival time. A year of prior ED visits for cases and controls were matched using facility-specific patient identifiers or birthdate, gender and home location. Patient history chief complaints were sanitized to standardize spelling, expand abbreviations and consolidate phrases. Word frequency comparisons between groups identified candidate terms for modeling. Odds ratios of patient history terms were calculated with univariate logistic regression. Multivariate lasso logistic regression selected covariates for prediction. These models were fit to data from one quarter and cutoffs for covariate inclusion were validated on the following quarterâ€™s data. Model predictions were validated on a 1% sample of ED registrations from the next quarter. Results:Â  Quarter three of 2016 yielded 23,769 overdose ED visits and matching controls; quarter four yielded 21,957 pairs; and 15,824 ED visits were sampled from the first quarter of 2017 including 130 overdose visits. Contrary to expectations, patients in the control group averaged 0.7 additional ED visits in the prior year relative to controls; this pattern was consistent across quarters and regardless of how prior visits were matched (Fig 1). Prior visits for various pain categories were also more common among control patients than overdose patients (e.g. odds ratio for â€œback painâ€: 0.78). Terms associated with drug use (e.g. â€œdetoxâ€ odds ratio: 2.66) and mental health concerns (e.g. â€œpsychologicalâ€ odds ratio: 4.28) were most consistently overrepresented in the history of overdose patients (Table 1). Terms associated with chronic disease were most overrepresented in the history of control patients (Table 2). The best predictive model achieved a sensitivity of 57% and a specificity of 86% on test data (Fig 2). Conclusions:Â  While a history of more overall ED visits and more ED visits related to pain were not associated with overdose ED visits, vocabulary of prior ED visits did predict future overdose ED visits. Performance of predictive models exceeded expectations, given the relative scarcity of overdoses among ED visits and the simplicity of chief complaints used for prediction. The correlation between past and future overdose visits highlights the need for targeted intervention to break addiction cycles.",2018,Online Journal of Public Health Informatics
A serum microRNA signature predicts trastuzumab benefit in HER2-positive metastatic breast cancer patients,"Trastuzumab is a standard treatment for HER2-positive (HER2+) breast cancer, but some patients are refractory to the therapy. MicroRNAs (miRNAs) have been used to predict therapeutic effects for various cancers, but whether miRNAs can serve as biomarkers for HER2+ metastatic breast cancer (MBC) patients remains unclear. Using miRNA microarray, we identify 13 differentially expressed miRNAs in the serum of HER2+ MBC patients with distinct response to trastuzumab, and four miRNAs are selected to construct a signature to predict survival using LASSO model. Further, our data show that miR-940 is mainly released from the tumor cells and miR-451a, miR-16-5p and miR-17-3p are mainly from the immune cells. All these four miRNAs directly target signaling molecules that play crucial roles in regulating trastuzumab resistance. In summary, we develop a serum-based miRNA signature that potentially predicts the therapeutic benefit of trastuzumab for HER2+ MBC patients and warrants future validation in prospective clinical trials.Resistance to therapy is a significant issue for patients with metastatic breast cancer (MBC). Here the authors analyze total miRNA from serum samples of 386 MBC patients before treatment with a follow up of 31 months and define a four miRNA signature that predicts the therapeutic benefit of trastuzumab.",2018,Nature Communications
Susceptibility of Anopheles gambiae to insecticides in CÃ´te-dâ€™Ivoire,Studies on the susceptibility of Anopheles gambiae to insecticides were carried out in rice field areas of Cote-dâ€™Ivoire. An. gambiae larvae populations from Cote-dâ€™Ivoire were resistant to DDT but susceptible to organophosphorous insecticides. Adult populations from the surroundings of Bouake were resistant to DDT and permethrin. Resistance to propoxur was strongly suspected. The knock-down effect of both deltamethrin and lambdacyhalothrin was delayed and strongly decreased. The control strain from Bobo-Dioulasso and populations from rice fields of Katiola located far from the city were still susceptible to the three pyrethroids. It is likely that resistance to pyrethroids in Bouake has been promoted by the intensive use of domestic aerosol sprays.,1994,
Multimodal classification of prostate tissue: a feasibility study on combining multiparametric MRI and ultrasound,"The common practice for biopsy guidance is through transrectal ultrasound, with the fusion of ultrasound and MRI-based targets when available. However, ultrasound is only used as a guidance modality in MR-targeted ultrasound-guided biopsy, even though previous work has shown the potential utility of ultrasound, particularly ultrasound vibro-elastography, as a tissue typing approach. We argue that multiparametric ultrasound, which includes B-mode and vibro-elastography images, could contain information that is not captured using multiparametric MRI (mpMRI) and therefore play a role in refining the biopsy and treatment strategies. In this work, we combine mpMRI with multiparametric ultrasound features from registered tissue areas to examine the potential improvement in cancer detection. All the images were acquired prior to radical prostatectomy and cancer detection was validated based on 36 whole mount histology slides. We calculated a set of 24 texture features from vibro-elastography and B-mode images, and five features from mpMRI. Then we used recursive feature elimination (RFE) and sparse regression through LASSO to find an optimal set of features to be used for tissue classification. We show that the set of these selected features increases the area under ROC curve from 0.87 with mpMRI alone to 0.94 with the selected mpMRI and multiparametric ultrasound features, when used with support vector machine classification on features extracted from peripheral zone. For features extracted from the whole-gland, the area under the curve was 0.75 and 0.82 for mpMRI and mpMRI along with ultrasound, respectively. These preliminary results provide evidence that ultrasound and ultrasound vibro-elastography could be used as modalities for improved cancer detection in combination with MRI.",2015,
Successful release of an entrapped circular mapping catheter using a snare and a multidisciplinary approach.,"A 44-year-old attended for pulmonary vein isolation procedure as treatment for highly symptomatic, paroxysmal atrial fibrillation. SLO sheaths (St Jude Medical, USA) were used to facilitate introduction of a 3.5-mm irrigated tip ablation catheter and a 15-mm circular mapping catheter (LassoÂ®, Biosense Webster, USA) into the left atrium via trans-septal access. Geometry for a non-contact mapping system was collected using the circular mapping catheter. During manipulation of the catheter, it became entangled in the mitral valve apparatus (Fig. 1). Following a number of unsuccessful manoeuvres to free the catheter including gentle clockwise or anticlockwise rotation whilst either advancing or withdrawing the catheter, performing the same motions with the sheath advanced to the fixed portion of the catheter, and trying to free the catheter using a pigtail catheter introduced retrograde via the femoral artery (Fig. 1D), we sought assistance from an Interventional Radiology colleague. Our hypothesis from fluoroscopic and echocardiographic imaging was that a pair of chordae had entwined the point of intersection of the catheter in opposite directions, thus fixing it and preventing release by rotation in either direction. The distal tip of the circular mapping catheter was captured using a snare (9â€“15 mm EN SnareTM Endovascular Snare System, Merit Medical, USA) delivered through a trans-septal AgilisTM steerable sheath (St. Jude Medical, USA), positioned in place of the free SLO. By combining the experience of the radiologist in utilising snare devices and the detailed cardiac anatomical knowledge and catheter manipulation skills of the electrophysiologist, we were able to fix the distal tip of the mapping catheter and provide counter traction as it was rotated, thus facilitating its safe release from the mitral valve apparatus (Fig. 2). Transthoracic echocardiography directly after catheter release and at 4 weeks post procedure demonstrated no significant mitral regurgitation. The patient has since undergone successful pulmonary vein isolation without incident. The rotational techniques of manipulation and the shape of a circular mapping catheter are such that it is now well established that it can entangle in the mitral valve apparatus and become trapped. Measures to prevent this complication include using only clockwise rotation of the catheter (Fig. 3) and deliberate manipulation of the catheter along the posterior rather than anterior aspect of the left atrium. Specific features that may contribute to the tendency include the bulbous distal tip and the inherent â€œshape memoryâ€ from the Nitinol composition of the catheter. The incidence of entrapment as a complication is not well understood; some publications place it as high as 0.9% [Kesek M et al. Heart Rhythm, 2007; 4: 17â€“91]. Reported consequences of the phenomenon include surgical extraction of the catheter [Grove R et al. Clin Res Cardiol, 2008; 97: 628â€“629], severe damage to the valve requiring surgical repair during percutaneous removal of the catheter, and a small number of reports of techniques used to affect safe, percutaneous release of the device. Ours is the first to document the successful use of a snare to facilitate catheter release. We believe that co-operation between the 2 interventional specialists was a major component of the safe release of the instrument.",2015,Kardiologia polska
High-density circumferential pulmonary vein mapping with a 20-pole expandable circular mapping catheter.,"The differentiation of pulmonary vein (PV) electrograms from atrial far-field signals during PV isolation (PVI) for atrial fibrillation (AF) may be difficult. In addition, owing to highly variable PV ostial sizes, current fixed-diameter circular PV mapping catheters may not yield optimal electrograms. We evaluated an expandable, circular 15-25 mm diameter, 20-pole mapping catheter for PV mapping during sustained AF in 25 patients. After selective PV angiography to define the ostial position and size, the catheter was introduced into each PV and withdrawn to the most stable proximal position, with optimal wall contact ensured by progressive loop expansion. At each PV ostium, electrograms recorded at high resolution (HR) were compared with those recorded at a resolution similar to that of a standard 10-pole Lasso catheter. After PVI performed during ongoing AF, the presence of residual far-field potentials (FFP) under both set-ups was compared. We mapped 97 PV, including 4 pairs with common ostia. In the HR recordings, the PV potentials had greater amplitude (0.5 +/- 0.1 vs 0.3 +/- 0.1 mV, P = 0.001) and fragmentation, whereas left atrial FFP were minimized. After successful isolation of all PV, FFP were observed in 33% of left superior and 28% of left inferior PV on the HR recordings, compared to 66% and 61%, respectively under normal resolution. Catheter stability and optimal wall contact, in combination with HR electrograms can optimize circumferential PV mapping during AF and improve the discrimination of FFP postablation.",2005,Pacing and clinical electrophysiology : PACE
Multiple Kernel Fusion with HSIC Lasso,"Multiple kernel learning (MKL) is a principled way for kernel fusion for various learning tasks, such as classification, clustering and dimensionality reduction. In this paper, we develop a novel multiple kernel learning model based on the Hilbert-Schmidt independence criterion (HSIC) for classification (called HSIC-MKL). In the proposed HSIC-MKL model, we first propose a HSIC Lasso-based MKL formulation, which not only has a clear statistical interpretation that minimum redundant kernels with maximum dependence on output labels are found and combined, but also the global optimal solution can be computed efficiently by solving a Lasso optimization problem. After the optimal kernel is obtained, the support vector machine (SVM) is used to select the prediction hypothesis. It is evident that the proposed HSIC-MKL is a two-stage kernel learning approach. Extensive experiments on real-world data sets from UCI benchmark repository validate the superiority of the proposed model in terms of prediction accuracy.",2018,
Unsupervised Interpretable Pattern Discovery in Time Series Using Autoencoders,"We study the use of feed-forward convolutional neural networks for the unsupervised problem of mining recurrent temporal patterns mixed in multivariate time series. Traditional convolutional autoencoders lack interpretability for two main reasons: the number of patterns corresponds to the manually-fixed number of convolution filters, and the patterns are often redundant and correlated. To recover clean patterns, we introduce different elements in the architecture, including an adaptive rectified linear unit function that improves patterns interpretability, and a group-lasso regularizer that helps automatically finding the relevant number of patterns. We illustrate the necessity of these elements on synthetic data and real data in the context of activity mining in videos.",2016,
Secrecy and Betrayal: On Kafka and Welles,"IN A REVIEW OF MAX BRODâ€™S BIOGRAPHY OF KAFKA (1937), WHICH REMAINED unpublished because of Brodâ€™s virtually unchallenged authority at the time as trustee of a work he had no less than saved and discovered to the world, Walter Benjamin denounced immediately its limits: on the one hand, it presents itself unabashedly as hagiography; on the other, it betrays an intimacy that is incompatible with the alleged holiness of its subject (Benjamin 1972, 526â€“29). Brod has remained a target of choice for many later Kafka interpreters, up to the merciless indictment of Milan Kunderaâ€™s Testaments Betrayed (1996), but he could at least boast of a friendship that, as Benjamin aptly remarks, remains one of the great â€œenigmasâ€ (RÃ¤tsel) of Kafkaâ€™s life (Benjamin 1972, 529). In the case of a book such as Roberto Calassoâ€™sK., however, which I",2012,CR: The New Centennial Review
Biomarkers Can Identify Pulmonary Tuberculosis in HIV-infected Drug Users Months Prior to Clinical Diagnosis,"BACKGROUND
Current diagnostic tests cannot identify which infected individuals are at risk for progression to tuberculosis (TB). Our aim was to identify biomarkers which can predict the development of TB prior to clinical diagnosis.


METHOD
In a retrospective case-control study, RNA of 14 HIV-infected drug users obtained before TB diagnosis (cases) and of 15 who did not develop TB (controls) was analyzed for the expression of 141 genes by dcRT-MLPA followed by Lasso regression analysis.


FINDINGS
A combined analysis of IL13 and AIRE had the highest discriminatory power to identify cases up to 8Â months prior to clinical diagnosis. Cases expressing IL13 had a gene expression pattern strongly enriched for type I IFN related signaling genes, suggesting that these genes represent processes that contribute to TB pathogenesis.


INTERPRETATION
We here demonstrated that biomarkers, such as IL13-AIRE, can identify individuals that progress to TB within a high risk population, months prior to clinical diagnosis.",2015,EBioMedicine
"Business Process Re-Engineering: Information Systems Opportunities and Challenges, Proceedings of the IFIP TC8 Open Conference on Business Re-engineering: Information Systems Opportunities and Challenges, Queensland Gold Cost, Australia, 8-11 May, 1994","Opening address - business process re-engineering - information systems opportunity or challenge?, B. Glasson widening our views of information systems development, M. Lundeberg reengineering the role of IS professionals, N. Bjorn-Andersen and A. Cavaye I/S challenges and opportunities - DSS and EDM, R. Sprague re-engineering towards the meeting of the future, D. Vogel a revisionist view of re-engineering, J. King panel introduction - from re-equipment to people architecture - the modernization of the Australian taxation office, B. Wilson et al panel introduction - the FRISCO announcement and its analysis, E.D. Falkenberg and R.K. Stamper a methodology for business process re-engineering?, G. Simsion a new second information systems course - personal productivity with information technology, G.B. Davis and J.D. Naumann the challenge of transferring software and information technology, P.J. Fowler panel introduction - improving the quality of IS research - key issues for debate, E. Jordan relevance and rigour in information systems research - some personal reflections on issues facing the information systems research community, R.D. Galliers closing address - false prophecies, successful practice and future directions in IT management, P.W. Yetton.",1994,
Split regression modeling,"In this note we study the benefits of splitting variables variables for reducing the variance of linear functions of the regression coefficient estimate. We show that splitting combined with shrinkage can result in estimators with smaller mean squared error compared to popular shrinkage estimators such as Lasso, ridge regression and garrote.",2018,arXiv: Methodology
Breast cancer diagnostics in daily practice: the place of PAMMOTH,"With incidence numbers still rising, breast cancer is the leading cancer diagnosis in women worldwide. Therefore, early detection and precise diagnosis of breast cancer is an important factor contributing to accurate therapy and better survival chances. The goal of this study is to outline the hospital-based diagnostic care pathway of patients with suspected breast cancer in the Netherlands and to identify features which influence the diagnostic pathway. Two different databases have been analysed; one â€™benignâ€™ database containing approximately 31,000 patients with suspected breast cancer, and one â€™malignantâ€™ database containing approximately 2,200 diagnosed breast cancer pa- tients. Information in the malignant database originates from the Netherlands Cancer Registry (NCR) and hospital-based financial data, accommodated by Performation. Information in the benign database was based on financial data only. Both databases have been carefully evaluated to reveal variation between and patterns within the diagnostic care pathways. In- fluencing features on the diagnosis of breast cancer, days until diagnosis and number of diagnostic care activities have been identified in the malignant diagnostic care pathway, using the Lasso method and cross-validation together with Cox and Poisson regression models.",2018,
Lasso for holding and positioning rectal,"The invention relates to a lasso for holding and positioning the rectal. The lasso is characterized in that the lasso comprises a casing (3) and a handle (1), a connection rope (4) is arranged inside the casing, the connection rope (4) penetrates through the casing (3), and one end of the connection rope (4) is connected with a hook. The lasso for holding and positioning the recta has the advantages that the structure is simple, operation is convenient, positioning is precise, and use is convenient when a doctor does an operation while injury to the intestinal canal in operation is reduced.",2014,
An efficient stochastic approach for flow in porous media via sparse polynomial chaos expansion constructed by feature selection,"Abstract An efficient method for uncertainty quantification for flow in porous media is studied in this paper, where response surface of sparse polynomial chaos expansion (PCE) is constructed with the aid of feature selection method. The number of basis functions in PCE grows exponentially as the random dimensionality increases, which makes the computational cost unaffordable in high-dimensional problems. In this study, a feature selection method is introduced to select major stochastic features for the PCE by running a limited number of simulations, and the resultant PCE is termed as sparse PCE. Specifically, the least absolute shrinkage and selection operator modified least angle regression algorithm (LASSO-LAR) is applied for feature selection and the selected features are assessed by cross-validation (CV). Besides, inherited samples are utilized to make the algorithm self-adaptive. In this study, we test the performance of sparse PCE for uncertainty quantification for flow in heterogeneous media with different spatial variability. The statistical moments and probability density function of the output random field are accurately estimated through the sparse PCE, meanwhile the computational efforts are greatly reduced compared to the Monte Carlo method.",2017,Advances in Water Resources
Sexual and reproductive life of women informed of their HIV seropositivity: a prospective cohort study in Burkina Faso.,"BACKGROUND
In the context of the DITRAME-ANRS 049 research program that evaluated interventions aimed at reducing mother-to-child transmission of HIV (MTCT) in Bobo-Dioulasso (Burkina Faso), Voluntary HIV counseling and testing (VCT) services were established for pregnant women. HIV-infected women were advised to disclose their HIV serostatus to their male partners who were also offered VCT, to use condoms to reduce sexual transmission, and to choose an effective contraception method to avoid unwanted pregnancies. This study aimed at assessing how HIV test results were shared with male sexual partners, the level of use of modern contraceptive methods, and the pregnancy incidence among these women informed of the risks surrounding sexual and reproductive health during HIV infection.


METHODS
From 1995 to 1999, a quarterly prospective follow-up of a cohort of HIV-positive women.


RESULTS
Overall, 306 HIV-positive women were monitored over an average period of 13.5 months following childbirth, accounting for a total of 389 person-years. The mean age at enrollment in the cohort was 25.1 (standard deviation, 5.2 years). In all, 18% of women informed their partners, 8% used condoms at each instance of sexual intercourse to avoid HIV transmission, and 39% started using hormonal contraception. A total of 48 pregnancies occurred after HIV infection was diagnosed, an incidence of 12.3 pregnancies per 100 person-years. Pregnancy incidence was 4 per 100 person-years in the first year of monitoring and this rose significantly to 18 per 100 person-years in the third year. The only predictor of the occurrence of a pregnancy after HIV diagnosis was the poor outcome of the previous pregnancy (stillbirth, infant death). Severe immunodeficiency and change in marital status were the only factors that prevented the occurrence of a pregnancy after HIV diagnosis.


CONCLUSION
Our study shows a poor rate of HIV test sharing and a poor use of contraceptive methods despite regular advice and counseling. Pregnancy incidence remained comparable with the pregnancy rate in the general population. To improve this situation, approaches for involving husbands or partners in VCT and prevention of MTCT interventions should be developed, evaluated, and implemented.",2001,Journal of acquired immune deficiency syndromes
The Python's Back: Pathways of Comparison Between Indonesia and Melanesia (review),"The Python's Back: Pathways of Comaprison Between Indonesia and Melanesia Andrew Strathern and Pamela J. Stewart. 2000 London and Westport. Conn: Bergin and Garvey. 174 pages. The Python's Back is an intriguing exercise in comparative analysis, an enterprise that recently has fallen into some disrepute. But this book proves there is still much to be learned from such an enterprise, especially when geographic proximity establishes certain shared cultural features (a focus on relations of exchange, debt and the animal world) but historical and political differences have placed societies in distinct ""regional systems"" where their features are rarely juxtaposed. The comparison is restricted to the highlands of Papua New Guinea (where both Strathern and Stewart have conducted research), the Bird's Head area of Irian Jaya, and the cluster of Eastern Indonesian islands which extend westwards to Sumba, but no further. It therefore excludes the better known parts of Indonesia (Java, Bali, Sumatra, etc.) which have been heavily penetrated by a Hindu-Buddhist legacy and an Islamic present, but it provides many thought provoking insights into the ""Melanesian"" aspects of the eastern islands. The approach is ""thematic"", focusing on topics such as slavery, personhood, kinship and commoditization, the spirit world, witchcraft, and the representation of particular animal motifs (cassowaries, pythons, etc.). The first exploration is among the most interesting. in this section, the authors struggle with the ethnographic fact that although debt is an important concept in both Eastern Indonesia and Melanesia, slavery is virtually absent from the Melanesian scene, but an important component of many Eastern Indonesian societies. They argue that ""slavery represents a gradation of relationships of bondage tied to the commoditization, but also the decommoditization, of the person, and feeding into the categories of gift and sacrifice"" (p. 128). The shift from prescribed forms of marriage to more open ones has, they argue, led to the potential for ""a marriage market that is analytically comparable to the flow of commoditized persons under the rubric of slavery"" (p.128). The ""analytical analogy"" they establish between the circuits of marriage and of slavery is established through an examination of data from the Bird's Head of Irian Jaya where adoption was used as rubric under which to commoditize persons. This area does indeed seem to ""mediate"" in many fascinating ways between the more hierarchical eastern Indonesia societies of Sumba and Tanimbar and the more egalitarian New Guinea highlands. Strathern and Stewart suggest a model of fixity and flow for examining the relationship between slavery and kinship: slaves may be either fixed into kinship positions or detached from these and circulated as commoditized entities, and ""adoption mediates between fixture and flow and may facilitate either"" (p.26). This argument also addresses the long standing debates within the anthropology of slavery about whether kinship and slavery exist on a continuum (as in the work of Suzanne Miers and Igor Kopytoff) or are strictly antinomic (as in the work of Claude Meillassoux). â€¦",2002,Anthropological Quarterly
Frequentist and Bayesian Lasso Techniques for Parameter Selection in Nonlinearly Parameterized Models,"Abstract: In this paper, we discuss the use of frequentist and Bayesian lasso (least absolute shrinkage and selection operator) techniques for parameter selection in nonlinearly parameterized models employed for control design. This is necessary to isolate the subset of identifiable or influential parameters, which can be uniquely calibrated from experimental data. We survey the performance of existing algorithms and present a new Bayesian lasso implementation based on the Delayed Rejection Adaptive Metropolis (DRAM) algorithm.",2016,IFAC-PapersOnLine
Survival prediction for patients with lung adenocarcinoma: A prognostic risk model based on gene mutations.,"BACKGROUND
Lung adenocarcinoma is the most common type of lung cancer, and it is one of the most aggressive and rapidly fatal tumor types.


OBJECTIVE
To identify a signature mutation genes for prognostic prediction of lung adenocarcinoma.


METHODS
Four hundred and sixty-two lung adenocarcinoma cases were screened out and downloaded from TCGA database. Mutation data of 18 targeted genes were detected by MuTect. LASSO-COX model was used to screen gene loci, and then a prognosis model was established. Afterwards, 40 clinical patients of lung adenocarcinoma were collected to verify the mutation features and the predictive function of the above prognostic model. The mutations of above 18 genes were sequenced with targeted next generation sequencing (NGS) and analyzed with GATK and MuTect.


RESULTS
TP53 (282, 32.38%), NF1 (82, 9.41%) and EGFR (80, 9.18%) were the top 3 most frequent mutation genes. A total of 7 variables were screened out after lasso-COX analysis (tumor stage, age, diagnostic type, SMARCA4, GNAS, PTCH2, TSC2). SMARCA4, GNAS and TSC2 were a gene mutation signature to predict a poor prognosis.


CONCLUSIONS
We established a prognostic model for lung adenocarcinoma, and further concluded that SMARCA4, GNAS and TSC2 were a gene signature which plays a prognostic role.",2020,Cancer biomarkers : section A of Disease markers
Orbiting Resonances and Bound States in Molecular Scattering,"AbstractA family of orbiting resonances in molecular scattering is globally described by using asingle pole moving in the complex angular momentum plane. The extrapolation of this poleat negative energies gives the location of the bound states. Then a single pole trajectory, thatconnects a rotational band of bound states and orbiting resonances, is obtained. These complexangular momentum singularities are derived through a geometrical theory of the orbiting. Thedownward crossing of the phaseâ€“shifts through Ï€/2, due to the repulsive region of the molecularpotential, is estimated by using a simple hardâ€“core model. Some remarks about the diï¬€erencebetween diï¬€racted rays and orbiting are also given. 1 Introduction After a long search, about two decades ago it became possible to observe orbiting resonances (orquasiâ€“bound states) in molecular beam scattering [1, 2, 3, 4, 5]. Although these phenomena canbe quite naturally interpreted in the framework of scattering theory [6], their semiclassical naturecalls for a more reï¬ned analysis, mainly geometrical, which has been partially performed by severalauthors, and notably by Berry [7, 8, 9]. In this spirit, it has been also advocated the use of thecomplex angular momentum plane polology, especially by Bosanac [10, 11, 12], Connor [13, 14]and Nussenzveig (see in particular his book [15] and the references quoted therein). In the latterapproach, however, some problems remain, and a detailed phenomenological analysis is in part stillmissing.In the standard complex angular momentum approach one generally considers a given classof potentials, and then explores the analytical properties of the partialâ€“waves along with theirasymptotic behaviour in the complex angular momentum plane. If these analytical properties and1",2002,Physical Review A
Female Taboos and the Nenets System of Concepts of the Unclean,"In Nenets culture, as in most others, womenÂ’s behaviour is closely regulated by a system of prohibitions. Thus it is forbidden for a woman to step over tools, or equipment used in reindeer-breeding, reindeer harnesses, and lassos for catching reindeer, nor may she step over men or children. If she comes across bear tracks on the road, she may not cross them, but she must efface the tracks from the road; only then may she continue on her way. A woman may not take part in sacrifices, and she may not visit sacred sites. She is forbidden to cut through the spine of certain kinds of fish. Ethnographers have repeatedly pointed out the existence of these regulations in their works, see e.g. [Lekhtisalo 1998: 90Â–1; Kostikov 1930: 40Â–1; Verbov 1937, Khomich 1966: 185Â–6; Khomich 1995: 195Â–6; Khomich 1988: 75; Golovnev 1995: 212Â–9; Atsusi 1997: 177Â–9; Kharyuchi 2001: 155Â–8]. Indeed, commentators invariably noted these rules straight away, as women were sometimes so obviously inconvenienced by observing them: Â‘More than once we happened to notice how a woman leading an anas (a convoy of sleighs) had to mend a harness that had Elena Lyarskaya",2006,
Optimization of an H0 photonic crystal nanocavity using machine learning,"Using machine learning, we optimized an ultrasmall photonic crystal nanocavity to attain a high $Q$Q. Training data were collected via finite-difference time-domain simulation for models with randomly shifted holes, and a fully connected neural network (NN) was trained, resulting in a coefficient of determination between predicted and calculated values of 0.977. By repeating NN training and optimization of the $Q$Q value on the trained NN, the $Q$Q was roughly improved by a factor of 10â€“20 for various situations. Assuming a 180-nm-thick semiconductor slab at a wavelength approximately 1550 nm, we obtained $Q={1},\!{011},\!{400}$Q=1,011,400 in air; 283,200 in a solution, which was suitable for biosensing; and 44,600 with a nanoslot for high sensitivity. Important hole positions were also identified using the linear Lasso regression algorithm.",2020,Optics Letters
A model for predicting overall survival in men with metastatic castrate-resistant prostate cancer (CRPC) for whom first-line chemotherapy failed.,"24 Background: Several prognostic models for overall survival (OS) have been developed and validated in men with chemotherapy naÃ¯ve mCRPC. The primary objective was to develop and validate a prognostic model that can be used to predict OS in men who have failed first-line chemotherapy.


METHODS
Data was used from a phase III trial of 755 mCRPC men who had developed progressive disease following first-line chemotherapy and were randomized to cabazitaxel plus prednisone or mitoxantrone plus prednisone (TROPIC trial). The data was randomly split into training (n=507) and testing (n=248) sets. A separate data, consisting of 488 men previously treated with docetaxel who were randomly assigned to either satraplatin and prednisone or placebo and prednisone, was used as the validation set (SPARC trial). Penalized regression method was used to identify important prognostic factors. Adaptive Lasso selected nine variables of OS. A predictive score was computed from the estimated regression coefficients and used to classify patients into low (<-1.29) and high (>= -1.29) risk groups in the testing datasets. The model was assessed for its predictive accuracy using time dependent area under the curve (AUC) on the testing sets (TROPIC and SPARC trials).


RESULTS
The final selected model included: ECOG performance status, time since last docetaxel use, measurable disease, presence of visceral disease, pain, duration of prior hormonal use, hemoglobin, prostate specific antigen and alkaline phosphatase. In the TROPIC testing set, the median OS in high and low risk groups were 11 and 17 months, respectively, with a hazard ratio (HR)=2.47 (p-value<0.0001). Using the SPARC set, the median OS were 11 and 20 months in the high and low risk groups, respectively, with a HR=1.94 (p<0.0001). The time dependent AUC were 0.73 and 0.70 on the testing sets.


CONCLUSIONS
A prognostic model of OS in the post-docetaxel mCRPC setting was developed and validated and risk groups were identified. This model can be used to select patients based on their prognosis to participate in clinical trials. Prospective validation is needed.",2013,Journal of clinical oncology : official journal of the American Society of Clinical Oncology
Su18: Investigating Shrinkage Methods to Improve Accuracy of Gwas and Prs Effect Size Estimates,"Background As the scale and power of GWAS have increased to detect the small genetic effect sizes involved in complex polygenic traits, the results of GWAS, especially SNP effect size estimates, are increasingly utilised for prediction. A popular approach is the application of Polygenic Risk Scores (PRS). However, the effect size estimates are inherently prone to overfit the specific samples on which the GWAS were performed (e.g. â€œthe Winner's Curseâ€). The inflation of effect size estimation reduces the out-of-sample accuracy of prediction based on GWAS results. Many shrinkage methods have been developed to correct for such inflation. As GWAS results and large individual genotype data sets become widely available, there is greater opportunity to accurately evaluate effect size inflation and compare the performance of different shrinkage methods. Methods We develop a novel permutation-based shrinkage method and compare its performance with previously developed methods based on local false discovery rate and the LASSO. We evaluate the performance of the methods across a wide range of phenotypes and investigate different factors (e.g. phenotype heritability) that influence their impact on the predictive power of polygenic risk scores. Results Using large-scale real genotype data, we show that SNP effect sizes are markedly overfit even in relatively large samples, but that our permutation-based shrinkage approach can improve PRS prediction dramatically. Discussion Our results suggest that GWAS results can be adjusted using an efficient empirical approach to provide more accurate effect size estimates and thus greater downstream predictive power. This approach could be applied to a wide variety of big data settings.",2019,European Neuropsychopharmacology
Could thermal sensitivity of mitochondria determine species distribution in a changing climate?,"For many aquatic species, the upper thermal limit (Tmax) and the heart failure temperature (THF) are only a few degrees away from the species' current environmental temperatures. While the mechanisms mediating temperature-induced heart failure (HF) remain unresolved, energy flow and/or oxygen supply disruptions to cardiac mitochondria may be impacted by heat stress. Recent work using a New Zealand wrasse (Notolabrus celidotus) found that ATP synthesis capacity of cardiac mitochondria collapses prior to T(HF). However, whether this effect is limited to one species from one thermal habitat remains unknown. The present study confirmed that cardiac mitochondrial dysfunction contributes to heat stress-induced HF in two additional wrasses that occupy cold temperate (Notolabrus fucicola) and tropical (Thalassoma lunare) habitats. With exposure to heat stress, T. lunare had the least scope to maintain heart function with increasing temperature. Heat-exposed fish of all species showed elevated plasma succinate, and the heart mitochondria from the cold temperate N. fucicola showed decreased phosphorylation efficiencies (depressed respiratory control ratio, RCR), cytochrome c oxidase (CCO) flux and electron transport system (ETS) flux. In situ assays conducted across a range of temperatures using naive tissues showed depressed complex II (CII) and CCO capacity, limited ETS reserve capacities and lowered efficiencies of pyruvate uptake in T. lunare and N. celidotus. Notably, alterations of mitochondrial function were detectable at saturating oxygen levels, indicating that cardiac mitochondrial insufficiency can occur prior to HF without oxygen limitation. Our data support the view that species distribution may be related to the thermal limits of mitochondrial stability and function, which will be important as oceans continue to warm.",2014,The Journal of experimental biology
Abstract MP20: The Discriminatory Characteristics of Neighborhood Socioeconomic Status in Predicting Cardiovascular Disease in Electronic Health Record Based Studies Differs by Age,"Introduction: Recent studies report an association between neighborhood residence and health outcomes. There is less information on the relative utility of neighborhood socioeconomic status (nSES) in models that predict future health outcomes and the impact that age may have on this. Objective: To quantify if nSES data alone or in concert with electronic health record (EHR) data can improve risk prediction for myocardial infarction (MI) and stroke beyond current models. Methods: Neighborhood SES was derived using the AHRQ SES index. Clinical and demographic data was obtained from the EHR of patients seen at the Duke University Health System from 2009-2015; it was split into a training set (2009-2012) and testing set (2012-2015). Age (in yrs) was categorized as young (18-44), middle age (45-64), and old (â‰¥65). Logistic regression models were fit for each outcome over 6 time horizons (30, 90, & 180 days; 1, 2, & 3 years) using machine learning methods (least absolute shrinkage and selection operator [LASSO]) for model selection to determine if nSES improved discrimination, as measured by the c-statistic. Results: Of 106703 patients, 63% were female, 41% were Black, 2.6% had CVD, 12% had diabetes, and 29% had hypertension at baseline with mean age of 47 years. The majority of the correlation between EHR variables and nSES (r 2 =0.31) was explained by demographic information within the EHR (r 2 =0.29; p Conclusions: The added value of nSES was less than expected as much variability in nSES may be phenotyped through demographic information in the EHR. In discrete instances, nSES can improve risk prediction but varies by age, clinical outcome, and time horizon.",2018,Circulation
M37: Taking a Polygenic Approach to GâŽg and GâŽe Interactions in the Prediction of Mdd,"Background Major Depressive Disorder (MDD) is a complex heterogeneous disorder, with an estimated heritability of ~40%. Known environmental risk factors (e.g. neuroticism, cognition) also play an important role in the development of MDD. Despite the successful identification of many associated loci in the most recent MDD GWAS, this required a huge sample size and so these loci explain only a small fraction of the heritability, making clinical application challenging. One way of revealing greater aetiological insight, and potentially increasing disease prediction, is to detect gene-gene and gene-environment interactions. The identification of these interactions is challenging due to the huge model space involved (esp. for GâŽG). While these individual variant interactions may exist, there may also be interactions â€“ more easily identified â€“ between the overall polygenic risk of a disorder and that of other disorders or environmental risk factors. Here we aim to 1) use Polygenic Risk Scores (PRS) to identify global genetic interaction effects, and 2) build a predictive model of MDD case-control status utilizing the rich phenotypic data available in the UK Biobank. Methods To build and validate predictive models of MDD, we split the UK Biobank data into discovery GWAS, testing and validation datasets. The predictive model was developed via model selection techniques such as stepwise AIC/BIC and lasso regression, with a large number of PRSâŽPRS and PRSâŽE predictors. Results We identify several intriguing PRS interaction effects and increase out-of-sample prediction of MDD case/control status significantly via inclusion of PRS interactions.",2019,European Neuropsychopharmacology
Cardiac Radiosurgery (CyberHeartâ„¢) for Treatment of Arrhythmia: Physiologic and Histopathologic Correlation in the Porcine Model,"Objectives: This porcine pre-clinical investigation sought to demonstrate a new and novel application for radiosurgery, the ablation of cardiac arrhythmias. Pre-clinical studies in the porcine animal model were used to investigate the accuracy with which the pathological region in the heart that is routinely treated for atrial fibrillation could be targeted with radiosurgery. Pathologic and electrophysiologic (EP) changes resulting from radiosurgical ablation were used as primary study endpoints. Methods: Two Hanford mini-swine (approximately 35 kg) were studied. A cardiac-gated CT study was performed. Isocentric treatments were delivered with the CyberKnifeÂ® (Accuray Inc, Sunnyvale, CA) in a single fraction at prescribed doses of 25 Gy (N=1) and 35 Gy (N=1). The treatment volume was selected to create electrical isolation of two pulmonary veins (the source of atrial aberrant tachycardias, such as atrial fibrillation) from the body (antrum) of the left atrium, as has been proven successful with thermal catheter ablation procedures. Animals were followed for six months, and then underwent electrophysiologic (EP) testing in the cardiac catheterization lab to test for electrical isolation of the pulmonary veins. Trans esophageal echocardiography was carried out to examine cardiac function post-radiosurgery. Finally, the hearts of the treated animals were submitted for pathologic analysis. Results: Long-term follow-up after left atrial radiosurgery demonstrated transmural, circumferential fibrosis that correlated to electrical isolation, similar to that found in catheter ablation. The EP study documented intended pulmonary vein isolation (electrical block), using a decapolar Lasso catheter (Biosense Webster, Diamond Bar, CA). Histologic analysis showed transmural fibrosis and contiguity (desired) of the ablation scar within the target. Echocardiographic monitoring of atrial and ventricular function six months post radiosurgery demonstrated normal cardiac function. Both animals met the survival endpoint with no adverse",2011,Cureus
Analysis of landscape transformation processes in and around four West African cities over the last 50 years,"Sub-Saharan Africa has experienced substantial urbanisation and land degradation processes over the past three decades. Using multi-source satellite imagery combined with geographical and demographic data, this study's aims were to analyse the extent of land cover changes (LCC) and identifying major landscape transformation processes (LTP) and their drivers for four West African cities in Mali, Burkina-Faso, Nigeria and Niger. A common classification scheme was used for a visual interpretation of Corona images from the 1960s and an automated classification of Landsat scenes from 1986, 2000/2001 and 2009. Based on a postclassification comparison LCC were summarized and related to the demographic trends of the past 50 years. Map changes were calculated from 1986 to 2009 to depict LTP (urbanisation, crop expansion, deforestation, and land abandonment) for the cities and their respective hinterlands. To investigate the effect of accessibility and infrastructural factors, LTP were related to the distance to roads, surface water and urban areas. From 1960 to 2009 a large-scale urban agglomeration was detected and the proportion of cultivated land in former natural woody savannas surrounding all four cities increased by 35%. The expansion of cropland during the past 30 years seemed to depend greatly on the availability of irrigation water in the semi-arid Sahelian cities (Kano and Niamey), whilst this was not a major driving factor for the cities of the Sudanian zone (Sikasso and Bobo-Dioulasso). Given the likely increase in water scarcity and land suitable for agriculture, ex ante land use planning and monitoring strategies will become increasingly important.",2012,Landscape and Urban Planning
Cassava yield traits predicted by genomic selection methods,"Genomic selection (GS) has been used to optimize genetic gains when phenotypic selection is considered costly and difficult to measure. The objective of this work was to evaluate the efficiency and consistency of GS prediction for cassava yield traits (Manihot esculenta Crantz) using different methods, taking into account the effect of population structure. BLUPs and deregressed BLUPs were obtained for 888 cassava accessions and evaluated for fresh root yield, dry root yield and dry matter content in roots in 21 trials conducted from 2011 to 2016. The deregressed BLUPs obtained for the accessions from a 48K single nucleotide polymorphism dataset were used for genomic predictions based on the BayesB, BLASSO, RR-BLUP, G-BLUP and RKHS methods. The accessions' BLUPs were used in the validation step using four cross-validation strategies, taking into account population structure and different GS methods. Similar estimates of predictive ability and bias were identified for the different genomic selection methods in the first cross-validation strategy. Lower predictive ability was observed for fresh root yield (0.4569 -RR-BLUP to 0.4756-RKHS) and dry root yield (0.4689 -G-BLUP to 0.4818-RKHS) in comparison with dry matter content (0.5655 -BLASSO to 0.5670 -RKHS). However, the RKHS method exhibited higher efficiency and consistency in most of the validation scenarios in terms of prediction ability for fresh root yield and dry root yield. The correlations of the genomic estimated breeding values between the genomic selection methods were quite high (0.99-1.00), resulting in high coincidence of clone selection regardless of the genomic selection method. The deviance analyses within and between the validation clusters formed by the discriminant analysis of principal components were significant for all traits. Therefore, this study indicated that i) the prediction of dry matter content was more accurate compared to that of yield traits, possibly as a result of the smaller influence of non-additive genetic effects; ii) the RKHS method resulted in high and stable prediction ability in most of the validation scenarios; and iii) some kinship between the validation and training populations is desirable in order for genomic selection to succeed due to the significant effect of population structure on genomic selection predictions.",2019,PLoS ONE
Connectionismâ€”the miracle mind model,"Abstract: Connectionism as a model of the mind has recently been challenging the Classical model, in which the mind is regarded as symbol manipulating system. The main arguments against Connectionism concern its inability to form mental representations for complex expressions, which can be used for structure sensitive operations. Some argue for hybrid models which combine some of the most attractive features of the Classical and Connectionist models. This paper starts off by examining the definitions of the different approaches and also their strengths and weaknesses. One section is devoted to the debate between the advocators of the different paradigms, including the arguments about the lack of compositionality and systematicity in Connectionist cognitive models. We then argue for the Connectionist approach as the most attractive model of the mind. This includes performing the ""miracle"" of defining structure sensitive operations on non-symbolic representations of concepts. Annotation: Published in Connectionism in a Broad Perspective, (Eds) Niklasson & Boden, Ellis Horwood, 1994",1994,
