title,abstract,year,journal
Exploring the areas of applicability of whole-genome prediction methods for Asian rice (Oryza sativa L.),"Key messageOur simulation results clarify the areas of applicability of nine prediction methods and suggest the factors that affect their accuracy at predicting empirical traits.AbstractWhole-genome prediction is used to predict genetic value from genome-wide markers. The choice of method is important for successful prediction. We compared nine methods using empirical data for eight phenological and morphological traits of Asian rice cultivars (Oryza sativa L.) and data simulated from real marker genotype data. The methods were genomic BLUP (GBLUP), reproducing kernel Hilbert spaces regression (RKHS), Lasso, elastic net, random forest (RForest), Bayesian lasso (Blasso), extended Bayesian lasso (EBlasso), weighted Bayesian shrinkage regression (wBSR), and the average of all methods (Ave). The objectives were to evaluate the predictive ability of these methods in a cultivar population, to characterize them by exploring the area of applicability of each method using simulation, and to investigate the causes of their different accuracies for empirical traits. GBLUP was the most accurate for one trait, RKHS and Ave for two, and RForest for three traits. In the simulation, Blasso, EBlasso, and Ave showed stable performance across the simulated scenarios, whereas the other methods, except wBSR, had specific areas of applicability; wBSR performed poorly in most scenarios. For each method, the accuracy ranking for the empirical traits was largely consistent with that in one of the simulated scenarios, suggesting that the simulation conditions reflected the factors that affected the method accuracy for the empirical results. This study will be useful for genomic prediction not only in Asian rice, but also in populations from other crops with relatively small training sets and strong linkage disequilibrium structures.",2014,Theoretical and Applied Genetics
Galo Plaza y el turismo: MÃ¡s allÃ¡ de la misiÃ³n cultural,"The goal of this paper has been to research deeply the contributions done by the ecuadorian president Galo Plaza Lasso for the tourist development, since for the investigations carried out, we only known about the organization and sending of the Cultural Mission to the United States, made up of three indians from Otavalo community. For the elaboration of this paper primary sources as Official Registers, official reports from the Ecuadorian Presidency and press reports have been consulted; secundary sources have been scarce, however the few of them have been analized. Some of the obtained results are that in spite of the ignorance about tourism that the Government had, It invested a lot of money for building hotels in some strategic cities. Finally the paper let us see that the Cultural Mission that was recognized as an input for tourism, actually it was not, maybe it could be considered as a mission trying to find new markets for the indian woven.",2019,
A Robust Multivariate EWMA Control Chart for Detecting Sparse Mean Shifts,"In multivariate statistical process control (MSPC) applications, process mean shifts sometimes occur in only a few components. To solve this MSPC problem, many control charts were proposed in the literature. Most of these charts assumed that the multivariate quality characteristics are normally distributed. Among them, the control chart proposed by Zou and Qiu (2009), incorporating the least absolute shrinkage and selection operator (LASSO) method into the EWMA scheme, has the best overall performance. In this paper, we extend the classical multivariate LASSO control chart to a robust version that has an affine-invariance property and is distribution free under the family of elliptical direction distributions, indicating that the in-control run-length distribution is the same for any continuous distribution in this family and the control limit can be acquired from the multivariate standard normal distribution. Our simulation results show that the proposed method is very efficient in detecting various sparse shifts under heavy-tailed and skewed multivariate distributions. In addition, it is easy to implement with an iterative algorithm and the least angle regression (LARS) algorithm. White-wine data illustrates that the proposed control chart performs quite well in applications.",2016,Journal of Quality Technology
Polymorphic gene markers ILRA and IL2: population distinctions in association with diabetes mellitus,"Aims. In order to study type 1 diabetes mellitus associations, we conducted a comparative analysis of allele and genotype frequencydistribution of polymorphic markers rs41295061 and rs11594656 of IL2RA gene, which encodes ?-chain of interleukin-2receptor, - and rs2069762, a marker of IL2, gene, encoding interleukin-2. Materials and methods. Experimental group included 451 patients with type 1 diabetes mellitus (DM); control group consistedof 306 healthy subjects (both groups were represented by ethnic Russians). Alleles and polymorphic markers were identified byreal-time amplification method. Results. A comparative analysis of patients with type 1 DM and healthy control group did not show statistically significant differencesfrom the viewpoint of allele and genotype frequency distribution of polymorphic markers rs41295061, rs11594656 andrs2069762. This makes Russian patients considerably different from European ones where markers in question show substantialassociation with type 1 DM. Conclusion. A comparative analysis of allele and genotype frequency distribution of IL2-RA and IL2 genes polymorphic markersshowed population differences in association of these markers in Russian and European patients.",2012,Diabetes mellitus
On quantifying quality of care,"In this thesis, we examine how the analysis of quality outcomes, such as 30-day mortality for patients with acute stroke, can help compare the quality of care between hospitals. As in the neighboring countries, the demand for quality control in hospitals is growing but also, for example for residential care centers and schools, both by government and patients as well as centers themselves. 
Given the potentially large impact of reported results, this requires a careful statistical analysis of the available data, as discussed in Chapter 1. To estimate the causal effect of the quality of care on the outcome of interest, we have to control for differences between patients on admission, such as age and initial disease severity. This is necessary because they may influence the outcome and they are possibly distributed differently across centers. Otherwise, hospitals treating mostly elderly patients may show higher mortality risks, even though the given care is excellent. The research questions in this thesis were mostly inspired by the analysis of the Swedish register for acute stroke care, Riksstroke (http://www.riksstroke.org/eng/), but the discussed methods are more generally applicable. To account for measured patient characteristics we will use, depending on the research question, directly or indirectly ized risks as performance measure. 
It has been proven that when standardized risks are estimated based on the popular normal mixed effects model, the estimated quality of care may be shrunken towards the average, often masking outlying performance of hospitals (Normand et al., 1997; Ash et al., 2012). In Chapter 2 we therefore investigated the use of a Firth corrected fixed effects model and found little shrinkage of the center effects towards the overall mean. This approach is thus particularly valuable when some centers have a small number of registered patients since the convergence of this estimation strategy is better than for fixed effects models and a better detection of outlying performance is obtained than for normal mixed effects models. Secondly, we investigate undue model extrapolation when estimating for example, directly standardized risks, especially if patient mix differs substantially between hospitals. Extrapolation in combination with the use of misspecified statistical models can yield biased results with an underestimated uncertainty. Therefore, we examined a method that weights observations by the inverse of the so-called propensity score, i.e. the probability to be treated in the observed center (Shahian and Normand, 2008). The investigated doubly robust method is protected against model misspecification (Robins et al., 2007) and, if the propensity score is very small, the user will be warned for extrapolation via inflated variance estimates. Although promising, the obtained results suggested to use the Firth corrected fixed effects method. 
Common adjustments for differences in patientmix generally assume that the effect of the given care level on the outcome is constant across patient groups (Ohlssen et al., 2007b; Shahian and Normand, 2008). In practice, however, this may be violated when some centers are for example specialized in care for the elderly (Nicholl et al., 2013;Mohammed et al., 2009). If then no center-patient interactions are included in the outcome regression model, we found in Chapter 3 that the directly and indirectly standardized risks will only be biased if the distribution of that patient characteristic differs substantially across centers, otherwise bias is negligible. Being able to justify common practice is especially important in settings where it is simply impossible to estimate these interactions in the model, because insufficient information is available in small hospitals, for example see Ash et al. (2012). 
In Chapter 4 we also examined how the number of (expensive, genetic) measurements - and thus the cost per patient - can be reduced when predicting individual patient outcomes or estimating standardized risks for hospital quality evaluation. Stochastic search algorithms allow for a relatively quick and costefficient variable selection and they can easily handle multiple imputed datasets when some measurements are missing. We have also illustrated how the search time can be further reduced by a priori performing a cost-efficient generalized LASSO search. 
Because we believe in the broad applicability of the statistical methods in this thesis, we havemade them available via the R-package RiskStandard (www.cvstat.ugent.be), as documented in Chapter 5.",2015,
Generalized Peacemanâ€“Rachford splitting method with substitution for convex programming,"The generalized alternating direction method of multipliers (GADMM), which expands the dual step length to (0,2), is a benchmark for solving the two-block separable convex programming. Recently, there are many ADMM-based improved algorithms with indefinite term, that is, the second subproblem is linearized by a specialized indefinite matrix. In this paper, we propose a generalized proximal Peacemanâ€“Rachford splitting method (abbreviated as GPRSM-S) with substitution step and indefinite term. We will find out the relationship between linearized parameter, dual step length and substitution factor. The global convergence and the worst-case convergence rate in nonergodic sense are established theoretically by variational inequality. Finally, some numerical results on LASSO and total variation based denoising problems are presented to verify the feasibility of the introduced method.",2019,Optimization Letters
Inference in High-Dimensional Linear Regression via Lattice Basis Reduction and Integer Relation Detection,"We focus on the high-dimensional linear regression problem, where the algorithmic goal is to efficiently infer an unknown feature vector $\beta^*\in\mathbb{R}^p$ from its linear measurements, using a small number $n$ of samples. Unlike most of the literature, we make no sparsity assumption on $\beta^*$, but instead adopt a different regularization: In the noiseless setting, we assume $\beta^*$ consists of entries, which are either rational numbers with a common denominator $Q\in\mathbb{Z}^+$ (referred to as $Q$-rationality); or irrational numbers supported on a rationally independent set of bounded cardinality, known to learner; collectively called as the mixed-support assumption. Using a novel combination of the PSLQ integer relation detection, and LLL lattice basis reduction algorithms, we propose a polynomial-time algorithm which provably recovers a $\beta^*\in\mathbb{R}^p$ enjoying the mixed-support assumption, from its linear measurements $Y=X\beta^*\in\mathbb{R}^n$ for a large class of distributions for the random entries of $X$, even with one measurement $(n=1)$. In the noisy setting, we propose a polynomial-time, lattice-based algorithm, which recovers a $\beta^*\in\mathbb{R}^p$ enjoying $Q$-rationality, from its noisy measurements $Y=X\beta^*+W\in\mathbb{R}^n$, even with a single sample $(n=1)$. We further establish for large $Q$, and normal noise, this algorithm tolerates information-theoretically optimal level of noise. We then apply these ideas to develop a polynomial-time, single-sample algorithm for the phase retrieval problem. Our methods address the single-sample $(n=1)$ regime, where the sparsity-based methods such as LASSO and Basis Pursuit are known to fail. Furthermore, our results also reveal an algorithmic connection between the high-dimensional linear regression problem, and the integer relation detection, randomized subset-sum, and shortest vector problems.",2019,arXiv: Statistics Theory
Iterative selection using orthogonal regression techniques,"High dimensional data are nowadays encountered in various branches of science. Variable selection techniques play a key role in analyzing high dimensional data. Generally two approaches for variable selection in the high dimensional data setting are consideredâ€”forward selection methods and penalization methods. In the former, variables are introduced in the model one at a time depending on their ability to explain variation and the procedure is terminated at some stage following some stopping rule. In penalization techniques such as the least absolute selection and shrinkage operator (LASSO), as optimization procedure is carried out with an added carefully chosen penalty function, so that the solutions have a sparse structure. Recently, the idea of penalized forward selection has been introduced. The motivation comes from the fact that the penalization techniques like the LASSO give rise to closed form expressions when used in one dimension, just like the least square estimator. Hence one can repeat such a procedure in a forward selection setting until it converges. The resulting procedure selects sparser models than comparable methods without compromising on predictive power. However, when the regressor is high dimensional, it is typical that many predictors are highly correlated. We show that in such situations, it is possible to improve stability and computational efficiency of the procedure further by introducing an orthogonalization step. At each selection step, variables potentially available to be selected in the model are screened on the basis of their correlation with variables already in the model, thus preventing unnecessary duplication. The new strategy, called the Selection Technique in Orthogonalized Regression Models (STORM), turns out to be extremely successful in reducing the model dimension further and also leads to improved predicting power. We also consider an aggressive version of the STORM, where a potential predictor will be permanently removed from further consideration if its regression coefficient is estimated as zero at any stage. We shall carry out a detailed simulation study to compare the newly proposed method with existing ones and analyze a real dataset. ï›™ 2013 Wiley Periodicals, Inc. Statistical Analysis and Data Mining 6: 557-564, 2013",2013,Statistical Analysis and Data Mining
Prognostic implications of autophagy-associated gene signatures in non-small cell lung cancer,"Autophagy, a highly conserved cellular proteolysis process, has been involved in non-small cell lung cancer (NSCLC). We tried to develop a prognostic prediction model for NSCLC patients based on the expression profiles of autophagy-associated genes. Univariate Cox regression analysis was used to determine autophagy-associated genes significantly correlated with overall survival (OS) of the TCGA lung cancer cohort. LASSO regression was performed to build multiple-gene prognostic signatures. We found that the 22-gene and 11-gene signatures could dichotomize patients with significantly different OS and independently predict the OS in TCGA lung adenocarcinoma (HR=2.801, 95% CI=2.252-3.486, P<0.001) and squamous cell carcinoma (HR=1.105, 95% CI=1.067-1.145, P<0.001), respectively. The prognostic performance of the 22-gene signature was validated in four GEO lung cancer cohorts. Moreover, GO, KEGG, and GSEA analyses unveiled several fundamental signaling pathways and cellular processes associated with the 22-gene signature in lung adenocarcinoma. We also constructed a clinical nomogram with a concordance index of 0.71 to predict the survival possibility of NSCLC patients by integrating clinical characteristics and the autophagy gene signature. The calibration curves substantiated fine concordance between nomogram prediction and actual observation. Overall, we constructed and verified a novel autophagy-associated gene signature that could improve the individualized outcome prediction in NSCLC.",2019,Aging (Albany NY)
Title: Contextual MDPs: A New Model and PAC Guarantees for Reinforcement Learning with Rich Observations,"s: Alekh Agarwal (Microsoft Research) Title: Contextual MDPs: A New Model and PAC Guarantees for Reinforcement Learning with Rich Observations We propose and study a new tractable model for reinforcement learning with highdimensional observation called Contextual-MDPs, generalizing contextual bandits to a sequential decision making setting. These models require an agent to take actions based on high-dimensional observations (features) with the goal of achieving long-term performance competitive with a large set of policies. Since the size of the observation space is a primary obstacle to sample-efficient learning, Contextual-MDPs are assumed to be summarizable by a small number of hidden states. In this setting, we design a new reinforcement learning algorithm that engages in global exploration while using a function class to approximate future performance. We also establish a sample complexity guarantee for this algorithm, proving that it learns near optimal behavior after a number of episodes that is polynomial in all relevant parameters, logarithmic in the number of policies, and independent of the size of the observation space. This represents an exponential improvement on the sample complexity of all existing alternative approaches and provides theoretical justification for reinforcement learning with function approximation. This is joint work with Akshay Krishnamurthy and John Langford. Available online at http://arxiv.org/abs/1602.02722. Jelena Bradic (UC San Diego) Title: Robust Machine Learning Recent advances in technologies for cheaper and faster data acquisition and storage have led to an explosive growth of data complexity in a variety of research areas such as high-throughput genomics, biomedical imaging, high-energy physics, astronomy and economics. As a result, noise accumulation, experimental variation and data inhomogeneity have become substantial. However, machine learning in such settings is known to pose many statistical challenges and hence calls for new methods and theories. Moreover, the impact of outliers or non-gaussianity is far from obvious. In this talk we provide two methods for machine learning that adapt to the unknown outliers in the data and we provide theoretical understanding of the impact of outliers on the learning. In particular, we propose a new boosting framework called Arch Boost. It is designed for augmenting the existing work such that its corresponding classification algorithms with non-convex losses are significantly more adaptable to unknown data contamination. Along with the Arch Boost framework, a family of non-convex losses are proposed which leads to new robust boosting algorithms, namedAdaptive Robust Boosting (ARB). Moreover, when the dimension of the feature space is high, we propose a novel, robust and sparse approximate message passing algorithm (RAMP), that is adaptive to the error distribution. Our algorithm includes many non-quadratic and non-differentiable loss functions. We derive its asymptotic mean squared error and show its convergence, while allowing p, n, s â†’ âˆž, with n/p âˆˆ (0, 1) and n/s âˆˆ (1, âˆž). Lastly, we present theoretical developments that showcase the difficulty of studying robustness in machine learning and lead to many open questions. Emmanuel CandÃ¨s (Stanford) Title: A knockoff filter for controlling the false discovery rate The big data era has created a new scientific paradigm: collect data first, ask questions later. Imagine that we observe a response variable together with a large number of potential explanatory variables, and would like to be able to discover which variables are truly associated with the response. At the same time, we need to know that the false discovery rate (FDR)---the expected fraction of false discoveries among all discoveries---is not too high, in order to assure the scientist that most of the discoveries are indeed true and replicable. We introduce the knockoff filter, a new variable selection procedure controlling the FDR in the statistical linear model whenever there are at least as many observations as variables. This method works by constructing fake variables, knockoffs, which can then be used as controls for the true variables; the method achieves exact FDR control in finite sample settings no matter the design or covariates, the number of variables in the model, and the amplitudes of the unknown regression coefficients, and does not require any knowledge of the noise level. This is joint work with Rina Foygel Barber. Chen-Nee Chuah (UC Davis) Title: Network Inference with Online Learning in Software Defined Networking Network measurement and inference play a key role in different networking applications including network design, traffic engineering, and security analytics. Obtaining fine-grained measurement data under hard resource constraints is a challenging task in todayâ€™s large-scale networks. This talk will demonstrate how flexibility of software-defined networking (SDN) can be leveraged to adapt measurement rules based on optimal online strategies to augment traditional network inference techniques to obtain better estimates of network characteristics, such as traffic matrix or per-hop delay/loss rates. We will present a few case studies that demonstrate how SDN-enabled network monitoring and inference problems can benefit from theories and results from compressive sensing, multi-arm bandit, and statistical online learning. Simulation results using mininet and prototyping effort using hardware OpenFlow will be discussed. Ian Davidson (UC Davis) Title: Variations of Spectral Clustering Formulations and Challenges Spectral clustering is a commonly used method for segmenting graphs due to its ease of implementation and underpinning in spectral graph theory such as connections to min-cut of a graph. Recent variations by our selves and others involve: i) adding in guidance and constraints, ii) segmenting multiple graphs and iii) adding a human to the process via active learning. I will cover all these three settings pointing out why they are useful, existing formulations and challenges, particularly core underlying questions that remain unanswered. Cho-Jui Hsieh (UC Davis) Title: Asynchronous Parallel Optimization in Machine Learning Asynchronous parallel optimization is important for solving large-scale machine learning problems. In this talk, I will present theoretical and practical challenges of asynchronous parallel optimization, and talk about our current approaches for addressing these challenges in multi-core or distributed system. Sham Kakade (University of Washington) Title: Discovering Hidden Structure in the Sparse Regime In many applications, we face the challenge of modeling the hidden interactions between multiple observations (e.g. discovering clusters of points in space or learning topics in documents). Furthermore, an added difficulty is that our datasets often have empirical distributions which are heavy tailed tailed (e.g. problems in natural language processing). In other words, even though we have large datasets, we are often in a sparse regime where there is a large fraction of our items that have only been observed a few times (e.g. Zipfâ€™s law which states that regardless of how big our corpus of text is, a large fraction of the words in our vocabulary will only be observed a few times). The question we consider is how to learn a model of our data when our dataset is large and yet is sparse. We provide an algorithm for learning certain natural latent variable models applicable to this sparse regime, making connections to a body of recent work in sparse random graph theory and community detection. We also discuss the implications to practice. Xiaodong Li (UC Davis) Title: Wirtinger flow and thresholded Wirtinger flow By dimension lifting techniques, phase retrieval can be also viewed as a special low-rank recovery problem. Although convex methods, such as PhaseLift, are provably effective and robust, the computational complexity and storage cost could be pretty high. To address these issues, we introduce a non-convex optimization algorithm, named Wirtinger flow, with theoretically guaranteed performances. It is much more efficient than convex methods in terms of computation and memory. Finally, I will introduce how to modify Wirtinger flow into an adaptive thresholded gradient descent method given the signal is known to be sparse, in order to achieve the minimax convergence rates under l_2 loss. Miles Lopes (UC Davis) Title: Unknown Sparsity in Compressed Sensing: Denoising and Inference The theory of Compressed Sensing (CS) asserts that an unknown signal x in R can be accurately recovered from an underdetermined set of n linear measurements with n<<p, provided that x is sufficiently sparse. However, in applications, the degree of sparsity ||x||0 is typically unknown, and the problem of directly estimating ||x||0 has been a longstanding gap between theory and practice. A closely related issue is that ||x||0 is a highly idealized measure of sparsity, and for real signals with entries not equal to 0, the value ||x||0=p is not a useful description of compressibility. In our previous work that examined these problems, we considered an alternative measure of â€œsoftâ€ sparsity, (||x||1/||x||2), and designed a procedure to estimate (||x||1/||x||2) that does not rely on sparsity assumptions. The present work offers a new deconvolution-based method for estimating unknown sparsity, which has wider applicability and sharper theoretical guarantees. In particular, we introduce a family of entropy-based sparsity measures sq(x) parameterized by qâ‰¥0, which includes (||x||1/||x||2) and ||x||0 as special cases. Also, we propose an estimator for sq(x) whose relative error converges at the dimension-free rate of n, even when p/n diverges. Our main results also describe the limiting distribution of the estimator, as well as some connections to Basis Pursuit Denosing, the Lasso, deterministic measure",2016,
Quantitative methods for metabolomic analyses evaluated in the Childrenâ€™s Health Exposure Analysis Resource (CHEAR),"With advances in technologies that facilitate metabolome-wide analyses, the incorporation of metabolomics in the pursuit of biomarkers of exposure and effect is rapidly evolving in population health studies. However, many analytic approaches are limited in their capacity to address high-dimensional metabolomics data within an epidemiologic framework, including the highly collinear nature of the metabolites and consideration of confounding variables. In this Childrenâ€™s Health Exposure Analysis Resource (CHEAR) network study, we showcase various analytic approaches that are established as well as novel in the field of metabolomics, including univariate single metabolite models, least absolute shrinkage and selection operator (LASSO), random forest, weighted quantile sum (WQSRS) regression, exploratory factor analysis (EFA), and latent class analysis (LCA). Here, in a Bangladeshi birth cohort (nâ€‰=â€‰199), we illustrate research questions that can be addressed by each analytic method in the assessment of associations between cord blood metabolites (1H NMR measurements) and birth anthropometric measurements (birth weight and head circumference).",2019,Journal of Exposure Science & Environmental Epidemiology
Use of a tourniquet in patients with sickle-cell disease,"Fifteen patients, 13 male and two female, known to be carrying the sickle-cell gene (12 HbSS and 3 HbAS), who were undergoing operations requiring a bloodless field, were included in the study. Of the 12 with HbSS, seven had haemoglobin A, component of between 11 and 27%, three had fetal haemoglobin ranging from 5.7 to 29% and the remaining two had increased haemoglobin A2 concentrations suggesting a beta non-thalassaemia combination. All had a tourniquet applied to the appropriate limb and were given general anaesthesia with moderate hyperventilation throughout the procedure. The tourniquet inflation time was 61.7 Â± 27.5 min. The mean PaO2 remained above 200 mmHg, mean PaCO2 was less than 37 mmHg, and pH ranged between 7.40 and 7.45. There were no clinically important changes in BP or ECG. All patients made uneventful recoveries and none developed sickle-cell crises. It is suggested that it is safe to use tourniquet in patients with sickle-cell disease provided optimum acid-base status and oxygenation are maintained throughout the procedure.RÃ©sumÃ©Quinze patients dont 13 hommes et 2 femmes, connus porteurs du gÃ¨ne dâ€™hÃ©matie falciforme (12 HbSS et 3 HbAS) ont Ã©tÃ© inclus dans lâ€™Ã©tude. Ils subissaient des interventions nÃ©cessitant un champ exsangue. Parmi les 12 HbSS, sept avaient une HbA1 entre 11 et 27%, trois avaient une Hb foetale entre 5,7 et 29% et deux autres avaient une HbA2 accrue suggÃ©rant une combinaision Î² non thalassÃ©mique. Tous ont eu un garrot placÃ© sur le membre appropriÃ© et ont eu une anesthÃ©sie gÃ©nÃ©rale avec une hyperventilation modÃ©rÃ©e pendant lâ€™intervention. Le temps de garrot a Ã©tÃ© de 61,7 Â± 27,5 min. La PaO2 moyenne est restÃ©e au-dessus de 200 mm de Hg, la PCO2 moyenne infÃ©rieure Ã  37 mmHg et le pH entre 7,40 et 7,45. Il nâ€™y a pas eu de changement cliniquement important de la pression artÃ©rielle et de lâ€™ECG. Tous les patients se sont rÃ©veillÃ©s sans problÃ¨me, aucun nâ€™a eu de crise dâ€™hÃ©molyse. On suggÃ¨re quâ€™il est inoffensif dâ€™utiliser un garrot en cas de thalassodrÃ©panocytose pourvu que lâ€™Ã©tat acido-basique et lâ€™oxygÃ©nation optimum soient maintenus pendant lâ€™intervention.",1993,Canadian Journal of Anaesthesia
Jean-Jacques Rousseau gramatÃ³logo,"An analysis about Jean-Jacques Rousseauâ€™s contribution to the theory of writing and the grammatology. This analysis contains a systematic comparison of the rousseaunian ideas about the language and the writing with another theories of the 17 th (Arnauld and Lancelot), 18 th (Condillac, Paillasson, Jaucourt) and 20 th centuries (Saussure). The contrast of Rousseauâ€™s ideas to Saussureâ€™s about writing also, allows to make explicit Rousseauâ€™s grammatological ideasâ€™s big importance and his relation with the grammatology (Gelb, Derrida, Harris), exceeding avant la lettre modern linguisticsâ€™s phonocentrism.",2009,Ã‡Ã©dille: Revista de Estudios Franceses
Genetic prediction of quantitative lipid traits: comparing shrinkage models to gene scores.,"Accurate genetic prediction of quantitative traits related to complex disease risk would have potential clinical impact, so investigation of statistical methodology to improve predictive performance is important. We compare a simple approach of polygenic scores using top ranking single nucleotide polymorphisms (SNPs) to a set of shrinkage models, namely Ridge Regression, Lasso and Hyper-Lasso. These penalised regression methods analyse all genotyped SNPs simultaneously, potentially including much larger sets of SNPs in the models, not only those with the smallest P values. We compare the accuracy of these models for predicting low-density lipoprotein (LDL) and high-density lipoprotein (HDL) cholesterol, two lipid traits of clinical relevance, in the Whitehall II and British Women's Health and Heart Study cohorts, using SNPs from the HumanCVD BeadChip. For gene scores, the most accurate predictions arise from multivariate weighted scores and include only a small number of SNPs, identified as top hits by the HumanCVD BeadChip. Furthermore, there was little benefit from including external results from published sets of SNPs. We found that shrinkage approaches rarely improved significantly on gene score results. Genetic predictive performance is trait specific, depending on the heritability and genetic architecture of the trait, and is limited by the training data sample size. Our results for lipid traits suggest no current benefit of more complex methods over existing gene score methods. Instead, the most important choice for the prediction model is the number of SNPs and selection of the most predictive SNPs to include. However further comparisons, in larger samples and for other phenotypes, would still be of interest.",2014,Genetic epidemiology
Synthetic peptides derived from the sequence of a lasso peptide microcin J25 show antibacterial activity.,"Microcin J25 (MccJ25) is a plasmid-encoded, ribosomally synthesized antibacterial peptide with a unique lasso structure. The lasso structure, produced with the aid of two processing enzymes, provides exceptional stability to MccJ25. We report the synthesis of six peptides (1-6), derived from the MccJ25 sequence, that are designed to form folded conformation by disulfide bond formation and electrostatic or hydrophobic interactions. Two peptides (1 and 6) display good activity against Salmonella newport, and are the first synthetic derivatives of MccJ25 that are bactericidal. Peptide 1 displays potent activity against several Salmonella strains including two MccJ25 resistant strains. The solution conformation and the stability studies of the active peptides suggest that they do not fold into a lasso conformation and peptide 1 displays antimicrobial activity by inhibition of target cell respiration. Like MccJ25, the synthetic MccJ25 derivatives display minimal toxicity to mammalian cells suggesting that these peptides act specifically on bacterial cells.",2012,Bioorganic & medicinal chemistry
"First Records of the Echiurans Anelassorhynchus inanensis (Ikeda, 1904) and Ochetostoma pellucidum (Fischer, 1895) from the East Coast of Southern Africa (Echiuroinea: Echiuridae)","Two species of echiurans (Echiura), Anelassorhynchus inanensis (Ikeda, 1904) and Ochetostoma pellucidum (Fischer, 1895), were collected from intertidal rocky shores at Perriers Rock on the KwaZulu-Natal north coast. This is the first known record of these two species from South African waters and considerably extends their geographical ranges. A. inanensis, originally described by Ikeda (1904) from Naha, Japan, was later recorded and redescribed by Wesenberg-Lund (1939) from a single specimen from South Annam while Haldar & DattaGupta (1991) assigned two specimens from Kavaratti Island, on the southwest coast of India, to the species. O. pellucidum is based on several specimens collected from Whydah, West Africa. According to Stephen & Edmonds (1972) no illustrations of this species have been given while the description given by Wesenberg-Lund (1954) is based on a single badly-preserved specimen from French Guinea. Both species are redescribed and compared with other closely related forms.",2011,
Radiomic Profiling of Head and Neck Cancer: 18F-FDG PET Texture Analysis as Predictor of Patient Survival,"Background and Purpose
The accurate prediction of prognosis and pattern of failure is crucial for optimizing treatment strategies for patients with cancer, and early evidence suggests that image texture analysis has great potential in predicting outcome both in terms of local control and treatment toxicity. The aim of this study was to assess the value of pretreatment 18F-FDG PET texture analysis for the prediction of treatment failure in primary head and neck squamous cell carcinoma (HNSCC) treated with concurrent chemoradiation therapy.


Methods
We performed a retrospective analysis of 90 patients diagnosed with primary HNSCC treated between January 2010 and June 2017 with concurrent chemo-radiotherapy. All patients underwent 18F-FDG PET/CT before treatment. 18F-FDG PET/CT texture features of the whole primary tumor were measured using an open-source texture analysis package. Least absolute shrinkage and selection operator (LASSO) was employed to select the features that are associated the most with clinical outcome, as progression-free survival and overall survival. We performed a univariate and multivariate analysis between all the relevant texture parameters and local failure, adjusting for age, sex, smoking, primary tumor site, and primary tumor stage. Harrell c-index was employed to score the predictive power of the multivariate cox regression models.


Results
Twenty patients (22.2%) developed local failure, whereas the remaining 70 (77.8%) achieved durable local control. Multivariate analysis revealed that one feature, defined as low-intensity long-run emphasis (LILRE), was a significant predictor of outcome regardless of clinical variables (hazard ratioâ€‰<â€‰0.001, P=0.001).The multivariate model based on imaging biomarkers resulted superior in predicting local failure with a c-index of 0.76 against 0.65 of the model based on clinical variables alone.


Conclusion
LILRE, evaluated on pretreatment 18F-FDG PET/CT, is associated with higher local failure in patients with HNSCC treated with chemoradiotherapy. Using texture analysis in addition to clinical variables may be useful in predicting local control.",2018,Contrast Media & Molecular Imaging
Development and internal validation of a depression severity prediction model for tinnitus patients based on questionnaire responses and socio-demographics,"Tinnitus is a complex condition that is associated with major psychological and economic impairments â€“ partly through various comorbidities such as depression. Understanding the interaction between tinnitus and depression may thus improve either symptom clusterâ€™s prevention, diagnosis and treatment. In this study, we developed and validated a machine learning model to predict depression severity after outpatient therapy (T1) based on variables obtained before therapy (T0). 1,490 patients with chronic tinnitus (comorbid major depressive disorder: 52.2%) who completed a 7-day multimodal treatment encompassing tinnitus-specific components, cognitive behavioural therapy, physiotherapy and informational counselling were included. 185 variables were extracted from self-report questionnaires and socio-demographic data acquired at T0. We used 11 classification methods to train models that reliably separate between subclinical and clinical depression at T1 as measured by the general depression questionnaire. To ensure highly predictive and robust classifiers, we tuned algorithm hyperparameters in a 10-fold cross-validation scheme. To reduce model complexity and improve interpretability, we wrapped model training around an incremental feature selection mechanism that retained features that contributed to model prediction. We identified a LASSO model that included all 185 features to yield highest predictive performance (AUC = 0.87â€‰Â±â€‰0.04). Through our feature selection wrapper, we identified a LASSO model with good trade-off between predictive performance and interpretability that used only 6 features (AUC = 0.85â€‰Â±â€‰0.05). Thus, predictive machine learning models can lead to a better understanding of depression in tinnitus patients, and contribute to the selection of suitable therapeutic strategies and concise and valid questionnaire design for patients with chronic tinnitus with or without comorbid major depressive disorder.",2020,Scientific Reports
P117 Machine learning tool provides new insights into risk assessment in pulmonary endarterectomy,"Background Chronic thromboembolic pulmonary hypertension (CTEPH) is an uncommon disorder characterised by persistent obstruction of the pulmonary arteries by thromboembolic material, usually following an acute pulmonary embolus.1 Pulmonary endarterectomy (PEA) is the gold standard treatment for eligible patients and is potentially curative.1Whilst pre-operative parameters have been associated with post-operative mortality no sytematic method for predicting individualised PEA risk presently exists. Objectives To identify pre-operative risk factors of 90 day mortality (90DM), five year mortality (5YM) and improvement in self-reported functional status (DQ) following PEA for inclusion in a clinically-implementable risk prediction tool. Methods Consecutive patients undergoing PEA for CTEPH at Royal Papworth Hospital, UK between 2007 and 2017 were included. Potential pre-operative predictors including patient demographics, medical history and results of functional, physiological and patient self-reported measures were included in a hypothesis-free approach. Three stastical predictive models were considered (linear regression, lasso regression and random forest), each of which were calibrated, fitted and assessed using cross-validation ensuring internal consistency. Results 1336 individuals were included in risk modelling. 96 patients (6.4%) died within 90 days of hospital discharge and 154 (11.5%) within five years of PEA. Random forest based predictions were more accurate than linear or lasso based. All post-operative outcomes were predicted well from pre-operative variables (90DM: AUROC 0.82 (95% CI 0.78, 0.87); 5YM: C-Index 0.81 (0.76, 0.85); DQ (Spearmanâ€™s correlation 0.47 (0.43, 0.51)) using random forest modelling. The strongest individual pre-operative predictor of 90DM and 5YM was left atrial dilatation and of DQ, pulmonary vasodilator therapy. Post-hoc analysis confirmed not only excess mortaltiy following PEA in those with left atrial dilatation secondary to diastolic dysfunction but adverse functional, haemodynamic and patient-reported outcomes in this group. Conclusions Outcomes from PEA can be predicted from pre-operative observations to a clinically useful degree enabling individualised risk prediction. Post-hoc analysis highlights the under-recognised adverse outcomes in those with left atrial dilatation. We present an online application to facilitate use of these tools. Further work validating our model in other centres will be necessary and aided by the open availability of our methodology. Reference Galie N, Humbert M, Vachiery J-L, et al. 2015 ESC/ERS Guidelines for the diagnosis and treatment of pulmonary hypertension. Eur Heart J2016;37(1):67â€“119.",2019,Thorax
Tracing the resources of iron working at ancient sagalassos (south-west Turkey): A combined lead and strontium isotope study on iron artefacts and ores,"Lead and strontium isotope analyses were performed by thermal ionization mass spectrometry (TIMS) on Roman to Byzantine iron artefacts and iron ores from the territory of ancient Sagalassos (south-west Turkey), to evaluate Pb and Sr isotopes for provenance determination of ores for local iron production. It can be demonstrated that for early Roman artefacts and hematite iron ore processed in early Roman times from Sagalassos proper, as well as for magnetite placer sands and early Byzantine raw iron from the territory of the city, Sr isotopes are much less ambiguous than Pb isotopes in providing clearly coherent signatures for ore and related iron objects. Late Roman iron objects were produced from iron ores that as yet remain unidentified. Early Byzantine iron artefacts display more scatter in both their Pb and Sr isotope signatures, indicating that many different ore sources may have been used. Our study demonstrates that iron objects can be precisely analysed for their Sr isotopic composition, which, compared to Pb isotopes, appears to be a much more powerful tool for distinguishing between chronological groups and determining the provenance of raw materials.",2007,Archaeometry
Machine learning approaches for supporting patient-specific cardiac rehabilitation programs,"Cardiac rehabilitation is a well-recognised non-pharmacological intervention that prevents the recurrence of cardiovascular events. Previous studies investigated the application of data mining techniques for the prediction of the rehabilitation outcome in terms of physical, but fewer reports are focused on using predictive models to support clinicians in the choice of a patient-specific rehabilitative treatment path. Aim of the work was to derive a prediction model for help clinicians in the prescription of the rehabilitation program. We enrolled 129 patients admitted for cardiac rehabilitation after a major cardiovascular event. Data on anthropometric measures, surgical procedure and complications, comorbidities and physical performance scales were collected at admission. The prediction outcome was the rehabilitation program divided in four different paths. Different algorithms were tested to find the best predictive model. Models performance were measured by prediction accuracy. Mean model accuracy was 0.790 (SD 0.118). Best model selected was Lasso regression showing an average classification accuracy on test set of0.935. Data mining techniques have shown to be a reliable tool for support clinicians in the decision of cardiac rehabilitation treatment path.",2016,2016 Computing in Cardiology Conference (CinC)
Development of predictive models to identify advanced-stage cancer patients in a US healthcare claims database.,"BACKGROUND
Although healthcare databases are a valuable source for real-world oncology data, cancer stage is often lacking. We developed predictive models using claims data to identify metastatic/advanced-stage patients with ovarian cancer, urothelial carcinoma, gastric adenocarcinoma, Merkel cell carcinoma (MCC), and non-small cell lung cancer (NSCLC).


METHODS
Patients with â‰¥1 diagnosis of a cancer of interest were identified in the HealthCore Integrated Research Database (HIRD), a United States (US) healthcare database (2010-2016). Data were linked to three US state cancer registries and the HealthCore Integrated Research Environment Oncology database to identify cancer stage. Predictive models were constructed to estimate the probability of metastatic/advanced stage. Predictors available in the HIRD were identified and coefficients estimated by Least Absolute Shrinkage and Selection Operator (LASSO) regression with cross-validation to control overfitting. Classification error rates and receiver operating characteristic curves were used to select probability thresholds for classifying patients as cases of metastatic/advanced cancer.


RESULTS
We used 2723 ovarian cancer, 6522 urothelial carcinoma, 1441 gastric adenocarcinoma, 109 MCC, and 12,373 NSCLC cases of early and metastatic/advanced cancer to develop predictive models. All models had high discrimination (Câ€¯>â€¯0.85). At thresholds selected for each model, PPVs were all >0.75: ovarian cancerâ€¯=â€¯0.95 (95% confidence interval [95% CI]: 0.94-0.96), urothelial carcinomaâ€¯=â€¯0.78 (95% CI: 0.70-0.86), gastric adenocarcinomaâ€¯=â€¯0.86 (95% CI: 0.83-0.88), MCCâ€¯=â€¯0.77 (95% CI 0.68-0.89), and NSCLCâ€¯=â€¯0.91 (95% CI 0.90 - 0.92).


CONCLUSION
Predictive modeling was used to identify five types of metastatic/advanced cancer in a healthcare claims database with greater accuracy than previous methods.",2019,Cancer epidemiology
Sparse learning of partial differential equations with structured dictionary matrix.,"This paper presents a ""structured"" learning approach for the identification of continuous partial differential equation (PDE) models with both constant and spatial-varying coefficients. The identification problem of parametric PDEs can be formulated as an â„“1/â„“2-mixed optimization problem by explicitly using block structures. Block-sparsity is used to ensure parsimonious representations of parametric spatiotemporal dynamics. An iterative reweighted â„“1/â„“2 algorithm is proposed to solve the â„“1/â„“2-mixed optimization problem. In particular, the estimated values of varying coefficients are further used as data to identify functional forms of the coefficients. In addition, a new type of structured random dictionary matrix is constructed for the identification of constant-coefficient PDEs by introducing randomness into a bounded system of Legendre orthogonal polynomials. By exploring the restricted isometry properties of the structured random dictionary matrices, we derive a recovery condition that relates the number of samples to the sparsity and the probability of failure in the Lasso scheme. Numerical examples, such as the SchrÃ¶dinger equation, the Fisher-Kolmogorov-Petrovsky-Piskunov equation, the Burger equation, and the Fisher equation, suggest that the proposed algorithm is fairly effective, especially when using a limited amount of measurements.",2019,Chaos
Bud burst of birch in Finland and the United Kingdom - Logistic regression analysis and modeling,"The day of bud burst (DBB) of different tree species are known to be 
affected by factors such as growing degree days and temperature. In this 
paper a two state Markov chain is used to model DBB for birch. The model 
is fit using logistic regression and LASSO regularization is used to 
evaluate which of many potential factors best forecast DBB. Data of birch 
from both Finland and the United Kingdom is studied and differences 
between the models adapted to the two countries are investigated. For 
modeling purposes to capture the environment of forecasting, estimated 
interpolated gridded climate data was used and not directly measured 
climate data. 
It is found that the models give very accurate predictions on the DBB. For 
Finland it is little more than 2 days in mean absolute error (MAE). The 
model is also fairly compact having less than 10 explaining covariates. 
The covariate, accumulated growing degree days, was as expected part of 
the models as well as among others variation of precipitation.",2013,
Does Cross-validation Work when p n ?,"Cross-validation is a popular tool for evaluating the performance of a predictive model, and hence also for model selection when we have a series of models to choose from. It has been suggested that cross-validation can fail when the number of predictors p is very large. We demonstrate through a suggestive simulation example that while K-fold cross-validation can have high variance in some situations, it is unbiased. We also study two permutation methods to assess the quality of a cross-validation curve for model selection, which we demonstrate using the lasso. The first approach is visual, while the second computes a p-value for our observed error. We demonstrate these approaches using two real datasets â€œColonâ€ and â€œLeukemiaâ€, as well as a null dataset. Finally we use the bootstrap to estimate the sampling distribution of our cross-validation curves, and their functionals. This adds to the graphical evidence of whether our findings are real or could have arisen by chance. âˆ—Trevor Hastie was partially supported by grant DMS-1007719 from the National Science Foundation, and grant RO1-EB001988-15 from the National Institutes of Health.",2012,
Confidence Intervals Using the Lasso,"Asymptotic linearity of a de-sparsified Lasso is established. This implies asymptotic normality under certain conditions and therefore can be used to construct confidence intervals for parameters of interest. Asymptotic linearity of groups of parameters, leading to confidence sets for groups, is also presented. Here, a the multivariate version of the square-root Lasso is invoked. The case of a linearized lossâ€”applicable when the covariance matrix of the design is knownâ€”is briefly addressed as well. Throughout the chapter except for the last section, the design is considered as fixed.",2016,
Mechanoregulation of bacterial phagocytosis and surface colonization,"Antimicrobial biomaterials are still considered the most ideal solution to control biomaterialassociated infection, despite the difficulties involved in their clinical validation and subsequent regulatory approval. The concept of â€œthe race for the surfaceâ€ between tissue integration and microbial colonization has long been a guide in developing antimicrobial surfaces, but strangely experimental methods to study the actual race for the surface between tissue cells and microbes have only been recently described [1,2].",2017,
Necessary and Sufficient Conditions for Sparsity Pattern Recovery,"The paper considers the problem of detecting the sparsity pattern of a k -sparse vector in \BBR n from m random noisy measurements. A new necessary condition on the number of measurements for asymptotically reliable detection with maximum-likelihood (ML) estimation and Gaussian measurement matrices is derived. This necessary condition for ML detection is compared against a sufficient condition for simple maximum correlation (MC) or thresholding algorithms. The analysis shows that the gap between thresholding and ML can be described by a simple expression in terms of the total signal-to-noise ratio (SNR), with the gap growing with increasing SNR. Thresholding is also compared against the more sophisticated Lasso and orthogonal matching pursuit (OMP) methods. At high SNRs, it is shown that the gap between Lasso and OMP over thresholding is described by the range of powers of the nonzero component values of the unknown signals. Specifically, the key benefit of Lasso and OMP over thresholding is the ability of Lasso and OMP to detect signals with relatively small components.",2009,IEEE Transactions on Information Theory
The Sylvester Graphical Lasso (SyGlasso),"This paper introduces the Sylvester graphical lasso (SyGlasso) that captures multiway dependencies present in tensor-valued data. The model is based on the Sylvester equation that defines a generative model. The proposed model complements the tensor graphical lasso (Greenewald et al., 2019) that imposes a Kronecker sum model for the inverse covariance matrix by providing an alternative Kronecker sum model that is generative and interpretable. A nodewise regression approach is adopted for estimating the conditional independence relationships among variables. The statistical convergence of the method is established, and empirical studies are provided to demonstrate the recovery of meaningful conditional dependency graphs. We apply the SyGlasso to an electroencephalography (EEG) study to compare the brain connectivity of alcoholic and nonalcoholic subjects. We demonstrate that our model can simultaneously estimate both the brain connectivity and its temporal dependencies.",2020,ArXiv
Data-driven confounder selection via Markov and Bayesian networks.,"To unbiasedly estimate a causal effect on an outcome unconfoundedness is often assumed. If there is sufficient knowledge on the underlying causal structure then existing confounder selection criteria can be used to select subsets of the observed pretreatment covariates, X, sufficient for unconfoundedness, if such subsets exist. Here, estimation of these target subsets is considered when the underlying causal structure is unknown. The proposed method is to model the causal structure by a probabilistic graphical model, for example, a Markov or Bayesian network, estimate this graph from observed data and select the target subsets given the estimated graph. The approach is evaluated by simulation both in a high-dimensional setting where unconfoundedness holds given X and in a setting where unconfoundedness only holds given subsets of X. Several common target subsets are investigated and the selected subsets are compared with respect to accuracy in estimating the average causal effect. The proposed method is implemented with existing software that can easily handle high-dimensional data, in terms of large samples and large number of covariates. The results from the simulation study show that, if unconfoundedness holds given X, this approach is very successful in selecting the target subsets, outperforming alternative approaches based on random forests and LASSO, and that the subset estimating the target subset containing all causes of outcome yields smallest MSE in the average causal effect estimation.",2018,Biometrics
Radiomics Features of 18F-fluorodeoxyglucose Positron-Emission Tomography as a Novel Prognostic Signature in Colorectal Cancer,"Purpose: The aim of this study was to investigate the prognostic value of radiomics signatures derived from 18F-fluorodeoxyglucose (18F-FDG) positron-emission tomography (PET) in patients with colorectal cancer (CRC). 
Methods: From April 2008 to Jan 2014, we identified CRC patients who underwent 18F-FDG-PET before starting any neoadjuvant treatments and surgery. Radiomics features were extracted from the primary lesions identified on 18F-FDG-PET. Patients were divided into a training and a validation set by random sampling. A least absolute shrinkage and selection operator (LASSO) Cox regression model was applied for prognostic signature building with progression-free survival (PFS) using the training set. Using the calculated radiomics score, a nomogram was developed, and the clinical utility of this nomogram was assessed in the validation set. 
Results: Three-hundred-and-eight-one patients with surgically resected CRC patients (training set 228 vs. validation set 153) were included. In the training set, a radiomics signature called a rad_score was generated using two PET-derived features such as Gray Level Run Length Matrix_Long-Run Emphasis (GLRLM_LRE) and Grey-Level Zone Length Matrix_Short-Zone Low Gray-level Emphasis (GLZLM_SZLGE). Patients with a high-rad_score in the training and validation set had shorter PFS. Multivariable analysis revealed that the rad_score was an independent prognostic factor in both training and validation sets. A radiomics nomogram, developed using rad_score, nodal stage, and lymphovascular invasion, showed good performance in the calibration curve and comparable predictive power with the staging system in the validation set. 
Conclusion: Textural features derived from 18F-FDG-PET images may enable more detailed stratification of prognosis in patients with CRC.",2019,medRxiv
"Pedro Bros Circus Limited :First appearance in New Zealand. A complete mammoth show, coming in all its restless conquering grandeur, the most worthy combine in amusement annals. Evening Post print - 48863 [1931].","Poster promoting a circus whose proprietors were Messrs Pedro and Cabot. The business manager was Charles Cabot and the treasurer Cecil Pedro. The touring manager was Joe Bruce, and the equestrian director William Tyler. The superintendent of canvas was Reg Stunt.
An arrangement of text listing: The Flying Winskills (aerial acrobats) and Charlie Chaplin clown; Tyler's wonderful performing monkeys; a great troupe of performing ponies; the Great Tyler (the world's greatest Risley act [where three acrobats lie on their backs and toss a fourth from one to the other]); Bert Weston (balancer); the Aerial Delevants (three women); Pimpo (acrobatic talking clown); Val-de-Mare (trick cyclist); Rosie Rifle & Co. (world's greatest lady rifle shot supported by Wild West lariat spinners, lassoers and stock-whip experts); Lavigue Sisters (double wire act); Joey the laughing clown with dummy August; Bubs Winrow (juvenile acrobatic dancer and contortionist); La Belle Maisie (trapeze performer); Togo the Charleston horse; Nelson Brothers (jugglers); Tommy (miniature trick pony); Alice Wilton (lady bareback rider); silver band headed by Charles Ross. 
Top cropped. Original dimensions 1020 x 380 mm (see copy at Eph-E-CABOT-Circus-Pedro-1931-02). 
Date verified in Cabot scrapbook number 98 (Eph-A-CABOT-Scrapbook-98). 
Quantity: 1 colour photo-mechanical print(s) on poster.. 
Physical Description: Offset lithograph 940 x 380 mm (cropped) 
Provenance: Donated by Mrs Beatrice Cabot, widow of Charles Cabot, in 1978.",1931,
"Role of differentially expressed genes and long non-coding RNAs in papillary thyroid carcinoma diagnosis, progression, and prognosis.","Currently, the combination of ultrasonography and fine-needle aspiration biopsy (FNAB) can not discriminate between benign and malignant tumor of thyroid in some cases. The main issue in assessing the patients with thyroid nodules is to distinguish thyroid cancer from benign nodules, and reduce diagnostic surgery. To identify potential molecular biomarkers for patients with indeterminate FNAB, we explored the differentially expressed genes (DEGs) and differentially expressed long non-coding RNAs (DElncRNAs) in TCGA database between 318 papillary thyroid carcinoma (PTC) tissues and 35 normal thyroid gland tissues by DESeq R. Furthermore, DEGs were verified by gene expression profile GSE33630. Ten top DEGs and DElncRNAs were identified as candidate biomarkers for diagnosis and Lasso (Least Absolute Shrinkage and Selection Operator) logistic regression analysis were performed to improve the diagnostic accuracy of them. Besides, partial molecular biomarkers of top DEGs and DElncRNAs were closely related to the tumor stage (T), lymph node metastasis (N), metastasis (M) and pathological stage of PTC, which could reflect behavior of tumor progression. According to multivariate Cox analysis, the combination of two DEGs (METTL7B and KCTD16) and two DElncRNAs (LINC02454 and LINC02471) could predict the outcome in a more exact way. In conclusion, top DEGs and DElncRNAs could raise diagnosis of PTC in indeterminate FNAB specimens, and some could function as molecule biomarkers for tumor progression and prognosis.",2018,Journal of cellular biochemistry
"Hemorrhagic Blisters, Necrosis, and Cutaneous Ulcer after Envenomation by the Niquim Toadfish","Toadfishes are found in tropical, marine, and estuarine waters. They have a highly developed venomous apparatus with dorsal and preopercular spines (Figure 1). Envenomation by this species can cause local inflammatory manifestations such as pain, edema, and erythema that can progress to cutaneous necrosis. A 38-year-old woman stepped on something in a lagoon among the stones of a beach in Bahia state, Brazil. She then noticed two small perforations in the third toe of the right footwith slight bleeding. The place began to ache unbearably and she wasmedicatedwithpainkillers.After 3days, intense inflammation and hemorrhagic blisters appeared near to the perforations. In about 10 days, the upper blister delimited a necrosis and the formationofanulcercoveredbyhemato-melicericcrust (Figure2). The pain, which had persisted for about a week, had disappeared. One month later, ulcer was healed, leaving a scar. Wounds by venomous fishes can be difficult to identify. Catfishes and stingrays causemainly unique perforations, but the envenomation by toadfishes causes a characteristic double perforation by the dorsal spicules. The species present in the region is Thalassophryne nattereri, the â€œniquim.â€ FIGURE 1. Live specimens of the toadfish Thalassophryne nattereri, with one of them semi-buried in the sand in a typical position. In the details, dorsal spicules of the fish, responsible for inoculation of the venom. Photos: Vidal Haddad Jr. This figure appears in color at www.ajtmh.org.",2019,The American Journal of Tropical Medicine and Hygiene
"The Group-Lasso : ` 1 , âˆž Regularization versus ` 1 , 2 Regularization","The `1,âˆž norm and the `1,2 norm are well known tools for joint regularization in Group-Lasso methods. While the `1,2 version has been studied in detail, there are still open questions regarding the uniqueness of solutions and the efficiency of algorithms for the `1,âˆž variant. For the latter, we characterize the conditions for uniqueness of solutions, we present a simple test for uniqueness, and we derive a highly efficient active set algorithm that can deal with input dimensions in the millions. We compare both variants of the Group-Lasso for the two most common application scenarios of the Group-Lasso, one is to obtain sparsity on the level of groups in â€œstandardâ€ prediction problems, the second one is multi-task learning where the aim is to solve many learning problems in parallel which are coupled via the Group-Lasso constraint. We show that both version perform quite similar in â€œstandardâ€ applications. However, a very clear distinction between the variants occurs in multi-task settings where the `1,2 version consistently outperforms the `1,âˆž counterpart in terms of prediction accuracy.",2010,
Bradycardia-dependent conduction block into pulmonary vein after isolation.,"Pulmonary vein (PV) isolation is the cornerstone of ablation for the treatment of paroxysmal atrial fibrillation. Once PV isolation is achieved, multiple maneuvers may be used to assure durable effect, including pacing along the ablation line,1 adenosine challenge2 to uncover dormant PV conduction, and an appropriate waiting period after successful isolation.3 We describe a novel finding of transient PV reconnection by rapid pacing of the coronary sinus.

A 69-year-old man with symptomatic, drug-refractory, paroxysmal atrial fibrillation was referred for PV isolation. Echocardiography displayed a normal left ventricular ejection fraction with mild left atrial enlargement.

Antral isolation was performed in atrial fibrillation, first around the left PVs, followed by the right PVs. Ablation was performed with an open-irrigated ablation catheter (Thermocool SF, Biosense Webster, Diamond Bar, CA), guided by a 10-pole circular mapping catheter (Lasso, Biosense Webster, Diamond Bar, CA). During the right-sided lesion set, sinus rhythm resumed at â€¦",2014,Circulation. Arrhythmia and electrophysiology
Using probabilistic graphical models to reconstruct biological networks and linkage maps,"Probabilistic graphical models (PGMs) offer a conceptual architecture where biological and mathematical objects can be expressed with a common, intuitive formalism. This facilitates the joint development of statistical and computational tools for quantitative analysis of biological data. Over the last few decades, procedures based on well-understood principles for constructing PGMs from observational and experimental data have been studied extensively, and they thus form a model-based methodology for analysis and discovery. In this thesis, we further explore the potential of this methodology in systems biology and quantitative genetics, and illustrate the capabilities of our proposed approaches by several applications to both real and simulated omics data. In quantitative genetics, we partition phenotypic variation into heritable, genetic, and non-heritable, environmental, parts. In molecular genetics, we identify chromosomal regions that drive genetic variation: quantitative trait loci (QTLs). In systems genetics, we would like to answer the question of whether relations between multiple phenotypic traits can be organized within wholly or partially directed network structures. Directed edges in those networks can be interpreted as causal relationships, causality meaning that the consequences of interventions are predictable: phenotypic interventions in upstream traits, i.e. traits occurring early in causal chains, will produce changes in downstream traits. The effect of a QTL allele can be considered to represent a genetic intervention on the phenotypic network. Various methods have been proposed for statistical reconstruction of causal phenotypic networks exploiting previously identified QTLs. In chapter 2, we present a novel heuristic search algorithm, namely the QTL+phenotype supervised orientation (QPSO) algorithm, to infer causal relationships between phenotypic traits. Our algorithm shows good performance in the common, but so far uncovered case, where some traits come without QTLs. Therefore, our algorithm is especially attractive for applications involving expensive phenotypes, like metabolites, where relatively few genotypes can be measured and population size is limited. Standard QTL mapping typically models phenotypic variations observable in nature in relation to genetic variation in gene expression, regardless of multiple intermediate-level biological variations. In chapter 3, we present an approach integrating Gaussian graphical modeling (GGM) and causal inference for simultaneous modeling of multilevel biological responses to DNA variations. More specifically, for ripe tomato fruits, the dependencies of 24 sensory traits on 29 metabolites and the dependencies of all the sensory and metabolic traits further on 21 QTLs were investigated by three GGM approaches including: (i) lasso-based neighborhood selection in combination with a stability approach to regularization selection, (ii) the PC-skeleton algorithm and (iii) the Lasso in combination with stability selection, and then followed by the QPSO algorithm. The inferred dependency network which, though not essentially representing biological pathways, suggests how the effects of allele substitutions propagate through multilevel phenotypes. Such simultaneous study of the underlying genetic architecture and multifactorial interactions is expected to enhance the prediction and manipulation of complex traits. And it is applicable to a range of population structures, including offspring populations from crosses between inbred parents and outbred parents, association panels and natural populations. In chapter 4, we report a novel method for linkage map construction using probabilistic graphical models. It has been shown that linkage map construction can be hampered by the presence of genotyping errors and chromosomal rearrangements such as inversions and translocations. Our proposed method is proven, both theoretically and practically, to be effective in filtering out markers that contain genotyping errors. In particular, it carries out marker filtering and ordering simultaneously, and is therefore superior to the standard post-hoc filtering using nearest-neighbour stress. Furthermore, we demonstrate empirically that the proposed method offers a promising solution to genetic map construction in the case of a reciprocal translocation. In the domain of PGMs, Bayesian networks (BNs) have proven, both theoretically and practically, to be a promising tool for the reconstruction of causal networks. In particular, the PC algorithm and the Metropolis-Hastings algorithm, which are representatives of mainstream methods to BN structure learning, are reported to have been successfully applied to the field of biology. In view of the fact that most biological systems exist in the form of random network or scale-free network, in chapter 5 we compare the performance of the two algorithms in constructing both random and scale-free BNs. Our simulation study shows that for either type of BN, the PC algorithm is superior to the M-H algorithm in terms of timeliness; the M-H algorithm is preferable to the PC algorithm when the completeness of reconstruction is emphasized; but when the fidelity of reconstruction is taken into account, the better one of the two algorithms varies from case to case. Moreover, whichever algorithm is adopted, larger sample sizes generally permit more accurate reconstructions, especially in regard to the completeness of the resulting networks. Finally, chapter 6 presents a further elaboration and discussion of the key concepts and results involved in this thesis.",2017,
Recognition and Detection of Two-Person Interactive Actions Using Automatically Selected Skeleton Features,"Recognition and detection of interactive actions performed by multiple persons have a wide range of real-world applications. Existing studies on the human activity analysis focus mainly on classifying video clips of simple actions performed by a single person, whereas the problem of understanding complex human activities with causal relationships between two people has not been sufficiently addressed yet. In this paper, we employ systematically organized skeleton features enhanced with directional features, and utilize sparse-group lasso to automatically choose discriminative factors that help in dealing with interactive action recognition and real-time detection tasks. Experiments on two person interaction datasets demonstrate the superiority of our approach to the state-of-the-art methods.",2018,IEEE Transactions on Human-Machine Systems
Comparing abyssal nematode assemblages of physically disturbed and adjacent sites of the eastern equatorial Pacific,"The nematode assemblages of experimentally impacted and adjacent sediments in abyssal depths of the eastern equatorial Pacific were investigated seven years after a physical disturbance was set. A total of 3048 nematodes belonging to 68 genera and 26 families were identified. Abundance data were subjected to univariate and multivariate statistical analyses, which discriminate between sites based on their faunistic attributes. The nematode fauna at both disturbed and control sites was dominated by specimens belonging to the genera Acantholaimus, Chromadorita, Thalassomonhystera, Desmoscolex, Halalaimus and Diplopeltula. These genera contribute to about 55 % and 50 % of total nematode fauna in the disturbed and control sites, respectively. The mean relative abundance of the dominant genus Acantholaimus amounted to about 20 %. Generic diversity, evenness and richness at the undisturbed sites do not significantly differ from the corresponding median values at the disturbed sites. Mean k-dominance curves show differences in community structure between treatments. Ordination of O- and OO-transformed family abundances revealed groupings of the disturbed and undisturbed samples (significant at the 5 % level), whereas ordination of genus abundances did not. Sample variability was investigated by inspection of the relationship between variance and mean abundance of genera and families in each sample group and by calculating the comparative Index of Multivariate Dispersion (IMD). There is a clear increase in the standard deviation for a given mean of genus or family abundances at the disturbed sites. A higher variability among the disturbed samples, however, does not appear to be true in the multivariate sense.",2001,
Physical properties of Thalassosols in the coastal zone of the Sea of Japan,Particle-size distribution and physical properties of the soils of coastal lowlands in the Russian part of the coastal zone of the Sea of Japan are analyzed. These soils are referred to as a specific group of Thalasso- sols. Regional peculiarities of Thalassosols are considered in the context of global variability in the properties of coastal soils.,2000,Eurasian Soil Science
"Factors affecting feelings of justice in biodiversity conflicts: Toward fairer jaguar management in Calakmul, Mexico","Abstract Conservation focuses on environmental objectives, but neglecting social concerns can lead to feelings of injustice among some actors and thus jeopardise conservation aims. Through a case study on a biodiversity conflict around jaguar management in Southern Mexico, we explored actors' feelings of injustice and their associated determinants. We employed a framework distinguishing four dimensions of justice: recognition, ecological, distributive and procedural. By conducting and analysing 235 interviews with farmers and ranchers, we investigated what drive their feeling of injustice, namely their perceptions of the injustice itself, individual characteristics and interactions with their environment. The participants selected 10 statements representing criteria characterizing their feeling of justice toward jaguar management, which they compared using pair-wise comparisons. A pioneering statistical analysis, BTLLasso, revealed that self-interest assumptions were not upheld; feelings of injustice were only weakly influenced by experience of depredation. Feelings of injustice were influenced mainly by factors related to actors' intra-and inter-group relationships (e.g. perception of collective responsibility, perceived coherence in the group to which they identified). This nuanced understanding of how people build their perception of justice can inform fairer and more effective conservation approaches. Whilst details will be context specific, it emerged that building relationships and enabling debate over ecological responsibilities are important and conservation efforts should go beyond merely offering financial compensation. We conclude that perception of justice is a neglected but important aspect to include in integrative approaches to managing biodiversity conflicts, and that novel mixed methods can advance both conceptual and applied understanding in this area.",2019,Biological Conservation
The social origins of property and contract: a study of East Africa before 1918,"The thesis examines the social basis of the property and 
contractual relations of social groups in German East Africa. Chapter 1 oonsiders property relations arising principally from the labour of the producer. Social groups characterised by a communal mode of production are subdivided into shifting and stable sub-forms. In the first form, production units comprise production communities and family work-teams. In contrast to Meillassoux's study of the Guro, property relations are realised atthe level of the work-team. Land tenure in the two sub-forms differs, reflecting distinct practices in agriculture and labour organisation. Chapter 2 examines property relations arising from the direct appropriation of surplus labour by non-producers. Tributary and feudal modes of production are distinguished. Forms of tribute are examined. The 'bundle of rights' concept and Honore's theory of ownership are criticised. Chapter 3 concerns the social dissolution of the two previous forms of property due to the growth of commodity relations. Forms of sale, lease and mortgage are examined. The notion of 'absolute title' is analysed and comparisons with English Law made. Chapter 4 is a theoretical study of forms of exchange and corresponding legal relations. Chapter 5 applies aspects of the theory to contracts in East Africa. Contracts were generally not enforced. The significant point in the emergence of a law of contract was in debt relations. Generally loans were made without interest. In this case there is no distinction between restitution and enforcement of a promise. Instances of charging of interest are found where trade was developed. The Islamic rule against usury was found on the coast, but numerous exceptions developed. The enforcement of interest necessarily implies the enforcement of a promise and hence the emergence of a law of contract.",1980,
The Advantage of Juvenile Coloration in Reef Fishes a Dissertation Submitted to the Graduate Division of the University of Hawai'i in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy in Zoology,"Juvenile reef fishes often have a color pattern different from that of adults. It has been theorized that this reduces the aggression received by juveniles from adult conspecifics. This was tested using two species of Labroides cleaning wrasses in which certain-sized individuals can quickly shift back and forth between the adult and juvenile color patterns. Adult Labroides phthirophagus has the same single-male grouping social structure as previously described for L. dimidiatus. Small L. phthirophagus and L. dimidiatus in juvenile coloration shifted to adult coloration when isolated and then quickly shifted back to juvenile coloration when chased by an adult conspecific female. In L. phthirophagus the adult females attacked small cleaners more frequently when they displayed the adult color pattern, indicating that juvenile coloration gives some protection from conspecific aggression. Two other species oflabrids, Thalassoma duperrey and Coris gaimard, showed the ability to shift back to juvenile coloration when aggression was received from con specific adults, although the shift was not nearly as rapid as seen in Labroides species. Dascyllus albisella and Zebrasomajlavescens, common reef fishes, preferred to solicit cleaning (by posing) from the adult-colored L. phthirophagus, indicating that some hosts prefer the adult color pattern. Small L. phthirophagus shifted to adult coloration more quickly when starved than when provided with host fish on which to feed, indicating that the coloration shift is motivated by hunger.",2010,
Predicting frequent ED use by people with epilepsy with health information exchange data,"Objectives:To describe (1) the predictability of frequent emergency department (ED) use (a marker of inadequate disease control and/or poor access to care), and (2) the demographics, comorbidities, and use of health services of frequent ED users, among people with epilepsy. Methods:We obtained demographics, comorbidities, and 2 years of encounter data for 8,041 people with epilepsy from a health information exchange in New York City. Using a retrospective cohort design, we explored bivariate relationships between baseline characteristics (year 1) and subsequent frequent ED use (year 2). We then built, evaluated, and compared predictive models to identify frequent ED users (â‰¥4 visits year 2), using multiple techniques (logistic regression, lasso, elastic net, CART [classification and regression trees], Random Forests, AdaBoost, support vector machines). We selected a final model based on performance and simplicity. Results:People with epilepsy who, in year 1, were adults (rather than children or seniors), male, Manhattan residents, frequent users of health services, users of multiple health systems, or had medical, neurologic, or psychiatric comorbidities, were more likely to frequently use the ED in year 2. Predictive techniques identified frequent ED visitors with good positive predictive value (approximately 70%) but poor sensitivity (approximately 20%). A simple strategy, selecting individuals with 11+ ED visits in year 1, performed as well as more sophisticated models. Conclusions:People with epilepsy with 11+ ED visits in a year are at highest risk of continued frequent ED use and may benefit from targeted intervention to avoid preventable ED visits. Future work should focus on improving the sensitivity of predictions.",2015,Neurology
"How to relax hypotheses on the LASSO and the Dantzig Selector, and application to the transductive context","We consider the linear regression problem, where the number $p$ of covariates is possibly larger than the number $n$ of observations $(x_{i},y_{i})_{i\leq i \leq n}$, under sparsity assumptions. On the one hand, several methods have been successfully proposed to perform this task, for example the LASSO in \cite{Tibshirani-LASSO} or the Dantzig Selector in \cite{Dantzig}. On the other hand, consider new values $(x_{i})_{n+1\leq i \leq m}$. If one wants to estimate the corresponding $y_{i}$'s, one should think of a specific estimator devoted to this task, referred by Vapnik as a ""transductive"" estimator. This estimator may differ from an estimator designed to the more general task ""estimate on the whole domain"". In this work, we propose a generalized version both of the LASSO and the Dantzig Selector, based on the geometrical remarks about the LASSO in previous works. The ""usual"" LASSO and Dantzig Selector, as well as new estimators interpreted as transductive versions of the LASSO, appear as special cases. These estimators are interesting at least from a theoretical point of view: we can give theoretical guarantees for these estimators under hypotheses that are relaxed versions of the hypotheses required in the papers about the ""usual"" LASSO. These estimators can also be efficiently computed, with results comparable to the ones of the LASSO.",2009,arXiv: Statistics Theory
Pelvic floor imaging: comparison between magnetic resonance imaging and conventional defecography in studying outlet obstruction syndrome,"PurposeThis study prospectively compared the diagnostic capabilities of magnetic resonance (MR) imaging with conventional defecography (CD) in outlet obstruction syndrome.Materials and methodsNineteen consecutive patients with clinical symptoms of outlet obstruction underwent pelvic MR examination. The MR imaging protocol included static T2-weighted fast spin-echo (FSE) images in the sagittal, axial and coronal planes; dynamic midsagittal T2-weighted single-shot (SS)-FSE and fast imaging employing steady-state acquisition (FIESTA) cine images during contraction, rest, straining and defecation. MR images (including and then excluding the evacuation phase) were compared with CD, which is considered the reference standard.ResultsComparison between CD and MR with evacuation phase (MRWEP) showed no significant differences in sphincter hypotonia, dyssynergia, rectocele or rectal prolapse and significant differences in descending perineum. Comparison between CD and MR without evacuation phase (MRWOEP) showed no significant differences in sphincter hypotonia, dyssynergia or enterocele but significant differences in rectocele, rectal prolapse and descending perineum. Comparison between MRWEP and MRWOEP showed no significant differences in sphincter hypotonia, dyssynergia, enterocele or descending perineum but significant differences in rectocele, rectal prolapse, peritoneocele, cervical cystoptosis and hysteroptosis.ConclusionsMR imaging provides morphological and functional study of pelvic floor structures and may offer an imaging tool complementary to CD in multicompartment evaluation of the pelvis. An evacuation phase is mandatory.RiassuntoObiettivoScopo del presente lavoro Ã¨ stato confrontare prospettivamente le capacitÃ  diagnostiche della risonanza magnetica (RM) con quelle della defecografia tradizionale (DT) nello studio della sindrome da defecazione ostruita.Materiali e metodiDiciannove pazienti consecutivi con defecazione ostruita sono stati sottoposti ad RM della pelvi. Sono state acquisite sequenze statiche fast spin echo (FSE)-T2-pesate sui piani sagittale, assiale e coronale e sequenze dinamiche single shot fast spin echo (SSFSE) e fast imaging employing steady-state acquisition (FIESTA) sul piano sagittale mediano durante contrazione dello sfintere anale, riposo, ponzamento, defecazione. Le immagini RM (prima includendo, poi escludendo la fase di evacuazione) sono state confrontate con la DT considerata come standard di riferimento.RisultatiIl confronto DT vs RM con fase di evacuazione (RMCE) ha evidenziato differenze statisticamente non significative nellâ€™ipotonia sfinteriale, dissinergia, rettocele, prolasso rettale, enterocele e differenze significative nel perineo discendente. Il confronto DT vs RM senza fase di evacuazione (RMSE) ha evidenziato differenze non significative nellâ€™ipotonia sfinteriale, dissinergia, enterocele e differenze significative nel rettocele, prolasso rettale, perineo discendente. Il confronto RMCE vs RMSE ha evidenziato differenze non significative nellâ€™ipotonia sfinteriale, dissinergia, enterocele, perineo discendente e differenze significative nel rettocele, prolasso rettale, peritoneocele, cervicocistoptosi, isteroptosi.ConclusioniLa RM consente di effettuare uno studio morfologico e funzionale del pavimento pelvico; puÃ² rappresentare un esame complementare alla DT nella valutazione multicompartimentale della pelvi. La fase di evacuazione Ã¨ fondamentale.",2012,La radiologia medica
Statistical models for multi-step-ahead forecasting of fine particulate matter in urban areas,"Abstract In recent years, the atmospheric pollution in most metropolitan cities has become a crisis and the necessity of air quality forecasting has increased. Among different air pollutants, PM2.5 is considered as the major air pollutant in urbanized regions, especially because of serious harmful health effects on human being. So, there is an urgent need to develop air quality forecast programs capable of providing accurate predictions over a long future horizon. Predicting PM2.5 concentrations for several steps ahead of time is of great interest, especially in decision-making related to control policies and emergency measures such as traffic limitations, school closures, or temporarily shutting down major polluting industrial units. In this paper, commonly used multi-step ahead prediction strategies, including Recursive (Rec), Direct (Dir), Direct-Recursive (DirRec), Multi-Input Multi-Output (MIMO) and Direct-MIMO (DIRMO) along with Autoregressive integrated moving average with exogenous variables (ARIMAX) and Multi-Layer Perceptron (MLP) modelling techniques are examined. Also, the independent variables are considered as time series variables and are forecasted using ARIMA/MLP model in order to be used for prediction of the dependent variables in multi-steps ahead of time. The experimental study is performed using PM2.5 data in Mashhad, Iran. Daily PM2.5 forecasts for this city is provided for the next 10 days. Four different feature selection methods are also implemented and compared. The results indicate that recursive strategy with LASSO feature selection in ARIMAX model overcomes in most of time steps.",2019,Atmospheric Pollution Research
Digital narrative with mobile devices: An experience for the emotional education,"This work present a educational experience about digital narrative with mobile devices and emotional education developed at the Art School â€œPancho Lassoâ€, inside the Language and Audiovisual Media cycle. The objective of this experience was to work on the specific competences of audiovisual communication and creation of specific interactive products trough the creation of digital narratives, and at the same time working on transversal key competences such as emotional, technological and social abilities.",2012,2012 International Symposium on Computers in Education (SIIE)
FRI0768-HPRâ€…Muscle wasting in osteoarthritis model induced by anterior cruciate ligament transection,"Background Osteoarthritis (OA) is a chronic joint disease characterized by progressive loss of articular cartilage and abnormal bone formation. Furthermore, there are changes in periarticular muscles, such as loss of muscle mass, strength and function. These features may contribute to functional impairment among patients. Objectives This study aimed to investigate the molecular pathways involved in muscle wasting in an animal model of OA induced by anterior cruciate ligament (ACL) transection in rats. Methods Female Wistar rats were allocated into two groups: OA (submitted to the ACL transection; n=9) and SHAM (submitted to surgical procedures without ACL transection; n=8) [1]. Spontaneous exploratory locomotion, nociception and body weight of animals were evaluated weekly. Twelve weeks after the disease induction, animals were euthanized and the right knee joints were collected for further confirmation of the disease by histopathology, accordingly to OARSI histologic scoring system [2]. Gastrocnemius muscle from the right hind paw were dissected and weighed. Gastrocnemius was used for evaluation of muscle atrophy [3] and protein expression of myostatin, MuRF-1, MyoD and myogenin. Data were compared by Student's t test or ANOVA followed by Tukey's test or ANOVA followed by Mannâ€“Whitney's U-test. The results are expressed as mean values Â± standard deviation (SD) for symmetric variables and as medians with interquartile range for asymmetric variables. Significance was accepted at P<0.05. Results Histopathology of the right knee joints confirmed the development of the disease in animals from OA group. Gastrocnemius area of animals from OA group had a reduction of about 10% compared to animals from SHAM group. Protein expression of myostatin was increased in OA group, while myogenin expression was decreased. MuRF-1 and MyoD expression was similar in both OA and SHAM groups. Spontaneous exploratory locomotion, nociception, body weight and weight of gastrocnemius showed no difference between OA and SHAM groups. Conclusions Gastrocnemius atrophy in OA induced by ACL transection involves increased protein expression of myostatin and decreased protein expression of myogenin. In this model, muscle wasting may be linked to myostatin-induced deficits in satellite-cell differentiation due to decreased expression of myogenin. ReferencesElsaid KA, Machan JT, Waller K, Fleming BC, Jay GD. The Impact of Anterior Cruciate Ligament Injury on Lubricin Metabolism and the Effect of Inhibiting Tumor Necrosis Factor alpha on Chondroprotection in an Animal Model. Arthritis and Rheumatism. 2009;60(10):2997â€“3006.Gerwin N, Bendele AM, Glasson S, Carlson CS. The OARSI histopathology initiative - recommendations for histological assessments of osteoarthritis in the rat. Osteoarthritis and Cartilage. 2010;18:S24-S34.Filippin LI, Teixeira VN, Viacava PR, Lora PS, Xavier LL, Xavier RM. Temporal development of muscle atrophy in murine model of arthritis is related to disease severity. Journal of Cachexia Sarcopenia and Muscle. 2013;4(3):231â€“8.de Oliveira Nunes Teixeira V, Filippin LI, Viacava PR, de Oliveira PG, Xavier RM. Muscle wasting in collagen-induced arthritis and disuse atrophy. Exp Biol Med (Maywood). 2013;238(12):1421â€“30. Disclosure of Interest None declared",2017,Annals of the Rheumatic Diseases
Calibrated zero-norm regularized LS estimator for high-dimensional error-in-variables regression,"This paper is concerned with high-dimensional error-in-variables regression that aims at identifying a small number of important interpretable factors for corrupted data from many applications where measurement errors or missing data can not be ignored. Motivated by CoCoLasso due to Datta and Zou \cite{Datta16} and the advantage of the zero-norm regularized LS estimator over Lasso for clean data, we propose a calibrated zero-norm regularized LS (CaZnRLS) estimator by constructing a calibrated least squares loss with a positive definite projection of an unbiased surrogate for the covariance matrix of covariates, and use the multi-stage convex relaxation approach to compute the CaZnRLS estimator. Under a restricted eigenvalue condition on the true matrix of covariates, we derive the $\ell_2$-error bound of every iterate and establish the decreasing of the error bound sequence, and the sign consistency of the iterates after finite steps. The statistical guarantees are also provided for the CaZnRLS estimator under two types of measurement errors. Numerical comparisons with CoCoLasso and NCL (the nonconvex Lasso proposed by Poh and Wainwright \cite{Loh11}) demonstrate that CaZnRLS not only has the comparable or even better relative RSME but also has the least number of incorrect predictors identified.",2018,arXiv: Optimization and Control
"CaracterizaciÃ³n morfolÃ³gica de hongos fitopatÃ³genos en el cultivo de cebolla larga (allium fistulosum) sector lasso, cantÃ³n Latacunga, Cotopaxi 2015","The development of this present work is the morphological characterization of pathogenic fungus on the green onions crop (Allium fistulosum) from Lasso sector with coordinates: 0Â° 45' 11.30"" latitude S, 78Â° 36' 39.53"" longitude W, to a height of 2850 mnsm; in the Latacunga canton, Cotopaxi province, 2015; as the research results were determined that the phytopathogenic fungus is causing greater impact on crop production of long onion (Allium fistulosum). It is dominated Mildiu (Peronospora destructo.). can cause yield reductions of 30% to 70%. This was reached by making a determination of field, itself that was based on own criterion and bibliographic help got. Peronospora destructor is a causative pathogen of a disease whose characteristic symptom. It is the appearance on the leaves at oval or cylindrical areas of green, yellow, pale brown color. Initially, the symptoms can appear on the adult leaves, and is got a long, dull pale stain. 
The experimental work was made in the laboratory implemented of the Latacunga city, with coordinates: 0ï‚° 55' 44.8"" latitude S, 78Â° 37' 24.2"" longitude W, to a height of 2850 mnsm, place which is performed the characterization macro structure, themselves that are presented at beginning a mycelium of white color, itself which was developed to the surrounded point, all crop medium, itself which its mycelium took a greyish color. 
Themselves that were looked with an Olympus CX31 trinocular microscope, coupled with an INFINITY 1-2CB camera with increases of 40x, 100x, 200x, 1000x, It was characterized by Peronospora destructor fungus, their micro structures are characterized by branched sporangiophores not accepted and from purplish colors, with a length of 100.42 Î¼m and 13.56 Î¼m wide, and as soon as its life cycle, this gender has spores with dimensions of 9.62 Î¼m, into average to fourth day of infection.",2015,
"PalinologÃ­a estadÃ­stica en el CretÃ¡cico de la Cuenca Austral, Plataforma Continental Argentina. I. Seis perforaciones del Ã¡rea Magallanes","A statistical study of palynomorph groups found in six offshore wells of the Magallanes area in the Austral Basin is here presented. All samples are sidewall cores. The following groups have been considered: E (pteridophytes and bryophytes), Ci (cicatricose spores), G (gleicheniaceous spores), C ( Classopollis ), Ca ( Callialasporites ), P (other Podocarpaceae), Pt (pteridosperms of the Vitreisporites type and monocolpate pollen grains of cycadophyta and/or ginkgophyta), Cy ( Cyclusphaera, Balmeiopsis & Araucariacites ) and A (angiosperms). A separate count was devoted to marine vs. continental palynomorphs (C/M) and the pterophytes/ gymnosperms/angiosperms relationship (H/G/A). Percentages of each group are presented for all six wells, and their significance analyzed. A correlation of the lower sections of most wells with the Early Cretaceous Springhill Formation and the Baquero Group of southern Argentina and Chile is suggested. One well (MFJ-8) cuts strata of Late Cretaceous age as suggested by the finding of known microplankton taxa that were mentioned elsewhere.",2014,
Interregional cytogenetic comparisons in Halichoeres and Thalassoma wrasses (Labridae) of coastal and insular regions of the southwestern Atlantic.,"The distribution patterns of marine biodiversity are complex, resulting from vicariant events and species dispersion, as well as local ecological and adaptive conditions. Furthermore, the wide geographic distribution of some species may be hindered by biogeographical barriers that can interfere in the gene flow. Cytogenetic analyses in marine fishes, especially those involving populations in small remote insular environments, remain scarce. In the Western Atlantic, species of wrasses from the genera Halichoeres and Thalassoma occur in biogeographic arrangements that make it possible to analyze cytogenetic patterns between coastal and widely separated island populations. Species of these genera were punctually analyzed in some Atlantic regions. In this study, we compared several chromosomal features, such as karyotype macrostructure, heterochromatic patterns, patterns of base-specific fluorochromes, Ag-NORs, and 18S and 5S ribosomal sites in Thalassoma noronhanum, Halichoeres poeyi, and Halichoeres radiatus individuals from distinct coastal or insular regions of Atlantic. Notably, all of them are characterized by multiple 18S and 5S rDNA sites with syntenic arrangements in some chromosome pairs. Individuals of T. noronhanum (between the insular regions of Rocas Atoll and Fernando de Noronha Archipelago - FNA) and H. poeyi (coastal areas from Northeastern Brazil) show no detectable differences among their cytogenetic patterns. On the other hand, H. radiatus from FNA and SÃ£o Pedro and SÃ£o Paulo Archipelago exhibit differences in the frequency of rDNA sites that could suggest some level of population structuring between these insular regions. Interregional cytogenetic inventories of marine species with wide geographic distribution need to be rapidly expanded. These data will allow a better understanding of the level of chromosomal stability between vast oceanic spaces, which may be less than previously thought.",2017,Genetics and molecular research : GMR
Lasso Regularization Paths for NARMAX Models via Coordinate Descent,We propose a new algorithm for estimating NARMAX models with $L_{1}$ regularization for models represented as a linear combination of basis functions. Due to the $L_{1}$-norm penalty the Lasso estimation tends to produce some coefficients that are exactly zero and hence gives interpretable models. The novelty of the contribution is the inclusion of error regressors in the Lasso estimation (which yields a nonlinear regression problem). The proposed algorithm uses cyclical coordinate descent to compute the parameters of the NARMAX models for the entire regularization path. It deals with the error terms by updating the regressor matrix along with the parameter vector. In comparative timings we find that the modification does not reduce the computational efficiency of the original algorithm and can provide the most important regressors in very few inexpensive iterations. The method is illustrated for linear and polynomial models by means of two examples.,2018,2018 Annual American Control Conference (ACC)
Development and validation of a radiomics nomogram for identifying invasiveness of pulmonary adenocarcinomas appearing as subcentimeter ground-glass opacity nodules.,"The aim of the present study was to develop and validate a radiomics-based nomogram for differentiation of pre-invasive lesions from invasive lesions that appearing as ground-glass opacity nodules (GGNs) â‰¤10â€‰mm (sub-centimeter) in diameter at CT. A total of 542 consecutive patients with 626 pathologically confirmed pulmonary subcentimeter GGNs were retrospectively studied from October 2011 to September 2017. All the GGNs were divided into a training set (nâ€‰=â€‰334) and a validation set (nâ€‰=â€‰292). Researchers extracted 475 radiomics features from the plain CT images; a radiomics signature was constructed with the least absolute shrinkage and selection operator (LASSO) based on multivariable regression in the training set. Based on the multivariable logistic regression model, a radiomics nomogram was developed in the training set. The performance of the nomogram was evaluated with respect to its calibration, discrimination, and clinical-utility and this was assessed in the validation set. The constructed radiomics signature, which consisted of 15 radiomics features, was significantly associated with the invasiveness of subcentimeter GGNs (Pâ€‰<â€‰0.0001 for both training set and validation set). To build the nomogram model, radiomics signature and mean CT value were used. The nomogram model demonstrated good discrimination and calibration in both training set (C-index, 0.716 [95% CI, 0.632 to 0.801]) and validation set (C-index, 0.707 [95% CI, 0.625 to 0.788]). Decision curve analysis (DCA) indicated that radiomics-based nomogram was clinically useful. A radiomics-based nomogram that incorporates both radiomics signature and mean CT value is constructed in the study, which can be conveniently used to facilitate the preoperative individualized prediction of the invasiveness in patients with subcentimeter GGNs.",2019,European journal of radiology
A non-linear approximation to the distribution of total expenditure distribution of cruise tourists in Uruguay,"Abstract This study contributes to the literature on the determinants of tourism spending on cruises at a microeconomic level, through the application of innovative methodologies framed within the machine learning literature. The objective is to study the distribution of the total expenditure of cruise passengers in Uruguay, using data of the 2016â€“2017 cruise season survey (collected by the Ministry of Tourism of Uruguay). Due to the nature of this variable, we implement a two stages modeling strategy. In the first stage, we model the probability of spending, and in the second, the strictly positive spending. The paper analyze the distribution of conditional expenditure to a set of sociodemographic, travel, contextual and satisfaction variables applying non-linear regression techniques with Lasso penalty and nonparametric techniques such as Random Forest. The empirical results show that the key variables that determine the average spending of cruise tourists are their residence and the port of arrival of the cruise. The analysis of the predictive performance of the models (applied through a training sample and a test sample) shows that Random Forest method has the greater predictive capacity. Finally, the importance variable is analyzed by Random Forest.",2018,Tourism Management
Origin of the Word â€˜Neutronâ€™,"THE word â€˜neutronâ€™ has been attributed to Rutherford by Glasson1 and to W. D. Harkins2 by Glasstone3. It appears likely that it was not used by either Rutherford or Hawkins before about 1920. In both cases, the neutron was a hypothetical combination of a hydrogen nucleus (also called a â€˜positive electronâ€™ or â€˜protonâ€™) and an ordinary negative electron.",1961,Nature
"Joint support recovery under high-dimensional scaling: Benefits and perils of â„“ 1,âˆž -regularization","Given a collection of r â‰¥ 2 linear regression problems in p dimensions, suppose that the regression coefficients share partially common supports. This set-up suggests the use of l1/lâˆž-regularized regression for joint estimation of the p x r matrix of regression coefficients. We analyze the high-dimensional scaling of l1/lâˆž-regularized quadratic programming, considering both consistency rates in lâˆž-norm, and also how the minimal sample size n required for performing variable selection grows as a function of the model dimension, sparsity, and overlap between the supports. We begin by establishing bounds on the lâˆž-error as well sufficient conditions for exact variable selection for fixed design matrices, as well as designs drawn randomly from general Gaussian matrices. These results show that the high-dimensional scaling of l1/lâˆž-regularization is qualitatively similar to that of ordinary l1-regularization. Our second set of results applies to design matrices drawn from standard Gaussian ensembles, for which we provide a sharp set of necessary and sufficient conditions: the l1/lâˆž-regularized method undergoes a phase transition characterized by the rescaled sample size Î¸1,âˆž(n,p, s, Î±) = n/{(4 - 3Î±)s log(p - (2 - Î±) s)}. More precisely, for any Î´ > 0, the probability of successfully recovering both supports converges to 1 for scalings such that Î¸1,âˆž â‰¥ 1 + Î´, and converges to 0 for scalings for which Î¸1,âˆž â‰¤ 1-Î´. An implication of this threshold is that use of l1,âˆž-regularization yields improved statistical efficiency if the overlap parameter is large enough (Î± > 2/3), but performs worse than a naive Lasso-based approach for moderate to small overlap (Î± < 2/3). We illustrate the close agreement between these theoretical predictions, and the actual behavior in simulations.",2008,
Viennese Classical Masses,"The present issue includes several articles touching upon the sacred music of Viennese classicism. This provides an opportunity to reflect upon questions that arise concerning that repertory. These have been persistent questions, asked in their own time, in succeeding generations, and even in the present. The fundamental question is one that pertains to the church music of our own time as well: to what extent can the music of the church adopt the idioms and procedures of the surrounding secular musical world? We read complaints from the eighteenth century that the church music had become too operatic, that it did not respect the conventional distinctions between music of the church, chamber, and theater. Yet masses of Haydn and Mozart particularly, but also of other composers--Schubert, Michael Haydn, Weber, and even Beethoven--have had a stable place in the repertories of certain large city churches, particularly in Europe, but also in the United States; so it will be useful to consider the issues surrounding these works to come to an understanding of their use in the sacred liturgy. The focus should be upon the normative works, not the curious exceptions. For example, there are certain masses of the type missa brevis in which the texts of the longer movements, particularly the Credo, are ""telescoped,"" the text is divided among the four voice parts, which then sing four successive lines of text simultaneously, resulting in a very brief setting of the complete text, but one for which it is difficult for any listener to discern just what is being sung. At the opposite extreme are extended compositions with ample space for the development of each movement; perhaps the most obvious example is the Missa solemnis of Beethoven, a work whose music alone totals a duration of well over an hour. (Recordings show durations of about seventy-two minutes; contrast this with nineteen minutes for Mozart's Missa brevis, K. 275, or his Missa longa, K. 262 at twenty-seven minutes.) The liturgy which included such a work would be quite long, but more important, the music would most likely dwarf the other parts of the liturgy. Whether such works are remotely conceivable for liturgical use is not the point here; rather the question is, are the standard works often sung for the sacred liturgy appropriate for this use? To take a contrasting example: my choir frequently sings masses of Orlando di Lasso; these are mainly parody masses--masses based upon the polyphonic materials of a pre-existing piece, a motet or a chanson. I usually choose a mass based upon a motet, since the borrowed material is more securely sacred. Some of Lasso's masses use a borrowed chanson so transparently as to raise the question of whether their sacred character is compromised by it. Yet, others show striking differences from the secular piece. For example, Lasso's Missa Il me suffit: the chanson is a simple piece, very homophonic with considerable repetition. The mass uses the tune of the chanson, but incorporates it into a relatively complex contrapuntal texture. For anyone who knows the chanson, the difference between the secular and sacred versions is quite clear; the elements of the secular have been transformed into a sacred work, have been set aside to sacred purposes and distinguished from the secular by a remarkable change in musical style. (1) The questions are similar for the Viennese classical masses: are there distinguishing features that set off the style of orchestrally accompanied solo, vocal, and choral music sufficiently to maintain the sacred character needed for use in the liturgy? First, a fundamental issue should be cleared up. These works are often called ""concert Masses,"" placing them in a category of works such as the War Requiem of Benjamin Britten or the Mass of Leonard Bernstein, implying that they were composed for performance in a concert rather than in a Mass. Nothing could be farther from the truth; they were composed for and regularly performed for the liturgy. â€¦",2009,Sacred Music
Multi-source models for civil unrest forecasting,"Civil unrest events (protests, strikes, and â€œoccupyâ€ events) range from small, nonviolent protests that address specific issues to events that turn into large-scale riots. Detecting and forecasting these events is of key interest to social scientists and policy makers because they can lead to significant societal and cultural changes. We forecast civil unrest events in six countries in Latin America on a daily basis, from November 2012 through August 2014, using multiple data sources that capture social, political and economic contexts within which civil unrest occurs. The models contain predictors extracted from social media sites (Twitter and blogs) and news sources, in addition to volume of requests to Tor, a widely used anonymity network. Two political event databases and country-specific exchange rates are also used. Our forecasting models are evaluated using a Gold Standard Report, which is compiled by an independent group of social scientists and subject matter experts. We use logistic regression models with Lasso to select a sparse feature set from our diverse datasets. The experimental results, measured by F1-scores, are in the range 0.68â€“0.95, and demonstrate the efficacy of using a multi-source approach for predicting civil unrest. Case studies illustrate the insights into unrest events that are obtained with our method. The ablation study demonstrates the relative value of data sources for prediction. We find that social media and news are more informative than other data sources, including the political event databases, and enhance the prediction performance. However, social media increases the variation in the performance metrics.",2016,Social Network Analysis and Mining
Circuits and Circuit Disorders: Approaches to Neuromodulation Call for Papers and New Initiative With the American Neurological Association and the Annals of Neurology,"TheAmericanNeurologicalAssociation (ANA)willhost thesatellite symposiumâ€œCircuitsandCircuitDisorders:Approaches to Neuromodulationâ€onSaturdayevening,September26,2015, in Chicago, Illinois, the evening before the start of the regular scientific program. The symposium is cosponsored by theAnnals of Neurology and JAMANeurology andwill be cochaired by the respectiveeditors,CliffordSaper,MD,PhD,andRogerN.Rosenberg,MD.Wearepleasedwiththisnewrelationshipandlookforwardinfutureyearstodevelopingeducationalprogramswiththe ANA, theAnnals of Neurology, and JAMANeurology. The program features Mahlon DeLong, MD, Emory University, 2014Lasker-DeBakeyClinicalMedicalResearchAward recipient, for his research in developing deep brain stimulation (DBS); Philip Starr,MD, PhD,University of California, San Francisco; Jonathan Mink, MD, PhD, University of Rochester Medical Center; Helen Mayberg, MD, Emory University; and Bryan L. Roth, PhD, University of North Carolina. The scientific program for the symposium represents a comprehensive review of DBS for Parkinson disease since its inception anddevelopment byDrDeLong andhis colleagues, followedbycomprehensivepresentationsof thedystonias,Tourette syndrome, obsessive-compulsive disorder, depression, and chemogenetics using designer receptors exclusively activated by designer drugs (DREADDs). DrDeLongwill review the concepts of circuits, circuit disorders, and associated neurological signs and symptoms. He will emphasize that the introduction of high-frequency DBS more than 2 decades ago, first for tremor and then for Parkinson disease, has led to a renaissance in functional stereotaxic surgery for movement disorders as well as for a wide variety of other neurological and psychiatric disorders. Dr DeLong maintains thatDBS isnotdisease specificbut rather circuit specific, since the same target may be used to treat a variety of movement disorders.1,2 DrStarrwillpresenthisworkoncircuitmechanismsofdystonia using combined cortical and basal ganglia recordings in humansundergoingDBS.Hewill presenthis findings that support the view that generalized dystonia and Parkinson diseasemay have physiologic overlapwith respect tomotor cortex synchronization and resting-state activity. Dr Minkâ€™s presentation will focus on the results of recent studiesofDBS inTourettesyndromeandobsessive-compulsive disorder, current controversies, andemergingdirections,while DrMaybergwilldiscussDBSasanemergingexperimental treatment strategy for patientswith intractablemajor depression. DrRothwill summarizeDREADDs, the chemogeneticplatform thatprovides remote control of neuronal activity in a cell typeâ€“specific and noninvasive manner. He will then highlight applications of this technology as a therapeutic approach for a variety of neurological disorders and how chemogenetic technologies induce the sequential multimodal control of neurons in freely moving animals. JAMA Neurology welcomes manuscripts submitted to us on these subjects by May 1, 2015, so that they can be peer reviewed in the standard manner and be published as an OnlineFirst articleduring the samemonthas the symposiumand subsequently in print as a Theme Issue on â€œCircuits and Circuit Disorders: Approaches to Neuromodulation.â€ RegistrationfortheANAmeetingandahotel reservationcan be obtained by going to http://myana.org/events/ana-2015 -annual-meeting. This symposium is the prologue to an excellent scientific programof the 140thAnnualMeetingof theANA.Wehopeyou will begin this outstanding educational opportunity provided by the ANA by attending this symposium and experiencing a first-rate scientific discussion on neuromodulation and the anticipated future developments in this dynamic and rapidly emerging field of neurology.",2015,JAMA Neurology
A predictive model and socioeconomic and demographic determinants of under-five mortality in Sierra Leone,"Sierra Leone is among the countries that recorded high under-five child mortality rate in the world. To design and implement policies that can address this public health challenge, the present study developed a predictive model of factors that explained under-five mortality in Sierra Leone using the 2008 and 2013 Sierra Leone Demographic and Health Survey (SDHS) datasets. LASSO regression technique was used to select the predictors to build the under-five predictive single-level logit and multilevel logit models. Statistical analyses were performed in the R freeware version 3.6.1. About 588 (10.4%) and 1320 (11.1%) children under five were reported dead in 2008 and 2013, respectively. The significant predictors of under-five mortality in Sierra Leone were the total number of children ever born, number of children under five in the household, mother's birth in the last five years, mother's number of living children, and number of household members, household wealth, maternal contraceptive use and intention, number of eligible women in the household, type of toilet facility, sex of the child, and weight of the child at birth. The study identified certain predictors that deserve policy attention and interventions to strengthen the efforts of creating child welfare and survival atmosphere in Sierra Leone.",2020,Heliyon
Approximate Message Passing,"In this note, I summarize Sections 5.1 and 5.2 of Arian Malekiâ€™s PhD thesis. 1 Notation We denote scalars by small letters e.g. a, b, c, . . ., vectors by boldface small letters e.g. Î»,Î±,x, . . ., matrices by boldface capital letter e.g. A,B,C, . . ., (subsets of) natural numbers by capital letters e.g. N,M, . . .. We denote iâ€™th element of a vector a by ai and (i, j)â€™th entry of a matrix A by Aij . We denote the iâ€™th column (or row) of A by A:,i (or Ai,:). We use Aa,âˆ’i (or Aâˆ’a, i to refer to the aâ€™th row (or iâ€™th column) without the element Aa,i. Also, A T denote the transpose of a matrix A. 2 Basis Pursuit Problem Given measurements y of length n and matrix A of size nÃ—N , we wish to compute s which is the minimizer of Eq. 1. This is known as the basis pursuit problem. Here, || Â· ||1 is the l1-norm. A version of this problem where we allow for errors in the measurements is called basis pursuit denoising problem (aka LASSO), shown in Eq. 2. Here, || Â· ||2 is the l2-norm. BP: min s ||s||1, s.t. y = As (1) BPDN: min s Î»||s||1 + 12 ||y âˆ’As|| 2 2 (2) 3 Posterior Distribution Consider the following posterior distributions in Eq. 3, where the prior distribution p(si) is the Laplace distribution and the likelihood p(ya|s,Aa,:) is the Dirac distribution. p(s|y) âˆ N âˆ",2012,
Scalable Probabilistic Matrix Factorization with Graph-Based Priors,"In matrix factorization, available graph side-information may not be well suited for the matrix completion problem, having edges that disagree with the latent-feature relations learnt from the incomplete data matrix. We show that removing these $\textit{contested}$ edges improves prediction accuracy and scalability. We identify the contested edges through a highly-efficient graphical lasso approximation. The identification and removal of contested edges adds no computational complexity to state-of-the-art graph-regularized matrix factorization, remaining linear with respect to the number of non-zeros. Computational load even decreases proportional to the number of edges removed. Formulating a probabilistic generative model and using expectation maximization to extend graph-regularised alternating least squares (GRALS) guarantees convergence. Rich simulated experiments illustrate the desired properties of the resulting algorithm. On real data experiments we demonstrate improved prediction accuracy with fewer graph edges (empirical evidence that graph side-information is often inaccurate). A 300 thousand dimensional graph with three million edges (Yahoo music side-information) can be analyzed in under ten minutes on a standard laptop computer demonstrating the efficiency of our graph update.",2019,ArXiv
Sparse Regularization for Mixture Problems,"This paper investigates the statistical estimation of a discrete mixing measure $Âµ^0$ involved in a kernel mixture model. Using some recent advances in l1-regularization over the space of measures, we introduce a ""data fitting + regularization"" convex program for estimating $Âµ^0$ in a grid-less manner, this method is referred to as Beurling-LASSO. Our contribution is twofold: we derive a lower bound on the bandwidth of our data fitting term depending only on the support of $Âµ^0$ and its so-called ""minimum separation"" to ensure quantitative support localization error bounds; and under a so-called ""non-degenerate source condition"" we derive a non-asymptotic support stability property. This latter shows that for sufficiently large sample size n, our estimator has exactly as many weighted Dirac masses as the target $Âµ^0$ , converging in amplitude and localization towards the true ones. The statistical performances of this estimator are investigated designing a so-called ""dual certificate"", which will be appropriate to our setting. Some classical situations, as e.g. Gaussian or ordinary smooth mixtures (e.g. Laplace distributions), are discussed at the end of the paper. We stress in particular that our method is completely adaptive w.r.t. the number of components involved in the mixture.",2019,ArXiv
Influence functions for penalized M-estimators,"We study the local robustness properties of general penalized Mestimators via the influence function. More precisely, we propose a framework that allows us to define rigourously the influence function as the limiting influence function of a sequence of approximating estimators. Our approach can deal with nondifferentiable penalized Mestimators and a diverging number of parameters. We show that it can be used to characterize the robustness properties of a wide range of sparse estimators and we derive its form for general penalized Mestimators including lasso and adaptive lasso type estimators. We prove that our influence function is equivalent to a derivative in the sense of distribution theory.",2014,
Discussion of â€œCorrelated variables in regression: Clustering and sparse estimationâ€,"Y = XÎ² + Îµ. Here Y is the response vector in Rn, X is an n Ã— p matrix, Î²0 âˆˆ Rp is the vector of coefficients, and finally Îµ âˆˆ Rn is assumed to be multivariate normal with mean zero and covariance matrix Ïƒ2I. While it has been shown that the lasso, and its many variants, â€œworkâ€ in terms of variable selection and prediction, they work best for near orthogonal cases of X. However, if p > n, correlation among the covariates is obviously inevitable. It is worth pointing out that the fit of the lasso estimator Î²Ì‚ always satisfies",2013,Journal of Statistical Planning and Inference
Nonparametric Greedy Algorithms for the Sparse Learning Problem,"This paper studies the forward greedy strategy in sparse nonparametric regression. For additive models, we propose an algorithm called additive forward regression; for general multivariate models, we propose an algorithm called generalized forward regression. Both algorithms simultaneously conduct estimation and variable selection in nonparametric settings for the high dimensional sparse learning problem. Our main emphasis is empirical: on both simulated and real data, these two simple greedy methods can clearly outperform several state-of-the-art competitors, including LASSO, a nonparametric version of LASSO called the sparse additive model (SpAM) and a recently proposed adaptive parametric forward-backward algorithm called Foba. We also provide some theoretical justifications of specific versions of the additive forward regression.",2009,
Atrial Fibrillation Burden Signature and Near-Term Prediction of Stroke: A Machine Learning Analysis.,"BACKGROUND
Atrial fibrillation (AF) increases the risk of stroke 5-fold and there is rising interest to determine if AF severity or burden can further risk stratify these patients, particularly for near-term events. Using continuous remote monitoring data from cardiac implantable electronic devices, we sought to evaluate if machine learned signatures of AF burden could provide prognostic information on near-term risk of stroke when compared to conventional risk scores.


METHODS AND RESULTS
We retrospectively identified Veterans Health Administration serviced patients with cardiac implantable electronic device remote monitoring data and at least one day of device-registered AF. The first 30 days of remote monitoring in nonstroke controls were compared against the past 30 days of remote monitoring before stroke in cases. We trained 3 types of models on our data: (1) convolutional neural networks, (2) random forest, and (3) L1 regularized logistic regression (LASSO). We calculated the CHA2DS2-VASc score for each patient and compared its performance against machine learned indices based on AF burden in separate test cohorts. Finally, we investigated the effect of combining our AF burden models with CHA2DS2-VASc. We identified 3114 nonstroke controls and 71 stroke cases, with no significant differences in baseline characteristics. Random forest performed the best in the test data set (area under the curve [AUC]=0.662) and convolutional neural network in the validation dataset (AUC=0.702), whereas CHA2DS2-VASc had an AUC of 0.5 or less in both data sets. Combining CHA2DS2-VASc with random forest and convolutional neural network yielded a validation AUC of 0.696 and test AUC of 0.634, yielding the highest average AUC on nontraining data.


CONCLUSIONS
This proof-of-concept study found that machine learning and ensemble methods that incorporate daily AF burden signature provided incremental prognostic value for risk stratification beyond CHA2DS2-VASc for near-term risk of stroke.",2019,Circulation. Cardiovascular quality and outcomes
DegreeCox â€“ a network-based regularization method for survival analysis,"BackgroundModeling survival oncological data has become a major challenge as the increase in the amount of molecular information nowadays available means that the number of features greatly exceeds the number of observations. One possible solution to cope with this dimensionality problem is the use of additional constraints in the cost function optimization. Lasso and other sparsity methods have thus already been successfully applied with such idea. Although this leads to more interpretable models, these methods still do not fully profit from the relations between the features, specially when these can be represented through graphs. We propose DegreeCox, a method that applies network-based regularizers to infer Cox proportional hazard models, when the features are genes and the outcome is patient survival. In particular, we propose to use network centrality measures to constrain the model in terms of significant genes.ResultsWe applied DegreeCox to three datasets of ovarian cancer carcinoma and tested several centrality measures such as weighted degree, betweenness and closeness centrality. The a priori network information was retrieved from Gene Co-Expression Networks and Gene Functional Maps. When compared with Ridge and Lasso, DegreeCox shows an improvement in the classification of high and low risk patients in a par with Net-Cox. The use of network information is especially relevant with datasets that are not easily separated. In terms of RMSE and C-index, DegreeCox gives results that are similar to those of the best performing methods, in a few cases slightly better.ConclusionsNetwork-based regularization seems a promising framework to deal with the dimensionality problem. The centrality metrics proposed can be easily expanded to accommodate other topological properties of different biological networks.",2016,BMC Bioinformatics
Le microcitosi nel bambino: classificazione e approccio diagnostico,"Summary The Authors provide an overview of microcytic anemias. Causes of microcytic anemia inclu- de a wide variety of diseases, the most common being iron-deficiency, impaired haemoglo- bin synthesis, sideroblastic anemias and anemias due to chronic disease. Other less com- mon causes are copper deficiency, lead poisoning and haemosiderosis. A classification of the main microcytic anemias is provided and a diagnostic approach to microcytosis, with and without anemia, based on RDW and MCV is suggested. E un aggiornamento monografico complementare a quello sulla macrocitosi, pubblicato nel 1996: l'anemia sideropenica, la talassemia, la talasso-drepanocitosi, l'infezione cronica, il tumore, l'infezione da Helicobacter pylori, i numerosi ma in- consueti difetti della sintesi dell'eme con le loro caratteristiche.",2001,
Predictive Models of Student Performance for Data-Driven Learning Analytics,"Analytic tools are useful for detecting patterns in education data and providing insights about student performance and learning. This study compared six supervised learning algorithms (linear regression, ridge regression, the lasso, regression trees, random forests regression, gradient boosted regression) and identified features important for predicting student performance. The dataset consisted of N=1044 observations from two secondary schools in Portugal (UCI-MLR, Cortez & Silva, 2008). Performance was assessed by final grades (range: 0-20) in two courses, mathematics and Portugese. The models were fit to training data with 27 independent variables and evaluated on a testing subset. Overall, performance was lower for students in mathematics than Portugese. The models selected a similar set of variables as important for predicting performance: mother's education level, student plans for higher education, and weekly study time were positively related to predicted performance, whereas course subject, school educational support, and romantic relationships were associated with decreased student performance. The models differed in the number, weighting, order and importance given to predictor variables. Linear regression provided a model with 13 predictors. Ridge regression shrank the coefficient estimates toward zero; the lasso performed variables selection for a model with 20 predictors. There was a tradeoff between model complexity and interpretability. The single pruned regression tree provided a simple, interpretable non-linear model with four features. Random forests regression and gradient boosting reduced overfitting, but were more difficult to interpret. Advantages and limitations of the different models are discussed. Applications for educational data mining (EDM) and learning analytics (LA) are considered.",2019,
Learning Latent Variable Gaussian Graphical Model for Biomolecular Network with Low Sample Complexity,"Learning a Gaussian graphical model with latent variables is ill posed when there is insufficient sample complexity, thus having to be appropriately regularized. A common choice is convex â„“1 plus nuclear norm to regularize the searching process. However, the best estimator performance is not always achieved with these additive convex regularizations, especially when the sample complexity is low. In this paper, we consider a concave additive regularization which does not require the strong irrepresentable condition. We use concave regularization to correct the intrinsic estimation biases from Lasso and nuclear penalty as well. We establish the proximity operators for our concave regularizations, respectively, which induces sparsity and low rankness. In addition, we extend our method to also allow the decomposition of fused structure-sparsity plus low rankness, providing a powerful tool for models with temporal information. Specifically, we develop a nontrivial modified alternating direction method of multipliers with at least local convergence. Finally, we use both synthetic and real data to validate the excellence of our method. In the application of reconstructing two-stage cancer networks, ""the Warburg effect"" can be revealed directly.",2016,Computational and Mathematical Methods in Medicine
Estimation of Mean and Covariance of Stochastic Multi-class OD Demands from Classified Traffic Counts,"This paper proposes a new model to estimate the mean and covariance of stochastic multi-class (multiple vehicle classes) origin-destination (OD) demands from hourly classified traffic counts throughout the whole year. It is usually assumed in the conventional OD demand estimation models that the OD demand by vehicle class is deterministic. Little attention is given on the estimation of the statistical properties of stochastic OD demands as well as their covariance between different vehicle classes. Also, the interactions between different vehicle classes in OD demand are ignored such as the change of modes between private car and taxi during a particular hourly period over the year. To fill these two gaps, the mean and covariance matrix of stochastic multi-class OD demands for the same hourly period over the year are simultaneously estimated by a modified lasso (least absolute shrinkage and selection operator) method. The estimated covariance matrix of stochastic multi-class OD demands can be used to capture the statistical dependency of traffic demands between different vehicle classes. In this paper, the proposed model is formulated as a non-linear constrained optimization problem. An exterior penalty algorithm is adapted to solve the proposed model. Numerical examples are presented to illustrate the applications of the proposed model together with some insightful findings on the importance of covariance of OD demand between difference vehicle classes.",2015,Transportation research procedia
Obligate oil-degrading marine bacteria.,"Over the past few years, a new and ecophysiologically unusual group of marine hydrocarbon-degrading bacteria - the obligate hydrocarbonoclastic bacteria (OHCB) - has been recognized and shown to play a significant role in the biological removal of petroleum hydrocarbons from polluted marine waters. The introduction of oil or oil constituents into seawater leads to successive blooms of a relatively limited number of indigenous marine bacterial genera--Alcanivorax, Marinobacter, Thallassolituus, Cycloclasticus, Oleispira and a few others (the OHCB)--which are present at low or undetectable levels before the polluting event. The types of OHCB that bloom depend on the latitude/temperature, salinity, redox and other prevailing physical-chemical factors. These blooms result in the rapid degradation of many oil constituents, a process that can be accelerated further by supplementation with limiting nutrients. Genome sequencing and functional genomic analysis of Alcanivorax borkumensis, the paradigm of OHCB, has provided significant insights into the genomic basis of the efficiency and versatility of its hydrocarbon utilization, the metabolic routes underlying its special hydrocarbon diet, and its ecological success. These and other studies have revealed the potential of OHCB for multiple biotechnological applications that include not only oil pollution mitigation, but also biopolymer production and biocatalysis.",2007,Current opinion in biotechnology
Multivariate Regression with Small Samples: A Comparison of Estimation Methods,"High dimensional multivariate data, where the number of variables approaches or exceeds the sample size, is an increasingly common occurrence for social scientists. Several tools exist for dealing with such data in the context of univariate regression, including regularization methods (i.e., Lasso, Elastic net, Ridge Regression, as well as Bayesian models with spike and slab priors. These methods have not been widely studied in the context of multivariate regression modeling. Thus, the goal of this simulation study was to compare the performance of these methods for high dimensional data with multivariate regression, in which there exist more than one dependent variable. Simulation results revealed that the regularization methods, particularly Ridge Regression, were found to be particularly effective in terms of parameter estimation accuracy and control over the Type I error rate. Implications for practice are discussed. ocial scientists frequently work in contexts with multiple dependent variables of interest, where appropriate data analysis involves the use of multivariate linear models. In some situations, the number of independent variables (p) may approach, or even exceed the sample size (N), leading to what is commonly referred to as high dimensional data. When used with high dimensional data, standard regression estimators, including those associated with multivariate models, yield unstable coefficient estimates with inflated standard errors (BÃ¼hlmann & van de Geer, 2011), leading to reduced statistical power and erroneous conclusions regarding relationships between independent and dependent variables. Furthermore, when p exceeds N, it is simply not possible to obtain estimates for model parameters using standard estimation methods. The problems associated with high dimensional data in the univariate case could be further amplified when the data are multivariate in nature, given that the number of parameters to be estimated is the number of independent variables +1 multiplied by the number of dependent variables. Although prior research has been done focusing on methods for dealing with high dimensional univariate linear models, relatively little work has been done in the context of multivariate linear models. Therefore, the objective of this simulation study was to compare the performance of several methods for handling high dimensional multivariate data with one another, and with standard ordinary least squares (OLS) multivariate regression. First, a description of OLS regression is provided, followed by descriptions of models designed for use in the high dimensional case, including the lasso, elastic net, and ridge regression. Next, descriptions of two Bayesian alternatives for multivariate regression estimation are provided. The research goals and the methodology used to address those goals are then presented, followed by a discussion of the results of the simulation study, and an application of each method to an existing dataset. Finally, the implications of the simulation results, in light of existing research, are discussed.",2017,
Integrative approach for inference of gene regulatory networks using lasso-based random featuring and application to psychiatric disorders,"BackgroundInferring gene regulatory networks is one of the most interesting research areas in the systems biology. Many inference methods have been developed by using a variety of computational models and approaches. However, there are two issues to solve. First, depending on the structural or computational model of inference method, the results tend to be inconsistent due to innately different advantages and limitations of the methods. Therefore the combination of dissimilar approaches is demanded as an alternative way in order to overcome the limitations of standalone methods through complementary integration. Second, sparse linear regression that is penalized by the regularization parameter (lasso) and bootstrapping-based sparse linear regression methods were suggested in state of the art methods for network inference but they are not effective for a small sample size data and also a true regulator could be missed if the target gene is strongly affected by an indirect regulator with high correlation or another true regulator.ResultsWe present two novel network inference methods based on the integration of three different criteria, (i) z-score to measure the variation of gene expression from knockout data, (ii) mutual information for the dependency between two genes, and (iii) linear regression-based feature selection.Based on these criterion, we propose a lasso-based random feature selection algorithm (LARF) to achieve better performance overcoming the limitations of bootstrapping as mentioned above.ConclusionsIn this work, there are three main contributions. First, our z score-based method to measure gene expression variations from knockout data is more effective than similar criteria of related works. Second, we confirmed that the true regulator selection can be effectively improved by LARF. Lastly, we verified that an integrative approach can clearly outperform a single method when two different methods are effectively jointed. In the experiments, our methods were validated by outperforming the state of the art methods on DREAM challenge data, and then LARF was applied to inferences of gene regulatory network associated with psychiatric disorders.",2015,BMC Medical Genomics
Design and Analysis of Statistical Learning Algorithms which Control False Discoveries,"In this thesis, general theoretical tools are constructed which can be applied to develop ma- chine learning algorithms which are consistent, with fast convergence and which minimize the generalization error by asymptotically controlling the rate of false discoveries (FDR) of features, especially for high dimensional datasets. Even though the main inspiration of this work comes from biological applications, where the data is extremely high dimensional and often hard to obtain, the developed methods are applicable to any general statistical learning problem. 
In this work, the various machine learning tasks like hypothesis testing, classification, regression, etc are formulated as risk minimization algorithms. This allows such learning tasks to be viewed as optimization problems, which can be solved using first order optimization techniques in case of large data scenarios, while one could use faster converging second order techniques for small to moderately sized data sets. Further, such a formulation allows us to estimate the first order convergence rates of an empirical risk estimator for any arbitrary learning problem, using techniques from large deviation theory. 
In many scientific applications, robust discovery of factors affecting an outcome or a phe- notype, is more important than the accuracy of predictions. Hence, it is essential to find an appropriate approach to regularize an under-determined estimation problem and thereby control the generalization error. In this work, the use of local probability of false discovery is explored as such a regularization parameter, which forces the optimized solution towards functions with a lower probability to be a false discovery. Again, techniques from large devi- ation theory and the Gibbs principle allow the derivation of an appropriately regularized cost function. 
These two theoretical results are then used to develop concrete applications. First, the problem of multi-classification is analyzed, which classifies a sample from an arbitrary proba- bility measure into a finite number of categories, based on a given training data set. A general risk functional is derived, which can be used to learn Bayes optimal classifiers controlling the false discovery rate. 
Secondly, the problem of model selection in the regression context is considered, aiming to select a subset of given regressors which explains most of the observed variation i.e. perform ANOVA. Again, using techniques mentioned above, a risk function is derived which when optimized, controls the rate of false discoveries. This technique is shown to outperform the popular LASSO algorithm, which can be proven to not control the FDR, but only the FWER. 
Finally, the problem of inferring under-sampled and partially observed non-negative dis- crete random variables is addressed, which has applications to analyzing RNA sequencing data. By assuming infinite divisibility of the underlying random variable, its characterization as being a discrete Compound Poisson Measure (DCP), is derived. This allows construction of a non-parametric Bayesian model of DCPs with a Pitman-Yor Mixture process prior, which is shown to allow for consistent inference under Kullback-Liebler and Renyi divergences even in the under-sampled regime.",2018,
"A new species of Tupuxuara (Thalassodromidae, Azhdarchoidea) from the Lower Cretaceous Santana Formation of Brazil, with a note on the nomenclature of Thalassodromidae","A new species of the sail-crested pterosaur Tupuxuara is described from the Santana Formation of Brazil, Tupuxuara deliradamus sp. nov. The holotype, a partial skull, and a larger, partial skull referred to the same taxon differs from Tupuxuara leonardii by having a nasoantorbital fenestra with an acutely-angled posterior border with a long, straight posterodorsal margin, a reclined cranium, and an orbit situated entirely in the ventral half of the nasoantorbitral fenestra. Unfortunately, neither specimen is comparable with the fragmentary rostrum representing Tupuxuara longicristatus. In addition, resolution of a recent nomenclatural problem over the correct name for the clade containing Tupuxuara and its sister taxon, Thalassodromeus, is provided. Both genera are used by different authors as the nomenclatural basis for the group, but â€œTupuxuaridaeâ€ has never been explicitly erected as a new taxon, and therefore fails to meet ICZN criteria that new taxa are only valid if authors clearly indicate their intention to establish new names. By contrast, â€œThalassodrominaeâ€ was explicitly erected as a name for the Thalassodromeus + Tupuxuara clade, thereby fulfilling all ICZN requirements for naming of a new taxon and making Thalassodromeus stand as the type genus for this group.",2009,Cretaceous Research
Attitudes of Women and Men Towards Contraception in Bobo-Dioulasso,A series of taped interviews in the town of Bobo-Dioulasso in Burkina Faso (formerly Upper Volta) were conducted with 80 women whose child had been born in May and June 1981 and was still alive. The survey took place during the months of July and August 1983 and January 1984. All the women interviewed had a child who was between 25 and 28 months old. The women were selected among the Bobo and the Mossi ethnic groups. The topics discussed in the loosely structured interviews were the circumstances customs desires and delusions which influence the conception of the next child. Latent motivations for avoiding births are different for men and women and both have to be reached by action programs. Traditional spacing behavior remains a primary concern for all. Abstinence is a prescribed form of behavior. Popular interpretation of religion and what is seen as the African tradition remain powerful obstacles to the use of contraception. Contraception is very much seen as a Western import and a culturally diffused behavior. Men seem to have a better knowledge of modern contraception than women. Modern contraception is still taboo. Knowledge of modern contraception is spreading slowly. The 1st roles of contraception may be to replace postpartum abstinence and avoid premarital births. Married women may start to use contraception to space childbearing and young urban unmarried women may need it to postpone pregnancy.,1986,
Towns in a Rural World,"Contents: Preface Part I Introduction: Small towns of hope and glory, Teresa de Noronha Vaz and Peter Nijkamp Towns today and their multifunctional activities, Eveline van Leeuwen. Part II Rural Networks and Partnerships: The role of small and medium-sized towns in local and regional economies, Waldemar Ratajczak Market potential and new firm formation, Jenny Grek, Charlie Karlsson and Johan Klaesson Critique of new economic geography to understand rural development: the influence of corporate strategy, Jose Antonio Porfirio Public-private partnership in small and medium-sized towns, Jose Luis Navarro Espigares and Jose Antonio Camacho Ballesta Social and political determinants of the area of influence of medium-sized cities in Portugal, Ana Paula Barreira. Part III Knowledge Transfers in Rural Environments: Technological transfer in the perspective of town dimension: the case of Oxford and Oxfordshire in the UK, Helen Lawton Smith and John Glasson Divided knowledge on small and medium-sized towns, Tomaz P. Dentinho, Rita D. Coelho and J. Dias Coelho The role of universities for economic development in urban poles, Clive Winters, John Dodd and Keith Harrison The influence of the urban-rural gap on the R&D and innovation potential in Romania, Anca Dachin, Daniela L. Constantin and Zizi Goschin Rural tourism in peripheral areas: evidence from the Portuguese municipality of Almeida, Fernando P. Fonseca and Rui A.R. Ramos. Part IV Urban-Rural Interdependencies: How knowledge on land values influences rural-urban development processes, Emilia Malcata Rebelo From depreciation to appreciation of rural areas: 'beauty idols' in Europe, Aliye Ahu Akgun, Tuzin Baycan and Peter Nijkamp ICT's role in rural areas' neighbouring towns - stakeholders' perception, Zbigniew Florianczyk, Adam Wasilewski and Claudia Chlebek Land-use conflicts and the sharing of resources between urban and agricultural activities in the Greater Paris region: results based on information provided by the daily regional press, Segolene Darly and Andre Torre. Part V Conclusion: Lessons from successful small towns, Teresa de Noronha Vaz, Eveline van Leeuwen and Peter Nijkamp Index.",2016,
Fast User-Guided Single Image Reflection Removal via Edge-aware Cascaded Networks,"Taking photos through a glass window leads to glare or reflection, which might distract the viewer from the scene behind the window. In this paper, we involve user interaction to tackle the ill-posedness of the reflection removal problem. Users are allowed to draw strokes or lassos to indicate the background and reflection layers. Instead of designing hand-crafted features, we propose the edge-aware cascaded networks for reflection removal. The proposed network is a two-stage pipeline. The first stage takes the edge hints converted from user guidance and the image with reflection as input, and then separates the input image into the background and reflection layers. The second stage involves a refinement network to recover the missing details of the background layers. We simulate different types of user guidance, and the networks are trained on simulated data. The cascaded networks are end-to-end and perform with a single feed-forward pass, enabling fast editing. Extensive experimental evaluations demonstrate that the proposed used-guided reflection removal network yields better performance than the state-of-the-art methods on real-world scenarios. Furthermore, we show that novice users can easily generate reflection-free images, and large improvements in reflection removal quality can be obtained in just one minute.",2019,IEEE Transactions on Multimedia
Spatial soundfield reproduction using deep neural networks,"Sparsity-based sound field reproduction algorithms often result in improved localization and larger reproduction region, but also lead to high computational cost. In this work, we present a novel approach for sparse reproduction, where a deep neural network (DNN) is trained to determine the optimal driving signals for a loudspeaker array, given the desired sound field coefficients as the input. We show that when trained using the proposed method, the DNN-based algorithm can outperform existing Lasso-based algorithms in terms of noise sensitivity and computation speed.",2019,
"Osteology and Functional Morphology of the Axial Postcranium of the Marine Sloth Thalassocnus (Mammalia, Tardigrada) with Paleobiological Implications","The gross morphology of the axial postcranium of Thalassocnus is presented here, completing the description of the skeleton of the genus. Thalassocnus is characterized by a low spinous process on C7, a cranially shifted position of the diaphragmatic vertebra, a great number of caudal vertebrae, the morphology of their transverse processes, and the conservation of the craniocaudal length of their centra up to Ca19. Additionally, the late species of Thalassocnus feature cranial articular surfaces of the atlas that are oriented cranioventrally and thoracolumbar vertebrae with spinous processes that are more inclined caudally, shorter craniocaudally, and have a smaller apex than in earlier species. In the late species, the thoracolumbar vertebrae are also characterized by zygapophyseal articulations that are more conspicuously concavo-convex, and by ribs that are affected by osteosclerosis and pachyostosis. Thalassocnus yaucensis additionally differs from the earlier species of the genus in featuring thoracolumbar vertebral centra that are shortened craniocaudally. The morphology of the axial postcranium of Thalassocnus is consistent with a reduced amount of time spent in a terrestrial habitat. Furthermore, the overall body size and extensive and extreme osteosclerosis of Thalassocnus suggest that bottom-walking was part of its modes of swimming. The tail was probably involved in diving and equilibration but did not contribute to propulsion. A downturned position of the head is inferred for the late species of Thalassocnus, and is probably related to grazing activity on the seafloor. The stabilized vertebral column may be related to the digging behavior purported in Thalassocnus. The aquatic functions of the entire skeleton of Thalassocnus are reviewed.",2014,Journal of Mammalian Evolution
Spatio-temporal additive regression model selection for urban water demand,"Understanding the factors influencing urban water use is critical for meeting demand and conserving resources. To analyze the relationships between urban household-level water demand and potential drivers, we develop a method for Bayesian variable selection in partially linear additive regression models, particularly suited for high-dimensional spatio-temporally dependent data. Our approach combines a spike-and-slab prior distribution with a modified version of the Bayesian group lasso to simultaneously perform selection of null, linear, and nonlinear models and to penalize regression splines to prevent overfitting. We investigate the effectiveness of the proposed method through a simulation study and provide comparisons with existing methods. We illustrate the methodology on a case study to estimate and quantify uncertainty of the associations between several environmental and demographic predictors and spatio-temporally varying household-level urban water demand in Tampa, FL.",2019,Stochastic Environmental Research and Risk Assessment
Transcriptomic analysis of xylan utilization systems in Paenibacillus sp. strain JDR-2.,"Xylans, including methylglucuronoxylans (MeGX(n)) and methylglucuronoarabinoxylans (MeGAXn), are the predominant polysaccharidesin hemicellulose fractions of dicots and monocots available for conversion to biofuels and chemicals. Paenibacillus sp. strain JDR-2 (Pjdr2) efficiently depolymerizes MeGX(n) and MeGAX(n) and assimilates the generated oligosaccharides, resulting in efficient saccharification and subsequent metabolism of these polysaccharides. A xylan utilization regulon encoding a cellassociated GH10 (glycoside hydrolase family 10) endoxylanase, transcriptional regulators, ABC (ATP binding cassette) transporters, an intracellular GH67 -glucuronidase, and other glycoside hydrolases contributes to complete metabolism. This GH10/GH67 system has been proposed to account for preferential utilization of xylans compared to free oligo- and monosaccharides. To identify additional genes contributing to MeGX(n) and MeGAXn utilization, the transcriptome of Pjdr2 has been sequenced following growth on each of these substrates as well as xylose and arabinose. Increased expression of genes with different substrates identified pathways common or unique to the utilization of MeGX(n) or MeGAX(n). Coordinate upregulation of genes comprising the GH10/GH67 xylan utilization regulon is accompanied with upregulation of genes encoding a GH11 endoxylanase and a GH115 -glucuronidase, providing evidence for a novel complementary pathway for processing xylans. Elevated expression of genes encoding a GH43 arabinoxylan arabinofuranohydrolase and an arabinose ABC transporter on MeGAX(n) but not on MeGX(n) supports a process in which arabinose may be removed extracellularly followed by its rapid assimilation.Further development of Pjdr2 for direct conversion of xylans to targeted products or introduction of these systems into fermentative strains of related bacteria may lead to biocatalysts for consolidated bioprocessing of hemicelluloses released from lignocellulose.",2015,Applied and environmental microbiology
Mission and Afroâ€brazilian Cultural Reality,"The black speaker tells his story: The lasso was zipping through the woods. ""Run, get him. Don't let them get away."" No one knew where these men had come from. They came running, grabbing everything. They were neither young nor old. They would throw the pots to the ground, overturning and piling everything up right there in the middle of the jungle, in our home. Whoever fled into the depths of the jungle was hunted like a crazy escaped animal about to tear someone to pieces. They threw the lasso at me. I couldn't take another step. I was dragged over the ground behind some animal until I lost my senses. I awoke on the seashore, amidst many others. Some I recognized, others I did not. The silence was heavy and no one could say anything. And to whom would we talk? What would we say? One by one we were thrown aboard an old, filthy ship. Without food, drink or anything. We left everything behind. The ship in the water. People alive, in the midst of vomit and excrement. Eating filth and drinking salt water. Those who died would be thrown into the sea. We didn't know if it was night or day. Mama? Papa? My brothers and sisters? Where were they? How were they? At certain times the Big One would appear. The Big One would come and see who had died and order them to be taken away. One day I arrived here. After living a long time at sea. Without knowing how long I had spent in that horror. What was the land called? No one knew. Braaaaazil, was what they would say. And I stayed. I stayed to tell of the atrocities that were committed. Black men and women tell the story and make history. It is from this view we wish to share the feelings, thoughts, indignation, discoveries, enrichments and losses of the Afro people before the mission's history. This memory of suffering and resentment will accompany us through these pages, since the mission of the Christian churches is part of the scene of terror that we have just told. We believe that it is for this the effort of the Afro community is in the process of historical recuperation, theological reconstruction, re-reading of the Bible and announcement of a God who survived, together with the people in the process of denial and extermination of the African identity and culture. This is why we resist, today we can proclaim it! Mission: denial of life Mission: slavery of the body, salvation of the soul Brazil was the last country in the world to abolish African slavery. Not only did slavery there last the longest, it was also the most cruel ever recorded in history. The church as an institution consented to and legalized slavery. The mission was understood as rescuing souls, condemned to die in sin, in Africa, and save them by teaching them the gospel in the Americas. The logic in the missionary work consisted of passing from free bodies and enslaved souls in Africa to saving enslaved bodies and free souls. This logic is found in the theology of slavery, which was based on two main theological discourses: that of the theology of transmigration and the theology of retribution. The theology of transmigration states that the Africans would need to undergo successive migrations in order to reach their soul's salvation. These migrations consisted of: leaving Africa for America and from America to the Heavenly Land. Slavery was a temporary state necessary to reach salvation. Slavery was part of God's plan to save the Africans. There were three places for them: Africa as hell, the kingdom of the body's captivity and soul; Brazil as purgatory, captive only in body; and Heaven, where ultimate freedom is enjoyed. In the theology of retribution, we find the discourse of patience and submission as forms similar to the sufferings of Christ and achieving happiness in another life. What we must do is give you great comfort with these examples: suffer patiently the works of your status; give many thanks to God for the moderation of captivity to which you are brought; and above all take advantage of it to exchange for freedom and happiness in another life, which does not pass like this one but lives forever. â€¦",1996,International Review of Mission
"Characterization of the fungal flora of dolo, a traditional fermented beverage of Burkina Faso, using MALDI-TOF mass spectrometry","A cross-sectional study was conducted in Bobo-Dioulasso, Burkina Faso, to identify the yeast diversity associated with the manufacture of dolo, a traditional fermented beverage of Burkina Faso. From sixty specimens spread onto chromogenic medium plates, sixty-two strains were isolated then identified using MALDI-TOF analysis. Seven yeast species were identified, Saccharomyces cerevisiae (39%) followed by Pichia manshurica (18%) being the most frequent. Forty-three percent of the samples contained Candida species, notably Candida albicans. In conclusion, the combined use of a chromogenic medium and MALDI-TOF analysis reveals a higher diversity in yeast species present in the dolo than previously thought.",2017,World Journal of Microbiology and Biotechnology
Size dominance regulates tree spacing more than competition within height classes in tropical Cameroon,"Does competition prevail in large size classes of trees in tropical forests? This question is fundamental to our understanding of the demography and dynamics occurring in rain forests. We investigated this question based on an undisturbed late-secondary forest on a 1-ha plot in central Cameroon. Trees were stem-mapped and classified into threesizeclasses:understorey,midstoreyandoverstorey.Thediameteratbreastheightandyearlybiomassincrement were determined as measures of plant growth and performance. Spatial statistics such as pair- and mark-correlation functions were used to detect scale-dependent patterns that could be caused by competition within and between the three size classes. The results revealed a random pattern and spatially uncorrelated measures of plant growth of overstoreytrees.Thissuggeststhatcompetitiveeffectsareofminorimportanceinthelargesizeclassofoverstoreytrees. Likewise, only weak evidence for competition between trees was found within the two lower size classes. However, negativedistancecorrelationswerefoundbetweenthedifferentsizeclasses.Wesuggestthatcompetitionwithinheight classes was relatively low due to the diversity of species with their variable niche differentiations and phenotypic plasticity that may compensate for competitive effects.",2011,Journal of Tropical Ecology
Joint Multi-family Evolutionary Coupling Analysis for Protein Contact Prediction,"Protein contacts contain important information for protein structure and functional study, but contact prediction is very challenging especially for protein families without many sequence homologs. Recently evolutionary coupling (EC) analysis, which predicts contacts by analyzing residue co-evolution in a single target family, has made good progress due to better statistical and optimization techniques. Different from these single-family EC methods that focus on only a single protein family, this paper presents a joint multi-family EC analysis method that predicts contacts of one target family by jointly modeling residue co-evolution in itself and also (distantly) related families with divergent sequences but similar folds, and enforcing their co-evolution pattern consistency based upon their evolutionary distance. To implement this multi-family EC analysis strategy, this paper presents a novel joint graphical lasso method to model a set of related protein families. In particular, we model a set of related families using a set of correlated multivariate Gaussian distributions, the inverse covariance matrix (or precision matrix) of each distribution encoding the contact pattern of one family. Then we co-estimate the precision matrices by maximizing the occurring probability of all the involved sequences, subject to the constraint that the matrices shall share similar patterns. Finally we solve this optimization problem using Alternating Direction Method of Multipliers (ADMM). Experiments show that joint multi-family EC analysis can reveal many more native contacts than single-family analysis even for a target family with 4000-5000 non-redundant sequence homologs, which makes many more protein families amenable to co-evolution-based structure and function prediction.",2013,arXiv: Quantitative Methods
"Thalassobacillus pellis sp. nov., a moderately halophilic, Gram-positive bacterium isolated from salted hides.","A Gram-positive, moderately halophilic and endospore-forming bacterium, designated strain 18OM(T), was isolated from salted animal hides. The cells were rods and produced ellipsoidal endospores at a terminal position. Strain 18OM(T) was motile, strictly aerobic and grew at 0.5-25 % (w/v) NaCl [optimal growth at 10 % (w/v) NaCl], at between pH 5.0 and 9.0 (optimal growth at pH 7.5) and at temperatures between 15 and 45 Â°C (optimal growth at 37 Â°C). Phylogenetic analysis based on 16S rRNA gene sequence comparisons showed that strain 18OM(T) was closely related to species of the genus Thalassobacillus within the phylum Firmicutes. The closest phylogenetic similarity was with Thalassobacillus devorans G-19.1(T) (98.4 %), Thalassobacillus cyri HS286(T) (97.9 %) and Thalassobacillus hwangdonensis AD-1(T) (97.4 %). The major cellular fatty acids were anteiso-C(15 : 0) (57.9 %), anteiso-C(17 : 0) (14.0 %), iso-C(15 : 0) (10.8 %) and iso-C(16 : 0) (8.1 %). The respiratory isoprenoid quinones were MK-7 (98.5 %) and MK-6 (1.5 %). The DNA G+C content was 42.9 mol%. These features confirmed the placement of strain 18OM(T) within the genus Thalassobacillus. The DNA-DNA hybridization values between strain 18OM(T) and T. devorans G-19.1(T), T. cyri HS286(T) and T. hwangdonensis AD-1(T) were 49 %, 9 % and 15 %, respectively, showing unequivocally that strain 18OM(T) constituted a novel genospecies. On the basis of phylogenetic analysis and phenotypic, genotypic and chemotaxonomic characteristics, strain 18OM(T) is considered to represent a novel species of the genus Thalassobacillus, for which the name Thalassobacillus pellis sp. nov. is proposed. The type strain is 18OM(T) (â€Š=â€ŠCECT 7566(T)â€Š=â€ŠDSM 22784(T)â€Š=â€ŠJCM 16412(T)).",2011,International journal of systematic and evolutionary microbiology
Bayesian Nominal Matrix Factorization for Mining Daily Activity Patterns,"With the advent of the Internet of things (IoT) and smart sensor technologies, the data-driven paradigm has been found promising to support human behavioral analysis in a smart home for better healthcare and well-being of senior adults. This work focuses on discovering daily activity routines from sensor data collected in a smart home. By representing the sensor data as a matrix, daily activity routines can be identified using matrix factorization methods. The key challenge rests on the fact that the matrix contains discrete labels as its elements, and decomposing the nominal data matrix into basis vectors of the labels is nontrivial. We propose a novel principled methodology to tackle the nominal matrix factorization problem. Assuming that the similarity matrix of the labels is known, the discrete labels are first projected onto a continuous space with the interlabel distance preserving the given similarity matrix of the labels as far as possible. Then, we extend a hierarchical probabilistic model for ordinal matrix factorization with Bayesian Lasso that the factorization can be more robust to noise and more sparse to ease human interpretation. Our experimental results based on a synthetic data set shows that the factorization results obtained using the proposed methodology outperform those obtained using a number of the state-of-the-art factorization methods in terms of the basis vector reconstruction accuracy. We also applied our model to a publicly available smart home data set to illustrate how the proposed methodology can be used to support daily activity routine analysis.",2016,2016 IEEE/WIC/ACM International Conference on Web Intelligence (WI)
Should Psychologists Unionize? A Colloquy With Labor and Management Experts,"Finkelstein, Bruckman, Wohl, Most, & RothmanJim MillerNew \brk State School of Industrial and Labor RelationsHaydee MontenegroNew York State Public Employees FederationMarcia MoodyUniversity of Wisconsinâ€”MadisonIn this article, experts in labor and management address the question of whether unionizing is anappropriate vehicle through which psychologists can protect professional autonomy, standards, andquality of care. One threshold issue is the degree to which health care professionals have controlover their incomes and working conditions in the current marketplace and their willingness to perceivethemselves as ""workers."" Examples of successful labor-management collaboration on behalf ofpatients and union representation on behalf of psychologists are provided. Some legal and strategicconsiderations about forming or joining unions are also discussed.As corporate downsizing has been eliminating job securityfor millions of American workers, the prevailing conditions inthe health care marketplace have been threatening the economicsecurity of thousands of health care professionals, includingpsychologists. Health care providers have begun to use the lever-age of forming large group practices as a means of acquiringmore bargaining power with large managed care organizations.However, only a minority of health care professionals have ex-plored another possible alternative that could potentially benefitthem: forming labor unions to deal with corporate management(Sullivan, LaOana, Wiggins, & DeLeon, 1997).This article addresses some of the advantages and disadvan-tages of union representation of psychologists. It is excerptedfrom a symposium that took place at the 103rd Annual Conven-tion of the American Psychological Association, New York City.The symposium, held on August 13, 1995, was titled ""LaborRepresentation in Psychologyâ€”If You're Employed, You'llNeed It."" The impetus for that program came from Bill Safarjan,who has been involved in union representation issues for public-sector psychologists in California (Safarjan, 1997). The panelof labor and management experts addressed the question ofwhether unionizing is an appropriate option by which profes-JOEL A. DVOSKIN is the former acting commissioner of the New YorkState Office of Mental Health, where he served as the chief executiveofficer of the largest mental health organization of the United States, aheavily unionized agency with more than 23,000 employees and anannual budget of more than 2.3 billion dollars. Prior to that, he servedfor 10 years as the agency's associate commissioner for forensic services.He is currently a full-time consultant and expert witness in forensicpsychology in Tucson, Arizona, and teaches on the faculty of the Univer-sity of Arizona's College of Law and Medicine.LEONARD DAVIDMAN is chief psychologist in the Division of Child andAdolescent Psychiatry at Metropolitan Hospital in New ""fork City andis assistant professor of psychiatry at New York Medical College. Hehas served as a delegate, the vice president, and, currently, the presidentof Local 1189 of District Council 37, which represents New York Citypsychologists who work in municipal hospitals, police departments, fam-ily court, and prison health. His local is affiliated with the AmericanFederation of State, County, and Municipal Employees of the Ameri-can Federation of Labor and Congress of Industrial Organizations(AFL-CIO).BERNARD FERSTER is an attorney specializing in labor relations and em-ployment law and is a partner in the firm of Finkelstein, Bruckman,Wohl, Most, & Rothman in New Mirk City. He advises and representsmanagement in all aspects of employment, labor organization, negotia-tions, and administration of collective bargaining agreements.JIM MILLER is a senior labor associate at the New ""fork State School ofIndustrial and Labor Relations, a division of Cornell University. Heteaches courses on labor history, conflict resolution, and labor practice,and he has provided educational, technical, and consulting services forapproximately 1,500 unions.HAYDEE MONTENEGRO is a staff psychologist at Rockland PsychiatricCenter a facility of the New York State Office of Mental Health. She isa trustee of the New York State Public Employees Federation, whichrepresents 57,000 professional sector employees.MARCIA MOODY is a doctoral student in psychology at the Universityof Wisconsinâ€”Madison and is chair of the American PsychologicalAssociation (APA) Graduate Students Advocacy Coordinating Team.She transcribed the proceedings of the APA convention symposium fromwhich this article was excerpted.CORRESPONDENCE CONCERNING THIS ARTICLE should be addressed to JoelA. Dvoskin, 5174 North Via de la Lanza, Tucson, Arizona 85750-7077.425",1997,Professional Psychology: Research and Practice
Novel Text Preprocessing Framework for Sentiment Analysis,Aim of this article is to propose a text preprocessing model for sentiment analysis (SA) over twitter posts with the help of Natural Language processing (NLP) techniques. Discussions and investments on health-related chatter in social media keep on increasing day by day. Capturing the actual intention of the tweeps (twitter users) is challenging. Twitter posts consist of Text. It needs to be cleaned before analyzing and we should reduce the dimensionality problem and execution time. Text preprocessing plays an important role in analyzing health-related tweets. We gained 5.4% more accurate results after performing text preprocessing and overall accuracy of 84.85% after classifying the tweets using LASSO approach.,2019,
TI{ANSIiORMATION OF VATERITE TO CALCITE DURING GRINDING,"Calcium carbonate exists in three crystalline polymorphs with different symmetries structures, and densities, aiz., calcite, rhombohedral, density 2.71; aragonite, orthorhombic, density 2.93; and vaterite, hexagonal, densit-v2.56. Calcite and aragonite occur naturally in large quantit ies, but the existence of vaterite has rarely been reported (McConne l l . 1960 ) . Vaterite has been subjected to a hydrostatic pressure of 24,000 bars without any transformation to calcite (.famieson, 1957), but readily transforms to calcite on grinding at room temperature (Gammage and Glasson 1963) It was our opinion that this difference in behaviour was due to the shear strains which are generated during grinding. Since a mere inspection of many geological specimens which have come from the depth of the earth is sufficient to disclose the universality of flow under those conditions and therefore to suggest the importance of shear strains, it was thought that these shear strains could account for the rare occurrence of vaterite in nature. A mill was therefore constructed for use over a range of temperatures and the changes produced in the powder were examined using X-ray tcchniques. ExpenruBNrAL DETATLS",2007,
Short-Term Effects of Three Herbicides on the Maximum Quantum Yield and Electron Transport Rate of Tropical Seagrass Thalassodendron ciliatum,"This article describes the laboratory findings of the short-term effects of three herbicides on the tropical seagrass Thalassodendron ciliatum. For three days T. ciliatum was exposed to Diuron, Fusillade (Forte) and 2, 4-D amine, either individually or in combination. The toxic effects were investigated by measuring the effective quantum yield through rapid light curves and the maximum quantum yield (Fv/Fm), before and after exposure at intervals of 2, 4, 6, 8, 24, 48 and 72 hrs. During the recovery phase both Fv/Fm and effective quantum yield were measured after 2, 4, 6, 8, 24, 48 and 72 hrs. Results revealed an inhibition of both ETRmax and Fv/Fm after diuron exposure. No effect on ETRmax and Fv/Fm were observed when T. ciliatum was exposed to Fusilade Forte and 2, 4-D amine. Any combination of the herbicides that involved Diuron showed inhibition both in ETRmax and Fv/Fm. Exposure to a combination of Fusilade Forte and 2,4-D amine had no effect on both ETRmax and Fv/Fm of T. ciliatum. It is concluded that, diuron is toxic to T. ciliatum at a concentration which can be found in a polluted environment while the other herbicides did not show inhibition of the parameters measured. KEYWORDS : Thalossodendron ciliatum , herbicides, toxicity, Fucilade, 2,4-D amine",2012,
Genome-Wide Association Studies and Comparison of Models and Cross-Validation Strategies for Genomic Prediction of Quality Traits in Advanced Winter Wheat Breeding Lines,"The aim of the this study was to identify SNP markers associated with five important wheat quality traits (grain protein content, Zeleny sedimentation, test weight, thousand-kernel weight, and falling number), and to investigate the predictive abilities of GBLUP and Bayesian Power Lasso models for genomic prediction of these traits. In total, 635 winter wheat lines from two breeding cycles in the Danish plant breeding company Nordic Seed A/S were phenotyped for the quality traits and genotyped for 10,802 SNPs. GWAS were performed using single marker regression and Bayesian Power Lasso models. SNPs with large effects on Zeleny sedimentation were found on chromosome 1B, 1D, and 5D. However, GWAS failed to identify single SNPs with significant effects on the other traits, indicating that these traits were controlled by many QTL with small effects. The predictive abilities of the models for genomic prediction were studied using different cross-validation strategies. Leave-One-Out cross-validations resulted in correlations between observed phenotypes corrected for fixed effects and genomic estimated breeding values of 0.50 for grain protein content, 0.66 for thousand-kernel weight, 0.70 for falling number, 0.71 for test weight, and 0.79 for Zeleny sedimentation. Alternative cross-validations showed that the genetic relationship between lines in training and validation sets had a bigger impact on predictive abilities than the number of lines included in the training set. Using Bayesian Power Lasso instead of GBLUP models, gave similar or slightly higher predictive abilities. Genomic prediction based on all SNPs was more effective than prediction based on few associated SNPs.",2018,Frontiers in Plant Science
Quality of Hospital Bed Performance Studies based on Pabon Lasso Model,"Hospitalsâ€™ bed productivity has a remarkable effect on health system performance. The Pabon Lasso Model (PLM) is a useful tool for evaluation of inpatient beds performance and there is a growing trend in use of this technique in hospital performance evaluation. The aim of this study is to review the literature on PLM to gain insight into quality the results of these studies. By adopting a systematic review style, the full text of a total of 29 documents on the topic was reviewed. While in 81.3% (n=26) of the documents Pabon Lasso diagram has been represented complete and correctly, the results of a large fraction of the reviewed studies (59.6%) was limited to identifying the status of the hospitals in question the Pabon Lasso chart, without further analysis of the chart in the context of hospital resources. Our study hence recommends that future studies can draw further useful implications from the PLM model by focusing more on the interpretation of the results in the practical context of hospital management.",2015,international journal of hospital research
Discrete Seismic Tomography,"Tomographic imaging reveals the interior of an object. Similar to a camera, it images an object by illuminating it with electromagnetic or acoustic waves (or a beam of photons). Due to its non-invasive nature, it has found applications in various fields of sciences and engineering. Recent challenges include fast and accurate reconstructions of high contrasts in the object from a limited number of tomographic measurements. To tackle this, prior information about the object under inspection is beneficial. One particular example is a discrete prior, where an object is made up of only a few homogeneous materials of known grey levels. The tomography that deals with this prior is known as discrete tomography. The discrete assumption holds approximately for many objects. In general, the low-contrast surrounding is not spatially invariant. This leads to a class of objects called partially discrete objects, where high-contrast materials lie in the non-homogeneous low-contrast background. This thesis develops algorithms based on the theory of convex optimization, regularization, and the level-set method to reconstruct discrete and partially discrete objects from limited measurements. In X-ray tomography, the challenge to reconstruct an object from limited measurements stems from the high levels of radiation dose from X-rays. Although the tomographic problem is linear, the discrete prior makes it non-convex. Many heuristic algorithms exist to image discrete objects from a few of their ray projections. These algorithms often require manual tuning of parameters and may suffer in the noisy scenario. We develop a convex program to recover the binary objects (i.e., objects composed of only two materials) that relies on the Lagrangian duality. The resulting problem is a l1-regularized least-squares problem (LASSO) that can be solved quickly. Based on small-scale experiments, we conjecture that if the binary tomography problem admits a unique solution, it can be recovered using the proposed formulation. In the case of multiple solutions, the convex program gives the intersection of the solutions. The proposed algorithm compares favorably to existing state-of-the-art algorithms like total variation and DART. In wavefield imaging, the access to the measurements on one side of the object and the nonlinear interaction of waves with the object leads to challenges in the recovery of high contrast objects. The famous example of high contrast is the salt-bodies in the earth, which are good indicators of hydrocarbon reservoirs. In the first instance, we assume that the grey level of the high contrast material is known and it is homogeneous. We develop a level-set approach that explicitly separates the high-contrast object from the low-contrast surrounding. We make use of a parametrization technique to represent the level-set function and make the problem lower-dimensional and well-behaved. On synthetic phantoms, we show that the high-contrast objects are recoverable under one-sided limited measurements. The parametric level-set approach is extended to partially discrete objects as well. In the second instance, we assume that the data consists of noise, and the noise level is known. We developed a total variation regularized multiscale framework that solves a series of least-squares problems.",2019,
Geometria â€“ Costruzione â€“ Architettura nel trattato delle fortificazioni di Galasso Alghisi,"This article presents an application of geometry in architecture. It aims to investigate the geometric pattern underlying the conceptual design of the model of Renaissance fortification proposed by Galasso Alghisi in the treatise Delle Fortificationi (Venice 1570). The study focuses on the geometrical analysis of the generative dynamic of the tested form which is illustrated here by means of detailed engravings. More specifically, the following aspects will be examined: the method of the geometric-configurative of the fortification type proposed by Alghisi, together with the identification of the related formal matrices; the functioning of the Istromento (instrument) described by Alghisi and advised in order to proportion the sites to be built upon and transform the drawings of the fortresses into structures following the proportions.",2012,
Energy Models for Signal Processing and Matrix Factorization,"Author(s): Meyer, Travis Robert | Advisor(s): Bertozzi, Andrea L | Abstract: In this work, we present a variety of energy-based methods that are solutions to problems in the fields of microscopy, hyperspectral and medical imaging, and data mining. These solutions are formulated from the perspective of extremization an energy function capturing deviation of the solution from observations and desirable properties. First we present new methods for improving imaging acquisition rates of atomic force microscopes. We propose and experimentally demonstrate image inpainting as a way to liberate scanner position limitations thereby enabling faster scans. Traditionally the scanner takes measurements in a raster pattern; in this work, we demonstrate that high-quality surface reproduction is attainable by sampling with non-raster patterns using variational image inpainting. With non-raster scan patterns existing thermomechanical drift error removal approaches no longer can be used. We propose a solution to this task with a highly effective corrective technique that utilize points of self-intersection. Our model only requires a few points of self-intersection that have minimal impact on scan time. Our correction model is potentially numerically unstable in some special, though easy to produce, cases. We propose a fitness based on analysis of the model energy that quantifies how well our method will perform for a given scan path. With minor experimental design modifications, often resulting simply from uncertainties in the scanner positioning, this fitness can be drastically increased and issues thereby alleviated. Due to its desirable properties, we focus specifically on improving the Archimedean spiral scan. By considering basic limitations of the scanner's tip speed and resonant frequency, we derive the parametrization that exactly obeys limitations while minimizing total scan time. With small and reasonable approximations the form of this scan becomes analytically simple to state and easy to implement in practice. We defend this optimal parameterization against other choices from the perspectives of scan time, scanner limitations, and sampling distribution uniformity.In the area of medical imaging we address the issue of signal cleaning for simultaneous electroencephalographic and functional magnetic resonance imaging. During acquisition dominant signals are produced through the ballistocardiographic effects that have challenge variability over time. Noting some properties of the signals, we propose applying an existing model known as low-rank + sparse matrix decomposition. We performed experiments with twenty individuals in simultaneous capture to observe decreases in alpha-band neural activity following Gabor flashes and find that the proposed method improves signal cleaning results considerably when compared to an existing method known as independent component analysis. In the domain of hyperspectral unmixing we address the problem of unmixing with spectral variability. We propose and study using social sparsity to enforce sparsity assumptions in the context of existing models that extract per-material endmember bundles. In a trio of experiments, two quantitative and one qualitative, we demonstrate that social sparsity - in particular group lasso - improves the solution.In the final chapter of this work we investigate the recently popular machine learning problem of topic modeling. We present two models for solving this problem - latent Dirichlet allocation and non-negative matrix factorization - in their original forms, review the literature, and present what is known about the analytic relationship they share. In practice, because the problems are non-convex, the inference or optimization technique plays a role in solution quality. We therefore also summarize three popular algorithms for these models and frame the algorithms themselves in a common variational setting specific to the topic modeling problem. In addition to contributing this perspective for the models and algorithms together, we experimentally demonstrate differences in performance for the methods as well as practical topic model results. The final contribution of this work is two metrics for studying the distributional properties of topics extracted from documents with additional information e.g. time or location.We study these metrics with a geotagged Twitter data set taken from Madrid throughout 2011 and find that these simple metrics provide a useful summary for topics and can significantly simplify the initial process of studying topic model results when the number of topics is large.",2017,
