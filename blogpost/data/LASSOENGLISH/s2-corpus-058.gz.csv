title,abstract,year,journal
Multi-task Bolasso based aircraft dynamics identification,"HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. Lâ€™archive ouverte pluridisciplinaire HAL, est destinÃ©e au dÃ©pÃ´t et Ã  la diffusion de documents scientifiques de niveau recherche, publiÃ©s ou non, Ã©manant des Ã©tablissements dâ€™enseignement et de recherche franÃ§ais ou Ã©trangers, des laboratoires publics ou privÃ©s. Multi-task Bolasso based aircraft dynamics identification CÃ©dric Rommel, Joseph FrÃ©dÃ©ric Bonnans, Baptiste Gregorutti, Pierre Martinon",2017,
"Sedimentological and palynological evidence of regional climatic changes in the Campanian to Paleocene sediments of the Rocky Mountain Foothills, Canada","Abstract Evidence of paleoclimatic variations in the upper Campanian to lower Paleocene post-Wapiabi sequence of strata is visible both laterally between the central and southern Foothills, and vertically in the stratigraphic record. These differences are expressed by the distribution of climatically sensitive sediments, i.e. coal and caliche, and associated palynological assemblages within floodplain facies, as well as by changes in the style of fluvial channels. The interpretation of a semi-arid environment for mature caliche paleosols is supported by the impoverished character of the associated palynological assemblages, both in terms of diversity and the number of specimens recovered, and by the conspicuous presence of Classopollis . The lateral extent of the semiarid floodplain facies and associated broad and mobile channel deposits is limited to the southern part of the basin. No signs of a caliche facies have been found in the post-Wapiabi strata of the central Foothills. Instead, some of the floodplain deposits associated with meandering streams in this part of the basin contain numerous, thick, coal-bearing intervals. The relative climatic differences between the more humid central part and the drier southern part of the basin prevailed throughout the entire post-Wapiabi interval. As this cannot be satisfactorily explained by the position of the sea shore or by orographic influences alone, there was probably another external factor. This could have been the pattern of atmospheric circulation, such as that responsible for the present-day climatic differences existing between the southern and central Foothills. Semiarid floodplain facies occur at two levels in the stratigraphic column of the southern Foothills (in the late Campanian, Belly River Formation and in the upper Maastrichtian to lower Paleocene, Willow Creek Formation). They correspond to regressive episodes of the epicontinental seaway. Intervening between these semiarid floodplain facies are the marine shales of the Bearpaw Formation and, both overlying and underlying them, thin coal beds. These represent recurrent periods of swamp growth and peat accumulation in back-barrier environments (lagoon-fill and supratidal marsh respectively). Because of the proximity of these swamps to the sea shore it is difficult to assess the influence of climate on the relative humidity of these settings on strictly sedimentological grounds. However, the terrestrial components of the palynological assemblages recovered from these marginal-marine settings and correlative lacustrine sediments (containing fresh-water stromatolites but no coal) in the central Foothills are in sharp contrast with the impoverished assemblages known from the caliche facies. The former are prolific, diverse, and contain a number of triprojectate pollen species, which indicate a relatively humid climate during the latest Campanian time.",1988,Sedimentary Geology
Does Capacity Analysis Help us Meet Fishery Policy and Management Objectives,"There is a United Nations Food and Agricultural Organization International Plan of Action for the management of fishing capacity where countries agree to, among other things, periodically provide measures of their fishing capacity. For the past several years, many fisheries economists have conducted a significant amount of research measuring capacity in several different ways. However, even after considerable effort to measure capacity has been made, policies such as buyback schemes to reduce capacity have not achieved their goals. The purpose of this special Thalassorama section is to look more closely at questions such as:",2007,Marine Resource Economics
Asymmetric snap-buckling of a column restrained by a stiff wire,"SommarioUn esempio relativamente semplice di collasso asimmetrico per carico di punta in una struttura continua Ã¨ il problema non lineare di una colonna incastrata ad una estremitÃ  e vincolata all'altra estremitÃ  da un filo rigido che forma un angolo acuto con l'asse della colonna e caricata a quella estremitÃ  con una forza perpendicolare allo stesso asse. Un parametro chiamato Î¼, che Ã¨ il rapporto adimensionale fra la rigiditÃ  flessionale della colonna e la rigidezza longitudinale del filo e dell'asse della colonna, determina le caratteristiche essenziali del cedimento. Se Î¼ Ã¨ zero o Ã¨ piccolo rispetto all'unitÃ , l'inflessione della colonna Ã¨ sufficientemente piccola per giustificare l'uso della teoria lineare di inflessione per la colonna. Di conseguenza anche se il vincolo non Ã¨ lineare la soluzione del problema Ã¨ ottenuta in forma compatta. Il punto critico della struttura si trova nel punto di biforcazione asimmetrica per Î¼=0, mentre per Î¼ positivo, il punto critico rappresenta un punto di collasso. L'effetto di Î¼ Ã¨ simile a quello prodotto da imperfezioni iniziali in strutture piÃ¹ complesse. Per Î¼ molto piccolo il carico critico Ã¨ notevolmente ridotto rispetto al valore per Î¼=0. Inoltre il grafico del carico in funzione della curvatura all'estremitÃ  sembra avere una netta discontinuitÃ  nella pendenza dal punto di biforcazione per Î¼ molto piccolo benchÃ¨, in realtÃ  si trovi che il grafico ha lÃ¬ una tangente orizzontale.SummaryA relatively simple example of asymmetric snap-through buckling in a continuous structure is the nonlinear problem of a cantilevered column restrained at its tip by a stiff wire, which is inclined at an acute angle to the column centerline, and loaded at its tip by a force perpendicular to the centerline. A parameter called Î¼, which is the nondimensional ratio of the flexural rigidity of the column to the combined extensional stiffness of the wire and the column centerline, determines the essential features of the buckling. If Î¼ is zero, or is small compared to unity, the bending of the column is small enough to justify the use of linear bending theory for the column. Hence, even though the constraint is nonlinear, the solution to this problem is obtained in closed form. The critical point for the structure is found to be an asymmetric branching point for Î¼=0, while for Î¼ positive, the critical point is a snap-through type. The effect of Î¼ is similar to that induced by initial imperfections in more complex structures. For very small Î¼, the critical load is markedly decreased from the value for Î¼=0. Moreover, the graph of the load vs. tip deflection has the appearance of having an acute discontinuity in slope at the critical point for Î¼ very small, although it is actually found that the graph has a horizontal tangent there.",1970,Meccanica
Food from the empire: The new productive territory of post brexit UK,"Among the several events that have shaped UKâ€™s present , the British colonial empire could be one of the most significant ones. With the North Sea as Britains new passage to the world the British thalassocracy created one of the biggest colonial empires that lasted over three centuries. At its colonial peak, the imperial empire had occupied 24% of the Earthâ€™s land area with 23% of the worldâ€™s population . Trade and exploitation of resources in the new colonies became the understructure of this empire. While UKâ€™s proximity to the North Sea on the global scale facilitated the exchange of food and raw materials on the local scale it encouraged the growth of a complex system of internalised waterways and ports providing a lot of trade opportunities for the mercantile traders. During this time, food trade linked its colonies and the metropolis via complex bilateral and multilateral shipping routes of the North Sea, laying the foundation for the development of some of UKâ€™s biggest cities today - London, Bristol,Manchester, Liverpool etc. Food therefore, was not just an adjunct to the British imperial might but fundamental to it . At the core of the colonial expansion was the concept of land appropriation that encouraged new forms of landuses . This act of reappropriating land was happening simultaneously at two scales - the global scale, where land in the colonies was being utilised to produce food products and raw materials, and on the domestic scale where land was being reappropriated to introduce new forms of industrial typologies. Within the city privately owned land was progressively sold or rented out to speculative house builders and merchants to build small scale mills factories , while on the other hand the small scattered strips of agricultural land in the rural were being enclosed and privatised to introduce large scale manufacturing industries. Over the years this gradual appropriation of rural land has led to its depopulation and has facilitated the decline of the small farmers, leaving valuable arable land in the hands of private owners. Today, the decline of the small farms and the progressive privatisation of rural land has led to a severe lack of occupational and living diversity and has also dispossessed the rural of its means of agricultural sustenance . Large number of privatised rural farms in UK have shifted to commercial or animal based farms forcing the outsourcing of its increasing food demands to its former colonies. Currently 43% of the total food consumed by UK is imported by 2050, with a population of 75 million this number is predicted to go up by another 20%. This project therefore focuses on food production within the UK, using two main aspects - the North sea :as its territorial frame of reference and the British colonial empire :as its backdrop . Together both these factors were crucial in developing a design proposal that explores both, the possibility of food sufficiency in a post Brexit future and speculative strategies to reimagine the rural as the new productive territory . Since food is a natural derivative of productive land, land becomes a key element of the project narrative. By overlaying new systems of production, occupation and habitat the project tries to both, establish new relationships between natural and man-made systems and also eschew the traditional distinctions between the city and the rural. Using a systematic sprawl the design tries to highlight the flexibility of a decentralised city to be able to accommodate and respond to future uncertainties without compromising on the sustainable and efficient utilisation of land. By establishing new forms of ownership and occupation the design also becomes a tool to decolonize the rural land of its industrial remnants to make way for new forms of infrastructure and logistics . In this new city, the land is no longer a commodity, it is a mode of sustenance that is equally accessible to every citizen living in it. By internalizing the systems of production and distribution within this city the project tries to contest North seaâ€™s current role as a facilitator of an unequitable decentralised global trade. The end result does not claim to be a definitive solution to the impending food crisis, rather it is a test of whether the revival and appropriation of one of the most archaic systems of land ownership and profit will be able to diminish the perilous consequences of years of consumerism that was a direct result of colonial industrialisation.",2018,
Catheter simulator software tool to generate electrograms of any multi-polar diagnostic catheter from 3D atrial tissue.,"Simulations are excellent tools for assessing new therapeutic strategies and are often conducted before implementing new therapy options in a clinical practice. For patients suffering from a heart arrhythmia, the main source of information comes from an intracardiac catheter. One of the common catheters is a Lasso multi-pole diagnostic catheter, which is a catheter that has 20 electrodes in a circular pattern. In this paper, we developed algorithm and simulation software that allows the users to place a multi-pole catheter on the atrial endocardial surface and record electrograms. In 3D atrial tissue, the plane of principal curvature is determined using eigenvectors of catheter vertices, from where the normals are projected and registered to the surface using 3D geodesic distance. This tool provides a platform for performing customized virtual cardiac experiments.",2016,Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference
Panda: AdaPtive Noisy Data Augmentation for Regularization of Undirected Graphical Models,"We propose PANDA, an AdaPtive Noise Augmentation technique to regularize estimating and constructing undirected graphical models (UGMs). PANDA iteratively solves MLEs given noise augmented data in the regression-based framework until convergence to achieve the designed regularization effects. The augmented noises can be designed to achieve various regularization effects on graph estimation, including the bridge, elastic net, adaptive lasso, and SCAD penalization; it can also offer group lasso and fused ridge when some nodes belong to the same group. We establish theoretically that the noise-augmented loss functions and its minimizer converge almost surely to the expected penalized loss function and its minimizer, respectively. We derive the asymptotic distributions for the regularized regression coefficients through PANDA in GLMs, based on which, the inferences for the parameters can be obtained simultaneously with variable selection. Our empirical results suggest the inferences achieve nominal or near-nominal coverage and are far more efficient compared to some existing post-selection procedures. On the algorithm level, PANDA can be easily programmed in any standard software without resorting to complicated optimization techniques. We show the non-inferior performance of PANDA in constructing graphs of different types in simulation studies and also apply PANDA to the autism spectrum disorder data to construct a mixed-node graph.",2018,ArXiv
Akute Verletzung des hinteren Kreuzbandes mit femoraler Avulsion,"ZusammenfassungOperationszielWiederherstellung der anatomischen und biomechanischen Eigenschaften des hinteren Kreuzbandes (HKB) in der Akutsituation. Hierbei erfolgt die arthroskopisch gestÃ¼tzte Reinsertion des HKB durch AuszugsnÃ¤hte kombiniert mit einem â€žLigament Bracingâ€œ zur ErhÃ¶hung der PrimÃ¤rstabilitÃ¤t und zum Erhalt der propriozeptiven Funktion.IndikationenAkute Verletzungen des HKB mit femoraler Avulsion, isoliert oder im Rahmen von Multiligamentverletzungen.KontraindikationenChronische InstabilitÃ¤ten des HKB, Gelenkinfektionen.OperationstechnikArthroskopische PrÃ¤paration der femoralen HKB-Insertion. Anschlingen der intakten HKB-Struktur mit nichtresorbierbarem Fadenmaterial mittels Fadenzange oder Lassosystem. Platzieren der BohrkanÃ¤le fÃ¼r das â€žLigament Bracingâ€œ mit Hilfe arthroskopischer ZielgerÃ¤te femoral und tibial. Fixation des Fadenaugmentationssystems und der vorgelegten AnschlingfÃ¤den femoral extrakortikal Ã¼ber einen Button oder intraartikulÃ¤r mit einem Anker. AbschlieÃŸend tibiale Fixation Ã¼ber einen Button in mindestens 80Â°-Flexion bei permanentem vorderem Schubladenstress.WeiterbehandlungStreckorthese mit tibialem posteriorem Support 24Â h/Tag sowie Teilbelastung von 20â€¯kg fÃ¼r 6Â Wochen. Physiotherapeutische BeÃ¼bung in Bauchlage, ROM (â€žrange of motionâ€œ) bis max. 0â€‘0-90Â°. Ab der 7.Â postoperativen Woche Belastungsaufbau, Steigerung der Beweglichkeit und Tragen einer Hartrahmenorthese mit posteriorem Support fÃ¼r weitere 6Â Wochen.AbstractObjectiveThe aim of arthroscopic bracing of the posterior cruciate ligament (PCL) is to restore anatomic and biomechanic function in acute PCL tears. Therefore, primary augmentation of the PCL by using aÂ stable suturing system is used.IndicationsAcute tears of the PCL, femoral avulsions, isolated or combined in cases of multiligament injuries (knee dislocations of Schenk typesÂ IIâ€“IV).ContraindicationsChronic instabilities of the PCL, infection of the knee joint.Surgical techniqueArthroscopic preparation of the femoral PCL footprint. Suturing of the PCL stump with non-resorbable sutures. Placement of the femoral and tibial tunnel with aÂ specific arthroscopic PCL guide. Femoral fixation of the bracing system and the PCL augmenting sutures extracortical via aÂ button or intraarticular with aÂ suture anchor. Tibial fixation via aÂ button has to be performed in aÂ minimum of 80Â° of flexion and under permanent anterior drawer tension.Postoperative managementBrace in full extension with posterior support 24â€¯h/day, range of motion (ROM) restricted up to 90Â° of flexion and limited weight bearing with 20â€¯kg for the first 6Â weeks postoperatively. After 6Â weeks, weight bearing and ROM can be increased and aÂ solid frame brace with posterior support is recommended for the next 6Â weeks.",2018,Operative OrthopÃ¤die und Traumatologie
Evaluation of an Algorithm for Identifying Ocular Conditions in Electronic Health Record Data,"Importance For research involving big data, researchers must accurately identify patients with ocular diseases or phenotypes of interest. Reliance on administrative billing codes alone for this purpose is limiting. Objective To develop a method to accurately identify the presence or absence of ocular conditions of interest using electronic health record (EHR) data. Design, Setting, and Participants This study is a retrospective analysis of the EHR data of patients (nâ€‰=â€‰122 339) in the Sight Outcomes Research Collaborative Ophthalmology Data Repository who received eye care at participating academic medical centers between August 1, 2012, and August 31, 2017. An algorithm that searches structured and unstructured (free-text) EHR data for conditions of interest was developed and then tested to determine how well it could detect the presence or absence of exfoliation syndrome (XFS). The algorithm was trained to search for evidence of XFS among a sample of patients with and without XFS (nâ€‰=â€‰200) by reviewing International Classification of Diseases, Ninth Revision or International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-9 or ICD-10) billing codes, the patientâ€™s problem list, and text within the ocular examination section and unstructured (free-text) data in the EHR. The likelihood that each patient had XFS was estimated using logistic least absolute shrinkage and selection operator (LASSO) regression. The EHR data of all patients were run through the algorithm to generate an XFS probability score for each patient. The algorithm was validated with review of EHRs by glaucoma specialists. Main Outcomes and Measures Positive predictive value (PPV) and negative predictive value (NPV) of the algorithm were computed as the proportion of patients correctly classified with XFS or without XFS. Results This study included 122 339 patients, with a mean (SD) age of 52.4â€‰(25.1) years. Of these patients, 69 002 (56.4%) were female and 99 579 (81.4%) were white. The algorithm assigned a less than 10% probability of XFS for 121 085 patients (99.0%) as well as an XFS probability score of more than 75% for 543 patients (0.4%), more than 90% for 353 patients (0.3%), and more than 99% for 83 patients (0.07%). Validated by glaucoma specialists, the algorithm had a PPV of 95.0% (95% CI, 89.5%-97.7%) and an NPV of 100% (95% CI, 91.2%-100%). When there was ICD-9 or ICD-10 billing code documentation of XFS, in 86% or 96% of the records, respectively, evidence of XFS was also recorded elsewhere in the EHR. Conversely, when there was clinical examination or free-text evidence of XFS, it was documented with ICD-9 codes only approximately 40% of the time and even less often with ICD-10 codes. Conclusions and Relevance The algorithm developed, tested, and validated in this study appears to be better at identifying the presence or absence of XFS in EHR data than the conventional approach of assessing only billing codes; such an algorithm may enhance the ability of investigators to use EHR data to study patients with ocular diseases.",2019,JAMA Ophthalmology
Inferring gene regulatory networks by integrating ChIP-seq/chip and transcriptome data via LASSO-type regularization methods.,"Inferring gene regulatory networks from gene expression data at whole genome level is still an arduous challenge, especially in higher organisms where the number of genes is large but the number of experimental samples is small. It is reported that the accuracy of current methods at genome scale significantly drops from Escherichia coli to Saccharomyces cerevisiae due to the increase in number of genes. This limits the applicability of current methods to more complex genomes, like human and mouse. Least absolute shrinkage and selection operator (LASSO) is widely used for gene regulatory network inference from gene expression profiles. However, the accuracy of LASSO on large genomes is not satisfactory. In this study, we apply two extended models of LASSO, L0 and L1/2 regularization models to infer gene regulatory network from both high-throughput gene expression data and transcription factor binding data in mouse embryonic stem cells (mESCs). We find that both the L0 and L1/2 regularization models significantly outperform LASSO in network inference. Incorporating interactions between transcription factors and their targets remarkably improved the prediction accuracy. Current study demonstrates the efficiency and applicability of these two models for gene regulatory network inference from integrative omics data in large genomes. The applications of the two models will facilitate biologists to study the gene regulation of higher model organisms in a genome-wide scale.",2014,Methods
Penerapan Model Pembelajaran Probing Prompting Untuk Meningkatkan Kemampuan Berpikir Analitis Ipa Pada Siswa Sekolah Dasar,"Abstract: The research aimed to improve students' analytical thinking ability in science learning by applying probing prompting learning model at fourth grade of Totosari No 102 Surakarta State Elementary School in 2016/2017. This reseach was a classoom action research which was held in two cycles. There were four stage in each cycle, which was planning, implementation, obsevation, and reflection. The subjects were a teacher and 34 students from the fourth grade of Totosari No 102 Surakarta State Elementary School in Surakarta in 2016/2017.Â  The data sources were the teacher and the students. The data collection techniques were in depth interview, obsevation, test and documentation. Data validity was technic triangulation and source triangulation. Data analysis were descriptive comparative statistics, critical analysis, and interactive analysis. Based on the result of the research, a conclusion in drawn that the apply ofÂ  probing prompting leaning model can improve studentsâ€™ analytical thinking ability in science learning at fourth grade of Totosari No 102 Surakarta State Elementary School in Surakarta in 2016/2017. Abstrak : Tujuan penelitian ini adalah untuk meningkatkan kemampuan berpikir analitis dalam pembelajan IPA dengan menerapkan model pembelajaran probing prompting pada siswa kelas IV SDN Totosari No 102 Surakarta tahun ajaran 2016/2017. Bentuk penelitian ini adalah Penelitian Tindakan Kelas (PTK), yang dilaksanakan dalam dua siklus. Tiap siklus terdiri dari empat tahap, yaitu perencanaan, pelaksanaan, obsevasi, dan refleksi. Subjek penelitian ini adalah seoang guru dan siswa kelas IV berjumlah 34 siswa pada semester dua SDN Totosari No 102 Surakarta tahun ajaran 2016/2017. Sumber data berasal dari guru dan siswa. Teknik pengumpulan data yang digunakan yakni wawancara, observasi, tes dan dakumentasi. Validitas yang digunakan yakni triangulasi teknik dan triangulasi sumber. Analisis data yang digunakan yaitu statistik deskriptif komparatif, analisis kritis, dan analisis interaktif. Bedasarkan hasil penelitian, dapat ditarik kesimpulan bahwa penerapan model pembelajaran probing prompting dapat meningkatkan kemampuan berpikir analitis pada pembelajaran IPA pada siswa kelas IV SDN Totosari No 102 Surakarta tahun ajaran 2016/2017. Kata kunci: Probing Prompting, Berpikir Analitis, Pembelajaran IPA",2017,
Predictor ranking and false discovery proportion control in high-dimensional regression,"We propose a ranking and selection procedure to prioritize relevant predictors and control false discovery proportion (FDP) in variable selection. Our procedure utilizes a new ranking method built upon the de-sparsified Lasso estimator. We show that the new ranking method achieves the optimal order of minimum non-zero effects in ranking relevant predictors ahead of irrelevant ones. Adopting the new ranking method, we develop a variable selection procedure to asymptotically control FDP at a user-specified level. We show that our procedure can consistently estimate the FDP of variable selection as long as the de-sparsified Lasso estimator is asymptotically normal. In simulations, our procedure compares favorably to existing methods in ranking efficiency and FDP control when the regression model is relatively sparse.",2019,J. Multivar. Anal.
Accuracy of left atrial bipolar voltages obtained by ConfiDENSE multielectrode mapping in patients with persistent atrial fibrillation,"INTRODUCTION
The ConfiDENSEâ„¢ module (Carto3 v4) allows rapid annotation of endocardial electrograms acquired by multielectrode (ME) mapping. However, its accuracy in assessing atrial voltages is unknown.


METHODS AND RESULTS
Two ConfiDENSEâ„¢ left atrial voltage maps were created during continuous pacing in 20 patients undergoing catheter ablation for persistent AF using a ME lasso catheter and a contact force (CF) sensing ablation catheter. The automated tissue proximity indicator (TPI) filter was then applied to the ME map to yield a TPI map. Reference maps (RM) were created offline by a blinded observer by manually assessing all points against fidelity criteria. Bipolar voltages and proportion of low voltage points (<Â 0.5Â mV) derived from the ME, CF, and TPI maps were compared with those derived from the RM. Note that 853 Â± 365 points, 252 Â± 184 points, and 144 Â± 73 were collected for ME, TPI, and CF maps, respectively, and 429 Â± 153 points were included in the RM. Voltages with CF and TPI maps were similar to those with RM (1.57 Â± 0.47Â mV vs. 1.63 Â± 0.31Â mV, PÂ =Â 0.57 and 1.50 Â± 0.38Â mV vs. 1.63 Â± 0.31Â mV, PÂ =Â 0.07, respectively), whereas ME maps showed a significantly lower mean voltage (1.00 Â± 0.22Â mV, PÂ <Â 0.001). As compared to RM maps (17 Â± 8%), low voltage points were significantly overestimated by the ME maps (50 Â± 9% (PÂ <Â 0.001) and TPI maps (28 Â± 13% (PÂ <Â 0.001), but not by the CF maps (22 Â± 14%, PÂ =Â 0.17).


CONCLUSION
Application of the TPI filter to ConfiDENSE maps significantly increases the quality of the voltage data, conserving a reasonable point density, but still overestimates low voltage points as compared to CF-sensing maps or maps reviewed manually.",2018,Journal of Cardiovascular Electrophysiology
Times Change and So Do People,"1. Susan J. Leclair
 1. Editor-in-Chief

The winter issue of the journal is the time when there is a change in the Editorial Board. This year we say goodbye to our Editor-in-Chief, Bunny Rodak. For those of you who know her, it will not be surprising to you to know that she has been a hard working, efficient leader of the Editorial Board and has infused the journal with her perceptions of the needs of an ever changing discipline and profession. For the past three years she has guided the journal through a number of updates and challenges.

Recently she formulated a plan to assist first time authors as they dared the publication process. Besides adding writing mentors to the journal, she has made it possible for people to be assisted through the sometimes winding path to authorship. She created a stronger group of Consulting Editors who will help in not only providing assistance to authors but also to provide a sounding board for potential authors and to evaluate proposed journal updates or policies.

Thank you, Bunny.

David McGlasson is also stepping down as Research Section Editor. He agreed to stay longer than his designated term in order to provide a smooth transition for his successor, MariBeth Flaws. Since we can't let him just walk away, David will be serving as a Consulting Editor. Thanks to David, our research section has become more robust and addresses a wider range of topics.

Thank you, David.

Similarly, George Fritsma has handed his role as Focus Section Editor overâ€¦",2013,
The degrees of freedom of partly smooth regularizers,"We study regularized regression problems where the regularizer is a proper, lower-semicontinuous, convex and partly smooth function relative to a Riemannian submanifold. This encompasses several popular examples including the Lasso, the group Lasso, the max and nuclear norms, as well as their composition with linear operators (e.g., total variation or fused Lasso). Our main sensitivity analysis result shows that the predictor moves locally stably along the same active submanifold as the observations undergo small perturbations. This plays a pivotal role in getting a closed-form expression for the divergence of the predictor w.r.t. observations. We also show that, for many regularizers, including polyhedral ones or the analysis group Lasso, this divergence formula holds Lebesgue a.e. When the perturbation is random (with an appropriate continuous distribution), this allows us to derive an unbiased estimator of the degrees of freedom and the prediction risk. Our results unify and go beyond those already known in the literature.",2014,Annals of the Institute of Statistical Mathematics
[Predominant strains of polycyclic aromatic hydrocarbon-degrading consortia from deep sea of the Middle Atlantic Ridge].,"OBJECTIVE
In order to identify the predominant strains of polycyclic aromatic hydrocarbon (PAH)-degrading consortia harboring in sea water and surface sediment collected from deep sea of the Middle Atlantic Ridge.


METHODS
We employed enrichment method and spread-plate method to isolate cultivable bacteria and PAHs degraders from deep sea samples. Phylogenetic analysis was conducted by 16S rRNA gene sequencing of the bacteria. Then we analyzed the dominant bacteria in the PAHs-degrading consortia by denaturing gradient gel electrophoresis (DGGE) combined with DNA sequencing.


RESULTS
Altogether 16 cultivable bacteria were obtained, including one PAHs degrader Novosphingobium sp. 4D. Phylogenetic analysis showed that strains closely related to Alcanivorax dieselolei NO1A (5/16) and Tistrella mobilis TISTR 1108T (5/16) constituted two biggest groups among the cultivable bacteria. DGGE analysis showed that strain 4L (also 4M and 4N, Alcanivorax dieselolei NO1A, 99.21%), 4D (Novosphingobium pentaromativorans US6-1(T), 97.07%) and 4B (also 4E, 4H and 4K, Tistrella mobilis TISTR 1108T, > 99%) dominated the consortium MC2D. While in consortium MC3CO, the predominant strains were strain 5C (also 5H, Alcanivorax dieselolei NO1A, > 99%), uncultivable strain represented by band 5-8 (Novosphingobium aromaticivorans DSM 12444T, 99.41%), 5J (Tistrella mobilis TISTR 1108T, 99.52%) and 5F (also 5G, Thalassospira lucentensis DSM 14000T, < 97%).


CONCLUSION
We found that strains of genus Alcanivorax, Novosphingobium, Tistrella and Thalassospira were predominant bacteria of PAHs-degrading consortia in sea water and surface sediment of Middle Atlantic Ridge deep sea, with Novosphingobium spp. as their main PAHs degraders.",2009,Wei sheng wu xue bao = Acta microbiologica Sinica
Strong Consistency of Variable Selection for Stationary Linear Stochastic Systems,"In this paper, we consider the variable selection for linear stochastic systems. A modified LASSO-type estimator is introduced. Then based on the classical persistent excitation (PE) for systems identification, the strong consistency of the estimates is established, i.e., the zero elements in the unknown parameter vector being correctly identified and estimates for the nonzero elements in the unknown parameter vector converging to the true values with probability one. Compared with the existing results on similar topics, the strong consistency of estimates is established while in existing literature only the convergence in probability was obtained. For this, new theoretical analysis method is adopted in this paper.",2019,2019 Chinese Control Conference (CCC)
"Limit analysis and design of structures having elements with random distribution of yield stresses, with associated and non-associated flow laws","SommarioSi considera una generica struttura composta da elementi di materiale rigido-plastico standard a costante di plasticitÃ  aleatoria e comunque distribuita attorno al valor medio.Si dimostra che il carico di collasso della struttura dotata di elementi a costante di plasticitÃ  media Ã¨ maggiore o uguale al valor medio dei carichi limite di tutte le strutture possibili, generalizzando un teorema [1] formulato per le travature reticolari. Si dimostra poi che il minimo volume della struttura dotata di elementi a costante di plasticitÃ  media Ã¨ minore o uguale al valor medio dei minimi volumi di tutte le strutture possibili. Si estendono quindi i teoremi precedenti al caso di materiali non standard.SummaryA generic structure is considered, made up of elements with rigid perfectly plastic standard material and random plasticity constant, however distributed around the average value. The limit load of structures having elements of average plasticity constant is shown to be greater than or equal to the average value of the limit loads of all the feasible structures, thus generalising a theorem [1] formulated for framed structures.The minimum volume of structures having elements of average plasticity constant is then shown to be less than or equal to the average value of the minimum volumes of all the feasible structures. Then the earlier theorems are extended to take in non standard materials.",1971,Meccanica
Web-based visualization of virtual archaeological sites,"We present a web-based visualization tool for archaeological sites that has been developed within the 3D Murale project. The problem of structuring the scene prior to visualization is addressed by an extension to the 3D modeling and animation package MayaTM which enables communication with the common data pool of 3D Murale. Texture data is prepared for visualization by encoding it using the JPEG 2000 standard, which is based on wavelet technology and allows easy access to encoded images at different resolutions. Finally, we provide an ActiveX plugin for the Microsoft Internet Explorer to enable convenient exploration of the archaeological scene in a web environment. 
 
Our approaches are demonstrated using a model of a frieze of dancing girls (Sagalassos, southwest Turkey). The discussion of our methods is supported by performance data and screen shots.",2003,
Concise comparative summaries (CCS) of large text corpora with a human experiment,"In this paper we propose a general framework for topic-specific summarization of large text corpora and illustrate how it can be used for the analysis of news databases. Our framework, concise comparative summarization (CCS), is built on sparse classification methods. CCS is a lightweight and flexible tool that offers a compromise between simple word frequency based methods currently in wide use and more heavyweight, model-intensive methods such as latent Dirichlet allocation (LDA). We argue that sparse methods have much to offer for text analysis and hope CCS opens the door for a new branch of research in this important field. For a particular topic of interest (e.g., China or energy), CSS automatically labels documents as being either on- or off-topic (usually via keyword search), and then uses sparse classification methods to predict these labels with the high-dimensional counts of all the other words and phrases in the documents. The resulting small set of phrases found as predictive are then harvested as the summary. To validate our tool, we, using news articles from the New York Times international section, designed and conducted a human survey to compare the different summarizers with human understanding. We demonstrate our approach with two case studies, a media analysis of the framing of â€œEgyptâ€ in the New York Times throughout the Arab Spring and an informal comparison of the New York Timesâ€™ and Wall Street Journalâ€™s coverage of â€œenergy.â€ Overall, we find that the Lasso with L 2 normalization can be effectively and usefully used to summarize large corpora, regardless of document size.",2014,ArXiv
The 2008 Oregon Shakespeare Festival Season,"For reviewers concerned with the omnipresent phenomenon of ""director's Shakespeare,"" 2008 was a difficult season at the Oregon Shakespeare Festival. The Festival mounted two early comedies and two mature tragedies: A Midsummer Night's Dream in the Angus Bowmer Theatre; Coriolanus in the New Theatre; and Comedy of Errors and Othello on the Elizabethan Stage. Both comedies were heavily ""conceptualized""; Penny Metropulos's Errors was set in the old west, and just barely followed Shakespeare's plot; Mark Rucker's Dream adhered closely to Shakespeare's script, but was so over-laden with multiple settings, especially its futuristic dream-forest, that one's sense of the poetic nuances of the play and its overarching vision of romantic harmony was confused. Conversely, Lisa Peterson's Renaissance Othello was an incisive study in black and white of corrosive sexual jealousy, while Laird Williamson's Fascist era setting brilliantly enhanced Coriolanus. One sensed in new Artistic Director Bill Rauch's selection of plays and directorial approaches a desire to attract younger spectators. Like other festivals, OSF is attempting to counter the aging of its audience, and Rauch and Executive Director Paul Nicholson realize that OSF simply must attract new spectators if it is going to remain economically and artistically viable. The Festival's operating budget for 2008 was $25,900,000, and amazingly 78% of that figure came from earned income. During the 2007 season the Festival had a financial impact on southern Oregon of $163,123,808, and still employs approximately 450 theatre professionals for eleven plays during its eight month season. (1) These statistics are amazing, and emphasize the Festival's overall economic and artistic health. However, they also emphasize how hard the Festival must work to maintain current audience levels. Hence, perhaps, the directorial choices of Penny Metropulos in Errors and Mark Rucker in Dream: way over-simplify an early comedy by setting it on ""the western frontier,"" an icon of Americana; or blast spectators into a mind-bending journey to a futuristic fairy-world populated by gay fairies and a Captain Oberon whose love potion #9 ignites human sexual desire and leaves young couples nearly naked on stage. Great fun, to be sure. And while such ""concepts"" may lure younger spectators to the OSF, seasoned playgoers, and reviewers, might genuinely wonder at what cost to Shakespeare's poetry and even his plots. Sheryl Harmon, a student in my OSF class, remarked after seeing Comedy of Errors that the production was ""60% Blazing Saddles and 40% Shakespeare."" Indeed, the playbill lists Errors as ""Adapted by,"" not ""Directed by,"" Penny Metropulos. Ms. Harmon's observation was astute: the set was the multi-level Shady Pine Saloon in ""A town west of the Pecos,"" complete with a hanging pole, rope, and pulley suggesting that lynching occurred frequently at Shady Pine. The town was inhabited by a rambling assortment of folks one might expect to find in such a locale, either shifted from Shakespeare's Ephesus to the wild west or added for local color. Thus Shakespeare's Duke Solinus became the town's sheriff; Emilia, Shakespeare's Lady Abbess, became the ""proprietress of the saloon"" and the ""Madame"" for several sleazy ""dancehall gals"" (named Starr and Grace) who ""worked"" upstairs; Doctor Pinch, Shakespeare's schoolmaster, became the ""snake-oil"" salesman Doctor Antonio Pitch; and Angelo the goldsmith became Li Wei, a Chinese merchant played by Cristofer Jean with surprisingly stereotyped diction and gestures. Other denizens included several cowboys, a mine owner, a sheriff's deputy, and Jose Luis, played by Rene Millan, a troubadour in Spanish leather and splendid sombrero who strummed his guitar as he crossed the stage singing love songs in English and Spanish and narrating the twists of the plot even when they had little to do with Shakespeare's play. The entire production was highly farcical, with numerous beatings of the bewildered Dromios; cowboys pursuing the dancehall gals up and down the stairs; Nell, wide as a VW Bug, lurking everywhere and lustily chasing Dromio of Syracuse all over the set; Jake, the sheriff's deputy, lassoing them thar bad uns whenever necessary, including both Dromios and in 4. â€¦",2009,
Joint estimation of multiple Gaussian graphical models across unbalanced classes,"Abstract The problem of jointly estimating unbalanced multi-class Gaussian graphical models is considered. Most existing methods require equal or similar sample sizes among classes. However, many real applications do not have similar sample sizes. Hence, the joint adaptive graphical lasso, a weighted l 1 penalized approach is proposed for unbalanced multi-class problems. The joint adaptive graphical lasso approach combines information across classes so that their common characteristics can be shared during the estimation process. Regularization is also introduced into the adaptive term. Simulation studies show that the new approach performs better than existing methods in terms of false positive rate, accuracy, Mathews correlation coefficient, and false discovery rate. The advantages of the new approach are also demonstrated using a liver cancer data set.",2018,Comput. Stat. Data Anal.
Structured kernel quantile regression,"Quantile regression can provide more useful information on the conditional distribution of a response variable given covariates while classical regression provides informations on the conditional mean alone. In this paper, we propose a structured quantile estimation methodology in a nonparametric function estimation setup. Through the functional analysis of variance decomposition, the optimization of the proposed method can be solved using a series of quadratic and linear programmings. Our method automatically selects relevant covariates by adopting a lasso-type penalty. The performance of the proposed methodology is illustrated through numerical examples on both simulated and real data.",2013,Journal of Statistical Computation and Simulation
Structured Lasso for Regression with Matrix Covariates,"High-dimensional matrix data are common in modern data analysis. Simply applying Lasso after vectorizing the observations ignores essential row and column information inherent in such data, rendering variable selection results less useful. In this paper, we propose a new approach that takes advantage of the structural information. The estimate is easy to compute and possesses favorable theoretical properties. Compared with Lasso, the new estimate can recover the sparse structure in both rows and columns under weaker assumptions. Simulations demonstrate its better performance in variable selection and convergence rate, compared to methods that ignore such information. An application to a dataset in medical science shows the usefulness of the proposal.",2014,Statistica Sinica
Endoscopic retrieval of a proximally migrated pancreatic stent: variation of the lasso technique.,"retrieve proximally migrated pancreatic stents [1,2]. The lasso technique involves inserting a guide wire through the lumen of the migrated stent followed by insertion of a partially opened polypectomy snare over the wire to grasp the stent [3]. We present the case of a 72-year-old woman with recurrent acute biliary pancreatitis, who underwent endoscopic retrograde cholangiopancreatography (ERCP) for biliary sphincterotomy due to high surgical risk. During the ERCP procedure, a flared pancreatic stent (diameter 5 Fr; length 5 cm) was placed. However, in spite of the stent, the patient developed pancreatitis. A computed tomography (CT) scan showed proximal migration of the pancreatic stent (â—"" Fig. 1), and another ERCP procedure was carried out to retrieve it. The pancreatic duct was deeply cannulatedwith a guide wire introduced alongside the stent. We then threaded the external end of thewire through a partially opened polypectomy snare (â—"" Fig. 2) and gently closed the snare and introduced it over the wire in the pancreatic duct until it reached the distal end of the stent (â—"" Fig. 3). At this point, we gently opened the snare (â—"" Fig. 4) and manipulated it until we had lassoed the stent. Endoscopic retrieval of a proximally migrated pancreatic stent: variation of the lasso technique",2010,Endoscopy
A uniform framework for the combination of penalties in generalized structured models,"Penalized estimation has become an established tool for regularization and model selection in regression models. A variety of penalties with specific features are available and effective algorithms for specific penalties have been proposed. But not much is available to fit models with a combination of different penalties. When modeling the rent data of Munich as in our application, various types of predictors call for a combination of a Ridge, a group Lasso and a Lasso-type penalty within one model. We propose to approximate penalties that are (semi-)norms of scalar linear transformations of the coefficient vector in generalized structured modelsâ€”such that penalties of various kinds can be combined in one model. The approach is very general such that the Lasso, the fused Lasso, the Ridge, the smoothly clipped absolute deviation penalty, the elastic net and many more penalties are embedded. The computation is based on conventional penalized iteratively re-weighted least squares algorithms and hence, easy to implement. New penalties can be incorporated quickly. The approach is extended to penalties with vector based arguments. There are several possibilities to choose the penalty parameter(s). A software implementation is available. Some illustrative examples show promising results.",2017,Advances in Data Analysis and Classification
An ultrastructural overview of tubificid spermatozoa,"The spermatozoa of seven species of tubificid oligochaete were compared to those already described in order to supply spermatozoal characters for systematic work on Tubificidae. The spermatozoa of Clitellio arenarius (subfamily Tubificinae) resemble those of the two other known members of the subfamily (Tubifex tubifex and Tubificoides amplivasatus) in being of two different types and in showing the same morphology of acrosomes and nuclei. Among Phallodrilinae, the three gutless species Inanidrilus bulbosus, Inanidrilus leukodermatus and Olavius planus share with Bathydrilus formosus the shape of the nucleus and various characters of the acrosome, whereas Thalassodrilus prostatus is particular in having the acrosome vesicle external to the tube and the longest middle piece recorded in oligochaetes. Monopylephorus limosus and Rhizodrilus russus (Rhyacodrilinae) differ widely in acrosomal and nuclear characters: M. limosus has a twisted nucleus, whereas R. russus has an apically flanged nucleus with a conspicuous apical concavity and an endonuclear canal. The data published on spermatozoa of the Limnodriloidinae are reviewed.",2004,Hydrobiologia
Predicting atrial fibrillation in primary care using machine learning,"BACKGROUND
Atrial fibrillation (AF) is the most common sustained heart arrhythmia. However, as many cases are asymptomatic, a large proportion of patients remain undiagnosed until serious complications arise. Efficient, cost-effective detection of the undiagnosed may be supported by risk-prediction models relating patient factors to AF risk. However, there exists a need for an implementable risk model that is contemporaneous and informed by routinely collected patient data, reflecting the real-world pathology of AF.


METHODS
This study sought to develop and evaluate novel and conventional statistical and machine learning models for risk-predication of AF. This was a retrospective, cohort study of adults (aged â‰¥30 years) without a history of AF, listed on the Clinical Practice Research Datalink, from January 2006 to December 2016. Models evaluated included published risk models (Framingham, ARIC, CHARGE-AF), machine learning models, which evaluated baseline and time-updated information (neural network, LASSO, random forests, support vector machines), and Cox regression.


RESULTS
Analysis of 2,994,837 individuals (3.2% AF) identified time-varying neural networks as the optimal model achieving an AUROC of 0.827 vs. 0.725, with number needed to screen of 9 vs. 13 patients at 75% sensitivity, when compared with the best existing model CHARGE-AF. The optimal model confirmed known baseline risk factors (age, previous cardiovascular disease, antihypertensive medication usage) and identified additional time-varying predictors (proximity of cardiovascular events, body mass index (both levels and changes), pulse pressure, and the frequency of blood pressure measurements).


CONCLUSION
The optimal time-varying machine learning model exhibited greater predictive performance than existing AF risk models and reflected known and new patient risk factors for AF.",2019,PLoS ONE
Reflections on the quality of mining EIA reports in South Africa,"Environmental impact assessment (EIA) was first introduced in the USA in 1969 and is considered one of the most successful policy interventions of the last few decades, with over one hundred countries practising environmental assessment (Glasson et al.10; Interparliamentary Union12; Lee and George14; Wood29). However, internationally the effectiveness of EIA is a particular concern amongst EIA practitioners (Barker and Wood2; Wood29; Christensen et al.5). One important causal component of effectiveness deals with the quality of the report emanating from the EIA process, i.e. the environmental impact report (EIR), also referred to as the environmental impact statement (EIS) or simply the environmental statement (ES). It is argued that poor quality reports would invariably lead to ineffectiveness since they contain the information that serves as the basis for decision making. South Africa adopted mandatory EIA in 1997 at a relatively late stage of its global diffusion, by virtue of a set of regulations promulgated in terms of the Environment Conservation Act (ECA), Act No. 73 of 1989 (South Africa21, 23). These regulations contained a list of activities for which EIA was mandatory. Notably, mining activities were excluded from this list. In 1998, the ECA was partially repealed in favour of the National Environmental Management Act, Act No. 107 of 1998 (NEMA) (South Africa24), with only a few sections, including 21, 22 and 26, together with the regulations promulgated in 1997, remaining in force. These were finally repealed in 2006 when EIA regulations in terms of NEMA came fully into effect after a lengthy revision process. The NEMA is framework legislation allowing for other government departments such as the Department of Minerals and Energy (DME) and the Department of Water Affairs and Forestry (DWAF) to promulgate separate sets of sectoral specific legislation. Since the beginning of mandatory EIA, the designated competent authority for EIA authorization was the national Department of Environmental Affairs and Tourism (DEAT), and the various provincial environmental departments, with the exception of mining projects, for which the Department of Minerals and Energy (DME) was the competent authority. This resulted in the unique dualistic South African system for environmental authorizations. This dualistic system was caused partly by a different route for EIA development in the Reflections on the quality of mining EIA reports in South Africa",2008,Journal of The South African Institute of Mining and Metallurgy
On Identification of Sparse Multivariable ARX Model: A Sparse Bayesian Learning Approach,"This paper begins with considering the identification of sparse linear time-invariant networks described by multivariable ARX models. Such models possess relatively simple structure thus used as a benchmark to promote further research. With identifiability of the network guaranteed, this paper presents an identification method that infers both the Boolean structure of the network and the internal dynamics between nodes. Identification is performed directly from data without any prior knowledge of the system, including its order. The proposed method solves the identification problem using Maximum a posteriori estimation (MAP) but with inseparable penalties for complexity, both in terms of element (order of nonzero connections) and group sparsity (network topology). Such an approach is widely applied in Compressive Sensing (CS) and known as Sparse Bayesian Learning (SBL). We then propose a novel scheme that combines sparse Bayesian and group sparse Bayesian to efficiently solve the problem. The resulted algorithm has a similar form of the standard Sparse Group Lasso (SGL) while with known noise variance, it simplifies to exact re-weighted SGL. The method and the developed toolbox can be applied to infer networks from a wide range of fields, including systems biology applications such as signaling and genetic regulatory networks.",2016,ArXiv
Uniformly valid confidence intervals for conditional treatment effects in misspecified high-dimensional models.,"Eliminating the effect of confounding in observational studies typically involves fitting a model for an outcome adjusted for covariates. When, as often, these covariates are high-dimensional, this necessitates the use of sparse estimators such as the Lasso, or other regularisation approaches. Naiive use of such estimators yields confidence intervals for the conditional treatment effect parameter that are not uniformly valid. Moreover, as the number of covariates grows with sample size, correctly specifying a model for the outcome is non-trivial. In this work, we deal with both of these concerns simultaneously, delivering confidence intervals for conditional treatment effects that are uniformly valid, regardless of whether the outcome model is correct. This is done by incorporating an additional model for the treatment-selection mechanism. When both models are correctly specified, we can weaken the standard conditions on model sparsity. Our procedure extends to multivariate treatment effect parameters and complex longitudinal settings.",2019,arXiv: Methodology
Organochlorine pollutants and population status of least terns in South Carolina,"Most populations of Least Terns (Sterna albifrons) in the United States are reportedly declining or experiencing poor reproductive success (Fisk 1975, Massey 1974). The California race (S. a. browni) is classified as ""endangered"" by the U.S. Fish and Wildlife Service (Wilbur 1974) and the eastern race (S. a. antillarum) is classified as ""threatened"" by the State of Florida. Interior Least Tern (S. a. athalassos) populations are apparently experiencing much the same problems as those of the other races (R. Downing, pers. comm.). Little Tern (S. a. albifrons) populations in Great Britain and Ireland have steadily decreased since the early 1930's (Norman and Saunders 1969). Sprunt and Chamberlain (1949), in the last evaluation of the Least Tern in South Carolina described its population status as ""completely satisfactory."" Recent concern about the future of the Least Tern and the need for updating its status in South Carolina prompted us to study its population status and reproductive success in that state, particularly in relation to organochlorine pollutants.",1979,The Wilson Journal of Ornithology
Multivariate Statistical Analysis for Estimating Grassland Leaf Area Index and Chlorophyll Content using Hyperspectral Data,"DISCLAIMER This document describes work undertaken as part of a programme of study at the Faculty of Geo-Information Science and Earth Observation of the University of Twente. All views and opinions expressed therein remain the sole responsibility of the author, and do not necessarily represent those of the Faculty. ABSTRACT Grassland habitat covers about one-quarter of the Earth's land surface, providing significant contribution to the world's total agricultural production, plant biodiversity, and carbon sequestration. Remote sensing (RS) provides a practical and cost-effective means for quantifying grassland biophysical and biochemical properties. However, grassland presents a challenge for RS due to the complexity of their spectral response. The advent of hyperspectral RS and the future launch of planned spaceborne hyperspectral missions will open up new possibilities over conventional multispectral RS to better quantify grassland characteristics. In this regard, hyperspectral data, while rich in information, presents a challenge for analysis due to its high dimensionality and multicollinearity. This present study investigated four selected high dimensional multivariate regression methods namely partial least squares regression (PLSR), regularization and shrinkage method Lasso, nonparametric Random Forest (RF) regression, and ensemble method Bayesian model averaging (BMA) to predict grassland leaf area index (LAI) and chlorophyll using field canopy hyperspectral measurements (n=185). For each regression model, three spectral transformations namely continuum-removal, first-derivative, and pseudo-absorbance were evaluated. The results showed that relatively good predictive accuracy could be obtained for canopy-integrated chlorophyll content (cross-validated R 2 =0.760; relative RMSE=32.1% or 0.28) and LAI (R 2 =0.719; relative RMSE=28.9% or 0.81), whereas leaf chlorophyll content could be predicted with relatively low accuracy (R 2 =0.492; relative RMSE=14.8% or 4.45). Multivariate methods utilizing all wavebands (whole spectral analysis) outperformed Lasso which performed waveband selection (optimal spectral analysis), suggesting some loss of information in the latter. Compared to the gold-standard model PLSR, no significant improvement in accuracy was obtained by the alternative multivariate regression models. Further, the spectral transformations in general did not significantly improve the accuracy either. This could suggest that the prediction errors were likely the results of grassland canopy spectral complexity due to heterogeneity such as the presence of different grass species having different canopy architecture. Therefore, approaches that explicitly account for structural differences such as model stratification based on species, incorporation of multiple structural parameters as in 3-D radiative transfer model for heterogeneous canopy, and data integration with radar or lidar capable of extracting the structural parameters are potentially useful. â€¦",2015,
"The gastropod genus Thalassocyon Barnard, 1960","Summary The tonnacean genus Thalassocyon Barnard, 1960 contains only two species, T. bonus Barnard, 1960 from deep water off South Africa and T. mi Dell, 1967 from deep water off northern New Zealand. The genus is removed from the Cymatiidae and placed in the Ficidae on the basis of shell morphology, the reduced periostracum and the details of the radula.",1969,New Zealand Journal of Marine and Freshwater Research
Increasing the Complexity Minireview of Coactivation in Nuclear Receptor Signaling,"Cell Biology ProgramMemorial Sloan-Kettering Cancer CenterNew York, New York 10021ligand-dependent transactivation function maps to theNuclear receptors lead somewhat of a double life. In C terminus of this domain (AF2; Figure 1). A second,many respects, these proteins are indistinguishable ligand-independent activation function (AF1) resideswithin the N terminus of many but not all nuclear recep-fromothereukaryoticfactorsthatregulatetranscription.tors. Besides sequence homology, p160 proteins shareNuclear receptors bind selectively to DNA, primarily asan ability to stimulate ligand-dependent transactivationdimers through two characteristic zinc finger modulesbyaratherlargenumberofnuclearreceptorsintransientand a dimerization region that directs self-interaction oroverexpression experiments. A distinctive structural fea-hetero-partnering. Moreover, they possess identifiableture of the p160 coactivators is the presence of multipleactivationfunctions(AFs)thatconfertransactivationpo-LXXLL signature motifs (also called LXDs, NR boxes, ortential toheterologous DNA-bindingdomains. However,NIDs), which comprise determinants for direct interac-an important feature of nuclear receptors that distin-tions with the nuclear receptor LBD.guishes them from other transcription factors is thatAlthough the amino acid context surrounding thethese proteins possess a hair-trigger switch, which is LXXLL motif appears to influence selectivity of interac-conferredbytheirligand-bindingdomain(LBD).Itishere tion,itisunclearatthispointwhat,ifanything,influencesthat the receptors have evolved their uncanny ability to the specificityof nuclear receptor/p160binding. Severalstifle intrinsictransactivation potentialswhen notbound recent LBD crystal structures have established thatbytheircognateligandsandtoimmediatelyinducethem upon ligand binding, the a helix containing the AF2 corewhenagivenligandmakesastereospecific,high-affinity (helix 12) undergoes a major reorientation in the contextinteraction with a pocket in the LBD waiting to accomo- of the overall LBD structure, forming part of a â€œchargeddate it. clampâ€ that accommodates p160 coactivators within aThe ligands for nuclear receptors include steroids, hydrophobic cleft of the LBD; this occurs through directretinoids, vitamin D, thyroid hormone, prostanoids, and contacts with the LXXLL motif (reviewed in Xu et al.,farnesoids. Their combined effects are vast, influencing 1999). Remarkably, estrogen antagonists such as ta-virtually every fundamental biological process, from de- moxifen and raloxifene appear to alter the position ofvelopment and homeostasis, to proliferation and differ- the AF2 core such that helix 12 itself occupies the hy-entiation. As more ligands have been uncovered for or- drophobiccleft inthe LBD,thereby precludingcoactiva-phan receptors, it is becoming increasingly apparent tor binding (Brzozowski et al., 1997; Shiau et al., 1998).that nonendocrine pathways, including those involving In fact, several experiments preceding these crystalprotein kinases and metabolic products, are also re- structure analyses indicated that a key mechanistic ef-sponsible for signaling. Because this family of receptors fectofhormonalantagonistsistoinhibitp160interactionare intracellular, they are direct mediators of the action with the LBD, supporting the biological relevance ofoftheircognatehormone.Althoughsomesteroidrecep- coactivators in nuclear receptor function.tors are compartmentalized initially to the cytoplasm as Insight into a potential mechanism of p160 coactiva-complexes with heat shock proteins acting as chaper- tion came with the finding that SRC-1 is capable ofones and subsequently translocate to the nucleus as interacting with the C terminus of CBP/p300 and to-a consequence of ligand binding, most receptors are gether they can coactivate synergistically (Yao et al.,prelocalized to the nucleus. How then do the ligands 1996). Inaddition, CBP/p300 itself interactsdirectly withexert their inducing effects on nuclear receptor activity nuclear receptors in a ligand-dependent manner, againif they already reside in the nucleus (presumably DNA- through the AF2 domain (Chakravarti et al., 1996; Kameibound), and how do some receptors become activated et al., 1996). CBP/p300 and p160 coactivators both pos-sess intrinsic histone acetyl transferase (HAT) activityby kinase cascades independently of their cognate li-and therefore may be acting in concert to remodel chro-gands? The answer appears to be reflected in anothermatin.Moreover, p/CAF,themammalianhomolog oftheaspect of the double life of nuclear receptors: an initialassociation with transcriptional",1999,
Conservative reconstruction using stents as salvage therapy for disruption of esophago-gastric anastomosis.,"Esophagectomy with extended lymphadenectomy and gastric conduit reconstruction is a radical procedure for the treatment of esophageal cancer that is associated with a high morbidity rate. Gastric conduit necrosis is a fatal complication that occurs in 2% of patients. Conventionally, two-stage salvage surgery consisting of removal of the necrotic gastric conduit followed by reconstruction has been performed; however, this procedure has a high morbidity rate. We describe a 61-year-old man who underwent minimally invasive esophagectomy complicated by slowly progressive gastric conduit necrosis associated with complete neck drainage and a stable overall condition. There was a 2 cm gap in the anastomosis. Because there was no evidence of residual gastric conduit necrosis, a removable, covered self-expanding metal stent (SEMS) was inserted to bridge the anastomosis. The stent was fixed to the patient's ear with silk thread through the lasso on its proximal end to prevent migration. Eight weeks after insertion, the stent was removed easily without any associated complications. The anastomotic defect was completely bridged with granulation tissue, showing progressive epithelialization without leakage or stenosis. The patient was discharged home in good general health. This is the first report of the successful conservative management of esophago-gastric conduit anastomosis disruption with SEMS placement.",2015,World journal of gastroenterology
Studentsâ€™ Ability in Transforming a Sentence: Deep and Surface Structure,"The present study aims at exploring studentsâ€™ difficulties in determining deepand surface structure in sentences. The study used quantitative descriptive as aresearch design. Test and questionnaire were employed as data collectiontechnique. The population of the study is all seventh semester students ofEnglish Education Department, since they have studied syntax in the previoussemesters. 50 students were sampled in this study. The study reveals that mostof students cannot transform deep structure into surface structure. They onlycan identify the surface structure of simple sentences. The study also showsthat English Education Department students find much difficulty in determiningthe labeling of the words in surface structure, for they cannot classify the classof wordos in surface structure. The study suggests that the ability todifferentiate word categories be essential in transforming the surface structuregenerated through deep structure.",2017,
"The lasso, persistence, and cross-validation","During the last fifteen years, the lasso procedure has been the target of a substantial amount of theoretical and applied research. Correspondingly, many results are known about its behavior for a fixed or optimally chosen smoothing parameter (given up to unknown constants). Much less, however, is known about the lasso's behavior when the smoothing parameter is chosen in a data dependent way. To this end, we give the first result about the risk consistency of lasso when the smoothing parameter is chosen via cross-validation. We consider the high-dimensional setting wherein the number of predictors p = nÎ±, Î± > 0 grows with the number of observations.",2013,
"[Immunobiological ""Allassotherapy"" in sarcoidosis. Method and results (author's transl)].",Immunobiological allassotherapy is performed with subcutaneous injections of a mixture of old tuberculin and blood of a healthy donor of the same blood group who is highly sensitive to tuberculin and additional BCG injections. The results and experience over 15 years with this treatment show the advantages of this method in a series of patients with proved resistance to therapy and a poor prognosis compared with methods previously possible.,1976,"MMW, Munchener medizinische Wochenschrift"
Progress in Time Transfer by Laser Pulses,"Time transfer by laser pulses is based on the propagation of light pulses between satellite and ground clocks or between remote clocks on earth. It will realize the synchronization of these clocks with high accuracy and stability. Several experiments of the time transfer by laser pulses had been successfully carried out in some countries. These experiments validate the feasibility of the synchronization of clocks by laser pulses. The paper describes the results of these experiments. The time comparison by laser pulses between atomic clocks on aircraft and ground ones in the United States, and the LASSO and T2L2 projects in France are introduced in detail.",2004,Progress in Astronomy
Sparse Generalized Principal Component Analysis for Large-scale Applications beyond Gaussianity,"Principal Component Analysis (PCA) is a dimension reduction technique. It produces inconsistent estimators when the dimensionality is moderate to high, which is often the problem in modern large-scale applications where algorithm scalability and model interpretability are difficult to achieve, not to mention the prevalence of missing values. While existing sparse PCA methods alleviate inconsistency, they are constrained to the Gaussian assumption of classical PCA and fail to address algorithm scalability issues. We generalize sparse PCA to the broad exponential family distributions under high-dimensional setup, with built-in treatment for missing values. Meanwhile we propose a family of iterative sparse generalized PCA (SG-PCA) algorithms such that despite the non-convexity and non-smoothness of the optimization task, the loss function decreases in every iteration. In terms of ease and intuitive parameter tuning, our sparsity-inducing regularization is far superior to the popular Lasso. Furthermore, to promote overall scalability, accelerated gradient is integrated for fast convergence, while a progressive screening technique gradually squeezes out nuisance dimensions of a large-scale problem for feasible optimization. High-dimensional simulation and real data experiments demonstrate the efficiency and efficacy of SG-PCA.",2015,arXiv: Computation
Simulation of multiple functions of the retinal circuitry: a computational and a hardware model,"Experimental findings showed that retinal signal process-ing is not a linear light-to-spike conversion mechanismbut is composed of nonlinear computations that realizecomplex visual functions. However, even before lighttransduction at the photoreceptor (PR) layer, the image iscomplicated by sudden saccadic eye movements. It waspreviously shown that certain retinal ganglion cells (GC)alleviate this problem by segregating object motion fromglobal motion [1]. Even for a stationary scene, due tothose saccades, a different image impinges on the retinafor short periods, thus complicating retinal computation.Previous reports showed that a class of GCs can encodevisual stimulation based on the latencies of the first spikesrather than complex features of the spike train [2], so thatwithin those short periods, rapid neural coding can berealized efficiently. Although ""segregation"" and ""rapidneural coding"" mechanisms are observed at GC layer, itwas shown that those mechanisms arised from inter-reti-nal neurons such as horizontal cells (HC), bipolar cells(BC) and amacrine cells (AC) [1,2]. Specifically, wide-field amacrine cells (wfAC) are believed to play an impor-tant role in ""segregation"" mechanism by providing timedinhibition to blank out excitatory signals produced by glo-bal movements [1]. The latency between On- and Off- BCpathways are found to be critical for ""rapid neural coding""mechanisms [2]. Although separate models can realizethose mechanisms by means of GC responses, each classof retinal neurons were largely omitted in those models[1,2]. Here, we present a spatio-temporal model of the ret-inal circuit [3], combining temporal cellular responsefunctions and anatomical inter-cellular connections. Themodel was constructed in a two-dimensional grid andeach pixel of the grid was composed of eight cell elementsrepresenting PR, HC, On- and Off- BCs, On- and Off- ACs,On-Off wfAC and On-Off GC. For each of the cell ele-ments, the response function was governed by push-pulldifferential equations [4] in which chemical/electricalsynaptic inputs as well as intrinsic membrane dynamicswere implemented. Additionally, same retinal circuitrywas re-designed by using CMOS elements and the modelresponse tested by a SPICE simulator [5]. In the presentstudy, not only center-surround antagonistic receptivefields of BCs and GC, but also complex visual functionssuch as ""object motion segregation from a backgroundmotion"" (Figure 1, left panel) and ""rapid neural coding""",2009,BMC Neuroscience
Learning graph structure with parametric and non-parametric models,"In discrete undirected graphical models, the conditional independence of the node labels Y is specified by the graph structure. We study the case where there is another input random vector X (e.g. observed features) such that the distribution P(Y | X) is determined by functions of X that characterize the (higher-order) interactions among the Y's. The main contribution is to learn the graph structure and the functions conditioned on X at the same time. 
Parameterizing the graphical models with potential functions might lead to overparameterization. We prove that the discrete undirected graphical models with feature X are equivalent to the multivariate discrete models. The reparameterization of the potential functions in graphical models by conditional log odds ratios of the latter offers advantages in the representation of the conditional independence structure. And the two parameterizations are proved to be equivalent. In addition, the spaces of conditional log odds ratios can be chosen flexibly. They could be linear functional spaces (parametric), or separable Reproducing Kernel Hilbert Spaces determined by kernels (non-parametric). 
To obtain a sparse estimation of the graph structure, we impose a Structure Lasso (SLasso) penalty on groups of the conditional log odds ratios to learn the graph structure. These groups with overlaps are designed to enforce hierarchical function selection. An efficient gradient descent algorithm is given to estimate the complete model. The global convergence of the algorithm is guaranteed. And a greedy approach is applied when the graph is large. The BGACV tuning method is derived to select the tuning parameter. It achieves satisfactory numerical results in simulation studies. The asymptotic analysis shows that the SLasso method is consistent in terms of estimating the graph structure. The consistency properties hold for both the parametric models and the non-parametric models. The experiments show that the SLasso method is able to recover the graph structure with increasing sample size. It also outperforms other methods in the simulation studies.",2012,
FirmNet: A Sparsity Amplified Deep Network for Solving Linear Inverse Problems,"Recovering a sparse signal from a noisy linear measurement is an important problem in signal processing. Typically, one employs greedy pursuit techniques such as OMP, CoSaMP to solve an ${\ell _0}$ regular- ization problem. For large-scale problems, iterative shrinkage tech- niques such as ISTA, FISTA, ${\text{AMP}} - {\ell _1}$ have been introduced. The underlying formulation in the iterative algorithms is a LASSO prob- lem with an ${\ell _1}$-penalty. It is known in the literature that an ${\ell _1}$-penalty in LASSO suffers from underestimation of large signal amplitudes. Also, the iterative shrinkage-based approaches such as ISTA typi- cally have only one free parameter to trade-off between noise variance and sparsity. We consider a minimax-concave penalty-based formulation, which offers an unbiased estimate of the sparse signal. The resulting iterative firm-thresholding algorithm is restructured as a DNN architecture called FirmNet. The proposed network, FirmNet, has two interpretable shrinkage function parametersâ€“one that controls the noise variance, and the other that allows for explicit sparsity control. We compare the network with a broader network architecture of Learned-ISTA (LISTA), and show that it outperforms in terms of the probability-of-error-in-support (PES)-a strong support recovery metric, by at least three-fold. We also observe an improve- ment of 2 to 4 dB in reconstruction SNR compared with LISTA.",2019,"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Linear growth faltering in infants is associated with Acidaminococcus sp. and community-level changes in the gut microbiota,"BackgroundChronic malnutrition, termed stunting, is defined as suboptimal linear growth, affects one third of children in developing countries, and leads to increased mortality and poor developmental outcomes. The causes of childhood stunting are unknown, and strategies to improve growth and related outcomes in children have only had modest impacts. Recent studies have shown that the ecosystem of microbes in the human gut, termed the microbiota, can induce changes in weight. However, the specific changes in the gut microbiota that contribute to growth remain unknown, and no studies have investigated the gut microbiota as a determinant of chronic malnutrition.ResultsWe performed secondary analyses of data from two well-characterized twin cohorts of children from Malawi and Bangladesh to identify bacterial genera associated with linear growth. In a case-control analysis, we used the graphical lasso to estimate covariance network models of gut microbial interactions from relative genus abundances and used network analysis methods to select genera associated with stunting severity. In longitudinal analyses, we determined associations between these selected microbes and linear growth using between-within twin regression models to adjust for confounding and introduce temporality. Reduced microbiota diversity and increased covariance network density were associated with stunting severity, while increased relative abundance of Acidaminococcus sp. was associated with future linear growth deficits.ConclusionsWe show that length growth in children is associated with community-wide changes in the gut microbiota and with the abundance of the bacterial genus, Acidaminococcus. Larger cohorts are needed to confirm these findings and to clarify the mechanisms involved.",2015,Microbiome
The Symmetry of a Simple Optimization Problem in Lasso Screening,"Recently dictionary screening has been proposed as an effective way to improve the computational efficiency of solving the lasso problem, which is one of the most commonly used method for learning sparse representations. To address today's ever increasing large dataset, effective screening relies on a tight region bound on the solution to the dual lasso. Typical region bounds are in the form of an intersection of a sphere and multiple half spaces. One way to tighten the region bound is using more half spaces, which however, adds to the overhead of solving the high dimensional optimization problem in lasso screening. This paper reveals the interesting property that the optimization problem only depends on the projection of features onto the subspace spanned by the normals of the half spaces. This property converts an optimization problem in high dimension to much lower dimension, and thus sheds light on reducing the computation overhead of lasso screening based on tighter region bounds.",2016,ArXiv
Size assortment in mixed-species groups of juvenile-phase striped parrotfish (Scarus iserti) in The Bahamas,"Striped parrotfish (Scarus iserti) often form heterospecific groups with other reef fishes. In this study, we examined the species and body size composition of these groups on reefs in The Bahamas. Groups averaged approximately 4 S.Â iserti and 2 associated species, with surgeonfish (Acanthurus chirurgus and A.Â bahianus), slippery dick (Halichoeres bivittatus), and bluehead wrasse (Thalassoma bifasciatum) as the most common associates. Fewer groups than expected had only 1 associate; groups with 3 or more associates were more common than expected. Both the S.Â iserti and associated species tended to be closely size-matched within a group, perhaps due to benefits of size assortment in lowering predation risk. Likewise, the high frequency of groups with greater than a single associate species suggests that associates may benefit from not being the only phenotypically different individual in a group.",2012,Ichthyological Research
Abyssal nematode assemblages in physically disturbed and adjacent sites of the eastern equatorial Pacific,"The nematode assemblages of experimentally impacted and adjacent sediments in abyssal depths of the eastern equatorial Pacific were investigated 7 years after a physical disturbance. A total of 3048 nematodes belonging to 68 genera and 26 families were identified. The nematode fauna at both disturbed and control sites was dominated by specimens belonging to the genera Acantholaimus, Chromadorita, Thalassomonhystera, Desmoscolex, Halalaimus and Diplopeltula. These genera contribute to about 55% and 50% of total nematode fauna in the disturbed and control sites, respectively. The mean relative abundance of the dominant genus Acantholaimus amounted to about 20%. Generic diversity, evenness and richness at the undisturbed sites do not significantly differ from the corresponding median values at the disturbed sites. Mean k-dominance curves show differences in community structure between treatments. Ordination of square- and fourth-root-transformed family abundances revealed groupings of the disturbed and undisturbed samples (significant at the 5% level), whereas ordination of genus abundances did not. Sample variability was investigated by inspection of the relationship between variance and mean abundance of genera and families in each sample group and by calculating the comparative index of multivariate dispersion (IMD). There is a clear increase in the standard deviation for a given mean of genus or family abundances at the disturbed sites. A higher variability among the disturbed samples, however, does not appear to be true in the multivariate sense.",2001,Deep-sea Research Part Ii-topical Studies in Oceanography
Gradually atom pruning for sparse reconstruction and extension to correlated sparsity,"We propose a new algorithm for recovery of sparse signals from their compressively sensed samples. The proposed algorithm benefits from the strategy of gradual movement to estimate the positions of non-zero samples of sparse signal. We decompose each sample of signal into two variables, namely â€œvalueâ€ and â€œdetectorâ€, by a weighted exponential function. We update these new variables using gradient descent method. Like the traditional compressed sensing algorithms, the first variable is used to solve the Least Absolute Shrinkage and Selection Operator (Lasso) problem. As a new strategy, the second variable participates in the regularization term of the Lasso (l1 norm) that gradually detects the non-zero elements. The presence of the second variable enables us to extend the corresponding vector of the first variable to matrix form. This makes possible use of the correlation matrix for a heuristic search in the case that there are correlations among the samples of signal. We compare the performance of the new algorithm with various algorithms for uncorrelated and correlated sparsity. The results indicate the efficiency of the proposed methods.",2012,20th Iranian Conference on Electrical Engineering (ICEE2012)
Marine Fungi from Easter Island and Notes on Thalassoascus,"SUMMARY Six marine Ascomycetes and four Fungi Imperfecti were discovered on Easter Island (southern Pacific Ocean) on driftwood, intertidal wood, and washed-up algae (Zonaria sp.). All are new records for this island, and most of them are new records for the South Pacific. Ascospores of sand-inhabiting fungi occur in sea foam. The marine mycota of Easter Island is considered tropical to subtropical. Thalassoascus lessoniae sp. nov. is a parasite on holdfasts of Lessonia nigrescens on the coast of central Chile. The new binomial T. cystoseirae is proposed and a key to the species of Thalassoascus is provided.",1981,Mycologia
Operation and data analysis in the LASSO experiment,"LASSO is a time transfer experiment which uses a laser link to a geostationary satellite. It allows time comparisons between remote clocks. A new concept of operation is proposed: the comparison of ground clocks by monitoring the satellite clock seen from each station. This technique has been successfully tested between McDonald Observatory (Texas) and the Observatoire de la Cote d'Azur (France). The common sessions show that LASSO allows intercontinental time transfer, as well as satellite clock monitoring, with a precision better than 100 picoseconds.",1995,Metrologia
Prediction of Aneurysm Stability Using a Machine Learning Model Based on PyRadiomics-Derived Morphological Features.,"Background and Purpose- Discrimination of the stability of intracranial aneurysms is critical for determining the treatment strategy, especially in small aneurysms. This study aims to evaluate the feasibility of applying machine learning for predicting aneurysm stability with radiomics-derived morphological features. Methods- Morphological features of 719 aneurysms were extracted from PyRadiomics, of which 420 aneurysms with Maximum3DDiameter ranging from 4 mm to 8 mm were enrolled for analysis. The stability of these aneurysms and other clinical characteristics were reviewed from the medical records. Based on the morphologies with/without clinical features, machine learning models were constructed and compared to define the morphological determinants and screen the optimal model for predicting aneurysm stability. The effect of clinical characteristics on the morphology of unstable aneurysms was analyzed. Results- Twelve morphological features were automatically extracted from PyRadiomics implemented in Python for each aneurysm. Lasso regression defined Flatness as the most important morphological feature to predict aneurysm stability, followed by SphericalDisproportion, Maximum2DDiameterSlice, and SurfaceArea. SurfaceArea (odds ratio [OR], 0.697; 95% CI, 0.476-0.998), SphericalDisproportion (OR, 1.730; 95% CI, 1.143-2.658), Flatness (OR, 0.584; 95% CI, 0.374-0.894), Hyperlipemia (OR, 2.410; 95% CI, 1.029-5.721), Multiplicity (OR, 0.182; 95% CI, 0.082-0.380), Location at middle cerebral artery (OR, 0.359; 95% CI, 0.134-0.902), and internal carotid artery (OR, 0.087; 95% CI, 0.030-0.211) were enrolled into the final prediction model. In terms of performance, the area under curve of the model reached 0.853 (95% CI, 0.767-0.940). For unstable aneurysms, Compactness1 ( P=0.035), Compactness2 ( P=0.036), Sphericity ( P=0.035), and Flatness ( P=0.010) were low, whereas SphericalDisproportion ( P=0.034) was higher in patients with hypertension. Conclusions- Morphological features extracted from PyRadiomics can be used for aneurysm stratification. Flatness is the most important morphological determinant to predict aneurysm stability. Our model can be used to predict aneurysm stability. Unstable aneurysm is more irregular in patients with hypertension.",2019,Stroke
Nonparametric Bootstrap Inference for the Targeted Highly Adaptive LASSO Estimator.,"The Highly-Adaptive-LASSO Targeted Minimum Loss Estimator (HAL-TMLE) is an efficient plug-in estimator of a pathwise differentiable parameter in a statistical model that at minimal (and possibly only) assumes that the sectional variation norm of the true nuisance functional parameters (i.e., the relevant part of data distribution) are finite. It relies on an initial estimator (HAL-MLE) of the nuisance functional parameters by minimizing the empirical risk over the parameter space under the constraint that the sectional variation norm of the candidate functions are bounded by a constant, where this constant can be selected with cross-validation. In this article, we establish that the nonparametric bootstrap for the HAL-TMLE, fixing the value of the sectional variation norm at a value larger or equal than the cross-validation selector, provides a consistent method for estimating the normal limit distribution of the HAL-TMLE. 
In order to optimize the finite sample coverage of the nonparametric bootstrap confidence intervals, we propose a selection method for this sectional variation norm that is based on running the nonparametric bootstrap for all values of the sectional variation norm larger than the one selected by cross-validation, and subsequently determining a value at which the width of the resulting confidence intervals reaches a plateau. 
We demonstrate our method for 1) nonparametric estimation of the average treatment effect based on observing on each unit a covariate vector, binary treatment, and outcome, and for 2) nonparametric estimation of the integral of the square of the multivariate density of the data distribution. In addition, we also present simulation results for these two examples demonstrating the excellent finite sample coverage of bootstrap-based confidence intervals.",2019,arXiv: Statistics Theory
"Thalassomermis megamphis n. gen., n. sp. (Mermithidae: Nemata) from the Bathyal South Atlantic Ocean.","Thalassomermis megamphis n. gen., n. sp. (Mermithidae: Nemata) was extracted from sediment collected off the coast of Brazil at a depth of approximately 1,000 m. Although the food of this new nematode is unknown, the reduction of the stoma and esophagus and presence of a trophosome indicate that it is parasitic in its juvenile stages. Thalassomermis megaraphis n. gen., n. sp. is assigned to Mermithidae because of its similarity to that family in the appearance of the cephalic sensory receptors, the long and tubular vagina, and copulatory muscles of the male extending posteriorly throughout most of the length of the tail. Thalassomermis megamphis n. gen., n. sp. differs from all other members of Mermithidae by the large, lenticular, intracuticular amphidial fovea with coiled, emergent terminal filaments as well as the small amphidial aperture situated over the center of the fovea.",1997,Journal of nematology
Incontinence urinaire de la femme en milieu urbain au Burkina Faso: EnquÃªte Ã©pidemiologique auprÃ¨s de 759 femmes Ã  Bobo Dioulasso,"Objectifs : Determiner la prevalence de l'incontinence urinaire, identifier les facteurs de risque et apprecier les retentissements de cette affection sur la vie des femmes. 
Patientes et methodes : Etude prospective et transversale sur l'incontinence urinaire (UI) de la femme en milieu urbain au Burkina Faso. Il s'agit d'une enquete epidemiologique qui s'est deroulee de janvier 2003 a avril 2003 aupres de 759 femmes se rendant dans quelques formations sanitaires de la ville de Bobo-Dioulasso. 
Resultats : L'age moyen des femmes etait de 29,8 ans, la gestite et la parite moyenne respectivement de 3 et 2,6. La majorite d'entre elles (63,6%) etaient des femmes au foyer dont 65,5% de mariees. La prevalence globale de l'IU etait de 21,3% et l'incontinence urinaire d'effort (IUE) etait le type dominant (54,6%). Concernant les facteurs de risque, seules la dystocie, les in-fections urinaires a repetition, la constipation chronique, l'episiotomie et l'obesite restaient associes significativement a la survenue de l'IU, apres une analyse multivariee utilisant le mode de regression logistique. Le retentissement de l'IU a ete apprecie en terme de cout physique et surtout psychosocial ; le cout economique etant impossible a evaluer dans notre contexte. 
Conclusion : L'incontinence urinaire est frequente dans notre region malgre le peu de cas vus dans les services de gynecologie et d'urologie. Une enquete de ce type realisee en population generale et a l'echelle nationale permettrait de mieux apprecier l'amp-leur du probleme et identifier les elements necessaires a une strategie de prise en charge adequate de cette pathologie. Female Urinary Incontinence in an Urban Area in Burkina Faso: Epidemiological Study of 759 Women in the City of Bobo-Dioulasso 
Objective: To evaluate the prevalence of urinary incontinence, identify its risk factors and describe its effects on the life of women affected by it in an urban area in Burkina Faso. 
Patients and Methods: This prospective study was carried out between January and April 2003 and was based on interviews with 759 female patients presenting to the Department of Urology, Sanou Souro Teaching Hospital, and five other medical centers in the city of Bobo-Dioulasso. By means of a questionnaire we collected information on socio-demographic patient characteristics, history of previous surgical or gynecological interventions, type of urine loss and the effects of urinary incontinence on the patients\' physical, psychological and economical condition. 
Results: The mean age of the patients was 29,8 years. The majority (63.6%) were housewives, 65.5% of them married. The overall prevalence of urinary incontinence was 21,3% with a predominance (54,6%) of stress urinary incontinence. Multivariate analysis of the risk factors (using the logistic regression model) showed that the following risk factors were significantly associated with urinary incontinence: dystocia, repeated urinary tract infections, chronic constipation, episiotomy and obesity. The physical and psycho-social effect of urinary incontinence on the patients is described. 
Conclusion: Urinary incontinence is frequently encountered in our environment although only few cases are seen in our gynecology and urology departments. A population-based investigation on a national scale will allow for a better judgment of the actual extent of the problem and will help to establish a strategy on how to better control it. African Journal of Urology Vol.11(1) 2005: 45-54",2005,African Journal of Urology
Learning Clique Forests,"We propose a topological learning algorithm for the estimation of the conditional dependency structure of large sets of random variables from sparse and noisy data. The algorithm, named Maximally Filtered Clique Forest (MFCF), produces a clique forest and an associated Markov Random Field (MRF) by generalising Prim's minimum spanning tree algorithm. To the best of our knowledge, the MFCF presents three elements of novelty with respect to existing structure learning approaches. The first is the repeated application of a local topological move, the clique expansion, that preserves the decomposability of the underlying graph. Through this move the decomposability and calculation of scores is performed incrementally at the variable (rather than edge) level, and this provides better computational performance and an intuitive application of multivariate statistical tests. The second is the capability to accommodate a variety of score functions and, while this paper is focused on multivariate normal distributions, it can be directly generalised to different types of statistics. Finally, the third is the variable range of allowed clique sizes which is an adjustable topological constraint that acts as a topological penalizer providing a way to tackle sparsity at $l_0$ semi-norm level; this allows a clean decoupling of structure learning and parameter estimation. The MFCF produces a representation of the clique forest, together with a perfect ordering of the cliques and a perfect elimination ordering for the vertices. As an example we propose an application to covariance selection models and we show that the MCFC outperforms the Graphical Lasso for a number of classes of matrices.",2019,ArXiv
Moderately clipped LASSO,"The least absolute shrinkage and selection operator (LASSO) has been widely used in high-dimensional linear regression models. However, it is known that the LASSO selects too many noisy variables. In this paper, we propose a new estimator, the moderately clipped LASSO (MCL), that deletes noisy variables successively without sacrificing prediction accuracy much. Various numerical studies are done to illustrate superiority of the MCL over other competitors.",2015,Comput. Stat. Data Anal.
Grand Canal; Topographic Views,"Around Santa Lucia railway station, view along the north wall; The Grand Canal (Italian: Canal Grande, Venetian: Canalasso) is the most important canal in Venice, Italy. It forms one of the major water-traffic corridors in the city. Public transport is provided by water buses and private water taxis, but many tourists visit it by gondola. At one end the canal leads into the lagoon near Santa Lucia railway station and the other end leads into Saint Mark Basin: in between it makes a large S-shape through the central districts (""sestieri"") of Venice. It is 3800 m long, 30-90 m wide, with an average depth of five meters. Source: Wikipedia; http://en.wikipedia.org/wiki/Main_Page (accessed 7/4/2008)",1996,
Characterization of HIV-1 genotypes and antiretroviral drug-resistance mutations among patients in Burkina Faso.,"The purposes of this study were: (1) to describe the genetic variability of HIV strains found in Burkina Faso, (2) to characterize non-B HIV strains mutation profiles selected by ARVs and (3) to detect possible resistances induced by ARV drugs. From 30 October 2002 to 20 November 2003, 132 HIV 1-positive patients taking Highly Active Antiretroviral Therapy (HAART) for more than one year in Bobo-Dioulasso and Ouagadougou were included. T-CD4+ lymphocytes count was done using Dynabeads technique while genotypic test and ARV-resistance tests were conducted using Pol sequencing that codes for reverse transcriptase reverse, integrase and protease. Due to undetectable viremia, 86 samples out of 132 could not be characterized. Whereas in the 46 others that had a viral load exceeding 1000 copies mL(-1), the following HIV-1 subtypes were identified: CRF06 (54,55%); CRF02(38,63%); CRF01 (4,55%) and subtype A (2,27%). In addition, several mutations related to PI, NRTI and NNRTI resistance were isolated in 27 samples. This study found a huge genetic HIV-1 polymorphism in Burkina Faso. The level of acquired resistance to ARV after one year of treatment amounted 20.4%. These results clearly show that there is imperative need to set up an ARV resistance surveillance network in Burkina Faso to guide treatment strategies and follow the extension of the phenomenon in the country.",2011,Pakistan journal of biological sciences : PJBS
[Epidemiology of the injuries caused by Thalassophryne nattereri (niquim) in CearÃ¡ State (1992-2002)].,"In CearÃ¡ State (1992 to 2002) 16 cases of envenomation by Thalassophryne nattereri occurred in the seaside of CearÃ¡, 87.5% of cases in the region of Fortaleza and 12.5% in the interior of CearÃ¡ State. Ninety four percent were men and 6% women. Age range: 75% between 21 and 40 years and 19% between 41 and 60 years old. The time between medical assistance and the accident varied from 1 to 5 hours (4 cases), 6 to 12 hours (3 cases), over 12 hours in 4 cases and 5 patients did not know. Clinical manifestations observed were pain, local edema, transitory ischemia, paresthesia, ecchymosis and burned skin sensation. Anti inflammatory and analgesic drugs were used. In some cases, anesthetic, hot water, surgical peeling and anti-histaminic drugs were used. In 75% of cases cure was confirmed and in 12% cure was not confirmed. The number of accidents is probably higher than was found due to subnotification.",2005,Revista da Sociedade Brasileira de Medicina Tropical
A New View of Pterosaur Feeding Habits,"Few things capture a childâ€™s imagination like the age of dinosaurs, and itâ€™s no wonder. The dinosaur seems an improbable beast, yet the fossil record tells us that vegetarian sauropods longer than a football field once lumbered alongside tractor-trailerâ€“sized predatory carnosaurs. Above these behemoths soared the reptilian pterosaurs, some propelled by wings spanning more than 12 meters. Although pterosaurs are not dinosaurs, the two groups may well share a common ancestor on the reptilian tree. The size and body plan of these long-extinct animals can be reliably reconstructed from the fossil record, as can the dates of their time on Earth. But fossils only rarely provide direct evidence of behavior and ecology, freeing children to imagine whatever wild scenarios they please and forcing researchers to develop innovative approaches to recreate the ecology of an ancient era. 
 
One way scientists gain insight into ecological traits of extinct animals is by comparing fossilized morphological features to those of living animals. Such studies have suggested that some pterosaurs may have fed like modern-day â€œskimmers,â€ a rarified group of shorebirds, belonging to the genera Rynchops, that fly along the surface of still bodies of water scooping up small fish and crustaceans with their submerged lower jaw. Structural similarities between pterosaur and Rynchops skulls and jaws suggested to some paleontologists that certain pterosaur taxa were anatomically suited for skimming. But the fossilized jaws of putative pterosaur skimmers also bear features that undercut this hypothesis, including pointed jaw tips that likely couldnâ€™t deflect water, and thus reduce energy costs, the way the blunted jaw tips of Rynchops presumably do. 
 
In a new study, Stuart Humphries et al. report that biomechanical analyses offer valuable insights into the feasibility of pterosaur skimming. By combining experiments using life-size models of jaws from postulated pterosaur and model skimmers with hydrodynamic and aerodynamic modeling, the researchers show that skimming requires more energy than giant reptilian fliers were likely able to supply. 
 
Though considered reptiles, pterosaurs appear to lack scales and were, in fact, covered in short fur. Their wings, like those of bats, comprised a sophisticated flight membrane supported by elongate wing bones. Their extremely light, hollow skeletons were presumably filled with air, allowing these gigantic animals to take to the skies, which they did as far back as 230 million years ago. Guided by specimens and data on jaw morphology, the researchers built model bills of a Rynchops subspecies (R. niger cinerascens), a suggested pterosaur skimmer (Thalassodromeus sethi), and a presumed nonskimming, smaller pterosaur (Tupuxuara sp.). The models were suspended from a trolley and towed along a water-filled trough at speeds documented for Rynchops skimmers. The models were rigged with instruments designed to measure strainâ€”the physical response to an applied force like waterâ€”which was used to calculate the drag force acting on the models as they â€œskimmedâ€ the water. 
 
In the skimming experiments, the two pterosaur model bills experienced nearly ten times as much drag as the Rynchops model at the same depth. To describe the process in mathematical terms, the researchers developed a fluid dynamic model incorporating drag forces that would cause energy loss as the pterosaur or bird worked against gravity to displace water with its jaw. They validated the model by showing that the drag measurements produced by the Rynchops and pterosaur model bills matched the estimates derived from the principles of fluid dynamics. The researchers could then use this model to estimate drag costs and potential skimming capability of other reputed skimming pterosaurs without having to make casts of their bills. 
 
 
 
Physical and theoretical models show that pterosaurs (Thalassodromeus, right) could not meet the energy requirements of skimming, a rare feeding strategy practiced habitually by just a few extant Rynchops species (black skimmer, left). (Image: Mark Witton) ... 
 
 
 
To calculate the energetic costs of skimming, the researchers compared the estimated costs of powered flight, including their estimated costs of hydrodynamic drag, to estimates of available metabolic power for self-propelled flight. (Metabolic power estimates are based on estimates of body mass and wingspan.) Skimming carried â€œconsiderably higherâ€ flight costs for pterosaurs than for modern skimmers. But skimming is also an energetically costly foraging strategy for Rynchops, the researchers discovered, because their hydrodynamic drag costs are three times higher than previously estimated. Even so, the birds possess the metabolic muscle to sustain skimming. Itâ€™s unlikely, however, that pterosaurs could have mustered the power required to offset the energetic costs of skimming. (Interestingly, the researchersâ€™ theoretical models suggest that Tupuxuara sp., the smaller pterosaur considered a nonskimmer based on its anatomy, could theoretically meet the energy demands of skimming, though it would have to spend half of its flight energy budget on drag.) 
 
These results show that the bill is subjected to substantially greater hydrodynamic drag than previously appreciated, challenging the common assumption that drag costs pale in comparison to aerodynamic costs of flight. These high costs explain why skimming is habitually practiced by only three existing bird species, all Rynchopsâ€”and why itâ€™s very unlikely that ancient pterosaurs fed by skimming. Whatâ€™s more, the researchers argue, modern-day skimmers possess some 30 adaptations in the neck and skull to withstand hydrodynamic forces while catching prey with an immersed jaw during flight. Postulated pterosaur skimmers evince few of these adaptations, suggesting that even smaller pterosaurs with the capacity to meet skimming energy costs were not skim-feeders. While acknowledging that morphological comparisons offer clues to the ecological traits of extinct taxa, the researchers hope that others will supplement such efforts with biomechanical analyses to paint a more realistic portrait of the prehistoric landscape. 
 
For more information on pterosaurs, go to UC Berkeleyâ€™s Museum of Paleontology Web site: http://www.ucmp.berkeley.edu/diapsids/pterosauria.html.",2007,PLoS Biology
Neutrophil-to-Lymphocyte Ratio Predicts Severe Illness Patients with 2019 Novel Coronavirus in the Early Stage,"Background: Severe ill patients with 2019 novel coronavirus (2019-nCoV) infection progressed rapidly to acute respiratory failure. We aimed to select the most useful prognostic factor for severe illness incidence. Methods: The study prospectively included 61 patients with 2019-nCoV infection treated at Beijing Ditan Hospital from January 13, 2020 to January 31, 2020. Prognostic factor of severe illness was selected by the LASSO COX regression analyses, to predict the severe illness probability of 2019-CoV pneumonia. The predictive accuracy was evaluated by concordance index, calibration curve, decision curve and clinical impact curve. Results: The neutrophil-to-lymphocyte ratio (NLR) was identified as the independent risk factor for severe illness in patients with 2019-nCoV infection. The NLR had a c-index of 0.807 (95% confidence interval, 0.676-0.38), the calibration curves fitted well, and the decision curve and clinical impact curve showed that the NLR had superior standardized net benefit. In addition, the incidence of severe illness was 9.1% in age â‰¥ 50 and NLR < 3.13 patients, and half of patients with age â‰¥ 50 and NLR â‰¥ 3.13 would develop severe illness. Based on the risk stratification of NLR with age, the study developed a 2019-nCoV pneumonia management process. Conclusions: The NLR was the early identification of risk factors for 2019-nCoV severe illness. Patients with age â‰¥ 50 and NLR â‰¥ 3.13 facilitated severe illness, and they should rapidly access to intensive care unit if necessary.",2020,medRxiv
Operator Formulation of Classical Mechanics,"By making use of the Weylâ€“Wignerâ€“Groenewoldâ€“Moyalassociation rules, acommutative product and a new quantum bracket are constructed in the spaceof operators F(H). In this way, an isomorphism between the Lie algebra ofclassical observables (with Poisson bracket) and the Lie algebra of quantumobservables with this new bracket is established. By these observations, aformulation of classical mechanics in F(H) is obtained and is shown to be theÄ§ â†’ 0 limit of the Heisenberg-picture formulation of quantum mechanics.",2000,International Journal of Theoretical Physics
Associations between long-term exposure to PM2.5 component species and blood DNA methylation age in the elderly: The VA normative aging study.,"BACKGROUND
Long-term PM2.5 exposure and aging have been implicated in multiple shared diseases; studying their relationship is a promising strategy to further understand the adverse impact of PM2.5 on human health.


OBJECTIVE
We assessed the relationship of major PM2.5 component species (ammonium, elemental carbon, organic carbon, nitrate, and sulfate) with Horvath and Hannum DNA methylation (DNAm) age, two DNA methylation-based predictors of chronological age.


METHODS
This analysis included 552 participants from the Normative Aging Study with multiple visits between 2000 and 2011 (n=940 visits). We estimated 1-year PM2.5 species levels at participants' addresses using the GEOS-chem transport model. Blood DNAm-age was calculated using CpG sites on the Illumina HumanMethylation450 BeadChip. We fit linear mixed-effects models, controlling for PM2.5 mass and lifestyle/environmental factors as fixed effects, with the adaptive LASSO penalty to identify PM2.5 species associated with DNAm-age.


RESULTS
Sulfate and ammonium were selected by the LASSO in the Horvath DNAm-age models. In a fully-adjusted multiple-species model, interquartile range increases in both 1-year sulfate (95%CI: 0.28, 0.74, P<0.0001) and ammonium (95%CI: 0.02, 0.70, P=0.04) levels were associated with at least a 0.36-year increase in Horvath DNAm-age. No PM2.5 species were selected by the LASSO in the Hannum DNAm-age models. Our findings persisted in sensitivity analyses including only visits with 1-year PM2.5 levels within US EPA national ambient air quality standards.


CONCLUSION
Our results demonstrate that sulfate and ammonium were most associated with Horvath DNAm-age and suggest that DNAm-age measures differ in their sensitivity to ambient particle exposures and potentially disease.",2017,Environment international
Assessment of linear regression techniques for modeling multisensor data for non-invasive continuous glucose monitoring,"New scenarios in diabetes treatment have been opened in the last ten years by continuous glucose monitoring (CGM) sensors. In particular, Non-Invasive CGM sensors are particularly appealing, even though they are still at an early stage of development. Solianis Monitoring AG (ZÃ¼rich, Switzerland) has proposed an approach based on a multisensor concept, embedding primarily dielectric spectroscopy and optical sensors. This concept requires a mathematical model able to reconstruct the glucose concentration from the 150 channels measured with the device. Assuming a multivariate linear regression model (valid and usable for different individuals), the aim of this paper is the assessment of some techniques usable for determining such a model, namely Ordinary Least Squares (OLS), Partial Least Squares (PLS) and Least Absolute Shrinkage and Selection Operator (LASSO). Once the model is identified on a training set, the accuracy of prospective glucose profiles estimated from â€unseenâ€ multisensor data is assessed. Preliminary results obtained from 18 in-clinic study days show that sufficiently accurate reconstruction of glucose levels can be achieved if suitable model identification techniques, such as LASSO, are considered.",2011,2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society
An efficient linearly convergent semismooth Netwon-CG augmented Lagrangian method for Lasso problems,"We develop a fast and robust algorithm for solving large-scale convex composite optimization models with an emphasis on the $\ell_1$-regularized least square regression (the Lasso) problems. Although there exist a large amount of solvers in the literature for Lasso problems, so far no solver can handle difficult real large scale regression problems. By relying on the piecewise linear-quadratic structure of the problems to realize the remarkable fast linear convergence property of the augmented Lagrangian algorithm, and by exploiting the superlinear convergence of the semismooth Newton-CG method, we are able to design a new algorithm, called {\sc Ssnal}, to efficiently solve the aforementioned difficult problems. Global convergence and local linear convergence results for {\sc Ssnal} are established. Numerical results, including the comparison between our approach and several state-of-the-art solvers, on real data sets, are presented to demonstrate the high efficiency and robustness of our proposed algorithm in solving large-scale difficult problems.",2016,arXiv: Optimization and Control
Light C P-odd H iggs and Sm all tanScenario in the M SSM and B eyond,"Introduction: In our current understanding ofparti- cle physicsallknown elem entary particlesacquire m ass in theprocessofelectroweak sym m etry breaking.In the standard m odel(SM )thisisachieved by theHiggsm ech- anism :a com plex scalarelectroweak doubletgetsa vac- uum expectation value,spontaneously breaks the elec- troweak sym m etry,givesm assesto W and Z bosonsand leavesa scalarHiggsboson in the spectrum . The Higgs boson isthelastm issing pieceofthestandard m odel.In theoriesbeyond theSM theHiggssectoristypicallym ore com plicated,e.g. in the m inim alsupersym m etric stan- dard m odel(M SSM )therearetwo Higgsdoubletswhich leadtoveHiggsbosonsinthespectrum :lightandheavy CP even Higgses, h and H ,theCP odd Higgs, A,and a pairofcharged Higgsbosons, H ï¿½ ;and there are m any sim ple m odels with even m ore com plicated Higgs sec- tor. Discovery ofHiggsbosonsand exploration oftheir properties is the key to understanding the electroweak sym m etry breaking and a m ajorstep in uncovering the ultim atetheory ofparticlephysics. Since the searchesfor Higgsbosonsrely on detection oftheir decay products,it is crucialto understand the way Higgsbosonsdecay.Although itisusually the case thatthereisoneHiggsboson with properties(couplings to W and Z bosons)oftheSM Higgsitisnotnecessarily true thatsuch a Higgsdecaysin the way the SM Higgs does(1).A signicantm odeldependenceofdecay m odes appliesto otherHiggsesaswell. In this letter we would like to bring attention to the classofm odelswithHiggssectorsthatresem bletheHiggs sector ofthe M SSM in the region with a light CP odd Higgsboson, m A. 10 GeV,and tanï¿½ . 2:5.Although this region is ruled out in the M SSM ,after carefulre- view ofexperim entallim its we argue that it is easy to m akethisregion phenom enologically viablein sim pleex- tensionsoftheM SSM .W efocuson featuresthatinvolve the two Higgsdoubletpartofa possibleextension.Per- hapsthem ostinteresting observation isthatalltheHig- gsesresulting from two Higgsdoublets: h, H , A and H ï¿½",2008,
Tree-Guided Group Lasso for Multi-Task Regression with Structured Sparsity,"We consider the problem of learning a sparse multi-task regression, where the structure in the outputs can be represented as a tree with leaf nodes as outputs and internal nodes as clusters of the outputs at multiple granularity. Our goal is to recover the common set of relevant inputs for each output cluster. Assuming that the tree structure is available as prior knowledge, we formulate this problem as a new multi-task regularized regression called tree-guided group lasso. Our structured regularization is based on a group-lasso penalty, where groups are defined with respect to the tree structure. We describe a systematic weighting scheme for the groups in the penalty such that each output variable is penalized in a balanced manner even if the groups overlap. We present an efficient optimization method that can handle a large-scale problem. Using simulated and yeast datasets, we demonstrate that our method shows a superior performance in terms of both prediction errors and recovery of true sparsity patterns compared to other methods for multi-task learning.",2010,
"Distribution, density, and sequestration of host chemical defenses by the specialist nudibranch Tritonia hamnerorum found at high densities on the sea fan Gorgonia ventalina","The dendronotid nudibranch Tritonia hamnerorurn was observed on some reefs In the Flonda Keys, USA, at very high densities dunng the summer of 1992 T hamnerorum specializes on the sea fan Gorgonia vental~na and sequesters the furano-germacrene lulieannafuran from its host, this compound effectively protects the nudibranch from consumption by the common predatoiy reef f ~ s h Thalassoma bifasciatum T hamnerorum densit~es were extremely hlgh at some locations, with as Inany as 1700 nudibranchs found on a single G ventalina colony At high densities, nudibranch feeding killed large areas on some sea fan colonies by stnpping all tissue from portions of the sea fan and allowing fllamentous algae and other epibionts to colonize The density of T hamnerorum on G ventahna vaned greatly on scales of centimeters meters and k~lometers High density patches of nudlbranchs on individual sea fans were usually composed of equivalent-sized nudtbranchs These observations suggest that pelagic vellgers have an incredible capabil~ty to find and settle synchronously on one portion of a sea fan or that the larvae or luveniles hatch from egg masses and develop without leaving the sea fan This study adds to a growlng number of manne examples suggesting that feeding specialization occurs pnmardy among small sedentary consumers that deter or escape predators by associating w t h defended hosts",1995,Marine Ecology Progress Series
Dropout Feature Ranking for Deep Learning Models,"Deep neural networks are a promising technology achieving state-of-the-art results in biological and healthcare domains. Unfortunately, DNNs are notorious for their non-interpretability. Clinicians are averse to black boxes and thus interpretability is paramount to broadly adopting this technology. We aim to close this gap by proposing a new general feature ranking method for deep learning. We show that our method outperforms LASSO, Elastic Net, Deep Feature Selection and various heuristics on a simulated dataset. We also compare our method in a multivariate clinical time-series dataset and demonstrate our ranking rivals or outperforms other methods in Recurrent Neural Network setting. Finally, we apply our feature ranking to the Variational Autoencoder recently proposed to predict drug response in cell lines and show that it identifies meaningful genes corresponding to the drug response.",2017,ArXiv
Response shrinkage estimators in binary regression,"A shrinkage type estimator is introduced which has favourable properties in binary regression. The proposed response shrinkage estimator is based on a smoothed version of the observed responses which is obtained by shifting the observation slightly towards the mean of the observations and therefore closer to the underlying probability. Estimates of this type are easily computed by using common program packages. They exist also in cases where the number of variables is large as compared to the number of observations. Comparison to alternative shrinkage methods like ridge regression and LASSO shows that response shrinkage performs rather well. Moreover, a combination of response shrinkage estimators and Pregibon's resistant fitting procedure is considered. The resulting estimate corrects for the overprediction of the resistant fitting in a very simple way. Estimators are compared in simulation studies and applications.",2006,Comput. Stat. Data Anal.
Psychological Predicates and Verbal Complementation in Arabic,"The issue of verbal complementation patterns in the Arabic vernaculars isone which is relatively under-researched: this paper aims to make a small con-tribution in this area, focussing on essentially two issues (i) the syntax of so-called experiencer-object psychological predicates (EOPVs) (that is, predicates in the frighten or please classes) and (ii) the syntax of aspectual or phasal pred-icates (that is, verbs such as begin and continue). We argue that the latter classof verbs are in fact raising verbs and go on to show that in some dialects the interaction of EOPV and aspectual predicates permits a pattern reminiscent of Copy Raising.",2013,
"Mapping Regional Ceramic Fabrics in Sagalassos (SW-Turkey), Dating from 500 BCâ€“700 AD","Since the start of the excavations at Sagalassos in 1990, interdisciplinary research has been carried out with the purpose of reconstructing the economic history of the site. One of the most important finds was the discovery that Sagalassos was an important regional centre for pottery manufacture from at least the late Hellenistic period into early Byzantine times (Poblome 1999; Degeest 2000). In order to understand regional ceramic production and identify the clay raw materials used, an integrated approach of typological, petrographic and geochemical methods is used in the present study.",2011,
Optimal estimation of sparse high-dimensional additive models,"In this paper we discuss the estimation of a nonparametric component $f_1$ of a nonparametric additive model $Y=f_1(X_1) + ...+ f_q(X_q) + \varepsilon$. We allow the number $q$ of additive components to grow to infinity and we make sparsity assumptions about the number of nonzero additive components. We compare this estimation problem with that of estimating $f_1$ in the oracle model $Z= f_1(X_1) + \varepsilon$, for which the additive components $f_2,\dots,f_q$ are known. We construct a two-step presmoothing-and-resmoothing estimator of $f_1$ in the additive model and state finite-sample bounds for the difference between our estimator and some smoothing estimators $\tilde f_1^{\text{oracle}}$ in the oracle model which satisfy mild conditions. In an asymptotic setting these bounds can be used to show asymptotic equivalence of our estimator and the oracle estimators; the paper thus shows that, asymptotically, under strong enough sparsity conditions, knowledge of $f_2,\dots,f_q$ has no effect on estimation efficiency. Our first step is to estimate all of the components in the additive model with undersmoothing using a group-Lasso estimator. We then construct pseudo responses $\hat Y$ by evaluating a desparsified modification of our undersmoothed estimator of $f_1$ at the design points. In the second step the smoothing method of the oracle estimator $\tilde f_1^{\text{oracle}}$ is applied to a nonparametric regression problem with ""responses"" $\hat Y$ and covariates $X_1$. Our mathematical exposition centers primarily on establishing properties of the presmoothing estimator. We also present simulation results demonstrating close-to-oracle performance of our estimator in practical applications. The main results of the paper are also important for understanding the behavior of the presmoothing estimator when the resmoothing step is omitted.",2016,arXiv: Statistics Theory
Image-Adaptive Robust Transmission for Block Compressed Sensing,"Compressed media are vulnerable to channel errors during transmission, and protection of compressed media would be much required. In this paper, we employ block compressed sensing (BCS) for compression. We apply the inherent characteristics of original image content to aid the data protection performance for BCS. Image blocks are classified into active and smooth ones, and different protection schemes are applied. With active blocks, we protect with multiple description coding (MDC), while with smooth blocks, we perform the least absolute shrinkage and selection operator (LASSO). Both schemes can be worked together or be performed independently for data protection. Simulation results have pointed out the enhancements with image-adaptive classification of blocks for error resilient transmission of block compressed sensing.",2020,2020 IEEE 2nd Global Conference on Life Sciences and Technologies (LifeTech)
Comparison of haplotype-based statistical tests for disease association with rare and common variants,"Recent literature has highlighted the advantages of haplotype association methods for detecting rare variants associated with common diseases. As several new haplotype association methods have been proposed in the past few years, a comparison of new and standard methods is important and timely for guidance to the practitioners. We consider nine methods-Haplo.score, Haplo.glm, Hapassoc, Bayesian hierarchical Generalized Linear Model (BhGLM), Logistic Bayesian LASSO (LBL), regularized GLM (rGLM), Haplotype Kernel Association Test, wei-SIMc-matching and Weighted Haplotype and Imputation-based Tests. These can be divided into two types-individual haplotype-specific tests and global tests depending on whether there is just one overall test for a haplotype region (global) or there is an individual test for each haplotype in the region. Haplo.score is the only method that tests for both; Haplo.glm, Hapassoc, BhGLM and LBL are individual haplotype-specific, while the rest are global tests. For comparison, we also apply a popular collapsing method-Sequence Kernel Association Test (SKAT) and its two variants-SKAT-O (Optimal) and SKAT-C (Combined). We carry out an extensive comparison on our simulated data sets as well as on the Genetic Analysis Workshop (GAW) 18 simulated data. Further, we apply the methods to GAW18 real hypertension data and Dallas Heart Study sequence data. We find that LBL, Haplo.score (global test) and rGLM perform well over the scenarios considered here. Also, haplotype methods are more powerful (albeit more computationally intensive) than SKAT and its variants in scenarios where multiple causal variants act interactively to produce haplotype effects.",2016,Briefings in bioinformatics
Bayesian hierarchical structured variable selection methods with application to molecular inversion probe studies in breast cancer,"type=""main"" xml:id=""rssc12053-abs-0001""> The analysis of genomics alterations that may occur in nature when segments of chromosomes are copied (known as copy number alterations) has been a focus of research to identify genetic markers of cancer. One high throughput technique that has recently been adopted is the use of molecular inversion probes to measure probe copy number changes. The resulting data consist of high dimensional copy number profiles that can be used to ascertain probe-specific copy number alterations in correlative studies with patient outcomes to guide risk stratification and future treatment. We propose a novel Bayesian variable selection method, the hierarchical structured variable selection method, which accounts for the natural gene and probe-within-gene architecture to identify important genes and probes associated with clinically relevant outcomes. We propose the hierarchical structured variable selection model for grouped variable selection, where simultaneous selection of both groups and within-group variables is of interest. The hierarchical structured variable selection model utilizes a discrete mixture prior distribution for group selection and group-specific Bayesian lasso hierarchies for variable selection within groups. We provide methods for accounting for serial correlations within groups that incorporate Bayesian fused lasso methods for within-group selection. Through simulations we establish that our method results in lower model errors than other methods when a natural grouping structure exists. We apply our method to a molecular inversion probe study of breast cancer and show that it identifies genes and probes that are significantly associated with clinically relevant subtypes of breast cancer.",2014,Journal of The Royal Statistical Society Series C-applied Statistics
Comparison of frequentist and Bayesian regularization in structural equation modeling.,"Research in regularization, as applied to structural equation modeling (SEM), remains in its infancy. Specifically, very little work has compared regularization approaches across both frequentist and Bayesian estimation. The purpose of this study was to address just that, demonstrating both similarity and distinction across estimation frameworks, while specifically highlighting more recent developments in Bayesian regularization. This is accomplished through the use of two empirical examples that demonstrate both ridge and lasso approaches across both frequentist and Bayesian estimation, along with detail regarding software implementation. We conclude with a discussion of future research, advocating for increased evaluation and synthesis across both Bayesian and frequentist frameworks.",2018,Structural equation modeling : a multidisciplinary journal
Exploring the potential of small RNA subunit and ITS sequences for resolving phylogenetic relationships within the phylum Ctenophora.,"Ctenophores are a phylum of non-bilaterian marine (mostly planktonic) animals, characterised by several unique synapomorphies (e.g., comb rows, apical organ). Relationships between and within the nine recognised ctenophore orders are far from understood, notably due to a paucity of phylogenetically informative anatomical characters. Previous attempts to address ctenophore phylogeny using molecular data (18S rRNA) led to poorly resolved trees but demonstrated the paraphyly of the order Cydippida. Here we compiled an updated 18S rRNA data set, notably including a few newly sequenced species representing previously unsampled families (Lampeidae, Euryhamphaeidae), and we constructed an additional more rapidly evolving ITS1 + 5.8S rRNA + ITS2 alignment. These data sets were analysed separately and in combination under a probabilistic framework, using different methods (maximum likelihood, Bayesian inference) and models (e.g., doublet model to accommodate secondary structure; data partitioning). An important lesson from our exploration of these datasets is that the fast-evolving internal transcribed spacer (ITS) regions are useful markers for reconstructing high-level relationships within ctenophores. Our results confirm the paraphyly of the order Cydippida (and thus a ""cydippid-like"" ctenophore common ancestor) and suggest that the family Mertensiidae could be the sister group of all other ctenophores. The family Lampeidae (also part of the former ""Cydippida"") is probably the sister group of the order Platyctenida (benthic ctenophores). The order Beroida might not be monophyletic, due to the position of Beroe abyssicola outside of a clade grouping the other Beroe species and members of the ""Cydippida"" family Haeckeliidae. Many relationships (e.g. between Pleurobrachiidae, Beroida, Cestida, Lobata, Thalassocalycida) remain unresolved. Future progress in understanding ctenophore phylogeny will come from the use of additional rapidly evolving markers and improvement of taxonomic sampling.",2015,Zoology
Enhanced Transport of Nucleosides and Nucleoside Analogues with Complementary Base-Pairing Agents,"Baumal, et al., â€œPhotodynamic Therapy (PDT) of Experi mental Choroidal Neovascularization with Tin Ethyl Etiopurpurin.â€ Investigative Ophthalmology & Visual Sci ence, vol. 37, No. 3 Feb. 15, 1996. Henderson, et al., ""How does Photodynamic Therapy Work?"" Photochemistry and Photobiology, vol. 55. No. 1, pp. 145-157. 1992. Kliman, et al., ""Phthalocyanine Photodynamic Therapy: New Strategy for Closure of Choroidal Neovascularization.â€ Lasers in Surgery and Medicine, 15:2-10, 1994. Kliman, et al., â€œRetinal and Choroidal Vessel Closure Using Phthalocyanine Photodynamic Therapy."" Lasers in Surgery and Medicine, 15:11-18, 1994. Levy, Julia G. ""Photosensitizers in Photodynamic Therapy."" Seminars in Oncology, vol. 21. No. 6. Suppl. 15 (Dec.), pp. 4-10, 1994. Miller, et al. ""Phthalocyanine Photodynamic Therapy of Experimental Iris Neovascularization."" Ophthalmology, vol. 98, No. 11, pp. 1711-1719, Nov. 1991. Morgan, et al. ""Tin (IV) Etiopurpurin dichloride: An Alter native to DHE?â€ SPIE vol. 847 New Directions in Photo dynamic Therapy, pp. 172-179, 1987. Young, et al. ""Lutetium Texaphyrin (PCI-0123): A Near-Infrared Water-Soluble Photosensitizer."" Photochem istry and Photobiology, 63(6), pp. 892â€“897, 1996. Andreoni, et al., ""B16 melanoma response in vivo to pho tochemotherapy with mitoxantrone and red light."" Cancer Letters, 61. pp. 89-94, 1991. Sessler et al., ""Texaphyrins: Synthesis and Applications."" Accounts of Chemical Research, 27(2):43-50, 1994. Leff, â€œTexas 'Son-of-Porphyrin Molecule Lassos Europium to Kill Drug Resistance Gene."" BioWorld Today. 5(156):1, 1994. Young et al. ""Preclinical Evaluation of Gadolinium (III) Texaphyrin Complex. A New Paramagnetic Contrast Agent for Magnetic Resonance Imaging.â€ Investigative Radiology, 29(3):330-338, 1994. Furuta et al., â€œEnhanced Transport of Nucleosides and Nucleoside Analogues with Complementary Base-Pairing Agents,â€ Journal of the American Chemical Society, 113:47O6-4707, 1991. Sessler et al. ""Anion Binding: A New Direction. In Porphy rin-Related Research."" Pure & Applied Chem. 65(3):393-398. 1993. Sessler et al., ""Synthesis and Binding Properties of Mono meric and Dimeric Guanine and Cytosine Amine Deriva tives."" J. Org. Chem. 1992. 57:818-826. T.D. Mody et al., ""Lutetium (III) Texaphyrin: A Novel Photodynamic Therapy Agent."" Abstract, 22nd Annual American Society for Photobiology, Scottsdale, AZ, Jun. 25-29, 1994. Sessler et al., ""Gadolinium (III) Texaphyrin: A Novel MRI Contrast Agent.â€ Journal of the American Chemical Society, 115(22):10368-10369, 1993. Iverson et al., ""Interactions Between Expanded Porphyrins and Nucleic Acids."" Pure Applied Chemistry, 66(4):845-850, 1994. Magda et al., â€œSite-Specific Hydrolysis of RNA by Europium (III) Texaphyrin Conjugated to a Syntheitc Oli godeoxyribonucleotide."" Journal of the American Chemical Society, 116(16):7439-7440, 1994. Koenig et al., â€œPDT of Tumor-Bearing Mice Using Lipo some Delivered Texaphyrins."" International Conference. Milan, Italy, Biosis citation only, Jun. 24-27. 1992.",2017,
Covariance-regularized regression and classification for high-dimensional problems.,"In recent years, many methods have been developed for regression in high-dimensional settings. We propose covariance-regularized regression, a family of methods that use a shrunken estimate of the inverse covariance matrix of the features in order to achieve superior prediction. An estimate of the inverse covariance matrix is obtained by maximizing its log likelihood, under a multivariate normal model, subject to a constraint on its elements; this estimate is then used to estimate coefficients for the regression of the response onto the features. We show that ridge regression, the lasso, and the elastic net are special cases of covariance-regularized regression, and we demonstrate that certain previously unexplored forms of covariance-regularized regression can outperform existing methods in a range of situations. The covariance-regularized regression framework is extended to generalized linear models and linear discriminant analysis, and is used to analyze gene expression data sets with multiple class and survival outcomes.",2009,"Journal of the Royal Statistical Society. Series B, Statistical methodology"
