title,abstract,year,journal
Sparse Convolutional Neural Networks for Genome-Wide Prediction,"Genome-wide prediction (GWP) has become the state-of-the art method in artificial selection. Data sets often comprise number of genomic markers and individuals in ranges from a few thousands to millions. Hence, computational efficiency is important and various machine learning methods have successfully been used in GWP. Neural networks (NN) and deep learning (DL) are very flexible methods that usually show outstanding prediction properties on complex structured data, but their use in GWP is nevertheless rare and debated. This study describes a powerful NN method for genomic marker data that can easily be extended. It is shown that a one-dimensional convolutional neural network (CNN) can be used to incorporate the ordinal information between markers and, together with pooling and â„“ 1-norm regularization, provides a sparse and computationally efficient approach for GWP. The method, denoted CNNGWP, is implemented in the deep learning software Keras, and hyper-parameters of the NN are tuned with Bayesian optimization. Model averaged ensemble predictions further reduce prediction error. Evaluations show that CNNGWP improves prediction error by more than 25% on simulated data and around 3% on real pig data compared with results obtained with GBLUP and the LASSO. In conclusion, the CNNGWP provides a promising approach for GWP, but the magnitude of improvement depends on the genetic architecture and the heritability.",2020,Frontiers in Genetics
Ironâ€“Manganese Concretions Sustaining Microbial Life in the Baltic Sea: The Structure of the Bacterial Community and Enrichments in Metal-Oxidizing Conditions,"The abundant deposits of spherical iron-manganese concretions in the Gulf of Finland are colonized by bacteria in vast numbers. Communities on the surface and in the porous interior have formed two separate clusters, in accordance with their genetic differences. The overall bacterial community in the concretions was highly diverse, representing 12 phyla. Half of the bacteria were affiliated with the most common classes of Proteobacteria, while a third of the bacteria were unclassified. Cloned 16S rRNA-gene sequences of the concretion bacteria showed high scores for similarity to the sequences obtained from sea sediments, metal-rich environments, and ocean crust. The clone library of native concretions was not dominated by known Fe- and Mn-oxidizing species. Known Mn-oxidizing bacteria Sphingomonas, Pseudomonas, and Bacillus were enriched in experiments with Mn2+-containing liquid media, whereas Prosthecobacter (Verrucomicrobia) and Rheinheimera were enriched in semisolid media possibly better simulating the natural conditions in the concretions. In a corresponding experiment, the Fe2+-oxygen gradient favored the enrichment of Shewanella baltica and Thalassolituus oleivorans, which are known to reduce Fe and to degrade petroleum hydrocarbons, respectively. An individual spherical concretion forms a microcosm for a diverse microbial community having potential to oxidize Fe and Mn as shown in cultivation experiments. Therefore, bacteria may significantly affect the formation of the concretions in the Gulf of Finland.",2014,Geomicrobiology Journal
High-dimensional robust precision matrix estimation: Cellwise corruption under $\epsilon$-contamination,"We analyze the statistical consistency of robust estimators for precision matrices in high dimensions. We focus on a contamination mechanism acting cellwise on the data matrix. The estimators we analyze are formed by plugging appropriately chosen robust covariance matrix estimators into the graphical Lasso and CLIME. Such estimators were recently proposed in the robust statistics literature, but only analyzed mathematically from the point of view of the breakdown point. This paper provides complementary high-dimensional error bounds for the precision matrix estimators that reveal the interplay between the dimensionality of the problem and the degree of contamination permitted in the observed distribution. We also show that although the graphical Lasso and CLIME estimators perform equally well from the point of view of statistical consistency, the breakdown property of the graphical Lasso is superior to that of CLIME. We discuss implications of our work for problems involving graphical model estimation when the uncontaminated data follow a multivariate normal distribution, and the goal is to estimate the support of the population-level precision matrix. Our error bounds do not make any assumptions about the the contaminating distribution and allow for a nonvanishing fraction of cellwise contamination.",2015,arXiv: Statistics Theory
"Seroprevalence and risk factors of Toxoplasma gondii infection in pregnant women from Bobo Dioulasso, Burkina Faso","BackgroundToxoplasmosis is one of the common worldwide parasitic zoonosis due to Toxoplasma gondii (T. gondii). Toxoplasmosis during pregnancy can result in fetal and neonatal death or various congenital defects. The aim of this study was to assess the seroprevalence and risk factors of T. gondii infection in pregnant women following antenatal care (ANC) services at Bobo Dioulasso.MethodsA cross-sectional study was conducted enrolling a sample of 316 pregnant women attending ANC at centers for maternal and child health of Bobo-Dioulasso town from March 2013 to February 2014. Data on socio-demographic and potential risk factors were collected from each study participant using structured questionnaire through face-to-face interview. Moreover, venous blood specimens were collected and tested for IgM and IgG anti-T. gondii antibodies by enzyme-linked immunosorbent assay and enzyme linked fluorescent assay, respectively. Multivariable logistic regression modeling was used to identify the potential predictor variables for T. gondii infection.ResultsThe overall seroprevalence for T. gondii infection was 31.1% (98/316). All the pregnant women were positive for IgG anti-bodies exclusively. Multivariable logistic regression analysis showed that having at least a secondary education level (AORÂ =Â 2.23; 95% CI: [1.04â€“4.63]); being urban resident (AORÂ =Â 2.81; 95% CI: [1.24â€“6.86]) and the consumption of meat combination (pork + beef + mutton + wild meat + poultry) (AORÂ =Â 4.00; 95% CI: [1.06â€“15.24]) were potential risk factors of T. gondii infection.ConclusionToxoplasmosis is frequent in pregnant women and studies that show incidence of T. gondii among the neonates have to be done to introduce routine antenatal screening program to control congenital toxoplasmosis. There is the need for preventive measures such as education of pregnant women about the transmission routes and prevention methods of toxoplasmosis at ANC clinics.",2017,BMC Infectious Diseases
Limit analysis of arch-beam structures by dynamic programming,"SommarioSi studiano le strutture monodimensionali ad arco nello stato limite di collasso plastico, sulla base del dominio bidimensionale (momento flettente e sforzo normale). Il metodo proposto, atto a fornire una soluzione numerica del problema della ricerca del carico limite, si fonda sul teorema cinematico dell'analisi limite e sull'impiego della programmazione dinamica. Si prendono anche in esame talune questioni connesse con l'algoritmo di calcolo. Un successivo lavoro di carattere applicativo completerÃ  la trattazione.SummaryWe study one-dimensional structures like arch-beams in the limit state of plastic collapse, on the ground of a two-dimensional yielding surface (bending moment and normal generalized stress). The proposed method, which is able to give a numerical solution of the problem of finding the limit load, rests on the upper bound theorem of limit analysis and uses dynamic programming. We examine also some questions linked with numerical procedures. A future work devoted to applications will complete the treatment.",1974,Meccanica
Monitoring and factors affecting levels of airborne and water bromoform in chlorinated seawater swimming pools.,"Water and air quality of eight seawater swimming pools using chlorine disinfection was measured during four sampling campaigns, spread on one full-year, and in four thalassotherapy centers located in Southeast of France. Concentrations of trihalomethanes (THMs) in air and in water as well as concentrations of parameters, including nonpurgeable organic carbon (NPOC), free residual chlorine (Clf), pH, Kjeldhal Nitrogen (KN), salinity, conductivity, bromide ions and, water and air temperature, were measured. Water and air samples were collected in triplicates morning - at the opening of the pools -, noon and night - at the closing of the pools -, in summer and winter. Data analysis was performed by Principal Component Analysis (PCA) and rotated component matrix, from both data quality and other parameters such as TOC, aromaticity (UV254), pH, hygrometry, and free residual chlorine (Clf). This statistical analysis demonstrates a high correlation between TOC, Clf and UV254 and THM levels found in air and water, particularly for the major ones (CHBr3 in water: 300.0Î¼g/L mean, 1029.0Î¼g/L maximum; CHBr3 in air: 266.1Î¼g/m3 mean, 1600.0Î¼g/m3 maximum, and CHClBr2 in water: 18.9Î¼g/L mean, 81.0Î¼g/L maximum; CHClBr2 in air: 13.6Î¼g/m3 mean, 150.0Î¼g/m3 maximum). These high levels of bromoform (CHBr3) are particularly worrisome in such health institutions, even these levels do not exceed the Permissible Exposure Limit (PEL) of 5mg/m3 as an 8hour time-weighted average currently fixed by various administrations, such as Occupational Safety and Health Administration (OSHA).",2017,Journal of environmental sciences
Banning Pens and Pads Misses the Main Point,"member constitute a gift to each individual. In such cir-cumstances the psychology of gift-receiving, including asense of indebtedness, is probably at work. The argumentsagainst gifts to individuals would be applicable, and suchgifts should not be accepted. On the other hand, somegifts to educational programs might not share these fea-tures of gifts to individuals. An example might be a grantto a college of medicine to cover the costs of a conference.When the gift is to an institution, the psychology of gift-giving to individuals would come into play to a lesser ex-tent, and individual faculty and residents would be lesslikely to develop a feeling that they should reciprocate.The objections to gifts to individuals lose much of theirforce when applied to gifts to institutions. A positive ar-gument for such gifts is that they have educational value,supporting the view that gifts to educational programs cansometimes be ethically justiaable.Despite the shortcomings of the American MedicalAssociation guidelines (1998) pointed out by Katz,Caplan, and Merz, these guidelines contain several usefulrecommendations to help avoid the psychology of gift-receiving when gifts are made to educational programs.First, if the gift is a grant to support a conference or lec-ture, the content of the program should be decided by theeducational institution, not the pharmaceutical company.Second, the selection of speakers and persons invited to at-tend should be decided by the educational institution.Third, when gifts are passed to speciac individuals, such asa trip for a resident to attend a conference, then the rela-tionship between the recipient and the drug companyshould be made as indirect as possible. This implies thatthe selection of the recipient should be made by the educa-tional institution. Also, the gift should not transparentlybe a gift to a speciac individual, as would happen if onlyone resident were interested in attending a conference andthe companyâ€™s representative makes the gift with that resi-dent in mind.Changing the culture of medicine in regard to accept-ing gifts will likely be difacult. Ongoing discussion willbe necessary to raise physician awareness of the argumentsagainst accepting even minor gifts from pharmaceuticalcompanies. Although the companies pay for the gifts,there is a sense in which the physicians pay too. They payby putting themselves in a position of conoict of interestand by risking injury to the trust and conadence of theirpatients.",2003,The American Journal of Bioethics
Study of the Gastrointestinal Heat Retention Syndrome in Children: From Diagnostic Model to Biological Basis,"Gastrointestinal heat retention syndrome (GHRS) refers to a condition that is associated with increased gastrointestinal heat caused by a metabolic block in energy. It is common in children and is closely related to the occurrence and development of recurrent respiratory tract infection, pneumonia, recurrent functional abdominal pain, etc. However, there are no standardized diagnostic criteria to differentiate the GHRS. Therefore, this study is aimed to establish a diagnostic model for children's GHRS and explore the possible biological basis by using systems biology to achieve. Furthermore, Delphi method and the clinical data of Lasso analysis were used to screen out the core symptoms. Nineteen core symptoms of GHRS in children were screened including digestive symptoms such as dry stool, poor appetite, vomiting, and some nervous system symptoms such as night restlessness and irritability. Based on the core symptoms, a GHRS diagnosis model was established using the eXtreme Gradient Boosting (XGBoost) method, and the accuracy of internal verification reached 93.03%. Relevant targets of the core symptoms in the Human Phenotype Ontology (HPO) were retrieved, and target interactions were linked through the Search Tool for the Retrieval of Interacting Genes/Proteins (STRING) database, and core targets were selected after topological analysis using Cytoscape. Relevant biological processes and pathways were analyzed by applying the DAVID and KEGG databases. The enriched biological processes focused on the cell proliferation, differentiation, apoptosis, and mitochondrial metabolism, which were mainly associated with PI3K-AKT, MAPK network pathways, and the Wnt signaling pathway. In conclusion, we established a diagnosis model of GHRS in children based on the core symptoms and provided an objective standard for its clinical diagnosis. And, the Wnt signaling pathway and the estrogen receptor-activated PI3K-AKT and MAPK network pathways may play important roles in the GHRS processing.",2019,Evidence-based Complementary and Alternative Medicine : eCAM
"Country of origin and use of social benefits: A large, preregistered study of stereotype accuracy in Denmark","A nationally representative Danish sample was asked to estimate the percentage of persons aged 30-39 living in Denmark receiving social benefits for 70 countries of origin (N = 766). After extensive quality control procedures, a sample of 484 persons were available for analysis. Stereotypes were scored by accuracy by comparing the estimated values to values obtained from an official source. Individual stereotypes were found to be fairly accurate (median/mean correlation with criterion values = .48/.43), while the aggregate stereotype was found to be very accurate (r = .70). Both individual and aggregate-level stereotypes tended to underestimate the percentages of persons receiving social benefits and underestimate real group differences. 
 
In bivariate analysis, stereotype correlational accuracy was found to be predicted by a variety of predictors at above chance levels, including conservatism (r = .13), nationalism (r = .11), some immigration critical beliefs/preferences, agreement with a few political parties, educational attainment (r = .20), being male (d = .19) and cognitive ability (r = .22). Agreement with most political parties, experience with ghettos, age, and policy positions on immigrant questions had little or no predictive validity. 
 
In multivariate predictive analysis using LASSO regression, correlational accuracy was found to be predicted only by cognitive ability and educational attainment with even moderate level of reliability. In general, stereotype accuracy was not easy to predict, even using 24 predictors (k-fold cross-validated R2 = 4%). 
 
We examined whether stereotype accuracy was related to the proportion of Muslims in the groups. Stereotypes were found to be less accurate for the groups with higher proportions of Muslims in that participants underestimated the percentages of persons receiving social benefits (mean estimation error for Muslim groups relative to overall elevation error = -8.09 %points). 
 
The study was preregistered with most analyses being specified before data collection began.",2016,
An in vitro dissolution study of Ibuprofen using a Flow-through cell,"The flow-through cell is a suitable method for dissolution studies of poorly soluble drugs. The dissolution can be influenced by changing parameters in the apparatus and by changing the physical properties of the drug and the medium used. In this study the dissolution of ibuprofen was examined. Results showed that a smaller particle size gave a higher dissolution rate. With a dose of 50mg a higher percent dissolved was obtained compared to a dose of 100mg. However, a larger mass (mg) was dissolved when the dose of 100mg was used. When using a cell diameter of 12mm instead of a cell diameter of 22.6mm the dissolution rate increased. A larger dissolution rate was also obtained when the flow of the medium was increased. Finally the effect of changing medium was examined. Results showed that by including a surfactant to the medium a drastic increase of the dissolution rate was obtained. Introduction The flow-through cell has since the 90â€™s been used as an alternative method for dissolution studies (Sotax). It has some advantages over previous dissolution methods. It is easier to retain sink condition, i.e. to keep a sufficiently low concentration in the remaining solution. This makes it possible to keep a constant diving force (=concentration difference) the whole time during the release experiment. The concentration should not exceed one third of the saturated. The medium can be changed automatically during the study which is very useful in in vitro â€“ in vivo studies (Nicklasson, 1992). Previous studies have showed the importance of deaeration of the dissolution medium (Nicklasson, et al., 1987), how the packing of the cell can influence the dissolution (Shobha et al., 2002) and that the results obtained with the flow-through cell are more reproducible than obtained with previous methods as dissolution baths (Nicklasson, et al., 1987, Wennergren et al., 1989). In this study the dissolution of ibuprofen was examined in the flow-through cell. Six parameters were of interest: â€¢ the packing of the cell â€¢ the particle size of the drug â€¢ the dose â€¢ the volume flow of the medium through the cell â€¢ the cell diameter â€¢ the medium Desirable results were good reproducibility, i.e. small standard deviation between tests and cells, and to maintain sink condition during the experiment. Material The drug used was ibuprofen (fig. 1), a poorly soluble acidic drug. Three samples with different particle size distribution were used, 50 Î¼m, 25Î¼m purchased from BASF Chem. Trade GmbH and a powder with unknown size distribution purchased from Marsing & Co. LTD. They all existed in a crystalline form. Two doses of ibuprofen were used and investigated, 50mg and 100mg. The media used for the dissolution studies were hydrochloric acid, hydrochloric acid containing sodium chloride and also hydrochloric acid containing both, sodium chloride and cetrimide. They all had a pH at 2. At this pH the solubility of ibuprofen in hydrochloric acid, with and without sodium chloride, is about 0.050mg/ml. When adding cetrimide, at the concentration 0.01% and 0.5%, to the hydrochloric acid the solubility of ibuprofen is 0.052mg/ml respectively 1.22mg/ml (KÃ¤llquist, 2007). The absorbance of ibuprofen was measured at 221nm.",2007,
Monte Carlo Model Checking,"We present MC2, what we believe to be the first randomized, Monte Carlo algorithm for temporal-logic model checking. Given a specification S of a finite-state system, an LTL formula Ï•, and parameters e and Î´, MC2 takes M = ln (Î´) / ln (1 â€“ e) random samples (random walks ending in a cycle, i.e lassos) from the Buchi automaton B=BS Ã—BÂ¬Ï•. to decide if L(B) = âˆ…. Let pZ be the expectation of an accepting lasso in B. Should a sample reveal an accepting lasso l, MC2 returns false with l as a witness. Otherwise, it returns true and reports that the probability of finding an accepting lasso through further sampling, under the assumption that pZ â‰¥ e, is less than Î´. It does so in time O(MD) and space O(D), where D is B's recurrence diameter, using an optimal number of samples M. Our experimental results demonstrate that MC2 is fast, memory-efficient, and scales extremely well.",2005,
Bayesian Perspectives on Sparse Empirical Bayes Analysis ( SEBA ),"We consider a joint processing of n independent similar sparse regression problems. Each is based on a sample (yi1, xi1) . . . , (yim, xim) of m i.i.d. observations from yi1 = xi1Î²i + Îµi1, yi1 âˆˆ R, xi1 âˆˆ R, and Îµi1 âˆ¼ N(0, Ïƒ), say. The dimension p is large enough so that the empirical risk minimizer is not feasible. We consider, from a Bayesian point of view, three possible extensions of the lasso. Each of the three estimators, the lassoes, the group lasso, and the RING lasso, utilizes different assumptions on the relation between the n vectors Î²1, . . . , Î²n. â€œ. . . and only a star or two set sparsedly in the vault of heaven; and you will find a sight as stimulating as the hoariest summit of the Alps.â€ R. L. Stevenson",2010,
Genetyczna klasyfikacja osadÃ³w morenowych,"GENETIC CLASSIFICATION OF MORAINIC DEPOSITS Summary The Commission on the Origin and Lithology of Quaternary Deposits, INQUA, took the initiative to unify both the nomenclature and the systematics of morainic deposits. The classification of morainic deposits presented in this paper is one of possible answers to this initiative. The term - moraine - was left by the present author to determine the form produced by a glacier, whereas the material melted out of the glacier ice is consequently called by him - morainic deposit. This latter was formed at the cost of the glacier. The present classification of morainic deposits is based on genetical criteria. On the one hand, the palaeogeographical conditions of deglaciation, the dynamics of sedimentary processes and the way of formation of morainic deposits are considered for various taxonomical grades, on the other one, each taxonomical unit is determined by a specific complex of lithological features (Tables 1 and 2). The following are taxonomical units distinguished by the present author: I order - genetical type, II order - group of facies, III order - facies, IV order - subfacies, V order - family, VI order - lithotype (stratigraphic or regional). The morainic deposits, according to the conception or A. P. Pavlov, are a genetical type. They may be subdivided into the following two groups of facies: II A â€“ subaeral (continental) facies, and II B - subaqueous (underwater) facies - in relation to the site of deglaciation (on land and underwater). Group II A includes both ablation till facies (III 1) and basal till facies (III 2), whereas group II B comprises, depending upon the kind of water basin in which the melting out of rock matrial in a glacier takes place, the following facies: thalassotopic facies (III 3), limnotopic facies (III 4) and fluviotopic facies (III 5). In the subaqueous morainic deposits transition formations are frequently found to pass into type aqueous deposits (marine, lacustrine or fluvial). The dynamics of glaciations and deglaciation processes is reflected in the form of the appearance of morainic deposits. This fact was a basis to distinguish the following subfacies (IV): active ice subfacies, stagnant ice subfacies, and dead ice subfacies (on land); as well as drift ice subfacies and ice tongue subfacies (among subaqueous facies). The frequency of the individual subfacies is changing and depends, first of all, upon the physic-dynamical nature of a glacier and the kind of the subglacial relief. Thus, the ablation facies (III 1) may be divided into the stagnant ice subfacies (IV 1) end the dead ice subfacies (IV 2). The basal till facies comprises, in addition to the subfacies mentioned above (IV 4 and IV 5), the active (piled) ice subfacies (IV 3), too. The morainic deposits of this subfacies were formed during the inland ice advance onto the terrain hindrances such as thresholds, edges, elevations, a.o. In this case, the active ice was piled up, and after its melting, morainic deposits were laid down, characterized by a considerable thickness determined by the height of the hindrance. Small, distinctly wedged out patches and lenticles of the morainic deposits, are a remainder of the dead ice blocks. The morainic material melted out of various blocks and fragments of the glacier ice floating in a water basin was previously graded fractionally and then sedimented. In the deposits of sensu strict aqueous sedimentation it makes lenticles and intercalations. These are morainic deposits of drift ice subfacies (IV 6 and IV 8). Morainic deposits of ice tongues may have been formed when the glacier front was on the bottom of a water basin. This took place in shallow water (littoral) basins. The families of morainic deposits were distinguished on the basis of lithological criteria. Here are two families distinguished: boulder clays (V 1, V 3, V 5, V 6, V 8, V 11, V 14 and V 16) and boulder sands and gravels (V 2, V 4, V 7, V 9, V 12 and V 15). Within the drift ice subfacies a family of graded boulder clays (V 10 and V 13) occurs. The family of boulder sands and gravels was not distinguished in the drift ice subfacies, mainly due to some difficulties in separating these deposits from the sands of water sedimentation sensu stricto. Each family, e.g. that of boulder clays, includes a series of stratigraphical or regional lithotypes (VI). The subdivision into lithotypes depends upon the vertical and horizontal lithologic variations in morainic deposits of a given family. The amount of lithotypes is not constant and, first of all, depends on the exactness of geological reconnaissance made in the region considered. At present, for example, we can determine the lithotypes of boulder clays for various Pleistocene stratigraphical units that correspond to both glacial epochs and stages. A complex of the features determining a lithotype is not uniform either in the individual regions or stratigraphical horizons. A differentiation in properties of the lithotypes is for the most part of quantitative character, and only sporadically of qualitative one. Each feature of the morainic deposits appears in a definite relation to the remaining features of these deposits. Such mutual relations are a result of the genesis of the morainic deposits, thought to be an algebraic sum of all the weathering, denudation and sedimentary processes that take place under the definite historic-palaeogeographical, facial and physic-dynamical conditions. It should be added here that the genetic classification presented in this paper concerns unaltered morainic deposits only. Normal 0 21 false false false PL X-NONE X-NONE /* Style Definitions */ 
 table.MsoNormalTable 
 {mso-style-name:Standardowy; 
 mso-tstyle-rowband-size:0; 
 mso-tstyle-colband-size:0; 
 mso-style-noshow:yes; 
 mso-style-priority:99; 
 mso-style-qformat:yes; 
 mso-style-parent:""""; 
 mso-padding-alt:0cm 5.4pt 0cm 5.4pt; 
 mso-para-margin:0cm; 
 mso-para-margin-bottom:.0001pt; 
 mso-pagination:widow-orphan; 
 font-size:11.0pt; 
 font-family:""Calibri"",""sans-serif""; 
 mso-ascii-font-family:Calibri; 
 mso-ascii-theme-font:minor-latin; 
 mso-fareast-font-family:""Times New Roman""; 
 mso-fareast-theme-font:minor-fareast; 
 mso-hansi-font-family:Calibri; 
 mso-hansi-theme-font:minor-latin;}",1969,Geological Quarterly
Analysis and prediction of vehicle exhaust emission using ANN,"This paper focused on the analysis of vehicle emission based on the Hefei remote sensing data during the last three years. And we propose a three-layer artificial neural network model for predicting vehicle exhaust emission using remote sensing data. Firstly, we take adaptive-lasso algorithm to analyze the various factors from the emission data, and determine the principal factors. Secondly, after doing principal components analysis and selecting algorithm and architecture, the Back-Propagation neural network model with 7-12-1 architecture was established as the optimal approach. Finally, we give the prediction results on the testing data-set and prove the potentiality and validity of the proposed method in the prediction of vehicle exhaust emission.",2017,2017 36th Chinese Control Conference (CCC)
Effects of an Insecticide and a Herbicide Combination on Nontarget Arthropods in a Cornfield,"This study sought to assess the impact of an insecticide and a herbicide combination on nontarget arthropods in a cornfield. In each year of the experiment, 1.62 ha was divided into 16 plots. Barren strips of land, 3 m wide, were maintained around all 16 plots. A 4 Ã— 4 Latin square arrangement of the following treatments was used: (1) Furadan; (2) Furadan and a Lasso-Bladex mixture; (3) Lasso-Bladex mixture; and (4) no pesticides. Pitfall traps were placed in the field, each plot containing three traps. All 48 traps were run continuously from early summer to mid-October in 1980 and 1981. Throughout each summer, ground beetles (Coleoptera: Carabidae) and other nontarget arthropods were captured and identified. Furadan had very little effect on number of arthropods trapped in either year of the study. Weedier plots, those not receiving the Lasso-Bladex treatment, had more of certain nontarget arthropods trapped within them. Relative importance values were calculated for each type of arthropod to ascertain if a given species' position, within a community, had been shifted by a pesticide. The relative importance of most of the arthropods did not significantly differ among the four treatments in either year.",1983,Environmental Entomology
"Intra- and Intergeneric Similarities of the rRNA Cistrons of Alteromonas, Marinomonas (gen. nov.) and Some Other Gram-negative Bacteria","Summary: 14C-labelled rRNA was prepared from Alteromonas macleodii ATCC 27126 and from Alteromonas haloplanktis ATCC 14393. 3H-labelled rRNA was isolated from Alteromonas vaga ATCC 27119 and Alteromonas putrefaciens ATCC 8071 colony type tl. These rRNAs were hybridized under stringent conditions with filter-fixed DNA from various Alteromonas strains and from organisms of marine origin and/or with mol % G + C values in the range 40 to 50. Each hybrid was described by its Tm(e)
and percentage of rRNA binding. From rRNA similarity maps and Tm(e)
dendrograms the following conclusions were drawn. The genus Alteromonas is very heterogeneous and consists of four rRNA branches: (1) Alt. macleodii alone; (2) the Alt. haloplanktis cluster, containing most of the named Alteromonas species and a number of organisms which should be renamed Alteromonas (â€œPseudomonas marinoglutinosaâ€, â€œPseudomonas nigrifaciensâ€, â€œPseudomonas atlanticaâ€ ATCC 19262, â€œPseudomonas carrageenovoraâ€, â€œPseudomonas piscicidaâ€, and several unnamed alginolytic bacteria); we propose to limit the genus Alteromonas to the former two clusters; (3) Alt. putrefaciens, the rRNA cistrons of which resemble those of the Vibrionaceae and are as different from the above two Alteromonas rRNA branches as are those of the Vibrionaceae, the Enterobacteriaceae and Aeromonas; â€œPseudomonas rubescensâ€ belongs to this branch and Alteromonas hanedai seems to be a remote relative; (4) Alteromonas communis and Alt. vaga constitute another, separate rRNA branch; in conjunction with their special phenotypic features, we propose to create a new genus, Marinomonas, for them. The exact taxonomic position of â€œAlteromonas thalassomethanolicaâ€ could not be established.",1983,Microbiology
Ontology learning from text: Method for learning axioms,"Ontologies provide a structural organizational knowledge, they support the exchange and sharing of information. Moreover, one of the main benefits of using ontologies is the ability to infer new knowledge that allows the development of more realistic applications. The need for overcoming the bottleneck, given in the knowledge acquisition by the manual construction of ontologies, has motivated studies on semi-automatic and automatic methods to build ontologies. One of the main sources of knowledge created by humans is given by text resources. The analysis and extraction of the elements of an ontology from texts is a very hard task. In this report we focus on present the method for learning axioms from text based on named entity recognition. In our proposal we exploit corpora with high occurrence of named entities that give information on the individuals in a specific domain knowledge expressed by the corpus. Given the set of identified named entities the axiomatic relations such as subClassOf, disjointWith, and equivalentClass were identified. For this purpose a named entity recognition tool was used and the linguistic context, where classes co-occur, was extracted. This report of activities corresponds to the thrid year of doctoral studies.",2012,
Interval lasso regression based Extreme learning machine for nonlinear multivariate calibration of near infrared spectroscopic datasets,"As a nonlinear multivariate calibration method, extreme learning machine (ELM) has recently received increasing attention for its fast learning speed and excellent generalized performance. However, it is implemented normally under the empirical risk minimization scheme, and is prone to generate a large-scale and over-fitting model. Least absolute shrinkage and selection operator (LASSO) based ELM (LASSO-ELM) is a simple and efficient approach to avoid over-fitting and obtain an appropriate network structure. Unfortunately, when the initial hidden layer output matrix is in a high dimensional feature space, solving the LASSO problem remains a challenge. To improve the efficiency of solving high-dimension LASSO, we propose interval LASSO based ELM (iLASSO-ELM), which is generated by incorporating interval selection of hidden layer output matrix into original LASSO-ELM. The proposed model combines the coarse screening of interval selection and fine screening of LASSO. Thus, it can identify the relevant hidden nodes quickly and prevent over-fitting. A comparison of the proposed iLASSO-ELM with six other models, namely, ELM, partial least square based ELM (PLS-ELM), ridge regression based ELM (RR-ELM), elastic net based ELM (EN-ELM), LASSO-ELM and Least-Squares Support Vector Machines method (LS-SVM), was evaluated on four benchmark-near infrared (NIR) spectroscopic datasets. Additionally, the Wilcoxon signed rank test was used to statistically compare the predictive performance of the two competing calibration models. Experimental results show that iLASSO-ELM has the minimum root mean square errors of predictions and performs, at least statistically, not worse than other models.",2018,Analytical Methods
Putting the whole out of joint: Dupieuxâ€™s RÃ©alitÃ© as HyperChaos cinema.,"Digital cinema has widely suggested a time-space that many scholars have convincingly analysed as the reloading of Aeon - Â a whole expanding through the processes of becoming of its elements. However, some contemporary films develop through structures and narratives that resist such analysis, and focus on contingent changes that happen in a time without becoming and develop as a non-whole. This paper argues that Quentin Meillassouxâ€™s concept of hyperChaos provides a theoretical framework that resonates with the specificity of the temporality constructed by such films, and theorizes them as hyperChaos cinema. Meillassoux famously argues for an absolute contingency - the fact that any law can change at any moment and for no reason - and he calls HyperChaos the time in which these changes occur. Hyperchaos is the time that enables not only any possible becoming, but also such absolute changes as the radical interruption of all becomings in immobility, or the emergence of events ex nihilo, which do not find their origin in past processes. Through the analysis of Realite (Quentin Dupieux, 2014), as an example of HyperChaos cinema, this paper discusses how films can speculate not on a world with us, nor its variant of the world â€˜with-us-outâ€™, but an absolute world without us. I argue that Realite explores time as the repetition of closed sets that build up in a non-whole, i.e. an expansive structure in which each part emerges independently, and in which the changes are autonomous, and not contained in the past of the structure itself. Realite exemplifies, thus, the possibility of a radically non-anthropocentric cinema, and its ability to put the correlation between thought and world out of jointÂ  for both characters and audience.",2017,
"A Comparison of Pretest, Stein-Type and Penalty Estimators in Logistic Regression Model","Various estimators are proposed based on the preliminary test and Stein-type strategies to estimate the parameters in a logistic regression model when it is priori suspected that some parameters may be restricted to a subspace. Two different penalty estimators as LASSO and ridge regression are also considered. A Monte Carlo simulation experiment was conducted for different combinations, and the performance of each estimator was evaluated in terms of simulated relative efficiency. The positive-part Stein-type shrinkage estimator is recommended for use since its performance is robust regardless of the reliability of the subspace information. The proposed estimators are applied to a real dataset to appraise their performance.",2017,
"Weak signals in high-dimension regression: detection, estimation and prediction.","Regularization methods, including Lasso, group Lasso and SCAD, typically focus on selecting variables with strong effects while ignoring weak signals. This may result in biased prediction, especially when weak signals outnumber strong signals. This paper aims to incorporate weak signals in variable selection, estimation and prediction. We propose a two-stage procedure, consisting of variable selection and post-selection estimation. The variable selection stage involves a covariance-insured screening for detecting weak signals, while the post-selection estimation stage involves a shrinkage estimator for jointly estimating strong and weak signals selected from the first stage. We term the proposed method as the covariance-insured screening based post-selection shrinkage estimator. We establish asymptotic properties for the proposed method and show, via simulations, that incorporating weak signals can improve estimation and prediction performance. We apply the proposed method to predict the annual gross domestic product (GDP) rates based on various socioeconomic indicators for 82 countries.",2019,Applied stochastic models in business and industry
Interdependent effects of habitat quality and climate on population growth of an endangered plant,"Summary 1. To predict the viability of populations, it is essential to clarify how performance depends both on large-scale environmental changes, such as climate warming, and on the local habitat. However, in spite of their potential importance, effects of interactions between large-scale environmental changes and the local environment on population viability have rarely been examined. 2. We investigated how population dynamics of the endangered alpine plant Dracocephalum austriacum depend on local habitat quality and climatic variation, as well as how effects of climate depend on local habitat. We used lasso regression shrinkage and integral projection models to identify effects on vital rates and population growth rates in seven populations over seven annual transitions. 3. Populations on steeper slopes had lower survival and stochastic population growth rate than populations on more gentle slopes. In years with low spring temperatures and high summer temperatures, survival and population growth rate were lower. In addition, the negative effects of high summer temperatures did depend on local habitat quality, being more negative in populations on steeper slopes. 4. Combining the net positive effects of high spring temperature and the net negative effects of high summer temperature on plant vital rates with predicted climate change over the next 30 years suggested that effects on D. austriacum would be relatively small. 5. Synthesis. Our results show that different aspects of a warmer climate may have opposing effects on populations, and that climatic effects may depend on local habitat quality. Such interactive effects should be accounted for when determining effects of large-scale environmental changes on population and community dynamics.",2011,Journal of Ecology
Network-based investigation of genetic modules associated with functional brain networks in schizophrenia,"We developed a new sparse multivariate regression method, collaborative sparse reduced rank regression(C-sRRR) for detecting genetic networks associated with brain functional networks in schizophrenia (SZ). Our study: 1) introduced both genetic and brain network structure to group single nucleotide polymorphism (SNP) and voxels simultaneously for utilizing the interacting effects implied in both features; 2) used collaborative sparse group lasso to perform genetic variants selection and nuclear norm penalty to address the interrelationship among voxels; 3) developed an efficient algorithm for solving the non-smooth optimization. In real data analysis, we constructed 8605 genetic sub-networks (modules) from 722177 SNPs with a median module size of 9. A functional brain network was extracted which also showed significant discriminative characteristics between SZ and healthy controls. A sub sampling strategy was applied to identify 57 highly ranked genes from 14 high-ranking modules. 14 of them are SZ susceptibility genes and 6 genes were consistent with the findings in previous study.",2013,2013 IEEE International Conference on Bioinformatics and Biomedicine
A Transfer Learning Strategy for Short-term Wind Power Forecasting,"Newly-constructed wind farms often lack collections of historical wind power data and it is changeling to forecast their future wind power accurately. A novel transfer learning strategy for short-term wind power forecasting is proposed to tackle this issue in this paper. To more accurately forecast the wind power output of the newly constructed wind farm, a nearest-neighbors approach is employed to select highly relevant historical data from other wind farms. Thus, the wind power dataset of the target wind farm is significantly enriched and it allows to better train the forecasting models. A hybrid Jaya Extreme Gradient Boosting (Jaya-XGBoost) algorithm is employed to generate the forecasting results and wind power data collected in China is utilized. The Jaya-XGBoost algorithm is compared with Support Vector Machines (SVM), and Least Absolute Shrinkage and Selection Operator(LASSO),Neural Networks in wind power forecasting with different time horizons. Computational results demonstrate that the forecasting results of the four algorithms are all improved by leveraging information from other wind farms while the Jaya-XGBoost algorithm yields the best results over the four algorithms.",2018,2018 Chinese Automation Congress (CAC)
Utility of radiomics based on contrast-enhanced CT and clinical data in the differentiation of benign and malignant gallbladder polypoid lesions,"To develop and validate a novel method based on radiomics for the preoperative differentiation of benign and malignant gallbladder polypoid lesions (PLG). A total of 145 patients with pathological proven gallbladder polypoid lesionsâ€‰â‰¥â€‰1 cm were included in this retrospective study. All the patients underwent abdominal contrast-enhanced computed tomography (CT) examinations 3 weeks before cholecystectomy from January 2013 to January 2019. Seventy percent of the cases were randomly selected for the training dataset, and 30% of the cases were independently used for testing. Radiomics features extracted from portal venous-phase CT of the PLG and clinical features were analyzed, and the LASSO regression algorithm was used for data dimension reduction. Multivariable logistic regression was used to generate radiomics signatures, clinical signatures, and combination signatures. The receiver operating characteristic (ROC) curve and decision curve were plotted to assess the differentiating performance of the three signatures. The area under the ROC curve (AUC) of the radiomics signature and clinical signature was 0.924 and 0.861 in the testing dataset, respectively. For the radiomics signature, the accuracy was 88.6%, with 88.0% specificity and 89.5% sensitivity. When combined, the AUC was 0.931, the specificity was 84.0%, and the sensitivity was 89.5%. The differences between the AUC values of the two sole models and the combination model were statistically nonsignificant. Radiomics based on CT images can be helpful to differentiate benign and malignant gallbladder polypsâ€‰â‰¥â€‰1 cm in size.",2020,Abdominal Radiology
Effect of habitat fragmentation and protection status on seagrass-associated meiofauna along the Kenyan coast,"Habitat fragmentation threatens ecosystems worldwide including marine coastal ecosystems. Especially seagrass habitats suffer from increased levels of fragmentation often caused by (in)direct human activities. However, our understanding of species and community responses to variability in seagrass landscape structure and dynamics is still limited. Harpacticoid copepods, the dominant taxon of seagrass-associated meiofauna, are the main food source for juvenile fish. Any fragmentation effect on this taxon might impact the overall energy flow in the ecosystem and result in a modified fish production. Therefore, the abundance and diversity of meiofauna (harpacticoid copepods) were recorded in two fragmented and two continuous seagrass meadows (Thalassodendron ciliatum) nearby Mombasa and Watamu (Kenya). Fragmented meadows yielded significantly higher meiofauna (harpacticoids) densities likely caused by a positive edge effect. In contrast, the effect on faunal diversity was less pronounced.",2013,
Minimizing Modes for Smart Selection in Sketching/Drawing Interfaces,"User interface modes are ubiquitous in both mouse-keyboard and pen-based user interfaces, but the requirement for prior setting of a user interface mode before performing an action imposes a persistent drag on system usability. This chapter reviews our research in approaches to avoiding prior deliberate mode setting while still allowing overloading of fundamental tap and gesture operations. We analyze the humanâ€“machine dynamics of UI protocols through a graphical notation called the Interaction Flow Diagram. Our framework offers a pyramid of methods ranging from simple UI design techniques, through recognition of gestures and canvas content, to modeling of user knowledge and goals. These are represented in four methods: Overloaded Loop Selection to infer rectangle versus lasso selection mode; the Inferred Mode Protocol for Inferring Draw/Select Mode; the Sloppy Selection method for inferring intended content of an ambiguous selection; and the Cycle Tap Selection Method for exploiting structure recognition.",2011,
Evaluating the method of segmental isolation of pulmonary veins in patients with paroxysmal atrial fibrillation,"Objective To investigate the efficacy and safety of the segmental electrical isolation of pulmonary veins (PVs) in patients with paroxysmal atrial fibrillation (PAF). Methods Thirty-nine patients (28 males, 11 females) with recurrent documented symptomatic PAF were included. In order to avoid the risk of cardiac tamponand, we adopted one transseptal procedure and obtained unselective angiography of all PVs and left atrial appendage using pigtail catheter. Lasso mapping catheter and ablation catheter were put into target pulmonary vein ostium through the same site of atrial septum. We routinely mapped the right inferior PV lest any pulmonary vein potential (PVP) that triggered PAF should be omitted. RF ablation was applied at the PVP breakthrough and slightly right and left by moving the RF catheter. Results Eighty-five PVs were targeted for segmental RF ablation. Eight-one were isolated completely. Immediate successful rate was 95%. There was not any complication associated with the procedure. Conclusion It is suggested that the method of segmental PV isolation has a higher cure rate and a shorter procedure time compared with other traditional methods. It can minimize the lesion of pulmonary veins and avoid PV stenosis.",2003,Chinese Journal of Interventional Cardiology
[Immuno-virologic dissociation in patients infected by HIV-1 under antiretroviral treatment at the Day hospital of Bobo-Dioulasso from 2008 to 2012 (Burkina Faso)].,"OBJECTIVE
describe the sociodemographic, clinical, therapeutic, biological profile and the observance of treatment in cases of immuno-virologic dissociation response (IVDR) in HIV-1 patients at te 12 months of antiretroviral treatment (ARVT).


METHODS
This was a historical cohort study with a descriptive and analytical focus from January 2008 to December 2012; covering the IVDR cases at the day hospital of Bobo Dioulasso. We collected the data during medical consultations by means of the ESOPE software and from medical records of the patients.


RESULTS
Of 2078 patients on ARVT, 84 or 4% presented one IVDR, among which 56 women (66.7%) and 28 men (33.3%). The average age was 45 years [range: 45-55 years]. At the initiation of ARVT, most patients were in clinical stage 3 or 4 of the WHO classification (57.1%). The body mass index (BMI) average was 20.5kg/m2 [IQR = 18.5 and 23]. The average number of +CD4 T lymphocyte was 42 cells/mm3 [IQR = 12- 63]. During follow-up, the median gain in BMI was 3.2 kg/m2 [IQR = 1.2 to 4.3 kg/m2], the median gain was 76 cells/Âµl [IQR = 60 - 88]. The viral plasmatic load of the HIV-1 was undetectable with a rate of TCD4+ < 100 cells /Âµl in 12 months. Factors associated with IVDR were the age between 35 and 45 years (p = 0.0009), the number of +CD4 T cells (+CD4Tâ‰¤50) at initiation of ARVT (p = 0.00045 ) and the WHO classification clinical stage 3.


CONCLUSION
This study demonstrates the problem of IVDR management in Bobo-Dioulasso and reminds of the interest of care follow-up of people living with HIV-1 by viral load and not only by the rate of CD4+ T especially in the decentralized structures of coverage of HIV, where changes of therapeutic mechanisms operate disjointedly.",2015,Le Mali medical
Semi-Automatic Segmentation of Prostate in CT Images via Coupled Feature Representation and Spatial-Constrained Transductive Lasso,"Conventional learning-based methods for segmenting prostate in CT images ignore the relations among the low-level features by assuming all these features are independent. Also, their feature selection steps usually neglect the image appearance changes in different local regions of CT images. To this end, we present a novel semi-automatic learning-based prostate segmentation method in this article. For segmenting the prostate in a certain treatment image, the radiation oncologist will be first asked to take a few seconds to manually specify the first and last slices of the prostate. Then, prostate is segmented with the following two steps: (i) Estimation of 3D prostate-likelihood map to predict the likelihood of each voxel being prostate by employing the coupled feature representation, and the proposed Spatial-COnstrained Transductive LassO (SCOTO); (ii) Multi-atlases based label fusion to generate the final segmentation result by using the prostate shape information obtained from both planning and previous treatment images. The major contribution of the proposed method mainly includes: (i) incorporating radiation oncologist's manual specification to aid segmentation, (ii) adopting coupled features to relax previous assumption of feature independency for voxel representation, and (iii) developing SCOTO for joint feature selection across different local regions. The experimental result shows that the proposed method outperforms the state-of-the-art methods in a real-world prostate CT dataset, consisting of 24 patients with totally 330 images, all of which were manually delineated by the radiation oncologist for performance evaluation. Moreover, our method is also clinically feasible, since the segmentation performance can be improved by just requiring the radiation oncologist to spend only a few seconds for manual specification of ending slices in the current treatment CT image.",2015,IEEE Transactions on Pattern Analysis and Machine Intelligence
[Peripheral neuropathies revealing HIV infection at the Hospital Center of Bobo-Dioulasso (Burkina Faso)].,"Several peripheral neuropathies are associated with human immuno-deficiency virus (HIV) infection. In Africa, certain diseases are of particular importance. In the present work, we report peripheral neurological involvement as revealing signs of HIV infection within the internal medicine unit of a large city over a 2-year period. All adult subjects with a positive HIV serology revealed by a peripheral neuropathy observed in the National Hospital Centre of Bobo-Dioulasso over a two-year period (1 January 1999 and 31 December 2000) were included in the study. 46 cases of peripheral neuropathies revealing HIV infection were screened. Peripheral facial paralysis concerned 25 patients, 15 women and 10 men, in the early stages of HIV infection. The average age was 34 years. For 80% of the patients, he CD4 count was over 200. 5/10 cases of polyneuropathy occurred at the early stage of the HIV infection. Herpes zoster occurred in the early stages in 5/7 cases. 3/4 cases of polyradiculopathy occurred at a later stage with CD4 count under 200. Our study indicates clearly that isolated peripheral facial paralysis, sensitive polyneuropathy, herpes zoster and polyradiculopathy in young adults should lead to HIV testing.",2002,Bulletin de la Societe de pathologie exotique
Variable selection for models with missing data,"RAMON ISRAEL GARCIA: Variable Selection for Models with Missing Data. (Under the direction of Joseph G. Ibrahim and Hongtu Zhu.) This dissertation is composed of three papers which address the problem of variable selection for models with missing data. In the first paper, we consider variable selection for generalized linear models with missing data, including missing covariate and/or response data. The second paper deals with variable selection in the Cox regression model with covariates missing at random. For the third paper, we consider jointly selecting fixed and random effects in mixed effect models. In all three papers, we calculate the maximum penalized likelihood estimates using the smoothly clipped absolute deviation (SCAD) and adaptive LASSO (ALASSO) penalty functions and propose a unified model selection and estimation procedure for use in the presence of missing data. The maximum penalized likelihood estimates are shown to posses consistency and sparsity properties and are asymptotically normal. A computationally attractive algorithm is developed which simultaneously optimizes the penalized likelihood function and penalty parameters. Particularly, we propose to use a model selection criterion, called the ICQ criterion, for selecting the penalty parameters. We show that the variable selection procedure based on ICQ consistently selects important covariates and/or fixed and random effects. The methodology is very general and can be applied to numerous situations involving missing data, from covariates missing at random in arbitrary regression models to nonignorably missing longitudinal responses and/or covariates to mixed effects models.",2009,
Development Of Proxy Models For Reservoir Simulation By Sparsity Promoting Methods And Machine Learning Techniques,"Learning from data has been a rich topic of research in many engineering disciplines. In particular, in reservoir engineering, data-driven methodologies have been applied successfully to infer interwell connections and flow patterns in the subsurface and in assisting field development plans, including, history matching and performance prediction phases, of conventional and unconventional reservoirs. Although real-time data acquisition and analysis are becoming routine in many workflows, there is still a disconnect with the traditional theoretical first laws principles, whereby conservation laws and phenomenological behavior are used to derive the underlying spatio-temporal evolution equations. 
In this work, we propose to combine sparsity promoting methods and machine learning techniques to find the governing equation from the spatio-temporal data series from a reservoir simulator. The idea is to connect data with the physical interpretation of the dynamical system. We achieve this by identifying the nonlinear ODE system equations of our discretized reservoir system. The solution is assumed sparse because we know there is only few terms are relevant for each governing equation. The sparse structure is invoked by two methods: sparse regression with hard threshold (SINDy) and sparse regression with soft threshold (LASSO). For each method to work properly without overfitting, unique ways have been developed for seeking a balance between accuracy and complexity of the model with either l1 or l2 norm penalty. In addition, the sparsity structure can be further fixed with the physical fact that flow term is only related with its adjacent cells. 
We apply the method to a two-dimensional single phase flow system. First, the time series data is generated from the simulator with recording points equally spread in space. Then a large library is built containing possible linear, nonlinear terms of the governing ODE equation and finally the combination of the terms is identified through a coefficient vector for each equation. Difference in each technique and detailed modification to the threshold tolerance and penalty factor will be discussed and compared. Extensions to the two-phase flow case is also underway and promising initial results will also be shown in this paper. The validation process is achieved by comparing the original single/two phase simulator results and the results solved from the identified ODE system by Newton iteration.",2018,
On LARS/Homotopy Equivalence Conditions for Over-Determined LASSO,"We revisit the positive cone condition given by Efron for the over-determined least absolute shrinkage and selection operator (LASSO). It is a sufficient condition ensuring that the number of nonzero entries in the solution vector keeps increasing when the penalty parameter decreases, based on which the least angle regression (LARS) and homotopy algorithms yield the same iterates. We show that the positive cone condition is equivalent to the diagonal dominance of the Gram matrix inverse, leading to a simpler way to check the positive cone condition in practice. Moreover, we elaborate on a connection between the positive cone condition and the mutual coherence condition given by Donoho and Tsaig , ensuring the exact recovery of any k -sparse representation using both LARS and homotopy.",2012,IEEE Signal Processing Letters
Double-Selection based High-Dimensional Factor Model with Application in Asset Pricing,"This paper proposes a principal component analysis (PCA) approach after a double-selection Lasso and applies it to both Chinese and US stock market data. Similar to the idea of Post-Lasso, we perform least squares regression on the principal component factors. To accommodate the nonlinear nature of the data, this paper compares the support vector regression (SVR) model with least squares regression model. Empirical results show that the SVR method can improve the prediction ability, as evidenced by the superior accumulated rate of return using the test set sample of both markets.",2019,2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP)
Evaluasi Pelatihan Implementasi Kurikulum 2013Bagi Guru Kelas/Mapel Di SMP Se Kabupaten Toraja UtaraJokebet SaludungFakultas Teknik UNM MakassarE-mail: jokebet@yahoo.com,"Abstract 
This research was conducted to evaluate of Curriculum 2013 implementation Training for 
Teachers Classroom /Mapel in Junior High School at North Toraja Regency. Training 
conducted in North Toraja Regency of June 18, 2014 until June 23, 2014, for 52 hours and 
was trained by National Instructor. This research aims to evaluate what extent understand of 
knowledge, attitudes and skills possessed Teachers Classroom/Mapel at Junior High School 
in North Toraja Regency after Training of Curriculum 2013 Implementation is completed. The 
training aims to train teachers in order objectives to understand and implement of curriculum 
2013 in the classroom appropriate of subjects taught. Followed by the training of Teacher 
Classoom/Mapel of Mathematics, English, Indonesian, Science, Art and Culture, Penjas, and 
IPS, as much as 249 people. Subjects of research were Teachers Classroom/Mapel of seven 
subject were taken by proportional ramdom sampling as many as 100 people. Data were 
collected by questionnaires, observations, interviews, tests, and analysis by descriptive and 
qualitative. The expected result that participants understand the training material, has 
3 
attitude and skills to implement of Curriculum 2013 in the class as optimal as possible. 
Participants can understand the concept of curriculum 2013, rational and elements of 
curriculum change, SKL, KI, KD, implementation strategy of curriculum 2013, learning and 
assessment approaches, the teacher and the student books analyzes ; design and 
implementation of assessment, scientific approach, learning models, reporting results of 
assessment, preparation of lesson plans, and teaching practice. 
Keywords: Evaluation, Training of Curriculum 2013, Teacher of Junior High School",2014,
"Litorivita pollutaquae gen. nov., sp. nov., a marine bacterium in the family Rhodobacteraceae isolated from surface seawater of Xiamen Port, China.","A Gram-stain-negative Rhodobacterales strain, designated as FSX-11T, was isolated from surface seawater of Xiamen port in China. Strain FSX-11T showed less than 96.5â€Š% 16S rRNA gene sequence similarity to the type strains of species with validly published names. Phylogenetic analysis based on 16S rRNA gene sequences revealed that the novel isolate formed a distinct monophyletic clade within the family Rhodobacteriaceae and clustered distantly with the genera Thalassobius and Marivita. Cells of strain FSX-11T were non-motile, oval-shaped and facultative anaerobic. Optimal growth occurred at 20-30â€‰Â°C, at pH 7.0-8.0 and in the presence of 2-3â€Š%â€‰NaCl (w/v). The major respiratory quinone was ubiquinone-10. Summed feature 8 (C18â€Š:â€Š1Ï‰7c and/or C18â€Š:â€Š1Ï‰6c), 11-methyl C18â€Š:â€Š1Ï‰7c and C16â€Š:â€Š0 were the major fatty acids. The DNA G+Câ€‰content of strain FSX-11T was 58.7â€‰mol%. On the basis of phylogenetic analysis, phenotypic and chemotaxonomic characteristics and 16S rRNA gene signature nucleotide patterns, strain FSX-11T represents a novel species in a novel genus within the family Rhodobacteraceae, for which the name Litorivita pollutaquae gen. nov., sp. nov. is proposed. The type strain is FSX-11T (=JCM 32715T=MCCC 1K03503T).",2018,International journal of systematic and evolutionary microbiology
Bootstrapping promotes the RSFC-behavior associations: an application of individual cognitive traits prediction,"Resting state functional connectivity records enormous functional interaction information between any pair of brain nodes, which enriches the prediction of individual phenotypes. To reduce the high dimensional features in prediction, correlation analysis is a common way for feature selection. However, rs-fMRI signal exhibits typically low signal-to-noise ratio and correlation analysis is sensitive to outliers and data distribution, which may bring unstable and uninformative features to subsequent prediction. To alleviate this problem, a bootstrapping-based feature selection framework was proposed and applied on three widely used regression models: connectome-based predictive model (CPM), support vector regression (SVR) and least absolute shrinkage and selection operator (LASSO). A large open-source dataset from Human Connectome Project (HCP) was adopted in the study and a series of cognitive traits were acted as the prediction targets. To systematically investigate the influences of different parameter settings on the bootstrapping-based framework, a total of 216 parameter combinations were evaluated through the R value between the predicted and real cognitive traits, and the best identified performance among them was chosen out as the final prediction accuracy for each cognitive trait. By using bootstrapping without replacement, the best performances of CPM with positive and negative feature sets, SVR and LASSO averagely increased by 28.0%, 33.2%, 11.6% and 24.3% in R values in contrast to the baseline method without bootstrapping. By using bootstrapping with replacement, these best performances increased by 22.1%, 22.9%, 9.4% and 19.6%. Furthermore, the bootstrapping-based feature selection methods could effectively refine the original feature sets obtained from correlation analysis, which thus retained the more stable and informative feature sets. The results demonstrate that bootstrapping-based feature selection is an easy-to-use and effective method to improve RSFC prediction of cognitive traits and is highly recommended in future RSFC prediction studies.",2019,bioRxiv
The Construction of Risk Prediction Models Using GWAS Data and Its Application to a Type 2 Diabetes Prospective Cohort,"Recent genome-wide association studies (GWAS) have identified several novel single nucleotide polymorphisms (SNPs) associated with type 2 diabetes (T2D). Various models using clinical and/or genetic risk factors have been developed for T2D risk prediction. However, analysis considering algorithms for genetic risk factor detection and regression methods for model construction in combination with interactions of risk factors has not been investigated. Here, using genotype data of 7,360 Japanese individuals, we investigated risk prediction models, considering the algorithms, regression methods and interactions. The best model identified was based on a Bayes factor approach and the lasso method. Using nine SNPs and clinical factors, this method achieved an area under a receiver operating characteristic curve (AUC) of 0.8057 on an independent test set. With the addition of a pair of interaction factors, the model was further improved (p-value 0.0011, AUC 0.8085). Application of our model to prospective cohort data showed significantly better outcome in disease-free survival, according to the log-rank trend test comparing Kaplan-Meier survival curves (p--value 2:09 x 10(-11)). While the major contribution was from clinical factors rather than the genetic factors, consideration of genetic risk factors contributed to an observable, though small, increase in predictive ability. This is the first report to apply risk prediction models constructed from GWAS data to a T2D prospective cohort. Our study shows our model to be effective in prospective prediction and has the potential to contribute to practical clinical use in T2D.",2014,PLoS ONE
í•œêµ­ê³¼ ì¼ë³¸ì˜ ë”¸ë¼ì†Œí…Œë¼í”¼(Thalassotherapy) ì‚°ì—… í˜„í™©ê³¼ ë¯¸ëž˜,"Talassotherapy, a form of medical therapy using seawater, is also expected to gain a renewed popularity as a treatment modality for enhanced natural health. With abundant marine resources, both Japan and Korea are conveniently located to draw attention as attractive destinations for talassotherapy services. As for the development of talassotherapy centers, however, Japan is a step ahead of Korea. Jeju Island in Korea, often regarded as the most ideal location with its well-preserved natural environments and unique cultural heritage, is still scratching its ground. For Jeju Island to be more competitive in health tourism, it needs to be encouraged to spur development of thalassotherapy centers along with unique and viable service programs. For a latecomer, the experience of the leading centers in Japan will serve as a good lesson. Kanna Thalassa in Okinawa, Japan is one example of successful talassotherapy centers. The Kanna Thalassa, offers a variety of programs. Bath pools with seawater massage equipments and a line of bath tubs adjustable to individual health needs are among the key facilities of the Center. What the Center boasts of is the well-organized package menu system. A group of health consultants, residing at the Center, design and offer individual clients the best fit practicing programs with aims to improve their health. The customers practice the individually tailored programs for their intended staying periods. The performance of the leading thalassotherapy centers in Japan can give good lessons for planners in Jeju. When it comes to the location and its inherited natural environments, Jeju is as good as Okinawa and other coastal areas in Japan. Particularly, the lava sea water of Jeju is truly outstanding. It is already world famous for its clarity and rich minerals, which should be used as core assets for the successful development of thalassotherapy centers in Jeju in the near future. Drawing upon the lessons from Japanese talasso centers, the project suggested is aiming at studying the feasibility of unique Jeju thalassotherapy business models, which would shed useful lights on the development of the spa and tourism industry in Jeju.",2012,
Multi-block high-dimensional lasso-penalized analysis with imputation of missing data applied to postgenomic data in an Ebola vaccine trial,"Several sets of variables can be analyzed simultaneously by canonical correlation in a multi-way analysis. These sets of variables are often high-dimensional and repeated over time. For instance, full-transcriptome measured by RNA-Seq used to be performed in longitudinal studies as well as other measures such as peptides or cells. Hence, canonical correlation analysis has been extended with regularized approaches to deal with several high dimensional data. However, some measurements can be missing for technical reasons and therefore introduce undesired structures due to the huge dimension of the datasets. 
Our objective is to find an efficient method allowing to impute the missing values taking into account the three-way structure, participant-transcriptome-time, and also the missing path structure. 
We proposed an EM-like covariance-maximization lasso-penalized high-dimensional completion matrix algorithm to reach that goal. 
We compared our approach on simulated data-sets with the mean imputation per gene pertime step, the missMDA-imputeMFA algorithm which takes structure into account and the softImpute solution initially designed to solve the Netix competition a high-dimensional problem. We used two criterions: the L2-error between estimated and simulated values and the L2-error between estimated and simulated covariance matrices. The numerical results 
exhibited the superiority of the proposed method in most of the scenarii. We also illustrated our approach on a real data-set from a phase I Ebola vaccine trial measuring RNA-Seq data after vaccination (richtien, cell report 2017) in 20 participants at 4 different times on whole-blood samples, representing 74 sequenced-samples, among which 24 samples were missing because of technological issues.",2018,
Clinical and Hematologic Impact of Fetal and Perinatal Variables on Mutant GATA1 Clone Size in Neonates with Down Syndrome,"Children with Down syndrome (DS; trisomy 21) have an increased risk of acute myeloid leukemia (ML-DS) in the first 5 years of life. In most cases ML-DS is preceded by Transient Abnormal Myelopoiesis (TAM), a fetal/neonatal pre-leukemic disorder unique to DS which regresses after birth. Both TAM and ML-DS harbor acquired N-terminal mutations in the hematopoietic transcription factor gene GATA1 . In a prospective study of 200 DS neonates, we recently showed that 29% had acquired GATA1 mutations including 17/200 (8.5%) with clinical or hematologic evidence of TAM; the remaining 20.5% were clinically and hematologically 9silent9, with smaller mutant GATA1 clones and lower blast frequency compared to overt TAM. The reasons why some DS neonates develop overt TAM and the factors which determine mutant GATA1 clone size are unknown. To address this, we analysed data from neonates in the prospective Oxford-Imperial DS Cohort Study and investigated the impact of 30 clinical and hematologic factors on clone size using statistical and mathematical modelling. Mutant GATA1 clones were determined in 54 neonates by targeted next generation sequencing of GATA1 exon 2 (mutation detection limit 0.3%). Clone size was determined by analysing original unprocessed reads using less stringent filtering parameters and counting reads containing mutated v total sequence. Correlation analysis identified 4 hematologic variables correlated with mutant GATA1 clone size: circulating nucleated red cells (r=+0.5003; p=0.0001), platelets (r=+0.436; p=0.001), total leukocytes (r=+0.7094; p 150x10 9 /L (p=0.019). Numbers of neutrophils, monocytes, basophils, eosinophils and lymphocytes did not correlate with GATA1 clone size. Clinical variables significantly correlated with clone size were hepatomegaly (p=0.0016), splenomegaly (p=0.0001) and rash (0.0174). The only pregnancy-related variables affecting mutant GATA1 clone size were intrauterine growth restriction and maternal diabetes (p=0.0156). Linear regression to determine the joint impact of all 30 variables on clone size (r2=0.88) followed by Lasso penalization identified the same 4 hematologic variables (nucleated red cells, platelets, total leukocytes and % blasts); Lasso penalized regression with these 4 variables gave a coefficient of determination of 0.63. Together these data suggest that chronic intrauterine hypoxia may affect expansion/differentiation of mutant GATA1 clones in DS. Consistent with this, nucleated red cells from 3 neonates with TAM all harbored GATA1 mutations identical to those in total circulating nucleated cells. Since neither perinatal infection nor gestational age at birth correlated with mutant GATA1 clone size, infection-related cytokines and the timing of acquisition of a mutant GATA1 clone during fetal development may not play a major role in determining clone size. Finally, a hierarchical model to investigate the impact of GATA1 mutation on hematopoietic stem and progenitor (HSPC) differentiation in DS neonates using a Bayesian approach also predicted increased erythroid cell output from GATA1 mutated HSPC v HSPC without a GATA1 mutation. In conclusion, in neonates with DS the size of the mutant GATA1 clone correlates with the presence of clinical signs of hepatomegaly, splenomegaly and skin rash; mutant GATA1 clone size correlates with the numbers of circulating nucleated red cells, platelets and blast cells suggesting that GATA1 mutant HSPC retain the ability to differentiate down the erythroid and megakaryocyte lineage; intrauterine hypoxia may be one of the factors driving expansion and/or maturation of the GATA1 mutant clone during fetal life in DS. Disclosures No relevant conflicts of interest to declare.",2014,Blood
A Bayesian method for detecting pairwise associations in compositional data,"Compositional data consist of vectors of proportions normalized to a constant sum from a basis of unobserved counts. The sum constraint makes inference on correlations between unconstrained features challenging due to the information loss from normalization. However, such correlations are of long-standing interest in fields including ecology. We propose a novel Bayesian framework (BAnOCC: Bayesian Analysis of Compositional Covariance) to estimate a sparse precision matrix through a LASSO prior. The resulting posterior, generated by MCMC sampling, allows uncertainty quantification of any function of the precision matrix, including the correlation matrix. We also use a first-order Taylor expansion to approximate the transformation from the unobserved counts to the composition in order to investigate what characteristics of the unobserved counts can make the correlations more or less difficult to infer. On simulated datasets, we show that BAnOCC infers the true network as well as previous methods while offering the advantage of posterior inference. Larger and more realistic simulated datasets further showed that BAnOCC performs well as measured by type I and type II error rates. Finally, we apply BAnOCC to a microbial ecology dataset from the Human Microbiome Project, which in addition to reproducing established ecological results revealed unique, competition-based roles for Proteobacteria in multiple distinct habitats.",2017,PLoS Computational Biology
Molecular characterization of a decapod Penstylidensovirus 1 (PstDV1) isolated from Penaeus semisulcatus in Egypt,"As shrimp aquaculture in Egypt has evolved from a subsistent farming activity in the early 1980s to an economically important global industry in the early 2010. Penaeid shrimp farming is becoming an important industry in Egypt in its developmental goals. Currently, the shrimp industry is based mainly on the culture of introduced pacific white shrimp, Litopenaeus vannamei. Egypt seeks to be a big shrimp producer in the near future. Disease has had a major impact on shrimp aquaculture in Egypt since it became a significant commercial entity in the early 2010. Viral diseases have also evolved to become a serious threat to the sustainable growth of shrimp industry. Many practices have been used by shrimp farmers in Egypt to manage many of the viral, bacterial, fungal and protozoan diseases using chemotherapeutics. However, most diseases such as viral diseases have been more difficult to manage and they have been responsible for the mass mortalities and socioeconomic impacts to shrimp farmers. Five of the seven virus diseases of penaeid shrimp listed by the World Animal Organization (OIE), have become enzootic in Egypt following the introduction of both Fenneropenaeus indicus and L.vannamei between 2010 and 2015. Examples include the white spot syndrome virus (WSSV) (KR083866), Penaeus stylirostrisdensovirus 1 (PstDNV1) (KT316249.1, KT316250.1, KT316251.1, KT316252.1, KT316253.1, KT316254.1, KT316256.1, KT316257.1, KT316258.1, KT316259.1 and KT316260.1), hepatopancreatic parvovirus (HPV) (KR492908.1, KR492909.1, KR4929010.1, KR492911.1, KT316240.1, KT316241.1, KT316242.1, KT316243.1, KT316244.1 and KT316245.1), yellow head virus (YHV) (KT316278.1), and gillassociated virus (GAV) (KT316279.1).",2019,
"Tectonic Processes of Pliocene-Pleistocene Sedimentary Basin in the Uplift Belt of Inner Arc: Case of the Nishime Sedimentary Basin in the Dewa Hills, Northeast Japan Arc","In the Northeast Japan Arc, uplift ranges and subsided sedimentary basins form topographic rows parallel to the north-trending arc and trench, and their arrangement reflects the neotectonic movement of the arc-trench system due to the horizontal shortening stress field in the east-west direction. To reconstruct the detailed tectonic processes of the Dewa Hills, one of the remarkable uplift belts in the inner zone of the Northeast Japan Arc, this paper aims at elucidating the Latest Cenozoic succession of the Pliocene-Pleistocene Nishime Sedimentary Basin in the hills. In the Nishime Basin accompanying the Nishime Syncline, the Pliocene Tentokuji and Sasaoka Formations of marine origin, the Nishime Formation of latest Early to early Middle Pleistocene age, deposited under neritic to fluvial environments, and the Yurihara Debris Avalanche Deposits flowing down the Chokai Volcano in middle to late Middle Pleistocene time, are well-exposed in ascending order. The Last Interglacial thalassostatic terrace surface, namely Hj-M1 Surface, is fragmentarily present in the north of the basin. The Nishime Sedimentary Basin continued to exist as a relative subsided area accompanying the movement of the Nishime Syncline from the earliest Pliocene, and filling by a sequence of basin-fills was completed before the deposition of the Yurihara Debris Avalanche in the middle to late period of Middle Pleistocene age, caused by the extinction of the syncline. Since then, the regional uplift has predominated in the whole of the Nishime Basin up to present, and the basin is no longer an active sedimentary basin. The Nikaho Thrust Faults situated on the western fringe of the basin, partly promoted the growth of the Nishime Syncline, but are inferred to have also moved since Late Pleistocene time. From these and some data on the other sedimentary basins in the Dewa Hills, it is concluded that both the uplifted and subsided areas were concurrent during the time from the early Pliocene to the Middle Pleistocene in the Dewa Hills. In contrast, the hills are considered to have grown since Middle Pleistocene time until present as a single uplift zone restricted at its western margin by the Kitayuri Thrust Fault System. * Institute of Geography , Tohoku University, Sendai 980-8578, Japan Science Reports of Tohoku University, 7th Series (Geography) Vol. 50, No. 1, June, 2000, 35-57",2000,The science reports of the Tohoku University
Novel body fat estimation using machine learning and 3-dimensional optical imaging,"Estimates of body composition have been derived using 3-dimensional optical imaging (3DO), but no equations to date have been calibrated using a 4-component (4C) model criterion. This investigation reports the development of a novel body fat prediction formula using anthropometric data from 3DO imaging and a 4C model. Anthropometric characteristics and body composition of 179 participants were measured via 3DO (Size StreamÂ® SS20) and a 4C model. Machine learning was used to identify significant anthropometric predictors of body fat (BF%), and stepwise/lasso regression analyses were employed to develop new 3DO-derived BF% prediction equations. The combined equation was externally cross-validated using paired 3DO and DXA assessments (nâ€‰=â€‰158), producing a R2 value of 0.78 and a constant error of (Xâ€‰Â±â€‰SD) 0.8â€‰Â±â€‰4.5%. 3DO BF% estimates demonstrated equivalence with DXA based on equivalence testing with no proportional bias in the Blandâ€“Altman analysis. Machine learning methods may hold potential for enhancing 3DO-derived BF% estimates.",2020,European Journal of Clinical Nutrition
Detection of Copy Number Variation Regions Using the DNA-Sequencing Data from Multiple Profiles with Correlated Structure,"In this article, we investigate the problem of detecting boundaries of DNA copy number variation (CNV) regions using the DNA-sequencing data from multiple subject samples. Genomic features along the linear realization of the actual genome are correlated, especially within vicinity of a locus, so are the sequencing reads along the genome. It is then crucial to take the correlated structure of such high-throughput genomic data into consideration when modeling DNA-sequencing data for CNV detection from statistical and computational viewpoints. We use the framework of a fused Lasso latent feature model to solve the problem, and propose a modified information criterion for selecting the tuning parameter when search for common CNVs is shared by multiple subjects. Simulation studies and application on multiple subjects' next-generation sequencing data, downloaded from the 1000 Genome Project, showed that the proposed approach can effectively identify individual CNVs of a single subject profile and common CNVs shared by multiple subjects.",2018,Journal of computational biology : a journal of computational molecular cell biology
Linear models in genomic studies,"Abstract With the help of molecular markers, genome-wide association studies (GWAS) are conducted to identify genes associated with diseases. Association mapping uses unrelated individuals from the same population that has undergone recombination in many generations since the inception of the mutant gene and is the basis for detection of causal genes. The data that forms the basis for computational detection of causal genes are of three kinds, phenotypic values (single trait or several traits), genotypes of hundreds of thousands of SNP markers, and data on gene expression, a sort of intermediate phenotypes that are used to associate genes with disease phenotypes. Most of the studies except a few, however, consider single trait at a time and take either phenotypes and marker genotypes only or considers phenotypes, genotypes and gene expression all together. In actual situations, on the other hand, the problem is multivariate since many complex disease syndromes consist of a large number of highly related clinical or molecular phenotypes. For instance, asthma is influenced by as many as 53 clinical traits that can be represented as a quantitative trait network (QTN). The methodological issue is then to conduct association analysis that takes into account jointly all the relevant traits instead of a single trait only. Linear models in which a dependent variable (expression of a disease trait) is related to a set of independent variables (for instance, SNPs) provide with a very versatile tool that can be used for the association analysis both for a single as well as multiple traits. To this end, we systematically discuss the sparse regression methodology of Ridge Regression, Lasso, and GFLasso with illustrations from published literature.",2014,Current Medicine Research and Practice
Adaptive lasso for accelerated hazards models,"ABSTRACT The important feature of the accelerated hazards (AH) model is that it can capture the gradual effect of treatment. Because of the complexity in its estimation, few discussion has been made on the variable selection of the AH model. The Bayesian non-parametric prior, called the transformed Bernstein polynomial prior, is employed for simultaneously robust estimation and variable selection in sparse AH models. We first introduce a naive lasso-type accelerated hazards model, and later, in order to reduce estimation bias and improve variable selection accuracy, we further consider an adaptive lasso AH model as a direct extension of the naive lasso-type model. Through our simulation studies, we obtain that the adaptive lasso AH model performs better than the lasso-type model with respect to the variable selection and prediction accuracy. We also illustrate the performance of the proposed methods via a brain tumour study.",2018,Journal of Statistical Computation and Simulation
An overview of reciprocal L1â€regularization for high dimensional regression data,"High dimensional data plays a key role in the modern statistical analysis. A common objective for the high dimensional data analysis is to perform model selection, and penalized likelihood method is one of the most popular approaches. Typical penalty functions are usually symmetric about 0, continuous and nondecreasing in (0,â€‰âˆž). In this review article, we will focus on a special type of penalty function, the so call reciprocal Lasso (rLasso) penalty. The rLasso penalty functions are decreasing in (0,â€‰âˆž), discontinuous at 0, and converge to infinity when the coefficients approach zero. Although uncommon, this choice of penalty is intuitively appealing if one seeks a parsimonious model fitting. In this article, we will provide an overview for the motivation, theory, and computational challenges of this rLasso penalty, and we will also compare the theoretical properties and empirical performance of rLasso with other popular penalty choices. 
 
For further resources related to this article, please visit the WIREs website.",2018,Wiley Interdisciplinary Reviews: Computational Statistics
Long Life Testing of Oxide-Coated Iridium/Rhenium Rockets,"for radiation-, BrianD. Reed cooled rockets operating onEarth storablepropellantsNASA-LewisResearchCenter (ref. 1). The useofceramic oxides asan additionalCleveland, Ohio coating for iridiumlrhenium(k/Re) rocket chambers isâ€¢ beingevaluated. The addition oftheseoxidecoatingscouldfurtherincrease thelifetimesof/r/Re rocketsandAbs_ct allowoperation in more oxidizing combustion22-Nclass rockets,composedof arhenium environments thanEarth storablepropellants. The(Re) substmte, an iridium Or)coating,andan additional oxidecoatings that arebeingevaluatedfor Ir/Re rocketscomposite coatingconsistingof IXanda ceramicoxide, includehaf-nia0-IrOn,ziroonia(ZrOz),and a compositewere testedon gaseous oxygen/gaseoushydrogen coatingcomposed of Irand anoxide.(GO2/GH2) propellants. Tworockets weretested,onefor nearly 39 hoursat a nominal mixture ratio ('MR)of The primary life limitingmechanism for IX/Re4.6 and chamberpressure (Pc) of469 kPa, andthe other chambers is the diffusion of Re into theIr layer. As thefor over 13 hours ata nominal MR of 5.8and 621 kPa concentrationof Re increasesat theIXsurface, theIxPc. Four additional Ix/Rerockets, with a composite Ix- oxidationresistancecontinuallydegrades. When aoxidecoating fabricatedusingamodifiedprocess,were criticalRe concentrationattheinnersurface is reached,also tested, includingone for 1.3hours ata nominal theIxoxidationrate increasessignificantly,leadingtoMR of 16.7 and Pe of 503 kPa. The longlifetimes therapidremoval ofIxand oxidationof theunderlyingdemonstrated on lowMR GO2/G/-I2suggestgreatly Re (ref. 2). Re diffusion into Irand oxidationofIxareextended chamber lifetimes(tensof hours)in the beth temperature-drivenprocesses. Thelow thermalrelatively low oxidizing combustionenvironments of conductivityoxide layer actsas athermalbarrier,Earth storable propellants. The oxidecoatingscould significantly lowering thetemperatureat theIr surface,also serve as aprotective coating in thenear injector whereoxidationtakesplace,and attheRe-Ixinterface,region, wherea still-mixingflowfieldmaycause whereRe diffusion occurs.The oxidelayeralso actsas adegradation of their layer. Operation atMR close to 17 diffusion barrier, slowing theingressof oxidizers to thesuggests that oxide-coatedk/Re rocketscouldbe usedin ir surfaceand theegress ofIr oxidationproductsfromseverely oxidizing combustionenvironments, suchas theIXsurface. Furthermore,anoxidelayer would servehigh MR GO2/GH2,oxygen/hydrocarbon,andliquid asa protectoragainst Irdegradationexperiencedin somegun propellants, testing of!r/Re rockets (ref. 3). Thepresence ofanoxidecoating would prevent theIXlayerfrom beingexposed to a still-mixing,still-combustingflowfield,Introduction whichis thesuspected causeof their degradation. TheThe most common material systemcurrendy synergisticeffectsof oxidecoatingscouldresult inused for radiation-cooledrockets is aniobiumalloy significantly longer life for IX/Rerockets operating onsubstrate (C103)with a fusedsilica coating(R512E) for Earth storable propellantsand enableoperation inoxidation protection. Significant amounts of fuel film aggressivelyoxidizing combustionenvironments thatcooling arerequired to keep thismaterialsystem below would not be possible for/r/Re alone.its maximum operating temperature of 1370 ""C,adversely affectingengineperformance. Anew classof A previous technologyprogram(ref. 4)high-temperature,oxidation-resistantmaterialsis under evaluatedsevenoxide-coatedk/Re rocketsthroughdevelopment forradiation-cooledrockets. These testingon gaseous oxygen/gaseoushydrogenmaterials have thethermal marginto allow rocket (GO2/GH2)propellants. Sixof the22-Nthrust classoperation upto 2200 ""C. ""Fnelarge thermalmargin rockets were coated withmonolithiclayers of eitherallows thereduction or elimination of fuel film cooling, HfO2or ZrO2and tested frommixture ratio (MR)4 towhile still exceedingthe lifeof silicide-coatedniobium 11. Aseventh/r/Re rocket hada composite coating(R512E/C103) rockets. Amaterial systemcomposedof consistingof Ir and anoxide. This chamber wastestedâ€¢ a rhenium (Re) substrate(for high temperature& fromMR 4 to 16, including over 29 minutes at MR",1995,
Development and Validation of an Empiric Tool to Predict Favorable Neurologic Outcomes Among PICU Patients*,"Objectives: To create a novel tool to predict favorable neurologic outcomes during ICU stay among children with critical illness. Design: Logistic regression models using adaptive lasso methodology were used to identify independent factors associated with favorable neurologic outcomes. A mixed effects logistic regression model was used to create the final prediction model including all predictors selected from the lasso model. Model validation was performed using a 10-fold internal cross-validation approach. Setting: Virtual Pediatric Systems (VPS, LLC, Los Angeles, CA) database. Patients: Patients less than 18 years old admitted to one of the participating ICUs in the Virtual Pediatric Systems database were included (2009â€“2015). Interventions: None. Measurements and Main Results: A total of 160,570 patients from 90 hospitals qualified for inclusion. Of these, 1,675 patients (1.04%) were associated with a decline in Pediatric Cerebral Performance Category scale by at least 2 between ICU admission and ICU discharge (unfavorable neurologic outcome). The independent factors associated with unfavorable neurologic outcome included higher weight at ICU admission, higher Pediatric Index of Morality-2 score at ICU admission, cardiac arrest, stroke, seizures, head/nonhead trauma, use of conventional mechanical ventilation and high-frequency oscillatory ventilation, prolonged hospital length of ICU stay, and prolonged use of mechanical ventilation. The presence of chromosomal anomaly, cardiac surgery, and utilization of nitric oxide were associated with favorable neurologic outcome. The final online prediction tool can be accessed at https://soipredictiontool.shinyapps.io/GNOScore/. Our model predicted 139,688 patients with favorable neurologic outcomes in an internal validation sample when the observed number of patients with favorable neurologic outcomes was among 139,591 patients. The area under the receiver operating curve for the validation model was 0.90. Conclusions: This proposed prediction tool encompasses 20 risk factors into one probability to predict favorable neurologic outcome during ICU stay among children with critical illness. Future studies should seek external validation and improved discrimination of this prediction tool.",2018,Critical Care Medicine
Deep learning applied to glacier evolution modelling,"We present a parameterized glacier evolution model, with a :::: novel :::::::: approach ::: to ::::::: simulate :::: and :::::::::: reconstruct :::::: annual :::::::::: glacier-wide : surface mass balance (SMB) component :::: series : based on a deep artificial neural network (i.e. deep learning). :::: This :::::: method :::: has :::: been :::::::: included ::: as ::: the ::::: SMB ::::::::: component ::: of ::: an :::::::::: open-source :::::::: regional :::::: glacier :::::::: evolution :::::: model. : While most glacier models tend to incorporate more and more physical processes, here we take an alternative approach by creating a parameterized model based on data science. Annual glacier-wide SMBs can be simulated :::: from ::::::::::: topo-climatic ::::::::: predictors using 5 either deep learning or Lasso (regularized multilinear regression), whereas the glacier geometry is updated using a glacierspecific parameterization. We compare and cross-validate our nonlinear deep learning SMB model against other standard linear statistical methods on a dataset of 32 French alpine glaciers. Deep learning is found to outperform linear methods, with improved explained variance (up to +64% in space and +108% in time) and accuracy (up to +47% in space and +58% in time), resulting in an estimated r of 0.77 and RMSE of 0.51 m.w.e. Substantial nonlinear structures are captured by deep learning, 10 with around 35% of nonlinear behaviour in the temporal dimension. For the glacier geometry evolution, the main uncertainties come from the ice thickness data used to initialize the model. These results should encourage the use of deep learning in glacier modelling as a powerful nonlinear tool, capable of capturing the nonlinearities of the climate and glacier systems, that can serve to reconstruct or simulate SMB time series for individual glaciers at regional scale :: in : a :::::: whole ::::: region : for past and future climates. 15",2019,
"Cenomanian â€“ Turonain Foraminifera and Palynomorphs from the Calabar Flank, South Eastern Nigerian: Implications for Age and Depositional Environment","One of the most spectacular signatures of global â€œOceanic Anoxic Eventsâ€ (OAEs) of the Cretaceous was deposited at the Cenomanianâ€“Turonian Boundary. This global oceanic anoxic event is also referred to as Cenomanianâ€“Turonian Boundary Event (CTBE). This event is marked by the deposition of finely laminated organic carbon rich sediments deposited under oxygen depleted conditions. The main goal of the present research is to get a better understanding of the marine biota characterizing the oceanic anoxic event in the Calabar Flank. Core samples obtained from two (2) study wells in the Calabar Flank, southeastern Nigeria were utilized for this study and standard biostratigraphic sample preparation/ separation and analytical approaches were applied in the course of the study. The Cenomanian â€“ Turonian age was assigned based on age diagnostic foraminifera (Hedbergella crassa, Heterohelix moremani, Heterohelix planata, Heterohelix reussi, Hedbergella delrioensis, Hedbergella planispira) and age diagnostic palynomorphs (Steevesipollenites binodosus, Ephedripites sp, Leiotriletes sp, Classopollis sp, Classopollis classoides, Classopollis annulatus, Ephedripites jansonii, Cretacaeiporites mulleri, Cretacaeiporites polygonalis, Galeacornea clavis and Triorites africaensis). The sediments of the study wells were deposited in a range of environments from non-marine to mid neritic and the recovered foraminifera are characterized by the presence of abundant but dwarfed planktic forms and low diversity of dwarfed arenaceous forms at some intervals which strongly support deposition in an oxygen depleted environment.",2018,
Structure-based learning in wireless networks via sparse approximation,"A novel framework for the online learning of expected cost-to-go functions characterizing wireless networks performance is proposed. The framework is based on the observation that wireless protocols induce structured and correlated behavior of the finite state machine (FSM) modeling the operations of the network. As a result, a significant dimension reduction can be achieved by projecting the cost-to-go function on a graph wavelet basis set capturing typical sub-structures in the graph associated with the FSM. Sparse approximation with random projection is then used to identify a concise set of coefficients representing the cost-to-go function in the wavelet domain. This Compressed Sensing (CS) approach enables a considerable reduction in the number of observations needed to achieve an accurate estimate of the cost-to-go function. The proposed method is characterized via stability analysis. In particular, we prove that the standard CS approach of the Least Angle Selection and Shrinkage Operator (LASSO) will not provide stability. We also determine a connection between the structure of the FSM induced by the wireless protocols and the restricted isometry property of the effective projection matrix. Simulation results of our approximation method show that 15 wavelet functions can accurately represent a cost-to-go function defined on a state space of 2000 states. Moreover, the number of state-cost observations needed to estimate the cost-to-go function is orders of magnitude smaller than that required by traditional online learning techniques.",2012,EURASIP Journal on Wireless Communications and Networking
Disaster Management for Libraries and Archives,"Contents: Disaster management for libraries and archives - an introduction, Graham Matthews The disaster control plan, Heather Mansell Risk management, Alice Cannon In case of fire, Bill Jackson Flood prevention and recovery, Christine Wise Cooperative activity in the USA, or misery loves company, Sheryl Davis and Kristen Kern Psychological aspects of disaster management, Maj Klasson The Croatian experience 1991-1995, Kornelija Petr Aftermath - service continuity and recovery, John Creber A guide to sources of information, Graham Matthews Index.",2003,
Stigma as a barrier to health care utilization among female sex workers and men who have sex with men in Burkina Faso.,"PURPOSE
The aim of this study is to examine the prevalence and correlates of perceived health care stigma among female sex workers (FSWs) and men who have sex with men (MSM), including other stigma types, suicidal ideation, and participation in social activities.


METHODS
FSWs (NÂ = 350) and MSM (NÂ = 330) aged â‰¥18 were recruited in Bobo-Dioulasso, Burkina Faso. Perceived health care stigma was defined as either ever being afraid of or avoiding health care services because someone might find out the participant has sex with men (for MSM) or sells sex (for FSW). Correlates of perceived health care stigma were examined using multivariable logistic regression.


RESULTS
The prevalence of perceived health care stigma was 14.9% (52/350) and 24.5% (81/330) in FSWs and MSM, respectively. Among FSWs, experienced or social stigma, including verbal harassment (adjusted odds ratio [aOR]Â = 3.59, 95% confidence interval [CI] 1.48-8.71), feeling rejected by friends (aORÂ = 2.30, 95% CI 1.14-4.64), and feeling police refused to protect them (aORÂ = 2.58, 95% CI 1.27-5.25), was associated with perceived health care stigma. Among MSM, experiencing verbal harassment (aORÂ =Â 1.95, 95% CI 1.09-3.50) and feeling scared to walk in public (aORÂ = 2.93, 95% CI 1.47-5.86) were associated with perceived health care stigma.


CONCLUSIONS
In these key populations, perceived health care stigma was prevalent and associated with experienced and social stigmas. To increase coverage of effective HIV services, interventions should incorporate approaches to comprehensively mitigate stigma.",2018,Annals of epidemiology
Hypertension: A Companion to Brenner and Rector's The Kidney,"Oparil S, Weber MA, eds. 784 pages. Philadelphia: WB Saunders; 2000. $95.00. ISBN 0721677649. Order phone 800-545-2522. Field of medicine: Cardiovascular diseases, nephrology, and endocrinology. Format: Hardcover book. Audience: Physicians and trainees in internal medicine, cardiology, hypertension, vascular medicine, and nephrology. Purpose: To provide a comprehensive reference on the pathophysiology, epidemiology, consequences, and clinical management of essential and secondary hypertension. Content: The book provides in-depth coverage of the pathophysiology of, risk factors for, and epidemiology of hypertension; the mechanisms of action of antihypertensive drugs; and management of diseases associated with hypertension. It also offers a concise summary of recent clinical trials. Highlights: The sections on the pathophysiology and pharmacology of antihypertensive agents are especially detailed, and the material is presented in a concise and readable format. The editors have wisely included a chapter on chronotherapeutics in the treatment of hypertension. Chapters on the plethora of recently completed and ongoing clinical trials in the field are particularly welcome. Numerous tables, algorithms, and figures supplement the text. Limitations: The emphasis of this textbook is primary hypertension, and the section on the clinical aspects of secondary forms of hypertension is somewhat superficial. The chapter on management of hypertensive crisis is only 4 pages in length. A chapter covering target organ pathology in greater detail should have been included. The index is not sufficiently detailed. Related reading: Numerous textbooks of internal medicine, cardiology, endocrinology, and nephrology discuss hypertension in depth. Examples include Wilson and colleagues' Williams Textbook of Endocrinology (WB Saunders, 1998), Braunwald's Heart Disease: A Textbook of Cardiovascular Medicine (WB Saunders, 1996), Brenner and Rector's The Kidney (WB Saunders, 1995), and Massry & Glassock's Textbook of Nephrology (Lippincott, Williams & Wilkins, 1995). Laragh and Brenner'sHypertension: Pathophysiology, Diagnosis, and Management (Raven, 1995) is a two-volume treatise. Messerli's Cardiovascular Drug Therapy (WB Saunders, 1996) covers antihypertensive agents. The strengths of Oparil and Weber's text are its detailed treatment of primary hypertension and its manageable size. Reviewer: Gerald Schulman, MD, Vanderbilt University Medical Center, Nashville, Tennessee.",2000,Annals of Internal Medicine
Maritime Indian Ocean Routes: the port of Gwadar/GwÄtar,"Fra le principali rotte dellâ€™Oceano Indiano â€ sia m arittime sia terrestri â€ Gwadar, divisa nella seconda meta del X IX secolo dalla Commissione Britannica per le Frontiere fra la baia orientale persiana di Gw Ätar e quella occidentale di Gwadar, rappresento una delle principali vie di comunicazione tra il Medio Oriente ed il Subcontinente Indiano, giocando un ruolo strategico ne l commercio di schiavi, avorio, datteri e spezie dallâ€™Africa orien tale e dalla Penisola araba verso lâ€™Asia centrale e viceversa. Tanto GwÄtar quando Gwadar, sulla regione costiera del MakrÄn, sono state definite scientificamente terra incognita . History long the shores of the Western Indian Ocean, trade relations between the people of the Asian, Arabian and East African coasts were innumerable and deeply intelinked. Such links and relationships of trade a nd power were to be sought in those elements that constituted the close equilibrium of the Indian Ocean, that is, in the monsoons, in the pres ence of commercial thalassocracies (the well known â€˜merchant-statesâ€™), in the predominance of mercantile laws, and in the trade r outes of spices, ivory and slaves. Starting from the sixteenth centu ry onwards, the European desires for conquest of commercial monopolies in the slave A",2013,
Comparison of different variable selection methods for partial least squares soft sensor development,"Data-driven soft sensors have been widely used in both academic research and industrial applications for predicting hard-to-measure variables or replacing physical sensors to reduce cost. It has been shown that the performance of these data-driven soft sensors can be greatly improved by selecting only the vital variables that strongly affect the primary variables, rather than using all the available process variables. In this work, a comprehensive evaluation of different variable selection methods for soft sensor development is presented. The following seven variable selection methods are considered: stepwise regression (SR), partial least squares with regression coefficients (PLS-BETA), PLS with variable importance in projection (PLS-VIP), uninformative variable elimination with PLS (UVE-PLS), genetic algorithm with PLS (GA-PLS), least absolute shrinkage and selection operator (Lasso), and competitive adaptive reweighted sampling with PLS (CARS-PLS). Their strengths and limitations for soft sensor development are examined using a simulated case study and an industrial case study. Independent tuning datasets are used to optimize each method and to analyze the sensitivity of each method to its tuning parameters. Then independent test datasets are used to compare the prediction performances of PLS soft sensors developed based on different variable selection methods.",2014,2014 American Control Conference
Methylation Biomarker Panel Performance in EsophaCap Cytology Samples for Diagnosing Barrett's Esophagus: A Prospective Validation Study.,"PURPOSE
Barrett's esophagus is the only known precursor of esophageal adenocarcinoma (EAC). Although endoscopy and biopsy are standard methods for Barrett's esophagus diagnosis, their high cost and risk limit their use as a screening modality. Here, we sought to develop a Barrett's esophagus detection method based on methylation status in cytology samples captured by EsophaCap using a streamlined sensitive technique, methylation on beads (MOB).


EXPERIMENTAL DESIGN
We conducted a prospective cohort study on 80 patients (52 in the training set; 28 in the test set). We used MOB to extract and bisulfite-convert DNA, followed by quantitative methylation-specific PCR to assess methylation levels of 8 previously selected candidate markers. Lasso regression was applied to establish a prediction model in the training set, which was then tested on the independent test set.


RESULTS
In the training set, five of eight candidate methylation biomarkers (p16, HPP1, NELL1, TAC1, and AKAP12) were significantly higher in Barrett's esophagus patients than in controls. We built a four-biomarker-plus-age lasso regression model for Barrett's esophagus diagnosis. The AUC was 0.894, with sensitivity 94.4% [95% confidence interval (CI), 71%-99%] and specificity 62.2% (95% CI, 44.6%-77.3%) in the training set. This model also performed with high accuracy for Barrett's esophagus diagnosis in an independent test set: AUC = 0.929 (P < 0.001; 95% CI, 0.810%-1%), with sensitivity=78.6% (95% CI, 48.8%-94.3%) and specificity = 92.8% (95% CI, 64.1%-99.6%).


CONCLUSIONS
EsophaCap, in combination with an epigenetic biomarker panel and the MOB method, is a promising, well-tolerated, low-cost esophageal sampling strategy for Barrett's esophagus diagnosis. This approach merits further prospective studies in larger populations.",2019,Clinical cancer research : an official journal of the American Association for Cancer Research
"Chapter 8 Entangled Proteins : Knots , Slipknots , Links , and Lassos","In recent years the studies of entangled proteins have grown into thewhole new, interdisciplinary and rapidly developing field of research. Here we present various types of entangled proteins studied within this field, which form knots, slipknots, links, and lassos.Wediscuss their geometric features and indicatewhat biological and physical role the entanglement plays. We also discuss mathematical tools necessary to analyze such structures and present databases and servers assembling information about entangled proteins: KnotProt, LinkProt, and LassoProt.",2018,
College of Arts and Sciences Theories on Group Variable Selection in Multivariate Regression Models Table of Contents,"We study group variable selection on multivariate regression model. Group variable selection is selecting the non-zero rows of coefficient matrix, since there are multiple response variables and thus if one predictor is irrelevant to estimation then the corresponding row must be zero. In a high dimensional setup, shrinkage estimation methods are applicable and guarantee smaller MSE than OLS according to James-Stein phenomenon (1961). As one of shrinkage methods, we study penalized least square estimation for a group variable selection. Among them, we study L0 regularization and L0 + L2 regularization with the purpose of obtaining accurate prediction and consistent feature selection, and use the corresponding computational procedure Hard TISP and Hard-Ridge TISP (She, 2009) to solve the numerical difficulties. These regularization methods show better performance both on prediction and selection than Lasso (L1 regularization), which is one of popular penalized least square method. L0 acheives the same optimal rate of prediction loss and estimation loss as Lasso, but it requires no restriction on design matrix or sparsity for controlling the prediction error and a relaxed condition than Lasso for controlling the estimation error. Also, for selection consistency, it requires much relaxed incoherence condition, which is correlation between the relevant subset and irrelevant subset of predictors. Therefore L0 can work better than Lasso both on prediction and sparsity recovery, in practical cases such that collinearity is high or sparsity is not low. We study another method, L0 + L2 regularization which uses the combined penalty of L0 and L2. For the corresponding procedure Hard-Ridge TISP, two parameter work independently for selection and shrinkage (to enhance prediction) respectively, and therefore it gives better performance on some cases (such as low signal strength) than L0 regularization. For L0 regularization, Î» works for selection but it is tuned in terms of prediction accuracy. L0 + L2 regularization gives the optimal rate of prediction and estimation errors without any restriction, when the coefficient of l2 penalty is appropriately assigned. Furthermore, it can achieve a better rate of estimation error with an ideal choice of block-wise weight to l2 penalty.",2013,
Adaptive Inverse Optimal Control of Stochastic Nonlinear Systems with Uncertain Wiener Noises,"The solvable theorem of adaptive inverse optimal control problems for a classof stochastic nonlinear systems with uncertain Wiener noises and constant unknown param-eters is studied.The systems are depicted by stochastic differential equations.By usingbackstepping algorithms and stochastic control Lyapunov functions,a designing procedureof control laws of global asymptotic stability in probability and adaptive inverse optimalstabilization in probability are presented systematically.Adaptive control laws and updatelaws can be obtained at the same time by this design scheme.Results of simulation showthe effectiveness of the control algorithms.",2004,Acta Automatica Sinica
Sparse conditional logistic regression for analyzing large-scale matched data from epidemiological studies: a simple algorithm,"This paper considers the problem of estimation and variable selection for large high-dimensional data (high number of predictors p and large sample size N, without excluding the possibility that N < p) resulting from an individually matched case-control study. We develop a simple algorithm for the adaptation of the Lasso and related methods to the conditional logistic regression model. Our proposal relies on the simplification of the calculations involved in the likelihood function. Then, the proposed algorithm iteratively solves reweighted Lasso problems using cyclical coordinate descent, computed along a regularization path. This method can handle large problems and deal with sparse features efficiently. We discuss benefits and drawbacks with respect to the existing available implementations. We also illustrate the interest and use of these techniques on a pharmacoepidemiological study of medication use and traffic safety.",2015,BMC Bioinformatics
Favorable effect of pulmonic vein isolation by partial circumferential ablation on ostial flow velocity.,"OBJECTIVES
The aim of this study was to determine the effect of electrical isolation of pulmonic vein (PV) on flow velocity.


BACKGROUND
We report our experience with electrical isolation of PV by partial circumferential ablation and its effect on ostial peak flow velocity as assessed by phased-array ultrasound catheter imaging.


METHODS
Sixty-two patients participated in the study. Magnetic electroanatomic mapping, ultrasound catheter imaging, and Lasso mapping catheter were used. Electrical isolation was achieved by delivering radiofrequency ablation (RFA) lesions proximal to Lasso mapping catheter bipoles showing PV entry. Following this, the number of RFA lesions/PV and their segment-wise distribution (maximum 4/PV) were assessed.


RESULTS
Fifty right superior, 51 left superior, 32 left inferior, and 17 right inferior PVs were isolated. RFA involved 4 segments in 42 PVs, 3 segments in 61 PVs, and </=2 segments in 47 PVs. Electrical isolation augmented ostial peak flow velocity (55 +/- 15 cm/s to 96 +/- 26 cm/s). This net increase was higher for superior versus inferior PVs (43 +/- 23 cm/s and 34 +/- 18 cm/s; P = .02). For </=2, 3, and 4 segments ablated per vein, the net increase in peak flow velocity was 33 +/- 22 cm/s, 42 +/- 23 cm/s, and 46 +/- 23 cm/s, respectively (P = .02). Over a mean follow-up of 16 +/- 7 months, freedom from atrial fibrillation (AF) or >90% reduction in AF burden, either with or without previously ineffective antiarrhythmic agents, was achieved in 54 patients (87%).


CONCLUSIONS
In the majority of PVs (72%), electrical isolation can be achieved by partial circumferential ablation (targeting </=3 segments/PV) with lower acute increase in ostial peak flow velocity and good AF control.",2004,Heart rhythm
The glaucoma-associated olfactomedin domain of myocilin forms polymorphic fibrils that are constrained by partial unfolding and peptide sequence.,"The glaucoma-associated olfactomedin domain of myocilin (myoc-OLF) is a recent addition to the growing list of disease-associated amyloidogenic proteins. Inherited, disease-causing myocilin variants aggregate intracellularly instead of being secreted to the trabecular meshwork, which is a scenario toxic to trabecular meshwork cells and leads to early onset of ocular hypertension, the major risk factor for glaucoma. Here we systematically structurally and biophysically dissected myoc-OLF to better understand its amyloidogenesis. Under mildly destabilizing conditions, wild-type myoc-OLF adopts non-native structures that readily fibrillize when incubated at a temperature just below the transition for tertiary unfolding. With buffers at physiological pH, two main endpoint fibril morphologies are observed: (a) straight fibrils common to many amyloids and (b) unique micron-length, ~300 nm or larger diameter, species that lasso oligomers, which also exhibit classical spectroscopic amyloid signatures. Three disease-causing variants investigated herein exhibit non-native tertiary structures under physiological conditions, leading to a variety of growth rates and a fibril morphologies. In particular, the well-documented D380A variant, which lacks calcium, forms large circular fibrils. Two amyloid-forming peptide stretches have been identified, one for each of the main fibril morphologies observed. Our study places myoc-OLF within the larger landscape of the amylome and provides insight into the diversity of myoc-OLF aggregation that plays a role in glaucoma pathogenesis.",2014,Journal of molecular biology
News and Comments,"New Members, New Officersfor SpeciaJJy Councils The Boardof Pharmaceutical Specialties(BPS) has announcedthat Philip R. Diaz, Pharm.D; BCPS,and KathleenA. Stringer,Pharm.D; BCPS,have been appointedto the BPS SpecialtyCouncilon Pharmacotherapy by the AmericanCollegeof ClinicalPharmacy(ACCP), to succeed Peter Gal, Pharm.D.,and Peter Vlasses,Pharm.D.Diaz is clinicalassistantprofessor, Schoolof Pharmacy,Universityof North Carolina,Chapel Hill. He is also associatedirectorof PharmacyEducation,GreensboroArea HealthEducation Center.Stringeris assistantprofessor,School of Pharmacy, University of Colorado,Denver,and is a memberof The Annals CardiologySpecialty panel.Other membersof the SpecialtyCouncil includeJohn A. Bosso, Pharm.D; George E. Dukes, Pharm.D; Thomas C. Hardin,Pharm.D; WilliamA. Miller,Pharm.D; John Ogden, Philip1. Schneider,M.S.,and BarbaraJ. Zarowitz,Pharm.D, Thomas C. Hardin, Pharm.D; BCPS, has been electedchair of the Specialty Councilon Pharmacotherapy for 1993-94. Hardin is clinicalcoordinator and specialconsultantto the chief, PharmacyService,Audie L. Murphy MemorialVeterans' Hospital,San Antonio,TX, and clinicalassociateprofessor,Collegeof Pharmacy,Universityof Texas, Austin. The BPS SpecialtyCouncil on Nuclear Pharmacyelected ElaineLevine, BCNP, as chair for 1993-94 and Nicki L. Hilliard,Pharm.D; BCNP, as vice chair for the same period. Levine is a nuclearpharmacistat the Vanderbilt UniversityMedicalCenter, Nashville,TN. Hilliard is assistantprofessorof NuclearPharmacy,Universityof Arkansas,Collegeof Pharmacy,Little Rock,AR.",1993,Annals of Pharmacotherapy
Fast Bayesian Lasso for High-Dimensional Regression,"The lasso (Tibshirani, 1996) is an essential tool in modern high-dimensional regression and variable selection. The Bayesian lasso of Park and Casella (2008) interprets the lasso objective function as a posterior under a Laplace prior and proposes a three-step Gibbs sampler to sample from this posterior. The Bayesian lasso yields a natural approach to quantifying the uncertainty of lasso estimates. Furthermore, the Gibbs sampler for the Bayesian lasso has been shown to be geometrically ergodic (Khare and Hobert, 2013). The geometric rate constant of this Markov chain, however, tends to 1 if the number of regression coefficients grows faster than the sample size (Rajaratnam and Sparks, 2015). Thus, convergence of the Bayesian lasso Gibbs sampler can still be quite slow in modern high-dimensional settings despite the apparent theoretical safeguard of geometric ergodicity. In order to address this challenge, we propose a new method to draw from the same posterior via a tractable two-step blocked Gibbs sampler, which we call the fast Bayesian lasso. We provide a theoretical underpinning to the new method by proving rigorously that the fast Bayesian lasso is geometrically ergodic. We then demonstrate numerically that this blocked sampler exhibits vastly superior convergence behavior in high-dimensional regimes.",2015,arXiv: Methodology
Bayesian Randomized Response Technique,"When sensitive attributes are investigated, Randomized Response Technique (RRT) is a popular approach to reduce the bias arisen from untruthful response. Nonetheless, traditional RRT has weakness that it mainly focuses on estimating the moments of univariate random variables but not dependence among multiple random variables. This paper is to introduce a new method to estimate the covariance matrix of random vectors under the framework of RRT. Modified Cholesky decomposition is applied to reparameterize the covariance matrix so that the parameters of the covariance matrix can be expressed as regression on a row-by-row basis. This simplifies the structure of the matrix and ensures the positive definiteness of the estimator. To keep inference nonparametric, moment equations of the randomized realizations are adopted as the quasi-likelihood. Moreover, Bayesian lasso is applied to impose shrinkage effect in estimation. This helps reduce estimation error when the covariance matrix is sparse. An easy-to-implement Gibbs sampling scheme is proposed for the inference. A simulation study is conducted to evaluate the accuracy of estimation. An empirical study related to software piracy behavior is conducted to compare the difference of the estimates under randomized and non-randomized settings.",2012,
The use of plasma surface-enhanced laser desorption/ionization time-of-flight mass spectrometry proteomic patterns for detection of head and neck squamous cell cancers.,"PURPOSE
Our study was undertaken to determine the utility of plasma proteomic profiling using surface-enhanced laser desorption/ionization time-of-flight (SELDI-TOF) mass spectrometry for the detection of head and neck squamous cell carcinomas (HNSCCs).


EXPERIMENTAL DESIGN
Pretreatment plasma samples from HNSCC patients or controls without known neoplastic disease were analyzed on the Protein Biology System IIc SELDI-TOF mass spectrometer (Ciphergen Biosystems, Fremont, CA). Proteomic spectra of mass:charge ratio (m/z) were generated by the application of plasma to immobilized metal-affinity-capture (IMAC) ProteinChip arrays activated with copper. A total of 37356 data points were generated for each sample. A training set of spectra from 56 cancer patients and 52 controls were applied to the ""Lasso"" technique to identify protein profiles that can distinguish cancer from noncancer, and cross-validation was used to determine test errors in this training set. The discovery pattern was then used to classify a separate masked test set of 57 cancer and 52 controls. In total, we analyzed the proteomic spectra of 113 cancer patients and 104 controls.


RESULTS
The Lasso approach identified 65 significant data points for the discrimination of normal from cancer profiles. The discriminatory pattern correctly identified 39 of 57 HNSCC patients and 40 of 52 noncancer controls in the masked test set. These results yielded a sensitivity of 68% and specificity of 73%. Subgroup analyses in the test set of four different demographic factors (age, gender, and cigarette and alcohol use) that can potentially confound the interpretation of the results suggest that this model tended to overpredict cancer in control smokers.


CONCLUSIONS
Plasma proteomic profiling with SELDI-TOF mass spectrometry provides moderate sensitivity and specificity in discriminating HNSCC. Further improvement and validation of this approach is needed to determine its usefulness in screening for this disease.",2004,Clinical cancer research : an official journal of the American Association for Cancer Research
Pathologisches GlÃ¼cksspiel,"ZusammenfassungSuchtmittelverlangen, das unwiderstehliche BedÃ¼rfnis nach Drogeneinnahme, wird wieder verstÃ¤rkt als zentrales Konstrukt zur ErklÃ¤rung abhÃ¤ngigen Verhaltens und damit von RÃ¼ckfÃ¤llen, bisher jedoch v.Â a. bei stoffgebundener Sucht, diskutiert. Ziel ist es, in Anlehnung an lerntheoretische ErklÃ¤rungsansÃ¤tze zur Suchtentstehung das reizinduzierte Verlangen nach dem GlÃ¼cksspiel und psychologische Variablen, die dieses beeinflussen, erstmalig auch bei einer pathologischen und exzessiven, belohnenden Verhaltensweise mit standardisierten visuellen Reizen zu untersuchen. Im Rahmen des Reiz-Reaktions-Paradigmas werden pathologische GlÃ¼cksspieler und Kontrollpersonen mit glÃ¼cksspielrelevanten Reizen sowie Vergleichsreizen konfrontiert und die emotionale Reizverarbeitung, das reizinduzierte Verlangen und der Einfluss von Stress, Ã„ngstlichkeit und DepressivitÃ¤t auf das Verlangen nach dem GlÃ¼cksspiel untersucht. Die Ergebnisse zeigen eine stÃ¶rungsspezifisch verÃ¤nderte Verarbeitung von glÃ¼cksspielassoziierten Reizen bei pathologischen Spielern auch nach jahrelanger Abstinenz und ein in AbhÃ¤ngigkeit von psychischer BeeintrÃ¤chtigung erhÃ¶htes GlÃ¼cksspielverlangen. Die Ergebnisse werden hinsichtlich der Analogien zu den Befunden bei AbhÃ¤ngigkeit von psychotropen Substanzen diskutiert.AbstractDrug craving, the irresistible urge for drug intake, is being discussed as a central construct for the explanation of addictive behaviour and for relapses so far only in substance-related addiction. Based on learning models for the maintenance of addiction, in this study, cue-induced craving and psychological variables that influence craving were investigated in subjects with excessive rewarding behaviour such as pathological gambling. Based on the cue-reactivity paradigm, pathological gamblers and healthy controls were exposed to gambling and other cues. Emotional processing of the gambling cues, cue-induced craving, and the influence on craving of depression, anxiety, and stress-coping strategies were investigated. The results demonstrate disorder-specific processing of cues in pathological gamblers, even after abstinence for more than a year. In addition, craving is influenced by psychological disabilities. Data are discussed with respect to comparable data in studies about substance-related addicts.",2004,Der Nervenarzt
Bayesian variable selection and estimation in maximum entropy quantile regression,"ABSTRACT Quantile regression has gained increasing popularity as it provides richer information than the regular mean regression, and variable selection plays an important role in the quantile regression model building process, as it improves the prediction accuracy by choosing an appropriate subset of regression predictors. Unlike the traditional quantile regression, we consider the quantile as an unknown parameter and estimate it jointly with other regression coefficients. In particular, we adopt the Bayesian adaptive Lasso for the maximum entropy quantile regression. A flat prior is chosen for the quantile parameter due to the lack of information on it. The proposed method not only addresses the problem about which quantile would be the most probable one among all the candidates, but also reflects the inner relationship of the data through the estimated quantile. We develop an efficient Gibbs sampler algorithm and show that the performance of our proposed method is superior than the Bayesian adaptive Lasso and Bayesian Lasso through simulation studies and a real data analysis.",2017,Journal of Applied Statistics
Assiut Experience in the Application of Holmium Laser in Treatment of Ureteral Calculi in Adults,"Internal Optical Urethrotomy at the National Medical Center of Sanou Souro in Bobo-Dioulasso: Feasibility, Safety and Short-Term Results 
Objective To analyze the feasibility, safety and short-term results of internal optical urethrotomy in our hospital. Patients and Methods A retrospective study of 70 cases was done between January 1, 1994 and December 31st, 2000. Two principal aetiologies were pointed out: infectious strictures (68.6%) and traumatic strictures (12.9%). Results The procedure was successful in 73.7% of all cases with complications in 15.8% of the cases. The mortality rate was nil. The results were good in 67.3% at one month and in 44.2% after 4.5 months. Conclusion Internal optical urethrotomy in our medical context is feasible with few complications. Since urogenital infection is the predominant aetiology, the best management of urethral strictures is the prevention of such infections. Resume 
Objectif Le but de cette etude etait d'apprecier la faisabilite, l'innocuite et les resultats a court terme de l'uretrotomie interne endoscopique dans notre service. Patients et Methodes Une etude retro-spective de 70 cas couvrant la periode du 1er janvier 1994 au 31 decembre 2000 a ete faite. Deux etiologies principales furent degagees: Les retrecissements infectieux (68,9%) et les retrecissements traumatiques (12,9%). Resultats Le success de l'acte etait de 73,7% avec 15,8% de complications. La mortalite operatoire a ete nulle. A un mois la miction etait bonne dans 67,3% des cas et 44,2% au bout de 4,5 mois. Conclusion Cette methode est realisable dans notre contexte. Compte tenu de l'etiologie predominante qu'est l'infection urogenitale, le meilleur traitement est la prevention de ces infections. Key Words uretrotomie interne endoscopique, faisabilite, innocuite, Burkina Faso 
(African Journal of Urology: 2002 8 (4): 185-189)",2002,African Journal of Urology
Creating facial animation of characters via MoCap data,"We consider the problem of generating 3D facial animation of characters. An efficient procedure is realized by using the motion capture data (MoCap data), which is obtained by tracking the facial markers from an actor/actress. In some cases of artistic animation, the MoCap actor/actress and the 3D character facial animation show different expressions. For example, from the original facial MoCap data of speaking, a user would like to create the character facial animation of speaking with a smirk. In this paper, we propose a new easy-to-use system for making character facial animation via MoCap data. Our system is based on the interpolation: once the character facial expressions of the starting and the ending frames are given, the intermediate frames are automatically generated by information from the MoCap data. The interpolation procedure consists of three stages. First, the time axis of animation is divided into several intervals by the fused lasso signal approximator. In the second stage, we use the kernel k-means clustering to obtain control points. Finally, the interpolation is realized by using the control points. The user can easily create a wide variety of 3D character facial expressions by changing the control points.",2012,Journal of Applied Statistics
Reconstructing Valanginian (Early Cretaceous) mid-latitude vegetation and climate dynamics based on sporeâ€“pollen assemblages,"Abstract Changes in terrestrial vegetation patterns during the Valanginian (Early Cretaceous) and their link to major climatic and environmental alterations are poorly studied. In this study, the spatial and temporal changes in plant community structure are reconstructed based on sporeâ€“pollen records from two mid-latitude sites located in the Mid-Polish Trough (MPT, central Poland), and the Vocontian Basin (VB, southeast France). Stratigraphic control is provided by Î´ 13 C carb chemostratigraphy and calcareous nannofossil biostratigraphy. Reconstruction of hinterland vegetation is based on palynological investigations of 83 samples from hemipelagic (VB) and marginal marine (MPT) sediments rich in terrestrial palynomorphs. A total of 45 palynomorph taxa were identified at generic level (30 spores, 15 pollen). Vegetation around the MPT was dominated by araucarian/cupressacean conifers while that surrounding the VB was dominated by drought-resistant cheirolepidiacean conifers. At both sites the understorey and/or vegetation of open areas was dominated by pteridophytes. An early Valanginian gradual trend towards humid conditions at the MPT, well expressed by a distinct increase in the sporeâ€“pollen ratio, culminates in a short-lived spore-maximum stratigraphically located at the lower/upper Valanginian boundary. It is characterized by low conifer abundances and high abundances of the fern spore taxa Cyathidites , Leiotriletes and Gleicheniidites accompanied by enhanced abundances of the pteridosperm pollen Vitreisporites pallidus , whose parent plants are assumed to be indicative of swamp habitats. The spore-maximum is coeval to a similar peak observed in the VB, characterized by essentially the same taxa. Here, the spore-maximum is preceded by a protracted phase of arid conditions, characterized by low spore abundances and exceptionally high numbers of the cheirolepidiacean conifer pollen Classopollis . Changes in moisture, identified as the key climatic factor determining trends and turnovers in vegetation, were probably controlled by a monsoonal circulation. The supra-regional humid phase expressed by the coeval spore maxima was probably induced by an intensified monsoonal climate. The temporal influence of a northern hemisphere arid belt at the VB, under the influence of the subtropical high-pressure belt, may have caused the temporal drying not affecting the MPT site, located further north.",2013,Review of Palaeobotany and Palynology
Degasification of the earth,"Based on the constraints of the data of geology,geophysics,geochemistry,astrophysics,palaeoecology,we made research on degassing of the earth.The result shows: via the accretion,portion of cold matter of solar system formed the early earth.With the effect of that collision kinetic energy converted into heat energy,the surface of the early earth melted.On the condition of high temperature and high pressure,crystal water of the substance that composing the surface earth was released into the original atmosphere,and the carbonate,vitriol and halide decomposed,the carbon dioxide,sulfureted hydrogen,sulfur dioxide,hydrogen chloride,hydrogen fluoride were released into the atmosphere,too.All these gases composed the original atmosphere.With effect of geopotential and radiation energy,when the interior of the earth continued to melt,the surface of the earth solidified to form the original lithosphere.Afterward,except the surface original lithosphere,all the earth melted completely.The gases,such as the vapor and carbon dioxide that resulted from the melting of the interior substance of the earth,were enclosed by the lithosphere.Only when the glacier formation and melting,the epeirogenesis and the thalassogenesis occurred,then the volcano and earthquake occurred,these gases could be released out of the surface of the earth.These degassing is influenced by many factor,such as the melting condition of the interior of the earth,the position of the glacier formation(in ocean or in land),biotic evolvement,the intensity of the sunshine.",2006,
Robust Lasso With Missing and Grossly Corrupted Observations,"This paper studies the problem of accurately recovering a <formula formulatype=""inline""><tex Notation=""TeX"">$k$</tex> </formula>-sparse vector <formula formulatype=""inline""><tex Notation=""TeX"">$\beta^{\star}\in\BBR^{p}$</tex> </formula> from highly corrupted linear measurements <formula formulatype=""inline""><tex Notation=""TeX"">$y=X\beta^{\star}+e^{\star}+w$</tex> </formula>, where <formula formulatype=""inline""> <tex Notation=""TeX"">$e^{\star}\in\BBR^{n}$</tex></formula> is a sparse error vector whose nonzero entries may be unbounded and <formula formulatype=""inline""><tex Notation=""TeX"">$w$</tex></formula> is a stochastic noise term. We propose a so-called extended Lasso optimization which takes into consideration sparse prior information of both <formula formulatype=""inline""><tex Notation=""TeX"">$\beta^{\star}$</tex> </formula> and <formula formulatype=""inline""> <tex Notation=""TeX"">$e^{\star}$</tex></formula>. Our first result shows that the extended Lasso can faithfully recover both the regression as well as the corruption vector. Our analysis relies on the notion of extended restricted eigenvalue for the design matrix <formula formulatype=""inline""><tex Notation=""TeX"">$X$</tex></formula>. Our second set of results applies to a general class of Gaussian design matrix <formula formulatype=""inline""><tex Notation=""TeX"">$X$</tex> </formula> with i.i.d. rows <formula formulatype=""inline""><tex Notation=""TeX"">${\cal N}(0,\Sigma)$</tex></formula>, for which we can establish a surprising result: the extended Lasso can recover exact signed supports of both <formula formulatype=""inline""> <tex Notation=""TeX"">$\beta^{\star}$</tex></formula> and <formula formulatype=""inline""><tex Notation=""TeX"">$e^{\star}$</tex> </formula> from only <formula formulatype=""inline""> <tex Notation=""TeX"">$\Omega(k\log p\log n)$</tex></formula> observations, even when a linear fraction of observations is grossly corrupted. Our analysis also shows that this amount of observations required to achieve exact signed support is indeed optimal.",2013,IEEE Transactions on Information Theory
SEP-QN: Scalable and Extensible Proximal Quasi-Newton Method for Dirty Statistical Models,"We develop a generalized proximal quasi-Newton method for handling ""dirty"" statistical models where multiple structural constraints are imposed. We consider a general class of M-estimators that minimize the sum of a smooth loss function and a hybrid regularization. We show that the generalized proximal quasi-Newton method inherits the superlinear convergence theoretically and empirically. By employing the smoothed conic dual approach with a quasi-LBFGS updating formula, we obtain a scalable and extensible proximal quasi-Newton (SEP-QN) method. Our method is potentially powerful because it can solve some popular ""dirty"" statistical models like the fused sparse group lasso with superlinear convergence rate.",2015,ArXiv
Parceria- Uma EstratÃ©giaparapromoÃ§Ã£o Da SaÃºde,"The focus is on the partnership experience of the NUCRON (Nucleus ps Studies on chronical conditions.) ACO (Ostomized Association of the State of Santa Catarina) and the PAO (Program of Ostomized Patient Care). The partnership has been in progress since 1989, period in wich four research projects were conduted. The main partnership purpose was to envolve the ostomized patientes in a process os discovering their own potentialities in order to transform the ACO in a powerfulAssociation. DESCRIPTORS: Health promotion. PARTNESHIP -ASTRATEGY FOR HEALTH PROMOTION",1996,
Build Sentiment Classification Prediction Model for O2O Service,"With the rapid development of information and communication technology, O2O (Online to Offline) business model has attracted lots of attentions for enterprises. In such a fast-growing environment, some studies indicated that lack of trust will bring a great damage to O2O business. Besides, some published works pointed out those negative comments in social communities will decrease the consumer's trust to O2O companies and platforms. So, it is necessary for enterprises to understand the important factors that affect consumers' sentiment of textual reviews. Therefore, this study aims to build prediction models by using Support Vector Machines Recursive Feature Elimination (SVM-RFE) and Least Absolute Shrinkage and Selection Operator (LASSO), respectively. We do not only attempt to build sentiment classification models, but also to find the important factors that affect the sentiments of comments. The findings can be references for O2O market enterprises to carefully answer customers' comments to improve customers' trust and service quality.",2017,
