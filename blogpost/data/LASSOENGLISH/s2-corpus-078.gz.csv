title,abstract,year,journal
Polar Operators for Structured Sparse Estimation,"Structured sparse estimation has become an important technique in many areas of data analysis. Unfortunately, these estimators normally create computational difficulties that entail sophisticated algorithms. Our first contribution is to uncover a rich class of structured sparse regularizers whose polar operator can be evaluated efficiently. With such an operator, a simple conditional gradient method can then be developed that, when combined with smoothing and local optimization, significantly reduces training time vs. the state of the art. We also demonstrate a new reduction of polar to proximal maps that enables more efficient latent fused lasso.",2013,
Re-Weighted ð“1 Algorithms within the Lagrange Duality Framework: Bringing Interpretability to Weights,"We consider an important problem in signal processing, which consists in finding the sparsest solution of a linear system $\Phi x=b$. This problem has applications in several areas, but is NP-hard in general. Usually an alternative convex problem is considered, based on minimizing the (weighted) $\ell_{1}$ norm. For this alternative to be useful, weights should be chosen as to obtain a solution of the original NP-hard problem. A well known algorithm for this is the Re-Weighted $\ell_{1}$, proposed by Candes, Wakin and Boyd. In this article we introduce a new methodology for updating the weights of a Re-Weighted $\ell_{1}$ algorithm, based on identifying these weights as Lagrange multipliers. This is then translated into an algorithm with performance comparable to the usual methodology, but allowing an interpretation of the weights as Lagrange multipliers. The methodology may also be used for a noisy linear system, obtaining in this case a Re-Weighted LASSO algorithm, with a promising performance according to the experimental results.",2019,ArXiv
How to lasso a plane gravitational wave,"Beginning with the stress-energy tensor of an elastic string this paper derives a relativistic string and its form in a parallel transported Fermi frame including its reduction to a Cosserat string in the Newtonian limit. In a Fermi frame gravitational curvature is seen to induce three dominant relative acceleration terms dependent on: position, velocity and position, strain and position, respectively. An example of a string arranged in an axially flowing ring (a lasso) is shown to have a set of natural frequencies that can be parametrically excited by a monochromatic plane gravitational wave. The lasso also exhibits, in common with spinning particles, oscillations about geodesic motion in proportion to spin magnitude and wave amplitude when the spin axis lies in the gravitational wave front.",2005,General Relativity and Gravitation
Explanatory and Causal Analysis of the MIBEL Electricity Market Spot Price,"This paper analyzes the electricity prices of the MIBEL electricity spot market with respect to a set of possible explanatory variables. Understanding the main drivers of the electricity price is a key aspect in understanding price formation and in developing forecasting models, which are essential for the selling and buying strategies of market agents. For this analysis, different techniques have been applied in this work, including standard and lasso regression models, causal analysis based on bayesian networks and classification trees. Results from the different approaches are coherent and show strong dependency of the electricity prices with the Portuguese imported coal for lower non-dispatchable net demands, which has been progressively replaced by gas for larger non-dispatchable net demands. Hydro reservoirs and hydro production are also main explanatory variables of the electricity price for all non-dispatchable net demand levels.",2019,2019 IEEE Milan PowerTech
A small review and further studies on the LASSO,"Abstract High-dimensional data analysis arises from almost all scienti c areas, evolving withdevelopment of computing skills, and has encouraged penalized estimations that playimportant roles in statistical learning. For the past years, various penalized estimationshave been developed, and the least absolute shrinkage and selection operator (LASSO)proposed by Tibshirani (1996) has shown outstanding ability, earning the rst place onthe development of penalized estimation. In this paper, we rst introduce a number ofrecent advances in high-dimensional data analysis using the LASSO. The topics includevarious statistical problems such as variable selection and grouped or structured variableselection under sparse high-dimensional linear regression models. Several unsupervisedlearning methods including inverse covariance matrix estimation are presented. In ad-dition, we address further studies on new applications which may establish a guidelineon how to use the LASSO for statistical challenges of high-dimensional data analysis.Keywords: High dimension, LASSO, penalized estimation, review.",2013,
Replicability of Machine Learning Models in the Social Sciences: A Case Study in Variable Selection,"Machine learning tools are increasingly used in social sciences and policy fields due to their increase in predictive accuracy. However, little research has been done on how well the models of machine learning methods replicate across samples. We compare machine learning methods with regression on the replicability of variable selection, along with predictive accuracy, using an empirical dataset as well as simulated data with additive, interaction, and non-linear squared terms added as predictors. Methods analyzed include support vector machines (SVM), random forests (RF), multivariate adaptive regression splines (MARS), and the regularized regression variants, least absolute shrinkage and selection operator (LASSO), and elastic net. In simulations with additive and linear interactions, machine learning methods performed similarly to regression in replicating predictors; they also performed mostly equal or below regression on measures of predictive accuracy. In simulations with square terms, machine learning methods SVM, RF, and MARS improved predictive accuracy and replicated predictors better than regression. Thus, in simulated datasets, the gap between machine learning methods and regression on predictive measures foreshadowed the gap in variable selection. In replications on the empirical dataset, however, improved prediction by machine learning methods was not accompanied by a visible improvement in replicability in variable selection. This disparity is explained by the overall explanatory power of the models. When predictors have small effects and noise predominates, improved global measures of prediction in a sample by machine learning methods may not lead to the robust selection of predictors; thus, in the presence of weak predictors and noise, regression remains a useful tool for model building and replication.",2018,Zeitschrift fÃ¼r Psychologie
2018 Abstract Booklet,"Snow White is a well-known 19th century fairy tale by the Grimm Brothers. What is not known to everyone is that Snow White and many of other Grimms' fairy tales that were first published in 1812 were not intended for children. This fairy tale is about a young girl named Snow White whose vain stepmother tries to kill her because she is more beautiful than her. On three different occasions an attempt on Snow White's life is made until she finally succumbs to a poisoned apple. Only upon arrival of a prince, the girl is resurrected back to life. To readers of the fairy tale and to those familiar with Disney's cartoon version, Snow White is an enchanted, charming story in which good overcomes the evil, and in which Snow White lives happily ever after with the prince, while the wrongdoing evil stepmother receives a punishment for her actions. However, to say that the fairy tale is simply about the themes of good and evil, and good prevailing, is not enough. In fact, a lot of questions come to mind: Why is the stepmother jealous of a child? Why does the tale emphasize characteristics of the protagonist such as innocence and beauty? Why does there need to be a prince at the end to rescue Snow White? This research analyzes the fairy tale's underlying sexual morality and tension, and what it tells us about the culture and society at the time it was published. Starting level of inter-cultural competency among undergraduates at MSU, Mankato Jonathon Arndt and Sean O'Rourke Elizabeth Sandell, Faculty Mentor, Educational Studies: Elementary and Early Childhood (Education) The U.S. Bureau of the Census estimates America's whites will become a minority in 2043. All in all, minorities, now 37 percent of the U.S. population, are projected to comprise 57 percent of the population in 2060. The total minority population would more than double, from 116.2 million to 241.3 million over the period.â€ (U.S. Bureau of the Census, 2016). As the population changes, everybody will need to become more inter-culturally competent, including MSU graduates. Therefore, this study examined the starting level of inter-cultural competency (ICC) among undergraduates at MSU, Mankato. According to Hammer & Bennett (2010), ICC is ""the capability to accurately understand and adapt behavior to cultural differences and commonality.â€ Cultural competency is â€œthe ability to communicate and behave in appropriate ways with those who are culturally different and to co-create shared spaces, teams, and organizations that are inclusive, effective, innovative, and satisfying.â€ This research analyzed pre-existing, archived data from about 800 MSU students enrolled in the course, Human Relations in a Multicultural Society (EEC222W). ICC was assessed by the Intercultural Development Inventory (Hammer & Bennett, 2010). Results indicated that individuals perceived they had a high level of intercultural competency. However, data showed that they actually had a relatively low level of ICC. MSU may use this information in considering the effectiveness of its cultural diversity goal: experience diversity with supervised reflection and recognize and respond to conditions of marginalized populations. Politics, Personality, and Poor Decision-Making? Assessing Psychological Variables' Impact on Changing False Knowledge. Steven Arriaza, Sungjin Kim, and Isabella Cock-Villafane Karla Lassonde, Faculty Mentor, Psychology (Social and Behavioral Sciences) With the rising accessibility, and distribution of news through different media sources, the ability to discern factual from fake information becomes crucial. A theory called conceptual change has been widely used to design methods to revise misconceptions. Conceptual change theory asserts that learning depends on abandoning prior knowledge and experiencing dissonance that comes with being incorrect. Thus, a person has to realize their knowledge is incorrect to incorporate new, correct information. A similar approach has been employed for addressing misconceptions on social or political issues with little success. The term â€œbackfire effectâ€ has been used to name the process in which people, in the face of factual evidence, double down on their beliefs. Research indicates that when facts challenge our personal beliefs or moral values then we tend to discredit them as counterfactual, even in the face of overwhelming evidence. In this study we examine how political beliefs, the personality trait open-mindedness, and need for cognition interact with refutation text that are designed to correct false knowledge. The first stage of this study focuses on assessing beliefs. In the second, experimental stage, we present a series of passages about common misconceptions with half of them being shown a refutation and explanation that the misconceptions is untrue and half with no refutation or explanation. We hypothesize that individuals who are found to be more politically extreme in their views, less open-minded, and have little desire to think deeply will be less likely to correct misconceptions when reading refutation texts. African American History presented in Monuments and Museums from Select Cities in Southern United States Sara Baranczyk Angela Cooley, Faculty Mentor, History (Social and Behavioral Sciences) American history is often taught in an incomplete fashion, focusing mainly on the European perspectives. This research focuses on a specific aspect of American history that is often neglected or distorted in the canon representation of historic events: the African American perspective. This project aimed to identify which African American figures are memorialized in monuments and museums and what artistic choices are made to represent them. 3 scholarship texts on racial relations, reconciliation and memorializing history, and artistic choices in monuments were studied before traveling to select cities throughout the Southern United states to view African American historic sites, monuments, and museums. Archival studies of each site were conducted after visiting each site. Significant findings include the non-human representations (such as animal or godlike comparisons) of African Americans. These representations can lead to inaccurate ideas and perspectives of African American persons, both in history and the modern day. Investigating Shading as a Viable Control Method for I. pseudacorus Seed Establishment. Brandon Bentley Matthew Kaproth, Faculty Mentor, Biology (Science, Engineering and Technology) Iris pseudacorus (yellow iris), a wetland invasive species, is documented in all coastal regions of the U.S. and is prevalent in the Great Lakes states and Midwest. States including Connecticut, Massachusetts, Montana, New Hampshire, Oregon, and Washington have listed I. pseudacorus as a noxious weed. I. pseudacorus displaces native vegetation and negatively impacts wetland structure, function, habitat and successional trajectories. Recent research has provided evidence that I. pseudacorus spreads almost entirely by seed and not rhizome fragmentation as previously believed (Gaskin et al., 2016). I. pseudacorus seeds have high viability (Gaskin et al., 2016), can float long distances (Coops and Van Der Velde, 1995 in Tu et al., 2003), and form seed banks with their large, persistent seeds. I. pseudacorus seeds have demonstrated a photorequirement for successful germination (Deno, 1993), which may be a limiting factor in their establishment. Research has also found evidence that treatment/removal effectiveness could be genotype specific (Gaskin et al., 2016). Additional research regarding management and treatment/removal techniques is needed as I. pseudacorus demonstrates a strong potential for re-growth and reestablishment post treatment/removal. We hypothesized that reducing light availability by â‰¥50% would inhibit establishment of I. pseudacorus seeds. We performed a greenhouse experiment with two lighting conditions testing germination and establishment rates to investigate the use of shading as a viable control method for I. pseudacorus seed re-establishment post treatment/removal. We performed the experiment using two seed sources (assumed genetic difference) to establish further evidence that treatment and post-treatment control effectiveness could be genotype specific. Electric Utility Vehicle Samuel Biljan and Issac Leonard Bruce Jones, Faculty Mentor, Automotive Engineering Technology (Science, Engineering and Technology) Gary Mead, Faculty Mentor, Automotive Engineering Technology (Science, Engineering and Technology) Electric vehicles have been becoming more popular with the advancements in battery technology and increased emissions. Electric vehicles have the advantage of being quiet, efficient, powerful and produce no emissions. This has been very beneficial in the automotive industry and is starting to make its way in to off road power sports vehicles. The aim of this research was to determine the requirements and benefits that an electric utility terrain vehicle while keeping performance and usability comparable to the internal combustion engine drive train. The research vehicle was a 2015 Prowler that was donated to the university by Arctic Cat/ Textron Off-Road. This UTV was used for a platform to determine the requirements for the electric drive conversion. With the testing benchmarks such as top speed, range and sound tests were used for the design goals for the electric UTV. Surveys were created to help determine the wants and requirements of a consumer that would be interested in buying an electric drive UTV. One of the largest parts of the research was determining the energy required to reach the target speed of 50 MPH and a 50 mile range while being at 350-volts for the electric motor. An energy requirement calculator was used determine the appropriate battery size for the vehicle. Some of the inputs the calculator included were vehicle weight, tire diameter, rolling resistance, aerodynamic drag, desired speed and",2018,
Pretest and Stein-Type Estimations in Quantile Regression Model,"In this study, we consider preliminary test and shrinkage estimation strategies for quantile regression models. In classical Least Squares Estimation (LSE) method, the relationship between the explanatory and explained variables in the coordinate plane is estimated with a mean regression line. In order to use LSE, there are three main assumptions on the error terms showing white noise process of the regression model, also known as Gauss-Markov Assumptions, must be met: (1) The error terms have zero mean, (2) The variance of the error terms is constant and (3) The covariance between the errors is zero i.e., there is no autocorrelation. However, data in many areas, including econometrics, survival analysis and ecology, etc. does not provide these assumptions. First introduced by Koenker, quantile regression has been used to complement this deficiency of classical regression analysis and to improve the least square estimation. The aim of this study is to improve the performance of quantile regression estimators by using pre-test and shrinkage strategies. A Monte Carlo simulation study including a comparison with quantile $L_1$--type estimators such as Lasso, Ridge and Elastic Net are designed to evaluate the performances of the estimators. Two real data examples are given for illustrative purposes. Finally, we obtain the asymptotic results of suggested estimators",2017,arXiv: Statistics Theory
Camillea Malaysianensis Sp. Nov. and the Distribution of Camillea in Southeast Asia,"The genus Camillea Fr. was erected for those xylariaceous fungi which possess erect cylindrical, or short discoid black stromata and have a hard carbonaceous crust (Fries 1849). In modern accounts this generic concept has been broadened to accommodate those applanate species, formerly placed in Hypoxylon Bull., having light-coloured, ornamented ascospores, that apparently lack a germ slit or pore, which have a bipartite stroma with a dehiscent ectostroma (Laessoe et al. 1989; San Martin Gonzalez & Rogers 1993; Whalley 1995). The ascospores usually appear smooth by light microscopy but by scanning electron microscopy are seen to be characteristically ornamented with warts, spines, pits, reticulations or are longitudinally ribbed (Laessoe et al. 1989; San Martin Gonzalez & Rogers 1993; Whalley 1995; Whalley et al. 1996). Pitted or poroid reticulations are the most frequently observed form and species displaying this type are placed in the subgenus Camillea whilst those species possessing warted ornamentations are referred to the subgenusJongiella (Laessoe et al. 1989; Whalley et al. 1996). The genus is primarily neotropical with the majority of species occurring in the Amazon region (Laessoe et al. 1989). Camillea tinctor (Berk.) Lassoe, J. D. Rogers & Whalley is the only species currently known to be widely distributed and it has been reported from South and Central America, temperate North America, Africa, Singapore, Malaysia, Thailand, Papua New Guinea (Laessoe et al. 1989; Miller 1961; Van der Gucht 1992; Whalley 1993; Thienhirun 1997; Whalley 1995). Originally, Miller (1961) was doubtful about the occurrence of Camillea tinctor in Singapore and suggested that the specimens might have been placed in the wrong packet. Recent collections from Papua New Guinea (Van der Gucht 1992), Malaysia and Thailand (Thienhirun 1997; Whalley 1993, 1997), however, confirm that it is truly pantropical and probably common. The discovery of a second Camillea species, C. selangorensis M. A. Whalley, Whalley & E. B. G. Jones, described as new from",1999,Kew Bulletin
Quantile Regression Applied to Genome-Enabled Prediction of Traits Related to Flowering Time in the Common Bean,"Genomic selection (GS) aims to incorporate molecular information directly into the prediction of individual genetic merit. Regularized quantile regression (RQR) can be used to fit models for all portions of a probability distribution of the trait, enabling the conditional quantile that â€œbestâ€ represents the functional relationship between dependent and independent variables to be chosen. The objective of this study was to predict the individual genetic merits of the traits associated with flowering time (DFFâ€”days to first flower; DTFâ€”days to flower) in the common bean using RQR and to compare the predictive abilities obtained from Random Regression Best Linear Unbiased Predictor (RR-BLUP), Bayesian LASSO (BLASSO), BayesB, and RQR for predicting the genetic merit. GS was performed using 80 genotypes of common beans genotyped for 380 single nucleotide polymorphism (SNP) markers. Considering the â€œbestâ€ RQR fit models (RQR0.3 for DFF, and RQR0.2 for DTF), the gains in predictive ability in relation to BLASSO, BayesB, and RR-BLUP were 18.75%, 22.58%, and 15.15% for DFF, respectively, and 15.20%, 24.65%, and 12.55% for DTF, respectively. The potential cultivars selected, considering the RQR â€œbestâ€ models, were among the 5% of cultivars with the lowest genomic estimated breeding value (GEBV) for the DFF and DTF traitsâ€”the IAC Imperador, IPR Colibri, Capixaba Precoce, and IPR Andorinha were included in the list of early cycle cultivars.",2019,Agronomy
"Experimental effect of cold, La NiÃ±a temperatures on the survival of reef fishes from Gorgona Island (eastern Pacific Ocean)","Abstract. The eastern tropical Pacific (ETP) reefs are affected at irregular times by extremely cold temperatures that occur principally during La NiÃ±a events. The effects of these low temperatures on the survival of reef fishes were experimentally assessed by determining the critical thermal minimum (CTM) of 15 reef fish species from Gorgona Island (ETP), and comparing these CTMs with the records of temperature during past La NiÃ±a events. Among species, mean CTMs ranged from 10.8Â°C to 16.3Â°C, which were lower than the coldest temperature recorded during the last La NiÃ±a event (18Â°C during La NiÃ±a 1998â€“1999). However, the observed ranges of CTM for two species (Thalassomalucassanum and Eucinostomusgracilis) extended above 18Â°C. These results suggest that most of the reef fishes we studied are physiologically tolerant to the cold temperatures encountered during La NiÃ±a, though decreases in at least two populations may be expected as a result of the mortality of less tolerant individuals. Although tolerant to cold temperatures, reef fish populations may still experience negative changes during La NiÃ±a, because other determinants in population maintenance (e.g. reproduction and recruitment) are more temperature sensitive. The effects of other cold phenomena on reef fish survival are also discussed herein.",2002,Marine Biology
"Option Return Predictability, A Machine-Learning Approach","We apply the Least Absolute Shrinkage and Selection Operator (LASSO) to make option return forecasts using 101 signals as candidate predictors. We investigate the entire option universe from January 1996 to December 2016. We hold the options till maturity and buy the options from inception with corresponding positions in the underlying stocks to establish a delta-hedge. Our LASSO results yield delta-hedged trading strategies with annualized Sharpe Ratios above 1 for at-the-money calls and puts with 30 days-to-maturity. The LASSO selected predictors also work well out-of-sample. The LASSO selected predictors are different if we restrict our attention to options of different moneyness or maturities (30-, 60-, or 90-day). Overall, the results emphasize the importance of Capital gains overhang in predicting options returns, as it is one of the most frequently selected characteristics, in addition to lagged one month return of the underlying stock and 12 month momentum of the stock, institutional ownership, Standardized Unexplained Volume, cash-to-asset ratio and book-to-market ratio.",2017,Social Science Research Network
Selective Sequential Model Selection,"Many model selection algorithms produce a path of fits specifying a sequence of increasingly complex models. Given such a sequence and the data used to produce them, we consider the problem of choosing the least complex model that is not falsified by the data. Extending the selected-model tests of Fithian et al. (2014), we construct p-values for each step in the path which account for the adaptive selection of the model path using the data. In the case of linear regression, we propose two specific tests, the max-t test for forward stepwise regression (generalizing a proposal of Buja and Brown (2014)), and the next-entry test for the lasso. These tests improve on the power of the saturated-model test of Tibshirani et al. (2014), sometimes dramatically. In addition, our framework extends beyond linear regression to a much more general class of parametric and nonparametric model selection problems. 
To select a model, we can feed our single-step p-values as inputs into sequential stopping rules such as those proposed by G'Sell et al. (2013) and Li and Barber (2015), achieving control of the familywise error rate or false discovery rate (FDR) as desired. The FDR-controlling rules require the null p-values to be independent of each other and of the non-null p-values, a condition not satisfied by the saturated-model p-values of Tibshirani et al. (2014). We derive intuitive and general sufficient conditions for independence, and show that our proposed constructions yield independent p-values.",2015,arXiv: Methodology
Black American Undergraduate Women at a PWI: Switching Majors in STEM,"IntroductionThe well-documented academic achievement gap and lack of representation of African American or Black American students in Science, Technology, Engineering, and Mathematics also known as STEM fields is a matter of increasing concern (Fields, 1998; Green, 2008; O'Brien, Martinez-Pons, & Kopala, 1999; Parsons, Travis, & Simpson, 2005). The underrepresentation of Black American students in STEM fields has been a concern for science educators, researchers, and policy makers for over two decades (HaunFrank, 2011). It is essential for the U.S.A. to continue to promote STEM advancement and diversify the STEM workforce. (Green & Glasson, 2009).Unfortunately, Black Americans encounter negative experiences in scientific fields which is cause for their low representation in the sciences (Green, 2008; Green & Glasson, 2009). Many of these students start in science majors and don't complete their majors because they get lost in the science pipeline (Green, 2008; Green & Glasson, 2009). It is important to note that research reports by the National Science Foundation (2015) consistently outline the disparities between Black Americans in science relative to students from other racial/ethnic groups (e.g. White, Asian). According to research by the National Science Foundation (2015) whites' science and engineering degree attainment has recently declined, however, white students degree attainment still outpaces that of ethnic minority students.Black American Students: Barriers to Their Persistence in STEMThere are a number of barriers to the persistence of Black Americans in science and mathematics on the precollege level and STEM fields on the college level (Allen, 1992; Atwater, 2000; Carlone & Johnson, 2007; Hrabowski, 2002; Hrabowski & Maton, 1995; Hrabowski, Maton, & Greif, 1998; Lewis, 2003; Maton, Hrabowski, & Schmitt, 2000; Russell & Atwater, 2005; Seymour & Hewitt, 1997; Smith & Hausfaus, 1998). There is much research that outlines factors that contribute to persistence (switching majors) for Black African Americans which includes lack of preparation for the college science classroom, alienation and isolation at PWIs, (Brown, 2000; Green, 2008; Hrabowski & Maton, 1995; Hrabowski et al., 1998; Russell & Atwater, 2005; Seymour & Hewitt, 1997), and myths of intellectual inferiority for Black Americans (Hall-Greene, 2000 as cited in Greene 2008; Herrnstein & Murray 2010; Jensen, 1969; Moore, 2000 as cited in Green, 2008).Black American students encounter institutional factors that adversely impact their persistence in science-related majors and their talents are often wasted as they are discouraged from participating in STEM at predominantly white institutions (Green & Glasson, 2009). Furthermore, research studies on Black Americans in STEM clearly delineates the marginalization talented Black African American students encounter at predominantly white institutions and the ""weeding out"" ideology which is often the unfortunate message conveyed to racial and ethnic minorities, (Green, 2008; Seymour & Hewitt, 1997). This also conveys the message that the sciences are not for everyone but a select few, perpetuating the paradigm that science is just for white males. For example, the ""Draw A Scientist Test"" (DAST) experiment (Chambers, 1983) is done in classrooms with students across grade levels and consistently the perception of scientist is that of the stereotypical white, male, crazy-haired scientist with a lab coat, glasses, beakers and a pocket protector.Moreover, research demonstrates that academic persistence and success on the college level can be attributed to participation in advanced science and mathematics courses during the high school college preparatory program (Atwater, 2000; Brown, 2000; Connell & Lewis, 2003; Hrabowski et al., 1998; Russell & Atwater 2005; Seymour & Hewitt, 1997). Much research on curriculum tracking has found that advanced science and mathematics courses often serve as ""gateways"" to science-related degrees and, consequently, careers in STEM-related occupations. â€¦",2015,The Negro educational review
The Application of Agricultural Chemicals by Aircraft on Sugarcane,"other 50% contains fewer droplets larger than the VMD. Aerial application of agricultural chemicals has proved exFor pre-emergent herbicides, a coarse droplet spectrum with tremely successful on Ubombo Ranches, Swaziland, and this a VMD of 400 to 450 microns is considered to be most effective paper describes various aspects of the operation. The selection because recovery of the chemical is important. In post-emergent of optimum Volumetric Median Diameter of droplets is discusherbicides, a medium size droplet (300 400 microns) is sed and the D-Max method for determination of the VMD preferable for distribution on and penetration of the weed described. The methods for determining the optimum Flight canopy. In general, fine droplets give better distribution and Track Interval and nozzle placement on the boom are given. penetration at the expense of recovery due to evaporation. Practical techniques for aircraft loading and marking are Coarse droplets give a high chemical recovery at the expense of described, together with meteorological conditions affecting droplet distribution and penetration. aerial spraying. Advantages, disadvantages and costs of aerial 1, order to determine the VMD, it is necessary to make a spraying are discussed and the major ~hemicals used are menpass over special collector cards (e.g. Kromekote) whilst emittioned. ting a dye (e.g. Solophenyl Blue 4GLC). The VMD is then calculated by the D-Max method. The D-Max is the largest Introduction diameter droplet appearing at least twice on the cards. Approx~t ~ b o m b o Ranches, Swaziland, few herbicides were applied imately half of the mass of the liquid emitted by hydraulic presto sugarcane lands prior to Spring 1973, weeds having been consure nozzles consists of droplets smaller than 0,45 of the Dtrolled mainly by hand and mechanical means. In 1973, preMax, and the VMD is therefore D-Malc 0,45. emergent herbicides were introduced on a systematic basis to The diameter of the D-Max stain is divided by a spread factor reduce the dependence on expensive labour which varies slightly with the type of cards and dye being used. was progressively less Ubombo Ranches It is by the droplet size and is determined by means of a were also undertaking a large expansion programme, in which graph. The VMD is then determined as follows: development much of the labour was deployed. Lasso EC and atrazine were the major herbicides applied by means of three (1) Obtain D-Max stain tractor mounted spray-rigs. Broken diaphragms, burst tubes, (2) Divide D-Max stain by spread factor = D-Max effective blocked nozzles and other failures associated with this type of (3) D-Max effective x 0,45 = VMD. equipment provided a never-ending source of trouble. These tractors were unable to contend with the areas to be treated, and Application rate an aircraft was therefore used to assist in the application of The application rate is the total volume of spray mixture apdiuron and atrazine. plied per hectare, and it naturally influences the application cost. The topography, area and system of farming are well suited This application rate has a direct bearing on the droplet to the application of agri-chemicals by aircraft, and on the spectrum within the spray cloud, a high VMD necessitating a strength of the excellent results achieved in the 1973 programhigh volume. me, a contract was made with a Swaziland crop spraying comIn aerial spraying, the two types of applications are low pany to station an aircraft on the property for that part of the volume (5 to 75 elha) and ultra-low volume (ULV) (less than 5 harvesting season in which herbicides were to be applied, nameelha). The ULV technique is normall~r used for insecticides ly August to January. As this period was regarded by crop which are oil based chemicals, and is not applicable to herbicides sprayers as an off-season period, the bulk of their flying time bein sugar cane. ing devoted to cotton from ~anuary to May, it was possible to A, application rate of 35 e/ha is considered as the optimum negotiate a favourable contract. rate for both herbicides and ripeners on Ubombo Ranches. Application Technique Application Equipment Identity of target area There is application equipment available to cater for a variety of systems. Each system has its particular merits and disadvanIt is most important to identify the target to which the tages. chemical is to be applied. In the case of a post-emergent weedkiller, the target is the weed itself and the chemical is best The application equipment which is used to comply with the applied as a fine mist of small droplets to give wide droplet disspecifications mentioned above (VMD about 400 microns and tribution and penetration of the weed sward. For pre-emergent 35 e/ha application rate) is a boom with ~ l b u z ivory tee-jet nozherbicides, the target area is the soil surface on which a large zles at an operating Pressure between 120 and 170 kPa. For droplet is considered preferable, because its size ensures a higher Pre-emergent herbicides, the nozzles are set at 180' to produce chemical recovery. a minimum of atomization, while for chemical ripeners the nozzles are set at 135O. The droplet spectrum is materially affected Classification of spray cloud by the nozzle angle, as shown in Fig. 1. The spray cloud should conform to the specifications that will The aircraft speed is approximately 165 km/h. The number of accomplish the optimum effect of the chemical on a given target ~~ozzles is dependent on the application rate and Pump Pressure, area. The spray cloud is classified according to the spectrum of and they are strategically spaced along the length of the booms droplets within the cloud, which is expressed as the Volumetric to make ahwances for the wingtip vortices and propeller Median Diameter (VMD). This is the diametric median of the which otherwise cause a certain amount of swath distortion. droplets in microns, dividing the spray cloud into two equal These spacings are determined largely by trial and error, and parts by volume. In other words, 50% of the volume of the spray they depend on the equipment and aircraft in use. It has been cloud comprises many droplets smaller than the VMD, and the found that the greatest losses in recovery are caused by the Proceedings of The South African Sugar Technologists' Association June -a 1 80Â° -(coarse droplets) /'\ 4 5 O 135"" (fine droplets) 90"" (coarse-medium droplets) (medium-fine droplets) Figure 1: Illustration of a wing section showing spray angle to the line of flight. wingtip vortices, and to counteract this, it is preferable to move the outermost nozzles well inboard of the wingtips. This has the effect of reducing the effective swath marginally, but this can be overcome by flying at a slightly higher altitude. The propeller wash causes uneven distribution below the aircraft, and this is counteracted by placing more nozzles approximately 1 m from the fuselage along the starboard wing and omitting them for 1 m from the fuselage on the port wing. The nozzles on the aircraft boom are fitted with an automatic shut-off assembly, which is merely a diaphragm situated in a housing at the back of the nozzle which prevents liquid from leaving the boom below a certain pressure. This ensures that there is always liquid in the boom and that time lags are avoided. Besides the fan-jet in use on Ubombo Ranches, other types of nozzles are available for a variety of situtations. These include cone-jets and Raindrop nozzles. Rotary Atomizers or Micronairs, which are effectively used for ULV applications of insecticides have as yet a limited role in sugarcane.",2009,
Electroanatomical systems guided circumferential pulmonary veins ablation with single Lasso for atrial fibrillation,"Objective To assess the safety and effect of electroanatomical systems (Carto) guided circumferential pulmonary veins ablation for atrial fibrillation (AF).Methods Four patients with AF, one with paroxysmal atrial flutter, were studied.The mean age was (52Â±10) years. Three were male and one female. The mean AF duration was(3.3Â±1.8)years. Electroanatomical mapping was integrated with pre-acquired CT to guide catheter ablation. A 3D electroanatomical map of the left atrium including the pulmonary veins ostia was constructed with a nonfluoroscopic navigation system (Carto, Biosense Webster).All patients underwent circumferential pulmonary vein ablation. Cardioversion was done by means of drugs (Propafenone) or electrical shocks if AF persisted after ablation. Oral anticoagulant therapy lasted for 2 months after the procedure. Patients were followed up for 4-12 months.Results All patients with AF were AF-free. The radiofrequency ablation time was (6Â±43) min and the exposure time was (48Â±7) min. No serious complication or recurrence was found during the follow-up.Conclusion Carto systems united with single Lasso can be effective and safe in the guidance of the ablation for AF.Comparing with conventional approach, it reduces X-ray exposure and the cost.",2007,Journal of Minimally Invasive Medicine
New approaches for high-dimensional multivariate GARCH models,"This document contributes to high-dimensional statistics for multivariate GARCH processes. First, the author proposes a new dynamic called vine-GARCH for correlation processes parameterized by an undirected graph called vine. The proposed approach directly specifies positive definite matrices and fosters parsimony. The author provides results for the existence and uniqueness of stationary solution of the vine-GARCH model and studies its asymptotic properties. He then proposes a general framework for penalized M-estimators with dependent processes and focuses on the asymptotic properties of the adaptive Sparse Group Lasso regularizer. The high-dimensionality setting is studied when considering a diverging number of parameters with the sample size. The asymptotic properties are illustrated through simulation experiments. Finally, the author proposes to foster sparsity for multivariate variance covariance matrix processes within the latter framework. To do so, the multivariate ARCH family is considered and the corresponding parameterizations are estimated thanks to penalized ordinary least square procedures.",2017,
Wafer yield prediction using derived spatial variables,"Unreliable chips tend to form spatial clusters on semiconductor wafers. The spatial patterns of these defects are largely reflected in functional testing results. However, the spatial cluster information of unreliable chips has not been fully used to predict the performance in field use in the literature. This paper proposes a novel wafer yield prediction model that incorporates the spatial clustering information in functional testing. Fused LASSO is first adopted to derive variables based on the spatial distribution of defect clusters. Then, a logistic regression model is used to predict the final yield (ratio of chips that remain functional until expected lifetime) with derived spatial covariates and functional testing values. The proposed model is evaluated both on real production wafers and in an extensive simulation study. The results show that by explicitly considering the characteristics of defect clusters, our proposed model provides improved performance compared to existing methods. Moreover, the cross-validation experiments prove that our approach is capable of using historical data to predict yield on newly produced wafers.",2017,Quality and Reliability Eng. Int.
(54) Inhibitors of Herpes Simplex Virus,"Argnani, R., et al., â€œHerpes Simplex Virus Type 1 (HSV-1) Uracil-DNA Glycosylase: Functional Expression in Escherichia coli,â€ Biochemical Characterization, and Selec tive Inhibition by 6-(p-n-Octylanilino) Uracil, Virology. 211: 301â€“311 (1995). Bowman, C.A., et al., â€œAsymptomatic herpes Simplex virus Shedding from the genital tract whilst on Suppressive doses of oral acyclovir.â€ Int. J. STD AIDS 1: 174â€“177 (1990). Focher, F., et al., â€œHerpes simplex virus type I uracil-DNA glycosylase: isolation and Selective inhibition by novel uracil derivatives.â€ Biochem. J. 292: 883-889 (1993). Griffiths, P.D., â€œA proposal that herpesviruses are co-factors of HIV disease,â€ Antivir. Chem. Chemother: 6, (Supp. 1): 17â€“21 (1995). Ho, D.Y., â€œHerpes Simplex Virus Latency: Molecular Aspects.â€ Prog. Med. Virol. 39: 76â€“115 (1992). Jacobson, J.G., et al., â€œAherpes simplex virus ribonecleotide reductase deletion mutant is defective for productive acute and reactivatable latent infections of mice and for replication in mouse cellsâ€ Virology 173: 276-283 (1989). Jeffries, D.J.; DeClerq, E., Eds. Antiviral Chemotherapy. John Wiley and Sons, Chichester, pp. 199-223 (1995). Overall, Jr., J.C., â€œDermatological Diseases,â€ in Galasso, et al., Antiviral Agents and Viral Diseases of Man, Raven press, New York, pp. 325â€“384 (1979). Pregnolato, M., et al., â€œSynthesis and Molecular Modeling of novel HSV-1 Uracil-DNA glycosylase inhibitors.â€ Nucleosides & Nucleotides, 18 (4 & 5), 709â€“711 (1999). Price, R.W., â€œHerpes Simplex Virus Latency: Adaptation to the Peripheral Nervous System. I, Cancer Invest. 3: 285â€“292; II, ibid., 389â€“403 (1985). Roizman, B. and Sears, A.E., â€œAn Inquiry into the Mecha nisms of Herpes Simplex Virus Latency,â€ Annu. Rev. Micro biol. 41: 543â€“571 (1987). Savva, R. et al., â€œThe structural basis of specific base-ex cision by uracil-DNA glycosylase,â€ Nature. 373: 487-493 (1995). Schwab, I.R., â€œOral Acyclovir in the Management of herpes simplex ocular infections,â€ Ophthalmology 95: 423-429 (1988). Stevens, J.G., et al., â€œRNA Complementary to a Herpesvirus a Gene mRNA is Prominent in Latently Infected Neurons.â€ Science 235: 1056â€“1059 (1987). Sun, H., et al., â€œMolecular Modeling and Synthesis of inhibitors of herpes simplex virus Type 1 Uracil-DNA glycosylase,â€ J. of Medicinal Chemistry 42(13): 2344-2350 (1999). Wildy, P., et al., in Virus Persistence, Mahy, B.W.H., Min Son, A.C. and Darby, G.K., eds., Cambridge University Press, Cambridge, pp. 134-167 (1982). Youle, M.S., et al., â€œEffects of high-dose oral acyclovir on herpesvirus disease and Survival in patients with advanced HIV disease: a double-blind, placebo-controlled study,â€ AIDS 8: 641â€“649 (1994).",2017,
A Nodewise Regression Approach to Estimating Large Portfolios,"This paper investigates the large sample properties of the variance, weights, and risk of high-dimensional portfolios where the inverse of the covariance matrix of excess asset returns is estimated using a technique called nodewise regression. Nodewise regression provides a direct estimator for the inverse covariance matrix using the Least Absolute Shrinkage and Selection Operator (Lasso) of Tibshirani (1994) to estimate the entries of a sparse precision matrix. We show that the variance, weights, and risk of the global minimum variance portfolios and the Markowitz mean-variance portfolios are consistently estimated with more assets than observations. We show, empirically, that the nodewise regression-based approach performs well in comparison to factor models and shrinkage methods.",2016,arXiv: Statistics Theory
Structured sparse-low rank matrix factorization for the EEG inverse problem,"We consider the estimation of the Brain Electrical Sources (BES) matrix from noisy EEG measurements, commonly named as the EEG inverse problem. We propose a new method based on the factorization of the BES as a product of a sparse coding matrix and a dense latent source matrix. This structure is enforced by minimizing a regularized functional that includes the â„“21-norm of the coding matrix and the squared Frobenius norm of the latent source matrix. We develop an alternating optimization algorithm to solve the resulting nonsmooth-nonconvex minimization problem. We have evaluated our approach under a simulated scenario consisting on estimating a synthetic BES matrix with 5124 sources. We compare the performance of our method respect to the Lasso, Group Lasso, Sparse Group Lasso and Trace norm regularizers.",2014,2014 4th International Workshop on Cognitive Information Processing (CIP)
"Man, vegetation and climate during the Holocene in the territory of Sagalassos, Western Taurus Mountains, SW Turkey","Past vegetation change and the influence of climate change and anthropogenic pressure during the Holocene is constructed from a series of palynological records sampled from three locations within the territory of the antique site of Sagalassos. The disappearance of the original deciduous oak woodlands and increases in anthropogenic indicator species around 5300 and 4300 b.c. correspond with an increase in settlements in the region. A period of drought following the deforestation may have hampered the recovery of deciduous oak. The timing of the onset of the BeyÅŸehir Occupation Phase (BO-Phase) in the territory differs between locations, estimates ranging from ca. 1000â€“800 b.c. to the start of the Hellenistic period (334 b.c.). The most intense period of arboriculture coincides with the Roman and late-Roman periods. Increases in human pressure on the landscape as reflected in the pollen record correspond with an increased rate of sedimentation and fire activity. The timing of the end of the BO-Phase again differs between locations. Estimates range from the 4th century a.d. to the mid 7th century a.d., when a region-wide shift to dry environmental conditions is observed. Numerical analyses show that post BO-Phase vegetation change is largely driven by climate and displays a succession of dry and wet periods that coincided with well-defined European climate shifts, including the Medieval Climate Anomaly and the Little Ice Age. Current agricultural activities in the region are of a very recent (20th century) origin.",2011,Vegetation History and Archaeobotany
Grouped graphical Granger modeling methods for temporal causal modeling,"We develop and evaluate an approach to causal modeling based on time series data, collectively referred to as ""grouped graphical Granger modeling methods."" Graphical Granger modeling uses graphical modeling techniques on time series data and invokes the notion of ""Granger causality"" to make assertions on causality among a potentially large number of time series variables through inference on time-lagged effects. The present paper proposes a novel enhancement to the graphical Granger methodology by developing and applying families of regression methods that are sensitive to group information among variables, to leverage the group structure present in the lagged temporal variables according to the time series they belong to. Additionally, we propose a new family of algorithms we call group boosting, as an improved component of grouped graphical Granger modeling over the existing regression methods with grouped variable selection in the literature (e.g group Lasso). The introduction of group boosting methods is primarily motivated by the need to deal with non-linearity in the data. We perform empirical evaluation to confirm the advantage of the grouped graphical Granger methods over the standard (non-grouped) methods, as well as that specific to the methods based on group boosting. This advantage is also demonstrated for the real world application of gene regulatory network discovery from time-course microarray data.",2009,
"A New Azhdarchoid Pterosaur from the Crato Formation (lower Cretaceous, Aptian?) of Brazil","A partial pterosaur skull from the Nova Olinda Member of the Crato Formation (Lower Cretaceous, Aptian?) represents a new edentulous pterodactyloid, Lacu- sovagus magnificens gen. et sp. nov. The absence of teeth and a large nasoantorbital fenestra suggest assignment to Azhdar- choidea, and the combination of a particularly short, crestless and shallow rostrum and laterally flared jaw margins distin- guish it from other azhdarchoid taxa. The position of the new form within Azhdarchoidea is problematic: Lacusovagus is distinguished from Tapejaridae in its straight, as opposed to ventrally displaced, jaw tip and absence of a premaxillary crest; from thalassodromids by the absence of a premaxillary crest; and from Azhdarchidae by the short length of the ros- trum and shallow posterodorsal extension of the premaxilla. Lacusovagus shares a shallow, crestless rostrum and a slender posterodorsal premaxillary extension with Jiufotang Forma- tion azhdarchoids such as Chaoyangopterus and Jidapterus. The position of these genera within Azhdarchoidea is contro- versial, but the suite of plesiomorphic and derived azhdarch- oid characters in each suggests a placement between Tapejaridae and Neoazhdarchia. Further research is required, however, to determine the relationships of these genera both to each other and to other azhdarchoids. The new taxon ele- vates the faunal similarity found between the roughly con- temporaneous Jiufotang and Crato formations and continues the pattern of Crato Formation azhdarchoids being much larger than those from the Jehol Group. It also has jaws at least 67 and 55 per cent longer, respectively, than those of the largest azhdarchoids and ornithocheirids from the Crato pterosaur assemblage, making Lacusovagus the largest ptero- saur known from this unit.",2008,Palaeontology
Serum Newborn Screening Blood Metabolites Are not Associated With Childhood-onset Inflammatory Bowel Disease: A Population-based Matched Case-control Study.,"BACKGROUND
Originally used for screening of inborn errors of metabolism, routine metabolite profiles of newborns have also been associated with prematurity and some childhood diseases. We sought to determine whether metabolites measured during routine newborn screening could identify infants who develop inflammatory bowel disease (IBD) in childhood.


METHODS
We conducted a population-based matched case-control study using health administrative data from Ontario, Canada. Children born 2006 to 2015 with IBD were identified using a validated algorithm and matched to 5 controls based on birth date, sex, rural/urban household, and mean neighborhood income quintile at birth. Cases and controls were linked deterministically to metabolic profiles from Newborn Screening Ontario. We fit a lasso penalized logistic regression model and used 10-fold cross-validation to obtain internally valid performance measures. Models included metabolites, amino acids, and endocrine markers. Models also included ratios of metabolites, gestational age, birth weight, mode of delivery, age at serum collection, maternal age at delivery, maternal history of IBD, and parity.


RESULTS
Three hundred eight cases of IBD, diagnosed at 5.5 Â± 2.8 years, were matched to 1540 controls. No individual metabolites were associated with IBD. The c-statistic was 0.50 for the training data. After 10-fold cross-validation the C statistic was 0.50, indicating no significant association between metabolites and IBD diagnosis.


CONCLUSIONS
Newborn screening serum metabolites could not identify children who will develop IBD in this population-based cohort. Future studies with an expanded panel of metabolites may provide improved prediction of IBD.",2019,Inflammatory bowel diseases
Evaluating deprivation in Italy using a multidimensional counting approach,"In the last decades, there is a unanimous consensus that deprivation is a multidimensional concept that cannot be adequately captured by considering only unidimensional measures related to income. However, a difficulty arises. Whereas most of the multidimensional indices proposed deal well only with quantitative data, the majority of the data available to measure deprivations are either ordinal or categorical. In 2010, the European Council adopted 9 common indicators 2 to measure the material deprivation (EU-MD) for all the 27 EU Member States. The EU MD rate is currently defined as the proportion of people living in households who cannot afford at least 3 items. The main drawback of the MD indicators currently used is its small number of items. Since 2010, the importance of MD indicators has grown significantly and several initiatives have been implemented to modify and amply such dataset. An alternative to the traditional indices is the counting approach introduced by Atkinson (2003), who observed that empirical studies of deprivation do not use a social welfare function approach, but rather focus on counting the number of dimensions in which people suffer deprivation. The counting approach is an appropriate procedure that deals well with ordinal and categorical variables. A number of counting deprivation measures has been derived. Many times choosing different measures leads to contradictory results. The dominance criteria introduced by Lasso de la Vega (2010) guarantee reaching robust conclusions in a counting framework. This paper applies the cited methodology and dominance criteria to Italy in the period 2005-2009 using data collected in the Survey on Income and Living Conditions (EUSILC). Following Ravallion's (1996) recommendations, we",2014,
"Parasites of the gray bat, Myotis grÃ­sescens, in Kansas.","Fifty-four specimens of Myotis grisescens collected in Kansas were examined for parasites. New host records include: Spinturnix americanus, Myodopsylla collensi, Plagiorchis micracanthum, Urotrema scabridum, Limatulum oklahomensis, Vampirolepis christensoni, Allintoshius travassosi, Allassogonoporus marginalis and a Capillaria sp. Additional host records are given for Allassogonoporus marginalis, Spinturnix banksi and an Ichoronyssus sp. from Myotis velifer incautus, Spinturnix banksi, Paraspinturnix globosus and an Ichoronyssus sp., known from Myotis grisescens, and Spinturnix carloshoffmanni, Myodopsylla collensi from Myotis velifer incautus in other states are recorded from these hosts in Kansas. 'The gray bat, Myotis grisescens Howell, 1909, is limited in distribution to the Southeastern part of the United States. The species first was reported from Kansas by Long (1961) on the basis of a juvenile obtained within Pittsburg, Kansas. Subsequently, Hays and Bingman (1964) discovered a colony of gray bats in a storm sewer in Pittsburg (the northwesternmost locality from which M. grisescens is known). Fifty-four specimens collected in the storm sewer were examined for parasites in the autumn of 1962, spring and autumn of 1963, and the autumn of 1964. Additionally, many bats, were superficially examined for ectopara.sites. by colleagues and later released. 'Three species of mites, one species of flea, one bat fly, four species of trematodes, one cestode and two kinds of nematodes have been recovered. All bats collected were placed in cloth or plastic sacks until examined. Most were examined for ectoparasites by visual inspection, but some were washed in detergent to obtain a better sample. Ectoparasites were preserved in 70% alcohol for study. Thirty-seven freshly killed bats were examined for endoparasites. Trematodes and cestodes found were relaxed and killed in hot water before being fixed in Acetic-Formalin-Alcohol and stained in Harris' hematoxylin. Nematodes were prepared by the double-coverslip method outlined by Cable (1963), with the exception that glycerine was used in place of glycerine gel. Blood from 30 individual bats proved negative for parasites. No examinations were made for intestinal protozoans. The 12 species of parasites obtained from M. grisescens are discussed below. 1 Present address: Department of Zoology, Colorado State University, Fort Collins 80521.",1966,American Midland Naturalist
Social networks in the entrepreneurial career: life-stories analysis of informal entrepreneurs in Bobo-Dioulasso (Burkina-Faso) (In French),"This paper analyzes the evolution and transformation of social relations and networks of access to resources during the professional career of micro entrepreneurs in the informal African urban economy. Our analysis of social networks fits in the â€˜structural embeddednessâ€™ framework of Granovetter (1985) associated with a dynamic perspective of social relations. This perspective allows taking into account the temporal dimension of embeddedness, and its links with others social mediations, as communities, organizations and formal institutions. With such a view, embeddedness is analyzed with its reverse, the decoupling that is to say how actors and structures become independent from social relations (White, 1992). From a methodological standpoint, our analysis of life-stories of micro and small entrepreneurs of Bobo-Dioulasso (Burkina-Faso) combines qualitative and quantitative methods. It suggests that social networks and interpersonal relations of access to resources are constructed through a long-time process. Thus they can not be so easily and quickly mobilized by the entrepreneurs as it is sometimes suggested in social capital approaches. We then observe a co-construction phenomenon of social networks and activity that undermine the view of social capital as a substitute for lack of personal resources. The development and resilience of micro and small activities are directly linked to the professionalization and the stabilization of the network; and even the institutionalization of access to resources. However, it should not mask strong inequalities among entrepreneurs according to their initial social network and the dynamic of their business environment.",2010,
Robust cluster expansion of multicomponent systems using structured sparsity,"Identifying a suitable set of descriptors for modeling physical systems often utilizes either deep physical insights or statistical methods such as compressed sensing. In statistical learning, a class of methods known as structured sparsity regularization seeks to combine both physics- and statistics-based approaches. Used in bioinformatics to identify genes for the diagnosis of diseases, $\textit{group lasso}$ is a well-known example. Here in physics, we present group lasso as an efficient method for obtaining robust cluster expansions (CE) of multicomponent systems, a popular computational technique for modeling such systems and studying their thermodynamic properties. Via convex optimization, group lasso selects the most predictive set of atomic clusters as descriptors in accordance with the physical insight that if a cluster is selected, so should its subclusters. These selection rules avoid spuriously large fitting parameters by redistributing them among lower order terms, resulting in more physical, accurate, and robust CEs. We showcase these features of group lasso using the CE of bcc ternary alloy Mo-V-Nb. These results are timely given the growing interests in applying CE to increasingly complex systems, which demand a more reliable machine learning methodology to handle the larger parameter space.",2019,arXiv: Materials Science
A framework for feature selection in clustering.,"We consider the problem of clustering observations using a potentially large set of features. One might expect that the true underlying clusters present in the data differ only with respect to a small fraction of the features, and will be missed if one clusters the observations using the full set of features. We propose a novel framework for sparse clustering, in which one clusters the observations using an adaptively chosen subset of the features. The method uses a lasso-type penalty to select the features. We use this framework to develop simple methods for sparse K-means and sparse hierarchical clustering. A single criterion governs both the selection of the features and the resulting clusters. These approaches are demonstrated on simulated data and on genomic data sets.",2010,Journal of the American Statistical Association
"Lower, Middle and Upper Palaeolithic in the territory of Sagalassos (SW Turkey) : problems and prospects","The aim of this study is to discuss the lower, Middle and Upper Palaeolithic finds in the neighbourhood of Sagalassos (Pisidia, SW Turkey). The model proposed tries to explain the fact that sites dating to these periods are almost non-existent in the area. At the same time, the proposed model attempts to predict where more material may be found. The blank on the distribution maps of the find spots for the Lower, Middle and Upper Palaeolithic in this area is only an apparent blank and does not correspond to reality. The same is true for the Taurus region in general. We propose a three-stage selective strategy that should result in a more reliable distribution map for the Palaeolithic in this region.",1998,Anatolia Antiqua
Sparse Estimation Using General Likelihoods and Non-Factorial Priors,"Finding maximally sparse representations from overcomplete feature dictionaries frequently involves minimizing a cost function composed of a likelihood (or data fit) term and a prior (or penalty function) that favors sparsity. While typically the prior is factorial, here we examine non-factorial alternatives that have a number of desirable properties relevant to sparse estimation and are easily implemented using an efficient and globally-convergent, reweighted l1-norm minimization procedure. The first method under consideration arises from the sparse Bayesian learning (SBL) framework. Although based on a highly non-convex underlying cost function, in the context of canonical sparse estimation problems, we prove uniform superiority of this method over the Lasso in that, (i) it can never do worse, and (ii) for any dictionary and sparsity profile, there will always exist cases where it does better. These results challenge the prevailing reliance on strictly convex penalty functions for finding sparse solutions. We then derive a new non-factorial variant with similar properties that exhibits further performance improvements in some empirical tests. For both of these methods, as well as traditional factorial analogs, we demonstrate the effectiveness of reweighted l1-norm algorithms in handling more general sparse estimation problems involving classification, group feature selection, and non-negativity constraints. As a byproduct of this development, a rigorous reformulation of sparse Bayesian classification (e.g., the relevance vector machine) is derived that, unlike the original, involves no approximation steps and descends a well-defined objective function.",2009,
"SalomÃ³n Usque ante la ""CanciÃ³n 23"" de Petrarca","The Spanish translation in verse by Salomon Usque of the first part of the Canzoniere by Francesco Petrarca was published in Venice in 1567. The analysis of the Canzone delle Transformazione (C 23) explores the indebtedness of the translator to Petrarchan exegesis, the variations and the omissions in respect to the original Tuscan poem, the interference of the Italian language on the Spanish of Usque and this attitude towards the learned words used by Petrarca. De las traducciones castellanas del Canzoniere [C] de Francesco Petrarca llevadas a cabo en el siglo XVI la de SalomÃ³n Usque [SU] ha sido la que menor curiosidad ha suscitado entre los investigadores. Un desinterÃ©s que llama la atenciÃ³n, sobre todo si se tiene en cuenta que la tarea de Usque constituye el primer proyecto de traducciÃ³n sistemÃ¡tica de la obra magna en lengua vulgar de Petrarca. Es fatiga que el traductor, en su dedicatoria a Alessandro Farnese, pondera con orgullo por lo que representa de Â«Obra en la verdad de muchos desseada, de pocos emprendida y de ninguno hasta agora acabadaÂ». El pulcro volumen en 8o, que contiene la primera parte de C,1 fue publicado en 1567 por el impresor veneciano NicolÃ² Bevilacqua y contÃ³ con el 1. Primera segÃºn el criterio de ordenaciÃ³n tripartita de Alessandro Vellutello (cfr. MarÃ­a Pilar MANERO SOROLLA, Â«La primera traducciÃ³n de las Rime de Petrarca en lengua castellana: Los sonetos, canciones, mandriales y sextinas del gran poeta y orador Francisco Petrarca, de SalomÃ³n UsqueÂ», en Homenaje al profesor Antonio Vilanova, Barcelona: Universitat de Barcelona, 1989, ed. de Marta Cristina Carbonell, p. 385). SU abarca hasta C 266 y se excluyen las composiciones no directamente relacionadas con el ciclo de Laura in vita, que Vellutello relegaba a un breve apartado final. SÃ³lo algunos ejemplares se imprimieron con el nombre del autor; en el frontispicio de la mayor parte de los que han llegado hasta nosotros figura un seudÃ³nimo humanÃ­stico: Salusque Lusitano. Para los pocos datos biogrÃ¡ficos ciertos de este judÃ­o de origen portuguÃ©s residente en Ferrara cfr. Cecil ROTH, Â«Salusque Lusitano. An essay in disentaglementÂ», en Gleanings. Essays in Jewish History. Letters and Art, New York: Hermon Press, 1967, p. 179-199. aval de Alfonso de Ulloa, a quien debemos unas pÃ¡ginas preliminares en las que esboza las caracterÃ­sticas fundamentales de la labor de Usque. El cual consigue mantenerse equidistante tanto de la literalidad de una traducciÃ³n ad verbum, representada por la versiÃ³n en prosa de Francisco Trenado de AyllÃ³n [FT] en 1595,2 como de la libertad con la que Enrique GarcÃ©s [EG] adaptarÃ¡ en 1591 la recopilaciÃ³n poÃ©tica del sumo poeta toscano. Remitiendo a las palabras de Ulloa: Â«es mucho de loar la diligencia del intÃ©rprete, que jamÃ¡s se ha apartado del sentido del autor, ni tampoco ha traduzido solamente las palabras. Porque lo uno no lo podÃ­a hazer que tuviesse gracia, teniendo cada lengua su particular frase y manera de dezir diferente de las otras, aunque muy vezinas sean; y lo otro menos, de tomar el sentido y la sentencia del autor, por la variedad que en esto entre los expositores hay. Y ansÃ­, teniendo esta consideraciÃ³n, ha concertado y puesto las palabras en tal manera que dâ€™ellas se pueden con facilidad sacar todas las sentencias y sentidos que en toscano les danÂ». Ulloa resalta asimismo el esfuerzo de Usque, el cual ha vertido al castellano respetando el esquema mÃ©trico y la variedad estrÃ³fica del corpus original, lo que lleva al prologuista a elevar SU a rango de Â«dechadoÂ», de patrÃ³n en el que los poetas espaÃ±oles no familiarizados con la lengua de la vecina penÃ­nsula mediterrÃ¡nea puedan emular los metros italianos remontÃ¡ndose a la fuente, Â«aunque tengan las obras de BoscÃ¡n, de Garcilasso de la Vega, de Don Diego de MendoÃ§a, de Jorge de Montemayor y de otros autores que, con mucha gravedad y saber, han escrito en esta suerte de verso a imitaciÃ³n del PetrarcaÂ». Usque traduce en plena efervescencia petrarquista, pudiendo valerse para su tarea de una sÃ³lida tradiciÃ³n exegÃ©tica tejida en torno a C y sin cuyo auxilio la versiÃ³n castellana hubiera sido muy otra. AÃºn no se ha dado a la imprenta el magno comentario de Ludovico Castelvetro, que en 1582 Pietro de Sedabonis publicarÃ¡ en Basilea; pero el traductor demuestra tener familiaridad con las notas de Alessandro Vellutello [AV] (Venecia: 1525) y de Bernardino Daniello [BD] (Venecia: 1541). 1. LimitÃ¡ndonos a C 23 (conocida como Canzone delle trasformazioni), percibimos de inmediato la deuda para con AV tanto por la posiciÃ³n que el poema ocupa en el interior de esta primera parte de C,3 como por el breve resumen del contenido o Â«argumentoÂ». Ã‰ste reproduce, casi palabra por palabra, las lÃ­neas con que da inicio la exposiciÃ³n de Vellutello:4 102 Quaderns dâ€™ItaliÃ  4/5, 1999/2000 Jordi Canals 2. Se conserva una parte del manuscrito autÃ³grafo en British Library (ms. Egerton 2062). Cfr. VÃ­ctor Eduardo KREBS, Trenado de Ayllonâ€™s Â«Comento del PetrarcaÂ». An edition, Boston: Boston University, 1992 [tesis doctoral]. 3. Es en SU la CanciÃ³n XII (p. 127-132). 4. Citaremos en lo sucesivo segÃºn la ediciÃ³n de Venecia, tip. NicolÃ² Bevilacqua, 1563 [1a ed.:",1999,
Fermi-Bose mixtures : From mean-field interactions to ultracold chemistry,"Seit der Beobachtung von Bose-Einstein-Kondensation in einkomponentigen bosonischen Gasen und der Realisierung von spin-polarisierten idealen Fermigasen entwickelt sich das (noch sehr junge) Feld der ultrakalten Quantengase rasch in Richtung mehrkomponentiger Gase. Das letztendlich weiteste Spektrum an Moglichkeiten fur quantenmechanische Simulation, ultrakalte Chemie, exotische Paarbildungsmechanismen, Unordnungsphanomene und langreichweitige Wechselwirkung wird eroffnet durch Mischungen unterschiedlicher atomarer Elemente mit unterschiedlicher Statistik, unterschiedlichen Wechselwirkungen und Massen. 
 
Diese Dissertation stellt Experimente in einem System wechselwirkender, entarteter Mischungen aus fermionischen 40K und bosonischen 87Rb Quantengasen vor. Ein zusammen mit S. Ospelkaus aufgebautes Experiment zur Erzeugung von Fermi-Bose Mischungen wird detailliert vorgestellt. 
Bose-Einstein-Kondensation von 87Rb und die Erzeugung eines quantenentarteten Fermigases aus 40K wird demonstriert. 
 
Im Rahmen dieser Arbeit wurden Mischungen aus 87Rb und 40K mit den bislang grosten Teilchenzahlen realisiert. Die entsprechend hohen Dichten fuhren zur Beobachtung starker kontrahierender Effekte der attraktiven Fermi-Bose-Wechselwirkung, die das Verhalten der Mischung fundamental beeinflussen. Eindeutige Signaturen eines Kollapses fur grose Mischungen werden aufgezeigt, und das dynamische Verhalten der kollabierenden Mischung wird untersucht. Die beobachteten Instabilitaten haben wichtige Konsequenzen fur die Bestimmung der Wechselwirkungsparameter. 
 
Erstmalig wird die Durchstimmung heteronuklearer Wechselwirkung mittels Feshbach-Resonanzen demonstriert. Dies fuhrt zur Beobachtung aller Phasen harmonisch gespeicherter Mischungen: stabile, attraktiv oder repulsiv wechselwirkende Mischungen sowie Phasenseparation und ein kontrollierter Feshbach-induzierter Kollaps. 
 
Das hier beschriebene Experiment wurde von Beginn an fur Messungen in dreidimensionalen optischen Gittern ausgelegt. Fur homonukleare Systeme hat weltweit eine beeindruckende Reihe von Ergebnissen gezeigt, dass solche perfekten optischen Kristallgitter als Quantensimulatoren fur Festkorperphanomene dienen konnen. In dieser Dissertation wurde erstmalig eine Fermi-Bose Mischung in ein dreidimensionales optisches Gitter geladen. Dabei wird beobachtet, dass schon eine kleine Beimengung von fermionischen Atomen die Koharenz der bosonischen Wolke in betrachtlichem Mase beeinflusst. Diese Beobachtung ist momentan Gegenstand intensiver theoretischer Untersuchungen; es werden Beziehungen zu Thermodynamik im Gitter, Modellen in ""mean field"" Naherung und unordnungsgetriebenen Lokalisierungsphanomenen in Festkorpern diskutiert. 
 
Als wichtiger Schritt fur heteronukleare Systeme wird die Erzeugung ultrakalter Feshbach-Molekule vorgestellt. Diese ultrakalte chemische Reaktion findet an einer heteronuklearen Feshbachresonanz statt. Das beobachtete Spektrum der Bindungsenergien und die Effizienz der Molekulassoziation werden im Rahmen eines universellen Modelles (in Zusammenarbeit mit F. Deuretzbacher, K. Plassmeier und D. Pfannkuche) untersucht. Die langlebigen Molekule werden an einzelnen Gitterplatzen eines dreidimensionalen optischen Gitters in einem wohldefinierten Rovibrationszustand erzeugt, was sie zu idealen Kandidaten fur einen weiteren Transfer in den absoluten internen und externen Grundzustand mittels Femtosekunden-Frequenzkammtechnologie macht. Solche ultrakalten polaren Molekuleeignen sich als Bausteine neuartiger skalierbarer Quantencomputer, fur Quantengase mit langreichweitiger Wechselwirkung und fur fundamentale Messungen zu diskreten Symmetrieverletzungen in Atomen. 
Starting with the observation of Bose-Einstein condensation in single-component bosonic gases and Fermi degeneracy in spin-polarized Fermi gases, the (still relatively young) field of ultracold quantum gases is rapidly expanding to studies of mixed systems. Ultimately, mixtures of different atomic species with different statistics, different trapping properties, interactions and masses open up the widest spectrum of possibilities for quantum simulation, ultracold chemistry, exotic pairing phases, disorder-related many-body physics and long-range interacting systems. 
 
This thesis presents experiments in a system of interacting quantum degenerate fermionic 40K and bosonic 87Rb atoms. An experimental setup for producing Fermi-Bose mixtures which has been set up together with S. Ospelkaus is described in detail. The observation of both bosonic and fermionic degeneracy is demonstrated; in the case of fermionic atoms, showing the quantum behavior requires thorough analysis, which is rewarded by the observation of an ideal macroscopic Fermi sea. 
 
This thesis presents mixtures with the so far largest particle numbers for the 40K-87Rb system and discusses measurements with high densities where strong mean-field contracting interaction effects affect the behavior of the mixture. Clear signatures of the mean field collapse of large mixtures are observed, the dynamics of the collapsing sample is studied and important consequences for the interaction parameters are discussed. 
 
Tuning of interactions in a harmonically trapped heteronuclear mixture by means of Feshbach resonances is demonstrated for the first time, allowing all phases of the harmonically trapped mixture to be observed: stable heteronuclear interaction and repulsion as well as phase separation and a controlled Feshbach-induced collapse. 
 
From the very beginning, the setup described here has been designed for experiments in 3-dimensional optical lattices. In recent years, an impressive series on experiments with homonuclear systems has shown that such perfect optical crystals can be used as quantum simulators for condensed-matter phenomena. Within this thesis, a heteronuclear system, in particular a Fermi-Bose mixture, has been loaded into a 3D optical lattice for the first time, and only a very small fraction of fermionic ""impurities"" has been found to significantly reduce the coherence in the bosonic cloud. The observations are currently the subject of intense theoretical analysis, and there are important connections to thermodynamics, advanced mean field models and disorder physics. 
 
As a long-awaited step for heteronuclear systems, formation of ultracold Feshbach molecules from two different atomic elements is demonstrated. This ultracold chemical reaction takes place at temperatures in the nK regime at a heteronuclear Feshbach resonance. A detailed understanding of the observed energy spectrum and the molecular association process has been developed in collaboration with F. Deuretzbacher, K. Plassmeier and D. Pfannkuche in terms of a universal model. Long-lived molecules are produced within single wells of the 3D-optical lattice in a well-defined rovibrational state, which makes them an ideal basis for coherent transfer into both the external and internal ground state using readily available femtosecond technology. Such all ground state polar molecules open up the way towards ultracold long-range dipolar interacting systems. They may be used as building blocks of novel quantum gases, scalable quantum computation schemes and for fundamental measurements of P and T violating effects in atoms.",2007,
Epidemiological and clinical aspects of skin diseases observed in workers handling cement in Burkina Faso,"Background: The building and public works sector is booming in recent years in Burkina Faso and exposes workers to different materials including cement. The aim of this study was to describe the epidemiological and clinical characteristics of skin diseases observed among cement workers in Burkina Faso. Patients and Methods: We conducted a cross-sectional descriptive study, from April to June 2015, on 22 sites in the cities of Ouagadougou and Bobo Dioulasso. The study concerned workers on construction sites, handling cement and giving their agreement. A standardized survey form was designed for socio-demographic and dermatological examination data collection. Results: The study included 300 workers, all male. The median age was 29 years old. The extreme ages were 16 and 66 years old. The workers were masons (39.7%) and apprentice masons (34.7%). Two hundred and sixteen workers had a history of cement dermatitis and 56 had already observed a temporary cessation of work. Of the 300 workers, 265 had at least one dermatoses. The dermatoses prevalence was 88.3%. We recorded a prevalence of 12% cement contact dermatitis including 8.7% irritation contact dermatitis and 3.3% allergic contact dermatitis. We observed a total of 369 dermatoses including 237 keratoderma and 69 mycotic dermatoses. Conclusion: Dermatosis is common among workers who handle cement. They are dominated by keratoderma, mycotic dermatosis and cement contact dermatitis. Etiological investigations will be necessary in our context.",2020,Our Dermatology Online
Knowledges for Effective Integration of Mathematics and Science,"The level and complexity of knowledge held by a teacher affects what is done in classrooms and, as a consequence, also influences what students learn (Fennema and Franke 1992). Integrating mathematics and science requires the teacher in question to have a certain level of both content knowledge and pedagogical knowledge to educate students in both disciplines successfully (Frykholm and Glasson 2005).Â  Consequently, the knowledges required to effectively instruct students in an integrated setting is a vital element of the successful implementation of such lessons.Â  Research indicates that a teacherâ€™s content knowledge in the subjects he/she teaches is of utmost importance, this translates to an integrative setting â€“ content knowledge and pedagogical content knowledge within both mathematics and science must be of a high standard to implement these lessons successfully.Â  This can be achieved through provision of the relevant resources, a working support structure, and teacher training.",2014,
Stephanie Hubert : A comparison of multivariate methods for the detection of Differential Item Functioning,"This thesis focuses on the comparison of three, recently developed, methods for the detection of differential item functioning (DIF) in the measurement of latent traits, such as abilities or attitudes in psychological or educational research. Identifying group differences is crucial for the correct and unbiased assessment of questionnaires. Over time, various methods have been proposed in literature to identify test items where DIF is present, which range from test statistics to modeling approaches. Most of these methods have some drawbacks in terms of usability or underlying assumptions, e.g. that they cannot deal with multi-categorical variables or that they focus on the global test level and do not identify DIF on the item level. The methods presented in this thesis, however, represent an advancement in the sense, that they try to overcome these problems and limitations. A commonality of the methods, that are described in the following, is, that they can cope with both multiple, potentially DIF-inducing, variables and any form of predictor variables, either metric or categorical. The advantage is a flexible and less restricted approach for the detection of DIF. The first considered method is called DIFlasso and is based on an extension of the widelyknown Rasch model, that involves additional group-specific parameters to incorporate group differences. DIF-detection is performed using a penalized estimation approach. The second method, DIFboost, uses boosting techniques to determine additional group-specific parameters in the extended Rasch model by means of iterative updating of so-called base learners. The third approach called DIFtree relies on model based recursive partitioning resulting in a decision tree for every item that carries out DIF. The aim of this thesis is to compare the three methods regarding their methodological approaches and by means of both an extensive simulation study and an applied example.",2017,
Feature and decision level fusion using multiple kernel learning and fuzzy integrals,"Kernel methods for classification is a well-studied area in which data are implicitly mapped from a lower-dimensional space to a higher-dimensional space to improve classification accuracy. However, for most kernel methods, one must still choose a kernel to use for the problem. Since there is, in general, no way of knowing which kernel is the best, multiple kernel learning (MKL) is a technique used to learn the aggregation of a set of valid kernels into a single (ideally) superior kernel. The aggregation can be done using weighted sums of the pre-computed kernels, but determining the summation weights is not a trivial task. A popular and successful approach to this problem is MKL-group lasso (MKLGL), where the weights and classification surface are simultaneously solved by iteratively optimizing a min-max optimization until convergence. In this work, we propose an â„“p-normed genetic algorithm MKL (GAMKLp), which uses a genetic algorithm to learn the weights of a set of pre-computed kernel matrices for use with MKL classification. We prove that this approach is equivalent to a previously proposed fuzzy integral aggregation of multiple kernels called fuzzy integral: genetic algorithm (FIGA). A second algorithm, which we call decision-level fuzzy integral MKL (DeFIMKL), is also proposed, where a fuzzy measure with respect to the fuzzy Choquet integral is learned via quadratic programming, and the decision value-viz., the class label-is computed using the fuzzy Choquet integral aggregation. Experiments on several benchmark data sets show that our proposed algorithms can outperform MKLGL when applied to support vector machine (SVM)-based classification.",2015,2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)
Dynamics of Cortical Local Connectivity during Sleep-Wake States and the Homeostatic Process.,"Sleep exerts modulatory effects on the cerebral cortex. Whether sleep modulates local connectivity in the cortex or only individual neural activity, however, is poorly understood. Here we investigated functional connectivity, that is, covarying activity between neurons, during spontaneous sleep-wake states and during and after sleep deprivation using calcium imaging of identified excitatory/inhibitory neurons in the motor cortex. Functional connectivity was estimated with a statistical learning approach glasso and quantified by ""the probability of establishing connectivity (sparse/dense)"" and ""the strength of the established connectivity (weak/strong)."" Local cortical connectivity was sparse in non-rapid eye movement (NREM) sleep and dense in REM sleep, which was similar in both excitatory and inhibitory neurons. The overall mean strength of the connectivity did not differ largely across spontaneous sleep-wake states. Sleep deprivation induced strong excitatory/inhibitory and dense inhibitory, but not excitatory, connectivity. Subsequent NREM sleep after sleep deprivation exhibited weak excitatory/inhibitory, sparse excitatory, and dense inhibitory connectivity. These findings indicate that sleep-wake states modulate local cortical connectivity, and the modulation is large and compensatory for stability of local circuits during the homeostatic control of sleep, which contributes to plastic changes in neural information flow.",2020,Cerebral cortex
Selection of ordinally scaled independent variables with applications to international classification of functioning core sets,"Summary.â€‚ Ordinal categorial variables arise commonly in regression modelling. Although the analysis of ordinal response variables has been well investigated, less work has been done concerning ordinal predictors. We consider so-called international classfication of functioning core sets for chronic widespread pain, in which many ordinal covariates are collected. The effect of specific international classification of functioning variables on a subjective measure of physical health is investigated, which requires strategies for variable selection. In this context, we propose methods for the selection of ordinally scaled independent variables in the classical linear model. The ordinal structure is taken into account by use of a difference penalty on adjacent dummy coefficients. It is shown how the group lasso can be used for the selection of ordinal predictors, and an alternative blockwise boosting procedure is proposed. Both methods are discussed in general, and applied to international classification of functioning core sets for chronic widespread pain.",2011,Journal of The Royal Statistical Society Series C-applied Statistics
Fast Rate Analysis of Some Stochastic Optimization Algorithms,"In this paper, we revisit three fundamental and popular stochastic optimization algorithms (namely, Online Proximal Gradient, Regularized Dual Averaging method and ADMM with online proximal gradient) and analyze their convergence speed under conditions weaker than those in literature. In particular, previous works showed that these algorithms converge at a rate of O(ln T/T) when the loss function is strongly convex, and O(1/âˆšT) in the weakly convex case. In contrast, we relax the strong convexity assumption of the loss function, and show that the algorithms converge at a rate O(ln T/T) if the expectation of the loss function is locally strongly convex. This is a much weaker assumption and is satisfied by many practical formulations including Lasso and Logistic Regression. Our analysis thus extends the applicability of these three methods, as well as provides a general recipe for improving analysis of convergence rate for stochastic and online optimization algorithms.",2016,
"Study of cytokines microenvironment during autoimmune diseases in patients from Bobo-Dioulasso, Burkina Faso","The development of autoimmun diseases involves an intricate network of cytokines that recruit and activate TREGS/ TH17 cells. This study was aimed to compare PBMC levels of pro-inflammatory and anti-inflammatory cytokines in AID patients and non-AID controls from Bobo Dioulasso. We prospectively enrolled 17 patients who had autoimmune diseases and 17 healthy donors at University Hospital SOURO SANOU and other privates clinical, from Bobo Dioulasso, BURKINA FASO, between november 2014 and december 2015 for this cohort study. Demographic characteristics and cytokines profile: IL-2, IL-10, IL-17A, IL-21, IL-22, IL-23, TNF-Î± and TGF-Î²) were determined. We used the immunoenzymatic technology to assess the titer of cytokines. We found that there was no significant variation of TNF-Î± level in normal controls and autoimmune diseases patients(P=0.09).The concentrations of cytokines anti-inflammatory such as IL-2, IL-10 and TGF-Î² in PBMC supernatant were significantly higher in the control group than in the group of patients with autoimmun diseases (respectively P= 0.1;0.004;0.016).The supernatant levels of IL-17A, IL-21, IL-22, IL-23 and IFN-Ñƒ significantly increased in autoimmun diseases in comparison to healthy controls (respectively P=0.00001; 0.001, 0.006; 0.008 and 0.000).We also found that patients with SLE and RA exhibit increased levels of IL-22, IL-21, also, patients with RA exhibit increased levels of IL-17A. Patient with HT diseases exhibit increased levels of TGF-Î². Based on the level of cytokines such as IL-17A and IFN-Ñƒ, we demonstrate that the phenotype IL-17+, IFN-Ñƒ+ T cell is major in AID. We have shown that patients with autoimmune diseases from Bobo Dioulasso, Burkina Faso have proinflammatory cytokines produced by TH17 cells such as (IL-17A, IL-21, IL-22, IL-23 and IFN-Î³) are abundantly secreted in PBMC supernatants. While anti-inflammatory cytokines in the regulatory T-cell pathway (IL-2, IL-10 and TGF-Î²) are poorly secreted during autoimmune processes. We also found in the study a high prevalence of the phenotype of the following TH17 (IL-17 +, IFN-Î³ + T cells). We propose that the therapeutic targets be directed to the phenotypes to fight AID. Keywords : Phenotype, Cytokines, Autoimmun Diseases",2017,
Cryptand-imidazolium supported total synthesis of the lasso peptide BI-32169 and its d-enantiomer.,"Lasso peptides are attracting increasing attention due to their broad range of biological activities. The knot topology of lasso peptides, which contains an isopeptide bond-bridged macrocycle threaded by its C-terminal tail, has been proven to be an important structural feature for their bioactivities. The preparation of lasso peptides has been achieved by biosynthetic methods; nevertheless, a chemical synthesis of lasso peptides has not been described so far. Herein, a cryptand-imidazolium complex is designed as a multi-linker support and applied in the chemical synthesis of the lasso peptide BI-32169. Furthermore, the chiral switching of the support and the introduction of d-amino acids enable the synthesis of the d-enantiomer of BI-32169, which shows not only a strong glucagon receptor antagonist activity, but also a much higher enzymatic stability compared to the l-lasso peptide.",2019,Chemical communications
Variable Selection for Confounding Adjustment in High-dimensional Covariate Spaces When Analyzing Healthcare Databases,"Background: Data-adaptive approaches to confounding adjustment may improve performance beyond expert knowledge when analyzing electronic healthcare databases and have additional practical advantages for analyzing multiple databases in rapid cycles. Improvements seemed possible if outcome predictors were reliably identified empirically and adjusted. Methods: In five cohort studies from diverse healthcare databases, we implemented a base-case high-dimensional propensity score algorithm with propensity score decile-adjusted outcome models to estimate treatment effects among prescription drug initiators. The original variable selection procedure based on the estimated bias of each variable using unadjusted associations between confounders and exposure (RRCE) and disease outcome (RRCD) was augmented by alternative strategies. These included using increasingly adjusted RRCD estimates, including models considering >1,500 variables jointly (Lasso, Bayesian logistic regression); using prediction statistics or likelihood-ratio statistics for covariate prioritization; directly estimating the propensity score with >1,500 variables (Lasso, Bayesian regression); or directly fitting an outcome model using all covariates jointly (Lasso, Ridge). Results: In five example studies, most tested augmentations of the base-case hdPS did not meaningfully change estimates in light of wide confidence intervals except for Bayesian regression and Lasso to estimate RRCD, which moved estimates minimally closer to the expectation in three of five examples. The direct outcome estimation with Lasso performed worst. Conclusion: Overall, the basic heuristic of variable reduction in high-dimensional propensity score adjustment performed, as well as alternative approaches in diverse settings. Minor improvements in variable selection may be possible using Bayesian outcome regression to prioritize variables for propensity score estimation when outcomes are rare. See video abstract at, http://links.lww.com/EDE/B162.",2017,Epidemiology
Releasing the A3 pulley and leaving flexor superficialis intact increases pinch force following the Zancolli lasso procedures to prevent claw deformity in the intrinsic palsied finger.,"Objective estimates of fingertip force magnitude following surgery to prevent digital metacarpophalangeal (MCP) hyperextension (clawing) in cases of paralysis of the hand's intrinsic muscles will assist clinicians in setting realistic expectations for post-operative pinch strength. We used a cadaveric/optimization approach to predict and confirm the maximal biomechanically possible fingertip force in the intrinsic palsied hand before and after two popular tendon transfer methods to the volar plate of the MCP joint. Both surgeries were also evaluated after release of the A3 pulley-a modification predicted by our published computer model of the forefinger to increase fingertip force magnitude. We predicted maximal static fingertip force by mounting eight fresh cadaveric hands on a frame, placing their forefinger in a functional posture (neutral abduction, 45 degrees of flexion at the MCP and proximal interphalangeal joints, and 10 degrees at the distal interphalangeal joint) and pinning the distal phalanx to a 3D dynamometer. We pulled on individual tendons with tensions up to 25% of maximal isometric force of their associated muscle and measured fingertip force and torque output. Using these measurements, we predicted the optimal combination of tendon tensions that maximized palmar force (analogous to pinch force, directed perpendicularly from the midpoint of the distal phalanx, and in the plane of finger flexion-extension) for four cases: (i) the non-paretic case (all muscles available), (ii) intrinsic palsied hand (no intrinsic muscles functioning), (iii) transfer of flexor superficialis tendon to the volar plate of the MCP (Zancolli lasso) in the intrinsic palsied hand, and (iv) leaving flexor superficialis intact and transferring a tendon of comparable strength to the volar plate of the MCP in the intrinsic palsied hand. Lastly, we applied these optimal combinations of tension to the cadaveric tendons and measured fingertip output. With the A3 pulley intact, the maximal palmar force in cases (ii)-(iv) averaged 48 +/- 23% SD (non-paretic = 100%; case (iv) (61 +/- 25%) > cases (ii) and (iii) (43 +/- 23% and 39 +/- 19%, respectively), p < 0.05). Releasing the A3 pulley significantly increased the average palmar force in cases (ii)-(iv) (73 +/- 42%, p < 0.05), with no significant differences among them. Thus, releasing the A3 pulley may improve palmar force magnitude when it is necessary to transfer the digit's own flexor superficialis tendon to the volar plate of the MCP to prevent clawing in the intrinsic palsied hand.",2002,Journal of orthopaedic research : official publication of the Orthopaedic Research Society
Iatrogenic anterior papillary muscle rupture.,"Iatrogenic injury to the mitral valve or subvalvular apparatus is an uncommon, but severe complication. We present the case of a 40-year-old man with permanent atrial fibrillation accepted for circumferential ablation of the four pulmonary veins with the CARTO system. During the procedure, the Lasoo deflectable catheter (Lasso Nav, Biosense Webster) was trapped in the mitral subvalvular apparatus. Several maneuvers performed to free the device were ultimately successful, and the procedure was terminated satisfactorily. Nonetheless, the control echocardiography showed severe mitral regurgitation of the posterior leaflet, secondary to rupture of the anterior papillary muscle, warranting urgent surgery. A medial sternotomy and left atriotomy were carried out, and the mitral valve was repaired by annuloplasty and implantation of four polytetrafluoroethylene neochords in the posterior leaflet, with a good final outcome. In Figures 1 and 2, the intense abrasion (*) and damage resulting from the maneuvers to free the device are evident, as well as the sectioned papillary muscle (arrows). In a recent registry of 8745 patients undergoing ablation for atrial fibrillation, only 1 case of valve injury (without specifying the type) was recorded (Cappato et al., 2005). In a retrospective review of 348 patients, however, a significantly higher incidence (0.9%) was reported (Kesek et al., 2007). Most of these patients require a surgical intervention to extract the device or repair the mitral valve. Figure 1. Figure 2.",2013,Revista espanola de cardiologia
Ubiquitous Parameter Anthology For Energy In Wireless Sensor Network: A Statistical Analysis,"In this paper, statistical and machine learning tools are used to reduce the variety of parameters by analyzing the dependency between these parameters and the average energy consumption of a specific application, permitting very appropriate kinds to be chosen. The few techniques are used for correlation analysis, namely Pearson correlation, Spearman correlation; Lasso regularization as well as P-value are used for statistical analysis and suggested a model. Afterward, the random forest regression is applied to evaluate the exactness of prediction for each original and even decreased parameter in estimating the average energy consumption of the wireless sensor network.",2019,
Freud's Continuity Thesis,"The motivating force for the present paper comes from a recent paperby Dell, Schwartz, Martin, Saffran, and Gagnon (1997), whose model isconnectionist and incorporates interactive activation, cascade processing,and feedback among the levels. It is a two-step/three-level computationalsystem of lexical retrieval for simulating picture naming. The three hierarchi-cal levels are semantic, lexical, and phonological. The semantic level com-prises the units that represent the concept of a pictured object. Test wordsfor naming in the Dell study were drawn from The Philadelphia NamingTest (Roach, Schwartz, Martin, Greweal, & Brecher, 1996). Dell et al. (1997)arbitrarily assumed (i.e., set the values) that each object would correspondto 10 mathematical units. The 10 units for each picture to be named connectto that objectâ€™s word node by â€˜â€˜excitatory bidirectional connectionsâ€™â€™ (p.805). Each word node connects to its phoneme nodes in a similar fashion.[See Dell et al. (1997, pp. 805â€“809) for the mathematical details of the linearactivation function equation and how the numerical values for connectionweights and decay rates are set.]As an example, a picture of a cat is presented (see Fig. 1). The picture isperceived by the visual system (outside Dellâ€™s model). The 10 units (â€˜â€˜seman-tic nodesâ€™â€™) are each given a â€˜â€˜joltâ€™â€™ of activation of 10, for a total jolt of100. The metaphor jolt is a numerical valueâ€”not an electrical shock! Theword node for â€˜â€˜catâ€™â€™ will be activated and will subsequently activate itscomponent phonemes /k/, /ae/, and /t/. Figure 1 demonstrates the lexicalassociates such as â€˜â€˜dogâ€™â€™ and â€˜â€˜rat.â€™â€™ The former bears only a semantic rela-tion with cat, while he latter bears both a semantic and a phonological rela-tion with cat. Furthermore, Fig. 1 demonstrates phonological associativestructure in that rat and mat share the coda (ï¬nal vowel1 consonant, the",1999,Brain and Language
Plasmodium knowlesi gene expression differs in ex vivo compared to in vitro blood-stage cultures,"Background: Plasmodium knowlesi is one of five Plasmodium species known to cause malaria in humans and can result in severe illness and death. While a zoonosis in humans, this simian malaria parasite species infects macaque monkeys and serves as an experimental model for in vivo, ex vivo and in vitro studies. It has underpinned malaria discoveries relating to host-pathogen interactions, the immune response and immune evasion strategies. This study investigated differences in P. knowlesi gene expression in samples from ex vivo and in vitro cultures. Methods: Gene expression profiles were generated using microarrays to compare the stage-specific transcripts detected for a clone of P. knowlesi propagated in the blood of a rhesus macaque host and then grown in an ex-vivo culture, and the same clone adapted to long-term in vitro culture. Parasite samples covering one blood-stage cycle were analysed at four-hour intervals. cDNA was generated and hybridized to an oligoarray representing the P. knowlesi genome. Two replicate experiments were developed from in vitro cultures. Expression values were filtered, normalized, and analysed using R and Perl language and applied to a sine wave model to determine changes in equilibrium and amplitude. Differentially expressed genes from ex vivo and in vitro time points were detected using limma R/Bioconductor and gene set enrichment analysis (GSEA). Results: Major differences were noted between the ex vivo and in vitro time courses in overall gene expression and the length of the cycle (25.5 hours ex vivo; 33.5 hours in vitro). GSEA of genes up-regulated ex vivo showed an enrichment of various genes including SICAvar, ribosomalassociated and histone acetylation pathway genes. In contrast, certain genes involved in metabolism and cell growth, such as porphobilinogen deaminase and tyrosine phosphatase, and one SICAvar gene, were significantly up-regulated in vitro. Conclusions: This study demonstrates how gene expression in P. knowlesi blood-stage parasites can differ dramatically depending on whether the parasites are grown in vivo, with only one cycle of development ex vivo, or as an adapted isolate in long-term in vitro culture. These data bring emphasis to the importance of studying the parasite, its biology and disease manifestations in the context of the host.",2015,
Abstract 1479: A miRNA signature distinguishing low-grade and high-grade gliomas shows miR-21 and 210 as promising biomarkers of aggressive phenotype and prognosis,"Proceedings: AACR Annual Meeting 2014; April 5-9, 2014; San Diego, CA

BACKGROUND. Gliomas account for approximately 80% of all primary malignant brain tumors and, despite advances in clinical care, remain still associated with poor prognosis. They are currently classified by the WHO system in Low Grade Gliomas (LGGs, WHO I, II) and High Grade Gliomas (HGGs, WHO grade III, IV) based on histological features such as nuclear atypia, mitotic figures, microvascular proliferation and necrosis. LGGs and HGGs share several morphological traits and pathways abnormalities but have a different clinical behaviour. miRNAs have emerged as key regulators of many biological processes mediating genesis and dissemination of cancer. Molecular analyses based on miRNA measurements have shown to be able to better stratify and discriminate the two tumor types. We hypothesize the comparison of miRNA profile between LGGs and HGGs may lead to the identification of miRNAs associated with the most aggressive form, that is GBM (Glioblastoma Multiforme, WHO IV).

MATERIAL AND METHODS. miRNA expression profiling was performed in 8 LGGs, 24 HGGs, and 4 Normal Brain Tissues (NBT) by using the Affymetrix GeneChipÂ® miRNA Array 1.0. Data analysis was performed by Partek Genomic Suite software, setting a significative p-value â‰¤ 0.01 and a fold change cutoff of 2. A relative quantification method (RT-qPCR) with standard curve was used to validate the 22 miRNA signature resulted by array analysis. The prognostic performance of the 13 validated miRNAs was estimated by using the Tumor Cancer Genome Atlas (TCGA). RESULTS. miRNA profiling identified 80 miRNAs differentially expressed in LGGs vs NBT and 71 in HGGs vs NBT. A panel of 22 miRNAs clearly differentiated HGGs and LGGs. RT-qPCR assay confirmed differential expression for 13 out of the 22 miRNAs in LGG vs HGG. In addition, 6 among our 13-miRNA signature (miR-21, miR-210, miR-22, miR-155, miR-223, miR-219-2-3p) were found to be significantly associated with GBM molecular subtypes when compared on TCGA dataset. Moreover miR-21 and miR-210 show correlation with worse overall survival in both univariate and multivariate Cox Regression analysis (HR 1.19 95% CI 1.008-1.406 p=0.04; and 1.18 95%C 1.018-1.375 p=0.03).

CONCLUSIONS. We show the comparison of LGGs and HGGs profiles is able to identify miRNAs associated with invasive phenotype. Our results support a direct involvement of miR-21 and miR-210 in glioma progression, suggesting they may represent promising targets for new therapeutic approaches in gliomas.

Citation Format: Raffaela Barbano, Barbara Pasculli, Orazio Palumbo, Marco Galasso, Stefano Volinia, Vincenzo D'Angelo, Michelina Coco, Lucia Dimitri, Massimiliano Copetti, Vanna Maria Valori, Evaristo Maiello, Massimo Carella, Vito Michele Fazio, Paola Parrella. A miRNA signature distinguishing low-grade and high-grade gliomas shows miR-21 and 210 as promising biomarkers of aggressive phenotype and prognosis. [abstract]. In: Proceedings of the 105th Annual Meeting of the American Association for Cancer Research; 2014 Apr 5-9; San Diego, CA. Philadelphia (PA): AACR; Cancer Res 2014;74(19 Suppl):Abstract nr 1479. doi:10.1158/1538-7445.AM2014-1479",2014,Cancer Research
A potÃªncia do â€œnÃ£oâ€: Alessandro Baricco e Herman Melville â€“ um diÃ¡logo,"O autor italiano contemporÃ¢neo Alessandro Baricco investe na intertextualidade (SAMOYAULT, 2008) como um de seus procedimentos narrativos mais recorrentes. Esta revela uma concepcao de mundo que elege o afastamento das certezas, o elogio da oralidade e da narrativa, a multiplicidade de pontos de vista, a exaltacao de tipos a margem dos sistemas, o heroismo da derrota, a apologia da queda e da renuncia. O presente estudo visa analisar dois casos literarios em matriz comparatista: a) Novecentos e Bartleby e b) Bartleboom, Plasson e Bartleby, que ilustram de que forma o autor turines propoe esse dialogo intertextual com a obra Bartleby, o escrivao de H. Melville, sobretudo, a partir do estudo de AGAMBEN (1993) a respeito da â€œPotencia do naoâ€. The contemporary Italian author Alessandro Baricco invests in intertextuality (SAMOYAULT, 2008) as one of his most recurrent fictional procedures. It reveals a conception of the world that selects the removal of certainties, the praise of orality and narrative, the multiplicity of points of view, the exaltation of types at the margins of systems, the heroism of defeat, the fall and renunciationâ€™s apology.The present study aims at analyzing two literary cases in a comparative matrix: a) Novecentos and Bartleby and b) Bartleboom, Plasson and Bartleby, which illustrate how the Turin author proposes this intertextual dialogue with Bartleby H. Melvilleâ€™s on the basis of the study by AGAMBEN (1993) regarding the â€œPower of noâ€.",2019,Olho d'Ã¡gua
The Best Model of LASSO With The LARS (Least Angle Regression and Shrinkage) Algorithm Using Mallowâ€™s Cp,"Multicollinearity often occurs in regression analysis. Multicollinearity is a condition of correlation between independent variables which is a problem. One method that can overcome multicollinearity is the LASSO (Least Absolute Shrinkage and Selection Operator) method. LASSO is able to help to shrink multicollinearity and improve the accuracy of linear regression models. Estimators of LASSO parameters can be solved by the LARS (Least Angle Regression and Shrinkage) algorithm by algorithm which calculates the correlation vector, the largest absolute correlation value, equiangular vector, inner product vector, and determines the LARS algorithm limiter for LASSO. Selecting the best model using the Mallowâ€™s Cp statistics. The smallest Mallowâ€™s Cp value will be selected as the best model. LASSO method with a more detailed procedure with LARS algorithm and selecting the best model using the Mallowâ€™s Cp statistics is discussed in this paper. World Scientific News 116 (2019) 245-252 -246",2019,
Abstract 2893: Integrated genomic meta-analysis of colorectal cancer by elastic-net.,"To identify combinatorial sets of known, putative and new cancer drivers responsible for colorectal cancer (CRC) development and other associated specific clinical outcomes, we have developed an integrative analysis method for cancer genome data. This approach is based on the elastic-net algorithm that we have applied to genomic data from the Cancer Genome Atlas (TCGA) Project. Our supervised analysis simultaneously assesses the contribution of i) copy number variation (CNV), ii) gene expression, iii) miRNA, iv) methylation and v) cancer mutations to clinical features. The ongoing TCGA project is generating genomic and clinical data sets from different tumor types including CRC. These detailed catalogues of genetic changes in cancer genomes will continue to provide us with new insights about cancer development. However, extracting biologically/clinically relevant information from TCGA9s diverse and large cancer genome data remains a challenge. In attempt to overcome this challenge, we use regularized regression method: elastic-net that improves on â€œthe least absolute shrinkage and selection operatorâ€ (Lasso). To demonstrate the performance and validity of this approach, we showed that elastic-net successfully identified i) synthetic genes that have their CNVs perfectly associated with stages from a simulated data ii) TGFBR2 and other driver genes that have mutations associated with CRCs that demonstrate microsatellite instability CRC from TCGA data, and iii) IDH1 that obtained mutations associated with survival according to glioblastoma (GBM) data. In the next phase of the study, we identified the top ranked genes that delineate key clinical features such as TNM stages of CRC. We have identified a series of candidate genes that may indicate clinical stages including novel candidates on chromosome 8. Overall, we have successfully demonstrated that our approach allows for an integrative and highly robust supervised analysis of TCGA data. Citation Format: HoJoon Lee, Patrick Flaherty, Hanlee P. Ji. Integrated genomic meta-analysis of colorectal cancer by elastic-net. [abstract]. In: Proceedings of the 104th Annual Meeting of the American Association for Cancer Research; 2013 Apr 6-10; Washington, DC. Philadelphia (PA): AACR; Cancer Res 2013;73(8 Suppl):Abstract nr 2893. doi:10.1158/1538-7445.AM2013-2893",2013,Cancer Research
Least Squares Approximation for a Distributed System,"In this work, we develop a distributed least squares approximation (DLSA) method that is able to solve a large family of regression problems (e.g., linear regression, logistic regression, and Cox's model) on a distributed system. By approximating the local objective function using a local quadratic form, we are able to obtain a combined estimator by taking a weighted average of local estimators. The resulting estimator is proved to be statistically as efficient as the global estimator. Moreover, it requires only one round of communication. We further conduct shrinkage estimation based on the DLSA estimation using an adaptive Lasso approach. The solution can be easily obtained by using the LARS algorithm on the master node. It is theoretically shown that the resulting estimator possesses the oracle property and is selection consistent by using a newly designed distributed Bayesian information criterion (DBIC). The finite sample performance and the computational efficiency are further illustrated by an extensive numerical study and an airline dataset. The airline dataset is 52 GB in size. The entire methodology has been implemented in Python for a de-facto standard Spark system. The proposed DLSA algorithm on the Spark system takes 26 minutes to obtain a logistic regression estimator, whereas a full likelihood algorithm takes 15 hours to obtain an inferior result.",2019,ArXiv
Bayesian LASSO for QTL Mapping,"Mapping quantitative trait loci (QTL) is to identify molecular markers or genomic loci that influence the variation of complex traits. The problem is complicated by the facts that QTL data usually contain a large number of markers across the entire genome and most of them have little or no effect on the phenotype. In this paper, we propose several Bayesian hierarchical models for mapping multiple QTL that simultaneously fit and estimate all possible genetic effects associated with all markers. The proposed models use prior distributions for the genetic effects that are scale mixtures of normal distributions with mean zero and variances distributed to give each effect a high probability of being near zero. We consider two types of priors for the variances, exponential and scaled inverse-2 Ï‡ distributions, which result in Bayesian version of the popular LASSO model and the well-known Student-t model, respectively. Unlike most applications where fixed values are preset for hyperparameters in the priors, we treat all hyperparameters as unknowns and estimate them along with other parameters. Markov chain Monte Carlo (MCMC) algorithms are developed to simulate the parameters from the posteriors. The methods are illustrated using a well known barley data.",2008,
Re-evaluation of the comparative effectiveness of bootstrap-based optimism correction methods in the development of multivariable clinical prediction models.,"Multivariable predictive models are important statistical tools for providing synthetic diagnosis and prognostic algorithms based on multiple patients' characteristics. Their apparent discriminant and calibration measures usually have overestimation biases (known as 'optimism') relative to the actual performances for external populations. Existing statistical evidence and guidelines suggest that three bootstrap-based bias correction methods are preferable in practice, namely Harrell's bias correction and the .632 and .632+ estimators. Although Harrell's method has been widely adopted in clinical studies, simulation-based evidence indicates that the .632+ estimator may perform better than the other two methods. However, there is limited evidence and these methods' actual comparative effectiveness is still unclear. In this article, we conducted extensive simulations to compare the effectiveness of these methods, particularly using the following modern regression models: conventional logistic regression, stepwise variable selections, Firth's penalized likelihood method, ridge, lasso, and elastic-net. Under relatively large sample settings, the three bootstrap-based methods were comparable and performed well. However, all three methods had biases under small sample settings, and the directions and sizes of the biases were inconsistent. In general, the .632+ estimator is recommended, but we provide several notes concerning the operating characteristics of each method.",2020,arXiv: Applications
Unit nonresponse errors in income surveys: a case study,"A survey on the economic and social conditions of households in the city of Modena was carried out in 2002 and in 2006 (two waves) by the CAPP (Centre for Analyses of Public Policies). In the first wave of 2002, each designated sampling unit (i.e., the family) had three units as reserves. If the first refused to be interviewed, the interviewer contacted the three reserves, one after the other, until obtaining either one respondent or four non-participant units. At the end of the survey four categories of units were distinguished: interviewees, refusals, noncontacts, and unused reserves. All units were matched with their corresponding record in the databases of the Ministry of Finance of 2002 and the Census of 2001. The resulting data set permitted the analysis of unit or total nonresponses. The distribution of fiscal income showed different shapes for the four categories, implying a selective participation of the families. The interviewees yielded a positive bias of about 600â‚¬, holding constant other factors. The selection of the significant factors affecting nonresponse was performed via backward elimination in a logit model and with the lasso method. Participation increased as fiscal income and age increased and by education level (secondary school and university degree), while it decreased among entrepreneurs, independent workers, managers, and medium-to-low skilled workers.",2012,Quality & Quantity
Complex Network Short-Term Traffic Forecasting Based on Lasso-NN Model,"Traditional traffic forecasting models are transforming from single section historical data processing to multi-section and multi-timing historical data processing.However,when considering the influence between each section,the fickle traffic condition tends to complicate the forecasting model.Therefore,this paper introduced the Lasso method used in multivariable linear regression and utilized its excellent ability of variable selection.It selected partial high correction sections from a complex multi-section road network.Combined with the non-linear neural network,a new Lasso-NN model was proposed.The result shows that the Lasso-NN model has an overall lower error rate.In the intersection region of the road network,the error rate is less than 9.2% and in the non-intersection region,it is less than 6.7%.",2015,Journal of Shanghai Jiaotong University
High dimensional regression using the sparse matrix transform (SMT),"Regression from high dimensional observation vectors is particularly difficult when training data is limited. More specifically, if the number of sample vectors n is less than dimension of the sample vectors p, then accurate regression is difficult to perform without prior knowledge of the data covariance. In this paper, we propose a novel approach to high dimensional regression for application when n â‰ª p. The approach works by first decorrelating the high dimensional observation vector using the sparse matrix transform (SMT) estimate of the data covariance. Then the decorrelated observations are used in a regularized regression procedure such as Lasso or shrinkage. Numerical results demonstrate that the proposed regression approach can significantly improve the prediction accuracy, especially when n is small and the signal to be predicted lies in the subspace of the observations corresponding to the small eigenvalues.",2010,"2010 IEEE International Conference on Acoustics, Speech and Signal Processing"
DNA methylation-based forensic age estimation in human bone,"DNA methylation is an epigenetic modification of cytosine nucleotides that represents a promising suite of aging markers with broad potential applications. In particular, determining an individualâ€™s age from their skeletal remains is an enduring problem in the field of forensic anthropology, and one that epigenetic markers are particularly well-suited to address. However, all DNA methylation-based age prediction methods published so far focus on tissues other than bone. While high accuracy has been achieved for saliva, blood and sperm, which are easily accessible in living individuals, the highly tissue-specific nature of DNA methylation patterns means that age prediction models trained on these particular tissues may not be directly applicable to other tissues. Bone is a prime target for the development of DNA methylation-based forensic identification tools as skeletal remains are often recoverable for years post-mortem, and well after soft tissues have decomposed. In this study, we generate genome-wide DNA methylation data from 32 individual bone samples. We analyze this new dataset alongside published data from 133 additional bone donors, both living and deceased. We perform an epigenome-wide association study on this combined dataset to identify 108 sites of DNA methylation that show a significant relationship with age (FDR < 0.05). We also develop an age-prediction model using lasso regression that produces highly accurate estimates of age from bone spanning an age range of 49-112 years. Our study demonstrates that DNA methylation levels at specific CpG sites can serve as powerful markers of aging, and can yield more accurate predictions of chronological age in human adults than morphometric markers.",2019,bioRxiv
13th Anglo-French Physical Acoustics Conference (AFPAC2014),"The 13th Anglo-French Physical Acoustics Conference (AFPAC) was held at Selsdon Park Hotel, Croydon near London, United Kingdom, on 15â€17 January 2014. The venue was an excellent location to exchange ideas, regardless whether this happened in the conference room, over lunch at the drinks reception in the conservatory, in the oak panelled bar after the conference dinner or in the local pub next door. Over 45 papers were presented at the conference. There were over 60 delegates from institutions covering four countries. The invited speakers from the French side shared their knowledge about the generation of sound from supersonic jets (Prof Christophe Bailly, Ecole Centrale de Lyon) and the application of ultrasonic microscropy in the nuclear industry (Prof Gilles Despaux, Universite de Montpellier). The UK invited speakers included Prof Malcolm Povey (University of Leeds), who talked about characterisation of the nucleation of crystals using ultrasound, and Prof Bruce Drinkwater (University of Bristol), who captured the audience by speaking about ""ultrasonic lassos"" and ultrasonic particle manipulation. There was a strong representation of laser ultrasonics at the meeting with scientific considerations of problems and applications that range from the macro to the nanoscale. There were also numerous papers on the interaction of elastic and acoustic waves with complex materials and scattering of these waves by materials such as foams or cavitating liquids. Presentations on biomedical applications are increasingly being featured at AFPAC meetings. Talks this year covered topics such as imaging and high-intensity focused ultrasound for therapeutic applications. Finally, there were also several contributions from the field of Non-Destructive Evaluation (NDE) and Structural Health Monitoring (SHM) with talks ranging from the determination of the properties of in vivo wood to ultrasonic scattering techniques and tomographic reconstructions to recover the size and shape of defects in pipes and plates. The UK organising committee was particularly happy to welcome the many French contributors that travelled to Croydon and would like to thank Alain Lhemery and the Societe Francaise d'Acoustique (SFA) for publicising the event in France. We are happy to announce that many of the presented papers will be published in the conference proceedings in Journal of Physics: Conference Series. We would also like to draw the reader's attention to the upcoming 14th AFPAC conference that is scheduled to take place on 14â€16 of January 2015 in Frejus, France.",2012,
Prediction of breed composition in an admixed cattle population.,"Swiss Fleckvieh was established in 1970 as a composite of Simmental (SI) and Red Holstein Friesian (RHF) cattle. Breed composition is currently reported based on pedigree information. Information on a large number of molecular markers potentially provides more accurate information. For the analysis, we used Illumina BovineSNP50 Genotyping Beadchip data for 90 pure SI, 100 pure RHF and 305 admixed bulls. The scope of the study was to compare the performance of hidden Markov models, as implemented in structure software, with methods conventionally used in genomic selection [BayesB, partial least squares regression (PLSR), least absolute shrinkage and selection operator (LASSO) variable selection)] for predicting breed composition. We checked the performance of algorithms for a set of 40Â 492 single nucleotide polymorphisms (SNPs), subsets of evenly distributed SNPs and subsets with different allele frequencies in the pure populations, using F(ST) as an indicator. Key results are correlations of admixture levels estimated with the various algorithms with admixture based on pedigree information. For the full set, PLSR, BayesB and structure performed in a very similar manner (correlations of 0.97), whereas the correlation of LASSO and pedigree admixture was lower (0.93). With decreasing number of SNPs, correlations decreased substantially only for 5% or 1% of all SNPs. With SNPs chosen according to F(ST) , results were similar to results obtained with the full set. Only when using 96 and 48 SNPs with the highest F(ST) , correlations dropped to 0.92 and 0.90 respectively. Reducing the number of pure animals in training sets to 50, 20 and 10 each did not cause a drop in the correlation with pedigree admixture.",2012,Animal genetics
Streamflow prediction using LASSO-FCM-DBN approach based on hydro-meteorological condition classification,"Abstract Streamflow prediction is a challenging task due to the different processes involved in streamflow generation. These different processes have different characteristics of the relationships between hydro-meteorological variables and streamflow, which make it a challenging task to develop single data-driven stream flow prediction models that can map the input-output relationships for all different streamflow regimes. To improve the performance of streamflow prediction, we proposed a flow-regime-dependent approach to map the relationships between hydro-meteorological variables and streamflow based on hydro-meteorological condition classification. This approach integrates the least absolute shrinkage and selection operator (LASSO), Fuzzy C-means (FCM) and Deep Belief Networks (DBN) and therefore referred to as the LASSO-FCM-DBN approach. This approach employs LASSO to select the hydro-meteorological variables which have a significant impact on streamflow, FCM to identify different streamflow regimes, and DBN as a data-driven model to map the nonlinear and complex relationships between the selected hydro-meteorological variables and streamflow within different flow regimes. To assess the performance of the proposed approach, two comparative studies were carried out â€“ 1) the multi-variable FCM was compared to the traditional single-variable threshold-based method; and 2) the performance of the DBN was compared to a traditional Artificial Neural Networks (ANNs) model. Two stations in the Tennessee River, USA were used as the case study. The results demonstrate that the performance of the multi-variable-based FCM classification method is better and more stable than the traditional threshold-based single-variable method, due to the sensitivity of the single-variable method to different threshold values. In addition, DBNs performed better than traditional ANNs in all three statistical measures considered. Overall, the LASSO-FCM-DBN multi-model system significantly improved the performance of streamflow prediction and is therefore a valuable tool for water resources management and planning.",2020,Journal of Hydrology
Proving non-termination,"The search for proof and the search for counterexamples (bugs) are complementary activities that need to be pursued concurrently in order to maximize the practical success rate of verification tools.While this is well-understood in safety verification, the current focus of liveness verification has been almost exclusively on the search for termination proofs. A counterexample to termination is an infinite programexecution. In this paper, we propose a method to search for such counterexamples. The search proceeds in two phases. We first dynamically enumerate lasso-shaped candidate paths for counterexamples, and then statically prove their feasibility. We illustrate the utility of our nontermination prover, called TNT, on several nontrivial examples, some of which require bit-level reasoning about integer representations.",2008,
Subset Selection with Shrinkage: Sparse Linear Modeling when the SNR is low,"We study the behavior of a fundamental tool in sparse statistical modeling --the best-subset selection procedure (aka ""best-subsets""). Assuming that the underlying linear model is sparse, it is well known, both in theory and in practice, that the best-subsets procedure works extremely well in terms of several statistical metrics (prediction, estimation and variable selection) when the signal to noise ratio (SNR) is high. However, its performance degrades substantially when the SNR is low -- it is outperformed in predictive accuracy by continuous shrinkage methods, such as ridge regression and the Lasso. We explain why this behavior should not come as a surprise, and contend that the original version of the classical best-subsets procedure was, perhaps, not designed to be used in the low SNR regimes. We propose a close cousin of best-subsets, namely, its $\ell_{q}$-regularized version, for $q \in\{1, 2\}$, which (a) mitigates, to a large extent, the poor predictive performance of best-subsets in the low SNR regimes; (b) performs favorably and generally delivers a substantially sparser model when compared to the best predictive models available via ridge regression and the Lasso. Our estimator can be expressed as a solution to a mixed integer second order conic optimization problem and, hence, is amenable to modern computational tools from mathematical optimization. We explore the theoretical properties of the predictive capabilities of the proposed estimator and complement our findings via several numerical experiments.",2017,arXiv: Methodology
Lasso Regression Based on Empirical Mode Decomposition,"The Hilbertâ€“Huang transform uses the empirical mode decomposition (EMD) method to analyze nonlinear and nonstationary data. This method breaks a time series of data into several orthogonal sequences based on differences in frequency. These data components include the intrinsic mode functions (IMFs) and the final residue. Although IMFs have been used in the past as predictors for other variables, very little effort has been devoted to identifying the most effective predictors among IMFs. As lasso is a widely used method for feature selection within complex datasets, the main objective of this article is to present a lasso regression based on the EMD method for choosing decomposed components that exhibit the strongest effects. Both numerical experiments and empirical results show that the proposed modeling process can use time-frequency structure within data to reveal interactions between two variables. This allows for more accurate predictions concerning future events.",2016,Communications in Statistics - Simulation and Computation
"Differential Gene Expression in Response to Salinity and Temperature in a Haloarcula Strain from Great Salt Lake, Utah","Haloarchaea that inhabit Great Salt Lake (GSL), a thalassohaline terminal lake, must respond to the fluctuating climate conditions of the elevated desert of Utah. We investigated how shifting environmental factors, specifically salinity and temperature, affected gene expression in the GSL haloarchaea, NA6-27, which we isolated from the hypersaline north arm of the lake. Combined data from cultivation, microscopy, lipid analysis, antibiotic sensitivity, and 16S rRNA gene alignment, suggest that NA6-27 is a member of the Haloarcula genus. Our prior study demonstrated that archaea in the Haloarcula genus were stable in the GSL microbial community over seasons and years. In this study, RNA arbitrarily primed PCR (RAP-PCR) was used to determine the transcriptional responses of NA6-27 grown under suboptimal salinity and temperature conditions. We observed alteration of the expression of genes related to general stress responses, such as transcription, translation, replication, signal transduction, and energy metabolism. Of the ten genes that were expressed differentially under stress, eight of these genes responded in both conditions, highlighting this general response. We also noted gene regulation specific to salinity and temperature conditions, such as osmoregulation and transport. Taken together, these data indicate that the GSL Haloarcula strain, NA6-27, demonstrates both general and specific responses to salinity and/or temperature stress, and suggest a mechanistic model for homeostasis that may explain the stable presence of this genus in the community as environmental conditions shift.",2018,Genes
[HIV-associated polyneuropathies in the era of highly active antiretroviral therapy in Bobo-Dioulasso Hospital (Burkina Faso)],HIV-associated polyneuropathies in the era of highly active antiretroviral therapy in Bobo-Dioulasso Hospital (Burkina Faso). Background: Peripheral neuropathies represent the most common neurological manifestation in patients with HIV infection. Introduction of highly active antiretroviral therapy (HAART) had a significant impact on the epidemiology of HIV-associated polyneuropathies in developed countries. Objectives: We carried out this study to examine distal sensorimotor polyneuropathy (DSP) in HIV-infected patients to determine whether clinical manifestations are affected by HAART in a cohort of HIV-infected patients in Bobo-Dioulasso Hospital (Burkina Faso). Methods: HIV-infected patients were followed up over a 12-month period. DSP was clinically diagnosed based on amyotrophy and weakness abnormalities of ankle reflexes or vibratory perception and if patients described pain paresthesia or numbness in the limbs. Electromyography was not performed in this study. Results: Of 537 HIV-infected patients 239 were treated by HAART. Among them 94 patients (66 females and 28 males) with 40.2 of mean age were screened for DSP. Patients between 30-49 years represented 65.9% of the sample. 95.7% of 94 patients were HIV1-infected and 85.1% were treated by HAART while 14.9% were not. Prevalence of DSP among patients with HAART was higher 12.1% versus 8.4% among the whole sample. Among the whole sample average CD4 cell count was 227.6/Âµl. 62.2% of the patients had less than 200 cell counts at the time of diagnosis. Among patients with HAART DSP occurred within 4 months after exposure to the antiretroviral agent. Sensitive polyneuropathies represented 87.2% of the sample. The occurrence of polyneuropathy was more correlated with decreased CD4 cells counts and neurotoxic antiretroviral therapy. Conclusion: Introduction of HAART has modified the course and the prognosis of HIV infection. The incidence of toxic polyneuropathies is increasing with longer patient life expectancy and represents a major factor in treatment limitation in HIV-infected patients even in poor resources settings.,2008,African Journal of Neurological Sciences
Occurrence of brominated disinfection byproducts in the air and water of chlorinated seawater swimming pools.,"An undesirable consequence of disinfection is the formation of chemical contaminants known as disinfection byproducts (DBPs). Chronic exposure to DBPs has been linked to adverse health effects. The occurrence of DBPs in chlorinated pools filled with seawater (such as thalassotherapy pools and pools in spas) has received little attention so far. The present study evaluated the speciation and levels of disinfection byproducts in indoor swimming pools filled with seawater and treated with chlorine. Water and air samples were collected from three indoor swimming pools located in Southern France. Several classes of DBPs including trihalomethanes, haloacetic acids, haloacetonitriles, and trihaloacetaldehydes were analyzed in water. Halogenated volatile organic compounds were analyzed in air. Extractable organic halides (EOX) contents were determined using combustion/micro-coulometry system. The speciation of DBPs identified in the three pools was predominantly brominated. The mean (arithmetic) concentration of bromoform, dibromoacetic acid, tribromoacetic acid, dibromoacetonitrile and bromal hydrate in the three pools was 79.2, 72.9, 59.9, 26.9 and 10.0Î¼g/L, respectively. By weight, HAAs represented the most abundant chemical class followed by THMs. In air, bromoform was the most abundant THM occurring at a mean concentration of 133.2Î¼g/m3 in the three pools. The mean EOX level was 706Î¼gCl-/L for the three pools. In average, the quantified DBPs accounted for only 14% of EOX, thus 86% of EOX remained unknown. Further research is warranted to identify the unknown DBPs.",2017,International journal of hygiene and environmental health
Prediction of malignant glioma grades using contrast-enhanced T1-weighted and T2-weighted magnetic resonance images based on a radiomic analysis,"We conducted a feasibility study to predict malignant glioma grades via radiomic analysis using contrast-enhanced T1-weighted magnetic resonance images (CE-T1WIs) and T2-weighted magnetic resonance images (T2WIs). We proposed a framework and applied it to CE-T1WIs and T2WIs (with tumor region data) acquired preoperatively from 157 patients with malignant glioma (grade III: 55, grade IV: 102) as the primary dataset and 67 patients with malignant glioma (grade III: 22, grade IV: 45) as the validation dataset. Radiomic features such as size/shape, intensity, histogram, and texture features were extracted from the tumor regions on the CE-T1WIs and T2WIs. The Wilcoxonâ€“Mannâ€“Whitney (WMW) test and least absolute shrinkage and selection operator logistic regression (LASSO-LR) were employed to select the radiomic features. Various machine learning (ML) algorithms were used to construct prediction models for the malignant glioma grades using the selected radiomic features. Leave-one-out cross-validation (LOOCV) was implemented to evaluate the performance of the prediction models in the primary dataset. The selected radiomic features for all folds in the LOOCV of the primary dataset were used to perform an independent validation. As evaluation indices, accuracies, sensitivities, specificities, and values for the area under receiver operating characteristic curve (or simply the area under the curve (AUC)) for all prediction models were calculated. The mean AUC value for all prediction models constructed by the ML algorithms in the LOOCV of the primary dataset was 0.902â€‰Â±â€‰0.024 (95% CI (confidence interval), 0.873â€“0.932). In the independent validation, the mean AUC value for all prediction models was 0.747â€‰Â±â€‰0.034 (95% CI, 0.705â€“0.790). The results of this study suggest that the malignant glioma grades could be sufficiently and easily predicted by preparing the CE-T1WIs, T2WIs, and tumor delineations for each patient. Our proposed framework may be an effective tool for preoperatively grading malignant gliomas.",2019,Scientific Reports
"Phylogenomic analyses of a clade within the roseobacter group suggest taxonomic reassignments of species of the genera Aestuariivita, Citreicella, Loktanella, Nautella, Pelagibaca, Ruegeria, Thalassobius, Thiobacimonas and Tropicibacter, and the proposal of six novel genera.","Roseobacters are a diverse and globally abundant group of Alphaproteobacteria within the Rhodobacteraceae family. Recent studies and the cophenetic correlations suggest that the 16S rRNA genes are poor phylogenetic markers within this group. In contrast, the cophenetic correlation coefficients of the core-gene average amino acid identity (cAAI) and RpoC protein sequences are high and likely more predictive of relationships. A maximum-likelihood phylogenetic tree calculated from 53 core genes demonstrated that some of the current genera were either polyphyletic or paraphyletic. The boundaries of bacterial genera were redefined based upon the cAAI, the percentage of conserved proteins, and phenotypic characteristics and resulted in the following taxonomic proposals. Loktanella vestfoldensis, Loktanella litorea, Loktanella maricola, Loktanella maritima, Loktanella rosea, Loktanella sediminilitoris, Loktanella tamlensis, and Roseobacter sp. CCS2 should be reclassified into the novel genus Yoonia. Loktanella hongkongensis, Loktanella aestuariicola, Loktanella cinnabarina, Loktanella pyoseonensis, Loktanellasoe soekkakensis and Loktanella variabilis should be reclassified in the novel genus Limimaricola. Loktanella koreensis and Loktanella sediminum should be reclassified in the novel genus Cognatiyoonia. Loktanella marina should be reclassified in the novel genus Flavimaricola. Aestuariivita atlantica should be reclassified in the novel genus Pseudaestuariivita. Thalassobius maritima should be reclassified in the novel genus Cognatishimia. Similarly, Ruegeria mobilis, Ruegeria scottomollicae, Ruegeria sp. TM1040 and Tropicibacter multivorans should be reclassified in the genus Epibacterium. Tropicibacter litoreus and Tropicibacter mediterraneus should be reclassified in the genus Ruegeria. Thalassobius abyssi and Thalassobius aestuarii should be reclassified in the genus Shimia. Citreicella aestuarii, Citreicella manganoxidans, Citreicella marina, Citreicella thiooxidans, Pelagibaca bermudensis and Thiobacimonas profunda should be reclassified in the genus Salipiger. Nautella italica should be reclassified in the genus Phaeobacter. Because these proposals to reclassify the type and all others species of Citreicella, Nautella, Pelagibaca and Thiobacimonas, these genera are not used in this taxonomy.",2018,International journal of systematic and evolutionary microbiology
Development and multicenter validation of a CT-based radiomics signature for discriminating histological grades of pancreatic ductal adenocarcinoma.,"Background
The histological grade of pancreatic cancer is an important independent predictor of outcome. However, we lack a method for safely and accurately obtaining the pathological grade before surgery. Radiomics has been used to discriminate between histological grades in tumors. We aimed to develop and validate a radiomics signature for the preoperative prediction of histological grades of pancreatic ductal adenocarcinoma (PDAC) that was based on contrast-enhanced computed tomography (CE-CT).


Methods
This study comprised 301 patients with pathologically confirmed PDAC who were randomly divided into a training (n=151) and test group (n=150). Radiomics features were selected by a support vector machine (SVM) model, and a radiomics signature was generated by the least absolute shrinkage and selection operator (LASSO) model. An additional 100 patients from 2 other medical centers were used for external validation. Receiver operating characteristic (ROC) curve analysis was used to assess the model and to identify the optimal cutoff value.


Results
The radiomics signatures between high-grade and low-grade PDACs in the training and test groups were significantly different (P<0.05). The areas under the curve (AUCs) of the training and test datasets were 0.961 and 0.910, respectively. The optimal cutoff value of the radiomics score was 0.426. In the external validation dataset, the difference between the radiomics signatures of high-grade versus low-grade PDACs was also significant (P<0.05). The radiomics signature for the external validation data had an AUC of 0.770.


Conclusions
The CE-CT-based radiomics signature showed moderate predictive accuracy for differentiating low-grade from high-grade PDAC and should become a new noninvasive method for the preoperative prediction of histological grades of PDAC.",2020,Quantitative imaging in medicine and surgery
Intestinal obstruction in cystic fibrosis: a surgeonâ€™s perspective,"Cystic fibrosis (CF) is the commonest life shortening autosomal recessivedisorder seen in the white population with an incidence varying between 1 in2000 to 1 in 3000 live births. CF was recognised as a childhood condition with ahigh mortality rate due to respiratory complications.However, advances in the medical management of the respiratory complicationsof cystic fibrosis have considerably improved the quality of life and longevity ofthese patients who now live well into the third and fourth decades of life. Thishas brought forth newer challenges in the management of gastrointestinalassociated complications in the adult cystic fibrosis patient. Distal intestinalobstruction syndrome (DIOS) or meconium ileus equivalent is one of thecommonest gastrointestinal conditions in this group of patients.DIOS is a condition unique to cystic fibrosis and affects 10 to 20% of adult cysticfibrosis patients (Peckam et al). It occurs due to acute complete orincomplete impaction of abnormally viscous mucofaeculent material in theterminal ileum, caecum and ascending colon. Although DIOS occurscommonly in CF patients with pancreatic insufficiency, it has also beendescribed in patients who have normal pancreatic function (Clifton et al).Other factors contributing to DIOS include reduced intestinal water content,lower luminal acidity of the foregut, accumulation of ABSTRACT",2018,International Surgery Journal
Scalable Bayesian Model Averaging Through Local Information Propagation,"This article shows that a probabilistic version of the classical forward-stepwise variable inclusion procedure can serve as a general data-augmentation scheme for model space distributions in (generalized) linear models. This latent variable representation takes the form of a Markov process, thereby allowing information propagation algorithms to be applied for sampling from model space posteriors. In particular, We propose a sequential Monte Carlo method for achieving effective unbiased Bayesian model averaging in high-dimensional problems, using proposal distributions constructed using local information propagation. The methodâ€”called LIPS for local information propagation based samplingâ€”is illustrated using real and simulated examples with dimensionality ranging from 15 to 1000, and its performance in estimating posterior inclusion probabilities and in out-of-sample prediction is compared to those of several other methodsâ€”namely, MCMC, BAS, iBMA, and LASSO. In addition, it is shown that the latent variab...",2014,Journal of the American Statistical Association
Efficient Clustering of Correlated Variables and Variable Selection in High-Dimensional Linear Models,"In this paper, we introduce Adaptive Cluster Lasso(ACL) method for variable selection in high dimensional sparse regression models with strongly correlated variables. To handle correlated variables, the concept of clustering or grouping variables and then pursuing model fitting is widely accepted. When the dimension is very high, finding an appropriate group structure is as difficult as the original problem. The ACL is a three-stage procedure where, at the first stage, we use the Lasso(or its adaptive or thresholded version) to do initial selection, then we also include those variables which are not selected by the Lasso but are strongly correlated with the variables selected by the Lasso. At the second stage we cluster the variables based on the reduced set of predictors and in the third stage we perform sparse estimation such as Lasso on cluster representatives or the group Lasso based on the structures generated by clustering procedure. We show that our procedure is consistent and efficient in finding true underlying population group structure(under assumption of irrepresentable and beta-min conditions). We also study the group selection consistency of our method and we support the theory using simulated and pseudo-real dataset examples.",2016,ArXiv
The Chemistry and Chemical Ecology of Indo-Pacific Gorgonians,"Author(s): Eve, Tegan M. | Abstract: Previous studies have demonstrated that gorgonians produce secondary metabolites that act as chemical defenses against predators and pathogens in the reef environment. While there have been investigations of the gorgonacea of the Western Atlantic which have shown that these organisms do contain defensive chemistry, the chemical ecology of Indo-Pacific gorgonians has not been investigated. The goal of this thesis research was to investigate the ecological role of Indo-Pacific gorgonian secondary metabolites in mediating interactions with potential predators and pathogens and to identify and describe the secondary metabolites responsible for observed activity.This dissertation concerns Indo-Pacific gorgonian chemical defenses against predation by the generalist reef fish Thalassoma lunare and Halichoeres melanurus, and against the growth of fungi isolated from gorgonian tissues, including the known gorgonian pathogen Aspergillus sydowii. The identification and characterization of novel secondary metabolites from gorgonians is also presented in this dissertation.The information gathered in these surveys led to projects involving gorgonian species of particular interest, with the aim of revealing the compound or compounds responsible for observed activities. Each project is described both biologically and chemically. The biological aspects described are the taxonomic identification of gorgonians and fungal strains. and the testing of extracts and pure compounds in assays. The chemical studies involve the isolation and structure elucidation of known and novel gorgonian secondary metabolites. The possible importance of specific compounds,or in some cases a class of compounds. in the chemical ecology of gorgonians is discussed.",2001,California Sea Grant College Program
Cleavage of RNA by an amphiphilic compound lacking traditional catalytic groups.,"Recently, in experiments with combinatorial libraries of amphiphilic compounds lacking groups, known as catalysts of transesterification reaction, we discovered novel RNA-cleaving compounds [N. Kovalev, E. Burakova, V. Silnikov, M. Zenkova, V. Vlassov, Bioorg. Chem. 34 (2006) 274-286]. In the present study, we investigate cleavage of RNA by the most active representative of these libraries, compound named Dp12. Sequence-specificity of RNA cleavage and influence of reaction conditions on cleavage rate suggested that Dp12 enormously accelerates spontaneous RNA cleavage. Light scattering experiments revealed that the RNA cleavage proceeds within multiplexes formed by assembles of RNA and Dp12 molecules, at Dp12 concentration far below critical concentration of micelle formation. Under these conditions, Dp12 is presented in the solution as individual molecules, but addition of RNA to this solution triggers formation of the multiplexes. The obtained data suggest a possible mechanism of RNA cleavage, which includes interaction of the compound with RNA sugar-phosphate backbone resulting in changing of ribose conformation. This leads to juxtaposition of the 2'-hydroxyl group and internucleotide phosphorus atom at a distance needed for the transesterification to occur.",2008,Bioorganic chemistry
Identification of a 5â€‘microRNA signature and hub miRNAâ€‘mRNA interactions associated with pancreatic cancer.,"miRNAâ€‘gene axes have been reported to serve an important role in the carcinogenesis of pancreatic cancer (PC). The aim of the present study was to systematically identity the microRNA signature and hub molecules, as well as hub miRNAâ€‘gene axes, and to explore the potential biomarkers and mechanisms associated with the carcinogenesis of PC. Eleven microRNA profile datasets were obtained from the National Center for Biotechnology Information (NCBI) Gene Expression Omnibus (GEO) and ArrayExpress databases, and a metaâ€‘analysis was performed to identify the differentially expressed miRNAs (DEMs) between tumor tissue and normal tissue. Subsequently, a diagnostic regression model was constructed to identify PC based on The Cancer Genome Atlas (TCGA) miRNA sequence data by using the least absolute shrinkage and selection operator (LASSO) method. In addition, GSE41368 was downloaded, and a weighted gene coâ€‘expression network analysis (WGCNA) was performed to obtain the gene module associated with carcinogenesis by using the TCGAbiolinks and WGCNA packages, respectively. Finally, miRNAâ€‘gene networks were constructed and visualized using Cytoscape software, followed by Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) analyses based on the Database for Annotation, Visualization, and Integrated Discovery (DAVID). A total of 14 DEMs were identified, and a 5â€‘microRNAâ€‘based score generated by the LASSO regression model provided a high accuracy for identifying PC [area under the curve (AUC)=0.918]. In addition, 44 miRNAâ€‘mRNA interactions were constructed, and 4Â hub genes were screened on the basis of the above bioinformatic tools and databases. Furthermore, 14 biological process (BP) functions and 6 KEGG pathways were identified according to gene set enrichment analysis (GSEA). In summary, the present study applied integrated bioinformatics approaches to generate a holistic view of PC, thereby providing a basis for further clinical application of the 5â€‘miRNA signature and the identified hub molecules, as well as the miRNAâ€‘gene axes, which could serve as diagnostic markers and potential treatment targets.",2019,Oncology reports
SketchSnakes: Sketch-line initialized Snakes for efficient interactive medical image segmentation,"We present an intuitive, fast and accurate 2D interactive segmentation method that combines a general subdivision-curve Snake possessing powerful editing capabilities, with a novel sketch-line user initialization process, and a pen input device. Using the pen (or a mouse), the Snake is quickly and precisely initialized with a few quick sketch lines drawn across the width of the target object. The smooth contour constructed using these lines is extremely close to the position and shape of the object boundary. This makes the Snake's task of snapping to the object boundary much simpler and hence more likely to succeed in noisy images with minimal user editing. We apply our Snake to the segmentation of several 2D medical images to demonstrate it's efficiency, accuracy and robustness. We also compare SketchSnakes to Adobe Photoshop's Magnetic Lasso (Adobe Systems Inc., Adobe Photoshop User Guide, 2002) as well as a recent graph-cut based image cutout tool known as Snap (Digital Film Tools LLC, Snap User Guide, 2007) in order to highlight SketchSnakes effectiveness.",2008,Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society
Jennifer Bushman Shares Recipe: Verlasso Salmon & Chicken Burgers | Verlasso,Chef Jennifer Bushman shares a recipe for Verlasso Salmon and Chicken burgers just in time for the 4th of July.,2014,
The Evolution of Feeding Adaptations of the Aquatic Sloth Thalassocnus,"Abstract The aquatic sloth Thalassocnus is represented by five species that lived along the coast of Peru from the late Miocene through the late Pliocene. A detailed comparison of the cranial and mandibular anatomy of these species indicates different feeding adaptations. The three older species of Thalassocnus (T. antiquus, T. natans, and T. littoralis) were probably partial grazers (intermediate or mixed feeders) and the transverse component of mandibular movement was very minor, if any. They were probably feeding partially on stranded sea weeds or sea grasses, or in very shallow waters (less than 1 m) as indicated by the abundant dental striae of their molariform teeth created by ingestion of sand. The two younger species (T. carolomartini and T. yaucensis) were more specialized grazers than the three older species and had a distinct transverse component in their mandibular movement. Their teeth almost totally lack dental striae. These two species were probably feeding exclusively in the water at a greater depth than the older species.",2004,
A Multi-parametric MRI-Based Radiomics Signature and a Practical ML Model for Stratifying Glioblastoma Patients Based on Survival Toward Precision Oncology,"Purpose: Predicting patients' survival outcomes is recognized of key importance to clinicians in oncology toward determining an ideal course of treatment and patient management. This study applies radiomics analysis on pre-operative multi-parametric MRI of patients with glioblastoma from multiple institutions to identify a signature and a practical machine learning model for stratifying patients into groups based on overall survival. Methods: This study included 163 patients' data with glioblastoma, collected by BRATS 2018 Challenge from multiple institutions. In this proposed method, a set of 147 radiomics image features were extracted locally from three tumor sub-regions on standardized pre-operative multi-parametric MR images. LASSO regression was applied for identifying an informative subset of chosen features whereas a Cox model used to obtain the coefficients of those selected features. Then, a radiomics signature model of 9 features was constructed on the discovery set and it performance was evaluated for patients stratification into short- (<10 months), medium- (10-15 months), and long-survivors (>15 months) groups. Eight ML classification models, trained and then cross-validated, were tested to assess a range of survival prediction performance as a function of the choice of features. Results: The proposed mpMRI radiomics signature model had a statistically significant association with survival (P < 0.001) in the training set, but was not confirmed (P = 0.110) in the validation cohort. Its performance in the validation set had a sensitivity of 0.476 (short-), 0.231 (medium-), and 0.600 (long-survivors), and specificity of 0.667 (short-), 0.732 (medium-), and 0.794 (long-survivors). Among the tested ML classifiers, the ensemble learning model's results showed superior performance in predicting the survival classes, with an overall accuracy of 57.8% and AUC of 0.81 for short-, 0.47 for medium-, and 0.72 for long-survivors using the LASSO selected features combined with clinical factors. Conclusion: A derived GLCM feature, representing intra-tumoral inhomogeneity, was found to have a high association with survival. Clinical factors, when added to the radiomics image features, boosted the performance of the ML classification model in predicting individual glioblastoma patient's survival prognosis, which can improve prognostic quality a further step toward precision oncology.",2019,Frontiers in Computational Neuroscience
Directional Migration of Recirculating Lymphocytes through Lymph Nodes via Random Walks,"Naive T lymphocytes exhibit extensive antigen-independent recirculation between blood and lymph nodes, where they may encounter dendritic cells carrying cognate antigen. We examine how long different T cells may spend in an individual lymph node by examining data from long term cannulation of blood and efferent lymphatics of a single lymph node in the sheep. We determine empirically the distribution of transit times of migrating T cells by applying the Least Absolute Shrinkage & Selection Operator (LASSO) or regularised S-LASSO to fit experimental data describing the proportion of labelled infused cells in blood and efferent lymphatics over time. The optimal inferred solution reveals a distribution with high variance and strong skew. The mode transit time is typically between 10 and 20 hours, but a significant number of cells spend more than 70 hours before exiting. We complement the empirical machine learning based approach by modelling lymphocyte passage through the lymph node insilico. On the basis of previous two photon analysis of lymphocyte movement, we optimised distributions which describe the transit times (first passage times) of discrete one dimensional and continuous (Brownian) three dimensional random walks with drift. The optimal fit is obtained when drift is small, i.e. the ratio of probabilities of migrating forward and backward within the node is close to one. These distributions are qualitatively similar to the inferred empirical distribution, with high variance and strong skew. In contrast, an optimised normal distribution of transit times (symmetrical around mean) fitted the data poorly. The results demonstrate that the rapid recirculation of lymphocytes observed at a macro level is compatible with predominantly randomised movement within lymph nodes, and significant probabilities of long transit times. We discuss how this pattern of migration may contribute to facilitating interactions between low frequency T cells and antigen presenting cells carrying cognate antigen.",2012,PLoS ONE
Behavioral responses to pre-planned road capacity reduction based on smartphone GPS trajectory data: A functional data analysis approach,"Abstract Pre-planned events such as constructions or special events lead to road capacity reductions and create bottlenecks in the traffic network. The traffic impact of such events goes beyond local areas, as informed drivers may detour to alternative corridors and consequently the traffic congestion may divert or propagate to other corridors. Due to the lack of real observation data, traditional traffic impact analyses are typically based on simulation models, fixed-location sensor data or survey questionnaires. In this research, we use high-resolution vehicle trajectory data collected via a smartphone app, which is capable of keeping track of individual driverâ€™s behavior before and after road capacity reduction, to investigate travelersâ€™ behavioral responses to pre-planned events and the contribution factors. For this purpose, a functional data analysis (FDA) approach-based clustering method is firstly proposed to cluster trajectory data and identify detour patterns, and two logistic and a least absolute shrinkage and selection operator (LASSO) regression models are used to explain driversâ€™ detour behavior choice for each pattern with spatial and temporal features of interest. A case study based on a lane closure event on MoPac expressway in Austin, TX is used as an example in this research. The case study demonstrates that: (1) the freeway capacity reduction triggered heterologous behavior responses, (2) driver detour behavior exhibits three major patterns and (3) each detour pattern highly depends on spatial features such as trip length, distance to freeway entrance and distance to other alternative freeways, in addition to the temporal features when the trip happens.",2019,Journal of Intelligent Transportation Systems
Shrinkage Estimation of Common Breaks in Panel Data Models via Adaptive Group Fused Lasso,"In this paper we consider estimation and inference of common breaks in panel data models via adaptive group fused Lasso. We consider two approachesâ€”penalized least squares (PLS) for first-differenced models without endogenous regressors, and penalized GMM (PGMM) for first-differenced models with endogeneity. We show that with probability tending to one, both methods can correctly determine the unknown number of breaks and estimate the common break dates consistently. We establish the asymptotic distributions of the Lasso estimators of the regression coefficients and their post Lasso versions. We also propose and validate a data-driven method to determine the tuning parameter used in the Lasso procedure. Monte Carlo simulations demonstrate that both the PLS and PGMM estimation methods work well in finite samples. We apply our PGMM method to study the effect of foreign direct investment (FDI) on economic growth using a panel of 88 countries and regions from 1973 to 2012 and find multiple breaks in the model.",2016,Journal of Econometrics
A linear programming approach for estimating the structure of a sparse linear genetic network from transcript profiling data,"BackgroundA genetic network can be represented as a directed graph in which a node corresponds to a gene and a directed edge specifies the direction of influence of one gene on another. The reconstruction of such networks from transcript profiling data remains an important yet challenging endeavor. A transcript profile specifies the abundances of many genes in a biological sample of interest. Prevailing strategies for learning the structure of a genetic network from high-dimensional transcript profiling data assume sparsity and linearity. Many methods consider relatively small directed graphs, inferring graphs with up to a few hundred nodes. This work examines large undirected graphs representations of genetic networks, graphs with many thousands of nodes where an undirected edge between two nodes does not indicate the direction of influence, and the problem of estimating the structure of such a sparse linear genetic network (SLGN) from transcript profiling data.ResultsThe structure learning task is cast as a sparse linear regression problem which is then posed as a LASSO (l1-constrained fitting) problem and solved finally by formulating a Linear Program (LP). A bound on the Generalization Error of this approach is given in terms of the Leave-One-Out Error. The accuracy and utility of LP-SLGNs is assessed quantitatively and qualitatively using simulated and real data. The Dialogue for Reverse Engineering Assessments and Methods (DREAM) initiative provides gold standard data sets and evaluation metrics that enable and facilitate the comparison of algorithms for deducing the structure of networks. The structures of LP-SLGNs estimated from the IN SILICO 1, IN SILICO 2 and IN SILICO 3 simulated DREAM2 data sets are comparable to those proposed by the first and/or second ranked teams in the DREAM2 competition. The structures of LP-SLGNs estimated from two published Saccharomyces cerevisae cell cycle transcript profiling data sets capture known regulatory associations. In each S. cerevisiae LP-SLGN, the number of nodes with a particular degree follows an approximate power law suggesting that its degree distributions is similar to that observed in real-world networks. Inspection of these LP-SLGNs suggests biological hypotheses amenable to experimental verification.ConclusionA statistically robust and computationally efficient LP-based method for estimating the topology of a large sparse undirected graph from high-dimensional data yields representations of genetic networks that are biologically plausible and useful abstractions of the structures of real genetic networks. Analysis of the statistical and topological properties of learned LP-SLGNs may have practical value; for example, genes with high random walk betweenness, a measure of the centrality of a node in a graph, are good candidates for intervention studies and hence integrated computational â€“ experimental investigations designed to infer more realistic and sophisticated probabilistic directed graphical model representations of genetic networks. The LP-based solutions of the sparse linear regression problem described here may provide a method for learning the structure of transcription factor networks from transcript profiling and transcription factor binding motif data.",2008,Algorithms for Molecular Biology : AMB
Component-wise gradient boosting and false discovery control in survival analysis with high-dimensional covariates,"MOTIVATION
Technological advances that allow routine identification of high-dimensional risk factors have led to high demand for statistical techniques that enable full utilization of these rich sources of information for genetics studies. Variable selection for censored outcome data as well as control of false discoveries (i.e. inclusion of irrelevant variables) in the presence of high-dimensional predictors present serious challenges. This article develops a computationally feasible method based on boosting and stability selection. Specifically, we modified the component-wise gradient boosting to improve the computational feasibility and introduced random permutation in stability selection for controlling false discoveries.


RESULTS
We have proposed a high-dimensional variable selection method by incorporating stability selection to control false discovery. Comparisons between the proposed method and the commonly used univariate and Lasso approaches for variable selection reveal that the proposed method yields fewer false discoveries. The proposed method is applied to study the associations of 2339 common single-nucleotide polymorphisms (SNPs) with overall survival among cutaneous melanoma (CM) patients. The results have confirmed that BRCA2 pathway SNPs are likely to be associated with overall survival, as reported by previous literature. Moreover, we have identified several new Fanconi anemia (FA) pathway SNPs that are likely to modulate survival of CM patients.


AVAILABILITY AND IMPLEMENTATION
The related source code and documents are freely available at https://sites.google.com/site/bestumich/issues.


CONTACT
yili@umich.edu.",2016,Bioinformatics
Evaluating Conditional Cash Transfer Policies with Machine Learning Methods,"This paper presents an out-of-sample prediction comparison between major machine learning models and the structural econometric model. Over the past decade, machine learning has established itself as a powerful tool in many prediction applications, but this approach is still not widely adopted in empirical economic studies. To evaluate the benefits of this approach, I use the most common machine learning algorithms, CART, C4.5, LASSO, random forest, and adaboost, to construct prediction models for a cash transfer experiment conducted by the Progresa program in Mexico, and I compare the prediction results with those of a previous structural econometric study. Two prediction tasks are performed in this paper: the out-of-sample forecast and the long-term within-sample simulation. For the out-of-sample forecast, both the mean absolute error and the root mean square error of the school attendance rates found by all machine learning models are smaller than those found by the structural model. Random forest and adaboost have the highest accuracy for the individual outcomes of all subgroups. For the long-term within-sample simulation, the structural model has better performance than do all of the machine learning models. The poor within-sample fitness of the machine learning model results from the inaccuracy of the income and pregnancy prediction models. The result shows that the machine learning model performs better than does the structural model when there are many data to learn; however, when the data are limited, the structural model offers a more sensible prediction. The findings of this paper show promise for adopting machine learning in economic policy analyses in the era of big data.",2018,arXiv: Econometrics
L G ] 2 8 O ct 2 01 9 Variable Selection with Copula Entropy,"Variable selection is of significant importance for classification and regression tasks in machine learning and statistical applications where both predictability and explainability are needed. In this paper, a Copula Entropy (CE) based method for variable selection which use CE based ranks to select variables is proposed. The method is both model-free and tuning-free. Comparison experiments between the proposed method and traditional variable selection methods, such as Stepwise Selection, regularized generalized linear models and Adaptive LASSO, were conducted on the UCI heart disease data. Experimental results show that CE based method can select the â€˜rightâ€™ variables out effectively and derive better interpretable results than traditional methods do without sacrificing accuracy performance. It is believed that CE based variable selection can help to build more explainable models.",2019,
On some ideals of BCI-algebra,"The ideal of BCI-algebra is a very important concept. This paper introduced two types different ideals:general associated ideal and quasi-right alternating ideal. This paper studied the relations of its with ideal,associated ideal,P-ideal,and portraied general associated BCI-algebra by generalassociated ideal subalgebra. Moreover,the paper indicated the difference in quasi-right alternating ideal with associated ideal,portraied quasi-right BCI-algebra by quasi-right alternating ideal.",2003,Pure and Applied Mathematics
The Value of Complete Circular Isolation of the Pulmonary Veins in the Circumferential Radiofrequency Ablation for Patients with Paroxysmal Atrial Fibrillation,"Objective:To access the value of complete circular isolation of the pulmonary veins in the circumferential radiofre- quency ablation for patients with paroxysmal atrial fibrillation.Methods:Eighty-three patients with symptomatic PAF were di- vided into CPVA group(n=40)or CPVA+Lasso group(n=43).Circumferential linear ablation around the left and right-si- ded pulmonary veins guided by 3-dimensional electroanatomic mapping was performed in the two group.In the CVPA + Lasso group,the endpoints of ablation was defined as blocking of all PVs documented with the Lasso catheters by sinus rhythm or cor- onary sinus pacing.In the CPVA group,the endpoints was defined as circular PV lesions and reduction of the local potential amplitude by 80% or less than 0.1 mv.After follow-up of 3ï½ž6 months,a repeat ablation was performed after the initial proce- dure in 20 patients who experienced highly symptomatic atrial fibrillation or atrial tachyarrhythmias unresponsive to anti-ar- rhythmic drugs with the method of CVPA + Lasso.Results:After the initial procedures,74 percent of patients in the CVPA + Lasso group and 60 percent of those in the CVPA group were free of recurrent atrial fibrillation or atrial tachyarrhythmia with- out anti-arrhythmic drug therapy after the first 3-6 months.Repeat procedures were performed in 20 patients with recurrent at- rial fibrillation or atrial taehyarrhythmia from the two group with the method of CVPA + Lasso during follow-up of 3-6 months. During the 3-9months after the last procedure,18 patients(90%)did not have symptomatic atrial fibrillation or atrial tachya- rrhythmia while not taking anti-arrhythmic drugs.Conclusion:The complete circular isolation of the pulmonary veins in the cir- cumferential radiofrequency ablation is effective to reduce the recurrence of paroxysmal atrial fibrillation.",2007,Chinese journal of Clinical Medicine
Catheter Ablation for Atrial Fibrillation in the Critical Care Medicine,"Background: Ablation of atrial fibrillation (AF) is a rapidly growing field with advanced technological progress that is supposed to improve success rate and decrease complications. We intended in this study to evaluate complications and recurrence following AF ablation by Lasso, CARTO, and combined techniques in Critical Care Medicine Department, Cairo University. Methods: This is a retrospective study involving patients who underwent RF ablation of AF in the period between March 2004 and March 2009 in Critical Care Department, Cairo University. Patient data were collected from their medical records. Follow-up was done to the patient through in the follow up clinic or phone guided. According to the ablation technique, the study population was divided into 3 groups; patients for whom ablation done guided by Lasso catheter (Lasso group), patients for whom ablation done guided by CARTOTM XP system (Carto group), and those for whom ablation done guided by both Lasso catheter and CARTOTM XP system (combined group). Recurrence of AF was defined by the presence of symptomatic episodes of palpitation and documented ECG or 24 hours Holter showing AF. Freedom of AF is considered if there were no attacks of palpitations and at least two ECGâ€™s showing sinus rhythm, obtained in two different follow up visits. Results: The study included 58 pts with mean age of 43Â± 11 yrs, 35 (60.3%) males. AF ablation was done by Lasso technique in 29 pts (50%), by Carto technique in 16 pts (27.6%), and by combined technique in 13 pts (22.4%). Apart from the higher number of antiarrhythmic drugs and the larger left atrial dimension in the Lasso group, the three groups revealed no significant differences in their demographic Characteristics. The overall freedom of AF following ablation was 62% at 5 yrs with a non-significant trend toward freedom of AF in the combined group. It was 76.9% in combined group compared to 57.1% and 60% in Lasso and Carto groups respectively (p=0.59). We reported an overall complication rate of 17.2% including 12. 1 % pericardial effusion and 3.4% for pulmonary vein stenosis and thromboembolism. There was a non-significant tendency toward more complications in Lasso group (27.6%) compared to Carto group (6.3%) and combined group (15.4%) ( p=0.32). Correspondence to: Dr. Khaled Teama, The Department of Critical Care, Faculty of Medicine, Cairo University Conclusions: Radiofrequency ablation is a safe and effective long-term treatment strategy for drug-refractory atrial fibrillation. All techniques are successful but it seems that ablation technique guided by both CARTOTM XP navigation system and Lasso catheter has better long term outcome and less complication rate than ablation guided by either of them alone.",2014,
"Comparison of linear regression models Ordinary Lasso, Adaptive Group Lasso and Ordinary Least Squares models in selecting effective characteristics to predict the expected return","In this study, for the selection of the characteristics of the company that provides the incremental information to investors and financial analysts, the linear models are adapted by the ordinary Lasso method (Tibshirani, 1996), Adaptive Group LASSO (Zu, 2006) and the least squares method (OLS). The main objective of this research is to determine which method can predict the expected return on stock portfolios in the shortest time and using the least effective features. The research sample is1340observations, including 134companies listed in Tehran Stock Exchange, and the research variables from the financial statements of the companies and the stock market reports between 2008and 2018. The results of this study show that by employing the least squares regression method, 7 characteristics, the typical 5- characteristics LASSO method and in the Adaptive Group LASSO method, only 4characteristics, contain incremental information to predict the expected returns of stock portfolios. In the second place, by applying the Adaptive Group LASSO regression method, one can achieve the same results with using the least characteristics.",2018,
Multiple indefinite kernel learning with mixed norm regularization,"We address the problem of learning classifiers using several kernel functions. On the contrary to many contributions in the field of learning from different sources of information using kernels, we here do not assume that the kernels used are positive definite. The learning problem that we are interested in involves a misclassification loss term and a regularization term that is expressed by means of a mixed norm. The use of a mixed norm allows us to enforce some sparsity structure, a particular case of which is, for instance, the Group Lasso. We solve the convex problem by employing proximal minimization algorithms, which can be viewed as refined versions of gradient descent procedures capable of naturally dealing with nondifferentiability. A numerical simulation on a Uci dataset shows the modularity of our approach.",2009,
Supervised learning via the â€œhubNetâ€ procedure,"We propose a new method for supervised learning. The hubNet procedure fits a hub-based graphical model to the predictors, to estimate the amount of â€œconnectionâ€ that each predictor has with other predictors. This yields a set of predictor weights that are then used in a regularized regression such as the lasso or elastic net. The resulting procedure is easy to implement, can often yield higher or competitive prediction accuracy with fewer features than the lasso, and can give insight into the underlying structure of the predictors. HubNet can be generalized seamlessly to supervised problems such as regularized logistic regression (and other GLMs), Coxâ€™s proportional hazards model, and nonlinear procedures such as random forests and boosting. We prove recovery results under a specialized model and illustrate the method on real and simulated data. HubNet; Adaptive Lasso; Graphical Model; Unsupervised Weights",2018,Statistica Sinica
"Physiological and morphological factors influencing leaf, rhizome and stolon tensile strength in C4 turfgrass species","The intrinsic resistance of plant tissue to several biomechanical stresses, including tensile stress, is a decisive factor in determining the wear resistance of a turfgrass species. Lignin, dry matter, starch, sugars and silica are some of the tissueconstituentsthathavebeenassociatedwithleafandstemmechanicalresistance,whereaslittleinformationisavailable concerning stolons and rhizomes. These organs not only enable C4 turfgrass species lateral growth, soil colonisation and injury recovery, but are also key constituents of mature swards. This study consisted in an extensive investigation on the effective leaf, stolon and rhizome tensile strength of Cynodon dactylon (L.) Pers. var. dactylonC. transvaalensis Burt- Davy cv. Tifway 419,Zoysia matrella (L.) Merr. cv. Zeon andPaspalum vaginatumSwartz. cv. Salam, as measured with a FederationInternationaledeFootballAssociation(FIFA)-approveddynamometerandcorrelatingtheresultswithlaboratory investigationsonkeytissueconstituents.Tensilestrengthperunitareawasinfluencedbybothtissueconstituentsandtissue dimension.Inrhizomesandstolons,tissuebreakageusuallyoccurredintheareaattheintercalarymeristemattheapicalzone in the immediate proximity of a node. Older tissues had higher tensile strength owing to their higher levels of lignification. Lignin was the principal constituent determining tissue tensile strength and as such it could be used as a turfgrass wear resistancepredictorinthecultivarbreedingstages.Stolontotalsolublesugarsweregenerallyinverselyproportionaltolignin content and, therefore, can also be considered clear markers of tissue mechanical strength. Silica was found to have no influence on the mechanical properties tissues.",2011,Functional Plant Biology
PREDICTING PREFERENCES Analyzing Reading Behavior and News Preferences,"News reading has gradually become a significant activity in our daily life as the world is saturated with new information. We consume so much information every day that it becomes extremely difficult to filter and extract only the interesting and relevant news to us. To improve readersâ€™ experience, we need to be able to accurately predict the new stories that are most probable for them to read. This reduces to predicting preferences which is a common problem of finding out which items are most relevant to each user and essentially rank or feed them to tailored users. In our study, we in particular look at the stories users click and read previously in a news-reading mobile application Pulse in order to predict which stories users are most likely to read in the next few days. Similar challenge has been recently tackled by researchers in data mining and natural language processing because its implications can be applied to other popular areas such as search engine recommendation system. This paper considers applying different machine learning algorithms in the realm of supervised learning and unsupervised learning in attempt to predict the news stories that each user are most likely to read from a set of all available stories, which are much too large for the average users to parse and find the most relevant ones. In particular, using usersâ€™ click and read history, we explore text categorization algorithms by comparing the accuracy of several supervised learning methods such as a simple Naive Bayes, L2-norm regularized logistic regression, and L1-norm regularized logistic regression with Lasso algorithm. We then move on to investigate common unsupervised learning technique such as k-mean clustering of users and a simple implementation of collaborative filtering.",2011,
Impact of statistical models on the prediction of type 2 diabetes using non-targeted metabolomics profiling,"OBJECTIVE
Characterizing specific metabolites in sub-clinical phases preceding the onset of type 2 diabetes to enable efficient preventive and personalized interventions.


RESEARCH DESIGN AND METHODS
We developed predictive models of type 2 diabetes using two strategies. One strategy focused on the probability of incidence only and was based on logistic regression (MRS1); the other strategy accounted for the age at diagnosis of diabetes and was based on Cox regression (MRS2). We assessed 293 metabolites using non-targeted metabolomics in fasting plasma samples of 1,044 participants (including 231 incident cases over 9 years) used as training population; and fasting serum samples of 128 participants (64 incident cases versus 64 controls) used as validation population. We applied a LASSO-based variable selection aiming at maximizing the out-of-sample area under the receiver operating characteristic curve (AROC) and integrated AROC.


RESULTS
Sixteen and 17 metabolites were selected for MRS1 and MRS2, respectively, with AROCÂ =Â 90% and 73% in the training and validation populations, respectively for MRS1. MRS2 had a similar performance and was significantly associated with a younger age of onset of type 2 diabetes (Î²Â =Â -3.44 years per MRS2 SD in the training population, pÂ =Â 1.56Â Ã—Â 10(-7); Î²Â =Â -4.73 years per MRS2 SD in the validation population, pÂ =Â 4.04Â Ã—Â 10(-3)).


CONCLUSIONS
Overall, this study illustrates that metabolomics improves prediction of type 2 diabetes incidence of 4.5% on top of known clinical and biological markers, reaching 90% in total AROC, which is considered the threshold for clinical validity, suggesting it may be used in targeting interventions to prevent type 2 diabetes.",2016,Molecular Metabolism
"Green sulfur bacteria from hypersaline Chiprana Lake (Monegros, Spain): habitat description and phylogenetic relationship of isolated strains","The â€˜Salada de Chipranaâ€™ (Chiprana Lake) is a hypersaline (30â€“73â€°), permanent and shallow lake of endorheic origin in a semi-arid region of the Ebro depression (Aragon, Spain). Magnesium sulfate and sodium chloride represent the main salts of this athalassohaline environment. Anoxic conditions occurred periodically in the bottom layers of the lake during the study period. When stratified, high sulfide concentrations (up to 7 mM) were measured in the hypolimnion. Physical and chemical conditions gave rise to the development of very dense green sulfur bacteria blooms (10.7 mg lâˆ’1 of BChl c and 16.7 mg lâˆ’1 of BChl d) at 0.5â€“1 m from the bottom. Microscopic observations revealed that cells morphologically similar to Chlorobium vibrioforme were dominant in the phototrophic bacterial community, but Prosthecochloris aestuarii was also found sometimes at lower concentrations, as revealed by both microscopic observation and flow cytometric analyses. Deep agar dilution series allowed to obtain several axenic cultures of phototrophic bacteria. They were identified according to their morphology, pigment composition and phylogenetic relationships (16S rDNA sequence analysis). Two of the sequenced strains (CHP3401 and CHP3402) belonged to the green sulfur bacteria and were related to Prosthecochloris aestuarii SK413T and Chlorobium vibrioforme DSM260T, respectively. HPLC analyses of both natural samples and Chlorobium vibrioforme isolates indicated that these strains contained both BChl c and BChl d. Phylogenetic results suggested that Chlorobium vibrioforme strains DSM260T and CHP3402, all sequenced strains of Prosthecochloris aestuarii and strain CIB2401 constitute a separate cluster of green sulfur bacteria, all of them isolated from marine to hypersaline habitats.",2004,Photosynthesis Research
"Erythemato-squamous adalah salah satu kelompok jenis penyakit kulit. Penyakit kulit yang tergabung dalam kelompok ini adalah psoriasis, seboreic dermatitis, lichen planus, pityriasis rosea, cronic dermatitis dan pityriasis rubra pilaris. Penelitian mengenai klasifikasi jenis penyakit erythemato-squa","This study discusses the classification of types of erythematosquamous disease using the Vertex Discriminant Analysis (VDA) method based on clinical and histopathological examination results. We use three penalties in the VDA method i.e. Euclidian, Lasso, and Ridge where misclassification are assessed using Apparent Rate Error (APER) value and loss function minimization using Majorize Minimize Algorithm. There are 366 data which we will classify consists of 34 variables of clinical and histopathological examination results from 6 disease groups: psoriasis, seboreic dermatits, lichen planus, pityriasis rosea, chronic dermatitis, and pityriasis rubra pilaris. The result shows that each penalty in the VDA method forms 5 discriminant functions to classify 6 disease groups. VDA with Euclidian penalty succed to classify exactly 104 data from 110 training data with 27 explanatory variables consist of 12 clinical and 15 histopathological examination results. VDA with Lasso penalty succed to classify exactly 102 data from 110 training data with 25 explanatory variables consist of 11 clinical and 14 histopathological examination results, and the VDA with Ridge penalty succed to classify exactly 107 data from 110 training data with 34 explanatory variables consist of 12 clinical and 22 histopathological examination results.",2018,
"The Ptolemies, the sea and the Nile : studies in waterborne power","Preface In memoriam F. W. Walbank Christian Habicht 1. Introduction Kostas Buraselis and Dorothy J. Thompson 2. The Ptolemaic League of Islanders Andrew Meadows 3. Callicrates of Samos and Patroclus of Macedon: champions of Ptolemaic thalassocracy Hans Hauben 4. Rhodes and the Ptolemaic kingdom: the commercial infrastructure Vincent Gabrielsen 5. Polybius and Ptolemaic sea power Andrew Erskine 6. Ptolemaic grain, seaways and power Kostas Buraselis 7. Waterborne recruits: the military settlers of Ptolemaic Egypt Mary Stefanou 8. Our academic visitor is missing: Posidippus 89 (A-B) and 'smart capital' for the thalassocrats Paul McKechnie 9. Aspects of the diffusion of Ptolemaic portraiture overseas Olga Palagia 10. Ptolemies and piracy Lucia Criscuolo 11. The Nile police in the Ptolemaic period Thomas Kruse 12. Hellenistic royal barges Dorothy J. Thompson 13. Eudoxus of Cyzicus and Ptolemaic exploration of the sea route to India Christian Habicht 14. Timosthenes and Eratosthenes: sea routes and Hellenistic geography Francesco Prontera 15. Claudius Ptolemy on Egypt and East Africa Klaus Geus.",2013,
"Pixl Prediction Accuracies for Ni , Mn , S , and Major Elements : a Comparative Study Using the Same Standards","Introduction: Calibration models for detection and accurate quantification of elements on Mars are necessary to understand the composition of its surface. Mars 2020 will carry Planetary Instrument for X-ray Lithochemistry (PIXL), an x-ray fluorescence (XRF) instrument, and a laser-induced breakdown spectroscopy (LIBS) instrument as part of the SuperCam instrument for geochemical analyses. No comparison of prediction accuracies between these two techniques using identical standards has been undertaken to date, making it difficult to compare results from the two methods. Another issue with Mars geochemical accuracies is that most calibration models are made using terrestrial geologic standards with concentrations that may be significantly lower than those of, especially, Ni, Mn, and S in Martian soils [1], where these elements may be enriched by contributions from meteorites and volcanic gasses. Accordingly, this study uses standards created from several different rock types doped with up to 1 wt% (10,000 ppm) of these elements to create appropriate calibration models. Background: With XRF, samples are bombarded with high-energy X-rays, resulting in ejection of inner shell electrons. The resultant holes in the inner-shell orbitals are filled by electrons from outer shells, in the process ejecting a photon with energy diagnostic of each individual element. In contrast, LIBS uses energy from a laser pulse to excite electrons into higher energy orbitals. When electrons return to their ground state, they release photons detected by spectrometers from the UV to the NIR. These transitions occur at longer wavelengths and lower energies than those measured in XRF, due to differences in the energy of the two excitation sources (plasma heat and x-rays, respectively). So these two techniques are highly complementary, and each has its strengths and weaknesses. Methods: Doped samples consisted of 7 matrices with different bulk compositions, including three basalts, one granite, one rhyolitic volcanic glass, sea sand, and a 50:50 mixture of diopside and forsteritic olivine. Standard preparation and analyses are described in [2]. These powders were pressed into pellets and a subset of the 84 samples was analyzed under Mars conditions with the Mount Holyoke College ChemLIBS-analog instrument as well as with the Stony Brook University PIXL-analog instrument in air. Spectral Preprocessing: XRF spectra from three pellet locations were summed over a total dwell time of one or two hours using data from two spectrometers. X-axis resampling and baseline calculations for later removal were performed by PIQUANT, a software created specifically to analyze PIXL spectra [3-4]. To remedy temporal count differences, the spectra were normalized by the emission counts at 2.697 keV, which derive from Rh-anode L-emission lines in the PIXL Xray tube. LIBS spectra were averages of 36 individual shots taken on 6 locations across the pelletsâ€™ surfaces. Spectra were preprocessed using the same method as the ChemLIBS Curiosity team and normalized by the total intensity of each of the three spectrometers [5]. The baselines were removed using the Kajfosz-Kwiatek method (bottom width of 50 and top width of zero) [6]. Modeling and Analysis: Both datasets were uploaded to a web tool that utilizes the SciKit-learn library and allows for convenient multivariate analysis with partial-least squares (PLS) and the least absolute shrinkage and selection operator (lasso) regression methods [7]. Calibration models for the dopants (Ni, Mn, S) and the major oxides (SiO2, TiO2, Al2O3, Fe2O3, MgO, CaO, Na2O, K2O, P2O5) were made using both the entire available spectral range (0-40 keV for PIXL and ~240-850 nm for ChemLIBS) as well as limited regions of the spectra that contain emission peaks specific to the element of interest (Table 1). XRF regions used each elementâ€™s k-ï¡ fluorescence peak, while LIBS focused on regions with the most intense peaks or clusters of peaks found with the NIST LIBS spectral database [8]. PIXL calibrations for Na and Mg were not possible because their XRF emissions are not measurable in air.",2018,
Revisiting Additive Quantization,"We revisit Additive Quantization (AQ), an approach to vector quantization that uses multiple, full-dimensional, and non-orthogonal codebooks. Despite its elegant and simple formulation, AQ has failed to achieve state-of-the-art performance on standard retrieval benchmarks, because the encoding problem, which amounts to MAP inference in multiple fully-connected Markov Random Fields (MRFs), has proven to be hard to solve. We demonstrate that the performance of AQ can be improved to surpass the state of the art by leveraging iterated local search, a stochastic local search approach known to work well for a range of NP-hard combinatorial problems. We further show a direct application of our approach to a recent formulation of vector quantization that enforces sparsity of the codebooks. Unlike previous work, which required specialized optimization techniques, our formulation can be plugged directly into state-of-the-art lasso optimizers. This results in a conceptually simple, easily implemented method that outperforms the previous state of the art in solving sparse vector quantization. Our implementation is publicly available (https://github.com/jltmtz/local-search-quantization).",2016,
$\mathcal{DBSDA}$ : Lowering the Bound of Misclassification Rate for Sparse Linear Discriminant Analysis via Model Debiasing,"Linear discriminant analysis (LDA) is a well-known technique for linear classification, feature extraction, and dimension reduction. To improve the accuracy of LDA under the high dimension low sample size (HDLSS) settings, shrunken estimators, such as Graphical Lasso, can be used to strike a balance between biases and variances. Although the estimator with induced sparsity obtains a faster convergence rate, however, the introduced bias may also degrade the performance. In this paper, we theoretically analyze how the sparsity and the convergence rate of the precision matrix (also known as inverse covariance matrix) estimator would affect the classification accuracy by proposing an analytic model on the upper bound of an LDA misclassification rate. Guided by the model, we propose a novel classifier, <inline-formula> <tex-math notation=""LaTeX"">$\mathcal {DBSDA}$ </tex-math></inline-formula>, which improves classification accuracy through <italic>debiasing</italic>. Theoretical analysis shows that <inline-formula> <tex-math notation=""LaTeX"">$\mathcal {DBSDA}$ </tex-math></inline-formula> possesses a reduced upper bound of misclassification rate and better asymptotic properties than sparse LDA (SDA). We conduct experiments on both synthetic datasets and real application datasets to confirm the correctness of our theoretical analysis and demonstrate the superiority of <inline-formula> <tex-math notation=""LaTeX"">$\mathcal {DBSDA}$ </tex-math></inline-formula> over LDA, SDA, and other downstream competitors under HDLSS settings.",2019,IEEE Transactions on Neural Networks and Learning Systems
Comparing the performance of propensity score methods in healthcare database studies with rare outcomes.,"Nonrandomized studies of treatments from electronic healthcare databases are critical for producing the evidence necessary to making informed treatment decisions, but often rely on comparing rates of events observed in a small number of patients. In addition, studies constructed from electronic healthcare databases, for example, administrative claims data, often adjust for many, possibly hundreds, of potential confounders. Despite the importance of maximizing efficiency when there are many confounders and few observed outcome events, there has been relatively little research on the relative performance of different propensity score methods in this context. In this paper, we compare a wide variety of propensity-based estimators of the marginal relative risk. In contrast to prior research that has focused on specific statistical methods in isolation of other analytic choices, we instead consider a method to be defined by the complete multistep process from propensity score modeling to final treatment effect estimation. Propensity score model estimation methods considered include ordinary logistic regression, Bayesian logistic regression, lasso, and boosted regression trees. Methods for utilizing the propensity score include pair matching, full matching, decile strata, fine strata, regression adjustment using one or two nonlinear splines, inverse propensity weighting, and matching weights. We evaluate methods via a 'plasmode' simulation study, which creates simulated datasets on the basis of a real cohort study of two treatments constructed from administrative claims data. Our results suggest that regression adjustment and matching weights, regardless of the propensity score model estimation method, provide lower bias and mean squared error in the context of rare binary outcomes. Copyright Â© 2017 John Wiley & Sons, Ltd.",2017,Statistics in medicine
Vergleichende Untersuchung der Ciliatensukzession beim Abbau von Zellstoff in marinem Brackwasser und athalassogenem Brackwasser vom Typ der KaliwerksabwÃ¤sser,"ZusammenfassungDie Sukzession der Ciliaten beim Abbau von Zellstoff wurde unter Laboratoriumsbedingungen in marinem Brackwasser und in kÃ¼nstlichem Kaliwerksabwasser verfolgt. Im untersuchten Bereich bis hinauf zu 7 g/l Gesamtsalzgehalt verlief der Zellstoffabbau wie im SÃ¼ÃŸwasser. Bei Verwendung von SÃ¼ÃŸwasserorganismen als Impfmaterial zeigte sich mit steigendem Gesamtsalzgehalt eine Verminderung der Artenzahl gegenÃ¼ber der SÃ¼ÃŸwasserkontrolle; diese VerÃ¤nderung war in beiden Versalzungstypen nahezu gleich. Parallel mit der Verarmung des Artenspektrums erfolgt bei mehreren Arten eine deutliche Vermehrung der Individuenzahl in den hÃ¶heren Salzkonzentrationen.SummaryThe succession of freshwater ciliates associated with the decay of cellulose was investigated in thalassogenic brackish water and in athalassogenic brackish water derived from waste water of potash works. The amount of decomposition of cellulose was the same in both sorts of brackish water (up to 7 g/l salt content) and in freshwater. When brackish water was used instead of freshwater, the number of species of ciliates decreased while the total number of individuals of Cyclidium citrullus, Euplotes affinis and others increased. The changes in the succession of ciliates were nearly the same in both sorts of brackish water.",2004,Hydrobiologia
Anomaly detection based on efficient Euclidean projection,"Machine-learning algorithms are widely applied in traffic classification and anomaly detection. Due to the tremendous traffic on the network, an extremely challenging question arises: how to efficiently and accurately detect the anomalous flow from the backbone network. One solution is proposed, online anomaly-detection scheme, which is based on the sparse feature selection method, Lasso. The sparse feature selection can be efficiently solved by reformulating the problem as an optimization problem with an iÂ¾?1-ball constraint. At the evaluation stage, the authors preprocessed the raw data trace from the trans-Pacific backbone link between Japan and the United States and generated an evaluation data set. Their empirical study shows that the feature selection step can be solved quickly by applying the efficient Euclidean projection method; indeed, doing so resolves the feature selection step faster than using three classical iÂ¾?1-min solvers. In terms of overall accuracy, true positive rate, false positive rate, precision, and F-measure, the proposed scheme improves the quality of detection. Copyright Â© 2015John Wiley & Sons, Ltd.",2015,Security and Communication Networks
3 Screening Rules for Constrained Problems,"We propose a new framework for deriving screening rules for convex optimization problems. Our approach covers a large class of constrained and penalized optimization formulations, and works in two steps. First, given any approximate point, the structure of the objective function and the duality gap is used to gather information on the optimal solution. In the second step, this information is used to produce screening rules, i.e. safely identifying unimportant weight variables of the optimal solution. Our general framework leads to a large variety of useful existing as well as new screening rules for many applications. For example, we provide new screening rules for general simplex and L1-constrained problems, Elastic Net, squared-loss Support Vector Machines, minimum enclosing ball, as well as structured norm regularized problems, such as group lasso.",2016,
Using LASSO for formulating constraint of least-squares programming for solving one-norm equality constrained problem,"The paper proposes an efficient method for solving a one- norm equality constrained optimization problem. In fact, this kind of optimization problems is nonconvex. First, the problem is formulated as the least absolute shrinkage and selection operator (LASSO) optimization problem. Then, it is solved by iterative shrinkage algorithms such as the fast iterative shrinkage thresholding algorithm. Next, the solution of the LASSO optimization problem is employed for formulating the constraint of the corresponding least-squares constrained optimization problem. The solution of the least-squares constrained optimization problem is taken as a near globally optimal solution of the one-norm equality constrained optimization problem. The main advantage of this proposed method is that a solution with both lower one-norm constraint error and two-norm reconstruction error can be obtained compared to those of the LASSO problem, while the required computational power is significantly reduced compared to the full search approach. Computer numerical simulation results are illustrated.",2017,"Signal, Image and Video Processing"
A Fast and Flexible Algorithm for the Graph-Fused Lasso,"We propose a new algorithm for solving the graph-fused lasso (GFL), a method for parameter estimation that operates under the assumption that the signal tends to be locally constant over a predefined graph structure. Our key insight is to decompose the graph into a set of trails which can then each be solved efficiently using techniques for the ordinary (1D) fused lasso. We leverage these trails in a proximal algorithm that alternates between closed form primal updates and fast dual trail updates. The resulting techinque is both faster than previous GFL methods and more flexible in the choice of loss function and graph structure. Furthermore, we present two algorithms for constructing trail sets and show empirically that they offer a tradeoff between preprocessing time and convergence rate.",2015,arXiv: Machine Learning
Use multimedia to improve the reformation of education and teaching,"By analyzing the relationship between the multimedia technology and education practice,this paper emphasized that teachers should use multimedia to help their classoom teaching.So their teaching method,teaching quality and teaching efficiency should be improved.And using multimeddia is the inexorable trend of the development of modern education technology.",2003,Journal of Qiqihar University Thilosophy
Gabdelakhat Vildanovâ€™un Materyalleri ile BaÅŸkurtlarda Åžahin ile AvcÄ±lÄ±k,"I n the past, hunting with predatory hunting birds was common among many peoples of the world. It is known that Turkic and European monarchs, Russian princes and kings were fond of falconry. Among the Turkic peoples, hunting with hunting birds has been popular from ancient times. The article deals with ethnographic material about domestication and hunting with the aid of hunting birds, published in 1928 by the famous Bashkir scholar and folklorist Gabdelakhat Vildanov. The analysis is given in comparison with the data of the monograph Falconry among the Bashkirs written by Mirza Mullagulov, a prominent expert in the field, and other sources. Many aspect of this description coincide with the information of Russian scholars and local historians of the XVIII-XIX centuries, as well as with the materials of the monographic study of M.Â Mullagulov. Historical materials published by G.Â Vildanov were recorded near the north-eastern Bashkirs, and information about hunting was obtained from informants who were representatives of the Quvakan clan. It is noteworthy that the recording of G. Vildanov gives a way to catch the hawk bledgeling at the moment when the hawk herself brought them down to the gramd for training to flight. This method of catching the chick differs from other recorded facts in which hunters descended from above the top of a rock or a mountain with the help of a lasso. Thus, in the article new material containing data on the taming, training and use of predatory birds by Bashkirs is introduced into scientific circulation.",2020,
"Spectral Sensitivity of the Hawaiian Saddle Wrasse, Thalassoma duperrey, and Implications for Visually Mediated Behaviour on Coral Reefs","Although tropical coral reefs are one of the most spectrally complex habitats, there is relatively little known about colour vision of reef fish. In this study, we measured the spectral sensitivity of an endemic Hawaiian coral reef fish, Thalassoma duperrey (family Labridae), and assessed the possible role of visual sensitivity in mediating intraspecific communication. Electrophysiological recordings of compound action potentials from retinal ganglion cells were used to generate spectral sensitivity curves for specific wavelengths (380â€“620â€‰nm). We found at least 2 sensitivity peaks for the on response (Î»max=460, 550â€‰nm). The off response lacked a short wavelength mechanism but a medium wavelength mechanism (Î»max=545â€‰nm) and a longwave mechanism (Î»max=570â€‰nm) were found. To quantify the visual stimulus provided by a conspecific individual, spectral reflectance from the colour pattern of T. duperrey was measured with a spectroradiometer. Luminance and spectral contrast were computed between colour patches of the pattern and between the patches and natural backgrounds (i.e., water and coral). Reflectance from the blue head and contrast from the blue, green and red patches matched the sensitivity maxima of T. duperrey, although this depended on the type of background. Our results indicate that T. duperrey should be able to visually detect the colour pattern of a conspecific fish and that T. duperrey's visual system is designed to enhance target detection in the coral reef habitat with matched and offset cone mechanisms.",2004,Environmental Biology of Fishes
