title,abstract,year,journal
Determination of biological and physicochemical parameters of Artemia franciscana strains in hypersaline environments for aquaculture in the Colombian Caribbean,"BackgroundArtemia (Crustacea, Anostraca), also known as brine shrimp, are typical inhabitants of extreme environments. These hypersaline environments vary considerably in their physicochemical composition, and even their climatic conditions and elevation. Several thalassohaline (marine) environments along the Colombian Caribbean coast were surveyed in order to contribute to the knowledge of brine shrimp biotopes in South America by determining some vital biological and physicochemical parameters for Artemia survival. Additionally, cyst quality tests, biometrical and essential fatty acids analysis were performed to evaluate the economic viability of some of these strains for the aquaculture industry.ResultsIn addition to the three locations (Galerazamba, Manaure, and Pozos Colorados) reported in the literature three decades ago in the Colombian Caribbean, six new locations were registered (Salina Cero, Kangaru, Tayrona, BahÃ­a Hondita, Warrego and Pusheo). All habitats sampled showed that chloride was the prevailing anion, as expected, because of their thalassohaline origin. There were significant differences in cyst diameter grouping strains in the following manner according to this parameter: 1) San Francisco Bay (SFB-Control, USA), 2) Galerazamba and Tayrona, 3) KangarÃº, 4) Manaure, and 5) Salina Cero and Pozos Colorados. Chorion thickness values were smaller in Tayrona, followed by Salina Cero, Galerazamba, Manaure, SFB, KangarÃº and Pozos Colorados. There were significant differences in naupliar size, grouping strains as follows (smallest to largest): 1) Galerazamba, 2) Manaure, 3) SFB, KangarÃº, and Salina Cero, 4) Pozos Colorados, and 5) Tayrona. Overall, cyst quality analysis conducted on samples from Manaure, Galerazamba, and Salina Cero revealed that all sites exhibited a relatively high number of cysts.g-1. Essential fatty acids (EFA) analysis performed on nauplii from cyst samples from Manaure, Galerazamba, Salina Cero and Tayrona revealed that cysts from all sites exhibited high arachidonic acid:20:4(n-6) (ArA) and eicosapentaenoic acid: 20:5(n-3) (EPA) levels comparable to the control sample (SFB). In contrast, most cysts collected (including SFB) at different locations, and during different months, presented low docosahexaenoic acid: 22:6(n-3) (DHA) levels (Manaure was the only exception with high DHA levels). Some variations in EPA and ArA levels were observed in all sites, contrasting with the much lower DHA levels which remained constant for all locations, except for Manaure which exhibited variable DHA levels. DHA/EPA ratio was overall very low for all sites compared to SFB cysts. All strains had a low DHA/ArA, but a high EPA/ArA ratio, including the control.ConclusionThe Colombian A. franciscana habitats analyzed were determined to be thalassohaline, and suitable for A. franciscana development. EFA profiles demonstrated that Tayrona, Galerazamba, Manaure and Salina Cero strains are suitable food for marine fish and crustacean culture because of their high EPA/ArA ratio, but might have to be fortified with DHA rich emulsions depending on the nutritional requirements of the species to be cultured, because of their overall low DHA content. The relatively small nauplii are appropriate for marine larvaeculture. In contrast, the strains from Tayrona, KangarÃº, Salina Cero, and Pozos Colorados may be of use but limited to Artemia small biomass production quantities, because of the small surface area of their respective locations; Artemia could be exploited at these locations for local aquaculture applications. In general, cyst quality evaluation for Manaure, Salina Cero and Galerazamba cysts revealed that cysts from these three locations could improve their quality by concentrating efforts on cyst processing techniques. Finally, most locations had great A. franciscana production potential and require different degrees of water quality and/or infrastructure management.",2005,Saline Systems
A Network-Based Approach to Enhance Electricity Load Forecasting,"In the field of energy analysis, time series forecasting techniques are widely used to predict customer electricity consumptions. To enhance the electricity forecasting accuracy, in current approaches, clustering techniques are first applied to identify groups of customers exhibiting the same electricity load profile, from which a representative consumption pattern can be extracted. This pattern is later used to predict customers' subsequent electricity consumption. In the vast majority of clustering approaches, authors use the entire data set as input to identify customer consumption groups. However, electricity load data vary extremely rapidly and can thus be dominated by outdated historical information which may influence the effective cluster status at a given time-stamp. To overcome this constraint, instead of using the entire data set, we propose an adaptive process which involves tracking the evolution of identified customer consumption groups at different time-stamps. A network structure is used to model the interrelation between customer electricity load profiles. The network is then split into subnetworks that are treated as customer electricity consumption clusters. Representative subseries, called master subseries, are extracted to track the evolution of clusters over time. Finally, the master subseries are used as a knowledge base for forecasting customers' electricity consumption at later time-stamps and automatically predicting future cluster status. The load forecasting is done using a seasonal autoregressive integrated moving average model, which is compared to a multi-layer perceptron, support vector regression, lasso regression, bayesian ridge regression and K-nearest neighbor regression models.",2018,2018 IEEE International Conference on Data Mining Workshops (ICDMW)
Appearance-Based Outdoor Localization Using Group LASSO Regression,"This paper presents appearance-based localization for an omni-directional camera that builds on a combination of the group Least Absolute Shrinkage and Selection Operator (LASSO) and the extended Kalman filter (EKF). A histogram that represents the population of the Speeded-Up Robust Features (SURF points) is computed for each image, the features of which are selected via the group LASSO regression. The EKF takes the output of the LASSO regression-based first localization as observations for the final localization. The experimental results demonstrate the effectiveness of our approach.Copyright Â© 2015 by ASME",2015,
Jurassic-Cretaceous Boundary Strata of the Somanakamura Group in NE Japan and their Correlation with Coeval Terrestrial Deposits in China,"Defining the Jurassic-Cretaceous boundary is a controversy in stratigraphic study of the world. It has been widely accepted that this boundary can be defined at the bottom of Berriasian in Tethys, with the appearance of the ammonite Berriasella jacobi dating to ca. 145 Ma. However, it is difficult for the widespread terrestrial deposits in China to correlate with the international standard of marine facies. The Somanakamura Group in Japan is represented by a succession of marine-continental transitional strata. It provides a bridge of marine and nonmarine stratigraphic correlation. The ammonite and radiolarian fossils preserved in this group suggest an age from Bajocian to early Valanginian. The J-K boundary was defined in or atop the Tomizawa Formation of the group according to the ammonite data. The present authors study the fossil spores and pollen newly found from the Tomizawa and Koyamada formations. Three assemblages have been recognized. They are Assemblage 1 (Cyathidites-Classopollis) from the upper part of the Tomizawa Formation, Assemblage 2 (Cyathidites-Jiaohepollis) from the lower part of the Koyamada Formation, and Assemblage 3 (Cyathidites-Spheripollenites-Ephedripites) from the middle to upper part of the Koyamada Formation. With the reference of ammonite evidence, the J-K boundary can be defined between Assemblage 1 and Assemblage 2. This palynological J-K boundary can be correlated with that of terrestrial sequence in China. However, local biostratigraphy imply that the continental J-K boundary in China is of 135 or 137 Ma age. It has a considerable discrepancy from the marine standard. Biogeographically, the distribution pattern of spores and pollen in southern China is in accordance with that in the Somanakamura Group, which parallels the Tuchengzi Formation in northeastern China. By the palynological correlation between the Somanakamura Group and the strata in southern China, and then with the sequence in northeastern China, it is suggested that the continental J-K boundary is located in the Tuchengzi Formation.",2015,Acta Geologica Sinica-english Edition
Review of STI and HIV epidemiological data from 1990 to 2001 in urban Burkina Faso: implications for STI and HIV control.,"OBJECTIVES
To better understand the sexually transmitted infection (STI)/HIV dynamics in an urban west African setting in order to adapt STI/HIV control efforts accordingly.


METHODS
Review of STI and HIV epidemiological studies performed over the past decade in Bobo-Dioulasso, the second city of Burkina Faso. Trends in STI prevalence among commercial sex workers and the general population were assessed over time through studies that used the same recruitment and laboratory diagnostic procedures. Variations in aetiologies of vaginal discharge, urethral discharge, and genital ulcers were also evaluated among patients consulting for genital infection complaints. Antenatal clinic based surveys provided data to assess HIV trend among the general population.


RESULTS
We observed an important decline of classic bacterial STI such as syphilis, Neisseria gonorrhoea, Chlamydia trachomatis, and Haemophilus ducrey infections in all study groups. Trichomoniasis also declined but to a lesser extent. HIV infection followed the same trend at the same time, with a significant decline in the 15-19 year age group of pregnant women, suggesting a possible decrease of HIV incidence. Although no evidence of a causal relation can be drawn from this review, adoption of safer sex behaviour, introduction of the syndromic management (SM) approach, or higher antibiotic use may have contributed to these changes.


CONCLUSIONS
Classic bacterial STI declined over the past decade in parallel with a stabilisation of HIV infection. Variations in syndromes aetiology and sexual behaviours should be monitored as part of STI surveillance in order to improve STI syndromic management algorithms and to adapt HIV/STI prevention efforts.",2004,Sexually transmitted infections
Private Inter-household Transfers in Vietnam in the Early and Late 1990 s Author :,"This chapter uses data from the 1992/93 and 1997/98 Vietnam Living Standards Surveys (VLSS) to describe patterns of money transfers between households. Rapid economic growth during the 1990â€™s did little to diminish the importance of private transfers in Vietnam. Private transfers are large and widespread in both surveys, and they are much larger than public transfers are. Private transfers appear to function like means-tested public transfers, flowing from better off to worse off households and providing old-age support in retirement. Panel evidence suggests some hysteresis in private transfer patterns, but many households also changed from recipients to givers and vice versa between surveys. Changes in private transfers appear responsive to changes in household pretransfer income, demographic changes and life-course events. Transfer inflows rise upon retirement and widowhood, for example, and are positively associated with increases in health expenditures. It also appears that private transfer inflows increased for households affected by Typhoon Linda, which devastated Vietnamâ€™s southernmost provinces in late 1997. ________________________________________________________________________________ * Correspondence donald.cox@bc.edu . This paper has been prepared as part of the World Bank funded project â€œEconomic Growth and Household Welfare â€“ Policy Lessons from Vietnamâ€ directed by co-principal investigators David Dollar and Paul Glewwe. I thank Paul Glewwe for comments on earlier drafts and Emanuela Galasso for help with the 1997/98 VLSS data. The support of the World Bankâ€™s research committee is gratefully acknowledged.",2014,
Logistic Regression with Structured Sparsity,"Binary logistic regression with a sparsity constraint on the solution plays a vital role in many high dimensional machine learning applications. In some cases, the features can be grouped together, so that entire subsets of features can be selected or zeroed out. In many applications, however, this can be very restrictive. In this paper, we are interested in a less restrictive form of structured sparse feature selection: we assume that while features can be grouped according to some notion of similarity, not all features in a group need be selected for the task at hand. This is sometimes referred to as a â€œsparse groupâ€ lasso procedure, and it allows for more flexibility than traditional group lasso methods. Our framework generalizes conventional sparse group lasso further by allowing for overlapping groups, an additional flexiblity that presents further challenges. The main contribution of this paper is a new procedure called Sparse Overlapping Sets (SOS) lasso, a convex optimization program that automatically selects similar features for learning in high dimensions. We establish consistency results for the SOSlasso for classification problems using the logistic regression setting, which specializes to results for the lasso and the group lasso, some known and some new. In particular, SOSlasso is motivated by multi-subject fMRI studies in which functional activity is classified using brain voxels as features, source localization problems in Magnetoencephalography (MEG), and analyzing gene activation patterns in microarray data analysis. Experiments with real and synthetic data demonstrate the advantages of SOSlasso compared to the lasso and group lasso.",2014,ArXiv
"Anisostagma rotundatum gen. et sp. nov., a lignicolous marine ascomycete from SvanemÃ¸llen Harbour in Denmark","Anisostagma rotundatum gen. et sp. nov., a lignicolous marine ascomycete belonging to the Halosphaeriaceae is described from a harbour environment at the Oresund coast, Denmark. It was found in the tidal water region of mooring posts of oak (Quercus sp.). The species is compared with Thalassogena sphaerica, Iwilsoniella rotunda and Hapsidascus hadrus.",1996,Fungal Biology
"Solar Panel Tilt Angle Optimization Using Machine Learning Model: A Case Study of Daegu City, South Korea","Finding optimal panel tilt angle of photovoltaic system is an important matter as it would convert the amount of sunlight received into energy efficiently. Numbers of studies used various research methods to find tilt angle that maximizes the amount of radiation received by the solar panel. However, recent studies have found that conversion efficiency is not solely dependent on the amount of radiation received. In this study, we propose a solar panel tilt angle optimization model using machine learning algorithms. Rather than trying to maximize the received radiation, the objective is to find tilt angle that maximizes the converted energy of photovoltaic (PV) systems. Considering various factors such as weather, dust level, and aerosol level, five forecasting models were constructed using linear regression (LR), least absolute shrinkage and selection operator (LASSO), random forest (RF), support vector machine (SVM), and gradient boosting (GB). Using the best forecasting model, our model showed increase in PV output compared with optimal angle models.",2020,Energies
EROS: explorer for RDFS-based ontologies,"1. THE CHALLENGE IN VISUALIZING RDFS-BASED ONTOLOGIES RDFS is an acknowledged backbone of the Semantic Web architecture. Browsing and querying RDFS-based ontologies is becoming a characteristic (user) activity in Semantic Web applications. We argue that due to peculiarities of the RDFS language a new interface is needed to convey RDFS-based ontologies to the end-user in a comprehensible form. The two main approaches currently used, the tree-based approach and the graph-based approach, do not fulfill the above requirement completely. The tree paradigm does not help the user in grasping other concept relationships than that used to construct the tree structure (most of the time being the rdfs:subClassOf relationship). The graph approach, on the other hand, displays all concept relationships but as a result introduces the full complexity of a directed labeled graph in which it is very difficult to spot the hierarchical structure of the ontology â€œhiddenâ€ behind the special kind of edges.",2003,
"Elassoma Gilberti , a New Species of Pygmy Sunfish ( Elassomatidae ) from Florida and Georgia","A new species of pygmy sunfish, Elassoma gilberti (Elassomatidae), is described from northwestern Florida and extreme southwestern Georgia. It previously has been confused with its sister species, Elassoma okefenokee BÃ¶hlke 1956. The two are very similar morphologically, but differ in the number of preopercular canal pores (four in E. gilberti, three in E. okefenokee), in average number of anal fin rays (usually seven in E. gilberti, usually eight in E. okefenokee), and in more subtle differences in coloration, body depth, and dorsal and anal fin size. The distinction of the two species is supported by eight fixed differences at the mitochondrial 16S rRNA locus and 12 fixed differences at the nuclear S7 locus. Phylogenetic analyses using these molecular characters supported monophyletic clades that contained haplotypes and alleles found uniquely in the two taxa. Elassoma gilberti is found in stream systems draining into the Gulf of Mexico from Choctawhatchee Bay in the Florida panhandle south to the Withlacoochee and Homosassa drainages in west-central Florida. Both species occur in the Suwannee River drainage, E. gilberti in the lower and middle sections and E. okefenokee in the middle and upper sections. They remain genetically distinct where sampled in this drainage but have not been found syntopically. The history and nomenclatural status of the name Elassoma evergladei orlandicum LÃ¶nnberg 1894 is discussed and a lectotype is designated based on the earlier findings of R. M. Bailey and J. E. BÃ¶hlke. Lectotype designation relegates the name to the synonymy of Elassoma evergladei Jordan 1884.",2010,
Anticorpi policlonali prodotti nella gallina: unâ€™alternativa allâ€™utilizzo di mammiferi,"RIASSUNTO Il problema legato al benessere animale e una questione dai risvolti etici che negli ultimi anni ha notevolmente condizionato la ricerca scientifica coinvolgendo sempre di piu alcuni settori della medicina veterinaria. Nei laboratori di ricerca, infatti, si fa spesso uso di animali per la sperimentazione, come nel caso della produzione di anticorpi. Le metodiche impiegate possono talvolta causare sofferenze agli animali e, per questo motivo, da anni sono allo studio metodi alternativi a quelli piu frequentemente utilizzati. Lâ€™immunizzazione di galline con antigeni di natura proteica consente di ottenere grandi quantita di anticorpi dai tuorli delle uova. Questo tipo di procedura comporta alcuni vantaggi sia dal punto di vista del benessere animale, in quanto scongiura i prelievi ematici per la valutazione del titolo anticorpale dellâ€™animale in vita ed il salasso finale per la raccolta degli anticorpi, sia da quello economico dati i minori costi gestionali rispetto ai mammiferi da laboratorio di medie dimensioni e la maggiore resa finale di anticorpi. In questo lavoro sono stati prodotti anticorpi policlonali nelle galline contro una delle somatotropine bovine ricombinanti (rbST) esistenti in commercio, al fine di operare un confronto con anticorpi policlonali precedentemente prodotti nel coniglio contro la stessa molecola. Il raffronto delle curve ottenute tramite un test ELISA sandwich, messo a punto in precedenza per la quantificazione di bST nel siero e ripetuto utilizzando le due diverse specie anticorpali, ci ha permesso di valutare lâ€™effettiva validita dellâ€™immunizzazione di galliformi per la produzione di grandi quantita di immunoglobuline. SUMMARY Concerns about animal welfare are connected with ethical issues that affect scientific research, involving many veterinary fields. As a matter of facts, animals are often employed for experimental purposes, such as the production of antibodies. Applied methods could sometimes cause suffering to animals and for this reason several studies on alternative methods for antibody production are in progress. Immunisation of hens against proteic antigens allows to obtain a great amount of antibodies from the yolk of treated chicken eggs. This sort of practice brings many advantages for animal welfare, since blood collection is not necessary. In addition, some more advantages come either from the reduced breeding costs with respect to medium-size mammals or the higher antibodies yield. In this work, we have produced polyclonal antibodies in hens against one of the commercialised recombinant bovine somatotropins (rbST), with the aim to make a comparison with rabbit polyclonal antibodies against the same molecule, already produced in an earlier work. With this purpose, we performed a sandwich ELISA previously developed for bST measurement in serum and then compared the curves obtained by using the two different kind of polyclonal antibodies. This allowed us to estimate the worth of poultry immunisation for the production of a great amount of specific antibodies.",2004,
Forward LASSO analysis for high-order interactions in genome-wide association study,"Previous genome-wide association study (GWAS) focused on low-order interactions between pairwise single-nucleotide polymorphisms (SNPs) with significant main effects. Little is known how high-order interactions effect, especially one among the SNPs without main effects regulates quantitative traits. Within the frameworks of linear model and generalized linear model, the LASSO with coordinate descent step can be used to simultaneously analyze thousands and thousands of SNPs for normal and discrete traits. With consideration of high-order interactions among SNPs, a huge number of genetic effects make the LASSO failing to work under the presented condition of computation. Forward LASSO analysis is, therefore, proposed to shrink most of genetic effects to be zeros stage by stage. Simulation demonstrates that our proposed method could be used instead of the LASSO method for full model in mapping high-order interactions. Application of forward LASSO method is provided to GWAS for carcass traits and meat quality traits in beef cattle.",2014,Briefings in bioinformatics
Whole blood transcriptome analysis in amyotrophic lateral sclerosis: A biomarker study,"The biological pathways involved in amyotrophic lateral sclerosis (ALS) remain elusive and diagnostic decision-making can be challenging. Gene expression studies are valuable in overcoming such challenges since they can shed light on differentially regulated pathways and may ultimately identify valuable biomarkers. This two-stage transcriptome-wide study, including 397 ALS patients and 645 control subjects, identified 2,943 differentially expressed transcripts predominantly involved in RNA binding and intracellular transport. When batch effects between the two stages were overcome, three different models (support vector machines, nearest shrunken centroids, and LASSO) discriminated ALS patients from control subjects in the validation stage with high accuracy. The models' accuracy reduced considerably when discriminating ALS from diseases that mimic ALS clinically (N = 75), nor could it predict survival. We here show that whole blood transcriptome profiles are able to reveal biological processes involved in ALS. Also, this study shows that using these profiles to differentiate between ALS and mimic syndromes will be challenging, even when taking batch effects in transcriptome data into account.",2018,PLoS ONE
Integrative weighted group lasso and generalized local quadratic approximation,"Longitudinal clinical outcomes are often collected in genomic studies, where selection methods accounting for dynamic effects of biomarkers are desirable. Biomarker effects can be modeled by nonparametric B-splines and selected by group lasso. A novel weight function is proposed based on the extremum of the biomarker effects over time for the penalty. In addition to the common practice treating weights as adaptive functions depending on some first-stage estimates, an integrative group lasso which treats the loss, penalty and weight functions as an integrative whole is proposed, where parameters in all three are jointly estimated in one step. Generalized local quadratic approximations are developed to optimize the integrative group lasso whose guidelines are applicable in a wide range of non-convex optimization problems. The integrative version has theoretical advantages as it requires weaker assumptions in achieving consistency and sparsistency. Both adaptive and integrative procedures show larger areas under the ROC curves as well as smaller biases and mean square prediction errors over unweighted group lasso in simulation studies. Finally, the proposed method is illustrated on the GWAS from the Epidemiology and Intervention of Diabetes Complication trial. To accommodate more candidate markers, 23 chromosomes are analyzed separately with common tuning parameters. Weighted group lasso emphasizing extremum selects dynamic biomarker effects.Parameters in the loss, penalty and weight functions are estimated simultaneously.Local quadratic approximation is generalized to non-convex optimization problems.",2016,Comput. Stat. Data Anal.
Regression Approximations to Estimate Sensitivities,"Chapter 5 explores the idea of using regression problems to estimate sensitivities. Section 5.1 explains how one might approximate the gradient of the QoI at a nominal point using a least-squares (regression) formulation. This naive approach requires more QoI evaluations than one-sided finite differences as described in the previous chapter. Section 5.2 introduces a regularization term into the least-squares minimization problem, allowing for useful solutions also for the case where fewer QoI evaluations than parameters are available; sparsity-promoting regularization (1-norm, LASSO) and a combination of 1-norm and 2-norm (elastic net) are considered. Section 5.3 adds cross-validation techniques for selecting the regularization parameters.",2018,
Gradient Directed Regularization,"Regularization in linear regression and classiÂ…cation is viewed as a twoÂ–stage process. First a set of candidate models is deÂ…ned by a path through the space of joint parameter values, and then a point on this path is chosen to be the Â…nal model. Various pathÂ…nding strategies for the Â…rst stage of this process are examined, based on the notion of generalized gradient descent. Several of these strategies are seen to produce paths that closely correspond to those induced by commonly used penalization methods. Others give rise to new regularization techniques that are shown to be advantageous in some situations. In all cases, the gradient descent pathÂ…nding paradigm can be readily generalized to include the use of a wide variety of loss criteria, leading to robust methods for regression and classiÂ…cation, as well as to apply user deÂ…ned constraints on the parameter values. Key words and phrases : linear models, regularization, regression, classiÂ…cation, gradient descent, robustness, constrained estimation, lasso, ridgeÂ–regression, leastÂ–angle regression LARS, partial least squares PLS, linear support vector machines SVM.",2004,
Nonparametric estimation of galaxy cluster's emissivity and point source detection in astrophysics with two lasso penalties,"Astrophysicists are interested in recovering the 3D gas emissivity of a galaxy cluster from a 2D image taken by a telescope. A blurring phenomenon and presence of point sources make this inverse problem even harder to solve. The current state-of-the-art technique is two step: first identify the location of potential point sources, then mask these locations and deproject the data. 
We instead model the data as a Poisson generalized linear model (involving blurring, Abel and wavelets operators) regularized by two lasso penalties to induce sparse wavelet representation and sparse point sources. The amount of sparsity is controlled by two quantile universal thresholds. As a result, our method outperforms the existing one.",2017,arXiv: Applications
The Knowledge Gradient Policy Using A Sparse Additive Belief Model,"We propose a sequential learning policy for noisy discrete global optimization and ranking and selection (R\&S) problems with high dimensional sparse belief functions, where there are hundreds or even thousands of features, but only a small portion of these features contain explanatory power. We aim to identify the sparsity pattern and select the best alternative before the finite budget is exhausted. We derive a knowledge gradient policy for sparse linear models (KGSpLin) with group Lasso penalty. This policy is a unique and novel hybrid of Bayesian R\&S with frequentist learning. Particularly, our method naturally combines B-spline basis expansion and generalizes to the nonparametric additive model (KGSpAM) and functional ANOVA model. Theoretically, we provide the estimation error bounds of the posterior mean estimate and the functional estimate. Controlled experiments show that the algorithm efficiently learns the correct set of nonzero parameters even when the model is imbedded with hundreds of dummy parameters. Also it outperforms the knowledge gradient for a linear model.",2015,ArXiv
Integrative Analysis for Lung Adenocarcinoma Predicts Morphological Features Associated with Genetic Variations,"Lung cancer is one of the most deadly cancers and lung adenocarcinoma (LUAD) is the most common histological type of lung cancer. However, LUAD is highly heterogeneous due to genetic difference as well as phenotypic differences such as cellular and tissue morphology. In this paper, we systematically examine the relationships between histological features and gene transcription. Specifically, we calculated 283 morphological features from histology images for 201 LUAD patients from TCGA project and identified the morphological feature with strong correlation with patient outcome. We then modeled the morphology feature using multiple co-expressed gene clusters using Lasso-regression. Many of the gene clusters are highly associated with genetic variations, specifically DNA copy number variations, implying that genetic variations play important roles in the development cancer morphology. As far as we know, our finding is the first to directly link the genetic variations and functional genomics to LUAD histology. These observations will lead to new insight on lung cancer development and potential new integrative biomarkers for prediction patient prognosis and response to treatments.",2017,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
Smooth sparse representation for noise robust face super-resolution,"Face super-resolution has attracted much attention in recent years. Many algorithms have been proposed. Among them, sparse representation based face super-resolution approaches are able to achieve competitive performance. However, these sparse representation based approaches only perform well under the condition that the input is noiseless or has small noise. When the input is corrupted by large noise, the reconstruction weights of the input LR patches using sparse representation based approaches will be seriously unstable, thus leading to poor reconstruction results. To this end, in this paper, we propose a novel sparse representation based face super-resolution approach that incorporates a smooth prior to enforce similar training patches having similar sparse coding coefficients. Specifically, we introduce the fused Lasso to the least squares representation of the input LR image in order to obtain a stable sparse representation, especially when the noise level of the input LR image is high. Experiments are carried out on the benchmark FEI face dataset. Visual and quantitative comparisons show that the proposed face super-resolution method achieves comparable performance to the state-of-the-art methods under noiseless condition, and yields superior super-resolution results when the input LR face image is contaminated by strong noise.",2016,2016 Visual Communications and Image Processing (VCIP)
"Bibliography of Robert M. Solow's Publications, 1950-1987","1952 6. 'An Econometric Model of Interindustry Flows,"" (with K. J. Arrow and R. Shephard, abstract), Econometrica, July 1952. 7. ""On the Structure of Linear Models,"" Econometrica, January 1952. 8. Review of W. E. Deming: Some Theory of Sampling, Review of Econometrics and Statistics, May 1952. 9. Review of R. Dorfman: Application of Linear Programming to the Theory of the Firm, Journal of American Statistical Association, June 1952. 10. Review of T. C Koopmans (ed.): Activity Analysis of Production and Allocation, Journal of American Statistical Association, June 1952. 11. Review of R. Roy (ed.): Cahiers dii Seminaire dEconometrie, No. 1, Journal of American StatisticalAssociation, December 1952.",1988,The Scandinavian Journal of Economics
Learning step sizes for unfolded sparse coding,"Sparse coding is typically solved by iterative optimization techniques, such as the Iterative Shrinkage-Thresholding Algorithm (ISTA). Unfolding and learning weights of ISTA using neural networks is a practical way to accelerate estimation. In this paper, we study the selection of adapted step sizes for ISTA. We show that a simple step size strategy can improve the convergence rate of ISTA by leveraging the sparsity of the iterates. However, it is impractical in most large-scale applications. Therefore, we propose a network architecture where only the step sizes of ISTA are learned. We demonstrate that for a large class of unfolded algorithms, if the algorithm converges to the solution of the Lasso, its last layers correspond to ISTA with learned step sizes. Experiments show that our method is competitive with state-of-the-art networks when the solutions are sparse enough.",2019,
The Routledge History of Childhood in the Western World,"Introduction. Is There a Story in the History of Childhood? Paula S. Fass. Part I Childhood in the Ancient World, the Middle Ages and Early Modern Europe. 1.1 Childhood in the Ancient World up to Christianity. Keith Bradley 1.2. Childhood in Judaism and Christianity. Margaret King 1.3. Childhood in the Middle Ages and Early Modern Europe. Joanne Ferraro 1.4. Childhood and the Enlightenment: The Complications of Innocence. Larry Wolff Part II Creating Childhoods in the Western World Since 1600. 2.1. Parents and Children. Julia Grant 2.2. Children's Work in Countryside and City. Colin Heywood 2.3. Children and War. James Marten 2.4. The Emotional Life of Children. Peter Stearns 2.5. Children and the State. James Schmidt 2.6. The Vexed History of Children and Sex. Beth Bailey. 2.7. Age, Schooling and Life Stages. Stephen Lassonde 2.8. Adolescence. Don Romesburg 2.9. The Physical Spaces of Childhood. Marta Gutman 2.10. Games, Toys and Play. Gary Cross 2.11. Children and Consumption. Daniel Thomas Cook 2.12. Picturing Children in the Modern West. Anne Higonnet 2.13. Children's Literature. Maria Nikolajeva. Part III Special Children at Special Times or Places 3.1. Children in North American Slavery. Steven Mintz 3.2. Mixed Race Children in the American West. Anne Hyde 3.3. Infanticide and Abortion in Sweden. Bengt Sandin 3.4. Dependent Children, Social Welfare, and the Rights of Children. Ivan Jablonka 3.5. Children as Vagrants, Vagabonds, and Thieves. Timothy Gilfoyle 3.6. Scouting and Other Organizations for Children and Youth. Jay Mechlin 3.7. Children in the Great Depression in the United States. Kriste Lindenmeyer 3.8. Childhood in Nazi Germany. Dirk Schumann 3.9. International Child Saving. Dominique Marshall 3.10. Latin American Childhoods. Nara Milanich",2012,
Transnasal canthoplasty.,"The reconstruction of a traumatic telecanthus, particularly the repositioning and securing of the medial canthal tendon, presents a challenge to the reconstructive surgeon. The adequate positioning of the medial canthal tendon for proper intercanthal distance, and apposition of the lid to the globe, is the cornerstone of a successful reconstruction. The authors have developed a technique for transnasal canthoplasty that is fast, relatively easy, and safe. Transnasally, a 16-gauge spinal needle is introduced over a preplaced K-wire using a 4-0 Bunnell stainless wire suture (Ethicon, Somerville, NJ). The medial canthal tendon is lassoed, secured, and then fixed to the contralateral nasal bone. Six patients have undergone this technique to date. The authors believe this procedure offers an improvement to existing methods.",1997,The Journal of cranio-maxillofacial trauma
"Comunidad Ã­ctica de una franja arrecifal del Parque Nacional Mochima, Venezuela Fish community of a fringing reef at Mochima National Park, Venezuela","The fish community associated with a fringing reef was studied at Cautaro, Mochima National Park, Venezuela. A systematic sampling design based on visual censuses was carried out from December 2000 to May 2002. A total of 86 species belonging to 31 families were identified, dominated by Scaridae (10), Haemulidae and Labridae (9), Pomacentridae (7) and Serranidae (6), which accumulated, together with the sole species of Sparidae, 77.52% of the total abundance. Diplodus argenteus (13.15%), Microspathodon chrysurus (13.00%) and Thalassoma bifasciatum (10.79%) were the most abundant and frequent (>50%) species, and can therefore be considered typical and characteristic of the study area. The total diversity was 4.54 bits ind â€“1 and oscillated between 3.33 and 4.25 bits ind â€“1 , with an average of 3.86. Equitability varied between 0.74 and 0.89. The relationship between species abundance and rank was significant (r = 0.976) and the diversity index of the log-series based on the number of species was Î± = 14.19. The trophic analysis of the community indicated that the carnivorous species constituted the dominant group (63.10%), followed by the herbivores (21.40%) and omnivores (15.50%). The normal distribution fitted the species abundance data, indicating a tendency towards stabilization in relation to the number of species.",2006,
Group MCP for Cox Models with Time-Varying Coefficients,"Abstract Coxâ€™s proportional hazard models with time-varying coefficients have much flexibility for modeling the dynamic of covariate effects. Although many variable selection procedures have been developed for Coxs proportional hazard model, the study of such models with time-varying coefficients appears to be limited. The variable selection methods involving nonconvex penalty function, such as the minimax concave penalty (MCP), introduces numerical challenge, but they still have attractive theoretical properties and were indicated that they are worth to be alternatives of other competitive methods. We propose a group MCP method that uses B-spline basis to expand coefficients and maximizes the log partial likelihood with nonconvex penalties on regression coefficients in groups. A fast, iterative group shooting algorithm is carried out for model selection and estimation. Under some appropriate conditions, the simulated example shows that our method performs competitively with the group lasso method. By comparison, the group MCP method and group lasso select the same amount of important covariates, but group MCP method tends to outperform the group lasso method in selection of unimportant covariates.",2016,Journal of Systems Science and Information
"Statut du portage du virus de lâ€™hÃ©patite B (VHB) au sein du personnel de santÃ© du CHU SourÃ´ Sanou de Bobo-Dioulasso, Burkina Faso","RÃ©sumÃ©Le virus de lâ€™hÃ©patite B se transmet sexuellement mais Ã©galement par le sang. Les personnels de santÃ© reprÃ©sentent un groupe Ã  risque.ObjectifEvaluer le portage de lâ€™AgHBs chez le personnel de santÃ© du CHU SourÃ´ Sanou (CHUSS) de Bobo-Dioulasso afin de connaÃ®tre son ampleur et dâ€™envisager les mesures Ã  prendre.Personnel et mÃ©thodeIl sâ€™agissait dâ€™une Ã©tude transversale descriptive, qui sâ€™est dÃ©roulÃ©e du 9 mars au 13 avril 2012 pour la phase dâ€™enquÃªte et du 29 aoÃ»t au 4 septembre 2012 pour la phase dâ€™analyse biologique au laboratoire. Elle a concernÃ© le personnel de santÃ© exerÃ§ant dans un service hospitalier ou au laboratoire du CHUSS. Chaque personnel consentant a rÃ©pondu Ã  un questionnaire qui a permis de recueillir les donnÃ©es socio-dÃ©mographiques et les antÃ©cÃ©dents. Il a ensuite Ã©tÃ© soumis Ã  un prÃ©lÃ¨vement de 10 ml de sang veineux, dans le but dâ€™explorations biologiques (recherche Ag HBs, Anticorps anti HBs, Anticorps anti VHC et Anticorps anti VIH).RÃ©sultatsAu total, 285 agents de la santÃ©, Ã¢gÃ©s de 25 Ã  60 ans avec un Ã¢ge moyen de 43,6 Â± 8,2 ans ont participÃ© Ã  lâ€™Ã©tude. Cent vingt-trois agents (43,2%), ont dÃ©clarÃ© avoir reÃ§u au moins une dose de vaccin durant leur cursus professionnel. Trente-deux agents (32), soit 11,2% de lâ€™effectif, avaient une sÃ©rologie positive pour lâ€™AntigÃ¨ne HBs et parmi eux, 9 (soit 7,4% des agents vaccinÃ©s). La recherche de lâ€™Anticorps antiHBs sâ€™est rÃ©vÃ©lÃ©e positive chez 136 agents (47,7% des sujets de lâ€™Ã©tude), dont 45 non vaccinÃ©s (soit 27,8% dâ€™entre eux) et 91 vaccinÃ©s (73,9% dâ€™entre eux). Sept personnes, reprÃ©sentant 2,4% des sujets concernÃ©s avaient une sÃ©rologie VHC positive. Le dosage de lâ€™ARN HVC nâ€™a pu Ãªtre fait. Aucune co-infection ni avec le VHB ni avec le VIH nâ€™a Ã©tÃ© notÃ©e. Quatorze agents (soit 4,9% des sujets de lâ€™Ã©tude) avaient des anticorps anti VIH 1, dont un cas de co-infection VIH/VHB notÃ©.ConclusionLe portage du virus de lâ€™hÃ©patite B demeure un problÃ¨me dans les formations sanitaires du Burkina Faso. Le taux de couverture vaccinale chez les agents de santÃ© du CHUSS est faible (moins de 50%). Cette vaccination doit Ãªtre obligatoire et gratuite pour tous les agents de santÃ©.AbstractThe hepatitis B virus is sexually transmitted, but also by blood. Healthcare workers represent a group at risk.ObjectiveEvaluate the HBsAg carriers among the healthcare personnel in the Sanou Souro University Teaching Hospital (CHUSS) Bobo-Dioulasso to know its magnitude and consider further measures to be taken.Personnel and methodThis was a descriptive crosssectional study, which took place from 9 March to 13 April 13, 2012 for the data collection phase and from 29 August to 4 September 2012 for the biological analysis in the laboratory. It concerned healthcare personnel working in a hospital service or at the laboratory of the CHUSS. Each consenting staff responded to a questionnaire which collected demographic data and history. Each subject then gave 10 mls of venous blood sample for biological analysis (looking for HBs Ag, HBs Antibody, HCV Antibody and HIV Antibody).ResultsIn total, 285 healthcare workers, aged between 25 to 60 years with an average age of 43.6 Â± 8.2 years participated in the study. Forty three percent (43.2%) of the workers reported having received at least one dose of the vaccine during their professional training. Thirty two (32) workers or 11.2% of the participants had a positive serology for HBs Antigen and among them, 9 (or 7.4% of the vaccinated workers). The search for the HBs Antibody was positive 91 vaccinated workers (73.9% of them). Seven people, representing 2.4% of the study subjects had a positive HCV serology. The determination of the HVC RNA could not be made. No co-infection with HBVor HIV were noted. Fourteen agents (4.9% of the study subjects) had HIV 1 antibodies, including one case of HIV/HBV co-infection. amongst 136 workers (47.7% of the study subjects), including 45 non-vaccinated workers (27.8% of them) andConclusionThe transmission of the hepatitis B virus remains a problem in healthcare facilities in Burkina Faso. The rate of vaccination coverage among the CHUSS healthcare workers is low (less than 50%). This vaccination must be compulsory and free for all healthcare workers.",2015,Journal Africain d'HÃ©pato-GastroentÃ©rologie
Discriminative Feature Selection for Multiple Ocular Diseases Classification by Sparse Induced Graph Regularized Group Lasso,"Glaucoma, Pathological Myopia (PM), and Age-related Macular Degeneration (AMD) are three leading ocular diseases worldwide. Visual features extracted from retinal fundus images have been increasingly used for detecting these three diseases. In this paper, we present a discriminative feature selection model based on multi-task learning, which imposes the exclusive group lasso regularization for competitive sparse feature selection and the graph Laplacian regularization to embed the correlations among multiple diseases. Moreover, this multi-task linear discriminative model is able to simultaneously select sparse features and detect multiple ocular diseases. Extensive experiments are conducted to validate the proposed framework on the SiMES dataset. From the Area Under Curve (AUC) results in multiple ocular diseases classification, our method is shown to outperform the state-of-the-art algorithms.",2015,
The Persistence of the Trace: Interrogating the Gods of Speculative Realism,"This essay seeks to bring the speculative realism of Quentin Meillassoux into dialogue with Derrida on matters of religion. It argues that the answer Meillassoux provides to the suffering of the world - to wait for a future God to come - is abstract and empty. Turning to Derrida, it shows that the recent turn to speculative thinking in philosophy has been unduly dismissive of deconstruction, misreading its claims about the ubiquity of the trace. Rescuing the trace from false accusations of linguistic idealism, the essay argues that deconstruction offers a way to think the singularity, absolute otherness and translatability of objects together. Key to this is rethinking God as simultaneously dispersed into otherness and yet guarding an absolute secret which resists assimilation.",2014,
Bayesian Estimation of Sparse Spiked Covariance Matrices in High Dimensions,"We propose a Bayesian methodology for estimating spiked covariance matrices with jointly sparse structure in high dimensions. The spiked covariance matrix is reparametrized in terms of the latent factor model, where the loading matrix is equipped with a novel matrix spike-and-slab LASSO prior, which is a continuous shrinkage prior for modeling jointly sparse matrices. We establish the rate-optimal posterior contraction for the covariance matrix with respect to the operator norm as well as that for the principal subspace with respect to the projection operator norm loss. We also study the posterior contraction rate of the principal subspace with respect to the two-to-infinity norm loss, a novel loss function measuring the distance between subspaces that is able to capture element-wise eigenvector perturbations. We show that the posterior contraction rate with respect to the two-to-infinity norm loss is tighter than that with respect to the routinely used projection operator norm loss under certain low-rank and bounded coherence conditions. % on the corresponding eigenvector matrix. In addition, a point estimator for the principal subspace is proposed with the rate-optimal risk bound with respect to the projection operator norm loss. These results are based on a collection of concentration and large deviation inequalities for the matrix spike-and-slab LASSO prior. The numerical performance of the proposed methodology is assessed through synthetic examples and the analysis of a real-world face data example.",2018,arXiv: Methodology
Whole genome analysis identifies the association of TP53 genomic deletions with lower survival in Stage III colorectal cancer,"DNA copy number aberrations (CNA) were frequently observed in colorectal cancers (CRC). There is an urgent call for CNA-based biomarkers in clinics, in particular for Stage III CRC, if combined with imaging or pathologic evidence, promise more precise care at the timing. We conducted this Stage III specific biomarker discovery with a cohort of 134 CRCs, and with a newly developed high-efficiency CNA profiling protocol. Specifically, we developed the profiling protocol for tumor-normal matched tissue samples based on low-coverage clinical whole-genome sequencing (WGS). We demonstrated the protocolâ€™s accuracy and robustness by a systematic benchmark with microarray, high-coverage whole-exome and -genome approaches, where the low-coverage WGS-derived CNA segments were highly accordant (PCC>0.95) with those derived from microarray, and they were substantially less variable if compared to exome-derived segments. A lasso-based model and multivariate cox regression analysis identified a chromosome 17p loss, containing the TP53 tumor suppressor gene, that was significantly associated with reduced survival (P=0.0139, HR=1.688, 95% CI = [1.112-2.562]), which was validated by an independent cohort of 187 Stage III CRCs. In summary, the new low-coverage WGS protocol has high sensitivity, high resolution and low cost and the identified 17p-loss is an effective poor prognosis marker for Stage III patients.",2019,bioRxiv
The potential role of pain-related SSEPs in the early prognostication of long-term functional outcome in post-anoxic coma.,"BACKGROUND
Cardiac arrest (CA) is a common cause of disability. Multimodal evaluation has improved prognosis but precocious biomarkers are not appropriate in determining long-term functional outcome.


AIM
To identify early prognostication markers of long-term functional outcome in post-anoxic coma.


DESIGN
Retrospective assessment of outcomes.


POPULATION
Individuals older than 18 years with post-anoxic coma hospitalized in intensive care units after cardiac arrest (CA) regardless of cause (cardiac or non-cardiac) and location of event (in or out-of-hospital).


METHODS
Clinical, biological and neurophysiological data were collected within 48 hours from CA. Clinical data included time of no and low flow, CA rhythm, pupillary reflex, Glasgow motor score at admission and hyperthermia. Biological marker was the highest creatinine level. Neurophysiological parameters included EEG pattern and reactivity, Somatosensory Evoked Potential (SSEP), and Middle-Latency (ML) SSEP evoked at low (10 mA) and high (50 mA) intensity stimulation. Level of Cognitive Functioning Scale (LCFS), Disability Rating Scale and recovery from coma (Revised coma Recovery Scale [CRS-R]) were collected at 12 months. A LASSO multiple regression analysis was fitted to data to investigate the best predictors of LCF, DRS and CRS-R. In-sample prediction was obtained to verify the quality of fitting, and accuracy indices (i.e., total error rate) produced.


RESULTS
Presence of short and medium latency SSEPs with low and high stimulation intensity were identified as prognostic predictors of outcome for all the scales. Error rate was 4.5% for CRS and LCF, and 9.1% for DRS.


CONCLUSIONS
Middle latency somatosensory evoked potentials associated with short latency somatosensory evoked potentials during the first 48 hours after a cardiac arrest are strong predictors of functional outcome at 12 months from the event. Replication on larger cohorts is needed to support their routine use as prognostic markers.


CLINICAL REHABILITATION IMPACT
These markers could inform more appropriate allocation of resources, provide a basis for realistic goal-setting, and help the family to adjust its expectations.",2017,European journal of physical and rehabilitation medicine
Iteratively Reweighted â„“1 Approaches to Sparse Composite Regularization,"Motivated by the observation that a given signal $\boldsymbol{x}$ admits sparse representations in multiple dictionaries $\boldsymbol{\Psi}_d$ but with varying levels of sparsity across dictionaries, we propose two new algorithms for the reconstruction of (approximately) sparse signals from noisy linear measurements. Our first algorithm, Co-L1, extends the well-known lasso algorithm from the L1 regularizer $\|\boldsymbol{\Psi x}\|_1$ to composite regularizers of the form $\sum_d \lambda_d \|\boldsymbol{\Psi}_d \boldsymbol{x}\|_1$ while self-adjusting the regularization weights $\lambda_d$. Our second algorithm, Co-IRW-L1, extends the well-known iteratively reweighted L1 algorithm to the same family of composite regularizers. We provide several interpretations of both algorithms: i) majorization-minimization (MM) applied to a non-convex log-sum-type penalty, ii) MM applied to an approximate $\ell_0$-type penalty, iii) MM applied to Bayesian MAP inference under a particular hierarchical prior, and iv) variational expectation-maximization (VEM) under a particular prior with deterministic unknown parameters. A detailed numerical study suggests that our proposed algorithms yield significantly improved recovery SNR when compared to their non-composite L1 and IRW-L1 counterparts.",2015,IEEE Trans. Computational Imaging
Radiomics-Based Machine Learning Technology Enables Better Differentiation Between Glioblastoma and Anaplastic Oligodendroglioma,"Purpose: The aim of this study was to test whether radiomics-based machine learning can enable the better differentiation between glioblastoma (GBM) and anaplastic oligodendroglioma (AO). Methods: This retrospective study involved 126 patients histologically diagnosed as GBM (n = 76) or AO (n = 50) in our institution from January 2015 to December 2018. A total number of 40 three-dimensional texture features were extracted from contrast-enhanced T1-weighted images using LIFEx package. Six diagnostic models were established with selection methods and classifiers. The optimal radiomics features were separately selected into three datasets with three feature selection methods [distance correlation, least absolute shrinkage and selection operator (LASSO), and gradient boosting decision tree (GBDT)]. Then datasets were separately adopted into linear discriminant analysis (LDA) and support vector machine (SVM) classifiers. Specificity, sensitivity, accuracy, and area under curve (AUC) of each model were calculated to evaluate their diagnostic performances. Results: The diagnostic performance of machine learning models was superior to human readers. Both classifiers showed promising ability in discrimination with AUC more than 0.900 when combined with suitable feature selection method. For LDA-based models, the AUC of models were 0.986, 0.994, and 0.970 in the testing group, respectively. For the SVM-based models, the AUC of models were 0.923, 0.817, and 0.500 in the testing group, respectively. The over-fitting model was GBDT + SVM, suggesting that this model was too volatile that unsuitable for classification. Conclusion: This study indicates radiomics-based machine learning has the potential to be utilized in clinically discriminating GBM from AO.",2019,Frontiers in Oncology
Penalized Estimation of Sparse Directed Acyclic Graphs From Categorical Data Under Intervention,"We develop in this article a penalized likelihood method to estimate sparse causal Bayesian networks from categorical data under experimental intervention. The structure of a Bayesian network is represented by a directed acyclic graph (DAG). We model causal interactions in a discrete network by the multi-logit regression and achieve structure estimation of a DAG via maximizing a regularized likelihood. The adaptive group lasso penalty is employed to encourage sparsity by selecting grouped dummy variables encoding the level of a factor together. We develop a blockwise coordinate descent algorithm to solve the penalized likelihood problem subject to the acyclicity constraint of a DAG. We apply our method to three simulated networks and a real biological network, and demonstrate that our method shows very competitive performance compared to existing methods.",2014,
Services objectivization : A ranking approach,"Objectivization is a crucial task arising in a wide variety of industrial fields that aims at optimizing a certain service in terms of ""customer satisfaction"". In this paper focus is on car drivability objectivization and more precisely on the problem of calibrating the acceleration feeling. Our approach is based on statistical ranking of a sample of vehicles characterized by a series of physical parameters, so that cars whose drivability is positively evaluated ideally appear at the top of the list. A novel ranking method is used for this purpose, called TreeRank, that may be viewed as a recursive implementation of a cost-sensitive version of the celebrated classification algorithm Cart. When applied to a data sample made of pairs (X, Y) where Y is a binary label indicating subjective evaluation of a car's drivability and X its characteristics, this specific nonparametric partitioning technique not only outperforms standard methods based on statistical modelling of the posterior distribution but also yields easy-to-interpret models. Additionally, we show how to apply bootstrap aggregating techniques in this context in order to enhance ranking accuracy, the performance of the resulting model comparing favorably to a currently used method based on the Lasso procedure.",2010,The 2nd International Conference on Software Engineering and Data Mining
"Evolution of Brooks Range Thrust Belt and Arctic Slope, Alaska: ABSTRACT","Rotation of a small continental lithospheric plate in Early Cretaceous time formed the southern part of the Canada basin of the Arctic Ocean and an Atlantic-style extensional plate margin underlying the continental shelf north of Alaska. Simultaneously a compressional margin formed to the south, causing over 500 km of crustal shortening and large-scale obduction of ophiolitic rocks over the leading edge of the Arctic alaska plate. An asymmetric foredeep north of the thrust belt is filled with Neocomian to Albian lithic flysch derived from the imbricated sedimentary and mafic-ultramafic igneous terranes. Middle and Late Cretaceous isostatic rebound of the depressed sialic crust resulted in several kilometers of vertical uplift in the southern Brooks End_Page 754------------------------------ Range and extensive refolding and refaulting of the allochthons throughout the range. At the mountain front, autochthonous Triassic and older sedimentary rocks are at depths of over 8 km except in the northeast, where they are exposed by erosion of a regional Late Cretaceous and Tertiary vertical uplift centered in the Romanzof Mountains. North of the range an Albian and Late Cretaceous molassoid wedge derived from the south and west is deformed by decollement that dies out northward; the zone of detachment is incompetent Albian shale. Oil and gas potential is greatest to the north, where Cretaceous sedimentary rocks truncate and prograde over the rifted plate margin. At Prudhoe Bay, northward onlapping Carboniferous to Jurassic platform sedimentary rocks are truncated by organic-rich Cretaceous shale beds, which are the hydrocarbon source and part of the trap. Southward the basin is dominantly a gas-prone stratigraphic trap province; however, potential reservoirs are limited. In the Brooks Range, reservoir potential exists in only a few areas of Carboniferous carbonate rocks that have extreme structural complexity. End_of_Article - Last_Page 755------------",1980,AAPG Bulletin
A multivariable approach for risk markers from pooled molecular data with only partial overlap,"BackgroundIncreasingly, molecular measurements from multiple studies are pooled to identify risk scores, with only partial overlap of measurements available from different studies. Univariate analyses of such markers have routinely been performed in such settings using meta-analysis techniques in genome-wide association studies for identifying genetic risk scores. In contrast, multivariable techniques such as regularized regression, which might potentially be more powerful, are hampered by only partial overlap of available markers even when the pooling of individual level data is feasible for analysis. This cannot easily be addressed at a preprocessing level, as quality criteria in the different studies may result in differential availability of markers â€“ even after imputation.MethodsMotivated by data from the InterLymph Consortium on risk factors for non-Hodgkin lymphoma, which exhibits these challenges, we adapted a regularized regression approach, componentwise boosting, for dealing with partial overlap in SNPs. This synthesis regression approach is combined with resampling to determine stable sets of single nucleotide polymorphisms, which could feed into a genetic risk score. The proposed approach is contrasted with univariate analyses, an application of the lasso, and with an analysis that discards studies causing the partial overlap. The question of statistical significance is faced with an approach called stability selection.ResultsUsing an excerpt of the data from the InterLymph Consortium on two specific subtypes of non-Hodgkin lymphoma, it is shown that componentwise boosting can take into account all applicable information from different SNPs, irrespective of whether they are covered by all investigated studies and for all individuals in the single studies. The results indicate increased power, even when studies that would be discarded in a complete case analysis only comprise a small proportion of individuals.ConclusionsGiven the observed gains in power, the proposed approach can be recommended more generally whenever there is only partial overlap of molecular measurements obtained from pooled studies and/or missing data in single studies. A corresponding software implementation is available upon request.Trial registrationAll involved studies have provided signed GWAS data submission certifications to the U.S. National Institute of Health and have been retrospectively registered.",2019,BMC Medical Genetics
A relative error-based approach for variable selection,"The accelerated failure time model or the multiplicative regression model is well-suited to analyze data with positive responses. For the multiplicative regression model, the authors investigate an adaptive variable selection method via a relative error-based criterion and Lasso-type penalty with desired theoretical properties and computational convenience. With fixed or diverging number of variables in regression model, the resultant estimator achieves the oracle property. An alternating direction method of multipliers algorithm is proposed for computing the regularization paths effectively. A data-driven procedure based on the Bayesian information criterion is used to choose the tuning parameter. The finite-sample performance of the proposed method is examined via simulation studies. An application is illustrated with an analysis of one period of stock returns in Hong Kong Stock Exchange.",2016,Comput. Stat. Data Anal.
Elastic Net Regularization in Diffuse Optical Tomography Applications,"Diffuse optical tomography (DOT) uses near-infrared light to obtain quantitative information about the optical coefficients in biological tissues. Such an information can be clinically exploited for diagnostic purposes. In DOT, the surface of the investigated tissue is illuminated with a light source and the emerging light is measured at various locations on the surface itself. The minimization of the discrepancy between the observed data and the corresponding field generated by a mathematical model of light propagation is then performed, yielding an estimated distribution of the optical parameters in the tissue. This problem is characterized by severe ill-conditioning, so that appropriate regularization techniques must be applied to obtain a meaningful solution. To do this, the use of $\ell_{2}$ (Tikhonov) penalization has been generally advocated in this context; more recently, $\ell_{1}$ (LASSO)-norm penalization has also been proposed to detect the existence of sparsity patterns. Both approaches are classical regularization techniques and are often favored in DOT over other methods, when robustness with respect to geometry and need for almost real-time results are an issue. The goal of the present contribution is to explore the â€œelastic netâ€ regularization technique originally introduced by Zou and Hastie [1], that shares the desirable properties of both the $\ell_{2^{-}}$ and $\ell_{1}$-norm penalization approaches. Whilst this technique has been largely used as a learning theory tool in different applications, at the best of our knowledge, this paper presents its first use in DOT applications. Numerical simulations are performed here on a simple $2D$ geometry, to assess the potentialities of this approach. The results show that this technique may be a good choice for our target application, where DOT is used as a cheap, first-level and almost real-time screening technique for breast cancer detection.",2019,2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)
Robust sparse accelerated failure time model for survival analysis,"To identify the bio-mark genes related to disease with high dimension and low sample size gene expression data, various regression approaches with different regularization methods have been proposed to solve this problem. Nevertheless, high-noises in biological data significantly reduce the performances of methods. The accelerated failure time (AFT) modelwas designed for gene selection and survival time estimation in cancer survival analysis. In this article, we proposed a novel robust sparse accelerated failure time model (RS-AFT) through combining the least absolute deviation (LAD) and Lq regularization. An iterative weighted linear programming algorithm without regularization parameter tuning was proposed to solve this RS-AFT model. The results of the experiments show our method has better performancebothin gene selection and survival time estimationthan some widely used regularization methods such as lasso, elastic net and SCAD. Hence we thought the RS-AFT model may be a competitive regularization method in cancer survival analysis.",2018,Technology and Health Care
Outcomes and Management of Patients With Severe Pulmonary Vein Stenosis From Prior Atrial Fibrillation Ablation,"Background: Pulmonary vein (PV) stenosis remains a feared complication of atrial fibrillation ablation. Little is known about outcomes in patients with severe PV stenosis, especially about repeat ablations. Methods: In 10â€‰368 patients undergoing atrial fibrillation ablation (2000â€“2015), computed tomography scans were obtained 3 to 6 months after ablation. The clinical outcomes in severe PV stenosis were determined. Results: Severe PV stenosis was diagnosed in 52 patients (0.5%). This involved mostly the left superior PV (51% of severely stenosed veins). Percutaneous interventions were performed in 43 patients, and complications occurred in 5: 3 PV ruptures, 1 stroke, and 1 phrenic injury. Over a median follow-up of 25 months, 41 (79%) patients remained arrhythmia free. Repeat ablation was performed in 15 patients (7 from the main series and 8 from prior ablation at other institutions); of whom 10 had PV stents in place. Conduction recovery was noted in all but 2 of the stenosed or stented PVs, and areas with recovery were targeted with antral ablation. Lasso entrapment within stents occurred in 2 patients but eventually freed without complications. After redo ablation, preplanned stenting was performed in 3 patients and computed tomographic scans showed progression of concomitant stenoses in 1 patient (moderate to severe). No procedure-related deaths occurred. Conclusions: The incidence of severe PV stenosis is low but remains associated with significant morbidity. In patients with recurrent arrhythmia, conduction recovery at the stenosed or stented veins is common. Care must be taken to ablate antrally to avoid stenosis progression. In patients with prior PV stents, we suggest to avoid using Lasso.",2018,Circulation: Arrhythmia and Electrophysiology
Crime risk analysis through big data algorithm with urban metrics,"Abstract Crime is pervasive all around the world. Understanding the influence of social features on crime occurrences of a city is a hot topic among researchers. Correlations between crime and other social characteristics have been studied by large amounts of statistical models, including Ordinary Least Square (OLS) linear regression model, Random Forest (RF) regression model, Artificial Neural Network (ANN) model and so on. However, results of these studies, such as the prediction accuracy, are not satisfying and many contradictory conclusions are achieved in previous research works. These controversies are triggered by several factors, including the non-Gaussian distributions and multicollinearity of urban social data, inaccuracy and inadequacy of the processed data, etc. To fill these gaps, we analyzed the influence of 18 urban indicators within 6 categories including geography, economy, education, housing, urbanization and population structure on crime risk in Chinaâ€™s major prefecture-level cities by year. We used the big data algorithm, Least Absolute Shrinkage and Selection Operator (LASSO) and Extremely-randomized Trees (Extra-Trees), to predict the crime risk and quantify the influence of urban parameters on crime. 83% of accuracy on crime risk prediction can be obtained from our fitted model and the importance of urban indicators is ranked. Results show that area of land used for living, number of subscribers of mobile telephone, employed population are the three main factors on the crime occurrences in China. Our research makes contributions to better understanding of the effects of urban indicators on crime in a socialist nation, and providing instructions and strategies for crime prediction and crime rate control with governments, in this big-data era.",2020,Physica A-statistical Mechanics and Its Applications
Measuring productivity and its relationship to community health worker performance in Uganda: a cross-sectional study,"BackgroundTo explore the nature of the relationship between and factors associated with productivity and performance among the community health volunteer (CHV) cadre (Village Health Teams, VHT) in Busia District, Eastern Uganda. The study was carried out to contribute to the global evidence on strategies to improve CHV productivity and performance.MethodsThis cross-sectional study was conducted with 140 VHT members as subjects and respondents. Data were collected between March and May 2013 on the performance and productivity of VHT members related to village visits and activities for saving maternal and child lives, as well as on independent factors that may be associated with these measures. Data were collected through direct observation of VHT activities, structured interviews with VHTs, and review of available records. The correlation between performance and productivity scores was estimated, and LASSO regression analyses were conducted to identify factors associated with these two scores independently.ResultsVHTs demonstrated wide variation in productivity measures, conducting a median of 13.2 service units in a three-month span (range: 2.0-114.9). Performance of the studied VHTs was generally high, with a median performance score (out of 100) of 96.4 (range: 50.9-100.0). We observed a weak correlation coefficient of 0.05 (pâ€‰=â€‰0.57) between productivity and performance scores. Older VHT age (â‰¥50Â years old, reference: <50Â years old) (11.14, 95% CI: 3.26-19.01) and knowledge of danger signs (in units of ten-percentage points, 1.92, 95% CI: 0.01-3.83) were positively associated with productivity scores. Job satisfaction (1.46, 95% CI: 0.13-2.80) and knowledge of danger signs (in units of ten-percentage points, 1.02, 95% CI: 0.05-1.98) were positively associated with performance scores.ConclusionsOlder VHT age and knowledge of danger signs were positively associated with productivity, and job satisfaction and knowledge of danger signs were positively associated with performance. No correlation was observed between productivity and performance scores. This lack of correlation suggests that interventions to improve CHV effectiveness may affect the two dimensions of effectiveness differently. We recommend that productivity and performance both be monitored to evaluate the overall impact of interventions to increase CHV effectiveness.",2018,BMC Health Services Research
Time-varying Limit Order Book Networks,"A network analysis for limit order books (LOB) across stocks yields a better understanding of market behavior. The network is constructed in the presence of microstructure noise and non-synchronous trading. This paper contributes to directed network estimation through penalized vector autoregressive (VAR) approach. The connectedness table can be constructed for both Gaussian and non-Gaussian models, with a connectedness measure directly derived from generalized impulse response function by way of bootstrapping. The directional connectedness ""from"" and ""to"" are associated with the forecast error variation for specific order book across various stocks when the arising shocks transmit from one stock to the others. To balance the sparsity and estimation accuracy, a moderate tuning parameter in penalized VAR is determined by Bayesian information criterion (BIC), followed by a ordinary least squares (OLS) post-Lasso estimator, which can be configured to reduce finite-sample bias and ensure better model performance. Moreover we look for the short-horizon large portfolio allocation decisions, and provide novel empirical evidence using high frequency data trading in NASDAQ market. JEL classification: C02, C13, C22, C45, G12",2018,
Neural decoding of code modulated visual evoked potentials by spatio-temporal inverse filtering for brain computer interfaces,"This study addresses neural decoding of a code modulated visual evoked potentials (c-VEPs). c-VEP was recently developed, and applied to brain computer interfaces (BCIs). c-VEP BCI exhibits faster communication speed than existing VEP-based BCIs. In c-VEP BCI, the canonical correlation analysis (CCA) that maximizes the correlation between an averaged signal and single trial signals is often used for the spatial filter. However, CCA does not utilize information of given PN sequence, and hence, the filtered signal may not have properties of PN sequence. In this paper, we propose a decoding method to restore the given PN sequence from the observed VEP. We compare linear and nonlinear spatio-temporal inverse filtering methods. For the linear method, the least mean square error and lasso are used to obtain the filter coefficients. For the non-linear method, the artificial neural network is used. The proposed methods exhibited better decoding performance, and higher classification accuracies than conventional CCA spatial filtered c-VEP BCI.",2016,2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)
Prediction of Early Breast Cancer Metastasis from DNA Microarray Data Using High-Dimensional Cox Regression Models,"Background DNA microarray studies identified gene expression signatures predictive of metastatic relapse in early breast cancer. Standard feature selection procedures applied to reduce the set of predictive genes did not take into account the correlation between genes. In this paper, we studied the performances of three high-dimensional regression methods â€“ CoxBoost, LASSO (Least Absolute Shrinkage and Selection Operator), and Elastic net â€“ to identify prognostic signatures in patients with early breast cancer. Methods We analyzed three public retrospective datasets, including a total of 384 patients with axillary lymph node-negative breast cancer. The Amsterdam van't Veer's training set of 78 patients was used to determine the optimal gene sets and classifiers using sensitivity thresholds resulting in misclassification of no more than 10% of the poor-prognosis group. To ensure the comparability between different methods, an automatic selection procedure was used to determine the number of genes included in each model. The van de Vijver's and Desmedt's datasets were used as validation sets to evaluate separately the prognostic performances of our classifiers. The results were compared to the original Amsterdam 70-gene classifier. Results The automatic selection procedure reduced the number of predictive genes up to a minimum of six genes. In the two validation sets, the three models (Elastic net, LASSO, and CoxBoost) led to the definition of genomic classifiers predicting the 5-year metastatic status with similar performances, with respective 59, 56, and 54% accuracy, 83, 75, and 83% sensitivity, and 53, 52, and 48% specificity in the Desmedt's dataset. In comparison, the Amsterdam 70-gene signature showed 45% accuracy, 97% sensitivity, and 34% specificity. The gene overlap and the classification concordance between the three classifiers were high. All the classifiers added significant prognostic information to that provided by the traditional prognostic factors and showed a very high overlap with respect to gene ontologies (GOs) associated with genes overexpressed in the predicted poor-prognosis vs. good-prognosis classes and centred on cell proliferation. Interestingly, all classifiers reported high sensitivity to predict the 4-year status of metastatic disease. Conclusions High-dimensional regression methods are attractive in prognostic studies because finding a small subset of genes may facilitate the transfer to the clinic, and also because they strengthen the robustness of the model by limiting the selection of false-positive predictive genes. With only six genes, the CoxBoost classifier predicted the 4-year status of metastatic disease with 93% sensitivity. Selecting a few genes related to ontologies other than cell proliferation might further improve the overall sensitivity performance.",2015,Cancer Informatics
Block sparse linear models for learning structured dynamical systems in aeronautics,"This paper addresses an aircraft dynamical system identification problem, with the goal of using the learned models for trajectory optimization purposes. Our approach is based on multi-task regression. We present in this setting a new class of estimators that we call Block sparse Lasso, which conserves a certain structure between the tasks and some groups of variables, while promoting sparsity within these groups. An implementation leading to consistent feature selection is suggested, allowing to obtain accurate models, which are suitable for trajectory optimization. An additional regularizer is also proposed to help in recovering hidden representations of the initial dynamical system. We illustrate our method with numerical results based on real flight data from 25 medium haul aircraft, totaling 8 million observations.",2018,
Differentially Private Precision Matrix Estimation,"In this paper, we study the problem of precision matrix estimation when the dataset contains sensitive information. In the differential privacy framework, we develop a differentially private ridge estimator by perturbing the sample covariance matrix. Then we develop a differentially private graphical lasso estimator by using the alternating direction method of multipliers (ADMM) algorithm. The theoretical results and empirical results that show the utility of the proposed methods are also provided.",2019,
OP III â€“ 4 Exposure assessment models for no2 and pm2.5 in the elapse study: a comparison of supervised linear regression and machine learning approaches,"Background/aim Recent studies suggested machine learning as an alternative for supervised linear regression (SLR) in developing Land Use Regression models for air pollution exposure assessment. However, few studies have made direct comparisons. This study aimed to develop novel models using machine learning approaches, and compare the model performance to SLR models using an external dataset for validation. Methods A set of novel European-wide models were developed to estimate 2010 annual means for NO2 and PM2.5, based on AIRBASE routine monitoring data. Satellite observations, chemical transport model estimates, land use and traffic data were used as predictor variables. The alternative algorithms we used included shrinkage techniques (lasso, elastic net, ridge), ensemble learning (bagging, boosting, random forest), support vector machine and a super-learner algorithm. Besides 5-fold cross-validation, we also performed external validation using data from the ESCAPE study to evaluate the model performance. The novel models were compared to the previously developed models (SLR for both NO2 and PM2.5, with additional kriging on residuals in PM2.5 models). Results Random forest suggested a moderate improvement in cross-validation with R2 of 0.66 for NO2 models compared to the conventional supervised linear regression model (R2=0.58), while the external validation R2 was lower (0.46 compared to 0.50). The super-learner algorithm had the highest external validation R2 of 0.51, which was less than 0.01 higher than the original supervised linear regression model. For PM2.5, most of the machine learning methods showed similar or worse performance compared to the original supervised linear regression model. The super-learner algorithm had the highest cross-validation R2 of 0.72, which was 0.02 higher than the supervised linear regression model. However, no machine learning algorithm showed better performance in external validation. Conclusion Machine learning algorithms did not perform better than supervised linear regression in our Europe-wide datasets.",2018,Occupational and Environmental Medicine
Bayesian Variable Selection in Semiparametric Proportional Hazards Model for High Dimensional Survival Data,"Variable selection for high dimensional data has recently received a great deal of attention. However, due to the complex structure of the likelihood, only limited developments have been made for time-to-event data where censoring is present. In this paper, we propose a Bayesian variable selection scheme for a Bayesian semiparametric survival model for right censored survival data sets. A special shrinkage prior on the coefficients corresponding to the predictor variables is used to handle cases when the explanatory variables are of very high-dimension. The shrinkage prior is obtained through a scale mixture representation of Normal and Gamma distributions. Our proposed variable selection prior corresponds to the well known lasso penalty. The likelihood function is based on the Cox proportional hazards model framework, where the cumulative baseline hazard function is modeled a priori by a gamma process. We assign a prior on the tuning parameter of the shrinkage prior and adaptively control the sparsity of our model. The primary use of the proposed model is to identify the important covariates relating to the survival curves. To implement our methodology, we have developed a fast Markov chain Monte Carlo algorithm with an adaptive jumping rule. We have successfully applied our method on simulated data sets under two different settings and real microarray data sets which contain right censored survival time. The performance of our Bayesian variable selection model compared with other competing methods is also provided to demonstrate the superiority of our method. A short description of the biological relevance of the selected genes in the real data sets is provided, further strengthening our claims.",2011,The International Journal of Biostatistics
Imaging Diagnosis Prognosis ColoGuidePro : A Prognostic 7-Gene Expression Signature for Stage III Colorectal Cancer Patients,"Purpose: Improved prognostic stratification of patients with stage II and III colorectal cancer is warranted for postoperative clinical decision making. This study was conducted to develop a clinically feasible and robust prognostic classifier for these patients independent of adjuvant treatment. Experimental Design: Global gene expression profiles from altogether 387 stage II and III colorectal cancer tissue samples from three independent patient series were included in the study. ColoGuidePro, a seven-gene prognostic classifier, was developed from a selected Norwegian learning series (n 1â„4 95; no adjuvant treatment) using lasso-penalized multivariate survival modeling with cross-validation. Results: The expression signature significantly stratified patients in a consecutive Norwegian test series, in which patients were treated according to current standards [HR, 2.9 (1.1â€“7.5); P 1â„4 0.03; n1â„4 77] and an external validation series [HR, 3.7 (2.0â€“6.8); P < 0.001; n 1â„4 215] according to survival. ColoGuidePro was also an independent predictor of prognosis inmultivariatemodels including tumor stage in both series (HR, 3.1; P 0.03). In the validation series, which consisted of patients from other populations (United States and Australia), 5-year relapse-free survival was significantly predicted for stage III patients only (P < 0.001; n 1â„4 107). Here, prognostic stratification was independent of adjuvant treatment (P 1â„4 0.001). Conclusions:We present ColoGuidePro, a prognostic classifier developed for patients with stage II and III colorectal cancer. The test is suitable for transfer to clinical use and has best prognostic prediction potential for stage III patients. Clin Cancer Res; 18(21); 1â€“10. 2012 AACR.",2012,
Monte Carlo Simulation for Lasso-Type Problems by Estimator Augmentation,"Regularized linear regression under the l1 penalty, such as the Lasso, has been shown to be effective in variable selection and sparse modeling. The sampling distribution of an l1-penalized estimator is hard to determine as the estimator is defined by an optimization problem that in general can only be solved numerically and many of its components may be exactly zero. Let S be the subgradient of the l1 norm of the coefficient vector Î² evaluated at . We find that the joint sampling distribution of and S, together called an augmented estimator, is much more tractable and has a closed-form density under a normal error distribution in both low-dimensional (p â©½ n) and high-dimensional (p > n) settings. Given Î² and the error variance Ïƒ2, one may employ standard Monte Carlo methods, such as Markov chain Monte Carlo (MCMC) and importance sampling (IS), to draw samples from the distribution of the augmented estimator and calculate expectations with respect to the sampling distribution of . We develop a few concret...",2014,Journal of the American Statistical Association
"Three essays on time series : spatio-temporal modelling, dimension reduction and change-point detection","Modelling high dimensional time series and non-stationary time series are two import aspects in time series analysis nowadays. The main objective of this thesis is to deal with these two problems. The first two parts deal with high dimensionality and the third part considers a change point detection problem. In the first part, we consider a class of spatio-temporal models which extend popular econometric spatial autoregressive panel data models by allowing the scalar coefficients for each location (or panel) different from each other. The model is of the following form: yt = D(Î»0)Wyt + D(Î»1)ytâˆ’1 + D(Î»2)Wytâˆ’1 + et, (1) where yt = (y1,t, . . . , yp,t) T represents the observations from p locations at time t, D(Î»k) = diag(Î»k1, . . . , Î»kp) and Î»kj is the unknown coefficient parameter for the j-th location, and W is the pÃ—p spatial weight matrix which measures the dependence among different locations. All the elements on the main diagonal of W are zero. It is a common practice in spatial econometrics to assume W known. For example, we may let wij = 1/(1 + dij ), for i = j, where dij â‰¥ 0 is an appropriate distance between the i-th and the j-th location. It can simply be the geographical distance between the two locations or the distance reflecting the correlation or association between the variables at the two locations. In the above model, D(Î»0) captures the pure spatial effect, D(Î»1) captures the pure dynamic effect, and D(Î»2) captures the time-lagged spatial effect. We also assume that the error term et = (e1,t, e2,t, . . . , ep,t) T in (1) satisfies the condition Cov (ytâˆ’1, et) = 0. When Î»k1 = Â· Â· Â· = Î»kp for all k = 1, 2, 3, (1) reduces to the model of Yu et al. (2008), in which there are only 3 unknown regressive coefficient parameters. In general the regression function in (1) contains 3p unknown parameters. To overcome the innate endogeneity, we propose a generalized Yule-Walker estimation method which applies the least squares estimation to a Yule-Walker equation. The asymptotic theory is developed under the setting that both the sample size and the number of locations (or panels) tend to infinity under a general setting for stationary and Î±-mixing processes, which includes spatial autoregressive panel data models driven by i.i.d. innovations as special cases. The proposed methods are illustrated using both simulated and real data. 
In part 2, we consider a multivariate time series model which decomposes a vector process into a latent factor process and a white noise process. Let yt = (y1,t, Â· Â· Â· , yp,t) T be an observable p Ã— 1 vector time series process. The factor model decomposes yt in the following form: yt = Axt + et , (2) where xt = (x1,t, Â· Â· Â· , xr,t) T is a r Ã— 1 latent factor time series with unknown r â‰¤ p and A = (a1, a2, Â· Â· Â· , ar) is a p Ã— r unknown constant matrix. et is a white noise process with mean 0 and covariance matrix Î£e. The first part of (2) is a dynamic part and the serial dependence of yt is driven by xt. We will achieve dimension reduction once r â‰ª p in the sense that the dynamics of yt is driven by a much lower dimensional process xt. Motivated by practical needs and the characteristic of high dimensional data, the sparsity assumption on factor loading matrix is imposed. Different from Lam, Yao and Bathia (2011)â€™s method, which is equivalent to an eigenanalysis of a non negative definite matrix, we add a constraint to control the number of nonzero elements in each column of the factor loading matrix. Our proposed sparse estimator is then the solution of a constrained optimization problem. The asymptotic theory is developed under the setting that both the sample size and the dimensionality tend to infinity. When the common factor is weak in the sense that Î´ > 1/2 in Lam, Yao and Bathia (2011)â€™s paper, the new sparse estimator may have a faster convergence rate. Numerically, we employ the generalized deflation method (Mackey (2009)) and the GSLDA method (Moghaddam et al. (2006)) to approximate the estimator. The tuning parameter is chosen by cross validation. The proposed method is illustrated with both simulated and real data examples. The third part is a change point detection problem. we consider the following covariance structural break detection problem: Cov(yt)I(tjâˆ’1 â‰¤ t < tj ) = Î£tjâˆ’1, j = 1, Â· Â· Â· , m + 1, where yt is a p Ã— 1 vector time series, Î£tjâˆ’1 = Î£tj and {t1, . . ., tm} are change points, 1 = t0 < t1 < Â· Â· Â· < tm+1 = n. In the literature, the number of change points m is usually assumed to be known and small, because a large m would involve a huge amount of computational burden for parameters estimation. By reformulating the problem in a variable selection context, the group least absolute shrinkage and selection operator (LASSO) is proposed to estimate m and the locations of the change points {t1, . . ., tm}. Our method is model free, it can be extensively applied to multivariate time series, such as GARCH and stochastic volatility models. It is shown that both m and the locations of the change points {t1, . . . , tm} can be consistently estimated from the data, and the computation can be efficiently performed. An improved practical version that incorporates group LASSO and the stepwise regression variable selection technique are discussed. Simulation studies are conducted to assess the finite sample performance.",2015,
Determination of sex differences of human cadaveric mandibular condyles using statistical shape and trait modeling.,"The objective of this study was to elucidate sex differences in the anatomy of human temporomandibular joint mandibular condyles using a statistical shape and trait model (SSTM). Mandibles were obtained from 16 human cadavers (79Â±13years). The condyles were scanned using micro-computed tomography with 27Î¼m resolution. An image processing algorithm was used to segment the bone, determine the border of the entire mandibular condyle and trabecular bone compartments, and create triangulated meshes of the compartments. One subject was chosen as the template and was registered to the other individuals using a coherence point drift algorithm. This process positioned all vertices at corresponding anatomic locations. For the trabecular bone region, around each vertex position, the average bone image intensity, which is proportional to bone density, and microstructural traits, including trabecular bone volume fraction, thickness, separation, connectivity, and connectivity density were calculated. For the entire mandibular condyle mesh, the surface vertices were extracted to represent the overall anatomy of the condyle. Using a SSTM, the shape and trait information was reduced to a small set of independent and uncorrelated variables for each individual. Wilcoxon rank sum tests were used to test for differences in the variables between sexes. A lasso approach was used to determine a set of variables that differentiate between sexes. Male condyles were on average larger than female condyles, with complex differences in the microstructural traits. Two out of 15 principal components were statistically different between males and females (p<0.1). The lasso approach determined a set of 7 principal components that fully described the complex shape and trait differences between males and females. A SSTM was able to determine sex-dependent differences in the shape of the mandibular condyle. These differences may alter the biomechanics of the joint and contribute to the development of temporomandibular joint disease.",2018,Bone
A first-order optimization algorithm for statistical learning with hierarchical sparsity structure,"In many statistical learning problems, it is desired that the optimal solution conforms to an a priori known sparsity structure e.g. for better interpretability. Inducing such structures by means of convex regularizers requires nonsmooth penalty functions that exploit group overlapping. Our study focuses on evaluating the proximal operator of the Latent Overlapping Group lasso developed by Jacob et al. (2009). We develop an Alternating Direction Method of Multiplier with a sharing scheme to solve large-scale instance of the underlying optimization problem efficiently. In the absence of strong convexity, linear convergence of the algorithm is established using the error bound theory. More specifically, the paper contributes to establishing primal and dual error bounds over an unbounded feasible set and when the nonsmooth component in the objective function does not have a polyhedral epigraph. Numerical simulation studies supporting the proposed algorithm and two learning applications are discussed.",2020,arXiv: Optimization and Control
Insights into the local pathogenesis induced by fish toxins: role of natterins and nattectin in the disruption of cell-cell and cell-extracellular matrix interactions and modulation of cell migration.,"Combined proteomic and transcriptomic approaches to study the composition of the venom of Thalassophryne nattereri venomous fish revealed the primary structures of the major toxins as a family of proteases natterins, never described on venoms and a C-type lectin nattectin. To gain new insights into the mechanisms of venom pathogenesis and to further elucidate the role of its major toxins, the natterins and nattectin, we undertook in vitro investigations using these isolated toxins. Here we demonstrated the specific ability of the nattectin to bind types I and V collagen and natterins to bind and cleave type I collagen as well as type IV collagen, disrupting cell attachment and HeLa cells survival. Natterins have cytotoxic effect on both adherent cells or at in suspension, showing direct induction of necrosis that is followed by cell detachment. Nattectin improves integrin-mediated HeLa cell adhesion and resistance to apoptosis by its binding to RGD-dependent integrins, especially the Î²1 subunit. Based on our studies we now report that extracellular matrix (ECM) components as well as the integrin Î²1 subunit are targets for the natterins and nattectin. The ECM degradation or remodeling activities exerted by these toxins affect cell-cell and cell-ECM adhesion and survival and impair inflammatory cell migration into inflamed tissues.",2011,Toxicon : official journal of the International Society on Toxinology
Data Sharing and Resampled LASSO: A word based sentiment Analysis for IMDb data,"In this article we study variable selection problem using LASSO with new improvisations. LASSO uses $\ell_{1}$ penalty, it shrinks most of the coefficients to zero when number of explanatory variables $(p)$ are much larger the number of observations $(N)$. Novelty of the approach developed in this article blends basic ideas behind resampling and LASSO together which provides a significant variable reduction and improved prediction accuracy in terms of mean squared error in the test sample. Different weighting schemes have been explored using Bootstrapped LASSO, the basic methodology developed in here. Weighting schemes determine to what extent of data blending in case of grouped data. Data sharing (DSL) technique developed by [11] lies at the root of the present methodology. We apply the technique to analyze the IMDb dataset as discussed in [11] and compare our result with [11].",2017,arXiv: Applications
Interspecific interactions of heterotrophic bacteria during chitin degradation,"In this study, interactions between bacteria possessing either released or cellassociated enzymes for polymer degradation were investigated. For this, a co-culture of Aeromonas hydrophila strain AH-1N as an enzyme-releasing bacterium and of Flavobacterium sp. strain 4D9 as a bacterium with cell-associated enzymes was set up with chitin embedded into agarose beads to account for natural conditions, under which polymers are usually embedded in organic aggregates. In single cultures strain AH-1N grew with embedded chitin, while strain 4D9 did not. In co-cultures, strain 4D9 grew and outcompeted strain AH-1N in the biofilm fraction. Experiments with cell-free culture supernatants containing the chitinolytic enzymes of strain AH-1N revealed that growth of strain 4D9 in the co-culture was based on intercepting Nacetylglucosamine from chitin degradation. For this, strain 4D9 had to actively integrate into the biofilm of strain AH-1N. This study shows that bacteria using different chitin degradation mechanisms can co-exist by formation of a mixed-species biofilm.",2012,
Modelling the escape fraction of ionizing photons from galaxies in the reionization epoch : A machine learning approach,"The reionization of the hydrogen in the universe represents an important but poorly understood epoch in the evolution of our universe. The most promising explanation is that radiation emitted from young hot stars in the first generation of galaxies drove the reionization. However, this theory relies on the assumption that the fraction of escaping ionizing radiation from these galaxies was high enough to sustain reionization. The upcoming James Webb Space Telescope (JWST) will enable observations of large samples of spectra from reionization-epoch galaxies. The escape fraction of ionizing photons can not be directly measured from these observations, but is predicted to have an indirect effect on the spectra of these galaxies at observable wavelengths.In this thesis we train a machine learning algorithm known as the LASSO on simulated JWST observations, in order to obtain models which can predict escape fractions. The method studied in this thesis predicts the escape fraction with an absolute mean prediction error of 0.11 when applied to low resolution spectra with signal-to-noise ratio = 5. This prediction accuracy represents a significant improvement over previous similar methods. Our results indicate that a few spectral features exhibit the strongest effect on the escape fraction. The method shows a high level of robustness to the effects of varying levels of interstellar dust and spectral noise. A discussion which highlights some of the more problematic areas with the method is also included in this report, as well as proposed directions for future work.",2016,
Backward Elimination Algorithm for High Dimensional Variable Screening,"In recent times, variable selection in high-dimensional data has become a challenging problem. We investigate here a popular but classical variable screening method, the Backward Elimination (BE) in a high dimensional setup (small-n-large P). The BE method as a variable screening method reduces the dimension of small-n-large P data into a lower dimensional data and then established shrinkage methods such as: LASSO, SCAD and MCP can be applied directly. To overcome the problems in high dimensional data, Chen and Chen (2008) recently developed a family of Extended Bayesian Information Criterion (EBIC) which is consistent with finite sample properties (Chen and Chen, 2008) which we used in this study to select the best candidate model from the models generated by the proposed BE method. We compare the BE with other screening methods such as: Sure Independence Screening(SIS), Iterative Sure Independence Screening and Forward Regression (FR) in simulation studies and real-data analysis to illustrate the selection consistency of our proposed BE method. Our numerical analysis reveals that the BE with EBIC can identify all important variables with high coverage probability, low false discovery rate and a very good model size with high signal-to-noise.",2018,
Learning Granger Causality for Hawkes Processes,"Learning Granger causality for general point processes is a very challenging task. In this paper, we propose an effective method, learning Granger causality, for a special but significant type of point processes --- Hawkes process. We reveal the relationship between Hawkes process's impact function and its Granger causality graph. Specifically, our model represents impact functions using a series of basis functions and recovers the Granger causality graph via group sparsity of the impact functions' coefficients. We propose an effective learning algorithm combining a maximum likelihood estimator (MLE) with a sparse-group-lasso (SGL) regularizer. Additionally, the flexibility of our model allows to incorporate the clustering structure event types into learning framework. We analyze our learning algorithm and propose an adaptive procedure to select basis functions. Experiments on both synthetic and real-world data show that our method can learn the Granger causality graph and the triggering patterns of the Hawkes processes simultaneously.",2016,
"Characterization of microsatellite loci in a pelagic spawner: the bluehead wrasse, Thalassoma bifasciatum.","The predominant mode of reproduction for most marine fishes is pelagic spawning; gametes are released into the water where sperm, often contributed by more than one male, fertilize eggs of a female. As a consequence of external fertilization males are frequently in sperm competition with each other. However, little is known about the actual effects of sperm competition on the fitness of a pelagic spawning male. We have isolated and characterized microsatellite loci from the bluehead wrasse, Thalassoma bifasciatum. This coralreef fish has been extensively used in studies of sexual selection, life-history traits (Warner & Schultz 1992) and recruitment ecology (Caselle & Warner 1996). For our purposes microsatellite markers were developed to determine paternity of larvae from spawns involving multiple males. We developed microsatellite primers for T. bifasciatum not only for their suitability in paternity studies because of potential high variability (Tautz 1989), but also for their codominant allelic patterns, critical for powerful paternityexclusion analysis. Moreover, microsatellites require small tissue amounts and are specific to target DNA. These are important attributes for our study, because minute larvae and sperm are collected from sea water contaminated with various DNA sources. Microsatellite loci were isolated and characterized using the construction of a partial genomic DNA library of short fragments of T. bifasciatum as per Strassmann et al. (1996). Genomic DNA was isolated in large quantities from gill filaments and digested to completion by the restriction enzyme Sau3A1. Restriction fragments were separated by agarose gel electrophoresis and the 200Ã600 bp fragments were isolated and ligated into the pUC-18 vector pBluescript (Stratagene). Following transformation of competent DH5Î± bacterial cells, plating onto selective agar media, and replica plating onto nylon filters, the library was screened using [Î±P]-dCTP end-labelled oligonucleotides corresponding to common microsatellite motifs: (AAT)10, (CAT)10, (TAG)10, (AAG)10 and (AAC)10. A total of 24 positive clones was sequenced on an automated sequencer (ABI/Perkin Elmer) of which 12 contained dinucleotide or trinucleotide repeats. Two of these microsatellite loci did not contain adequate flanking region for primer set design. Thus 10 primer sets have been designed of which six are variable (Table 1). Population screens were conducted to determine allelic variability at the six loci by using genomic DNA from seven to 43 presumably unrelated individuals collected in 1993 from different coral reefs of St Croix, US Virgin Islands. The final concentrations of the PCR reagents in a volume of 15 Î¼L were as follows: â‰ˆ10 ng of genomic DNA, 1Ã— PCR buffer Molecular Ecology (1998) 7, 1613Ã1621",1998,Molecular ecology
"[Reinventing Africa: Matriarchy, Religion & Culture]","If one takes seriously the central message about identity politics and Africa in this latest book by the author of Male Daughters, Female Husbands, it presents difficulties for people like myself to review this collection of essays by Ifi Amadiume. Professor Amadiume, who herself received a doctorate in anthropology from the University of London, argues throughout Reinventing Africa that it is necessary to trenchantly critique the eurocentric, middle class and patriarchal biases inherent in anthropology as a discipline in order to clear the way for carrying out what she calls a social history of Africa that is more faithful to the historical realities of the continent. Although I am partial to criticisms of patronizing and hegemonic tendencies in both anthropology and African studies more broadly that are informed by ""anti- essentialist"" theoretical imaginaries and political goals that typically fall under the ""invention of"" literature, my non- African origins, gender and politics that fall outside pan-Africanist concerns make my qualifications to review this book, let alone carry out research in Africa, suspect from Amadiume's perspective. Instead of bowing to this prohibition, I will indicate some of the locations of Amadiume's interesting arguments, suggesting that ultimately she is more of an anthropologist than she wishes to be.Of the 10 essays in this book, two are original and eight come from earlier publications of, or more commonly, public lectures given in, the early 1990s. The essays deal with common themes such as racism, gender, feminism, matriarchy, classism, religion and how these are interwoven in both dominant academic studies of Africa that, for her, misrepresent the African identity and those works that ""answer back"" to such literature, like her own and, especially, that of the Senegalese historian and pan-Africanist, Cheikh Anta Diop, whose ""African historical sociology"" acts as a jumping off point for her ""social history."" Drawing on her own research in the 1980s amongst the Nnobi, an Igbo group in Nigeria, Diop's arguments, and her critiques of a rather limited, if not dated, number of anthropological works on Africa (mainly by Fortes, Meillassoux, Terray, Riesman, and Bloch), she expands her argument from her earlier book by not only providing a materialist theory of the dialectical tension between matriarchy and patriarchy in African societies but also by explaining the patriarchal biases of European anthropologists and feminists through the history of their sociocultural formation.Following Diop, Amadiume explains the violence and patriarchal moral philosophy of Europeans as arising from their Indo-European origins over five thousand years ago. This, she argues, not only explains the Atlantic slave trade, the violence of European colonialism in Africa and its continuation by postcolonial elites but also why Western feminists focus their struggles on the work-place and universally view the family as inherently patriarchal. In contrast, Africa social relations have contained a contradiction between the autonomous matricentric unit, which has led to the ideology of ""the motherhood paradigm,"" and broader, patriarchal polities. In her view, the African family has served as the basis of matriarchy in terms of goddess-based religions, strong ideology of motherhood, and a general moral principal rooted in love, which has led to alternative forms of power for women and for decentralized polities in tension with patriarchal centralization. In her model, conquests by patriarchal ""outsiders"" like Islamic Arabs and Christian Europeans have strengthened the patriarchal side of African social relations. â€¦",2000,Anthropologica
Speeding-Up Model-Selection in Graphnet via Early-Stopping and Univariate Feature-Screening,"The Graph Net (aka S-Lasso), as well as other ""spar-sity + structure"" priors like TV-L1, are not easily applicable to brain data because of technical problems concerning the selection of the regularization parameters. Also, in their own right, such models lead to challenging high-dimensional optimization problems. In this manuscript, we present some heuristics for speeding up the overall optimization process: (a) Early-stopping, whereby one halts the optimization process when the test score(performance on left out data) for the internal cross validation for model-selection stops improving, and (b) univariate feature-screening, whereby irrelevant (non-predictive) voxels are detected and eliminated before the optimization problem is entered, thus reducing the size of the problem. Empirical results with Graph Net on real MRI (Magnetic Resonance Imaging) datasets indicate that these heuristics are a win-win strategy, as they add speed without sacrificing the quality of the predictions. We expect the proposed heuristics to work on other models like TV-L1, etc.",2015,2015 International Workshop on Pattern Recognition in NeuroImaging
Macroeconomic Forecasting Using Penalized Regression Methods,"We study the suitability of lasso-type penalized regression techniques when applied to macroeconomic forecasting with high-dimensional datasets. We consider performance of the lasso-type methods when the true DGP is a factor model, contradicting the sparsity assumption underlying penalized regression methods. We also investigate how the methods handle unit roots and cointegration in the data. In an extensive simulation study we find that penalized regression methods are morerobust to mis-specification than factor models estimated by principal components, even if the underlying DGP is a factor model. Furthermore, the penalized regression methods are demonstrated to deliver forecast improvements over traditional approaches when applied to non-stationary data containing cointegrated variables, despite a deterioration of the selective capabilities. Finally, we also consider an empirical application to a large macroeconomic U.S. dataset and demonstrate that, in line with our simulations, penalized regression methods attain the best forecast accuracy most frequently.",2016,research memorandum
On the Possibility of Speculative Ethical Absolutes after Kant,"Abstract According to Quentin Meillassoux, one of the principal aims of speculative philosophy â€œmust be the immanent inscription of values in being.â€ In this regard, the return to speculation in contemporary philosophy is in many ways a deeply ethical project. This â€œinscription of valuesâ€ can only be successful, however, if it can somehow assert an absolute ethical value without, on the one hand, resorting to the kind of dogmatism laid to rest by the Kantian critique; or, on the other, by falling into some form of ethical relativism incapable of grounding universal ethical judgments. Unfortunately, too many of these attempts have failed. The aim of this paper is twofold: firstly, to explore the structure and failures of two such attempts through an analysis of the ethical projects of Alain Badiou and Quentin Meillassoux, respectively; and then, secondly, to show how both of these thinkers, and the project of speculative ethics in general, could benefit by turning to the work of F.W.J. Schelling on the concept of good and evil as absolute ethical values.",2016,Angelaki
Pulmonary Vein Stenosis after Catheter Ablation of Atrial Fibrillation: Emergence of a New Clinical Syndrome,"Context Because electrical signals initiating atrial fibrillation originate in the pulmonary veins, radiofrequency catheter ablation has been highly successful in curing the arrhythmia. Pulmonary vein stenosis is a recognized complication of this procedure, but past research has not established its frequency or clinical characteristics. Contribution Of 335 patients who received catheter ablation, 18 developed severe pulmonary vein stenosis. Only 44% were symptomatic. Failure to recognize the problem often led to inappropriate work-up and treatment. After pulmonary vein dilatation and stenting, 57% of patients improved. Implications Pulmonary vein stenosis following catheter ablation of atrial fibrillation is relatively common and clinically recognizable. Mechanical relief of venous obstruction can alleviate symptoms. The Editors Atrial fibrillation is one of the most common cardiac rhythm disorders and is associated with significant morbidity and mortality. Recent advances in the pathophysiologic understanding of this disorder have pointed to a focal origin that is mainly localized in the pulmonary veins and is thus amenable to ablative catheter procedures (1-6). Pulmonary vein stenosis is a recognized potential complication of radiofrequency ablation. Its incidence has been reported to range from 3% to 42%, depending on the ablative technique used and the method of assessment (6-11). Recognition of pulmonary vein stenosis is important to avoid unnecessary work-up and to allow initiation of appropriate treatment. However, reports on the constellation of signs and symptoms characterizing pulmonary vein stenosis are lacking. In this study, we describe our experience with patients who developed pulmonary vein stenosis as a complication of radiofrequency ablation of atrial fibrillation. Methods Study Sample Three hundred thirty-five patients (272 men; mean age, 54.0 years [range, 18 to 79 years]) with symptomatic, drug-refractory atrial fibrillation (mean duration [SD], 5.4 3.6 years) were referred to our laboratory for electrophysiologic study and catheter ablation. Therapy with antiarrhythmic drugs and use of oral anticoagulants were discontinued 5 half-lives and 5 days, respectively, before ablation. In all but three patients, amiodarone was withdrawn 1 month before the procedure. Informed consent was obtained from all patients before the procedure, and the institutional review board approved the collection and analysis of the data. In 71 patients, we used a three-dimensional nonfluoroscopic electroanatomic system (CARTO, Biosense Webster, Diamond Bar, California) to map and ablate arrhythmogenic pulmonary veins, as described elsewhere (3). Briefly, this system uses a low-level magnetic field to continuously record the mapping catheter location and create a catalog of electrical activity. The acquired information is then color-coded and displayed on a three-dimensional chamber geometry model of the heart chamber of interest. In 264 additional patients, we instead performed circumferential mapping and electrical isolation of all pulmonary veins, regardless of demonstration of ectopic activity. Procedure Description Patients came to the electrophysiology laboratory while fasting. Immediately before the procedure, transesophageal echocardiography was performed in all patients to exclude left atrial thrombus. A custom-made catheter (Cardiac Assist Device, Inc., Cleveland, Ohio) was placed in the coronary sinus. The proximal eight electrodes were positioned between the superior vena cava and the high crista terminalis, whereas the distal eight electrodes were placed in the coronary sinus. A transesophageal recording lead was used to record activation of the left atrial posterior wall. Mapping of left atrium and pulmonary veins was completed after the left atrium was accessed through the transseptal approach. A circular catheter (LASSO, Biosense Webster) and a steerable quadripolar catheter were placed in the pulmonary veins for mapping and ablation, respectively, through separate transseptal access points. Quadripolar 4-mmtip, 8-mmtip (Biosense Webster), and cooled-tip (Chilli, EPT, Sunnyvale, California) catheters were used for ablation. The procedure end point was the demonstration of electrical isolation of all pulmonary veins from the left atrium by evidence of entrance block. Initially, radiofrequency lesions were delivered inside the veins. For most patients, however, proximal isolation was obtained by energy delivery at the pulmonary veinleft atrium junction, which was defined by a phase-array intracardiac echocardiographic probe or by pulmonary vein angiography. The latter was performed during adenosine-induced asystole for better resolution. In patients in whom the electroanatomic system was used, only the superior pulmonary veins were targeted, unless firing from other veins was noted. The pulmonary vein profiles were reconstructed by using the electroanatomic system and by angiography. The procedure end point was pulmonary vein isolation, elimination of ectopic activity capable of initiating atrial fibrillation, or both. Follow-up Patients were given aspirin immediately after the procedure, and warfarin was restarted on the same evening. Antiarrhythmic medications were used for 6 weeks in patients who had permanent atrial fibrillation before the procedure. An arrhythmia transmitter was given to all patients before hospital discharge for detection of recurrent atrial fibrillation. Routine follow-up visits took place 3, 6, and 12 months after the procedure. Spiral computed tomography (CT) of the pulmonary veins, with three-dimensional reconstruction, was performed 3 months after ablation in all patients, regardless of the development of symptoms, to screen for pulmonary vein stenosis. Computed tomography was considered earlier if symptoms suggestive of stenosis developed; it was repeated at 6 and 12 months if any degree of pulmonary vein narrowing was observed. Pulmonary vein stenosis was judged by digital measurements of luminal diameters on adjacent segments as well as by comparison with previous films, when available. Stenosis was considered mild if luminal narrowing was less than 50%, moderate if luminal narrowing was 50% to 70%, or severe if luminal narrowing was more than 70%. Statistical Analysis We used the paired t-test to compare perfusion scan data and the Fisher exact test to evaluate the relation between the number of stenosed pulmonary veins and symptoms. StatXact software, version 3.0 (Cytel Corp., Cambridge, Massachusetts), was used for these analyses. Results Demographic characteristics of the study sample are presented in Table 1. At the 6-month follow-up visit, pulmonary vein isolation guided by the circular mapping technique had cured atrial fibrillation without use of medications in 80% of patients (212 of 264). Thirty-five patients underwent a second procedure, which resulted in an overall success rate of 92% (243 of 264 patients). This represented a significant improvement when compared with the electroanatomically guided technique, in which only 30% patients (21 of 71) were free of arrhythmia while not taking medications. Table 1. Demographic Characteristics of the Study Sample at Baseline Eighteen of 335 patients (5% [95% CI, 3% to 8%]) developed severe pulmonary vein stenosis, detected by spiral CT, a mean (SD) of 5.2 2.6 months after ablation. The mean age of these patients was 50.6 years (range, 26 to 71 years), and 78% were men. Five of these 18 patients (28%) had structural heart disease. The mean number of pulmonary veins ablated was three per patient (range, two to four per patient). Twelve patients had ablation guided by the circular mapping technique, and 6 patients had ablation guided by the CARTO system. Shortness of breath, the only respiratory symptom detected before the ablation procedure, was present in 5 patients and was attributed to atrial fibrillation. One patient had underlying pulmonary disease (asthma). Eight patients with severe pulmonary vein stenosis (44%) were asymptomatic. Among patients who had symptoms, shortness of breath was the most prevalent (8 patients [44%]), followed by cough (7 patients [39%]) and hemoptysis (5 patients [28%]). Pleuritic pain was observed in 4 patients (22%) and was usually associated with hemoptysis and cough. The presence of severe stenosis in more than one pulmonary vein was associated with a higher risk for symptoms (relative risk, 12.5 [CI, 1.2 to 391]; P = 0.04). Radiographic findings were abnormal in 9 of the 18 patients with severe stenosis (50%). The most common abnormal finding was lung consolidation (observed in 78% of patients), followed by left pleural effusions (observed in 56% of patients). Of note, in 7 of the 9 patients with radiologic abnormalities of the lungs (78%), symptoms were initially attributed to other diseases: pneumonia (4 patients), lung cancer (1 patient), and pulmonary embolism (2 patients). It is important to note that pulmonary vein stenosis was not initially considered in any of the patients who had the disorder. Misdiagnoses led to improper diagnostic and therapeutic procedures, such as prolonged antibiotic treatment (5 patients), treatment for possible asthmatic syndrome and bronchitis (3 patients), placement of a vena cava filter (1 patient), and lung resection surgery (1 patient). Table 2 summarizes the clinical and radiologic findings and pulmonary vein interventions performed. Of interest, in 5 patients who initially presented with symptomatic pulmonary vein stenosis (50%), symptoms spontaneously resolved before interventional procedures were undertaken. Table 2. Summary of Clinical and Radiologic Findings and Pulmonary Vein Interventions in 18 Patients Lung perfusion scans were obtained before and after pulmonary vein dilatation and showed a significant improvement in perfusion after the intervention. Average pulmonary flow to the affected lung increased from 15% (CI, 2% to 33%) to 23% (",2003,Annals of Internal Medicine
ToolSEG: A Tool for DNA Copy Number Segmentation,"To perform segmentation to identify regions of constant copy number is an important key for discovering structural variation in the human genome. It calls for a uniform pipeline to integrate various segmentation methods in a flexible software toolbox for conveniently evaluating outcome. We propose such toolbox and implement an open source Java package called ToolSEG to generate realistic DNA copy number profiles with known truth. Five typical methods have been assessed on synthetic data and real copy number profiles: HMM, CBS, PCF, Lasso, CLT.",2016,2016 3rd International Conference on Soft Computing & Machine Intelligence (ISCMI)
"Plasmodium falciparum msp1 and msp2 genetic diversity and allele frequencies in parasites isolated from symptomatic malaria patients in Bobo-Dioulasso, Burkina Faso","BackgroundIn Burkina Faso, malaria remains the overall leading cause of morbidity and mortality accounting for 35.12% of consultations, 40.83% of hospitalizations and 37.5% of deaths. Genotyping of malaria parasite populations remains an important tool to determine the types and number of parasite clones in an infection. The present study aimed to evaluate the merozoite surface protein 1 (msp1) and merozoite surface protein 2 (msp2) genetic diversity and allele frequencies in Bobo-Dioulasso, Burkina Faso.MethodDried blood spots (DBS) were collected at baseline from patients with uncomplicated malaria in urban health centers in Bobo-Dioulasso. Parasite DNA was extracted using chelex-100 and species were identified using nested PCR. Plamodium falciparum msp1 and msp2 genes were amplified by nested polymerase chain reaction (PCR) and PCR products were analyzed by electrophoresis on a 2.5% agarose gel. Alleles were categorized according to their molecular weight.ResultsA total of 228 blood samples were analyzed out of which 227 (99.9%) were confirmed as P. falciparum-positive and one sample classified as mixed infection for P. malaria and P. falciparum. In msp1, the K1 allelic family was predominant with 77.4% (162/209) followed respectively by the MAD20 allelic family with 41.3% and R033 allelic family with 36%. In msp2, the 3D7 allelic family was the most frequently detected with 93.1 % compared to FC27 with 41.3%. Twenty-one different alleles were observed in msp1 with 9 alleles for K1, 8 alleles for MAD20 and 4 alleles for R033. In msp2, 25 individual alleles were detected with 10 alleles for FC27 and 15 alleles for 3D7. The mean multiplicity of falciparum infection was 1.95 with respectively 1.8 (1.76â€“1.83) and 2.1 (2.03â€“2.16) for msp1 and msp2 (P = 0.01).ConclusionsOur study showed high genetic diversity and allelic frequencies of msp1 and msp2 in Plasmodium falciparum isolates from symptomatic malaria patients in Bobo-Dioulasso.",2018,Parasites & Vectors
Besondere Kreislaufreaktionen im akuten Stadium der SchÃ¤del-HirnschÃ¤digungen,"ZusammenfassungDie Kreislaufanalyse bei 1639 SchÃ¤del-Hirnverletzten im akuten Stadium hat ergeben, daÃŸ echte Schocksyndrome mit schwerem Kreislaufkollaps auffallend selten zur Beobachtung gelangen und vorwiegend nur dann, wenn erheblichere Nebenverletzungen (abdominal, thoracal, ExtremitÃ¤ten) bestehen. Sehr viel hÃ¤ufiger ist dagegen eine sogenannte hypertonische Kreislaufreaktion im akuten Stadium zu sehen, insbesondere in FÃ¤llen mit einer alleinigen SchÃ¤del-HirnschÃ¤digung (ohne anderweitige Nebenverletzungen).Der Schweregrad der hypertonischen Reaktion scheint in manchen FÃ¤llen der Schwere der Verletzung zu entsprechen, da systolische Druckanstiege um 200 mg Hg und mehr fast ausschlieÃŸlich in FÃ¤llen mit schweren ZertrÃ¼mmerungen der Hirnsubstanz gefunden wurden und geringere, meist sehr flÃ¼chtige arterielle Drucksteigerungen in leichteren bis mittelschweren HirnkontusionsfÃ¤llen.Es folgt eine kurze ErÃ¶rterung der pathogenetischen Faktoren dieser bemerkenswerten hypertonen Kreislaufreaktionsform im akuten Stadium der craniocerebralen Verletzungen.SummaryAn analysis of the circulatory state in 1639 head injury patients in the acute phase has shown that a definite â€œshockâ€ syndrome with severe circulatory collapse is remarkably rarely observed; it only develops if extensive additional damage (abdominal, thoracic, or in the extremities) is present. In contrast, it is very common in the acute stage to see a so-called hypertonic circulatory state, especially in patients with the injury confined to the head.The degree of the hypertonic reaction seems to be related in many cases to the severity of the injury. A rise in systolic pressure to about 200 mm. Hg. or over was found almost exclusively in patients with severe damage to the brain substance, whilst smaller and usually transient rises in arterial pressure occurred in the mild to moderately severe cases of cerebral contusion.In conclusion there is a short discussion of the factors responsible for this remarkable hypertonic type of circulatory reaction.RÃ©sumÃ©Une analyse de l'Ã©tat circulatoire sur 1639 malades atteints Ã  la tÃªte dans la phase aiguÃ« a montrÃ© qu'un syndrome prÃ©cis de â€œshockâ€ avec grave collapsus est trÃ¨s rarement observÃ©; il se dÃ©veloppe seulement si une importante lÃ©sion additionnelle se prÃ©sente (abdominale, thoracique ou dans les extrÃ©mitÃ©s). â€” Au contraire c'est trÃ¨s commun dans le stade aigu de voir un Ã©tat circulatoire appelÃ© hypertonique surtout chez les malades Ã  la lÃ©sion limitÃ©e Ã  la tÃªte.Le degrÃ© de la rÃ©action hypertonique semble Ãªtre en rapport avec la gravitÃ© de la lÃ©sion dans de nombreux cas. Une Ã©lÃ©vation de la pression systolique d'environ 200 mm Hg ou plus, fut trouvÃ©e presque exclusivement chez les malades atteints d'une grave lÃ©sion de la substance cÃ©rÃ©brale tandis que des Ã©lÃ©vations moindres et habituellement passagÃ¨res de la pression artÃ©rielle se sont prÃ©sentÃ©es dans les cas bÃ©nins et peu graves de contusion cÃ©rÃ©brale.En conclusion, il y a une brÃ¨ve discussion des facteurs responsables de ce type hypertonique de rÃ©action circulatoire.RiassuntoLo studio del circolo in 1639 traumatizzati cranio-cerebrali in stadio acuto ha dimostrato che la tipica sindrome di shock con grave collasso circolatorio Ã¨ sorprendentemente rara e presente soltanto quando coesistono notevoli lesioni di altri distretti (addome, torace, estremitÃ ). Molto piÃ¹ frequentemente, nello stadio acuto, si vede invece una reazione circolatoria ipertonica particolarmente nei casi con danno cranio-cerebrale isolato (cioÃ¨ senza lesioni di altri distretti).La entitÃ  della reazione ipertonica sembra in molti casi essere in rapporto alla gravitÃ  della lesione, in quanto un aumento della pressione sistolica sino a 200 mm di Hg e piÃ¹, fu trovato nei casi con grave distruzione della sostanza cerebrale; valori piÃ¹ bassi e molto fluttuanti furono riscontrati nei casi di contusione cerebrale piÃ¹ lieve e di media gravitÃ .Sugue una breve discussione sui fattori patogenetici di questa forma di ipertensione arteriosa degna di nota nello stadio acuto delle lesioni cranio-cerebrali.ResumenUn anÃ¡lisis sobre el estado circulatorio de 1.639 enfermos con afecciones cerebrales en su fase aguda ha demostrado que raramente se observaba un sÃ­ndrome claro de shock con colapso grave; este se presenta si concurre una lesiÃ³n nueva e importante (abdominal, torÃ¡cica o de las extremidades). Por el contrario es muy corriente observar en el estado agudo un cuadro circulatorio llamado hipertÃ³nico, sobre todo en enfermos con lesiones circunscritas en la cabeza.En numerosos casos el grado de reacciÃ³n hipertÃ³nica parece estar en relatiÃ³n con la gravedad de la lesiÃ³n. Una elevaciÃ³n de la presiÃ³n sistÃ³lica hasta alrededor de 200 mm. Hg. o mÃ¡s, se encontrÃ³ casi exclusivamente en los enfermos con graves lesiones de la substancia cerebral, mientras que elevaciones mÃ­nimas y habitualmente pasajeras de la presiÃ³n arterial se presentaron en los casos menos graves y benignos de contusiÃ³n cerebral.Para concluir se discuten brevemente los factores responsables de este tipo hipertÃ³nico de reacciÃ³n circulatoria.",2005,Acta Neurochirurgica
Efficient Randomized Feature Selection Algorithms,"Feature selection is a core problem in machine learning. It plays an important role in making efficient and explainable machine-driven decisions. Embedded feature selection methods, such as decision trees and LASSO, suffer from learner dependency and cannot be applied well to many popular learners. Wrapper methods, which fit arbitrary learning models, are receiving growing interests in many scientific fields. In order to effectively search relevant features in wrapper methods, many randomized schemes have been proposed. In this paper, we present efficient randomized feature selection algorithms empowered by automatic breadth searching and attention searching adjustments. Our schemes are generic and highly parallelizable in nature and can be easily applied to many related algorithms. Theoretical analysis proves the efficiency of our algorithms. Extensive experiments on synthetic and real dataset show that our techniques achieve significant improvements in the selected features' quality and selection time.",2019,2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)
Development and validation of a novel immune-related prognostic model in hepatocellular carcinoma,"Growing evidence has suggested that immune-related genes play crucial roles in the development and progression of hepatocellular carcinoma (HCC). Nevertheless, the utility of immune-related genes for evaluating the prognosis of HCC patients are still lacking. The study aimed to explore gene signatures and prognostic values of immune-related genes in HCC. We comprehensively integrated gene expression data acquired from 374 HCC and 50 normal tissues in The Cancer Genome Atlas (TCGA). Differentially expressed genes (DEGs) analysis and univariate Cox regression analysis were performed to identify DEGs that related to overall survival. An immune prognostic model was constructed using the Lasso and multivariate Cox regression analyses. Furthermore, Cox regression analysis was applied to identify independent prognostic factors in HCC. The correlation analysis between immune-related signature and immune cells infiltration were also investigated. Finally, the signature was validated in an external independent dataset. A total of 329 differentially expressed immuneâ€related genes were detected. 64 immuneâ€related genes were identified to be markedly related to overall survival in HCC patients using univariate Cox regression analysis. Then we established a TF-mediated network for exploring the regulatory mechanisms of these genes. Lasso and multivariate Cox regression analyses were applied to construct the immune-based prognostic model, which consisted of nine immuneâ€related genes. Further analysis indicated that this immune-related prognostic model could be an independent prognostic indicator after adjusting to other clinical factors. The relationships between the risk score model and immune cell infiltration suggested that the nine-gene signature could reflect the status of tumor immune microenvironment. The prognostic value of this nine-gene prognostic model was further successfully validated in an independent database. Together, our study screened potential prognostic immune-related genes and established a novel immune-based prognostic model of HCC, which not only provides new potential prognostic biomarkers and therapeutic targets, but also deepens our understanding of tumor immune microenvironment status and lays a theoretical foundation for immunotherapy.",2020,Journal of Translational Medicine
Debiasing Linear Prediction,"Standard methods in supervised learning separate training and prediction: the model is fit independently of any test points it may encounter. However, can knowledge of the next test point $\mathbf{x}_{\star}$ be exploited to improve prediction accuracy? We address this question in the context of linear prediction, showing how debiasing techniques can be used transductively to combat regularization bias. We first lower bound the $\mathbf{x}_{\star}$ prediction error of ridge regression and the Lasso, showing that they must incur significant bias in certain test directions. Then, building on techniques from semi-parametric inference, we provide non-asymptotic upper bounds on the $\mathbf{x}_{\star}$ prediction error of two transductive, debiased prediction rules. We conclude by showing the efficacy of our methods on both synthetic and real data, highlighting the improvements test-point-tailored debiasing can provide in settings with distribution shift.",2019,ArXiv
Differentially Private Model Selection via Stability Arguments and the Robustness of the Lasso,"We design differentially private algorithms for statistical model selection. Given a data set and a large, discrete collection of â€œmodelsâ€, each of which is a family of probability distributions, the goal is to determine the model that best â€œfitsâ€ the data. This is a basic problem in many areas of statistics and machine learning. We consider settings in which there is a well-defined answer, in the following sense: Suppose that there is a nonprivate model selection procedure f which is the reference to which we compare our performance. Our differentially private algorithms output the correct value f(D) whenever f is stable on the input data set D. We work with two notions, perturbation stability and subsampling stability. We give two classes of results: generic ones, that apply to any function with discrete output set; and specific algorithms for the problem of sparse linear regression. The algorithms we describe are efficient and in some cases match the optimal nonprivate asymptotic sample complexity. Our algorithms for sparse linear regression require analyzing the stability properties of the popular LASSO estimator. We give sufficient conditions for the LASSO estimator to be robust to small changes in the data set, and show that these conditions hold with high probability under essentially the same stochastic assumptions that are used in the literature to analyze convergence of the LASSO.",2013,
Padua Municipal Archives from the 13th to the 20th Centuries: A Case of a Record-Keeping System in Italy,"This research describes the record-keeping systems of Paduaâ€™s municipal administration from the 13 to the 20 centuries, i.e., by free commune, Carraresisâ€™ seigniory, public servants of the Republic of Venice, and local administration in the context of the State before and after the national unification (1861, but for Veneto and Padua 1866). The focus is on the analysis of the medieval and modern chancellery, while archives were preserved and kept by corporate bodies charged with public administration, and afterwards bureaucratic and historiographical work carried out in the 19 and the 20 centuries. At this time new management methods, adopted by States created by Napoleon and devoted to current archives, influenced historical 1 The States, started in North Italy after the Italian campaign, were, at the beginning, the â€œMunicipalitaâ€ in different towns and, later, the Repubblica Cisalpina (1797â€“1799), the Repubblica Italiana (1802â€“1805), and the Regno dâ€™Italia (1805â€“1814). There were some periods of direct French domination, interrupted by Austrian dominations, concomitant with the war events. A general overview of the period is offered in Carlo Zaghi, â€œLâ€™Italia di Napoleone dalla Cisalpina al Regno,â€ in Storia dâ€™Italia diretta da Giuseppe Galasso: XVIII/1 (Torino, 1986). On the Padua events see Giulio Monteleone, â€œPadova dal trattato di Campoformido alla caduta del regime napoleonico (1797â€“1814),â€ Bollettino del Museo Civico di Padova LXXV (1986), pp. 115â€“33. In those States public administrators utilized an archival management system, based on the concomitant use of three tools: the â€œregistro di protocolloâ€ (i.e., register of incoming and outcoming mail), the â€œtitolario di classificazioneâ€ (i.e., classification system or plan), and the â€œrepertorio dei fascicoliâ€ (i.e., file list). On this subject see Paola Carucci Il documento contemporaneo. Diplomatica e criteri di edizione (Roma, 1987), p. 32 and Paul Delsalle, Une histoire de lâ€™archivistique (Quebec, 1998), pp. 166â€“69.",2006,Archivaria
Can Machine Learning Algorithms Predict Which Patients Will Achieve Minimally Clinically Important Differences From Total Joint Arthroplasty?,"Background Identifying patients at risk of not achieving meaningful gains in long-term postsurgical patient-reported outcome measures (PROMs) is important for improving patient monitoring and facilitating presurgical decision support. Machine learning may help automatically select and weigh many predictors to create models that maximize predictive power. However, these techniques are underused among studies of total joint arthroplasty (TJA) patients, particularly those exploring changes in postsurgical PROMs. Question/purposes (1) To evaluate whether machine learning algorithms, applied to hospital registry data, could predict patients who would not achieve a minimally clinically important difference (MCID) in four PROMs 2 years after TJA; (2) to explore how predictive ability changes as more information is included in modeling; and (3) to identify which variables drive the predictive power of these models. Methods Data from a single, high-volume institutionâ€™s TJA registry were used for this study. We identified 7239 hip and 6480 knee TJAs between 2007 and 2012, which, for at least one PROM, patients had completed both baseline and 2-year followup surveys (among 19,187 TJAs in our registry and 43,313 total TJAs). In all, 12,203 registry TJAs had valid SF-36 physical component scores (PCS) and mental component scores (MCS) at baseline and 2 years; 7085 and 6205 had valid Hip and Knee Disability and Osteoarthritis Outcome Scores for joint replacement (HOOS JR and KOOS JR scores), respectively. Supervised machine learning refers to a class of algorithms that links a mapping of inputs to an output based on many input-output examples. We trained three of the most popular such algorithms (logistic least absolute shrinkage and selection operator (LASSO), random forest, and linear support vector machine) to predict 2-year postsurgical MCIDs. We incrementally considered predictors available at four time points: (1) before the decision to have surgery, (2) before surgery, (3) before discharge, and (4) immediately after discharge. We evaluated the performance of each model using area under the receiver operating characteristic (AUROC) statistics on a validation sample composed of a random 20% subsample of TJAs excluded from modeling. We also considered abbreviated models that only used baseline PROMs and procedure as predictors (to isolate their predictive power). We further directly evaluated which variables were ranked by each model as most predictive of 2-year MCIDs. Results The three machine learning algorithms performed in the poor-to-good range for predicting 2-year MCIDs, with AUROCs ranging from 0.60 to 0.89. They performed virtually identically for a given PROM and time point. AUROCs for the logistic LASSO models for predicting SF-36 PCS 2-year MCIDs at the four time points were: 0.69, 0.78, 0.78, and 0.78, respectively; for SF-36 MCS 2-year MCIDs, AUROCs were: 0.63, 0.89, 0.89, and 0.88; for HOOS JR 2-year MCIDs: 0.67, 0.78, 0.77, and 0.77; for KOOS JR 2-year MCIDs: 0.61, 0.75, 0.75, and 0.75. Before-surgery models performed in the fair-to-good range and consistently ranked the associated baseline PROM as among the most important predictors. Abbreviated LASSO models performed worse than the full before-surgery models, though they retained much of the predictive power of the full before-surgery models. Conclusions Machine learning has the potential to improve clinical decision-making and patient care by helping to prioritize resources for postsurgical monitoring and informing presurgical discussions of likely outcomes of TJA. Applied to presurgical registry data, such models can predict, with fair-to-good ability, 2-year postsurgical MCIDs. Although we report all parameters of our best-performing models, they cannot simply be applied off-the-shelf without proper testing. Our analyses indicate that machine learning holds much promise for predicting orthopaedic outcomes.â€ƒ Level of Evidence Level III, diagnostic study.",2019,Clinical Orthopaedics and Related Research
"Variability in mortality after caesarean delivery, appendectomy, and groin hernia repair in low-income and middle-income countries: implications for expanding surgical services","BACKGROUND
While surgical interventions occur at lower rates in resource-poor settings, rates of complication and death after surgery are substantial but have not been well quantified. A deeper understanding of outcomes is a crucial step to ensure that quality accompanies increased global access to surgical care. We aimed to assess mortality following surgery to assess the risks of such interventions in these environments.


METHODS
We collected the most recent demographic, health, and economic data from WHO for 114 countries classified as low-income or lower-middle-income according to the World Bank in 2005. We searched OVID, MedLine, PubMed, and SCOPUS to identify studies in these countries reporting all-cause mortality after three commonly performed operations: caesarean delivery, appendectomy, and groin hernia repair. Reports from governmental and other agencies were also identified. We modelled surgical mortality rates for countries without reported data with the lasso technique that performs continuous variable subset selection to avoid model overfitting. We validated our model against known case fatality rates for caesarean delivery. We aggregated mortality results by subregion to account for variability in data availability. We then created collective surgical case fatality rates by WHO region.


FINDINGS
We identified 42 countries with mortality data for at least one of the three procedures. Median reported mortality rates were 7Â·7 per 1000 operations for caesarean delivery (IQR 3-14), 4Â·0 per 1000 operations for appendectomy (IQR 0-17), and 4Â·7 per 1000 operations for hernia groin (IQR 0-13); all recorded deaths occurred during the same admission to hospital as the operation. Based on our model, case fatality rate estimates by subregion ranged from 0Â·7 (central Europe) to 13Â·9 (central sub-Saharan Africa) per 1000 caesarean deliveries, 5Â·6 (central Asia) to 6Â·4 (central sub-Saharan Africa) per 1000 appendectomies, and 3Â·5 (tropical Latin America) to 33Â·9 (central sub-Saharan Africa) per 1000 hernia repairs.


INTERPRETATION
All-cause postoperative mortality rates are exceedingly variable within resource-constrained environments, and substantially higher than those in middle-income and high-income settings. Efforts to expand surgical access and provision of services must include a strong commitment to improve the safety and quality of care.


FUNDING
None.",2015,The Lancet
"Centennial Changes in the Nearâ€Shore Mysid Fauna of the Gulf of Naples (Mediterranean Sea), with Description of Heteromysis riedli sp. n. (Crustacea, Mysidacea)",". The marine mysid fauna of the Gulf of Naples is the best known in the Mediterranean, dating back to faunal lists and revisions given by founder authors in 1877â€Šâ€“â€Š1929. Up to 1930, a total of 21 (currently valid) benthopelagic and benthic coastal species were recorded. The new census in 1975â€Šâ€“â€Š2000 yielded no species in brackish and freshwaters (salinity range 0â€Šâ€“â€Š30), only one species in mixoeuhaline waters (30â€Šâ€“â€Š39), and 39 species in fully marine near-shore waters (36â€Šâ€“â€Š38). Most species were restricted to islands and submarine banks as hotspots of biodiversity, while only four species were also found along the more intensively urbanized continental coasts of the gulf. Compared with the situation in the 19th century, two marine species, Acanthomysis longicornis and Mysidopsis angusta, have disappeared from the Gulf of Naples, while still present in the less urbanized and largely oligotrophic Gulf of Salerno. The numbers of known euthalassobiontic species decreased in the â€˜continentalâ€™ Gulf of Naples, but increased in the â€˜insularâ€™ gulf. 
 
 
 
Local population extinctions are related mainly to human impact on freshwater input into shallow coastal waters. Urbanization processes favoured the disappearance of brackish and freshwaters from the surface (through drainage and canalization) and the deterioration (through urban and industrial pollution) of the remaining ones, resulting in eutrophication of coastal waters and in impoverishment of the benthos, such as the visible regression of seagrasses. Increased species numbers in the â€˜insularâ€™ gulf reflect the lower degree of urbanization in the less polluted peripheral zones and the increased use of more specific sampling methods in combination with improved knowledge of mysid biology. 
 
 
 
With the use of epibenthic nets during the day and at night, Heteromysis (Heteromysis) riedli sp.Â n. was sampled from Posidonia oceanica meadows on the Island of Â­Ischia. The males of the new species are exceptional in having a pair of modified, backwards-oriented, flagellate setae terminally on the antennular trunc, while the females show only the usual forwards-oriented, smooth setae in this position.",2001,Marine Ecology
Feature Selecting Hierarchical Neural Network for Industrial System Health Monitoring,"Industrial System Health Monitoring relies usually on the monitoring of well-designed features. This requires both, the engineering of reliable features and a good methodology for their analysis. If traditionally, features were engineered based on the physics of the system, recent advances in machine learning demonstrated that features could be automatically learned and monitored. In particular, using Hierarchical Extreme Learning Machines (HELM), based on random features, very good results have already been achieved for health monitoring with training on healthy data only. 
Yet, although very useful and mathematically sound, random features have little popularity as they contradict the intuition and seem to rely on luck. This tends to increase the â€œblackboxâ€ effect often associated with Machine Learning. To mitigate this, in this paper, we propose to modify the traditional HELM architecture such that, while still relying on random features, only the most useful features among a large population will be selected. 
Traditional HELM are made of stacked contractive autoencoders with `1- or `2-regularisation and of a classifier as last layer. To achieve our objective, we propose to opt for expanding auto-encoders instead, but trained with a strong Group-LASSO regularization. This Group-LASSO regularisation fosters the selection of as few features as possible, making the auto-encoder in reality (or in testing condition) contractive. This deterministic selection provides useful features for health monitoring, without the need of learning or manually engineering them. 
The proposed approach demonstrates a better performance for fault detection and isolation on case studies developed for HELM evaluation.",2018,
The Application of Support Vector Machine with Elastic Net Regularizationin in Classification of Wheat Seeds,"Machine Learning is playing a big part in data analysis. Aiming at the problem of wheat seed classification, Seed data from UCI Machine Learning Repository is used as experimental data in this paper, firstly Support Vector Machine (SVM) algorithm is used to classify and predict the test set samples of wheat seed data sets. Secondly, Support Vector Machine (SVM) algorithm with Lasso and elastic net regularization is used to classify and predict wheat seed. The experimental results show that the SVM-Elastic Net model has high classification accuracy.",2019,
Seasonal and diel patterns of larval fish drift in a western South Carolina swamp,"Fish larvae were collected weekly during 1986-1987 from the lower 3 km of Steel Creek (Barnwell County), a riverine swamp, to assess reproduction in this rarely studied habitat type. In 1987, larvae appeared in the following order and abundance (as a percentage of the total diural density): blackbanded darter Percina nigromaculatus (3%) and other darters Etheostoma spp. (32%); pirate perch Aphredoderus sayanus (NA); pygmy sunfish Elassoma spp. (7%); chubsuckers Erimyson spp. (13%); bluespotted sunfish Enneacanthus gloriosus (16%); bluegill Lepomis macrochirus (1%), redbreast sunfish L. auritus (<1%), brook silverside Labidesthes sicculus (6%) and ironcolor shiner Notropis chalybaeus (8%); warmouth L. gulosus (8%); spotted sunfish L. punctatus (NA). Unidentified cyprinids (2%), centrarchids (2%) and miscellaneous species (3%) were collected throughout the study period. Monthly diel collections showed that drift densities of chubsuckers, cyprinids, Etheostoma spp., bluegill and pygmy sunfish increased 41 to 160X after sundown; pirate perch and spotted sunfish were collected only at night. Swamp densities peaked during 2000-0159 h (111.5 per 100m), whereas densities in the channel that drained the swamp into the Savannah River peaked during 0200-0759 h (38.7). The later peak in the channel was attributed to larvae that had drifted from the swamp and were essentially lost moreÂ Â» from the system. 4 figs., 1 tab. Â«Â less",1988,
clogitLasso: an R package for highâ€“dimensional analysis of matched caseâ€“control and caseâ€“crossover data,"The conditional logistic regression model is the standard tool for the analysis of epidemiological studies in which one or more cases (the event of interest), are individually matched with one or more controls (not showing the event). These situations arise, for example, in matched case-control and case-crossover studies. 
Usually, regression coefficients are estimated by maximizing the conditional log-likelihood function and variable selection is performed by conventional manual or automatic selection procedures, such as stepwise. These techniques are, however, unsatisfactory in sparse, high-dimensional settings in which penalized methods, such as the lasso (least absolute shrinkage and selection operator) [Tibshirani, 1996], have emerged as an alternative. In particular, the lasso and related methods have recently been adapted to conditional logistic regression [Avalos et al., 2012b]. 
The R package clogitLasso brings together algorithms to estimate parameters of conditional logistic regression models using lasso, other sparse methods (elastic net, adaptive lasso and bootstrapped versions of lasso). Different criteria are implemented for choosing the regularization term accounting for the dependent nature of data. Resampling methods for evaluating the stability of the selected model are proposed. The most common individually matched study designs are available.",2013,
"Pollen sequences from the city of Sagalassos (Pisidia, southwest Turkey).","Two pollen sequences from the Classical city of Sagalassos (Pisidia, southwest Turkey) show that the hills just north of the city were forested during the main occupation period of the city (late Hellenistic to early Byzantine). They demonstrate that there was a mixed needle-leaved forest of Pinus, Cedrus libani and Abies cilicica. The platform on which the city sat was already deforested, as is indicated by the presence of pollen from various light demanding herbs. Furthermore, there is evidence that grapevines (Vitis) were cultivated, indicating that much of the land below the city was already exploited for agricultural purposes. Walnut trees were also cultivated near the city. It is probable that suburban farmsteads were present close to the city. The pollen sequences show that man-made deposits from high altitudes may contain important information on the former natural and cultural vegetation of mountain sites in Anatolia. Archaeologists and palynologists should draw more attention to these pollen rich man-made contexts.",2003,Anatolian studies
An â„“1-oracle inequality for the Lasso in multivariate finite mixture of multivariate Gaussian regression models,"We consider a multivariate finite mixture of Gaussian regression models for high-dimensional data, where the number of covariates and the size of the response may be much larger than the sample size. We provide an l 1 -oracle inequality satisfied by the Lasso estimator according to the Kullbackâˆ’Leibler loss. This result is an extension of the l 1 -oracle inequality established by Meynet in [ ESAIM: PS 17 (2013) 650â€“671]. in the multivariate case. We focus on the Lasso for its l 1 -regularization properties rather than for the variable selection procedure.",2015,Esaim: Probability and Statistics
"The effects of pre-slaughter selection of reindeer bulls (Rangifer tarandus tarandus L.) on technological and sensory meat quality, blood metabolites and abomasal lesions","Thirty reindeer bulls (age 1 1/2 years) were subjected to different pre-slaughter treatments to study the effects on ultimate pH values, muscle glycogen content, blood metabolites and abomasal lesions. Gathering and herding into a grazing corral were followed by various selection procedures. Before starting these, a control group of 10 reindeer were captured by lasso and slaughtered outside the grazing corral. Ten reindeer were then selected by hand from a small group of animals (100-150 head) in a small selection corral. Another 10 reindeer were selected from a large herd of about 1000-2000 animals, by the traditional technique of using a lasso. During a 6-hour selection, animals were captured and slaughtered after 1.5 hours (n = 2), 3-5 hours (n = 2), 5 hours (n = 3) and 6 hours (n=3) respectively. The results showed the technique of using a lasso to be stressful and glycogen-depleting, as the two lasso captured groups (the control group and the reindeer exposed to the protracted lasso selection) had the highest ultimate pH values and lowest muscle glycogen values measured. By contrast, the selection procedure where reindeer were captured by hand, was not found to be detrimental to glycogen content and ultimate pH values. Nevertheless, both selection techniques expose the reindeer to acute stress during the capture and manual restraint, which in the present study was reflected in high plasma Cortisol values in all treatment groups. The frequency of abomasal lesions was highest in the group of reindeer subjected to the prolonged selection procedure. No connection between technological and sensory meat quality was found in this study. The technique of selecting animals by hand ought to be further developed so that existing practical problems can be solved. The technique could then be recommended for wider use.",1997,Rangifer
Statistical consistency and asymptotic normality for high-dimensional robust M-estimators,"We study theoretical properties of regularized robust M-estimators, applicable when data are drawn from a sparse high-dimensional linear model and contaminated by heavy-tailed distributions and/or outliers in the additive errors and covariates. We first establish a form of local statistical consistency for the penalized regression estimators under fairly mild conditions on the error distribution: When the derivative of the loss function is bounded and satisfies a local restricted curvature condition, all stationary points within a constant radius of the true regression vector converge at the minimax rate enjoyed by the Lasso with sub-Gaussian errors. When an appropriate nonconvex regularizer is used in place of an l_1-penalty, we show that such stationary points are in fact unique and equal to the local oracle solution with the correct support---hence, results on asymptotic normality in the low-dimensional case carry over immediately to the high-dimensional setting. This has important implications for the efficiency of regularized nonconvex M-estimators when the errors are heavy-tailed. Our analysis of the local curvature of the loss function also has useful consequences for optimization when the robust regression function and/or regularizer is nonconvex and the objective function possesses stationary points outside the local region. We show that as long as a composite gradient descent algorithm is initialized within a constant radius of the true regression vector, successive iterates will converge at a linear rate to a stationary point within the local region. Furthermore, the global optimum of a convex regularized robust regression function may be used to obtain a suitable initialization. The result is a novel two-step procedure that uses a convex M-estimator to achieve consistency and a nonconvex M-estimator to increase efficiency.",2015,ArXiv
SaÌmi Culture as Basis for Mathematics Teaching,"A QRS-system (Barton, 1999) is a meaningful system that for a given group of people gives meaning to Quantity, Relations and Space. Each cultural group has their own QRS-system. This paper focuses on how the SÃ¡mi cultureâ€™s elements lavvu, lasso, skis and duodji can function as basis for mathematics teaching. The elements are described and mathematised (Freudenthal, 1973); made accessible to mathematics treatment. The elements are further categorised into two groups, Relations and Space. There will be pointed out possibilities for how to use these elements in mathematics teaching.",2006,
Title : Accuracy of Genomic Selection Methods in a Standard Dataset of Loblolly Pine ( Pinus taeda L . ),"Genomic selection can increase genetic gain per generation through early selection. Genomic selection is expected to be particularly valuable for traits that are costly to phenotype, and expressed late in the life-cycle of long-lived species. Alternative approaches to genomic selection prediction models may perform differently for traits with distinct genetic properties. Here the performance of four different original methods of genomic selection that differ with respect to assumptions regarding distribution of marker effects, including (i) Ridge Regression â€“ Best Linear Unbiased Prediction (RRBLUP), (ii) Bayes A, (iii) Bayes CÏ€, and (iv) Bayesian LASSO are presented. In addition, a modified RR-BLUP (RR-BLUP B) that utilizes a selected subset of markers was evaluated. The accuracy of these methods was compared across 17 traits with distinct heritabilities and genetic architectures, including growth, development and diseaseresistance properties, measured in a Pinus taeda (loblolly pine) training population of 951 individuals genotyped with 4,853 SNPs. The predictive ability of the methods was evaluated using a 10-fold, cross-validation approach, and differed only marginally for most method/trait combinations. Interestingly, for fusiform rust disease-resistance traits Bayes CÏ€, Bayesian LASSO and RR-BLUB B had higher predictive ability than RRBLUP and Bayes A. Fusiform rust is controlled by few genes of large effect. A limitation of RR-BLUP is the assumption of equal contribution of all markers to the observed variation. The genotypic and phenotypic data used in this study is publically available for comparative analysis of genomic selection prediction models.",2012,
A Dual Alternating Direction Method of Multipliers for the Constrained Lasso Problems,"In this paper, we develope a dual alternating direction method of multipliers (ADMM) for the constrained asso problem, which is the standard lasso problem with linear inequality constraints. Under mild conditions, we resent the global convergence and local linear convergence rate for the algorithm. Numerical experiments demonstrate the efficiency and robustness of the dual ADMM.",2018,
"Geochemical indications of concealed copper mineralization in an area northwest of Mount Isa, Queensland, Australia","ABSTRACT Bampton, K.F., Collins, A.R., Glasson, K.R. and Guy, B.B., 1977. Geochemical indications of concealed copper mineralization in an area northwest of Mount Isa, Queensland, Australia. J. Geochem. Explor., 8: 169â€“188. Ferruginous outcrops (ironstones) are a common feature of deeply oxidized dolomitic members of the Middle Proterozoic dolomitic and carbonaceous/siliceous sequence in northwestern Queensland, Australia. The textural and geochemical interpretation of the ironstones is important in regional and detailed exploration for Cu, Ag, Pb and Zn. In the Mount Kelly area, primary Cu mineralization occurs in breccias, veins and disseminations in dolomitic-rich bands. Because of structural complexities, the moderate- to high-grade (>2% Cu) zones do not outcrop. The geochemistry of this primary mineralization is described, no element other than Cu being detected characteristic of the chalcopyrite. Surface indications of mineralization are Cu anomalous ironstones in the dolomitic units and some secondary Cu mineralization. The ironstones are classified as (1) gossans forming directly from in-situ oxidation of primary mineralization; (2) fault ironstones; (3) â€œstratigraphicâ€ ironstones which are broadly distributed along particular units but which transgress lithological boundaries in detail. Whole rock geochemistry of the fault and â€œstratigraphicâ€ ironstones reveals a significant positive correlation of Cu with Ag, a weak positive correlation with Ni and a strong negative correlation of Cu with Co. There is no statistical or spatial evidence of Cu being related to Mn. Co and As anomalies can reflect the presence of pyrite. The Fe in the ironstones is derived from dolomite and sulphides in the sequence. Cu in the ironstones is derived from three sources, namely: disseminated chalcopyrite in the sequence, Cu in pyrite, and specific higher-grade Cu concentrations. These three sources cannot readily be differentiated. The magnitude of a Cu anomaly is no indication of Cu values in the primary zone. Exploration should be aimed at locating ironstones and prospective stratigraphic horizons which are anomalous in Cu, followed by subsurface testing, but not necessarily with the subsurface continuation of ironstones as drilling targets. Where the primary dolomitic rocks average over 1500 ppm Cu over significant thickness, the sequence should be considered prospective.",1977,Journal of Geochemical Exploration
"Biosynthetic Gene Cluster of a d-Tryptophan-Containing Lasso Peptide, MS-271.","MS-271, produced by Streptomyces sp. M-271, is a lasso peptide natural product comprising 21 amino acid residues with a d-tryptophan at its Câ€…terminus. Because lasso peptides are ribosomal peptides, the biosynthesis of MS-271, especially the mechanism of d-Trp introduction, is of great interest. The MS-271 biosynthetic gene cluster was identified by draft genome sequencing of the MS-271 producer, and it was revealed that the precursor peptide contains all 21 amino acid residues including the C-terminal tryptophan. This suggested that the d-Trp residue is introduced by epimerization. Genes for modification enzymes such as a macrolactam synthetase (mslC), precursor peptide recognition element (mslB1), cysteine protease (mslB2), disulfide oxidoreductases (mslE, mslF), and a protein of unknown function (mslH) were found in the flanking region of the precursor peptide gene. Although obvious epimerase genes were absent in the cluster, heterologous expression of the putative MS-271 cluster in Streptomyces lividans showed that it contains all the necessary genes for MS-271 production including a gene for a new peptide epimerase. Furthermore, a gene-deletion experiment indicated that MslB1, -B2, -C and -H were indispensable for MS-271 production and that some interactions of the biosynthetic enzymes were essential for the biosynthesis of MS-271.",2018,Chembiochem : a European journal of chemical biology
"Brood-guarding duration in black-browed albatrosses Thalassarche melanophris: temporal, geographical and individual variation","In birds, the period spent brooding or guarding young chicks is highly variable, but such variation has seldom been studied. Previous single-year studies of Antarctic petrels Thalassoica antarctica and grey-headed albatrosses Thalassarche chrysostoma revealed a pronounced seasonal decline in brood-guarding duration and gave rise to the â€˜synchronisation hypothesisâ€™, which suggests that some of the variation in the length of the brood-guarding stage is related to predictable seasonal changes in the risk of chick predation. We tested the predictions of this and three other hypotheses in a two-site, four-year study of the black-browed albatross T. melanophris. The existence of a pronounced seasonal decline in broodguarding duration was apparent at both sites, and in years of contrasting food availability, providing further support for the â€˜synchronisation hypothesisâ€™. Alternative explanations for this pattern are that short brood-guarding periods for latehatched chicks result from a seasonal decline in food availability or from the fact that early nesting birds are of higher individual quality. However, these explanations are at odds with the absence of a seasonal decline in early chick growth or in probability of chick survival. Furthermore, adult quality (measured as past reproductive performance) had a weak and inconsistent effect on the duration of brood-guarding. Weather changes explained some of the variation in broodguarding, but there were no differences between regions of contrasting climates. Individual pairs displayed a degree of inter-annual consistency in brood-guarding duration and, at least in some years, longer brood-guarding resulted in higher fledging probability. We speculate that a higher investment in brood-guarding increases the cost of reproduction, which counteracts other selective pressures that would otherwise lead to longer brood-guarding durations.",2010,Journal of Avian Biology
Weighing and counting shell : A response to Glassow and Claassen,"Glassow discusses several problems with the use of minimum number of individuals (MNI) in archaeological shellfish analysis, including the difficulty of identifying non-repetitive elements (NRE) to species level for several taxa. However, these problems, especially fragmentation, are more critical for the weight method than for MNI estimates. We have successfully identified thousands of NRE for all species common in southern California coastal archaeological sites. We also suggest that a measure, such as MNI, that provides estimates of numbers of individuals is a more reliable and valid measure with which to address most research questions. The weight method only provides a measure of the weight of some of the fragments from the shells of those individuals.",2000,American Antiquity
Referees 2008,"Paolo Arrigoni (Milan, Italy) Pietro Bartolozzi (Verona, Italy) Celeste Bertone (Brescia, Italy) Amin Sadegh Bigham (Shahrekord, Iran) Sergio Brambilla (Milan, Italy) Umberto de Bellis (Milan, Italy) Shabir A. Dhar (Srinagar, India) Cesare Faldini (Bologna, Milan) Olimpio Galasso (Catanzaro, Italy) Vincenzo Guzzanti (Rome, Italy) Yoichi Koike (Miyagi, Japan) Arun Kumar (Cheshire, UK) Harish V. Kurup (Croydon, UK) Giulio Maccauro (Rome, Italy) Bruno Magnan (Verona, Italy) Masahiko Nozawa (Tokyo, Japan) Matthew E. Oetgen (New Haven, CT, USA) Elisha Ofiram (Rehovot, Israel) Roberto Padua (Rome, Italy) Luca Pierannunzii (Milan, Italy) Filippo Randelli (Milan, Italy) Enrico Rebuzzi (Oderzo, Italy) Fabrizio Rivera (Turin, Italy) Celeste Scotti (Milan, Italy) Kei Shiramizu (Sydney, Australia) Roop Singh (Rohtak, India) Matthias Therbo (Copenhagen, Denmark) Paolo Tranquilli Leali (Sassari, Italy) Carmine Zoccali (Rome, Italy) The quality of the Journal of Orthopaedics and Traumatology depends on the qualified and regular collaboration of renowned scientists who devoted their time to constructively review the submitted articles.We are indebted to the following experts who reviewed papers which completed the peer-reviewing process within 2008.",2008,Journal of Orthopaedics and Traumatology
Joint Learning of Multiple Differential Networks With Latent Variables,"Graphical models have been widely used to learn the conditional dependence structures among random variables. In many controlled experiments, such as the studies of disease or drug effectiveness, learning the structural changes of graphical models under two different conditions is of great importance. However, most existing graphical models are developed for estimating a single graph and based on a tacit assumption that there is no missing relevant variables, which wastes the common information provided by multiple heterogeneous data sets and underestimates the influence of latent/unobserved relevant variables. In this paper, we propose a joint differential network analysis (JDNA) model to jointly estimate multiple differential networks with latent variables from multiple data sets. The JDNA model is built on a penalized D-trace loss function, with group lasso or generalized fused lasso penalties. We implement a proximal gradient-based alternating direction method of multipliers to tackle the corresponding convex optimization problems. Extensive simulation experiments demonstrate that JDNA model outperforms state-of-the-art methods in estimating the structural changes of graphical models. Moreover, a series of experiments on several real-world data sets have been performed and experiment results consistently show that our proposed JDNA model is effective in identifying differential networks under different conditions.",2019,IEEE Transactions on Cybernetics
Performance Enhancements & Analysisinnext Generation Resilientpacket Ringnetworks,"In multi-service broadband networks, ringsarethe dominant topology. Resilient Packet Ring(RPR) hasemerged asakeytechnology andarecent IEEEstandard indelivering transport convergence. Nonetheless, thecurrent standard has several drawbacks suchas.slowconvergence, severe oscillation, ClassofService (CoS) end-to-end differentiation anddual-ring utilization. Wesummarize howrecent packet ringresearch partially addresses thesedrawbacks. We address theremaining items byintroducing anewtechnique which takes into account thetotal bandwidth available onboth ringlets, andallocate flowbandwidth basedonavailability, costandtraffic prioritization. Wederive theperformance analysis andpacket queueing delay forourtechnique, and compare theresults torecent RPRresearch. Oursimulation andresults demonstrate anincrease inutilization andservice fulfillment, withanacceptable increase inpacket delay. The outcome ofourworkwill beusedtoassist system designers andservice provider network planners withtheir development & network deployments.",2006,
Some applications of the Knaster-Kuratowski and Mazurkiewicz principle in hyperconvex metric spaces,"In this paper, as applications of the Knaster-Kuratowski and Mazurkiewicz principle in the hyperconvex version, we obtain the Ky Fan type matching theorems for closed and open covers. As applications, some intersection theorems which are hyperconvex versions of corresponding results due to Alexandroff and Pasynkoff, Fan, Klee, Horvath, and Lassonde are established. Then, the Ky Fan type best approximation theorem and Schauder-Tychonoff fixed-point theorem (i.e., Fan-Glicksberg fixed-point theorem) for set-valued mappings in noncompact hyperconvex spaces are also given. Finally, we obtain a general form of the Browder-Fan fixed-point theorem for set-valued mappings in noncompact hyperconvex spaces. These results include corresponding results in the literature as special cases.",2000,Mathematical and Computer Modelling
