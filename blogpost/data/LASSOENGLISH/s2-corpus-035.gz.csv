title,abstract,year,journal
"Fabrication, calibration, and recovery of chemical nanosensor array for ammonia detection","The low selectivity of nanosensors is one of their major obstacles for their wide deployment. To enhance the selectivity, nanosensor array made from zinc oxide (ZnO) nanowires and carbon nanotubes (CNTs) was assembled through dielectrophoresis (DEP). The fabricated nanosensor array was used to detect ammonia (NH3) in a well-controlled environment at room temperature. Because of their opposite material types, ZnO nanowire based sensor behaved oppositely to CNT based sensor. In this study, it is also demonstrated that DC biases can quickly recover both sensing elements. After collecting sensing signals from two transducers under different NH3 concentrations, the concentration of NH3 can be estimated through regression methods. It is shown that quadratic model with the lasso performs well on the collected data.",2017,2017 IEEE 17th International Conference on Nanotechnology (IEEE-NANO)
"Assessment of safety and quality of fermented milk of camels, cows, and goats sold and consumed in five localities of Burkina Faso","Background and Aim
Fermented milk is food produced and consumed all over the world and plays an important role in human nutrition. This work aimed to evaluate the microbiological and physicochemical quality and mineral composition of fermented milk consumed in Burkina Faso.


Materials and Methods
A total of 114 samples of fermented milk from camels, goats, and cows were purchased in the market in five localities in Burkina Faso; Bobo Dioulasso, Djibo, Dori, Gorom-Gorom, and Sebba. Microbiological and physical parameters were monitored using standards methods.


Results
Microbiological analysis of fermented milks showed high average values of 7.60Â±1.50Ã—109 colony-forming unit per milliliter (CFU/ml), 5.72Â±3.60Ã—107 CFU/ml, 5.53Â±2.00Ã—105 CFU/ml, 1.97Â±0.18Ã—103 CFU/ml, 1.98Â±0.25Ã—103 CFU/ml, and 0.10Â±0.09Ã—103 CFU/ml for total microbial flora, lactic acid bacteria, yeasts and molds, Staphylococcus aureus, total coliforms, and thermotolerant coliforms, respectively. None of the samples were contaminated by Salmonella or Shigella. The average values of pH, acidity, dry matter, ash, fats, proteins, and total carbohydrates content of samples were ranged, respectively: 3.830-4.137, 1.888-2.822%, 8.271-13.004%, 0.199-0.476%, 1.210-3.863%, 2.125-3.764%, and 3.080-5.428 % (w/w). Na/K and Ca/Mg ratio ranged from 0.104 to 0.909 and from 3.392 to 16.996, respectively. Total microbial flora, yeasts and molds, total coliforms, fats, calcium, potassium, iron, and zinc were significantly different.


Conclusion
This research contributed in the evaluation of the hygienic and nutritional qualities of local fermented milk. Results obtained in this study confirm the need to set up the training program on the sanitary condition to traditional maker's to ensure the good fermented milk with high organoleptic and nutritional qualities.",2019,Veterinary World
A palynological investigation of two till samples from Leicestershire,"The two samples yielded similar palynological signatures. Low levels of Carboniferous (Namurian and/or Westphalian) spores are present. However, the majority of the allochthonous palynomorphs are of Late Triassic (Rhaetian) age, based on the occurrences of key markers such as Rhaetipollis germanicus and Rhaetogonyaulax rhaetica. Sample 1 yielded extremely low numbers of Quaternary pollen grains. The majority of the palynologically-productive input to these tills are of Rhaetian age. It is possible that several Triassic lithotypes and ages are present. However, older Triassic strata in the UK tend to be organic-poor and the relative proportions of species recovered are typical of the Rhaetian Stage. The most likely sources of the Triassic input are the Westbury and Lilstock formations. It is also possible that some of the abundant Classopollis meyeriana specimens were derived from the Early Jurassic (Hettangian/early Sinemurian).",2004,
Encefalitis herpÃ©tica neonatal: valor de la clÃ­nica versusla biologÃ­a molecular,"Resumen La encefalitis herpetica genera un desafio diagnostico y es causa de alta morbi-mortalidad en ninos. Se requiere de una sospecha clinica precoz y una prueba diagnostica util, rapida y segura, ya que sin tratamiento oportuno y adecuado, hasta 70% de los casos puede fallecer. Comu-nicamos el caso de una recien nacida de 25 dias de vida, que presenta un cuadro clinico compatible con encefalitis herpetica, donde el diagnostico etiologico tardo en ser conï¬ rmado y solo la tecnica de reaccion de la polimerasa en cadena en tiempo real (RPC-TR) aplicada de forma repetida permitio certiï¬ car la presencia de virus herpes simplex tipo 1 en el LCR. Referencias bibliograï¬ cas 1.- Kimberlin D W. Neonatal herpes simplex infection. Clin Microbiol Rev 2004; 17: 1-13.2.- Kimberlin D W, Lin C Y, Jacobs R F, Powell D A, Frenkel L M, Gruber W C, et al. Natural history of neonatal herpes simplex virus infections in the acyclovir era. Pediatrics 2001; 108: 223-93.- Kimberlin D W. Management of HSV encephalitis in adults and neonates: Diagnosis, prognosis and treatment. Herpes 2007; 14: 11-6.4.- Whitley R J, Soong S J, Hirsh M S, Karchmer A W, Dolin R, Galasso G, et al. Herpes simplex encephalitis: vidarabine therapy and diagnostic problems. N Engl J Med 1981; 304: 313-8.5.- Gutierrez K M, Whitley R J, Arvin A M. Herpes simplex virus infections. En: Infectious Diseases of the Fetus and Newborn Infant. Remington JS, Klein JO, Wilson CB, Nizet V, Maldonado YA, eds. 7th Ed, 2011. Philadelphia; Elsevier Saunders pp. 813-33.6.- Whitley R J, Lakeman F. Herpes simplex virus infections of the central nervous system: therapeutic and diagnostic considerations. Clin Infect Dis 1995; 20: 414-20.7.- Weil A A, Glaser C A, Amad Z, Forghani B. Patients with suspected herpes simplex encephalitis: Rethinking an initial negative polymerase chain reaction result. Clin Infect Dis 2002; 34: 1154-78.- Fathi A, Lenoir A. PCR negative herpes simplex encephalitis: A case presentation. Int Pediatr 2001; 16 (2): 1-4.9.- Fica A, Perez C, Reyes P, Gallardo S, Calvo X, Salinas A M. Encefalitis herpetica. Serie clinica de 15 casos conï¬ rmados por reaccion de polimerasa en cadena. Rev Chilena Infectol 2005; 22: 38-46.10.- Conca N, Labrana Y, Bercovich M, Cienfuegos G, Santolaya M E. Encefalitis herpetica neonatal: dos gemelas, dos casos. Rev Chilena Infectol 2011; 28: 257-26.11.- Ruiz-Esquide F, Pena M, Pinuer E, Henriquez M, Hernandez A, Larranaga C. Encefalitis herpetica neonatal. Caso clinico y revision del tema. Rev Chil Pediatr 2002; 73: 152-8.12.- Caviness A C, Demmler G J, Selwyn B J. Clinical and laboratory features of neonatal herpes simplex virus infection: a case-control study. Pediatr Infect Dis J 2008; 27: 425-30.13.- Studhal M, Bergstrom T, Hagsberg L. Acute viral encephalitis in adults- a prospective study. Scand J Infect Dis 1998; 30: 215 -20.14.- Ferres M. Diagnostico Viral. En: Avendano L, Ferres M, Spencer E. Virologia Clinica. 1a ed, 2011. Ed. Mediterraneo, Santiago, Chile. pp 77-89.15.- Kimberlin D W, Whitley R J. Neonatal herpes: What have we learned. Semin Pediatr Infect Dis 2005; 16: 7-16.16.- Diamond C, Mohan K, Hobson A, Frenkel L, Corey L. Viremia in neonatal herpes simplex virus infections. Pediatr Infect Dis J 1999; 18: 487-9.17.- Kimberlin D W. Herpes simplex virus infections in the newborn. Semin Perinatol. 2007; 31:19-25.18.- Willoughby R, Long S. Encephalitis, meningoencephalitis, acute disseminated encephalomyelitis and acute necrotizing encephalopathy. En: Long S, Pickering L, Prober C. ed, Principles and Practice of Pediatric Infectious Diseases, 3th ed, 2008. Churchill Livingstone Elsevier, New York. pp 310 -7.19.- Kimberlin D W, Whitley R J, Wan W, Powell D A, Storch G, Ahmed A, et al. Oral acyclovir supression and neurodevelopment after neonatal herpes. N Eng J Med 2011; 365: 1284-92.20.- Fonseca-Aten M, Messina A F, Jafri H S, Sanchez P J. Herpes simplex virus encephalitis during suppressive therapy with acyclovir in a premature infant. Pediatrics 2005; 115: 804-9.",2012,Revista Chilena De Infectologia
Fast FSR methods for second-order linear regression models,"CREWS, HUGH BATES. Fast FSR Methods for Second-Order Linear Regression Models. (Under the direction of Leonard Stefanski and Dennis Boos.) Many variable selection techniques have been developed that focus on first-order linear regression models. In some applications, such as modeling response surfaces, fitting second-order terms can improve predictive accuracy. However, the number of spurious interactions can be large leading to poor results with many methods. We focus on forward selection, describing algorithms that use the natural hierarchy existing in second-order linear regression models to limit spurious interactions. We then develop stopping rules by extending False Selection Rate methodology to these algorithms. In addition, we describe alternative estimation methods for fitting regression models including the LASSO, CART, and MARS. We also propose a general method for controlling multiple-group false selection rates, which we apply to second-order linear regression models. By estimating a separate entry level for first-order and secondorder terms, we obtain equal contributions to the false selection rate from each group. We compare the methods via Monte Carlo simulation and apply them to optimizing response surface experimental designs. Fast FSR Methods for Second-Order Linear Regression Models",2008,
Building Cost-efficient Models using BLARS Method,"Variable selection is a difficult problem in building statistical models. Identification of cost efficient diagnostic factors is very important to health researchers, but most variable selection methods do not take into account the cost of collecting data for the predictors. The trade-off between statistical significance and cost of collecting data for a statistical model is our focus. In this paper, we extend the LARS variable selection method to incorporate costs of factors in variable selection, which also works with other methods of variable selection, such as Lasso and adaptive Lasso. A branch and bound search method combined with LARS is employed to select cost-efficient factors. We apply the resulting branching LARS method to a dataset from an Assertive Community Treatment project conducted in Southwestern Ontario to demonstrate the cost-efficient variable selection process, and the results show that a ""cheaper"" model could be selected by sacrificing a user selected amount of model accuracy.",2013,Journal of biometrics & biostatistics
The Use of Structural Linguistic Methods for Processing of Vector Geo-Information Data in the SXF Format,"Geo-information systems (GIS) designed for collection, storage, and retrievalof data on three-dimensional objects and for manipulation of these data rep-resent one of the lines for future development of modern information sys-tems [5].When various types of information systems are created, systems ori-ented to solution of problems of processing the complex structural imagesand situations by structural linguistic methods based on formal tools andmethods of the theory of formal grammars have found a wide utility [4].Complexity of data processing in GIS arises due to a great number ofheterogeneous three-dimensional objects that should be used [6].This article gives an example of structural linguistic processing of datain the geo-information format SXF [3]. To minimize the complexity, formalmeta-grammar instruments described in [1, 2] have been used as the algo-rithm base.To develop high-speed irreversible descending algorithms for syntaxanalysis, a number of restrictions have been applied to the type of the usedmeta-grammar structures. The main restriction is their inclusion into the classof formal regular right-hand meta-grammars [2]. Terminals of the developed grammars are divided into two classes:service terminals (VT2), allowing identification of the presented informationstructure, and information terminals (VT1) which describe individual quanti-tative and qualitative characteristics of the object.9",2004,Telecommunications and Radio Engineering
1 The uid/gravity correspondence,"Veronika E Hubeny, Shiraz Minwalla, Mukund Rangamani1.1 IntroductionIn this chapter we will study a particular long wavelength limit of Einsteinâ€™sequations with a negative cosmological constant in d+ 1 dimensions. Insuch a limit we nd that Einsteinâ€™s equations reduce to the equations of uiddynamics (relativistic generalizations of the famous Navier-Stokes equations)in ddimensions. While the motivation for our study lies within the AdS/CFTcorrespondence of string theory, the uid/gravity correspondence stands onits own and can be viewed as a map between two classic dynamical systems.1.1.1 Prelude: CFT stress tensor dynamics from gravityAn important consequence of the AdS/CFT correspondence [Ch.AdSCFT]is that the dynamics of the stress(-energy-momentum) tensor in a large classof d-dimensional strongly coupled quantum eld theories is governed by thedynamics of Einsteinâ€™s equations with negative cosmological constant in d+1dimensions. To begin with, we shall try to provide the reader with someintuition for this statement and argue that searching for a tractable cornerof this connection leads one naturally to the uid/gravity correspondence.In its most familiar example, the AdS/CFT correspondence [Ch.AdSCFT]asserts that SU(N) N= 4 Super Yang-Mills (SYM) theory is dual to TypeIIB string theory on AdS",2011,
Statistical and Network Analysis of Metabolomics Data,"Metabolomics encompasses analysis of metabolites using profiling techniques such as mass spectroscopy (MS) and nuclear magnetic resonance (NMR). Statistical analysis is performed on the profiled data to determine variations in the levels of metabolites. The goal here is to reveal relationships between the variations in the concentrations of metabolites and specific pathophysiological conditions such as diseases or external factors. Metabolomics has been widely used to characterize metabolites in various body fluids such as saliva, serum and urine in various fields of medical research including cancer [3], cardialogy [6], diabetes [5], human infections [12], neurology [7], neonatology [4] and respiratory diseases [2] to name a few.
 In the statistical analysis of metabolomics data, many methods are used which can be categorized as univariate and multivariate analysis methods. Univariate methods are very commonly applied due to their ease of use and interpretation. These methods consider metabolomic features (variables) one at a time independent of each other, thus, ignoring correlations with other features. Moreover, as pointed by Alonso et al. [1], these methods ignore confounding variables such as age, gender, body mass index (BMI), which may lead to incorrect results [13, 15]. On the other hand, multivariate methods consider all the features and their correlations during data analysis. These methods include unsupervised methods such as principal component analysis (PCA), and supervised methods such as partial least squares (PLS) and support vector machine (SVM). Alonso et al. has provided a review of univariate and multivariate methods used in metabolomics. To the best of our knowledge, there are many state of the art statistical methods that have not be used for metabolomic data analysis. A significant advantage of these methods over commonly used methods is their ability to process high-dimensional data. Along with state-of-the-art statistical methods we have used differential network analysis to identify variations at system level.
 In this work we have analyzed urine samples from Qatar Metabolomics Study on Diabetes (QMDiab) for identification of potential biomarkers. QMDiab was conducted by Hamad Medical Corporation, Qatar (HMC) and Weill Cornell Medical College, Qatar in 2012 with approval from the Institutional Review Boards of HMC and Weill Cornell Medical College-Qatar (Research Protocol number 11131/11). Written informed consent was obtained from all participants. Subjects in the study included males and females from Arab and Asian ethnicities aging 17-81 years. Urine samples were sent to Chenomx Inc., Alberta, Canada for proton nuclear magnetic resonance (1H NMR). Although the original study was targeting investigation of type 2 diabetes, in this paper we are focusing on obesity as well by using BMI as a representative measure of obesity.
 In this work we have used regularization models and differential network analysis. We have used the elastic net, glinternet, the lasso projection and high-dimensional inference. The elastic net uses L1 and L2 penalty resulting in a mix of ridge and lasso regression. The glinternet is a group-lasso based method developed by Lim and Hastie [9]. The method learns pairwise interactions of variables in linear regression models satisfying strong hierarchy. The lasso projection (lasso proj) or de-sparsified lasso is a regularization based method that performs statistical inference of low dimensional parameters with high dimensional data [17]. The method uses low dimension projection approach to construct confidence intervals for the estimated regression parameters. The high-dimensional inference computes P-values of variables and associated confidence intervals in high-dimensional data [10].
 Further, we performed differential network analysis to identify variable interactions, which differentiate between diabetic and non-diabetic, or obese and lean subjects. The network is constructed using mutual information between the variables for different groups of samples. We applied the differential network analysis, dGHD algorithm, proposed by Ruan et al. [14] for detecting interaction patterns, which differentiate two networks. The algorithm uses the Generalised Hamming Distance (GHD) for calculating topological differences between the networks along with computation of their statistical significance.
 It is astonishing that the proposed methods, which have not been applied in the field yet, identify potential biomarkers, proposed in the literature by previous studies, in a small dataset. The results for the elastic net, the glinternet and the lasso proj are summarized in Table 1. For diabetes analysis, identified significant variables include age, betaine, glycolate and glucose, well known biomarkers for diabetes [8, 11]. For obesity analysis, identified significant variables include age, dimethylamine, succinate and cis-aconitate, previously identified by [16]. The high-dimensional inference only identified age and betaine for diabetes study.
 We conclude that state-of-the-art statistical and network analysis methods can be used for metabolomics data analysis for datasets with limited number of samples. The number of metabolomic features is increasing with the advancement of technologies. The ability of these methods to handle high-dimensional data make them suitable in the settings where the number of samples is smaller than the number of features. These methods can help in identification potential biomarkers in future studies.",2016,"Proceedings of the 7th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics"
Genomic selection of agronomic traits in hybrid rice using an NCII population,"BackgroundHybrid breeding is an effective tool to improve yield in rice, while parental selection remains the key and difficult issue. Genomic selection (GS) provides opportunities to predict the performance of hybrids before phenotypes are measured. However, the application of GS is influenced by several genetic and statistical factors. Here, we used a rice North Carolina II (NC II) population constructed by crossing 115 rice varieties with five male sterile lines as a model to evaluate effects of statistical methods, heritability, marker density and training population size on prediction for hybrid performance.ResultsFrom the comparison of six GS methods, we found that predictabilities for different methods are significantly different, with genomic best linear unbiased prediction (GBLUP) and least absolute shrinkage and selection operation (LASSO) being the best, support vector machine (SVM) and partial least square (PLS) being the worst. The marker density has lower influence on predicting rice hybrid performance compared with the size of training population. Additionally, we used the 575 (115â€‰Ã—â€‰5) hybrid rice as a training population to predict eight agronomic traits of all hybrids derived from 120 (115â€‰+â€‰5) rice varieties each mating with 3023 rice accessions from the 3000 rice genomes project (3Â K RGP). Of the 362,760 potential hybrids, selection of the top 100 predicted hybrids would lead to 35.5%, 23.25%, 30.21%, 42.87%, 61.80%, 75.83%, 19.24% and 36.12% increase in grain yield per plant, thousand-grain weight, panicle number per plant, plant height, secondary branch number, grain number per panicle, panicle length and primary branch number, respectively.ConclusionsThis study evaluated the factors affecting predictabilities for hybrid prediction and demonstrated the implementation of GS to predict hybrid performance of rice. Our results suggest that GS could enable the rapid selection of superior hybrids, thus increasing the efficiency of rice hybrid breeding.",2018,Rice
Blood Saturation Decreasing Level Based on the Features of a Spirogram Signal,"Obstructive sleep apnea is a common disease associated with respiratory processes during sleep due to the narrowing of the upper respiratory airways, which leads to a decrease in the amount of oxygen in arterial blood flow - SpO2 â€“ to human internal organs. Low blood saturation values can lead to serious consequences in the patient's health, and it can be monitored, for example, using pulsoximetry sensors. In this article a comparative analysis of various regression approaches â€“ Support Vector Regression (SVR), Gradient Boosting, Lasso Regression, Ridge Regression and Sequential Neural Network-was carried out in order to discover an opportunity for predicting SpO2 level decreasing basing on the features of a spirogram for 4 different patients separately. The best results of R2 determination score were shown by models based on SVR and Neural Network: 0.6878 and 0.6697. The best correlation coefficient between the ground truth blood saturation decreasing and the predicted values was 0.9019 for the Support Vector Regressor model.",2019,"2019 Ural Symposium on Biomedical Engineering, Radioelectronics and Information Technology (USBEREIT)"
Selecting Shrinkage Parameters for Effect Estimation: The Multi-Ethnic Study of Atherosclerosis,"We present a method for improving estimation in linear regression models in samples of moderate size, using shrinkage techniques. Our work connects the theory of causal inference, which describes how variable adjustment should be performed with large samples, with shrinkage estimators such as ridge regression and the least absolute shrinkage and selection operator (LASSO), which can perform better in sample sizes seen in epidemiologic practice. Shrinkage methods reduce mean squared error by trading off some amount of bias for a reduction in variance. However, when inference is the goal, there are no standard methods for choosing the penalty ""tuning"" parameters that govern these tradeoffs. We propose selecting the penalty parameters for these shrinkage estimators by minimizing bias and variance in future similar data sets drawn from the posterior predictive distribution. Our method provides both the point estimate of interest and corresponding standard error estimates. Through simulations, we demonstrate that it can achieve better mean squared error than using cross-validation for penalty parameter selection. We apply our method to a cross-sectional analysis of the association between smoking and carotid intima-media thickness in the Multi-Ethnic Study of Atherosclerosis (multiple US locations, 2000-2002) and compare it with similar analyses of these data.",2018,American Journal of Epidemiology
Enhanced lasso recovery on graph,"This work aims at recovering signals that are sparse on graphs. Compressed sensing offers techniques for signal recovery from a few linear measurements and graph Fourier analysis provides a signal representation on graph. In this paper, we leverage these two frameworks to introduce a new Lasso recovery algorithm on graphs. More precisely, we present a non-convex, non-smooth algorithm that outperforms the standard convex Lasso technique. We carry out numerical experiments on three benchmark graph datasets.",2015,2015 23rd European Signal Processing Conference (EUSIPCO)
Mod eling Propensity for Readmissions with Claims Data,"We built a predictive model for hospital readmissions using claims data. The probability of hospital readmission was computed as a logit model. The coefficients for the logit model were trained with a Lasso regression on a set of 237,129 patients and tested on 70,465. The modelâ€™s discriminative power evaluated via ROC was 0.813 and its calibration had p <0.05 assessed using the Hosmer-Lemeshow test.",2011,
Comparison of Outcomes Using the First and Second Generation Cryoballoon to Treat Atrial Fibrillation.,"BACKGROUND
Pulmonary vein isolation using cryoballoon ablation is an effective treatment for patients with atrial fibrillation. We sought to compare outcomes with the first and second generation cryoballoon, with the second generation balloon incorporating the Achieve Lasso catheter, in terms of freedom from symptomatic recurrence and major complications.


METHODS
The first 200 patients who underwent cryoballoon ablation with the first generation balloon were compared with the first 200 patients using the second-generation balloon. All patients had symptomatic atrial fibrillation and had failed at least one antiarrhythmic drug. The primary efficacy endpoint was freedom from symptomatic recurrence of atrial fibrillation (AF) after a single pulmonary vein isolation (PVI) procedure using the cryoballoon. The primary safety endpoint was major procedural complications.


RESULTS
At 12 months, freedom from symptomatic AF after a single procedure in the first generation cohort was 64.3% compared with 78.6% in the second-generation cohort (pâ€‰=â€‰0.002). At 24 months, freedom from symptomatic AF in the first generation cohort was 51.3% compared with 72.6% in the second-generation cohort (pâ€‰<â€‰0.001). Procedural time (150â€‰min vs 101â€‰min; pâ€‰<â€‰0.001) and fluoroscopy time (32.5â€‰min vs 21.4â€‰min; pâ€‰<â€‰0.001) was lower in the second-generation group. The rate of major complications was comparably low in both groups.


CONCLUSIONS
The second-generation cryoballoon was associated with improved freedom from symptomatic AF with reduction in procedure and fluoroscopy time, with a similar low rate of major complications.",2019,"Heart, lung & circulation"
Oracle Efficient Estimation and Forecasting with the Adaptive Lasso and the Adaptive Group Lasso in Vector Autoregressions,"We show that the adaptive Lasso (aLasso) and the adaptive group Lasso (agLasso) are oracle efficient in stationary vector autoregressions where the number of parameters per equation is smaller than the number of observations. In particular, this means that the parameters are estimated consistently at root T rate, that the truly zero parameters are classiffied as such asymptotically and that the non-zero parameters are estimated as efficiently as if only the relevant variables had been included in the model from the outset. The group adaptive Lasso differs from the adaptive Lasso by dividing the covariates into groups whose members are all relevant or all irrelevant. Both estimators have the property that they perform variable selection and estimation in one step. We evaluate the forecasting accuracy of these estimators for a large set of macroeconomic variables. The Lasso is found to be the most precise procedure overall. The adaptive and the adaptive group Lasso are less stable but mostly perform at par with the common factor models.",2012,
Inference of high-dimensional linear models with time-varying coefficients,"We propose a pointwise inference algorithm for high-dimensional linear models with time-varying coefficients. The method is based on a novel combination of the nonparametric kernel smoothing technique and a Lasso bias-corrected ridge regression estimator. First, due to the non-stationarity feature of the model, dynamic bias-variance decomposition of the estimator is obtained. Second, by a bias-correction procedure according to our fundamental representation, the local null distribution of the proposed estimator of the time-varying coefficient vector is characterized to compute the p-values for the iid Gaussian and heavy-tailed errors. In addition, the limiting null distribution is also established for Gaussian process errors and we show that the asymptotic properties have dichotomy features between short-range and long-range dependent errors. Third, the p-values are further adjusted by a Bonferroni-type correction procedure, which is provably to control the familywise error rate (FWER) in the asymptotic sense at each time point. Finally, finite sample size performance of the proposed inference algorithm on a synthetic data and a real application to learn brain connectivity by using the resting-state fMRI data for Parkinson's disease are illustrated.",2015,arXiv: Methodology
Asset Allocation Under Predictability and Parameter Uncertainty Using LASSO,"We consider a short-term investor who exploits return predictability in stocks and bonds to maximize mean-variance utility. Since the true parameters are unknown, we resort to portfolio optimization in form of linear regression with LASSO in order to mitigate problems related to estimation errors as done by Li (2015). As standard cross-validation relies on the assumption of i.i.d. returns, we propose a new type of cross-validation that selects Î» from simulated returns sampled from a multivariate normal distribution. We find an inverse U-shaped relationship between selected Î» and expected utility, and we show that the optimal value of Î» declines as the number of observations used to estimate the parameters increases. We finally show how our strategy outperforms some commonly employed benchmarks.",2019,
P-161A phase I-trial assessing several schedules of Oral S-1 combined with fixed doses of Oxaliplatin and Irinotecan in patients with advanced or metastatic digestive adenocarcinoma as first- or second-line treatment,"HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. Lâ€™archive ouverte pluridisciplinaire HAL, est destinÃ©e au dÃ©pÃ´t et Ã  la diffusion de documents scientifiques de niveau recherche, publiÃ©s ou non, Ã©manant des Ã©tablissements dâ€™enseignement et de recherche franÃ§ais ou Ã©trangers, des laboratoires publics ou privÃ©s. A phase I-trial assessing several schedules of Oral S-1 combined with fixed doses of Oxaliplatin and Irinotecan in patients with advanced or metastatic digestive adenocarcinoma as firstor second-line treatment E. Samalin, S. Thezenas, J.-P Delord, A. Italiano, D. Smith, F. Portales, T. Mazard, E. Assenat, S. Poujol, I. Solassol, et al.",2015,Annals of Oncology
Markers of neuroinflammation associated with Alzheimerâ€™s disease pathology in older adults,"BACKGROUND
In vitro and animal studies have linked neuroinflammation to Alzheimer's disease (AD) pathology. Studies on markers of inflammation in subjects with mild cognitive impairment or AD dementia provided inconsistent results. We hypothesized that distinct blood and cerebrospinal fluid (CSF) inflammatory markers are associated with biomarkers of amyloid and tau pathology in older adults without cognitive impairment or with beginning cognitive decline.


OBJECTIVE
To identify blood-based and CSF neuroinflammation marker signatures associated with AD pathology (i.e. an AD CSF biomarker profile) and to investigate associations of inflammation markers with CSF biomarkers of amyloid, tau pathology, and neuronal injury.


DESIGN/METHODS
Cross-sectional analysis was performed on data from 120 older community-dwelling adults with normal cognition (n=48) or with cognitive impairment (n=72). CSF AÎ²1-42, tau and p-tau181, and a panel of 37 neuroinflammatory markers in both CSF and serum were quantified. Least absolute shrinkage and selection operator (LASSO) regression was applied to determine a reference model that best predicts an AD CSF biomarker profile defined a priori as p-tau181/AÎ²1-42 ratio >0.0779. It was then compared to a second model that included the inflammatory markers from either serum or CSF. In addition, the correlations between inflammatory markers and CSF AÎ²1-42, tau and p-tau181 levels were assessed.


RESULTS
Forty-two subjects met criteria for having an AD CSF biomarker profile. The best predictive models included 8 serum or 3 CSF neuroinflammatory markers related to cytokine mediated inflammation, vascular injury, and angiogenesis. Both models improved the accuracy to predict an AD biomarker profile when compared to the reference model. In analyses separately performed in the subgroup of participants with cognitive impairment, adding the serum or the CSF neuroinflammation markers also improved the accuracy of the diagnosis of AD pathology. None of the inflammatory markers correlated with the CSF AÎ²1-42 levels. Six CSF markers (IL-15, MCP-1, VEGFR-1, sICAM1, sVCAM-1, and VEGF-D) correlated with the CSF tau and p-tau181 levels, and these associations remained significant after controlling for age, sex, cognitive impairment, and APOEÎµ4 status.


CONCLUSIONS
The identified serum and CSF neuroinflammation biomarker signatures improve the accuracy of classification for AD pathology in older adults. Our results suggest that inflammation, vascular injury, and angiogenesis as reflected by CSF markers are closely related to cerebral tau pathology.",2017,"Brain, Behavior, and Immunity"
About Split Proximal Algorithms for the Q-Lasso,"Numerous problems in signal processing and imaging, statistical learning and data mining, or computervision Â can be formulated as optimization problems which consist in minimizing a sum of convex functions,not necessarily differentiable, possibly composed with linear operators. Each function is typically either a data fidelity term or a regularization termenforcing some properties on the solution, see for example [5, 6] and references therein. In this note we are interested in Â the general form of Â Q-Lasso Â introduced in [1] which generalized the well-known Lasso of Tibshirani [9].Â $Q$ is a closed convex subset of a Euclidean $m$-space, for some integer $m\geq1$, that can be interpreted as the set of errors Â within given tolerance level when linear measurements are taken to cover a signal/image via the Lasso.Â Â Only the unconstrained case was discussed in [1], we Â discuss Â here some split proximal algorithms Â for Â solving Â the general case. It is worth mentioning that the lasso modelÂ Â a number of applied problems arising from machine learning and signal/image processing due to the fact it Â promotes the sparsity of a signal.",2016,Thai Journal of Mathematics
Metabolic Biosynthesis Pathways Identified from Fecal Microbiome Associated with Prostate Cancer.,"BACKGROUND
The fecal microbiome is associated with prostate cancer risk factors (obesity, inflammation) and can metabolize and produce various products that may influence cancer but have yet to be defined in prostate cancer.


OBJECTIVE
To investigate gut bacterial diversity, identify specific metabolic pathways associated with disease, and develop a microbiome risk profile for prostate cancer.


DESIGN, SETTING, AND PARTICIPANTS
After prospective collection of 133 rectal swab samples 2 wk before the transrectal prostate biopsy, we perform 16S rRNA amplicon sequencing on 105 samples (64 with cancer, 41 without cancer). Phylogenetic Investigation of Communities by Reconstruction of Unobserved States (PICRUSt) was applied to infer functional categories associated with taxonomic composition. The p values were adjusted using the false discovery rate. The Î±- and Î²-diversity analyses were performed using QIIME. The Mann-Whitney U test was employed to evaluate the statistical significance of Î²-diversity distances within and between groups of interest, and least absolute shrinkage and selection operator (LASSO) regression analysis was used to determine pathway significance.


OUTCOME MEASUREMENTS AND STATISTICAL ANALYSIS
The detection of prostate cancer on transrectal prostate needle biopsy and 16s microbiome profile.


RESULTS AND LIMITATIONS
We identified significant associations between total community composition and cancer/non-cancer status (Bray-Curtis distance metric, p<0.01). We identified significant differences in enrichments of Bacteroides and Streptococcus species in cancer (all p<0.04). Folate (LDA 3.8) and arginine (LDA 4.1) were the most significantly altered pathways. We formed a novel microbiome-derived risk factor for prostate cancer based on 10 aberrant metabolic pathways (area under curve=0.64, p=0.02).


CONCLUSIONS
Microbiome analyses on men undergoing prostate biopsy noted mostly similar bacterial species diversity among men diagnosed with and without prostate cancer. The microbiome may have subtle influences on prostate cancer but are likely patient-specific and would require paired analysis and precise manipulation, such as improvement of natural bacterial folate production.


PATIENT SUMMARY
Microbiome evaluation may provide patients with personalized data regarding the presence or absence of particular bacteria that have metabolic functions and implications regarding prostate cancer risk. The study provides a basis to investigate the manipulation of aberrant microbiomes to reduce prostate cancer risk.",2018,European urology
"Preliminary Isolation and Characterization of Halotolerant and Halophilic Bacteria from Salt Mines of Karak, Pakistan","Halophiles are extremophile organisms that thrive in environments with very high concentrations of salt. The salt mines of Karak region, is an extremely saline environment and its microbial communities have not yet been explored. In the present study, twenty one halotolerant and halophilic bacterial strains were isolated from salt mines of Karak region. These strains can grow in media with 5-40% NaCl concentrations. Morphological, physiological and biochemical characteristics of these strains were studied by optimizing their growth conditions such as pH, NaCl and temperature. A high microbial density was observed at low NaCl concentration. Halophilic bacterial strains were divided into three groups on the basis of NaCl concentration; first was slightly halotolerant / halophilic; second, moderately halophilic and third, extreme halophilic bacteria. The phylogenetic analyses inferred from 16S rRNA gene sequence of these strains demonstrated that these are closely related to species belonging to different genera: Thalassobacillus, Halomonas, Brevibacterium, Oceanobacillus, Terribacillus, Pseudomonas, Bacillus, Enterobacter, Halobacillus, Staphylococcus and Virgibacillus. This preliminary study showed that the salt mine of Karak are rich in halotolerant / halophilic bacterial population with diverse bacterial communities, which may be utilized in various industrial applications.",2012,
Bayesian adaptive lasso with variational Bayes for variable selection in high-dimensional generalized linear mixed models,"ABSTRACT This article describes a full Bayesian treatment for simultaneous fixed-effect selection and parameter estimation in high-dimensional generalized linear mixed models. The approach consists of using a Bayesian adaptive Lasso penalty for signal-level adaptive shrinkage and a fast Variational Bayes scheme for estimating the posterior mode of the coefficients. The proposed approach offers several advantages over the existing methods, for example, the adaptive shrinkage parameters are automatically incorporated, no Laplace approximation step is required to integrate out the random effects. The performance of our approach is illustrated on several simulated and real data examples. The algorithm is implemented in the R package glmmvb and is made available online.",2019,Communications in Statistics - Simulation and Computation
The complete genome sequence of Thalassospira indica PB8BT insights into adaptation to the marine environment,"Abstract Thalassospira indica PB8BT was isolated from the deep water of the Indian Ocean. Here we report the complete genome sequence of type strain PB8BT, which comprises 4,701,725â€¯bp with a Gâ€¯+â€¯C content of 54.9â€¯mol%. We found that numerous genes related to iron acquisition, resistance, motility and chemotaxis, nitrogen, phosphorus and sulfur metabolism, and stress response. These metabolic features and related genes revealed genetic basis for the adaptation to the marine environment. The genome of T. indica PB8BT will be helpful for further insights into its adaptive evolution and ecological role in marine environment.",2019,Marine Genomics
PseudoLasso: leveraging read alignment in homologous regions to correct pseudogene expression estimates via RNASeq,"Pseudogenes have long been considered to be nonfunctional segments in the genome, but recent studies have provided evidence to support their novel regulatory roles in biological processes. With the growing interests in pseudogene research, scientists rely on RNA sequencing technology to estimate expression level of pseudogenes at different tissues or cell lines. The major challenge of RNASeq on pseudogene quantification falls in the high sequence similarity between pseudogenes and their homologous parents. Reads can be ambiguously aligned to multiple homologous regions. In this article, we present PseudoLasso, a genome-wide approach to accurately estimate the abundance of pseudogenes and their parents, and correctly align reads to their origins. Our approach focuses on learning read alignment behaviors, and leveraging this knowledge for abundance estimation and alignment correction. Compared to the read count estimates reported by TopHat2, PseudoLasso is able to provide estimates with a reduced error rate of 10-fold.",2014,
"Bioinformatic Profiling Identifies a Fatty Acid Metabolism-Related Gene Risk Signature for Malignancy, Prognosis, and Immune Phenotype of Glioma","Cancer cells commonly have metabolic abnormalities. Aside from altered glucose and amino acid metabolism, cancers cells often share the attribute of fatty acid metabolic alterations. However, fatty acid metabolism related-gene set has not been systematically investigated in gliomas. Here, we provide a bioinformatic profiling of the fatty acid catabolic metabolism-related gene risk signature for the malignancy, prognosis and immune phenotype of glioma. In this study, a cohort of 325 patients with whole genome RNA-seq expression data from the Chinese Glioma Genome Atlas (CGGA) dataset was used as training set, while another cohort of 667 patients from The Cancer Genome Atlas (TCGA) dataset was used as validating set. After confirmed that fatty acid catabolic metabolism-related gene set could distinguish clinicopathological features of gliomas, we used LASSO regression analysis to develop a fatty-acid metabolism-related gene risk signature for glioma. This 8-gene risk signature was found to be a good predictor of clinical and molecular features involved in the malignancy of gliomas. We also identified that this 8-gene risk signature had high prognostic values in patients with gliomas. Correlation analysis showed that our risk signature was closely associated with the immune cells involved in the microenvironment of glioma. Furthermore, the fatty acid catabolic metabolism-related gene risk signature was also found to be significantly correlated with immune checkpoint members B7-H3 and Tim-3. In summary, we have identified a fatty acid metabolism-related gene risk signature for malignancy, prognosis, and immune phenotype of glioma; and our study might contribute to better understanding of metabolic pathways and further developing of novel therapeutic approaches for gliomas.",2019,Disease Markers
Palynology of the Midway-Wilcox Boundary in South-Central Arkansas,"ABSTRACT In south-central Arkansas, sediments of the lower Eocene Wilcox group rest on the eroded upper surface of the Midway group of Paleocene age. An investigation of the palynomorphs present in these stratigraphic units disclosed a sharp change in spores, pollen and dinoflagellates across the Midway-Wilcox boundary. The most abundant pollen in the Porters Creek Clay of the Midway group is a Taxodium-like form. Triporate pollen and psilate, monolete spores are also common. Aquilapollenites and Classopollis, genera common in Cretaceous rocks, are also present in the Porters Creek Clay. Dinoflagellates are abundant, but hystrichosphaerids are rare. A varied palynomorph assemblage is present in the Wilcox sediments of the area. Tricolporate pollen, a type rare in the Porters Creek Clay, is the most abundant form. The Wilcox pollen flora has a more modern aspect than that of the Porters Creek Clay. Aquilapollenites and Classopollis have not been found. Dinoflagellates and hystrichosphaerids are rare in the Wilcox sediments. The sharp change in palynomorphs across the Midway-Wilcox boundary in this area apparently reflects both evolutionary changes in Tertiary floras and changes in the nature of the environment.",1962,
The Remarkable Multidimensionality in the Cross-Section of Expected U.S. Stock Returns,"20+ years after Fama & French (1992), we re-measure the dimensionality of the cross-section of expected U.S. monthly stock returns in light of the large number of return predictive signals (RPS) that have been identified by business academics over the past 40 years. Using 100 readily programmed RPS, we find that a remarkable 24 are multidimensionally priced as defined by their mean coefficients having an absolute t-statistic ï‚³ 3.0 in Fama-MacBeth regressions where all RPS are simultaneously projected onto 1-month ahead returns during 1980-2012. We confirm the high degree of dimensionality in returns using factor analysis of RPS, factor analysis of long/short RPS hedge returns, LASSO regression, regressions of portfolio returns on RPS factor returns, and out-ofsample RPS hedge portfolio returns. We put forward a new empirically determined 10-RPS model of expected returns for consideration by researchers and practitioners. We also discuss other implications of our findings, chief of which is the need for research that explains why stock returns are so multidimensional and why the most empirically important RPS are priced the way they are. This version: April 2, 2014 * Corresponding author. Our paper has greatly benefitted from the comments of Jeff Abarbanell, Sanjeev Bhojraj, Matt Bloomfield, John Cochrane, Oleg Grudin, Bruce Jacobs, Bryan Kelly, Juhani Linnainmaa, Ed Maydew, Scott Richardson, Jacob Sagi, Eric Yeung, and workshop participants at the University of Chicago, Cornell University, UNC Chapel Hill, the Fall 2013 Conference of the Society of Quantitative Analysts, and the Fall 2013 Chicago Quantitative Alliance Conference. The SAS programs we use to create our RPS data and execute most of our statistical analyses will be made publicly available on 7/1/14.",2013,
Oracle Inequalities for Convex Loss Functions with Nonlinear Targets,"This article considers penalized empirical loss minimization of convex loss functions with unknown target functions. Using the elastic net penalty, of which the Least Absolute Shrinkage and Selection Operator (Lasso) is a special case, we establish a finite sample oracle inequality which bounds the loss of our estimator from above with high probability. If the unknown target is linear, this inequality also provides an upper bound of the estimation error of the estimated parameter vector. Next, we use the non-asymptotic results to show that the excess loss of our estimator is asymptotically of the same order as that of the oracle. If the target is linear, we give sufficient conditions for consistency of the estimated parameter vector. We briefly discuss how a thresholded version of our estimator can be used to perform consistent variable selection. We give two examples of loss functions covered by our framework.",2013,Econometric Reviews
Seaweeds and their Applications,"Seaweed is a sustainable natural resource with industrial potential that is not fully utilized. The industry is broadly based, with the product being supplied to agriculture/horticulture, cosmetics, thalassotherapy, the biopharma sector (functional foods/nutraceuticals), and for human consumption. Nevertheless, in the light of the present and prospective world food situation, the more widespread use of seaweed meals merits further attention. The substitution and release for other uses of cereals by seaweed meal in the basic feed rations may in certain instances by justifiable both economically and socially. Also the seaweed community, well aware of the wonders of marine organisms as a whole, needs to follow suit to address the questions regarding marine algae and their pharmaceutical application, and to quantify the value that this information could add to the current industry, putting seaweeds on par with terrestrial plants in future drug development initiatives.",2017,
"Ancient Plant Use and the Importance of Geophytes among the Island Chumash of Santa Cruz Island, California","Author(s): Gill, Kristina Marie | Advisor(s): Glassow, Michael A | Abstract: Ancient plant use among the Island Chumash is much less well understood than other aspects of islander lifeways. There is a long history of research on faunal assemblages from Island Chumash sites, whereas comparatively little paleoethnobotanical research has been done. The resulting disparity in faunal vs. floral data combined with field observations of an island landscape ravaged by historical overgrazing, led various researchers to suggest that island plant foods were too marginal to support island populations and that mainland plant foods, subsequently, may have been a major motivating factor behind cross-channel exchange networks and increased sociopolitical complexity seen later in time. Within the context of optimal foraging theory and diet breadth models, I explore the significance of plant foods to the Island Chumash of Santa Cruz Island, using archaeological and paleoethnobotanical data from three sites with bedrock mortars, located in upland and interior areas. These non-coastal sites occur in some of the most productive terrestrial areas on the island, representing a range of time periods and site types: a logistical encampment (Sunburst â€“ AD 1260-1500); an interior residence (Brodiaea Ridge, 4330 BC-AD 1630); and, a village (Diablo Valdez, 3920 BC-AD 1800). Deep, well-stratified deposits and excellent preservation of domestic features (i.e., roasting pits, hearth clearing pits, structural floor) at Diablo Valdez provide a high-resolution record of archaeological and paleoethnobotanical remains, where I was unable to identify any significant change in plant food subsistence for nearly 6,000 years. Brodiaea corms were the most ubiquitous taxon identified at this site, sometimes occurring in great abundance and associated with large roasting pit features. Here, I argue that carbohydrate content, rather than caloric value, may be a more appropriate currency for ranking plant foods in island contexts, where abundant marine resources provided ample fats and protein. In this scheme, the ranking of plant foods on the northern Channel Islands, in terms of optimal foraging and island archaeobotanical data (ranked high to low) are: 1) geophytes; 2) kelps and seaweeds; 3) small seeds; 4) fruits, berries, and non-toxic pits; 5) leaves, stems, and stalks; 6) toxic nuts and pits; 7) non-toxic nuts; and, 8) aquatic roots/rhizomes. While there is a preservation bias between these various plant food categories, this general ranking scheme appears to be supported in the island archaeobotanical record. As Channel Island vegetation communities recover form more than a century of overgrazing, it has become clear that the phenomenally abundant geophyte resources that occur on the islands are significantly larger and denser than their mainland counterparts in the absence of gophers, moles, ground squirrels, deer, and other terrestrial herbivores. The brodiaeas are particularly well represented in archaeobotanical assemblages for the islands, used for at least 10,000 years and harvested in multiple seasons. The diversity and unparalleled abundance of island geophyte resources would have provided easily procurable and substantial carbohydrates for the Island Chumash and their ancestors. Combined with the diverse and abundant edible marine plants and algae surrounding the islands, geophytes and other island plants provided the Island Chumash with ample food, medicine, and raw materials that were more abundant and stable than previously assumed.",2015,
"Problems Facing Anopheline Vector Control Vector Ecology and Behavior Before , During , and After Application of Control Measures","The responses of anopheline vector populations to malaria-control operations were studied. Most of the emphasis was placed on their response to DDT, dieldrin, and lindane residual house spraying and on their implication for malaria control and eradication programs. The investigation deals mainly with Aitopheles labradkiae Falleroni, .) A. sergeittii (Theobald) , A. steplzeizsi Liston, A. fuizestiu Giles, A. ganzbiae Giles, s.le, A. pseudopuizctipenit~s Theobald, A. albiwianus Wiedemann, A. darliiagi Root, A. ?zwzeztovari Gabaldon, A. aquasalis Curry, A. cidicifacies Giles, A. m. wziiaimus Theobald, A. $it. flavirostris (Ludlow), A. maculatus Theobald, A. swidaicim (Rodenwaldt) , A. b. balabaceizsis Baisas, A. leucosphyrus DÃ¶nitz, and the A. puitctulatzcs DÃ¶nitz group. The intrinsic vector ecology and behavior are of importance in explaining the response of any vector population to control measures, but the most important clues to this response are the relationships between ecology, behavior, and the environment. Exophilic and exophagic tendencies have no protective value in an insecticidehouse-sprayed area if there are no available outside shelters or convenient alternative hosts spending the night outside treated premises. In some instances majer differences in response to insecticide treatment within a vector species in various areas of its distribution cannot be explained by changes in the environment. This may be attributed to less genetic plasticity of the species in some areas, restricting its adaptability. I t is stated that even where extensive prespraying data on vector ecology and behavior were available, the predictions about the vector population response to treatment have often been misleading, indicating that the investigations may have been incomplete or biased by sampling difficulties. At times vector control has been surprisingly easy and has led to malaria eradication without difficulty. On the other hand, there have been many continuous control operations which have been unsuccessful in tropical areas. Quite often, a weakness in control operations or a change in the environment allows the vector to resume malaria transmission at the same or higher levels. Since the end of World War II, malaria control and eradication programs have relied mostly on the destruction of adult vectors by indoor deposits of residual insecticides, sometimes supplemented by breeding place oiling, space fogging, or mass distribution of drugs. Only in rare instances has malaria eradication been attempted without any residual spraying operation. Apart from administrative and logistic difficulties, obstacles~ to malaria control and eradication have arisen mostly either from unexpected vector ecology and behavior or from insecticide and/or drug resistance. On the reverse, the fair success of some insecticide spraying operations was unexpected, preliminary investigations having concluded that the local vector could not be controlled easily by residual insecticides (Panipana 1951 ; Anonymous/WHO 1967, 1968). As the problem of insecticide resistance is discussed in another document presented before. this conference (Schoof 1970), and that of drug resistance is outside the scope of this meeting, we shall emmine the situation of malaria control and eradication in some selected areas of the main biogeographical regions and then discuss the situation for each facet of vector ecology and behavior. ; 0.R.S.T.O.M Team B.P. 171 Dobo Dioulasso Upper Volta. 0.R.S.T.O.M: Central Laborathries, Bondy, France. 3 O.R.S.T.O.M. Center, Tananarive, Madagascar. We are afraid our report will be biased in favor of the Ethiopian region, because we have more detailed information on this part of the world than the Americas and Asia. Furthermore, a large number of very valuable contributions written by W H O Staff are either available only as WHO/Mal and WHO/Vector Control mimeographed documents which usually cannot be quoted, or which remain in the files of W H O Regional Offices and Headquarters, thus preventing the presentation of an up-to-date picture of the situation in many areas. MALARIA CONTROL AND ERADICATION PROBLEMS I N",2001,
Combining Graph and Machine Learning Methods to Analyze Differences in Functional Connectivity Across Sex,"In this work we combine machine learning methods and graph theoretical analysis to investigate gender associated differences in resting state brain network connectivity. The set of all correlations computed from the fMRI resting state data is used as input features for classification. Two ensemble learning methods are used to perform the detection of the set of discriminative edges between groups (males vs. females) of brain networks: 1) Random Forest and 2) an ensemble method based on least angle shrinkage and selection operator (lasso) regressors. Permutation testing is used not only to assess significance of classification accuracy but also to evaluate significance of feature selection. Finally, these methods are applied to data downloaded from the Connectome Project website. Our results suggest that gender differences in brain function may be related to sexually dimorphic regional connectivity between specific critical nodes via gender-discriminative edges.",2012,The Open Neuroimaging Journal
Variable Selection and Model Building via Likelihood Basis Pursuit,"This article presents a nonparametric penalized likelihood approach for variable selection and model building, called likelihood basis pursuit (LBP). In the setting of a tensor product reproducing kernel Hilbert space, we decompose the log-likelihood into the sum of different functional components such as main effects and interactions, with each component represented by appropriate basis functions. Basis functions are chosen to be compatible with variable selection and model building in the context of a smoothing spline ANOVA model. Basis pursuit is applied to obtain the optimal decomposition in terms of having the smallest l1 norm on the coefficients. We use the functional L1 norm to measure the importance of each component and determine the â€œthresholdâ€ value by a sequential Monte Carlo bootstrap test algorithm. As a generalized LASSO-type method, LBP produces shrinkage estimates for the coefficients, which greatly facilitates the variable selection process and provides highly interpretable multivariate ...",2004,Journal of the American Statistical Association
"The ""leicester lasso"" lateral canthoplasty.","PURPOSE
To describe an innovative technique of lateral canthal tendon (LCT) anchoring to the lateral orbital rim on its inner aspect using a ""lasso"" technique, in order to provide the ideal vector.


METHODS
A retrospective case review of seven patients (n = 7), performed from 2009 to 2013 at our institution by the senior author (RGS).


RESULTS
Excellent results in all cases with optimal restoration of form and function.


CONCLUSIONS
The 'Leicester Lasso' technique is a safer technique of securing the LCT to the orbital rim.",2014,Ophthalmic plastic and reconstructive surgery
On penalized estimation for dynamical systems with small noise,We consider a dynamical system with small noise for which the drift is parametrized by a finite dimensional parameter. For this model we consider minimum distance estimation from continuous time observations under $l^p$-penalty imposed on the parameters in the spirit of the Lasso approach with the aim of simultaneous estimation and model selection. We study the consistency and the asymptotic distribution of these Lasso-type estimators for different values of $p$. For $p=1$ we also consider the adaptive version of the Lasso estimator and establish its oracle properties.,2009,arXiv: Statistics Theory
A facile route for rubber breakdown via cross metathesis reactions,"A new approach towards reprocessing cross-linked rubbery materials by catalytic disassembly of polymer chains, which eliminates the need for energy intensive mechanical processes, is demonstrated. First and second generation (G1 and G2) Grubbsâ€™ ruthenium catalysts break down polybutadiene (PBd) networks at their double bonds via cross-metathesis (CM) reactions to produce readily soluble molecules. A dramatic reduction in molecular weight to around 2000 g molâˆ’1 was observed by size exclusion chromatography and the breakdown of cross-linked networks was confirmed by rheometry. This process was repeated with a styrene-butadiene rubber sheet, a common component of vehicle tyres, with a G2 catalyst and a diester to accelerate the breakdown. A sufficient amount of G2 catalyst and a diester were found to diffuse into the styrene-butadiene rubber sheet, to catalyse its breakdown into rubber crumb. This reaction can be achieved at room temperature within 2.5 h. Increasing the reaction time and temperature increased the extent of the breakdown and under these conditions some breakdown of rubber occurred with the addition of only the G2 catalyst, without the need for a diester. We speculate that, when present, pendant ethylene groups in the PBd chain structure can participate in CM reactions, enabling break-down of the cross-linked network into individual molecules with lasso-like structures.",2016,Green Chemistry
Lasso screening with a small regularization parameter,Screening for lasso problems is a means of quickly reducing the size of the dictionary needed to solve a given instance without impacting the optimality of the solution obtained. We investigate a sequential screening scheme using a selected sequence of regularization parameter values decreasing to the given target value. Using analytical and empirical means we give insight on how the values of this sequence should be chosen and show that well designed sequential screening yields significant improvement in dictionary reduction and computational efficiency for lightly regularized lasso problems.,2013,"2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
Two-Stage Classification with SIS Using a New Filter Ranking Method in High Throughput Data,"Over the last decade, high dimensional data have been popularly paid attention to in bioinformatics. These data increase the likelihood of detecting the most promising novel information. However, there are limitations of high-performance computing and overfitting issues. To overcome the issues, alternative strategies need to be explored for the detection of true important features. A two-stage approach, filtering and variable selection steps, has been receiving attention. Filtering methods are divided into two categories of individual ranking and feature subset selection methods. Both have issues with the lack of consideration for joint correlation among features and computing time of an NP-hard problem. Therefore, we proposed a new filter ranking method (PF) using the elastic net penalty with sure independence screening (SIS) based on resampling technique to overcome these issues. We demonstrated that SIS-LASSO, SIS-MCP, and SIS-SCAD with the proposed filtering method achieved superior performance of not only accuracy, AUROC, and geometric mean but also true positive detection compared to those with the marginal maximum likelihood ranking method (MMLR) through extensive simulation studies. In addition, we applied it in a real application of colon and lung cancer gene expression data to investigate the classification performance and power of detecting true genes associated with colon and lung cancer.",2019,
Survival Analysis of Microarray Data With Microarray Measurement Subject to Measurement Error,"Microarray technology is essentially a measurement tool for measuring expressions of genes, and this measurement is subject to measurement error. Gene expressions could be employed as predictors for patient survival, and the measurement error involved in the gene expression is often ignored in the analysis of microarray data in the literature. Efforts are needed to establish statistical method for analyzing microarray data without ignoring the error in gene expression. A typical microarray data set has a large number of genes far exceeding the sample size. Proper selection of survival relevant genes contributes to an accurate prediction model. We study the effect of measurement error on survival relevant gene selection under the accelerated failure time (AFT) model setting by regularizing weighted least square estimator with adaptive LASSO penalty. Simulation results and real data analysis show that ignoring measurement error will affect survival relevant gene selection. Simulation-Extrapolation (SIMEX) method is investigated to adjust the impact of measurement error on gene selection. The resulting model after adjustment is more accurate than the model selected by ignoring measurement error. Microarray experiments are often performed over a long period of time, and samples can be prepared and collected under different conditions. Moreover, different protocols or methodology may be applied in the experiment. All these factors contribute to a possibility of heteroscedastic measurement error associated with microarray data set. It is of practical importance to combine microarray data from different labs or platforms. We construct a prediction AFT model using data with heterogeneous covariate measurement error. Two variations of the SIMEX algorithm are investigated to adjust the effect of the mis-measured covariates. Simulation re-",2010,
Structural Graphical Lasso for Learning Mouse Brain Connectivity,"Investigations into brain connectivity aim to recover networks of brain regions connected by anatomical tracts or by functional associations. The inference of brain networks has recently attracted much interest due to the increasing availability of high-resolution brain imaging data. Sparse inverse covariance estimation with lasso and group lasso penalty has been demonstrated to be a powerful approach to discover brain networks. Motivated by the hierarchical structure of the brain networks, we consider the problem of estimating a graphical model with tree-structural regularization in this paper. The regularization encourages the graphical model to exhibit a brain-like structure. Specifically, in this hierarchical structure, hundreds of thousands of voxels serve as the leaf nodes of the tree. A node in the intermediate layer represents a region formed by voxels in the subtree rooted at that node. The whole brain is considered as the root of the tree. We propose to apply the tree-structural regularized graphical model to estimate the mouse brain network. However, the dimensionality of whole-brain data, usually on the order of hundreds of thousands, poses significant computational challenges. Efficient algorithms that are capable of estimating networks from high-dimensional data are highly desired. To address the computational challenge, we develop a screening rule which can quickly identify many zero blocks in the estimated graphical model, thereby dramatically reducing the computational cost of solving the proposed model. It is based on a novel insight on the relationship between screening and the so-called proximal operator that we first establish in this paper. We perform experiments on both synthetic data and real data from the Allen Developing Mouse Brain Atlas; results demonstrate the effectiveness and efficiency of the proposed approach.",2015,
Subjects of Creation. On Materialist Abstraction and the Enactment of Ideas,"How are we to think creation today when such an act is understood as the making of something out of nothing? Insisting that genuine creation happens ex nihilo brings us into direct confrontation with much of contemporary philosophical thought, be it critical or analytic, since the latter predominantly rules out the possibility of making reasonable statements about nothingness, or, indeed, about any kind of radical outside to what exists. This thesis attempts to formulate a speculative, rudimentary model of creation that proceeds from the consequences of affirming the possibility to not only think a radical outside, but to also instantiate â€˜someâ€™ of the latter in the form of genuine novelty. The terms for this model are developed from, and via a close examination of, Alain Badiouâ€™s Being and Event and Logics of Worlds. Ultimately, however, it becomes necessary to take a critical distance to Badiouâ€™s system on the basis of some foundational inconsistencies that arise from his unrelenting Platonism. In its place, this thesis proposes an alternative generic conception of creation, which, although following Badiouâ€™s idea of subjective formalisms, transposes the latter onto a materialist foundation with the help of Quentin Meillassouxâ€™s work in After Finitude and the late work of Michel Foucault. It is then demonstrated how this new model can itself be materially effective, or, more specifically, how its enactment in any particular world can be thought to work. The argument is also made, contra Badiou, that the event â€“ that which establishes the possibility for radical difference â€“ is something we can intentionally induce or work towards. In summary, the aim of this thesis is to reinvigorate the notion of radical novelty and the process of its instantiation through the act of creation. In doing so it proposes a rational basis for the belief that genuinely different worlds are indeed possible â€“ and how such possibilities can be thought, occasioned and enacted.",2015,
Probing sequence-level instructions for gene expression,"Gene regulation is tightly controlled to ensure a wide variety of cell types and functions. These controls take place at different levels and are associated with different genomic regulatory regions. An actual challenge is to understand how the gene regulation machinery works in each cell type and to identify the most important regulators. Several studies attempt to understand the regulatory mechanisms by modeling gene expression using epigenetic marks. Nonetheless, these approaches rely on experimental data which are limited to some samples, costly and time-consuming. Besides, the important component of gene regulation based at the sequence level cannot be captured by these approaches. The main objective of this thesis is to explain mRNA expression based only on DNA sequences features. In a first work, we use Lasso penalized linear regression to predict gene expression using DNA features such as transcription factor binding site (motifs) and nucleotide compositions. We measured the accuracy of our approach on several data from the TCGA database and find similar performance as that of models fitted with experimental data. In addition, we show that nucleotide compositions of different regulatory regions have a major impact on gene expression. Furthermore, we rank the influence of each regulatory regions and show a strong effect of the gene body, especially introns.In a second part, we try to increase the performances of the model. We first consider adding interactions between nucleotide compositions and applying non-linear transformations on predictive variables. This induces a slight increase in model performances.To go one step further, we then learn deep neuronal networks. We consider two types of neural networks: multilayer perceptrons and convolution networks. Hyperparameters of each network are optimized. The performances of both types of networks appear slightly higher than those of a Lasso penalized linear model. In this thesis, we were able to (i) demonstrate the existence of sequence-level instructions for gene expression and (ii) provide different frameworks based on complementary approaches. Additional work is ongoing, in particular with the last direction based on deep learning, with the aim of detecting additional information present in the sequence.",2018,
Palynologic Assemblages within the depositional Sequences from the Middle to late Triassic Series of the Spanish and French Pyrenees,"The identification of seven palynology assemblages (P 1 to P 7 ) within the middle to late Triassic series (Anisian-Rhaetian interval) from the french and Spanish Pyrenees supports the correlations between the six successive Depositional Sequences (DS 237 to DS 211 ) forming this interval and the 3 rd order eustatic cycles of Haq et al. (1987). In this paper are described and illustrated: 1) an Anisian assemblages P 1 lower Muschelkalk, with Verrucosisporites applanatus and Calamospora tener, pointing to the base of the Transgressive Systems Tract of the DS 237 ; 2) a first Ladinian assemblages (middle Muschelkalk) P 2 , with Triadispora (T. Plicata, T. Aurea) and Vitreisporites pallidus, which characterizes the High Stand Systems Tract of the DS 237 , 3) a second Ladinian assemblages P 3 (upper Muschelkalk), with T. Plicata, Alisporites grauvogelli and Pityosporites neomundanus, indicating the base of the Transgressive Systems Tract of the DS 232 ; 4) a Carnian assemblage P 4 (lower Keuper), with Brodispora striata, Ovalipollis pseudoalatus and O. Ovalis which marks the High Stand Systems Tract of the DS 228 ; 5) a Norian assemblage P 5 (upper Keuper), with Circulina meyeriana, C. Granulatus and Praecirculina granifer, known in the High Stand Systems Tract of the DS 224 ; 6) and 7) two Rhaetian assemblages, P 6 and P 7 , belonging to distinct stratigraphic levels (base of the Transgressive Systems Tract and High Stand Systems Tract of the DS 215 ) but containing similar palynomorphs such as Rhaetipollis germanicus, Classopollis torsus, Cerebropollenites pseudomassulae and Granuloperculatipollis rudis. Four of these seven assemblages, (P 2 , P 3 , P 4 and P 5 ), are new for the Pyrenees. Particularly the P 4 and P 5 assemblages suggest new dating a for the Keuper pelitic facies where foraminfera are absent.",1993,
Identification of Transcriptional Regulatory Elements: Novel Machine Learning Approaches,"The identification of transcriptional regulatory elements is of pivotal importance in understanding the molecular mechanisms that govern specific expression patterns. Despite the fast development of next generation sequencing (NGS) technology for profiling genome-wide transcription factors (TFs) binding, DNA methylation and other epigenetic features, the identification of transcription factor binding sites (TFBSs) with active functional relevance remains a challenging task in system biology. Therefore, computational prediction still plays an important role. However, the sequence-based prediction can not represent the dynamics of transcription regulation in cell-specific or condition-specific manner. In addition, the overwhelming potential TFBSs obtained through experimental or computation procedures with an unknown false positive (FP) rate also prohibit the reliable biological findings. The integration of other types of functional genomics data are crucial for the elucidation of regulatory mechanism. 

In this thesis, we explore the potential of machine learning methods in distinguishing the most causal TFBSs from enormous predicted candidates. We first focus on the reconstruction of transcriptional regulatory network(TRN) using TFBSs predicted in the promoter regions of co-expressed genes, under the commonly-accepted assumption that a set of genes showing similar expression profiles are likely to be commonly regulated by a collection of TFs. We propose a penalized multinomial logistic regression model to prioritize the most representative TFBSs for each set of co-expressed genes, among multiple sets simultaneously. Joint effects of the TF interaction are also considered. The results through cross-validation show that the minimum classification error rate can be reached at 0.302 and the prioritized TFBSs are not obtained by chance. On this basis, we further model gene expression time course using the predicted TFBSs from a set of co-expressed genes to reconstruct TRN. The expression of one gene at one time point is modeled as the linear combination of expression of all non-TF coding genes and the expression of all TF coding genes weight by transformed TFBSs binding scores at the previous time point. The evaluation shows high performance in simulation study (AUC=0.85). Our model also successfully identify the TF coding genes causal for cell apoptosis in MCF-7:5C cell line which is sensitive to E2-induced apoptosis.

Lastly, we integrate DNA methylation and gene expression data to identify the TFBSs located in remote regulatory regions. Previous studies have indicated that Low-methylated regions (LMRs) are potential active distal regulatory regions (enhancers) in mammalian genomes. We propose several lasso-penalized logistic regression models to predict the directional change of differentially expressed (DE) genes using predicted TFBSs in pairwise cell-type-specific LMRs (dLMRs). The models are evaluated on pairs from four cell types. The AUCs from 10-fold cross-validation procedure show that the model using TFBSs in dLMRs in intergenic or genebody region has more predictive power (AUC 0.71 and 0.66 respectively), comparing with the one using TFBSs from promoter regions alone (AUC 0.62). When using the TFBSs in dLMRs from both intergenic and genebody regions together, the best prediction was obtained (AUC=0.78). Our models are capable to identify subsets of LMRs in which the binding sites of the insulator protein CTCF, p300 co-activator and other TFs verified before by ChIP-seq are significantly enriched. In summary, our models provide tools that detect distal and proximal TFBSs which may causally regulate gene expression.",2015,
Practical Stability of Singularly Impulsive Dynamical Systems: Bellman-Gronwall Approach,"In this paper we present new model of singularly impulsive dynamical systems. Dynamics of this systemis characterized by the set of differential, difference, and algebraic equations. They represent the class of hybrid systems , where algebraic equations represent constraints that differential and difference equations need to satisfy. For the classof singularly impulsive dynamical systems we state and prove Bellman-Gronwall lemma. Furthermore, using Bellman-Gronwall lemma for the class of singularly impulsive dynamical systems we present stability results.",2012,
Lake Tanganyika endemic gastropods also occur in the Lukuga River,"Abstract Ancient lakes with their endemic species assemblages, like Lake Tanganyika in East Africa, are regarded as hotspots of aquatic biodiversity and as natural laboratories providing insights into evolutionary processes, such as intra-lacustrine speciation. The origin of the gastropod species super flock in Lake Tanganyika has been debated intensively and remains unclear to date. For the fish community, it is generally assumed that it was derived from ancestors occurring in the Congo River Basin. Recently, a central biogeographical role of the Lukuga River system and the connected Lualaba River has been indicated. In an attempt to trace the origin of the enigmatic thalassoid gastropods of Lake Tanganyika, the fauna of the Lukuga-Lualaba systems is currently being studied. A recent expedition allowed collecting mollusc material from the eastern shores of Lake Tanganyika around Kalemie and down the Lukuga River until Niemba. We found gastropods known to be endemic to Lake Tanganyika living in the Lukuga River as far down as 95Â km, in populations with reasonable abundances. Based on mitochondrial DNA sequences, these populations are partially genetically distinct from Lake Tanganyikaâ€™s populations. However, sister taxa to the species flock have not yet been found in the Lukuga River. Our results are discussed in the context of intra-riverine evolutionary dynamics over shorter time periods. They will also help to understand the biogeographical and evolutionary dynamics within a large spatial and temporal framework, covering Lake Tanganyika and the Congo River system.",2020,Journal of Great Lakes Research
Regularized shapelet learning for scalable time series classification,"Abstract Time series shapelets are subsequences that best split time series data into classes. Therefore, shapelet discovery has attracted considerable interest in the time series classification community. However, almost all state-of-the-art shapelet-based time series classification methods have an inevitably high computational cost. To overcome this drawback, we present a regularized shapelet learning framework in which the fused lasso regularizer is used to maintain the time order of the shapelets and different loss functions can be employed to improve the speed and accuracy of the time series classification. The proposed framework converts the traditional brute force shapelet searching process into a regularized machine learning problem. The most prominent advantage of this conversion is that the speed of the shapelet learning process and the discrimination of the learned shapelets are both theoretically guaranteed. As such, both the speed and accuracy of the shapelet-based time series classification are improved in this paper. Comparison experiments on several datasets show that our framework effectively reduces the training time of time series classification while improving the classification accuracy.",2020,Computer Networks
"Peptide-Cation Systems: Conformational Search, Benchmark Evaluation, and Force Field Parameter Adjustment Using Regularized Linear Regression","Metal cations often play an important role in shaping the three-dimensional structure of peptides. As an example, the model system AcPheAla5LysH + is investigated in order to fully understand the forces that stabilize its helical structure. In particular, the question of whether the local fixation of the positive charge at the peptideâ€™s C-terminus is a prerequisite for forming helices is addressed by replacing the protonated lysine residue by alanine and a sodium cation. The combination of gas-phase cold-ion vibrational spectroscopy with molecular simulations based on density-functional theory (DFT) revealed that the charge localization at the C-terminus is imperative for helix formation in the gas phase as this stabilizes the structure through a cation-helix dipole interaction. For sodiated AcPheAla6, globular rather than helical structures were found caused by the strong cation-backbone and cation-Ï€ interactions. Interestingly, the global minimum-energy structure from simulation is not present in the experiment where the system remains kinetically trapped in a solution-state structure. Thereby calculated energies and IR spectra that are sufficiently accurate relied on DFT with computationally costly hybrid functionals, while for the structure search low-computationalcost force field (FF) models are crucial. This inspired a study where the goodness of commonly applied levels of theory, i.e. FFs, semi-empirical methods, density-functional approximations, composite methods, and wavefunction-based methods are being evaluated with respect to benchmark-grade coupled-cluster calculations. Acetylhistidine â€“ either bare or in presence of a zinc cation â€“ thereby serves as a molecular benchmark system. Neither FFs nor semi-empirical methods are reliable enough for a description of these systems within â€œchemical accuracyâ€ of 1kcal/mol. Accurate energetic description within chemical accuracy is achieved for all systems using the meta-GGA SCAN or computationally more demanding hybrid functionals. The double-hybrid functional B3LYP+XYG3 is best resembling the benchmark method DLPNOCCSD(T). Despite poor energetic performances of conventional FFs for peptides in the gas phase, their low computational costs still render them appealing tools for large-scale structure searches. Consequently, a machine learning approach is presented where the torsional parameters and (if desired) van der Waals parameters in the potential-energy function of a particular FF are adjusted by fitting it against DFT energies using regularized regression models like LASSO or Ridge regression. For the peptide AcAla2NMe, this resulted in a significant improvement when comparing to standard OPLS-AA FF parameters. For more challenging peptide-cation systems, e.g. AcAla2NMe+Na, this approach does not give satisfying results, which is caused iii by the formulation of the potential energy of the FF itself: While derived empirical partial charges using Hirshfeld partitioning or the electrostatic potential (ESP) decrease the accuracy, part of the energetic discrepancy can be â€œcompensatedâ€ due to the flexibility of the torsional contributions in terms of the energetic description.",2018,
Customized Training with an Application to Mass Spectrometric Imaging of Cancer Tissue.,"We introduce a simple, interpretable strategy for making predictions on test data when the features of the test data are available at the time of model fitting. Our proposal-customized training-clusters the data to find training points close to each test point and then fits an â„“ 1-regularized model (lasso) separately in each training cluster. This approach combines the local adaptivity of k-nearest neighbors with the interpretability of the lasso. Although we use the lasso for the model fitting, any supervised learning method can be applied to the customized training sets. We apply the method to a mass-spectrometric imaging data set from an ongoing collaboration in gastric cancer detection which demonstrates the power and interpretability of the technique. Our idea is simple but potentially useful in situations where the data have some underlying structure.",2015,The annals of applied statistics
PrissÃ¤ttning av begagnade varor - En fallstudie om centralisering och decentralisering pÃ¥ den svenska bilmarknaden,"Abstract 
 
Title: Pricing of Used Goods â€“ A Case Study of Decentralization and Centralization in the Swedish Car Dealer Business. 
 
Seminar date: June 1, 2012 
 
Course: FEKH95, Degree Project Undergraduate level, Business Administration, 
15 University Credits Points (UCP) or ECTS-cr) 
 
Authors: Henric Klasson, Paulina Lindskoug, Johan Svensson 
 
Advisor: Lars Carlman 
 
Key words: decentralization, centralization, pricing, cars, information asymmetry 
 
Purpose: The purpose of this thesis is to examine how the apprehension of pricing varies between the perspective of the management and the sales force. The thesis will also investigate to what degree a development to a more centralized pricing within the car dealer business affects the salesmanâ€™s relationship with the customers. 
 
Methodology: Qualitative method, cross-case synthesis and pattern matching. 
 
Theoretical perspectives: The theoretical perspectives of the thesis contain theories treating pricing strategies, personal selling, sales management, centralization and decentralization. 
 
Empirical foundation: We have performed a total of eight quality based interviews, with six sales representatives and two sales managers from an average sized and a small company in the Swedish car dealer business. 
 
Conclusions: The conclusions of this thesis is that an increase in competition and the degree of information asymmetry between the manager and the salesman, contributes to an increase in need of controlling prices at a central level. This leads to a change in the relationship between the salesman and the customer.",2012,
Minimax rates of convergence for high-dimensional regression under â„“q-ball sparsity,"Consider the standard linear regression model y = XÃŸâˆ— + w, where y âˆŠ R<sup>n</sup> is an observation vector, X âˆŠ R<sup>nÃ—d</sup> is a measurement matrix, ÃŸâˆ— âˆŠ R<sup>d</sup> is the unknown regression vector, and w ~ N (0, Ïƒ<sup>2</sup>Î™) is additive Gaussian noise. This paper determines sharp minimax rates of convergence for estimation of ÃŸâˆ— in l<inf>2</inf> norm, assuming that Î²âˆ— belongs to a weak l<inf>b</inf>-ball B<inf>q</inf>(Ã±<inf>q</inf>) for some q âˆŠ [0,1]. We show that under suitable regularity conditions on the design matrix X, the minimax error in squared l<inf>2</inf>-norm scales as R<inf>q</inf>(log d Ã· n)<sup>1 âˆ’qÃ·2</sup>. In addition, we provide lower bounds on rates of convergence for general l<inf>p</inf> norm (for all p âˆŠ [l,+âˆž], p â‰  q). Our proofs of the lower bounds are information-theoretic in nature, based on Fano's inequality and results on the metric entropy of the balls B<inf>q</inf>(R<inf>q</inf>). Matching upper bounds are derived by direct analysis of the solution to an optimization algorithm over B<inf>q</inf>(R<inf>q</inf>). We prove that the conditions on X required by optimal algorithms are satisfied with high probability by broad classes of non-i.i.d. Gaussian random matrices, for which RIP or other sparse eigenvalue conditions are violated. For q = 0, t<inf>1</inf>-based methods (Lasso and Dantzig selector) achieve the minimax optimal rates in t<inf>2</inf> error, but require stronger regularity conditions on the design than the non-convex optimization algorithm used to determine the minimax upper bounds.",2009,"2009 47th Annual Allerton Conference on Communication, Control, and Computing (Allerton)"
Research and applications: Dynamic contrast-enhanced MRI-based biomarkers of therapeutic response in triple-negative breast cancer,"OBJECTIVE
To predict the response of breast cancer patients to neoadjuvant chemotherapy (NAC) using features derived from dynamic contrast-enhanced (DCE) MRI.


MATERIALS AND METHODS
60 patients with triple-negative early-stage breast cancer receiving NAC were evaluated. Features assessed included clinical data, patterns of tumor response to treatment determined by DCE-MRI, MRI breast imaging-reporting and data system descriptors, and quantitative lesion kinetic texture derived from the gray-level co-occurrence matrix (GLCM). All features except for patterns of response were derived before chemotherapy; GLCM features were determined before and after chemotherapy. Treatment response was defined by the presence of residual invasive tumor and/or positive lymph nodes after chemotherapy. Statistical modeling was performed using Lasso logistic regression.


RESULTS
Pre-chemotherapy imaging features predicted all measures of response except for residual tumor. Feature sets varied in effectiveness at predicting different definitions of treatment response, but in general, pre-chemotherapy imaging features were able to predict pathological complete response with area under the curve (AUC)=0.68, residual lymph node metastases with AUC=0.84 and residual tumor with lymph node metastases with AUC=0.83. Imaging features assessed after chemotherapy yielded significantly improved model performance over those assessed before chemotherapy for predicting residual tumor, but no other outcomes.


CONCLUSIONS
DCE-MRI features can be used to predict whether triple-negative breast cancer patients will respond to NAC. Models such as the ones presented could help to identify patients not likely to respond to treatment and to direct them towards alternative therapies.",2013,Journal of the American Medical Informatics Association : JAMIA
Robust Object Tracking Via Low-Rank and Reverse Fused-Lasso Regularization,"Object tracking via low-rank and sparse learning easily exists the following problems: 1) requiring to solve a lot of l1 optimization problems, which is time-consuming. 2) usually occurring tracking drift when facing object abrupt motion. Therefore, a low-rank and reverse fused-lasso regularization based object tracking algorithm is proposed. Firstly, convex low rank approximation based on the nuclear norm is used to constraint the correlation of the candidate particles, so as to remove the uncorrelated particles. Secondly, fused lasso regularization is introduced to the object tracking, minimizing the absolute value sum of the sparse coefficient difference, which can restrict the object appearance with little difference between the consecutive frame, but allow the greater variation between individual frames, so as to adapt object abrupt motion. Thirdly, an inverse sparse representation formulation is built for object appearance, using candidate particles to represent the target template inversely, simplifying the computation for online tracking. Experimental results show that the proposed algorithm performs favorably against state-of-the-art methods, especially for object abrupt motion.",2019,2019 Chinese Control And Decision Conference (CCDC)
Regularized estimation for the accelerated failure time model.,"SUMMARY
In the presence of high-dimensional predictors, it is challenging to develop reliable regression models that can be used to accurately predict future outcomes. Further complications arise when the outcome of interest is an event time, which is often not fully observed due to censoring. In this article, we develop robust prediction models for event time outcomes by regularizing the Gehan's estimator for the accelerated failure time (AFT) model (Tsiatis, 1996, Annals of Statistics 18, 305-328) with least absolute shrinkage and selection operator (LASSO) penalty. Unlike existing methods based on the inverse probability weighting and the Buckley and James estimator (Buckley and James, 1979, Biometrika 66, 429-436), the proposed approach does not require additional assumptions about the censoring and always yields a solution that is convergent. Furthermore, the proposed estimator leads to a stable regression model for prediction even if the AFT model fails to hold. To facilitate the adaptive selection of the tuning parameter, we detail an efficient numerical algorithm for obtaining the entire regularization path. The proposed procedures are applied to a breast cancer dataset to derive a reliable regression model for predicting patient survival based on a set of clinical prognostic factors and gene signatures. Finite sample performances of the procedures are evaluated through a simulation study.",2009,Biometrics
Sparse Recovery With Unknown Variance: A LASSO-Type Approach,"We address the issue of estimating the regression vector Î² in the generic s-sparse linear model y = XÎ² + z, with Î² âˆˆ â„<sup>p</sup>, y âˆˆ â„<sup>n</sup>, z ~ )V (0, Ïƒ<sup>2</sup>I), and p > n when the variance Ïƒ2 is unknown. We study two least absolute shrinkage and selection operator (LASSO)-type methods that jointly estimate Î² and the variance. These estimators are minimizers of the l1 penalized least-squares functional, where the relaxation parameter is tuned according to two different strategies. In the first strategy, the relaxation parameter is of the order ÏƒÌ‚âˆšlog p, where ÏƒÌ‚<sup>2</sup> is the empirical variance. In the second strategy, the relaxation parameter is chosen so as to enforce a tradeoff between the fidelity and the penalty terms at optimality. For both estimators, our assumptions are similar to the ones proposed by CandeÌ€s and Plan in Ann. Stat. (2009), for the case where Ïƒ<sup>2</sup> is known. We prove that our estimators ensure exact recovery of the support and sign pattern of Î² with high probability. We present simulation results showing that the first estimator enjoys nearly the same performances in practice as the standard LASSO (known variance case) for a wide range of the signal-to-noise ratio. Our second estimator is shown to outperform both in terms of false detection, when the signal-to-noise ratio is low.",2014,IEEE Transactions on Information Theory
DNA methylation profiling to predict overall survival risk in gastric cancer: development and validation of a nomogram to optimize clinical management,"DNA methylation has been reported to serve an important role in the carcinogenesis and development of gastric cancer. Our aim was to systematically develop an individualized prediction model of the survival risk combing clinical and methylation factors in gastric cancer. A univariate Cox proportional risk regression analysis was used to identify the prognosis-associated methylation sites based on the differentially expressed methylation sites between early and advanced gastric cancer group, then we applied least absolute shrinkage and selection operator (LASSO) Cox regression model to screen candidate methylation sites. Subsequently, multivariate Cox proportional risk regression analysis was conducted to identify predictive signature according to the candidate sites. Relative operating characteristic curve (ROC) analysis manifested that an 11-methylation signature exhibited great predictive efficiency for 1-, 3-, 5-year survival events. Patients in the low-risk group classified according to 11-methylation signature-based risk score yield significantly better survival than that in high-risk group. Moreover, Cox regression analysis combing methylation-based risk score and other clinical factors indicated that 11-methylation signature served as an independent risk factor. The predictive value of risk score was validated in the testing dataset. In addition, a nomogram was constructed and the ROC as well as calibration plots analysis demonstrated the good performance and clinical application of the nomogram. In conclusion, the result suggested the 11-DNA methylation signature may be potentially independent prognostic marker and functioned as a significant tool for guiding the clinical prediction of gastric cancer patientsâ€™ overall survival.",2020,
Etiologic Agent of Marek's Disease,"SUMMARY Studies were conducted to determine the relationship of a cellassociated herpesvirus (MDHV), which was isolated from chickens with Marek's disease (MD), to the etiology of MD. The following obervations were made: 1) MDHV was isolated from 85 of 86 chickens with MD lesions but from only 20 of 58 similarly-exposed chicks lacking lesions and none of 43 control chicks. 2) Of 70 tissue samples assayed by parallel inoculation of chicks and cell cultures, 64 produced similar results by both. 3) MDHV was isolated from each of 6 laboratory MD strains. 4) Fifty-five of 57 MD-inoculated cultures with MDHV plaques produced MD when inoculated into chicks and the overall agreement between plaque response and infectivity in 131 cultures was 87%/o. These and other data presented strongly indicate that MDHV is an etiologic agent of MD.",2016,
Altered relaxation times in MRI indicate bronchopulmonary dysplasia.,"We developed a MRI protocol using transverse (T2) and longitudinal (T1) mapping sequences to characterise lung structural changes in preterm infants with bronchopulmonary dysplasia (BPD). We prospectively enrolled 61 infants to perform 3-Tesla MRI of the lung in quiet sleep. Statistical analysis was performed using logistic Group Lasso regression and logistic regression. Increased lung T2 relaxation time and decreased lung T1 relaxation time indicated BPD yielding an area under the curve (AUC) of 0.80. Results were confirmed in an independent study cohort (AUC 0.75) and mirrored by lung function testing, indicating the high potential for MRI in future BPD diagnostics. TRIAL REGISTRATION: DRKS00004600.",2019,Thorax
Structured sparse CCA for brain imaging genetics via graph OSCAR,"BackgroundRecently, structured sparse canonical correlation analysis (SCCA) has received increased attention in brain imaging genetics studies. It can identify bi-multivariate imaging genetic associations as well as select relevant features with desired structure information. These SCCA methods either use the fused lasso regularizer to induce the smoothness between ordered features, or use the signed pairwise difference which is dependent on the estimated sign of sample correlation. Besides, several other structured SCCA models use the group lasso or graph fused lasso to encourage group structure, but they require the structure/group information provided in advance which sometimes is not available.ResultsWe propose a new structured SCCA model, which employs the graph OSCAR (GOSCAR) regularizer to encourage those highly correlated features to have similar or equal canonical weights. Our GOSCAR based SCCA has two advantages: 1) It does not require to pre-define the sign of the sample correlation, and thus could reduce the estimation bias. 2) It could pull those highly correlated features together no matter whether they are positively or negatively correlated. We evaluate our method using both synthetic data and real data. Using the 191 ROI measurements of amyloid imaging data, and 58 genetic markers within the APOE gene, our method identifies a strong association between APOE SNP rs429358 and the amyloid burden measure in the frontal region. In addition, the estimated canonical weights present a clear pattern which is preferable for further investigation.ConclusionsOur proposed method shows better or comparable performance on the synthetic data in terms of the estimated correlations and canonical loadings. It has successfully identified an important association between an Alzheimerâ€™s disease risk SNP rs429358 and the amyloid burden measure in the frontal region.",2016,BMC Systems Biology
Surgical reconstruction of irreversible ulnar nerve paralysis in leprosy.,"Twenty-five patients with irreversible leprotic ulnar nerve palsy having undergone lumbrical replacement with two different tendon transfer techniques were assessed 6-120 months after surgery. Nineteen patients were reconstructed with the flexor digitorum four-tail procedure (FDS-4T), and six with Zancolli's lasso procedure (ZLP). Mean paralysis times were 103 months for FDS-4T, and 68 months for ZLP. Mean age of the patients was 36 years (21-57). Grip strength measurements, improvement in active range of motion at the PIP joints, patients' ability to open and close their hands fully, as well as sequence of phalangeal flexion, were noted. Mean grip strength measurements during follow-up were 76% of the contralateral extremity in the FDS-4T group and 82% in the ZLP group. Comparison of the follow-up grip strength with the preoperative value revealed 1% improvement in the FDS-4T group and 20% in the ZLP group. Claw hand deformity was completely corrected in 12 patients in FDS-4T group, and in five patients in the ZLP group. Residual flexion contracture remained in five patients after surgery. Swan-neck deformity subsequently developed in seven fingers. Age, sex, mean follow-up and surgical technique did not relate statistically to the functional outcome. However, preoperative extensor lag of the PIP joint and mean paralysis time significantly affected the functional outcome. ZLP was found to be a more effective procedure in restoring grip strength, whereas FDS-4T was more effective in correcting claw hand deformity.",2003,Leprosy review
The fragmentation of global climate governance: consequences and management of regime interactions,"The fragmentation of global climate governance: consequences and management of regime interactions / Harro van Asselt, Stockholm Environment Institute. Edward Elgar, April 2014, 360 p. - 145 $ http://www.e-elgar.co.uk/bookentry_main.lasso?currency=US&id=15327 The first chapter of the book is available for FREE here Presentation (Â© SEI) : How do the different international institutions addressing climate change interact? What are the actual and potential synergies and conflicts? What are the m...",2014,
"Middle Jurassic spore-pollen assemblages from Turpan-Shanshan area, Xinjiang","The Middle Jurassic palynoflora from the two wells of PU1 and CN1 of Turpan-Shanshan area in Xinjiang consists of 97 species of fossil spores and pollen grains referred to 45 genera, of which 2 species are newly described. Three palynological. assemblages including: 1) Cyathidites-Cycadopites-Quadraeculina (CCQ), 2) Cyathidites-Classopollis-Picites (CCP) and 3) Granulatisporites-Classopollis-Podocarpidites (GCP) assemblages are established in the Xishanyao, Sanjianfang and Qiketai Formations, respectively. Comparisons have been made between these assemblages with those of the adjacent regions in Xinjiang and other domestic areas and at abroad. The geological age of the CCQ assemblage is suggested to be at early Middle Jurassic (corresponding to Aalenian to Bajocian age); while the CCP and GCP assemblages are considered to be at late Middle Jurassic (corresponding to early to late Bathonian age, respectively).",1998,Acta Botanica Sinica
Alcohol-Attentional Bias in Alcohol-Dependent and Cocaine-Dependent Patients,"Background: Substance-related attentional bias refers to the reactivity to substance-related cues. This attentional bias to drugs has been examined in different addictive disorders such as cocaine, alcohol or tobacco dependence. There is extensive evidence regarding the attentional bias to alcohol-related cues in Alcohol Dependent (AD) patients. Furthermore, there is evidence regarding the higher attention bias to cocaine-related cues in Cocaine Dependent (CD) subjects after the exposure to alcohol consumption. However, there are still no data on the potential attentional bias to alcohol-related cues in patients diagnosed with CD. Objectives: we aimed to assess attentional bias in a sample of alcohol and cocaine users with a visual probe task. Material and methods: We used a sample of 35 AD patients, 30 CD patients and a control group formed by 35 healthy volunteers. Moreover, and to further study alcohol attentional bias in CD subjects, we divided this group in terms of their history of alcohol consumption. All subjects were examined using the visual probe task, in order to study the attentional bias to alcohol-related cues. Results: The patients that showed the greater attentional bias to alcohol-related cues were the AD subjects, followed by the CD patients and finally by controls. AD and CD exhibited lower reaction times to alcoholcongruent condition compared to the alcohol-incongruent, whereas in controls the opposite effect was found. Discussion: Our results indicated that although attentional bias to alcohol-related cues was clearly found in AD and CD patients, these data are in accordance with the hypothesis about the fact that cocaine dependence increases the attentional bias to other drugs, such as alcohol. Central Morales-MuÃ±oz et al. (2014) Email: J Subst Abuse Alcohol 2(2): 1013 (2014) 2/6 (CS), the CS comes to elicit a Conditioned Response (CR), such as physiological arousal or craving to use the substance. One consequence of classical conditioning is cues orient attention towards a predictive CS when encountered [5-7]. Therefore, when conditioning occurs and a substance of abuse is the US, one would expect that substance-related stimuli would attract the userâ€™s attention [3]. Researchers have found attentional bias for substance-related stimuli (presented verbally, pictorially, or as in vivo exposure) in users of different substances such as cocaine [8], alcohol [9] and tobacco [10]. Alcohol ingestion, for instance, increases this attentional bias to alcohol-associated stimuli [11]. In heavy social drinkers, alcoholassociated stimuli grab attention [1,12] and increase both the urge to drink alcohol and the amount of alcohol intake However, previous studies in individuals with alcohol dependence have shown that, unlike social drinking controls, individuals with alcohol dependence exhibit avoidance for alcohol-related visual stimuli in a dot probe detection task. Avoidance suggests the finding of a negative bias whereby the patients allocate their attention to the control stimuli and away from the alcohol-related stimuli [12]. Nikolaou et al found that attentional bias to alcohol related stimuli was reliably observed at the low, but not at the high alcohol dose when compared with placebo [13]. Thus, despite there are several studies related to attentional bias in alcohol, the underlying cognitive processes remain unknown. Alcohol and cocaine are used in higher quantities with concomitant use than when either of the substances are used individually [14], and it is proven by a wide variety of researches that cocaine and alcohol combination produces additive psychological and physiological effects [15]. Therefore, and given that dopamine activity in the mesolimbic pathway is hypothesised to be responsible for incentive salience attribution and attentional bias [3,16], acute administration of drugs that increase dopaminergic activity should lead to increases in attentional bias for any drug-related cues. In addition, Montgomery et al found increased attentional bias for cocaine cues following preload with alcohol in regular cocaine users, by means of a visual probe task [17]. In cocaine attentional bias, researches using the cocaine emotional Stroop task showed that subjects who use cocaine had slower reaction time compared to controls [8]. Other authors also observed that regions implicated in the general orientation of attention also showed significantly increased activation under low load in presence of the alcoholassociated stimuli compared to the neutral stimuli, and this observation extends to those findings with cocaine-related stimuli [17]. Now then, if cocaine consumption is associated with alcohol consumption in clinical samples and in general population [18], it can be hypothesized that cocaine may increase attentional bias alcohol-related cues in subjects without any alcohol use disorder (e.g., abuse or dependence). The present study sought to assess attentional bias in a sample of alcohol and cocaine users with a visual probe task. We hypothesized that Alcohol Dependent (AD) patients and cocainedependent subjects would show greater attentional bias for alcohol stimuli compared to controls. METHODS",2014,
Expected ground motion in the south-east of Spain due to an earthquake in the epicentral area of the 1910 Adra earthquake,"To study the ground motion levelassociated with historical earthquakeslocated in Southern Spain, we have chosen ascenario placed in the Poniente Almeriense(Southeast Spain). In this zone, somerelevant historical earthquakes haveoccurred, such as those of 1522, 1804 and1910. In particular, the earthquakes of 1804 and 1910 the estimated and calculatedmagnitudes are of M = 6.3. Those earthquakestook place near the epicentral zone of aseismic series happened in 1993â€“94. As partof this series, two earthquakes with Mâˆ¼5were recorded by strong ground motioninstruments on 23rd December 1993, and 4th January, 1994 at Adra, AlmerÃ­aand Motril. We have used the accelerationrecords as empirical Green functions inorder to simulate the expected groundmotion associated with a hypotheticalearthquake of magnitude M = 6.3 like those of1804 and 1910. The simulations have beencarried out for three sites (AlmerÃ­a,Adra and Motril) using three differentapproaches. A total of 30 simulations, foreach approach, have been carried out foreach ground motion component in each site.The peak ground acceleration (PGA) and theresponse spectra are compared with thevalues obtained through empiricalrelationships for the distances and soilconditions corresponding to the threechosen sites. The results of thesimulations show that the horizontal PGAcould exceed the values observed in23/XII/93 and 4/I/94 by a factor of 5â€“8,surpassing in some cases the value of 140gals. Besides, some of the peak spectralaccelerations simulated reach Samax =400 gals, Adra being the location where thehighest values of amax andSamax are reached, due to the nearnessof this station to the epicentres of 23/XII/93 and 4/I/94. At Almeria, the PGAvalues reach 40 gals, which may beconsidered as input in the bedrock. InMotril, the PGA surpass a value of 130gals, considering as due to a strong localsite effect. Finally, the peak groundacceleration (PGA) and the response spectraobtained with the simulations have beencompared with other values estimated through empirical relationships for similarconditions. The conclusions about theexpected ground motion levels have animportant application aimed at the revisionof the maximum acceleration and responsespectra of the Spanish building Code,NCSE-94.",2003,Journal of Seismology
Regularized Transformation Models: The tramnet Package,"The tramnet package implements regularized linear transformation models by combining the flexible class of transformation models from tram with constrained convex optimization implemented in CVXR. Regularized transformation models unify many existing and novel regularized regression models under one theoretical and computational framework. Regularization strategies implemented for transformation models in tramnet include the LASSO, ridge regression and the elastic net and follow the parametrization in glmnet. Several functionalities for optimizing the hyperparameters, including model-based optimization based on the mlrMBO package, are implemented. A multitude of S3 methods are deployed for visualization, handling and simulation purposes. This work aims at illustrating all facets of tramnet in realistic settings and comparing regularized transformation models with existing implementations of similar models.",2020,
Compressive phase-only filtering at extreme compression rates,"Abstract We introduce an efficient method for the reconstruction of the correlation between a compressively measured image and a phase-only filter. The proposed method is based on two properties of phase-only filtering: such filtering is a unitary circulant transform, and the correlation plane it produces is usually sparse. Thanks to these properties, phase-only filters are perfectly compatible with the framework of compressive sensing. Moreover, the lasso-based recovery algorithm is very fast when phase-only filtering is used as the compression matrix. The proposed method can be seen as a generalization of the correlation-based pattern recognition technique, which is hereby applied directly to non-adaptively acquired compressed data. At the time of measurement, any prior knowledge of the target object for which the data will be scanned is not required. We show that images measured at extremely high compression rates may still contain sufficient information for target classification and localization, even if the compression rate is high enough, that visual recognition of the target in the reconstructed image is no longer possible. The method has been applied by us to highly undersampled measurements obtained from a single-pixel camera, with sampling based on randomly chosen Walshâ€“Hadamard patterns.",2017,Optics Communications
Where is the Great Outdoors of Meillassouxâ€™s Speculative Materialism?,"Abstract Quentin Meillassouxâ€™s speculative materialism aims to define access to reality of the natural world apart from its giveness to sentient subjects. This world apart is designated by Meillassoux as the â€œGreat Outdoorsâ€ which was marginalized as a topic of philosophy after Kantâ€™s critiques. The question of the incommensurability of human subjects and physical objects is taken up by Meillassoux and addressed by allowing mathematizable properties of physical objects to be referred to objectively in mathematical statements. In this paper we follow the discussion with speculative materialism conducted by Deborah Danowski and Eduardo Viveiros de Castro in The Ends of the World (2017). These authors show that Meillassouxâ€™s conception of the â€œGreat Outdoorsâ€ includes, yet insufficiently explores, the notion of ancestral humanity in Amerindian myth â€“ and intimately related to the practice of hallucinogenic trance â€“ as the means to address the problem of said incommensurability.",2020,Open Philosophy
Forecasting the aggregate oil price volatility in a data-rich environment,"This paper explores the effectiveness of a large set of indicators in forecasting crude oil price volatility, including uncertainty and market sentiment, macroeconomic indicators, and technical indicators. Using the OLS, LASSO regression, and various combination forecasts, we obtain several noteworthy findings. First, we determine which indicators most effectively forecast oil price volatility. Specifically, the uncertainty index is notable. Second, in general, combination strategies and LASSO produce statistically and economically significant forecasts. Third, the combined and LASSO strategies perform considerably better during recessions than expansions. Overall, our study provides which indicators and strategies can improve forecasting accuracy in the oil market.",2018,Economic Modelling
Pharmacokinetics of thiamphenicol in veal calves.,"Thiamphenicol is a semi-synthetic structural analogue of chloramphenicol . The antibacterial spectrum of thiamphenicol is similar to that of chloramphenicol (Sutter & Finegold, 1976) with comparable minimum inhibitory concentration (MIC) values against bacteria such as Streptococcus faecalis, Pasteurella spp. and Brucella and lower MIC values against bacteria such as Neisseria meningitidis and Streptococcus viridans (Laplassotte & Brunaud, 1961 ; Van Beers et al., 1975) . Studies on thiamphenicol kinetics in a number of species (rat, dog, human and calf) show that it is well absorbed by the intramuscular (i.m.) and oral (p .o .) routes . The drug shows little tendency (5-10%) to bind to plasma proteins (Kawabe el al., 1966) . Data on the distribution in human tissues and body fluids indicate a high penetration of the drug into lung tissue, kidney, bile, etc . (Cambieri el al., 1970; Ferrari, 1984) . It undergoes some slight metabolism in liver and it is mainly excreted in unmetabolized form by the renal route (Nakagawa et al., 1975) . Thiamphenicol is considerably less toxic than chloramphenicol. Sideeffects reported in the literature are gastrointestinal (diarrhoea, nausea, pyrosis, vomiting) and cutaneous eruptions and haematological dyscrasias have also been reported, but the incidence is low and related to dosage and duration of treatment (Najean et al., 1981) . There is little information in the literature on thiamphenicol kinetics in animals intended for meat production . However, in view of the possible therapeutic use of thiamphenicol for the treatment of bovine respiratory complex (BRC), a study of its kinetic profile in the calf after intravenous and intramuscular administration is of interest. BRC is caused by several microorganisms, one of the most frequent pathogens being Pasteurella spp . Five healthy Friesian calves 8 weeks of age of mean weight (Â±sn) 75Â±6 .4 kg were used. Each calf received a single i .v. dose (30 mg/kg) of a 30% solution of thiamphenicol glycinate in physiological saline. Three weeks later, the sane animals received a second dose (30 mg/kg) of 30% solution of thiamphenicol in dimethvlacetarnide and propylene glycol by the i .n . route. Blood samples were collected at pre-established intervals after administration and assayed using a high-perforrn-",1992,The British veterinary journal
Bundle Methods for Regularized Risk Minimization,"A wide variety of machine learning problems can be described as minimizing a regularized risk functional, with different algorithms using different notions of risk and different regularizers. Examples include linear Support Vector Machines (SVMs), Gaussian Processes, Logistic Regression, Conditional Random Fields (CRFs), and Lasso amongst others. This paper describes the theory and implementation of a scalable and modular convex solver which solves all these estimation problems. It can be parallelized on a cluster of workstations, allows for data-locality, and can deal with regularizers such as L1 and L2 penalties. In addition to the unified framework we present tight convergence bounds, which show that our algorithm converges in O(1/e) steps to e precision for general convex problems and in O(log (1/e)) steps for continuously differentiable problems. We demonstrate the performance of our general purpose solver on a variety of publicly available data sets.",2010,J. Mach. Learn. Res.
Cyclic Block Coordinate Algorithms for DOA Estimation in CoPrime Arrays,"In this paper, two cyclic block coordinate minimization (CBCM) algorithms to solve the problem of the direction-of-arrival (DOA) estimation in co-prime arrays are proposed. These algorithms are developed in the context of nonnegative gridless compressive sensing for overcoming the grid mismatch that conventional grid-based sparse methods suffer from. In their processes relying on atom merging and atom activating, it is in subdomains of the continuous space that atom update is performed, which allows to have practically feasible computational complexity. We analyze convergence of our algorithms. Numerical simulations are provided to demonstrate that the proposed methods are superior to the joint sparsity reconstruction method (JLASSO) and the MUSIC method with spatial smoothing (SS-MUSIC) in terms of several criteria, and discuss their convergence properties.",2017,
A Censored Maximum Likelihood Approach to Quantifying Manipulation in Chinaâ€™s Air Pollution Dataâˆ—,"Data manipulation around cut-off points is observed in economics broadly and in environmental and resource economics in particular. This paper develops a simple and tractable censored maximum likelihood approach to quantify the degree of manipulation in Chinaâ€™s air pollution data around the â€œblue-sky dayâ€ cutoff. We construct annual measures of manipulation for 111 Chinese cities. For Beijing, we estimate 4%16.8% of manipulation among reported blue-sky days annually, which translate to an estimated total of 208.1 manipulated blue-sky days between 2001-2010. For the remaining cities reporting pollution data over the ten-year period, we estimate a 93.9 average for the total number of manipulated blue-sky days with a 395.9 maximum. Using LASSO shrinkage, we examine the relationship between manipulation and local official characteristics, and find a positive correlation between manipulation and having an elite-educated party secretary, robust to numerous checks. Further empirical analysis suggests that promotion considerations may help explain this finding.",2020,
Multichannel Reflectivity Inversion with Sparse Group Regularization Based on HPPSG Algorithm,"Summary Sparse -Spike Deconvolution (SSD) is commonly used in seismic deconvolution. However, when dealing with multichannel seismic data through the trace by trace procession, it can't maintain the lateral continuity and stability well. In this paper, we propose a new SSD method based on Hadamard Product Parametrization Sparse-Group algorithm (HPPSG). In order to preserve lateral continuity, we define each layer of the seismic profiles as a group, and then use L_p regularization (1â‰¤p) to constrain each element in this group. Assuming that reflectivity is sparse, we apply L_q (qâ‰¤1) as a regularization to constrain between groups along the time direction. Then, we construct a L_(p,q) optimization problem. After that, we solve this problem using HPPSG algorithm based on the Hadamard Product Parametrization Lasso algorithm (HPPL). Synthetic and real data examples indicate that the proposed method have significant improvements on the lateral continuity.",2019,
Learning Financial Networks using Quantile Granger Causality,"In the post-crisis era, financial regulators and policymakers require data-driven tools to quantify systemic risk and to identify systemically important firms. We propose a statistical method that measures connectivity in the financial sector using time series of firms' stock returns. Our method is based on system-wide lower-tail analysis, whereby we estimate linkages between firms that occur when those firms are distressed and that exist conditional on the financial information of all other firms in the sample. This is achieved using Lasso-penalized quantile vector autoregression. By considering centrality measures of the estimated networks, we can assess the build-up of systemic risk and identify risk propagation channels. We apply our method to monthly returns of large U.S. firms, demonstrating that we are able to detect many of the most recent systemic events, in addition to identifying key players in the 2007-2009 U.S. financial crisis. Importantly, these players are not identified using standard Granger causality, which estimates connectivity by averaging across good, bad, and normal days of the market.",2018,Proceedings of the Fourth International Workshop on Data Science for Macro-Modeling with Financial and Economic Datasets
High Density Linkage Map Construction and Mapping of Yield Trait QTLs in Maize (Zea mays) Using the Genotyping-by-Sequencing (GBS) Technology,"Increasing grain yield is the ultimate goal for maize breeding. High resolution quantitative trait loci (QTL) mapping can help us understand the molecular basis of phenotypic variation of yield and thus facilitate marker assisted breeding. The aim of this study is to use genotyping-by-sequencing (GBS) for large-scale SNP discovery and simultaneous genotyping of all F2 individuals from a cross between two varieties of maize that are in clear contrast in yield and related traits. A set of 199 F2 progeny derived from the cross of varieties SG-5 and SG-7 were generated and genotyped by GBS. A total of 1,046,524,604 reads with an average of 5,258,918 reads per F2 individual were generated. This number of reads represents an approximately 0.36-fold coverage of the maize reference genome Zea_mays.AGPv3.29 for each F2 individual. A total of 68,882 raw SNPs were discovered in the F2 population, which, after stringent filtering, led to a total of 29,927 high quality SNPs. Comparative analysis using these physically mapped marker loci revealed a higher degree of synteny with the reference genome. The SNP genotype data were utilized to construct an intra-specific genetic linkage map of maize consisting of 3,305 bins on 10 linkage groups spanning 2,236.66 cM at an average distance of 0.68 cM between consecutive markers. From this map, we identified 28 QTLs associated with yield traits (100-kernel weight, ear length, ear diameter, cob diameter, kernel row number, corn grains per row, ear weight, and grain weight per plant) using the composite interval mapping (CIM) method and 29 QTLs using the least absolute shrinkage selection operator (LASSO) method. QTLs identified by the CIM method account for 6.4% to 19.7% of the phenotypic variation. Small intervals of three QTLs (qCGR-1, qKW-2, and qGWP-4) contain several genes, including one gene (GRMZM2G139872) encoding the F-box protein, three genes (GRMZM2G180811, GRMZM5G828139, and GRMZM5G873194) encoding the WD40-repeat protein, and one gene (GRMZM2G019183) encoding the UDP-Glycosyltransferase. The work will not only help to understand the mechanisms that control yield traits of maize, but also provide a basis for marker-assisted selection and map-based cloning in further studies.",2017,Frontiers in Plant Science
Early-Late Cretaceous (Aptian-Cenomanian) Palynomorphs,"Samples from 12 wells situated mainly in the northern part of the Cyrenaica Shelf of northeast Libya have yielded palynomorph assemblages of Aptian, Albian or Cenomanian aspect. The Aptian assemblages are dominated by land-plant remains and contain relatively few dinoflagellate cysts. By contrast, the latter are generally common in those from the Albian and Cenomanian samples. Deposition in near-shore marine environments is indicated for most of the Aptian succession whereas more open marine conditions are generally suggested for the younger strata. In places, however, a substantial terrestrial input was maintained during the accumulation of the Albian sediments.

Dinoflagellate cysts typically recorded from Aptian palynological preparations include Aptea anaphrissa, Cyclonephelium sp. 1, Hystrichosphaerina schindewolfii, Muderongia simplex microperforata and Occisucysta spp. Several species of Cribroperidinium , but especially C. edwardsii and C. orthoceras , usually form an important part of the Albian assemblages; Kiokansium hydra is also often present. Skolochorate cysts referable to Coronifera and Florentinia are abundant in both these and the Cenomanian preparations, with Palaeohystrichophora infusorioides and several species of Canningia, Cyclonephelium, Oligosphaeridium, Spiniferites and Subtilisphaera being among the most numerous of the associated forms. In general the assemblages compare closely with those of similar age described by Below (1981, 1982) and Williams (1978) from onshore and offshore Morocco respectively.

Although miospores are common in the Aptian preparations, they show relatively little morphological diversity. Smooth walled triradiate specimens, Classopollis and Inaperturopollenites are often the dominant forms. Angiosperm pollen grains are generally scarce and bisaccates only rarely encountered. A few of the Albian . . .",1985,Journal of Micropalaeontology
WELCOMELassoing research,"2012 in Austin this year know that it was another fantastic gathering of ideas, values, and visions of the current and future state of HCI research. Like a lasso in midair (pardon our notion of a Texas reference), the outer limits of research and practice in the CHI community seem to be getting larger and changing shape as they move along. In part this is due to the diversity of CHI, the wide collection of interests and pursuits at the intersection of people and technologies. One such interest is design research. Among HCI researchers and practitioners, there is the implicit assumption that design relates critically to HCI, yet the degree to which design constitutes research in its own right is far from agreed upon. In this issue's cover story, Bill Gaver and John Bowers take on the relationship of research to design, proposing annotated portfolios as a way to further articulate the wider concerns within the making and reception of a design artifact or collection of artifacts. Annotated portfolios aim to go beyond but respect the tacit understanding of making and respect the existence of the objects or systems themselves. Artifacts and systems are a "" position statement "" on behalf of the designers in understanding what "" is important to consider in a given design situation "" and "" how best to respond. "" Annotated portfolios, Gaver and Bowers argue, emerge from the practice of designing in which designers converse and critique their concerns in and around the things they make. The authors aim to rescue design from the impositions of (and mismatch with) scientific research, which design could certainly be put in the service of, but at the expense of design itself. In our previous issue's welcome letter, we highlighted the work of our forum editors and their forums. A number of other sections rely equally on your submissions and input. These include: â€¢ Demo Hour: A collection of novel and new built systems and prototypes, edited by Leah Maestri â€¢ Visual Thinking Backpage Gallery: Curated digital images that explore the relationship between imagery and HCI, edited by Eli Blevis â€¢ Blogpost: Short and to-the-point opinion pieces on anything related to HCI and interaction design â€¢ Day in the Lab: A "" cook's tour "" of the HCI and design labs and studios within our community. We invite your submissions to any of these sections. And, as always, â€¦",2012,Interactions
The Group Lasso for Stable Recovery of Block-Sparse Signal Representations,"Group Lasso is a mixed l1/l2-regularization method for a block-wise sparse model that has attracted a lot of interests in statistics, machine learning, and data mining. This paper establishes the possibility of stably recovering original signals from the noisy data using the adaptive group Lasso with a combination of sufficient block-sparsity and favorable block structure of the overcomplete dictionary. The corresponding theoretical results about the solution uniqueness, support recovery and representation error bound are derived based on the properties of block-coherence and subcoherence. Compared with the theoretical results on the parametrized quadratic program of conventional sparse representation, our stability results are more general. A comparison with block-based orthogonal greedy algorithm is also presented. Numerical experiments demonstrate the validity and correctness of theoretical derivation and also show that in case of noisy situation, the adaptive group Lasso has a better reconstruction performance than the quadratic program approach if the observed sparse signals have a natural block structure.",2011,IEEE Transactions on Signal Processing
Exine ultrastructure in pollen grains of Classopollis Pflug from the Cretaceous of Lebanon,"Pollen grains of Classopollis Pflug from the Cretaceous deposits of Lebanon were studied by means of light and electron microscopy. Ultrastructurally, they are similar to pollen grains, extracted from Classostrobus comptonensis Alvin, Spicer et Watson from the Barremian of England. The differences concern the shape and size of spinules, ultrastructure of apertural regions, and preservation of the endexine. An analysis of our data and published results revealed three types of infratectum existed in members of Circumpolles: (1) with branchy elements, (2) with columella-like non-branching elements, and (3) with large granules arranged in one row. The palynological assemblage is described in detail; problems of dating are discussed.",2010,Paleontological Journal
Abstract 469: Microrna signature as a potential biomarker for predicting survival in colon cancer,"Background: Colon cancer is one of the most common cancers with increasing incidence and high mortality worldwide. Prognosis and choice of treatment is largely based on the tumor stage at presentation. Thus, finding novel biomarkers for predicting survival is highly desirable. Lately, several studies have been looking at microRNAs (miRNAs) in several cancers, including colon cancer. MicroRNAs are conserved, non-coding RNA molecules that play an important role in the regulation of post-transcriptional gene expression. Material and Methods: In the present study, we have profiled miRNA in one hundred and seventy two TNM stage I-IV colon cancer patients and 10 corresponding normal colon tissue samples. Total RNA was extracted from freshly frozen tissues, and the expression of miRNA profile were assessed using Pick and Mix focus panels from Exiqon containing 84 miRNAs that have been linked to cancer. Results: The results were visualized in a heatmap (Qlucore omics Software) and more than 20 miRNAs were found to be differentially expressed in tumors compared to the normal colon. Further, twelve miRNAs were found to discriminate between relapse and no-relapse patients in TNM- stage II and III, and four of these miRNAs (miR-23a, miR-25, miR-30d and miR-31) were found to be statistically significant in binary logistic regression with relapse as outcome variable. In univariate analysis, low expression of the four-miRNA signature was associated with better 3-year disease-free survival (DFS), 88 % versus 63% in low versus high signature, respectively (P=0.001). Moreover, the signature was a predictor of poor relapse-free survival in multivariate analyses (P=0.001; HR 31; 95% CI: 3.8-248.9). Another regression analyses method (LASSO) identified a 16-miRNA signature, and the four miRNAs found earlier were among them. The 16-miRNA signature was associated with better survival (P Conclusion: The present study has identified a four-miRNA signature predicting relapse in colon cancer stage II and III patients. Citation Format: Havjin Jacob, Luka Stanisavljevic, Kristian Eeg Storli, Olav Dahl, Mette Pernille Myklebust. Microrna signature as a potential biomarker for predicting survival in colon cancer [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2017; 2017 Apr 1-5; Washington, DC. Philadelphia (PA): AACR; Cancer Res 2017;77(13 Suppl):Abstract nr 469. doi:10.1158/1538-7445.AM2017-469",2017,Cancer Research
Salmon Recipe with for spring or summer | Verlasso,"Grilled Verlasso salmon with a crispy salad made with greens, jicama and orange sections to enrich the sweet southwestern flavors of the salmon.",2013,
High-dimensional Joint Sparsity Random Effects Model for Multi-task Learning,"Joint sparsity regularization in multi-task learning has attracted much attention in recent years. The traditional convex formulation employs the group Lasso relaxation to achieve joint sparsity across tasks. Although this approach leads to a simple convex formulation, it suffers from several issues due to the looseness of the relaxation. To remedy this problem, we view jointly sparse multi-task learning as a specialized random effects model, and derive a convex relaxation approach that involves two steps. The first step learns the covariance matrix of the coefficients using a convex formulation which we refer to as sparse covariance coding; the second step solves a ridge regression problem with a sparse quadratic regularizer based on the covariance matrix obtained in the first step. It is shown that this approach produces an asymptotically optimal quadratic regularizer in the multitask learning setting when the number of tasks approaches infinity. Experimental results demonstrate that the convex formulation obtained via the proposed model significantly outperforms group Lasso (and related multi-stage formulations",2013,ArXiv
"Approches statistiques avancÃ©es pour la modÃ©lisation des sÃ©ries chronologiques en rÃ©gression, appliquÃ©es Ã  lâ€™Ã©pidÃ©miologie environnementale.","La sante des populations est un des defis majeurs lies a lâ€™adaptation aux changements climatiques. Lâ€™effet des vagues de chaleur est notamment deja visible alors que ces evenements devraient se multiplier dans les annees a venir. Les maladies cardiovasculaires representent une des classes de maladies les plus touchees, tout en etant deja un probleme majeur de sante publique a lâ€™heure actuelle. De plus en plus dâ€™etudes en epidemiologie environnementale visent a identifier lâ€™effet de la meteorologie sur la sante, afin dâ€™anticiper les changements climatiques et mettre en place des alertes appropriees. Les etudes dâ€™epidemiologie environnementales sâ€™appuient notamment sur des modeles de regression, lesquels sont appliques avec des donnees pouvant prendre la forme de series chronologiques (on peut aussi citer les donnees de type spatial). Les series chronologiques violent notamment les hypotheses dâ€™independance et de distribution identique des residus dans la regression, et necessitent donc des methodes mieux adaptees. Cette these propose donc des methodologies statistiques visant a repondre aux problemes crees par lâ€™utilisation de series chronologiques dans la regression. Les methodologies consistent toutes en un pretraitement des donnees puis a lâ€™application de modeles de regression adaptes pour prendre en compte les caracteristiques des donnees transformees. Elles sont ensuite appliquees a lâ€™etude du lien existant entre la meteorologie, en particulier la temperature et lâ€™humidite, sur la mortalite par maladie cardiovasculaire dans la communaute metropolitaine de Montreal. 
Les donnees sanitaires utilisees dependent notamment de lâ€™organisation des services medicaux. Or, cette organisation entraine la presence de bruit dans les donnees (p. ex. davantage de personnel de jour que de nuit), pouvant rendre plus difficile lâ€™estimation de la relation entre une variable explicative et une reponse. Il est ainsi propose dâ€™agreger temporellement les series de donnees sanitaires afin de faire ressortir le signal du a la meteorologie, puis dâ€™appliquer un modele de regression pour serie temporelle visant a modeliser la dependance temporelle dans les residus. La comparaison de cette methodologie avec un modele classique dâ€™epidemiologie environnementale montre quâ€™elle permet un meilleur ajustement du modele aux donnees. La comparaison de diverses strategies dâ€™agregation mene cependant a la conclusion que la fenetre dâ€™agregation ne doit pas etre superieure a une semaine. 
Une problematique plus generale des etudes concernant des processus naturels est la presence de saisonnalite et tendance entre autres menant a des cas de regression fallacieuse. Il est ainsi propose dans la these de decomposer les differents motifs reguliers presents dans les series de donnees par decomposition modale empirique. Les composantes en resultant sont ensuite utilisees dans la regression au lieu des series de donnees dâ€™origine, en utilisant la technique du Lasso (operateur de selection et reduction par moindres valeurs absolues) pour ne conserver que les composantes les plus importantes pour lâ€™explication de la reponse. Lâ€™application de cette methodologie aux donnees de mortalite, temperature et humidite permet de mettre en evidence des aspects de la relation habituellement invisibles dans les modeles statistiques. Cette methodologie permet ainsi un regard alternatif et detaille sur la relation entre des series de donnees chronologiques. 
De nombreux problemes lies a lâ€™utilisation de series chronologiques dans la regression tels que lâ€™autocorrelation et la non-stationnarite sont issus du fait quâ€™elles sont en fait des discretisations de processus intrinsequement continus. La these propose donc de considerer les series sanitaires et meteorologiques comme des courbes continues en utilisant le cadre de lâ€™analyse de donnees fonctionnelle. Notamment, les modeles de regression fonctionnelle sont adaptes aux problematiques inherentes au domaine de lâ€™epidemiologie environnementale. Les resultats montrent le potentiel de la regression fonctionnelle pour comprendre le lien entre la meteorologie et la sante dans sa globalite, en retranscrivant notamment les processus dâ€™adaptation physiologique des individus. Abstract In the context of climate change adaptation, public health management is a major challenge. For instance, the frequency and strength of heatwaves are expected to increase in the future while their effect on mortality is already well-known. Among the affected disease classes are cardiovascular diseases, which are already an important public health issue. Nowadays, many environmental epidemiology studies seek to understand precisely the effect of weather on population health, in order to accurately anticipate the future. Studies of the effect of meteorological factors on health often rely on regression models applied on time series data (although other types of data exist such as spatial data). However, several assumptions of regression models do not hold in presence of time series data, i.e. the assumptions of independence and same distribution of the residuals. Therefore, the purpose of the present thesis is to propose a number of regression methodologies addressing several issues caused by the temporal structure of data. The methodologies all rely on data preprocessing, in order to obtain transformed data that could be used in existing and efficient regression methods. They are illustrated on the relationship between weather and cardiovascular mortality in the census metropolitan area of Montreal, Canada. 
Health data are often noisy because of organisational factors in hospitals, which complicate the task of estimating the effect of a weather exposure on a health issue. It is herein proposed to temporally aggregate the health response before using it in a regression model. A time series regression model is then used to account for the temporal dependence of data. Comparing this methodology with classical regression models show that it leads to a better fit to health data as well as unveiling the relationship at a the weekly scale than classical regression. Moreover, several aggregation strategies are tried and it is shown that the best results are obtained using aggregations with small time windows. 
Many natural time series contains nonstationary patterns such as seasonality and trend, which could lead to spurious regression. The present thesis proposes to decompose time series data into basic oscillating components through empirical mode decomposition in order to use the components as new variables in a regression model. The use of the Lasso (least absolute shrinkage and selection operator) allows keeping only the most important components in order to explain the health response. The application of this methodology on temperature and humidity related to cardiovascular morbidity unveils little known aspects of the relationship, in addition to providing a good fit of the data. Hence, it is argued that this methodology represents a tool to understand more accurately than classical models any relationship between time-related processes. 
Many time series related issues in regression models are due to the fact that time series can be viewed as the discretization of intrinsically continuous processes. Therefore, the present thesis argues for the use functional data analysis which deals with data as continuous curves instead of discrete series. In particular, functional regression models are adapted to the particular issues of environmental epidemiology. The application of such models on the temperature-related cardiovascular mortality shows that they are able to describe an overall relationship. Functional models especially bring a tool that allows representing the physiological adaptation of populations, rarely taken into account in classical models.",2017,
Arbitrary Bit Generation and Correction Technique for Encoding QC-LDPC Codes with Dual-Diagonal Parity Structure,"In this paper, we propose a simple yet low complex systematic LDPC encoding method for class of quasi-cyclic low-density parity-check (QC-LDPC) codes which have an efficient encoding/decoding algorithm due to the simple structure of their parity-check matrices. The proposed encoding method is applicable to parity-check matrices having dual-diagonal parity structure with single column of weight 3. Unlike finding a direct solution for parity bits in schemes (Richardson and Urbanke, 2001 and Classon and Blankeship, 2004), the proposed scheme first generates arbitrary parity bits. Then, given the parity bits for the first sub-block and exploiting the dual-diagonal structure, all parity bits are found through correction. With slight modification of parity-check matrix H, proposed LDPC encoding scheme is directly applicable to matrices defined in IEEE physical layer standards with almost negligible performance loss. Moreover, the overall computational complexity involving encoding process is lower than well-known Richardson's efficient encoding scheme (Richardson and Urbanke, 2001).",2007,2007 IEEE Wireless Communications and Networking Conference
MEBoost: Variable selection in the presence of measurement error.,"We present a novel method for variable selection in regression models when covariates are measured with error. The iterative algorithm we propose, Measurement Error Boosting (MEBoost), follows a path defined by estimating equations that correct for covariate measurement error. We illustrate the use of MEBoost in practice by analyzing data from the Box Lunch Study, a clinical trial in nutrition where several variables are based on self-report and, hence, measured with error, where we are interested in performing model selection from a large data set to select variables that are related to the number of times a subject binge ate in the last 28 days. Furthermore, we evaluated our method and compared its performance to the recently proposed Convex Conditioned Lasso and to the ""naive"" Lasso, which does not correct for measurement error through a simulation study. Increasing the degree of measurement error increased prediction error and decreased the probability of accurate covariate selection, but this loss of accuracy occurred to a lesser degree when using MEBoost. Through simulations, we also make a case for the consistency of the model selected.",2019,Statistics in medicine
Multi-population GWA mapping via multi-task regularized regression,"MOTIVATION
Population heterogeneity through admixing of different founder populations can produce spurious associations in genome-wide association studies that are linked to the population structure rather than the phenotype. Since samples from the same population generally co-evolve, different populations may or may not share the same genetic underpinnings for the seemingly common phenotype. Our goal is to develop a unified framework for detecting causal genetic markers through a joint association analysis of multiple populations.


RESULTS
Based on a multi-task regression principle, we present a multi-population group lasso algorithm using L(1)/L(2)-regularized regression for joint association analysis of multiple populations that are stratified either via population survey or computational estimation. Our algorithm combines information from genetic markers across populations, to identify causal markers. It also implicitly accounts for correlations between the genetic markers, thus enabling better control over false positive rates. Joint analysis across populations enables the detection of weak associations common to all populations with greater power than in a separate analysis of each population. At the same time, the regression-based framework allows causal alleles that are unique to a subset of the populations to be correctly identified. We demonstrate the effectiveness of our method on HapMap-simulated and lactase persistence datasets, where we significantly outperform state of the art methods, with greater power for detecting weak associations and reduced spurious associations.


AVAILABILITY
Software will be available at http://www.sailing.cs.cmu.edu/.",2010,Bioinformatics
Measures of Significance for Constructing Intelligent Feature Weights,"When part of the regressors can act on both the response and some of the other explanatory variables, the already challenging problem of selecting variables in a p > n context becomes more difficult. A recent methodology for variable selection in this context links the concept of q-values from multiple testing to the weighted Lasso. In this talk, we show that different informative measures of significance to q-values, such as partial correlation coefficients or Benjamini-Hochberg adjusted p-values, give similarly promising performance as when using q-values.",2012,
Thermohaline Anomalies in the Spring and Early Summer of 2000 in the Gulf of Trieste,". In the framework of the Interreg II Project (July 1998 - June 2001), hydro-logical, chemical and biological data were collected in the Gulf of Trieste. 
 
 
 
During spring and summer 2000, some particular thermohaline anomalies were observed in the Gulf of Trieste. Especially in May and June the water body showed: a very strong thermohaline stratification, an increase of advective salt water coming from the south and the presence of sharp pycnoclines. In July the temperature was higher than usual in the whole water column. Moreover, in late May and in June, massive mucilaginous aggregates were observed along the water column and at the surface. 
 
 
 
In order to highlight these particular thermohaline features the hydrological data of 16 stations were analysed (Fig. 1). Two stations, in particular, were considered: one offshore (St. AA1, average depth 20 m) and one close to the coast (St. C1, average depth 17 m). For these two stations a best-fit analysis, computed over 11 and 7 years, respectively, was performed on temperature, salinity and density excess data. 
 
 
 
Moreover, the hydrological features were compared with the rainfall, air temperature, wind speed data (Istituto Sperimentale Talassografico di Trieste - ISTT) and the Isonzo River's flow rate (Direzione Regionale dell'Ambiente - Regione F. V. G.) collected from January 1998 to December 2000.",2002,Marine Ecology
Variable selection via Group LASSO Approach : Application to the Cox Regression and frailty model,"In the analysis of survival outcome supplemented with both clinical information and high-dimensional gene expression data, use of the traditional Cox proportional hazards model (1972) fails to meet some emerging needs in biomedical research. First, the number of covariates is generally much larger the sample size. Secondly, predicting an outcome based on individual gene expression is inadequate because multiple biological processes and functional pathways regulate the expression associated with a gene. Another challenge is that the Cox model assumes that populations are homogenous, implying that all individuals have the same risk of death, which is rarely true due to unmeasured risk factors among populations. In this paper we propose group LASSO with gamma-distributed frailty for variable selection in Cox regression by extending previous scholarship to account for heterogeneity among group structures related to exposure and susceptibility. The consistency property of the proposed method is established. This method is appropriate for addressing a wide variety of research questions from genetics to air pollution. Simulated analysis shows promising performance by group LASSO compared with other methods, including group SCAD and group MCP. Future directions include expanding the use of frailty with adaptive group LASSO and sparse group LASS.",2018,arXiv: Computation
Integration of single nucleotide variants and whole-genome DNA methylation profiles for classification of rheumatoid arthritis cases from controls,"This study evaluated the use of multiomics data for classification accuracy of rheumatoid arthritis (RA). Three approaches were used and compared in terms of prediction accuracy: (1) whole-genome prediction (WGP) using SNP marker information only, (2) whole-methylome prediction (WMP) using methylation profiles only, and (3) whole-genome/methylome prediction (WGMP) with combining both omics layers. The number of SNP and of methylation sites varied in each scenario, with either 1, 10, or 50% of these preselected based on four approaches: randomly, evenly spaced, lowest p value (genome-wide association or epigenome-wide association study), and estimated effect size using a Bayesian ridge regression (BRR) model. To remove effects of high levels of pairwise linkage disequilibrium (LD), SNPs were also preselected with an LD-pruning method. Five Bayesian regression models were studied for classification, including BRR, Bayes-A, Bayes-B, Bayes-C, and the Bayesian LASSO. Adjusting methylation profiles for cellular heterogeneity within whole blood samples had a detrimental effect on the classification ability of the models. Overall, WGMP using Bayes-B model has the best performance. In particular, selecting SNPs based on LD-pruning with 1% of the methylation sites selected based on BRR included in the model, and fitting the most significant SNP as a fixed effect was the best method for predicting disease risk with a classification accuracy of 0.975. Our results showed that multiomics data can be used to effectively predict the risk of RA and identify cases in early stages to prevent or alter disease progression via appropriate interventions.",2020,Heredity
"Population dynamics of Anopheles gambiae s.l. in Bobo-Dioulasso city: bionomics, infection rate and susceptibility to insecticides","BackgroundHistorical studies have indicated that An. gambiae s.s. is the predominant malaria vector species in Bobo-Dioulasso the second biggest city of Burkina Faso (West Africa). However, over the last decade, An. arabiensis appears to be replacing An. gambiae s.s. as the most prevalent malaria vector in this urban setting. To investigate this species transition in more detail the present study aims to provide an update on the malaria vector composition in Bobo-Dioulasso, and also the Plasmodium infection rates and susceptibility to insecticides of the local An. gambiae s.l. population.MethodsAn entomological survey was carried out from May to December 2008 in Dioulassoba and Kodeni (central and peripheral districts respectively), which are representative of the main ecological features of the city. Sampling consisted of the collection of larval stages from water bodies, and adults by monthly indoor residual spraying (IRS) using aerosol insecticides. Insecticide susceptibility tests were performed using the WHO filter paper protocol on adults emerged from larvae. PCR was used to determine vector species and to identify resistance mechanisms (kdr and ace-1R). The Plasmodium infection rate was estimated by ELISA performed on female mosquitoes collected indoors by IRS.ResultsAn. arabiensis was found to be the major malaria vector in Bobo-Dioulasso, comprising 50 to 100% of the vector population. The sporozoite infection rate for An. arabiensis was higher than An. gambiae s.s. at both Dioulassoba and Kodeni. An. gambiae s.l. was resistant to DDT and cross-resistant to pyrethroids at the two sites with higher levels of resistance observed in An. gambiae s.s. than An. arabiensis. Resistance to 0.1% bendiocarb was observed in the An. gambiae s.s.â€‰S form but not the M form or in An. arabiensis. The L1014F kdr mutation was detected in the two molecular forms of An. gambiae s.s. at varying frequencies (0.45 to 0.92), but was not detected in An. arabiensis, suggesting that other mechanisms are involved in DDT resistance in this species. The ace-1R mutation was only detected in the S molecular form and was observed at the two sites at similar frequency (0.3).ConclusionsOver the last ten years, An. arabiensis has become the major malaria vector in Bobo-Dioulasso city where it was formerly present only at low frequency. However, the ecological determinant that enhances the settlement of this species into urban and peri-urban areas of Bobo-Dioulasso remains to be clarified. The impact of the changing An. gambiae s.l. population in this region for vector control including resistance management strategies is discussed.",2012,Parasites & Vectors
DistribuciÃ³ batimÃ¨trica dels peixos litorals de substract rocÃ³s a l'illa de Cabrera,"catalaLa ictiofauna que es troba sobre fons rocosos litorals de l'illa de Cabrera ha estat estudiada, mitjancant la tecnica de comptatges visuals, en transsectes fixos de 50 x 5 m, situats a -6, -30 i -45 m de fondaria. En total han estat observades 46 especies, pertanyents a 19 families, entre les quals dominen clarament els labrids i els esparids. La fondaria es el principal factor que determina les diferencies qualitatives i quantitatives observades al llarg de l'estudi. El segon factor sembla ser degut a la diferencia en l'heterogeneitat del substrat, i a l'existencia a absencia d'algues frondoses. En fondaria hom observa una certa disminucio del nombre d'especies de labrids i esparids. L'ampli marge de fondaries estudiades i l'extrema polaritzacio de les mostres en les comunitats bentoniques de Cabrera permet definir dues associacions de peixos litorals: una de superficial, carateritzada sobretot per Symphodus roissali, Symphodus ocellatus, Thalassoma pavo, i Parablennius rouxij i una de fonda, caracteritzada, entre d'altres per Anthias anthias, Labrus bimaculatus, Symphodus melanocercus i Gobius vittatus. Amb tot, mes que una zonacio en sentit estricte, hom postula l'existencia d'un continuum, on les diferencies quantitatives son gairebe tan importants com les qualitatives, i on unes especies succeeixen les altres de forma gradual. En un treball subsidiari, hom estudia amb mes detall la distribucio en fondaria de dues especies simpatriques, Serranus cabrilla i Serranus scriba, entre les quals es produeix, mes que una competencia per l'espai, un cas de compartimentacio espacial. Les pautes de distribucio en fondaria d'aquestes dues especies poden ser paradigmatiques del que ocorre en molts altres casos EnglishThe coastal fish fauna from Cabrera island rocky bottoms has been studied by visual censuses along 50 x 5 m strip transects sitted at -6, -30 and -45 m depth. 46 fish species have been recorded, belonging to 19 families dominated by Labridae (11 species) and Sparidae (9 species). Depth is the main environmental factor affecting qualitative and quantitative fish distribution, being bottom heterogenity (hole size and presence or absence of frondose algae) the second one. A decrease of Labridae and Sparidae species has been found with depth. Two rocky fish assemblages have been distinguished attending to their depth distribution ranks: a shallow one, characterized by Symphodus roissali, Symphodus ocellatus, Thalassoma pavo and Parablennius rouxij and a deep one, characterized mainly by Anthias anthias, Labrus bimaculatus, Symphodus melanocercus and Gobius vittatus. However, there is a continuum change of species with depth instead of critical discontinuities between the two fish assemblages. Depth patterns of two sympatric species (Serranus cabrilla and Serranus scribal has been studied as an example of this continuos depth fish distribution.",1993,
Penalized models for analysis of multiple mediators.,"Mediation analysis attempts to determine whether the relationship between an independent variable (e.g., exposure) and an outcome variable can be explained, at least partially, by an intermediate variable, called a mediator. Most methods for mediation analysis focus on one mediator at a time, although multiple mediators can be jointly analyzed by structural equation models (SEMs) that account for correlations among the mediators. We extend the use of SEMsÂ for the analysis of multiple mediators by creating a sparse group lasso penalized model such that the penalty considers the natural groupings of parameters that determine mediation, as well as encourages sparseness of the model parameters. This provides a way to simultaneously evaluate many mediators and select those that have the most impact, a feature of modern penalized models. Simulations are used to illustrate the benefits and limitations of our approach, and application to a study of DNA methylation and reactive cortisol stress following childhood trauma discovered two novel methylation loci that mediate the association of childhood trauma scores with reactive cortisol stress levels. Our new methods are incorporated into R software called regmed.",2020,Genetic epidemiology
Goodness of fit tests and lasso variable selection in time series analysis,"This thesis examines various aspects of time series and their applications. In the rst part, we study numerical and asymptotic properties of Box-Pierce family of portmanteau tests. We compare size and power properties of time series model diagnostic tests using their asymptotic c2 distribution and bootstrap distribution (dynamic and fixed design) against various linear and non-linear alternatives. In general, our results show that dynamic bootstrapping provides a better approximation of the distribution underlying these statistics. Moreover, we find that Box-Pierce type tests are powerful against linear alternatives while the CvM due to Escanciano (2006b) test performs better against non linear alternative models.
The most challenging scenario for these portmanteau tests is when the process is close to the stationary boundary and value of m, the maximum lag considered in the portmanteau test, is very small. In these situations, the c2 distribution is a poor approximation of the null asymptotic distribution. Katayama (2008) suggested a bias correction term to improve the approximation in these situations. We numerically study Katayama's bias correction in Ljung and Box (1978) test. Our results show that Katayama's correction works well and conrms the results as shown in Katayama (2008). We also provide a number of algorithms for performing the necessary calculations efciently.
We notice that the bootstrap automatically does bias correction in Ljung-Box statistic. It motivates us to look at theoretical properties of the dynamic bootstrap in this context. Moreover, noticing the good performance of Katayama's correction, we suggest a bias correction term for the Monti (1994) test on the lines of Katayama's correction. We show that our suggestion improves Monti's statistic in a similar way to what Katayama's suggestion does for Ljung-Box test. We also make a novel suggestion of using the pivotal portmanteau test. Our suggestion is to use two separate values of m, one a large value for the calculation of the information matrix and a smaller choice for diagnostic purposes. This results in a pivotal statistic which automatically corrects the bias correction in Ljung-Box test. Our suggested novel algorithm efciently computes this novel portmanteau test.
In the second part, we implement lasso-type shrinkage methods to linear regression and time series models. We look through simulations in various examples to study the oracle properties of these methods via the adaptive lasso due to Zou (2006). We study consistent variable selection by the lasso and adaptive lasso and consider a result in the literature which states that the lasso cannot be consistent in variable selection if a necessary condition does not hold for the model. We notice that lasso methods have nice theoretical properties but it is not very easy to achieve them in practice.
The choice of tuning parameter is crucial for these methods. So far there is not any fully explicit way of choosing the appropriate value of tuning parameter, so it is hard to achieve the oracle properties in practice. In our numerical study, we compare the performance of k-fold cross-validation with the BIC method of Wang et al. (2007) for selecting the appropriate value of the tuning parameter. We show that k-fold crossvalidation is not a reliable method for choosing the value of the tuning parameter for consistent variable selection.
We also look at ways to implement lasso-type methods time series models. In our numerical results we show that the oracle properties of lasso-type methods can also be achieved for time series models. We derive the necessary condition for consistent variable selection by lasso-type methods in the time series context. We also prove the oracle properties of the adaptive lasso for stationary time series.",2011,
Sparse Gaussian graphical mixture model,"Abstract. This paper considers the problem of networks reconstruction from heterogeneous data using a Gaussian Graphical Mixture Model (GGMM). It is well known that parameter estimation in this context is challenging due to large numbers of variables coupled with the degenerate nature of the likelihood. We propose as a solution a penalized maximum likelihood technique by imposing an l1 penalty on the precision matrix. Our approach shrinks the parameters thereby resulting in better identiability and variable selection . Resume. Cet article considere le probleme de la reconstruction de reseaux a partir de donnees heterogenes en utilisant le modele graphique gaussien memange (GGMM en Anglais). Il est connu que l'estimation parametrique, dans ce contexte, n'est pas aise a cause du grand nombre de variable et de la nature degeneree de la vraisemblance. Nous proposons comme une solution une methode de penalisation du maximum de vraisemblance en imposant une penalite de type L1 sur la precision de la matrice. Notre methode reduit les parametres et ainsi aboutit a une meilleure identication et a un meilleur choix des variables. Key words : Gaussian graphical mixture model; Expectation maximization algorithm; Graphical LASSO.",2016,Journal of Animal Science
Comparing Approaches to Treatment Effect Estimation for Subgroups in Clinical Trials,"ABSTRACTIdentifying subgroups, which respond differently to a treatment, both in terms of efficacy and safety, is an important part of drug development. A well-known challenge in exploratory subgroup analyses is the small sample size in the considered subgroups, which is usually too low to allow for definite comparisons. In early phase trials, this problem is further exaggerated, because limited or no clinical prior information on the drug and plausible subgroups is available. We evaluate novel strategies for treatment effect estimation in these settings in a simulation study motivated by real clinical trial situations. We compare several approaches to estimate treatment effects for selected subgroups, employing model averaging, resampling, and Lasso regression methods. Two subgroup identification approaches are employed, one based on categorization of covariates and the other based on splines. Our results show that naive estimation of the treatment effect, which ignores that a selection has taken place, ...",2016,Statistics in Biopharmaceutical Research
Stability of building gene regulatory networks with sparse autoregressive models,"BackgroundBiological networks are constantly subjected to random perturbations, and efficient feedback and compensatory mechanisms exist to maintain their stability. There is an increased interest in building gene regulatory networks (GRNs) from temporal gene expression data because of their numerous applications in life sciences. However, because of the limited number of time points at which gene expressions can be gathered in practice, computational techniques of building GRN often lead to inaccuracies and instabilities. This paper investigates the stability of sparse auto-regressive models of building GRN from gene expression data.ResultsCriteria for evaluating the stability of estimating GRN structure are proposed. Thereby, stability of multivariate vector autoregressive (MVAR) methods - ridge, lasso, and elastic-net - of building GRN were studied by simulating temporal gene expression datasets on scale-free topologies as well as on real data gathered over Hela cell-cycle. Effects of the number of time points on the stability of constructing GRN are investigated. When the number of time points are relatively low compared to the size of network, both accuracy and stability are adversely affected. At least, the number of time points equal to the number of genes in the network are needed to achieve decent accuracy and stability of the networks. Our results on synthetic data indicate that the stability of lasso and elastic-net MVAR methods are comparable, and their accuracies are much higher than the ridge MVAR. As the size of the network grows, the number of time points required to achieve acceptable accuracy and stability are much less relative to the number of genes in the network. The effects of false negatives are easier to improve by increasing the number time points than those due to false positives. Application to HeLa cell-cycle gene expression dataset shows that biologically stable GRN can be obtained by introducing perturbations to the data.ConclusionsAccuracy and stability of building GRN are crucial for investigation of gene regulations. Sparse MVAR techniques such as lasso and elastic-net provide accurate and stable methods for building even GRN of small size. The effect of false negatives is corrected much easier with the increased number of time points than those due to false positives. With real data, we demonstrate how stable networks can be derived by introducing random perturbation to data.",2011,BMC Bioinformatics
A sparse version of the ridge logistic regression for large-scale text categorization,"The ridge logistic regression has successfully been used in text categorization problems and it has been shown to reach the same performance as the Support Vector Machine but with the main advantage of computing a probability value rather than a score. However, the dense solution of the ridge makes its use unpractical for large scale categorization. On the other side, LASSO regularization is able to produce sparse solutions but its performance is dominated by the ridge when the number of features is larger than the number of observations and/or when the features are highly correlated. In this paper, we propose a new model selection method which tries to approach the ridge solution by a sparse solution. The method first computes the ridge solution and then performs feature selection. The experimental evaluations show that our method gives a solution which is a good trade-off between the ridge and LASSO solutions.",2011,Pattern Recognit. Lett.
A Preliminary Study of the Geology of the Elassona Lignite Deposits in Central Greece,"This study presents lithologic and macroscopic data from the recently-discovered lignite deposits of Domenikon and Amourion near Elassona in central Greece. The data is complimented with coal quality (proximate analysis and sulfur) as well as petrographic and palynological data aimed at unraveling the depositional environment during peat deposition. Samples taken from 3 deep boreholes, EL-57, EL-65, and EL-79, reveal that the lignite in both deposits contains a high percentage of xylite, with clay being the most abundant inorganic component. The Amourion deposit consists of alternations of lignite beds and inorganic strata. Proximate analysis data shows that the lignite deposit of Domenikon is of better quality than the Amourion lignite. The overall quality of both lignites is generally better than that of most other Greek lignites. On the basis of coal quality and estimated reserves obtained through drilling, it appears that both lignite deposits are suitable for economic exploitation.",2003,Energy Sources
Least Angle Regression and Partial Least Squares Regression on Process Data with High Collinearity,"Overview Collinearity is a common problem met in regression analysis for chemical process data. A popular method to deal with collinearity is partial least squares regression (PLS). It uses projections of the original variables to a reduce number of latent variables to circumvent the task of model selection. On the other hand, recent advances in statistics and machine learning provide promising methods of sparse analytics, which lead to a natural way to exclude variables that are irrelevant or redundant. To study the effectiveness of these methods, we evaluate the performance of least angle regression (LARS) on an industrial boiler dataset with high collinearity, and compare its performance with those of least absolute shrinkage and selection operator (LASSO) and PLS. The results show that LARS has a better performance on highly collinear data. It produces sparse coefficients like LASSO, which PLS cannot achieve, and it allows for an easier selection of a best set of coefficients comparative to LASSO.",2019,
Muscle Sleeve Electrical Isolation for Recurrent Cases of Paroxysmal Atrial Fibrillation After Focal Ablation,"This study is to evaluate the possible mechanisms of recurrence cases of paroxysmal atrial fibrillation (PAF) after focal ablation and the effects of second myocardial sleeve isolation with radiofrequency ablation technique. Guided by Lasso mapping catheter, isolation ablation procedures were performed in five patients with PAF recurred after focal ablation. Electrical isolation were successfully achieved in 15 veins ( 13 pulmonary veins and 2 superior vena cava ) of 5 cases through 6 procedures. After a mean follow up of 11.8Â±8.9 months , all cases remained free of PAF without medication. In conclusion, recurrence cases of PAF after focal ablation can be successfully cured with the electrical isolation of pulmonary vein and superior vena. The isolation of at least 3 or 4 veins in one procedure were feasible and preferable for reducing the recurrence of atrial fibrillation. The incidence of pulmonary vein stenosis is relatively low.",2003,The Chinese Journal of Cardiac Pacing and Electrophysiology
A note on path-based variable selection in the penalized proportional hazards model,"We propose an efficient and adaptive shrinkage method for variable selection in the Cox model. The method constructs a piecewise-linear regularization path connecting the maximum partial likelihood estimator and the origin. Then a model is selected along the path. We show that the constructed path is adaptive in the sense that, with a proper choice of regularization parameter, the fitted model works as well as if the true underlying submodel were given in advance. A modified algorithm of the least-angle-regression type efficiently computes the entire regularization path of the new estimator. Furthermore, we show that, with a proper choice of shrinkage parameter, the method is consistent in variable selection and efficient in estimation. Simulation shows that the new method tends to outperform the lasso and the smoothly-clipped-absolute-deviation estimators with moderate samples. We apply the methodology to data concerning nursing homes. Copyright 2008, Oxford University Press.",2008,Biometrika
Metagenomic abundance estimation and diagnostic testing on species level,"One goal of sequencing-based metagenomic community analysis is the quantitative taxonomic assessment of microbial community compositions. In particular, relative quantification of taxons is of high relevance for metagenomic diagnostics or microbial community comparison. However, the majority of existing approaches quantify at low resolution (e.g. at phylum level), rely on the existence of special genes (e.g. 16S), or have severe problems discerning species with highly similar genome sequences. Yet, problems as metagenomic diagnostics require accurate quantification on species level. We developed Genome Abundance Similarity Correction (GASiC), a method to estimate true genome abundances via read alignment by considering reference genome similarities in a non-negative LASSO approach. We demonstrate GASiC's superior performance over existing methods on simulated benchmark data as well as on real data. In addition, we present applications to datasets of both bacterial DNA and viral RNA source. We further discuss our approach as an alternative to PCR-based DNA quantification.",2013,Nucleic Acids Research
A Practical Variable Selection for Linear Models,"In the analysis of experiments, there are many variable selection algorithms for linear models. Most of these approaches select the best model based on some criteria such as AIC. These criteria do not allow for any relationship between predictors. However, in practice, the analysis is driven by following three principles: Effect Hierarchy, Effect Sparsity, and Effect Heredity Principle. The approach depending solely on those criteria ignore these principles, so it would often select a hard to interpretable models, for instance, which are consisted with only interaction terms. In this article, we extend the LASSO method to identify significant interaction terms mainly focusing on the heredity principle. And we compare the proposed method with ordinary LASSO and traditional variable selection approach. In the example, we analyze the data obtained from designed experiments such as Placket-Burman design and supersaturated design.",2012,
A note on the asymptotic distribution of LASSO estimator for correlated data,"The asymptotic distribution of the Lasso estimator for regression models with independent errors has been investigated by Knight and Fu (2000). In this note we extend these results to regression models with a general weak dependence structure. We determine the asymptotic distribution of the Lasso estimator when the number of parameters M is fixed and the number of observations, n, converges to infinity. We show that, for an appropriate choice of the tuning parameter of the method, this asymptotic distribution reduces to a multivariate normal distribution. As an illustrative example, the special case of AR(1) is also investigated.",2012,
Standardized comparison of the relative impacts of HIV-1 reverse transcriptase (RT) mutations on nucleoside RT inhibitor susceptibility.,"Determining the phenotypic impacts of reverse transcriptase (RT) mutations on individual nucleoside RT inhibitors (NRTIs) has remained a statistical challenge because clinical NRTI-resistant HIV-1 isolates usually contain multiple mutations, often in complex patterns, complicating the task of determining the relative contribution of each mutation to HIV drug resistance. Furthermore, the NRTIs have highly variable dynamic susceptibility ranges, making it difficult to determine the relative effect of an RT mutation on susceptibility to different NRTIs. In this study, we analyzed 1,273 genotyped HIV-1 isolates for which phenotypic results were obtained using the PhenoSense assay (Monogram, South San Francisco, CA). We used a parsimonious feature selection algorithm, LASSO, to assess the possible contributions of 177 mutations that occurred in 10 or more isolates in our data set. We then used least-squares regression to quantify the impact of each LASSO-selected mutation on each NRTI. Our study provides a comprehensive view of the most common NRTI resistance mutations. Because our results were standardized, the study provides the first analysis that quantifies the relative phenotypic effects of NRTI resistance mutations on each of the NRTIs. In addition, the study contains new findings on the relative impacts of thymidine analog mutations (TAMs) on susceptibility to abacavir and tenofovir; the impacts of several known but incompletely characterized mutations, including E40F, V75T, Y115F, and K219R; and a tentative role in reduced NRTI susceptibility for K64H, a novel NRTI resistance mutation.",2012,Antimicrobial agents and chemotherapy
Detecting genetic risk factors for Alzheimer's disease in whole genome sequence data via Lasso screening,"Genetic factors play a key role in Alzheimer's disease (AD). The Alzheimer's Disease Neuroimaging Initiative (ADNI) whole genome sequence (WGS) data offers new power to investigate mechanisms of AD by combining entire genome sequences with neuroimaging and clinical data. Here we explore the ADNI WGS SNP (single nucleotide polymorphism) data in depth and extract approximately six million valid SNP features. We investigate imaging genetics associations using Lasso regression - a widely used sparse learning technique. To solve the large-scale Lasso problem more efficiently, we employ a highly efficient screening rule for Lasso - called dual polytope projections (DPP) - to remove irrelevant features from the optimization problem. Experiments demonstrate that the DPP can effectively identify irrelevant features and leads to a 400Ã— speedup. This allows us for the first time to run the compute-intensive model selection procedure called stability selection to rank SNPs that may affect the brain and AD risk.",2015,2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)
Title Sieve likelihood ratio statistics and Wilks phenomenon,"Variable selection is vital to statistical data analyses. Many of procedures in use are ad hoc stepwise selection procedures, which are computationally expensive and ignore stochastic errors in the variable selection process of previous steps. An automatic and simultaneous variable selection procedure can be obtained by using a penalized likelihood method. In traditional linear models, the best subset selection and stepwise deletion methods coincide with a penalized leastsquares method when design matrices are orthonormal. In this paper, we propose a few new approaches to selecting variables for linear models, robust regression models and generalized linear models based on a penalized likelihood approach. A family of thresholding functions are proposed. The LASSO proposed by Tibshirani (1996) is a member of the penalized leastsquares with the L1-penalty. A smoothly clipped absolute deviation (SCAD) penalty function is introduced to ameliorate the properties of L1-penalty. A uni ed algorithm is introduced, which is backed up by statistical theory. The new approaches are compared with the ordinary leastsquares methods, the garrote method by Breiman (1995) and the LASSO method by Tibshirani (1996). Our simulation results show that the newly proposed methods compare favorably with other approaches as an automatic variable selection technique. Because of simultaneous selection of variables and estimation of parameters, we are able to give a simple estimated standard error formula, which is tested to be accurate enough for practical applications. Two real data examples illustrate the versatility and e ectiveness of the proposed approaches.",1999,
M ulti-Field Ination on the Landscape,"W e exam ine a wide classofm ulti-ï¿½eld inationary m odelsbased oneldsthatdecay orstabilize during ination in a staggered fashion.Theeldsdriving assisted ination areonat,shortstretches,beforethey encountera sharp drop;wheneveraeld encounterssuch a drop due to itsslow rollevolution,itsenergy is transferred to other degrees offreedom ,i.e. radiation. The rate at whichelds decay is determ ined dynam ically and itisnotafreeparam eterin thisclassofm odels.Tocom puteobservables,wegeneralizethe analyticfram eworkofstaggered ination,allowingform oregeneralinitialconditionsand varyingpotentials. By searching forgenericsituationsarising on thelandscape,wearriveata setup involving linearorhilltop potentialsand evenly spread outinitialeld values. Thisscenario isnotm orene tuned than large-ï¿½eld m odels,despite the factthatm any m ore degreesoffreedom are involved. Further,the ï¿½-problem can be alleviated. The additionaldecrease ofthe potentialenergy caused by the decay ofelds provides leading order contribution to observables,such asthe scalarand tensorspectralindex orthe tensorto scalarratio,for which we derive generalexpressions. W e com pare the predictionswith W M AP5 constraintsandnd that hilltop potentialsareborderlineruled outatthe2ï¿½-level,whilelinearpotentialsarein excellentagreem ent with observations.W efurthercom m enton additionalsourcesofgravitationalwavesand non-Gaussianities thatcould serveasa sm oking gun forstaggered ination.",2013,
"The effects of data sources, cohort selection, and outcome definition on a predictive model of risk of thirty-day hospital readmissions","BACKGROUND
Hospital readmission risk prediction remains a motivated area of investigation and operations in light of the hospital readmissions reduction program through CMS. Multiple models of risk have been reported with variable discriminatory performances, and it remains unclear how design factors affect performance.


OBJECTIVES
To study the effects of varying three factors of model development in the prediction of risk based on health record data: (1) reason for readmission (primary readmission diagnosis); (2) available data and data types (e.g. visit history, laboratory results, etc); (3) cohort selection.


METHODS
Regularized regression (LASSO) to generate predictions of readmissions risk using prevalence sampling. Support Vector Machine (SVM) used for comparison in cohort selection testing. Calibration by model refitting to outcome prevalence.


RESULTS
Predicting readmission risk across multiple reasons for readmission resulted in ROC areas ranging from 0.92 for readmission for congestive heart failure to 0.71 for syncope and 0.68 for all-cause readmission. Visit history and laboratory tests contributed the most predictive value; contributions varied by readmission diagnosis. Cohort definition affected performance for both parametric and nonparametric algorithms. Compared to all patients, limiting the cohort to patients whose index admission and readmission diagnoses matched resulted in a decrease in average ROC from 0.78 to 0.55 (difference in ROC 0.23, p value 0.01). Calibration plots demonstrate good calibration with low mean squared error.


CONCLUSION
Targeting reason for readmission in risk prediction impacted discriminatory performance. In general, laboratory data and visit history data contributed the most to prediction; data source contributions varied by reason for readmission. Cohort selection had a large impact on model performance, and these results demonstrate the difficulty of comparing results across different studies of predictive risk modeling.",2014,Journal of biomedical informatics
Iterative method with inertial terms for nonexpansive mappings: applications to compressed sensing,"Our interest in this paper is to introduce a Halpern-type algorithm with both inertial terms and errors for approximating fixed point of a nonexpansive mapping. We obtain strong convergence of the sequence generated by our proposed method in real Hilbert spaces under some reasonable assumptions on the sequence of parameters. As applications, we present some strong convergence results for monotone inclusion, variational inequality problem, linear inverse problem, and LASSO problem in Compressed Sensing. Our result improves the rate of convergence of existing Halpern method for monotone inclusion, variational inequality problem, linear inverse problem and LASSO problem in compressed sensing as illustrated in our numerical examples both in finite and infinite dimensional Hilbert spaces.",2019,Numerical Algorithms
Evolution of microbiota during spontaneous and inoculated Tonda di Cagliari table olives fermentation and impact on sensory characteristics,"Abstract Starters are widely used for driving food fermentations faster and more safely. Recently, the use of natural autochthonous microbiota is being reappraised for obtaining products with peculiar and unique characteristics. The aim of this study was to investigate, by DGGE and REP-PCR(GTG) 5 , the microbial dynamics and intra-species biodiversity of Tonda di Cagliari table olives inoculated with a mix of autochthonous Lactobacillus pentosus strains (SIE) or a single Lactobacillus plantarum strain (SSL), taking spontaneous fermentation (NF) as control. Furthermore, the sensory quality of the three fermentations trials was evaluated by Descriptive Analysis. Among 316 isolates, 289 were identified as Lactobacillus pentosus , and only 31, coming exclusively from batches SSL, as Lactobacillus plantarum . The predominance of L.Â pentosus can be explained by their better adaptation to the olive fermentation environment with respect to L.Â plantarum selected strain inoculated in SSL fermentations. Using the culture independent approaches, differences in the fermentation processes were shown only during the first months of fermentation, and several Gram negative species, not frequently isolated in these ecosystems ( Thalassomonas agarivorans , non-fermentative bacteria, and the cyanobacteria Chroococcidiopsis ), were identified. Autochthonous starter SIE, compared to SSL, produced olives more similar, in sensory attributes, to the naturally fermented ones.",2017,Lwt - Food Science and Technology
The dimensions of ethical consumption: A qualitative study of how consumers construct their identity through consumption of ecological food in Sweden,Title: The dimensions of ethical consumption: A qualitative study of how consumers construct their identity through consumption of ecological food in Sweden Date of the Seminar: 1st of June 2015 Course: BUSN39 Degree project in Global Marketing Authors: Karoline Bergseng and Sofia Rudell Supervisor: Marcus Klasson,2015,
Dictionary based action video classification with action bank,"Classifying action videos became challenging problem in computer vision community. In this work, action videos are represented by dictionaries which are learned by online dictionary learning (ODL). Here, we have used two simple measures to classify action videos, reconstruction error and projection. Sparse approximation algorithm LASSO is used to reconstruct test video and reconstruction error is calculated for each of the dictionaries. To get another discriminative measure projection, the test vector is projected onto the atoms in the dictionary. Minimum reconstruction error and maximum projection give information regarding the action category of the test vector. With action bank as a feature vector, our best performance is 59.3% on UCF50 (benchmark is 57.9%), 97.7% on KTH (benchmark is 98.2%)and 23.63% on HMDB51 (benchmark is 26.9%).",2014,2014 19th International Conference on Digital Signal Processing
Nonlinear Function Estimation with Empirical Bayes and Approximate Message Passing,"Nonlinear function estimation is core to modern machine learning applications. In this paper, to perform nonlinear function estimation, we reduce a nonlinear inverse problem to a linear one using a polynomial kernel expansion. These kernels increase the feature set, and may result in poorly conditioned matrices. Nonetheless, we show several examples where the matrix in our linear inverse problem contains only mild linear correlations among columns. The coefficients vector is modeled within a Bayesian setting for which approximate message passing (AMP), an algorithmic framework for signal reconstruction, offers Bayes-optimal signal reconstruction quality. While the Bayesian setting limits the scope of our work, it is a first step toward estimation of real world nonlinear functions. The coefficients vector is estimated using two AMP-based approaches, a Bayesian one and empirical Bayes. Numerical results confirm that our AMP-based approaches learn the function better than LASSO, offering markedly lower error in predicting test data.",2019,"2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)"
A social basis for the development of primary males in a sex-changing fish,"An example of alternative male strategies is seen in diandric protogynous (female first) hermaphrodites, where individuals either mature directly as male (primary males) or first reproduce as female and then change sex to male (secondary males). In some sex-changing fishes, the testes of primary males appear anatomically similar to those of non-sex-changing species, whereas the testes of secondary males have anatomical evidence of their former ovarian function. Here, we provide evidence that in the bluehead wrasse, Thalassoma bifasciatum, these strikingly different male phenotypes arise from differences in the ontogenetic timing of environmental sex determination, timing that can be experimentally altered through changes in the social circumstances. Juveniles differentiated almost exclusively as females when reared in isolation, regardless of whether they were collected from a reef with a high proportion of primary males or from a reef with a low proportion of primary males. In contrast, one individual usually differentiated as a primary male when reared in groups of three. Our results indicate that primary males of the bluehead wrasse are an environmentally sensitive developmental strategy that has probably evolved in response to variation in the reproductive success of primary males in populations of different sizes.",2006,Proceedings of the Royal Society B: Biological Sciences
Alex Sweet's Texas: The Lighter Side of Lone Star History,"Table of Contents Acknowledgments Introduction Part One: The State La Salle in Texas The Texas Climate The Alamo The Texas Navy Immigration Swedes to the Sweet Land Agents The Old Veteran Lost Boundaries The Texas Rangers Portraits at the Capitol Part Two: Cities San Antonio Sidewalks Ditches of San Antonio The San Antonio River San Antonio Elections Austin and San Antonio Compared Houston as a Seaport Galveston Peddlers Born on the Island The Galveston Cotton Exchange Part Three: People Boys The Big Firecracker A Boyhood Memory The Texas Carrier Boy That Typical Texan General Sheridan, Texas, and Hell Lawyers Sweet in the Militia The Dentist Another Mystery Explained Houston Indians Ladies' Choice Part Four: Life Border Troubles Eighty-five Little Indians A Mexican Revolution Throwing the Lasso Guide Posts Mail Delivery Country Store Billboards The Stovepipe Hat Spoofing Good Works The Circus H.M.S. Pinafore An Oil Painting Christmas New Year's Day Calls Part Five: Natural Resources Northers Cattle The Chaparral Cock The Texas Red Ant The Tarantula The Horned Frog Mosquitoes The Centipede The Devil's Horse The Family Dog The Awful Coal Bug The Shark Tarpon and Redfish Parrots Chile con Carne Bibliography Index",1986,
Clinico-pathological and transcriptomic determinants of SLFN11 expression in invasive breast carcinoma,"SLFN11 is a putative DNA/RNA helicase we discovered as causally associated with sensitivity to DNA damaging agents, such as platinum salts, topoisomerase I and II inhibitors, and other alkylators in the NCI-60 panel of cancer cell lines [1]. Later, SLFN11 was identified as an early interferon response gene, in association with HIV infection [2]. Here we assessed SLFN11 determinants in a gene expression meta-set of 5,061 breast cancer patients annotated with clinical data and multigene signatures obtained with the package genefu [3]. By correlation analysis, we found 537 transcripts above the 95th percentile of Pearsonâ€™s coefficients with SLFN11, identifying â€œimmune responseâ€, â€œlymphocyte activationâ€, and â€œT cell activationâ€ as top Gene Ontology enriched processes [4]. Through multiple correspondence analysis, we discovered a subgroup of patients characterized by high SLFN11 levels, ER negativity, basal phenotype, elevated CD3D, STAT1 signature [5], and young age. Fitting a penalized maximum likelihood lasso regression model [6], we found a strong multivariable association of SLN11 with the stroma 1 and stroma 2 signatures [7,8], associated with basal cancer and response to chemotherapy in ER- tumors. Finally, using Cox proportional hazard regression, ER-, high proliferation, high SLFN11 patients undergoing chemotherapy treatment showed a significantly longer disease-free interval than other patient categories included in our model.",2015,Journal for Immunotherapy of Cancer
â€˜To Be To Be Toolâ€™,"'to Be to Be tool' Arthur Bradley, Originary Technicity: The Theory of Technology from Marx to Derrida, London, Palgrave Macmillan, 2011, 216pp; Â£50 hardbackDeceptively reduced to a trajectory 'from Marx to Derrida' in its subtitle, Arthur Bradley's timely study offers a self-styled 'critical genealogy of Derrida's theory of originary technicity' (p3), which he minimally defines as 'the empirico-transcendental condition of life itself ' (p14). This first comprehensive reconstruction of a Derrida-inspired notion first given conceptual centre stage in Beardsworth's 1996 study on Derrida and the Political takes us not only through Marx, Freud and Lacan, Heidegger, and Derrida, but also, in the last two chapters, Stiegler (Derrida's former pupil) and several trans-, post-, anti-humanist critics and embodiment theorists (Haraway, Hayles, De Landa, Hansen, Meillassoux). The book is divided into seven chapters, which draw a neat arc from 'Life' to 'Death', taking in such 'essential' aspects as labour, the psyche, Being, the Other, and time, each of which is aligned with one major thinker and/ or area of thinking (philosophy, psychoanalysis).From the first, introductory section, on the 'being-technical of life itself from its pre- human inception millions of years ago, to the final, more tentative scenarios looking beyond human finitude towards species extinction (Meillassoux) and cosmological death (Lyotard), Bradley consistently unfolds 'the aporia of originary technicity itself ', by tracking 'a residual anthropocentrism' (p19) or humanism even in those theories most driven by a desire to think technology-in-itself.Two-thousand years of philosophical repression of technics start with the ancient Greek opposition between phusis and tekhne, between a self-causing ('auto-matic') causa efficiens and an inert, instrumental prosthesis, to which may be added the more specifically Platonic distinction between anamnesis (living memory: primary, pure, self-present, technics-free) and hypomnesis (non-living technological supplement: derived, prosthetic, artefactual) which will provide a recurrent touchstone throughout.The gradual, yet irreversible growth of the machine metaphor, from Descartes through the eighteenth century, leads Bradley to his first major port of call: the dialectic relation between man and the instruments he employs to perform labour in Marx, Derrida's 'premier penseur de la technique' whose historical materialism is the first to propose a radical critique of the Aristotelian understanding of techne and to ontologise technology in his theory of labour (p27). However, in a second movement of the analysis, Marx's critique of capital is shown to risk 're-ontologising the human over and against the technical' (p28). Marx's new technological materialism never totally supplants an atavistic humanism glimpsed in his earlier writings, before the introduction of a mutual constitution of the human and the technical through the labour process in Marx's writings after the Paris manuscripts: man's enfranchisement from the instruments of production whose deployment by capital has resulted in his alienation or 'exteriorisation', is bought at the cost of the subsumption and internalisation of the machine, when a future communist humanity 'finally assumes the collective subject position of technological mastery' (p37), and what once was an ontological condition for technology 'is reduced to little more than a dialectical moment in the narrative of humanity's emancipation from technics' (p38). But at least technics in Marx's overall itinerary has shifted from a pros- thetic (Aristotelian) to an intra-thetic position (p40).With the fast-paced advent of new technologies and sciences (such as thermodynamics) comes an intensification of the analogy between the organic and the mechanical, begun by Descartes' body-as-clock in the Meditations, whose logical outcome can be found in Freud's comparison between the psyche (with its drives) and the machine, and specifically his conception of the psyche as a writing machine from his unfinished Project for a Scientific Psychology onwards. â€¦",2013,new formations: a journal of culture/theory/politics
Anti-tuberculosis lead molecules from natural products targeting Mycobacterium tuberculosis ClpC1,"Tuberculosis (TB) is a serious and potentially fatal disease caused by Mycobacterium tuberculosis (M. tb). The occurrence of multidrug-resistant (MDR) and extensively drug-resistant (XDR) M. tb is a significant public health concern because most of the anti-TB drugs that have been in use for over 40Â years are no longer effective for the treatment of these infections. Recently, new anti-TB lead compounds such as cyclomarin A, lassomycin, and ecumicin, which are cyclic peptides from actinomycetes, have shown potent anti-TB activity against MDR and XDR M. tb as well as drug-susceptible M. tb in vitro. The target molecule of these antibiotics is ClpC1, a protein that is essential for the growth of M. tb. In this review, we introduce the three anti-TB lead compounds as potential anti-TB therapeutic agents targeting ClpC1 and compare them with the existing anti-TB drugs approved by the US Food and Drug Administration.",2015,Journal of Industrial Microbiology & Biotechnology
On first-order algorithms for l1/nuclear norm minimization,"In the past decade, problems related to l1/nuclear norm minimization have attracted much attention in the signal processing, machine learning and optimization communities. In this paper, devoted to ï¿½ 1/nuclear norm minimization as â€˜optimization beastsâ€™, we give a detailed description of two attractive first-order optimization techniques for solving problems of this type. The first one, aimed primarily at lasso-type problems, comprises fast gradient methods applied to composite minimization formulations. The second approach, aimed at Dantzig-selector-type problems, utilizes saddle-point first-order algorithms and reformulation of the problem of interest as a generalized bilinear saddle-point problem. For both approaches, we give complete and detailed complexity analyses and discuss the application domains.",2013,Acta Numer.
The Real: From Ancestrality to Actuality,"This chapter focuses on the philosophical Real vis-a-vis the Lacanian Real. It proposes a (weakly) transcendental framework to comprise the Real of Lacanian subjectivity within the anti-correlationist philosophy of Quentin Meillassoux. In doing so, I initially rely on a critique towards Meillassouxâ€™ account of (modern) science and argue that it is with the Lacanian reactualization of Freudism that we are really able to get rid of any substantialist or unscientific view on subjectivity itself. That is, I try to demonstrate how psychoanalysis radicalizes the anti-correlationist stance of contemporary ontologies by placing the subject in between the (self)reproductive automaton of language and its Truth. This chapter thus pinpoints the image of Lacan as a realist qua materialist thinker. However, contra Meillassoux, the theoretical emerging picture is that of a holed-realism which is able to give an account of subjectivity as a vibratile place of incompleteness.",2019,
"Science, Realism and Correlationism. A Phenomenological Critique of Meillassoux' Argument from Ancestrality","Quentin Meillassoux has recently launched a sweeping attack against â€˜correlationismâ€™. Correlationism is an umbrella term for any philosophical system that is based on â€˜the idea [that] we only ever have access to the correlation between thinking and being, and never to either term considered apart from the otherâ€™ (Meillassoux 2012: 5). Thus construed, Meillassoux' critique is indeed a sweeping one: It comprises major parts of the philosophical tradition since Kant, both in its more continental and in its more analytical outlooks. In light of this critique, the aim of this paper is twofold: On the one hand, I shall defend phenomenology against Meillassoux' main argument, the â€˜argument from ancestralityâ€™. On the other hand, I will argue that this argument, albeit unsuccessful in its original form, can be modified to pose a more serious threat. Although this modified version can also be circumvented, it forces phenomenologists to clarify their stance towards the natural sciences.",2017,European Journal of Philosophy
Bayesian neural network priors at the level of units,"We investigate deep Bayesian neural networks with Gaussian priors on the weights and ReLU-like nonlinearities, shedding light on novel sparsity-inducing mechanisms at the level of the units of the network. Bayesian neural networks with Gaussian priors are well known to induce the weight decay penalty on the weights. In contrast, our result indicates a more elaborate regularization scheme at the level of the units, ranging from convex penalties for the first two layers-L 2 regularization for the first and Lasso for the second-to non convex penalties for deeper layers. Thus, although weight decay does not allow for the weights to be set exactly to zero, sparse solutions tend to be selected for the units from the second layer onward. This result provides new theoretical insight on deep Bayesian neural networks, underpinning their natural shrinkage properties and practical potential.",2018,
