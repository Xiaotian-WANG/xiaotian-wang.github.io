title,abstract,year,journal
A Tutorial on Using the R Package FLLat,"This document provides a brief tutorial on using the FLLat package, which implements the Fused Lasso Latent Feature (FLLat) model (Nowak and others, 2011). The FLLat model is designed to identify regions of copy number variation (CNV) in multi-sample aCGH data. In particular, it takes advantage of any similarities shared among samples while maintaining the ability to identify any potential heterogeneity. The model is described in more detail below.",2017,
Age And Authority: Adult-Child Relations During the Twentieth Century in the United States,"Lassonde, using his own meticulous research on the twentieth century Catholic Church and the Little League, sketches the way changes in these institutions inform us about shifts in attitudes toward authority in the larger culture. In addition to the essay's particular insights, it also offers a model of how the study of youth can contribute to intellectual and social history altogether.-M.S.",2007,The Journal of the History of Childhood and Youth
"P3.399 Who Are Regular Sex Partners of Female Sex Workers in Bobo-Dioulasso, Burkina Faso?","Background In Burkina Faso, female sex workers (fsw) remain a core group for HIV transmission. Unfortunately fsw use condoms less consistently with their regular sex partners (RSP). Yet these RSP are not taken into account in interventions. Knowledge of their characteristics will help develop strategies to involve them in the fight against HIV. This study aimed to describe the sociodemographic and behavioural characteristics of RSP of fsw in Bobo-Dioulasso. Methods The study included baseline data of the Yerelon cohort (fsw cohort) formed between December 2003 and March 2011. A standardised questionnaire was administered face to face to fsw to gather information on their RSP. Data were entered into Access and analysed with stata11. Results We included 918 women (seaters, roamers, bar waitresses, sellers, cabarets and others). The median number of RSP pers fsw was 2 (range 0â€“5). These RSP were considered by the fsw as â€œboyfriendsâ€ (52.9%) and the relationship lasted less than a year (39.2%). They were of unknown age (62.5%), single (52.7%), national of Burkina Faso (94.9%), residing in Bobo (89.3%), travelling often (33.0%), using condoms consistently (28.4%). RSP of fsw had secondary or higher level of education (55.2%), and another regular sex partners (68.2%). Conclusion In relation to these characteristics, we are all concerned. The RSP approach will be difficult. Due to their position as â€œbridge groupâ€ between fsw and the general population, a qualitative investigation is necessary with fsw to develop a targeted strategic approach.",2013,Sexually Transmitted Infections
Integration of Network-Based Biological Knowledge With White Matter Features in Preterm Infants Using the Graph-Guided Group Lasso,"Abstract The effect of prematurity on normal developmental programs of white and gray matter as evaluated with magnetic resonance imaging indicates global changes in white and gray matter with functional implications. We have previously identified an association between lipids and diffusion tensor imaging features in preterm infants, both through a candidate gene approach and a data-driven statistical genetics method. Here we apply a penalized linear regression model, the graph-guided group lasso (GGGL), that can utilize prior knowledge and select single nucleotide polymorphisms (SNPs) within functionally related genes associated with the trait. GGGL incorporates prior information from SNP-gene mapping as well as from the gene functional interaction network to guide variable selection.",2018,
MicroRNA expression profiles associated with pancreatic adenocarcinoma and ampullary adenocarcinoma,"MicroRNAs have potential as diagnostic cancer biomarkers. The aim of this study was (1) to define microRNA expression patterns in formalin-fixed parafin-embedded tissue from pancreatic ductal adenocarcinoma, ampullary adenocarcinoma, normal pancreas and chronic pancreatitis without using micro-dissection and (2) to discover new diagnostic microRNAs and combinations of microRNAs in cancer tissue. The expression of 664 microRNAs in tissue from 170 pancreatic adenocarcinomas and 107 ampullary adenocarcinomas were analyzed using a commercial microRNA assay. Results were compared with chronic pancreatitis, normal pancreas and duodenal adenocarcinoma. In all, 43 microRNAs had higher and 41 microRNAs reduced expression in pancreatic cancer compared with normal pancreas. In all, 32 microRNAs were differently expressed in pancreatic adenocarcinoma compared with chronic pancreatitis (17 higher; 15 reduced). Several of these microRNAs have not before been related to diagnosis of pancreatic cancer (eg, miR-492, miR-614, miR-622). MiR-614, miR-492, miR-622, miR-135b* and miR-196 were most differently expressed. MicroRNA profiles of pancreatic and ampullary adenocarcinomas were correlated (0.990). MicroRNA expression profiles for pancreatic cancer described in the literature were consistent with our findings, and the microRNA profile for pancreatic adenocarcinoma (miR-196bâ€“miR-217) was validated. We identified a more significant expression profile, the difference between miR-411 and miR-198 (P=2.06 Ã— 10âˆ’54) and a diagnostic LASSO classifier using 19 microRNAs (sensitivity 98.5%; positive predictive value 97.8%; accuracy 97.0%). We also identified microRNA profiles to subclassify ampullary adenocarcinomas into pancreatobiliary or intestinal type. In conclusion, we found that combinations of two microRNAs could roughly separate neoplastic from non-neoplastic samples. A diagnostic 19 microRNA classifier was constructed which without micro-dissection could discriminate pancreatic and ampullary adenocarcinomas from chronic pancreatitis and normal pancreas with high sensitivity and accuracy. Ongoing prospective studies will evaluate if these microRNA profiles are useful on fine-needle biopsies for early diagnosis of pancreatic cancer.",2012,Modern Pathology
Risk assessment model for invasive breast cancer in Hong Kong women,"AbstractNo risk assessment tool is available for identifying high risk population of breast cancer (BCa) in Hong Kong. A caseâ€“control study including 918 BCa cases and 923 controls was used to develop the risk assessment model among Hong Kong Chinese women.Each participant received an in-depth interview to obtain their lifestyle and environmental risk factors. Least absolute shrinkage and selection operator (LASSO) selection model was used to select the optimal risk factors (LASSO-model). A risk score system was constructed to evaluate the cumulative effects of selected factors. Bootstrap simulation was used to test the internal validation of the model. Model performance was evaluated by receiver-operator characteristic curves and the area under the curve (AUC).Age, number of parity, number of BCa cases in 1st-degree relatives, exposure to light at night, and sleep quality were the common risk factors for all women. Alcohol drinking was included for premenopausal women; body mass index, age at menarche, age at 1st give birth, breast feeding, using of oral contraceptive, hormone replacement treatment, and history of benign breast diseases were included for postmenopausal women. The AUCs were 0.640 (95% CI, 0.598â€“0.681) and 0.655 (95% CI, 0.621â€“0.653) for pre- and postmenopausal women, respectively. Further subgroup evaluation revealed that the model performance was better for women aged 50 to 70 years or ER-positive.This BCa risk assessment tool in Hong Kong Chinese women based on LASSO selection is promising, which shows a slightly higher discriminative accuracy than those developed in other populations.",2016,Medicine
Selection of Radiomics Features based on their Reproducibility,"Dimensionality reduction is key to alleviate machine learning artifacts in clinical applications with Small Sample Size (SSS) unbalanced datasets. Existing methods rely on either the probabilistic distribution of training data or the discriminant power of the reduced space, disregarding the impact of repeatability and uncertainty in features.In the present study is proposed the use of reproducibility of radiomics features to select features with high inter-class correlation coefficient (ICC). The reproducibility includes the variability introduced in the image acquisition, like medical scans acquisition parameters and convolution kernels, that affects intensity-based features and tumor annotations made by physicians, that influences morphological descriptors of the lesion.For the reproducibility of radiomics features three studies were conducted on cases collected at Vall Hebron Oncology Institute (VHIO) on responders to oncology treatment. The studies focused on the variability due to the convolution kernel, image acquisition parameters, and the inter-observer lesion identification. The features selected were those features with a ICC higher than 0.7 in the three studies.The selected features based on reproducibility were evaluated for lesion malignancy classification using a different database. Results show better performance compared to several state-of-the-art methods including Principal Component Analysis (PCA), Kernel Discriminant Analysis via QR decomposition (KDAQR), LASSO, and an own built Convolutional Neural Network.",2019,2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)
"ÐœÐµÑ‚Ð¾Ð´Ð¾Ð»Ð¾Ð³Ð¸Ñ Ð­ÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ñ… ÐžÑ†ÐµÐ½Ð¾Ðº Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð›ÐµÑ‡ÐµÐ½Ð¸Ñ Ð’ Ð—Ð´Ñ€Ð°Ð²Ð½Ð¸Ñ†Ð°Ñ… Ð›Ð°Ð·Ð°Ñ€ÐµÐ²ÑÐºÐ¾Ð¹ Ð ÐµÐºÑ€ÐµÐ°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ð¹ Ð—Ð¾Ð½Ñ‹ Ð Ð¾ÑÑÐ¸Ð¹ÑÐºÐ¾Ð³Ð¾ ÐŸÑ€Ð¸Ñ‡ÐµÑ€Ð½Ð¾Ð¼Ð¾Ñ€ÑŒÑ Ð”ÐµÑ‚ÐµÐ¹, Ð¡Ñ‚Ñ€Ð°Ð´Ð°ÑŽÑ‰Ð¸Ñ… Ð¡Ð»Ð¸Ð·Ð¸ÑÑ‚Ð¾-Ð³Ð½Ð¾Ð¹Ð½Ñ‹Ð¼Ð¸ Ð¥Ñ€Ð¾Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼Ð¸ Ð‘Ñ€Ð¾Ð½Ñ…Ð¸Ñ‚Ð°Ð¼Ð¸",The article presents the author's approaches to indication of thalassotherapy which ensure really positive therapeutic effect at children with mucilaginous and purulent chronic bronchitis.,2011,
Forecasting Temperature in a Smart Home with Segmented Linear Regression,"Abstract The efficiency of heating, ventilation and cooling operations in a home are improved when they are controlled by a system that takes into account an accurate forecast of temperature in the house. Temperature forecasts are informed by data from sensors that report on activities and conditions in and around the home. Using publicly available data, we apply linear models based on LASSO regression and our recently developled MIDFEL LASSO regression. These models take into account the past 24 hours of the sensorsâ€™ data. We have previously identified the most influential sensors in a forecast over the next 48 hours. In this paper, we compute 48 separate one-hour forecast and for each hour we identify the sensors that are most influential. This improves forecast accuracy and reveals which sensors are most valuable to install.",2019,Procedia Computer Science
Penalized and Shrinkage Estimation in the Cox Proportional Hazards Model,"This article considers the shrinkage estimation procedure in the Cox's proportional hazards regression model when it is suspected that some of the parameters may be restricted to a subspace. We have developed the statistical properties of the shrinkage estimators including asymptotic distributional biases and risks. The shrinkage estimators have much higher relative efficiency than the classical estimator, furthermore, we consider two penalty estimatorsâ€”the LASSO and adaptive LASSOâ€”and compare their relative performance with that of the shrinkage estimators numerically. A Monte Carlo simulation experiment is conducted for different combinations of irrelevant predictors and the performance of each estimator is evaluated in terms of simulated mean squared error. Simulation study shows that the shrinkage estimators are comparable to the penalty estimators when the number of irrelevant predictors in the model is relatively large. The shrinkage and penalty methods are applied to two real data sets to illustrate the usefulness of the procedures in practice.",2014,Communications in Statistics - Theory and Methods
High-dimensional Linear Regression for Dependent Observations with Application to Nowcasting,"In the last few years, an extensive literature has been focused on the $\ell_1$ penalized least squares (Lasso) estimators of high dimensional linear regression when the number of covariates $p$ is considerably larger than the sample size $n$. However, there is limited attention paid to the properties of the estimators when the errors or/and the covariates are serially dependent. In this study, we investigate the theoretical properties of the Lasso estimators for linear regression with random design under serially dependent and/or non-sub-Gaussian errors and covariates. In contrast to the traditional case in which the errors are i.i.d and have finite exponential moments, we show that $p$ can at most be a power of $n$ if the errors have only polynomial moments. In addition, the rate of convergence becomes slower due to the serial dependencies in errors and the covariates. We also consider sign consistency for model selection via Lasso when there are serial correlations in the errors or the covariates or both. Adopting the framework of functional dependence measure, we provide a detailed description on how the rates of convergence and the selection consistencies of the estimators depend on the dependence measures and moment conditions of the errors and the covariates. Simulation results show that Lasso regression can be substantially more powerful than the mixed frequency data sampling regression (MIDAS) in the presence of irrelevant variables. We apply the results obtained for the Lasso method to nowcasting mixing frequency data in which serially correlated errors and a large number of covariates are common. In real examples, the Lasso procedure outperforms the MIDAS in both forecasting and nowcasting.",2017,arXiv: Statistics Theory
Uma experiÃªncia em EaD: a construÃ§Ã£o de uma rede virtual colaborativa no projeto escolas sustentÃ¡veis,"RESUMO O presente artigo tem comoprincipal objetivo apresentar os resultados obtidos com a utilizacao, no â€œProjeto Escolas Sustentaveisâ€, de uma redevirtual e colaborativa de escolas para a divulgacao e compartilhamento depraticas ambientais sustentaveis. O â€œProjeto EscolasSustentaveisâ€, aplicado em trinta e quatro unidades de educacao integral domunicipio de Curitiba, durante o ano de 2010, fez uso de uma rede decaracteristica mundial, o Ning. Trata-se de uma plataforma online, utilizadatipicamente em atividades educacionais, e que permite a criacao de redessociais individualizadas e o compartilhamento de interesses especificos. Palavras-chave :Educacao; Sustentabilidade; Redes VirtuaisColaborativas; Escolas Sustentaveis. ABSTRACT The present article has theobjective to present the resultsobtained from the use in the ""SustainableSchools Project"", a virtual networkand collaborative schools for the dissemination and sharing of sustainable environmental practices. The""Sustainable Schools Project"",implemented in thirty-four unitsof education of the city of Curitiba, in the year 2010,made â€‹â€‹use of a network feature world Ning.It is an online platform, typically used in educationalactivities, and allows thecreation of individualized socialnetworking and sharing interests. Keywords : Education, Sustainability, Virtual Collaborative Networks; Sustainable Schools. RESUMEN El presente articulo tiene como principal objetivo presentar losresultados obtenidos con el uso, en el ""Proyecto de Escuelassostenibles"", de una red virtual y colaborativa de escuelas para ladifusion y el intercambio de practicas medioambientales sostenibles. Elâ€œProyecto Escuelas Sostenibles"", aplicado en treinta y cuatro unidades deeducacion integral del municipio de Curitiba, durante el ano de 2010, hizo usode una red de caracter mundial, el Ning. Es una plataforma en linea, que seutiliza normalmente en las actividades educativas, y que permite la creacion deredes sociales individualizadas y cambios de intereses especificos. Palabras-clave: Educacion; Sostenibilidad; Redes Virtuales Colaborativas; EscuelasSostenibles.",2013,
An experimental and computational investigation of spontaneous lasso formation in microcin J25.,"The antimicrobial peptide microcin J25 (MccJ25) is posttranslationally matured from a linear preprotein into its native lasso conformation by two enzymes. One of these enzymes cleaves the preprotein and the second enzyme installs the requisite isopeptide bond to establish the lasso structure. Analysis of a mimic of MccJ25 that can be cyclized without the influence of the maturation enzymes suggests that MccJ25 does not spontaneously adopt a near-lasso structure. In addition, we conducted atomistically detailed replica-exchange molecular dynamics simulations of pro-microcin J25 (pro-MccJ25), the 21-residue uncyclized analog of MccJ25, to determine the conformational ensemble explored in the absence of the leader sequence or maturation enzymes. We applied a nonlinear dimensionality reduction technique known as the diffusion map to the simulation trajectories to extract two global order parameters describing the fundamental dynamical motions of the system, and identify three distinct pathways. One path corresponds to the spontaneous adoption of a left-handed lasso, in which the N-terminus wraps around the C-terminus in the opposite sense to the right-handed topology of native MccJ25. Our computational and experimental results suggest a role for the MccJ25 leader sequence and/or its maturation enzymes in facilitating the adoption of the right-handed topology.",2010,Biophysical journal
"Habitat models for juvenile pleuronectids around Kodiak Island, A1aska*","-Juveniles offour species of pleuronectid flatfishes were abundant in bays and nearshore areas around Kodiak Island, Alaska, during August 1991 and 1992. The four most abundant species of juvenile (age-O or age-1) flatfishes were rock sole (Pleuronectes bilineatus). flathead sole (Hippoglossoides elassodonJ, Pacific halibut IHippoglossus stenolepisJ. and yellowfin sole (Pleuronectes asper). These species appeared to share nursery areas; however, physical characteristics ofthe nursery areas occupied by each species limited the amount of true overlap among species. Tree-based regression of catch-per-unit-of-effort data on physical parameters was used to refine conceptual models of species distribution, which were originally based only on 1991 data. Threshold values of the physical parameters were specified that best discriminated among stations with different abundances. Highest abundances of age-O rock sole were found on sand or muddy sand at temperatures greater than 8.7Â°C. as well as on other mixed sand stations less than 28 m deep. Ageoflathead sole were most abundant at temperatures less than 8.9Â°C and on mixed mud substrates. At warmer temperatures, abundances were high only if the depth was greater than 48 m, regardless ofsediment type. Age-O Pacific halibut were most abundant in depths less than 40 m at sites more than 2.9 km outside the mouths of bays. Inside bays, halibut were found in lower abundances in water over 9.0Â°C and on sediments containing both sand and mud. Age-1 yellowfin sole were always found in depths less than 28 m on mixed mud substrates. They were usually found within bays, with highest abundances at heads oflarge bays more than 32 km from the bay mouth. These four most abundant flatfishes therefore appeared to partition the available habitat in ways that minimized resource competition. Manuscript accepted 26 February 1997. Fishery Bulletin 95:504-520 (1997). Brenda L. Norcross* *",1997,
"Discussion: "" a Significance Test for the Lasso "" 1","Professors Lockhart, Taylor, Tibshirani and Tibshirani are to be congratulated for their innovative and valuable contribution to the important and timely problem of testing the significance of covariates for the Lasso. Since the invention of the Lasso in Tibshirani (1996) for variable selection, there has been a huge growing literature devoted to its theory and implementation, its extensions to various model settings and different variants and developing more general regularization methods. Most of existing studies have focused on the prediction, estimation and variable selection properties ranging from consistency in prediction and estimation to consistency in model selection in terms of recovery of the true underlying sparse model. The problem of deriving the asymptotic distributions for regularized estimators, as the global or computable solutions, in high dimensions is relatively less well studied. How to develop efficient significance testing procedures for the regularization methods is particularly important since in real applications one would like to assess the significance of selected covariates with their p-values. Such p-values are also crucial for multiple comparisons in testing the significance of a large number of covariates simultaneously. In contrast to the use of some resampling or data splitting techniques for evaluating the significance, in the present paper Lockhart, Taylor, Tibshirani and Tibshirani propose a novel powerful yet simple covariance test statistic Tk for testing the significance of the covariate Xj that enters the model at the kth step of the piecewise linear Lasso solution path in the linear regression model setting. Such a test statistic is shown to have an exact Exp(1) asymptotic null distribution in the case of orthonormal design matrix and the case of k = 1 (i.e., the global null with zero true regression coefficient vector) for general design matrix. In the general case, the Exp(1) distribution provides a conservative asymptotic null distribution. The significance test for the Lasso proposed in the paper is elegant thanks to its simplicity and theoretical guarantees in high dimensions. We appreciate the opportunity to comment on several aspects of this paper. In particular, our discussion will focus on four issues: (1) alternative test statistics, (2) the event B and generalized irrepresentable conditions, (3) model misspecification, and (4) more general regularization methods.",2014,
L' Istituto Nazionale di Studi Talassografici e le ricerche in Adriatico,"Summary The 'Istituto Nazionale di Studi Talassografici' of the National Research Council is the heir of the former 'Comitato Talassografico' which was founded on 1909. The aim of this Institution is to promote thalassographical investigations on our seas. Its offices and laboratories are settling in Venice. There is a programme of research to be carried out with the help of ships adequate'y equipped. A first cruise took place in the summer of 1955, in the Adriatic sea, with a vessel provided by the Navy. It was effected with the cooperation of the 'Istituto Talassografico' of Trieste, whose head is Professor Picotti. Two oceanographers from the Oceanographical Institut, Goteborg, Dr. Kullenberg and Dr. Jerlow, have taken part to the cruise. The data and materials collected are being worked out.",1956,Italian Journal of Zoology
"Discovery of Short, 3'.Cholesterol-modffied DNA Duplexes with Unique Antitumor","A new classof modifiedoligodesxynucleofides withunique,selective cytotoxic properties has been discovered. Self-complementary, 3'-cboles terol-modified oligodeoxynucleotides caused morphology changes and death in certain cancer cell lines, whereas other cell lines were unaffected. Susceptible cells were killed in a dose-dependent manner at submicromo lar concentrations. Optimum potency was exhibited by phosphodiester duplexes approximately 10 base pairs in length, and base composition was Important taily in the context ofduplex stability. Pbospborothloateanalogues were@@ Althoughthe molecularmechaninn ofaction ofthese unique a@snposmds is not yet known, they offer potential app&ations in cancer therapy and In studies ofcell death. In addition, the path toward eluddation of the @nicture-bosed biologicalactivity of these oligonucleotidesshould be especiallyInstructivefor researchersstudyingsequence-specific",1994,
"Societal changes in the Hellenistic, Roman and early Byzantine periods. Results from the Sagalassos Territorial Archaeological Survey 2008 (southwest Turkey)","This contribution discusses the Hellenistic, Roman and early Byzantine pottery collected during archaeological survey in the Bereket valley (territory of ancient Sagalassos, southwest Turkey). This collection contains both pottery imported from as yet unknown production centres and wares produced at the Pottersâ€™ Quarter of Sagalassos. Changes in the proportions of pottery produced at Sagalassos and that produced at other locations become visible in the fourth century AD material and reflect the evolving relationship between the peripheral valley of Bereket and the regional centre of Sagalassos. Yet, the undiminished quantity of pottery collected suggests that human activity continued without significant changes in habitation density. However, pollen cores from the same valley show that at more or less the same time crop cultivation diminished and was largely replaced by pastoralism. This shift occured at a time when climatic conditions had become more favourable for crop cultivation. A somewhat similar decrease in crop cultivation is also observed in Gravgaz marsh. In both valleys, this shift occured about 300 years earlier than in the rest of the territory of Sagalassos. Although the reasons for these changes cannot be determined on the basis of the study of survey pottery alone, the results presented show the importance of intensive survey and the study of peripheral areas for understanding interregional interaction patterns.",2013,Anatolian studies
Isolation and identification of two strains of pathogenic bacteria and their effects on the volatile metabolites of Gracilariopsis lemaneiformis (Rhodophyta),"Apical necrosis is a widely distributed disease in the culture of the marine agar-producing alga, Gracilariopsis lemaneiformis. In this study, 16 strains of epiphytic bacteria were isolated from the tip bleaching parts of G. lemaneiformis; of the 16 strains, two strains could induce healthy algal tips to become necrotic. They were identified as Thalassospira sp. and Vibrio parahaemolyticus by 16S rDNA sequence analysis and biochemical characterization. Using solid phase microextraction and gas chromatographyâ€“mass spectrometry, the variation of volatile metabolites of G. lemaneiformis infected by these two strains of pathogenic bacteria was analyzed. The results showed that E-2-nonenal and 1-octen-3-one differed very significantly (Pâ€‰<â€‰0.01) between the Thalassospira infected group and the control group, while trichloromethane, 3-methyl butanal, benzaldehyde, and E-2-decenal differed significantly (Pâ€‰<â€‰0.05). The difference of 1-octen-3-one, benzaldehyde, and E-2-nonenal between the V. parahaemolyticus infected group and the control group was very significant (Pâ€‰<â€‰0.01), while 3-methyl butanal and octanal were significantly different (Pâ€‰<â€‰0.05). In conclusion, 1-octen-3-one, E-2-nonenal, and benzaldehyde might be the characteristic metabolites for the pathogenic infection and could be used as biomarkers for the disease prevention of G. lemaneiformis.",2011,Journal of Applied Phycology
Prediction Model of Cardiac Risk for Dental Extraction in Elderly Patients with Cardiovascular Diseases,"Background: With the rapidly increasing population of elderly people, dental extraction in elderly individuals with cardiovascular diseases (CVDs) has become quite common. The issue of how to assure the safety of elderly patients with CVDs undergoing dental extraction has perplexed dentists and internists for many years. And it is important to derive an appropriate risk prediction tool for this population. Objectives: The aim of this retrospective, observational study was to establish and validate a prediction model based on the random forest (RF) algorithm for the risk of cardiac complications of dental extraction in elderly patients with CVDs. Methods: Between August 2017 and May 2018, a total of 603 patients who fulfilled the inclusion criteria were used to create a training set. An independent test set contained 230 patients between June 2018 and July 2018. Data regarding clinical parameters, laboratory tests, clinical examinations before dental extraction, and 1-week follow-up were retrieved. Predictors were identified by using logistic regression (LR) with penalized LASSO (least absolute shrinkage and selection operator) variable selection. Then, a prediction model was constructed based on the RF algorithm by using a 5-fold cross-validation method. Results: The training set, based on 603 participants, including 282 men and 321 women, had an average participant age of 72.38 Â± 8.31 years. Using feature selection methods, 11 predictors for risk of cardiac complications were screened out. When the RF model was constructed, its overall classification accuracy was 0.82 at the optimal cutoff value of 18.5%. In comparison to the LR model, the RF model showed a superior predictive performance. The AUROC (area under the receiver operating characteristic curve) scores of the RF and LR models were 0.83 and 0.80, respectively, in the independent test set. The AUPRC (area under the precision-recall curve) scores of the RF and LR models were 0.56 and 0.35, respectively, in the independent test set. Conclusion: The RF-based prediction model is expected to be applicable for preoperative clinical assessment for preventing cardiac complications in elderly patients with CVDs undergoing dental extraction. The findings may aid physicians and dentists in making more informed recommendations to prevent cardiac complications in this patient population.",2019,Gerontology
New estimation methods for high dimensional inverse covariance matrices,"The estimation of inverse covariance matrix (also known as precision matrix) is an important problem in various research fields and methodologies, especially in the current age of high-dimensional data abundance. In addition, the classical estimation methods are no longer stable and applicable in high dimensional settings, i.e., when the dimensionality has the same order as the sample size or is much larger. This thesis focuses on the estimation of the precision matrices as well as their applications. In particular, the goal of this thesis is to develop and analyse accurate precision matrix estimators for problems in high-dimensional settings. Moreover, the proposed precision matrix estimators should emulate the existing prominent estimators in terms of different statistical measures without being computationally more extensive. This thesis is comprised of two articles on estimation of precision matrices in high dimensional settings. In what follows, we summarize the main contributions of this thesis. First, we propose a simple improvement of the popular Graphical LASSO (GLASSO) framework that is able to attain better statistical performance without increasing signi cantly the computational cost. The proposed improvement is based on computing a root of the sample covariance matrix to reduce the spread of the associated eigenvalues. Through extensive numerical results, using both simulated and real datasets, we show that the proposed modiffication improves the GLASSO procedure. Our results reveal that the square-root improvement can be a reasonable choice in practice. Second, we introduce two adaptive extensions of the recently proposed l1 norm penalized D-trace loss minimization method. It is well known that the l1 norm penalization often fails to control the bias of the obtained estimator because of its overestimation behavior. Our proposed extensions are based on the adaptive and weighted adaptive thresholding operators and intend to diminish the bias produced by the l1 penalty term. We present the algorithm for solving our proposed approaches, which is based on the alternating direction method. Extensive numerical results, using both simulated and real datasets, show the advantage of our proposed estimators.",2016,
Nocturnal and Feeding Behavior of the Labrid Fish Xyrichthys psittacus,"IT IS well known that a variety of labrid fishes spend the night buried in sand. This is known from first-hand observations on the genera Halichoeres, Thalassoma and Xyrichthys. They exist under a clear handicap and poorly in containers which do not have a depth of sand at the bottom under which they may spend the night. The behavior of the razorfish, Xyrichthys psittacus (Linnaeus), in the sea has been described by Longley, (in Longley and Hildebrand, 1941: 200) as follows:",1951,Copeia
Inferencia de edad y sexo de usuarios de facebook basado en las actualizaciones de Estado,"The use of Social Networks Sites has grown exponentially in the last decade. People
are sharing online (publicly or in private) their social and romantic interactions, expressing their likes and dislikes, etc. Among many Social Networks Sites, Facebook
is the most popular one. Since active and more connected users tend to adopt a private profile, some demographic information is not available (at least in a
public way). Knowing hidden demographic attributes is useful in many fields, e.g., marketing campaigns. In this study we predict age and gender attributes of Facebook
users relying on their status updates only. As baseline we replicated the predictive model based on language from the Open Vocabulary Approach which uses a set of
features based on the actual communication among users. In addition, based on such a set of linguistic features, we analyzed the performance of a new document
representation called Second Order Representation in the domain of Facebook. Second Order Representation has been proposed to deal with two problems of the Bag Of
Terms representation (used in the Open Vocabulary Approach): terms considered independents of the classes and its high dimensionality and sparsity. Second Order
Representation has been introduced in the field of the Author Profiling in the domain of microblogging and social networks. In order to investigate the effect of reducing
the feature dimension, we experimented with 2-test as term selection method for both the predictive model of the Open Vocabulary Approach and the predictive
model of the Second Order Representation. Our results show that it is possible to infer gender with an accuracy of 0.908 combining the Open Vocabulary Approach to
extract linguistic features and 2-test as term selection method which reduces the time of processing and the feature dimension to only 10, 000 highly discriminative
terms. On age inferring, our results (R = 0.792) show that we can beat the baseline (R = 0.791) by using only 10,000 highly discriminative terms for representing users
with Bag Of Terms and using lasso regression, which is a kind of feature reduction technique to reduce the number of terms used to perform regression. Finally, Second
Order Representation did not beat the base line model giving an accuracy of 0.816 in gender prediction and a square-root of the coefficient of determination of 0.782
in age prediction by using a subset of features of only 15,000 highly discriminative terms.",2015,
When Does the First Spurious Variable Get Selected by Sequential Regression Procedures,"Applied statisticians use sequential regression procedures to produce a ranking of explanatory variables and, in settings of low correlations between variables and strong true effect sizes, expect that variables at the very top of this ranking are truly relevant to the response. In a regime of certain sparsity levels, however, three examples of sequential procedures--forward stepwise, the lasso, and least angle regression--are shown to include the first spurious variable unexpectedly early. We derive a rigorous, sharp prediction of the rank of the first spurious variable for these three procedures, demonstrating that the first spurious variable occurs earlier and earlier as the regression coefficients become denser. This counterintuitive phenomenon persists for statistically independent Gaussian random designs and an arbitrarily large magnitude of the true effects. We gain a better understanding of the phenomenon by identifying the underlying cause and then leverage the insights to introduce a simple visualization tool termed the double-ranking diagram to improve on sequential methods. As a byproduct of these findings, we obtain the first provable result certifying the exact equivalence between the lasso and least angle regression in the early stages of solution paths beyond orthogonal designs. This equivalence can seamlessly carry over many important model selection results concerning the lasso to least angle regression.",2017,arXiv: Statistics Theory
1. Constructing the Past of Early Modern Naples: Sources and Historiography,This chapter identifies two separate historiographies that have dominated the study of Neapolitan history from the late 1960s: the internalist (a Crocean liberal history revivified by Giuseppe Galasso) and the externalist (a Marxian history often inspired by Gramscian analysis identified with Rosario Villari). Both of these historiographical approaches are generally in agreement on existing sources and central topics and processes. A summary of the dominant political model should return us to the primary sources of Neapolitan history. The main point of the recent historiography on Naples underlines the need to avoid anachronistic teleologies and overdetermined models as the basis for making false comparisons. Keywords:Crocean liberal history; Early Modern Naples; historiography; Marxian history; political model,2013,
Learning with Optimal Interpolation Norms: Properties and Algorithms,"We analyze a class of norms defined via an optimal interpolation problem involving the composition of norms and a linear operator. This framework encompasses a number of norms which have been used as regularizers in machine learning and statistics. In particular, these include the latent group lasso, the overlapping group lasso, and certain norms used for learning tensors. We establish basic properties of this class of regularizers and we provide the dual norm. We present a novel stochastic block-coordinate version of the Douglas-Rachford algorithm to solve regularization problems with these regularizers. A unique feature of the algorithm is that it yields iterates that converge to a solution in the case of non smooth losses and random block updates. Finally, we present numerical experiments on the latent group lasso.",2016,arXiv: Optimization and Control
Evaluation of Multiple Kernel Learning Algorithms for Cropmapping Using Satellite Image Time-series Data,"Abstract. Crop mapping through classification of Satellite Image Time-Series (SITS) data can provide very valuable information for several agricultural applications, such as crop monitoring, yield estimation, and crop inventory. However, the SITS data classification is not straightforward. Because different images of a SITS data have different levels of information regarding the classification problems. Moreover, the SITS data is a four-dimensional data that cannot be classified using the conventional classification algorithms. To address these issues in this paper, we presented a classification strategy based on Multiple Kernel Learning (MKL) algorithms for SITS data classification. In this strategy, initially different kernels are constructed from different images of the SITS data and then they are combined into a composite kernel using the MKL algorithms. The composite kernel, once constructed, can be used for the classification of the data using the kernel-based classification algorithms. We compared the computational time and the classification performances of the proposed classification strategy using different MKL algorithms for the purpose of crop mapping. The considered MKL algorithms are: MKL-Sum, SimpleMKL, LPMKL and Group-Lasso MKL algorithms. The experimental tests of the proposed strategy on two SITS data sets, acquired by SPOT satellite sensors, showed that this strategy was able to provide better performances when compared to the standard classification algorithm. The results also showed that the optimization method of the used MKL algorithms affects both the computational time and classification accuracy of this strategy.",2017,"ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences"
A fourâ€group urine risk classifier for predicting outcomes in patients with prostate cancer,"OBJECTIVES
To develop a risk classifier using urine-derived extracellular vesicle RNA (UEV-RNA) capable of providing diagnostic information of disease status prior to biopsy, and prognostic information for men on active surveillance (AS).


PATIENTS AND METHODS
Post-digital rectal examination UEV-RNA expression profiles from urine (n = 535, multiple centres) were interrogated with a curated NanoString panel. A LASSO-based Continuation-Ratio model was built to generate four Prostate-Urine-Risk (PUR) signatures for predicting the probability of normal tissue (PUR-1), D'Amico Low-risk (PUR-2), Intermediate-risk (PUR-3), and High-risk (PUR-4) PCa. This model was applied to a test cohort (nÂ =Â 177) for diagnostic evaluation, and to an AS sub-cohort (n = 87) for prognostic evaluation.


RESULTS
Each PUR signature was significantly associated with its corresponding clinical category (p<0.001). PUR-4 status predicted the presence of clinically significant Intermediate or High-risk disease, AUCÂ = 0.77 (95% CI: 0.70-0.84). Application of PUR provided a net benefit over current clinical practice. In an AS sub-cohort (n=87), groups defined by PUR status and proportion of PUR-4 had a significant association with time to progression (p<0.001; IQR HR = 2.86, 95% CI:1.83-4.47). PUR-4, when utilised continuously, dichotomised patient groups with differential progression rates of 10% and 60% five years post-urine collection (p<0.001, HRÂ = 8.23, 95% CI:3.26-20.81).


CONCLUSION
UEV-RNA can provide diagnostic information of aggressive PCa prior to biopsy, and prognostic information for men on AS. PUR represents a new & versatile biomarker that could result in substantial alterations to current treatment of PCa patients. This article is protected by copyright. All rights reserved.",2019,Bju International
On Identification of Distribution Grids,"Large-scale integration of distributed energy resources into distribution feeders necessitates careful control of their operation through power flow analysis. While the knowledge of the distribution system model is crucial for this analysis, it is often unavailable or outdated. The recent introduction of synchrophasor technology in low-voltage distribution grids has created ample opportunity to learn this model from high-precision, time-synchronized measurements of voltage and current phasors at various locations. This paper focuses on joint estimation of admittance parameters and topology of a polyphase distribution network from the available telemetry data via the lasso, a method for regression shrinkage and selection. We propose tractable convex programs capable of tackling the low-rank structure of the distribution system and develop an online algorithm for early detection and localization of critical events that induce a change in the admittance matrix. The efficacy of these techniques is corroborated through power flow studies on four three-phase radial distribution systems serving real and synthetic household demands.",2019,IEEE Transactions on Control of Network Systems
The Finite Sample Performance of Treatment Effects Estimators based on the Lasso,"This paper contributes to the literature on treatment effects estimation with machine learning inspired methods by studying the performance of different estimators based on the Lasso. Building on recent work in the field of high-dimensional statistics, we use the semiparametric efficient score estimation structure to compare different estimators. Alternative weighting schemes are considered and their suitability for the incorporation of machine learning estimators is assessed using theoretical arguments and various Monte Carlo experiments. Additionally we propose an own estimator based on doubly robust Kernel matching that is argued to be more robust to nuisance parameter misspecification. In the simulation study we verify theory based intuition and find good finite sample properties of alternative weighting scheme estimators like the one we propose.",2018,arXiv: Econometrics
[Methodological reflections on multi-stage field surveys: the EMIS survey of the region of Bobo-Dioulasso],Some problems concerning data collection in multistage surveys are examined using the example of the EMIS survey on infant mortality in the Sahel carried out between 1981 and 1984 in the region of Bobo-Dioulasso Burkina Faso. The emphasis is on the problem of nonresponse for unknown reasons. The reasons for error sources include the determination of place of delivery especially for women undergoing cesarean sections who were moved from outlying health centers and for deliveries where the child subsequently died. The evidence also indicates that some women particularly those in vulnerable categories were not included in subsequent phases of the survey. (SUMMARY IN ENG AND SPA),1987,Population
A Survey of Methods in Variable Selection and Penalized Regression,"Statistical learning often deals with the problem of finding a best predictive model from a set of possible models on the basis of the observed data. â€œBestâ€ often means most parsimonious; thus a sparse model that is composed of a subset of variables is usually preferable to a full model that uses all input variables because of its better interpretability and higher prediction accuracy. To this extent, systematic approaches such as variable selection methods for choosing good interpretable and predictive models have been developed. This paper reviews variable selection methods in linear regression, grouped into two categories: sequential methods, such as forward selection, backward elimination, and stepwise regression; and penalized methods, also called shrinkage or regularization methods, including the LASSO, elastic net, and so on. In addition to covering mathematical properties of the methods, the paper presents practical examples using SAS/STATÂ® software and SASÂ® ViyaÂ®.",2020,
Optimal risk minimization of Australian energy and mining portfolios under multiple measures of risk,"Australia's 2000's decade saw the sharpest rise in mining investments arising from developing Asian emerging economies' high demand for commodities like coal, iron ore, nickel, oil and gas which drove up prices to a historic level (Connolly & Orsmond, 2011). As of December 2012, 39 % and 9 % of the Australian Securities Exchange's stocks were of the mining (coal and uranium stocks are included in this category) and energy (e.g. oil, gas and renewable energy stocks) sectors respectively, and investors recently have been considering separate portfolio positions in energy and mining stocks (Jennings, 2010). Facts of these nature set the stage for the task of selecting an optimal portfolio of stock securities where the fundamental questions faced by every investor, individual or institutional, are: a) what is the optimal point in time to go long in the investment position?, b) what are the optimal amounts to invest in every asset of a portfolio? and, c) when is the optimal time to short the portfolio investment position? The focus of the present study is on b) within a one period ahead forecast scenario. Understanding the price and volatility movements of stock securities taking as a basis of study their own dynamics and co-dynamics is a complex task that may be better addressed through a multilateral modelling approach. This paper, in this regard, departs from a single model application by fitting multiple risk measures to the optimization of four portfolios each consisting of 20 ASX's stocks from the gold, iron ore-nickel, uranium-coal and oil-gas sectors. The five risk measures compared are: the variance, mean absolute deviation (MAD), minimizing regret (Minimax), conditional value at risk (CVaR), and conditional drawdown at risk (CDaR), where the last two are threshold based measures. The risk measure parameters are input into mean- variance quadratic (QP) and differential evolution (DE) portfolio problem specifications. Accurate estimations of the underlying interaction of stocks return series is a crucial element in portfolio allocation and portfolio risk management and frequentist traditional measures of dependence are rather inadequate. Here, with the objective of achieving more accuracy in the estimation of the dependence matrix, a Gaussian pair c-vine copula (PC), the regular graphical lasso (RL) and adaptive graphical lasso (AL) are fitted. Possible advantages from using these recently proposed and sophisticated techniques under model specifications where the covariance matrix is the measure of risk are indicated. The main objectives of the present study are to calculate the optimal weights to be invested in every stock of the portfolios making use of linear and nonlinear model specifications and the risk measures suggested, analyse the weight allocation differences and seek portfolio optimization advantages from using pair vine copulas and the graphical lasso in the estimation of dependence. The present multimodal approach is, therefore, expected to be more robust and as a consequence, provide more complete information that could serve for improved decision making on portfolio selection, allocation and rebalancing. Research questions are answered based on the analysis of gold portfolio outcome values, only. Findings indicate that CDaR is an important risk measure to be considered, along with other measures of risk when optimizing portfolios of stocks and no single measure of risk is suggested alone. The Gaussian pair c- vine copula through the use of one different parameter in the modelling of every pair of variables' joint distribution appears to be more sensitive in capturing data's distribution characteristics. The adaptive graphical lasso also appears to be more perceptive when grasping the signal of the underlying interaction of the stocks. Therefore, valuable information could be drawn and inferred from applying multiple risk measures and sophisticated statistical techniques for their estimation. The weight allocation from threshold risk measures such as CVar and DaR and Minimax clearly differs from the rest. The models identified stocks with high return relative to risk and vice versa. The originality of the present study lies on the sectors of application and its multi-model nature.",2013,
Learning multiple granger graphical models via group fused lasso,"Granger graphical models explain Granger causality between variables in time series through an estimation of zero pattern of coefficients in multivariate autoregressive (AR) models. In this paper, we consider a problem of estimating multiple Granger graphical models simultaneously that share similar topology structures from a set of time series data belonging to distinct classes. This is achieved by estimating a group of AR models and employing group fused lasso penalties to promote sparsity in AR coefficients of each model and sparsity in the difference between AR coefficients from two adjacent models. The resulting problem is in a class of group fused lasso formulation which fits nicely in a convex framework and then can be solved by a fast alternating directions method of multipliers (ADMM) algorithm. Advantages of the proposed method and the performance of the algorithm are illustrated through randomly generated data in a high-dimensional setting.",2015,2015 10th Asian Control Conference (ASCC)
Intelligent object group selection,"Current object group selection techniques such as lasso or rectangle selection can be time consuming and error prone. This is apparent when selecting distant objects on a large display or objects arranged along curvilinear paths in a dense area. We present a novel group selection technique based on the Gestalt principles of proximity and good continuity. The results of a user study show that our new technique outperforms lasso and rectangle selection for object groups in(curvi)linear arrangements or clusters, i.e. groups with an implicit structure.",2008,
"Early Cretaceous Sporopollen Assemblages from Well Te 1 in the Wanlite Depression,eastern Gobi Basin,mongolia","Abundant Early Cretaceous spores and pollen were found from Well Te 1 in the Wanlite Depression,Eastern Gobi Basin,Mongolia.Three assemblages have been divided,including:1.Cicatricosisporites-Classopollis-Piceites-Piceaepollenites assemblage,2.Perinopollenites-Cycadopites-Pinaceae-Walchiites assemblage,3.Laevigatosporites-Lygodiaceae-Perinopollenites assemblage.Based on the characteristics of the sporopollen assemblage,the first assemblage is assigned to the Berriasian(Early Cretaceous),but may also possibly correspend to the Late Jurassic;the second assemblage is considered to be the Berriasianâ€”Valanginian(Early Cretaceous),and the third assemblage is equivalent to the Hauterivianâ€”Barremian of the Early Cretaceous.",2009,
Low Carbon Fuel Standards Can Mark a New Era in Energy Regulation: The Case of California,"Finding an effective economic policy tool to reduce greenhouse gas (GHG) emissions is critical amid exacerbating environmental issues. â€œBottom-upâ€ sector-specific GHG mitigation policies, such as setting emission standards that cover all stages of production, have been recommended by many recent studies as an alternative policy approach. The Californiaâ€™s Low Carbon Fuel Standards (LCFS) to motor fuels for on-road vehicles is the very first attempt to apply this new policy approach at the state level. In this study we analyze the effect of the LCFS to CO2 emissions in the transportation sector of California. We use the Synthetic Control and Difference-in-Differences econometric methods, and the Lasso machine learning approach in our analyses. The three different approaches robustly confirm that the Low Carbon Fuel Standards have reduced carbon emissions in the Californiaâ€™s transportation sector around 10%. Furthermore, our calculations show that improved air quality, due to the application of the LCFS, may have benefited California, in the magnitude of hundreds of millions of dollars through an increase in workerâ€™s productivity.",2017,
Finger Vein Recognition with Personalized Feature Selection,"Finger veins are a promising biometric pattern for personalized identification in terms of their advantages over existing biometrics. Based on the spatial pyramid representation and the combination of more effective information such as gray, texture and shape, this paper proposes a simple but powerful feature, called Pyramid Histograms of Gray, Texture and Orientation Gradients (PHGTOG). For a finger vein image, PHGTOG can reflect the global spatial layout and local details of gray, texture and shape. To further improve the recognition performance and reduce the computational complexity, we select a personalized subset of features from PHGTOG for each subject by using the sparse weight vector, which is trained by using LASSO and called PFS-PHGTOG. We conduct extensive experiments to demonstrate the promise of the PHGTOG and PFS-PHGTOG, experimental results on our databases show that PHGTOG outperforms the other existing features. Moreover, PFS-PHGTOG can further boost the performance in comparison with PHGTOG.",2013,"Sensors (Basel, Switzerland)"
"Lariatins, Novel Anti-mycobacterial Peptides with a Lasso Structure, Produced by Rhodococcus jostii K01-B0171","Two anti-mycobacterial peptides with a lasso structure, named lariatins A and B, were separated by HP-20 and ODS column chromatographies and purified by HPLC from the culture broth of Rhodococcus jostii K01-B0171, which was isolated from soil aggregates collected in Yunnan, China. Lariains A and B showed growth inhibition against Mycobacterium smegmatis with MIC values of 3.13 and 6.25 Î¼g/ml in agar dilution method, respectively. Furthermore, lariatin A inhibited the growth of Mycobacterium tuberculosis with an MIC of 0.39 Î¼g/ml in liquid microdilution method.",2007,The Journal of Antibiotics
Defenses of Caribbean sponges against predatory reef fish. I. Chemical deterrency,"Laboratory feeding assays employing the common Canbbean wrasse Thalassoma bifasciatum were undertaken to determine the palatability of food pellets containing natural concentrations of crude organic extracts of 71 species of Caribbean demosponges from reef, mangrove, and grassbed habitats. The majority of sponge species (69%) yielded deterrent extracts, but there was considerable interand intraspecific vanability in deterrency. Most of the sponges of the aspiculate orders Verongida and Dictyoceratida yielded highly deterrent extracts, as did all the species in the orders Homosclerophorida and Axinellida. Palatable extracts were common among species in the orders Hadromerida, Poecilosclerida and Haplosclerida. Intraspecific variability was evident, suggesting that, for some species, some individuals (or portions thereof) may be chemically undefended. Reef sponges generally yielded more deterrent extracts than sponges from mangrove or grassbed habitats, but 4 of the 10 most common sponges on reefs yielded palatable extracts (Callyspongia vaginalis, Mycale laevis, Niphates erecta, Iotrochota birotulata), including those most commonly eaten by sponge-eating reef fish. The presence of symbiotic zoanthid cnidarians of the genus Parazoanthus in the tissues of otherwise palatable sponges had little effect on the deterrency of tissue extracts, indicating that these commensal polyps do not confer a chemical defense by association There was no relationship between sponge color and deterrency, suggesting that sponges are not aposematic and that color variation is the result of other factors. There was also no relationship between the toxicity of sponge extracts (as determined in previous studies) and deterrency, confirming the invalidity of previous assessments of chemical defense based on toxicity. Although chemical antipredatory defenses are important strategies for most Caribbean sponges, some common species appear to rely on other tactics.",1995,Marine Ecology Progress Series
Spline-Lasso in High-Dimensional Linear Regression,"We consider a high-dimensional linear regression problem, where the covariates (features) are ordered in some meaningful way, and the number of covariates p can be much larger than the sample size n. The fused lasso of Tibshirani et al. is designed especially to tackle this type of problems; it yields sparse coefficients and selects grouped variables, and encourages local constant coefficient profile within each group. However, in some applications, the effects of different features within a group might be different and change smoothly. In this article, we propose a new spline-lasso or more generally, spline-MCP to better capture the different effects within the group. The newly proposed method is very easy to implement since it can be easily turned into a lasso or MCP problem. Simulations show that the method works very effectively both in feature selection and prediction accuracy. A real application is also given to illustrate the benefits of the method. Supplementary materials for this article are avai...",2016,Journal of the American Statistical Association
Claw-finger Correction in Leprosy Using Half of the Flexor Digitorum Superficialis,"The commonest paralytic deformity in leprosy is the claw deformity of the fingers. Many surgical procedures have been described and are practiced to correct this deformity, but none is free from complications. A modification of the Zancolli lasso operation in which only half of the flexor digitorum superficialis tendon of the middle finger was used as the motor is described and a comparative study of this and the conventional procedure was carried out in 70 hands in 70 patients. The results suggest that the modification is technically simpler, with comparable results to those of the conventional procedure and fewer complications.",2008,Journal of Hand Surgery (European Volume)
Supplementary materials for paper : Revealing Common Statistical Behaviors in Heterogeneous Populations,"This supplementary document contains: 1. Proofs for Lemmas 1 and 2; 2. An alternative common-covariance estimation algorithm, which can be more efficient on parallel platforms, and an empirical comparison to Alg. 1; 3. Resting-state fMRI experiments on a group of ADHD subjects, and a comparison to graphLasso covariance estimation; 4. Analysis of the effect of kernel bandwidth on the pdf estimation in the ABP-PPG experiment.",2018,
On the Choice of Prior in Bayesian Model Averaging,"Bayesian model averaging attempts to combine parameter estimation and model uncertainty in one coherent framework. The choice of prior is then critical. Within an explicit framework of ignorance we define a â€˜suitableâ€™ prior as one which leads to a continuous and suitable analog to the pretest estimator. The normal prior, used in standard Bayesian model averaging, is shown to be unsuitable. The Laplace (or lasso) prior is almost suitable. A suitable prior (the Subbotin prior) is proposed and its properties are investigated.",2011,
Faster R-CNN with structured sparsity learning and Ristretto for mobile environment,"Deep learning is a part of machine learning area that has proven to solve many problems in the real world such as object recognition and detection. One of popular deep learning methods is Faster Region-Based Convolutional Neural Network (Faster R-CNN). Faster R-CNN proposed an integrated structure of CNN and region proposal network to detect multiple objects in a single image. Even though deep learning is powerful for object recognition or detection, it would still be a problem for implementing both the learning and the inference on mobile devices due to the need for a large memory and computation. In this paper, we propose to reduce the number of fliters and nodes in the convolutional and fully connected layer to 50% to make it feasible for implementation in a mobile environment and compared it with the original model. Second, we use Structured Sparsity Learning (SSL) in the convolutional layer to regularize Deep Neural Network (DNN) structure with group lasso. Third, we use Ristretto framework to convert floating point to 8 and 16 bits fixed point to represent weights and outputs of the fully connected layer. Our result shows that filter and node number reduction lowering memory storage down to 4.16x and successfully trained on NVIDIA Jetson Tegra TX1 Development Kit as mobile environment emulator. Ristretto successfully condense a model to 16 or 8 bits with error tolerance âˆ¼1% but has better accuracy from 0.85 to 0.87 at k = 5 for the original model, and 0.84 to 0.85 at k = 10 for 50% model on CCTV UT dataset. SSL works well on 50% model that obtain better accuracy from 0.83 to 0.84 in k=5 and from 0.84 to 0.86 in k=10 and accelerates computation time 2.72x faster than the original convolution layer without SSL.",2017,2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)
Efficient construction and applications of higher-order force constant models,"The vibrational properties of solids are fundamental to a large number of physical phenomena, including phase stability and thermal conduction. The canonical approach to modeling these properties requires knowledge of the interatomic forces constants (FCs). The problem of extracting the parameters in the FC expansion from a set of reference forces can be cast in linear form making it amenable to linear regression techniques. Here, we consider the efficiency of various common regression methods for FC extraction and the efficacy of the resulting models for predicting various thermodynamic properties. The regression approach drastically reduces the required number of reference calculations, which constitute the computationally most demanding task in FC extraction, compared to explicit enumeration techniques. It thereby becomes possible to extract both harmonic and high-order anharmonic FCs for large systems with low symmetry, including defects and surfaces. It is shown that ordinary least-squares, especially in connection with feature elimination, often yields the best performance in terms of convergence with respect to training set size and sparsity of the solution. Regression based on the least absolute shrinkage and selection operator (LASSO) on the other hand, while useful in some cases, tends to yield a larger number of features, with a noise level that has a detrimental effect on the prediction of e.g., the thermal conductivity. Finally, we also consider methods for the prediction of the temperature dependence of vibrational spectra from high-order FC expansions via molecular dynamics simulations as well as self-consistent phonons.",2019,arXiv: Materials Science
Feeding biology of the brackish-water oncholaimid nematode Adoncholaimus thalassophygas,"The brackish-water inhabiting nematode Adoncholaimus thalassophygas (De Man, 1876) may be classified as an omnivore and predator according to the gut contents of the adults. A series of 14C experiments was conducted to investigate the feeding potential of labelled microorganisms and dissolved 14C glucose. The observed consistent failure to incorporate 14C from labelled microorganisms, and its consistent success with dissolved 14C glucose suggests that dissolved organic matter may be more important than microorganisms as a food source for his nematode. This corresponds also with direct observations of living worms which showed very little uptake of particulate food other than that originating from predation. Defecation and mean gulping rates were low and, therefore, 14C glucose uptake from solution can hardly be explained by the assumption that large amounts of water are swallowed and passing through the gut. By means of mucus secretion, A. thalassophygas forms compact agglutinations of detrital sediment which are sites of enhanced microbial activity. We suggest that hatched juveniles feed primarily on dissolved organic matter released by the intensive microbial activity within this habitat. Adults retain the ability to utilize dissolved organic matter, and supplement their diet by scavenging on carcasses and occasional predation. Thus, the biology of oncholaimid nematodes may be characterized by an intimate linkage to microbial metabolism, although they do not appear to feed directly upon microorganisms.",1979,Marine Biology
High-dimensional variable selection in regression and classification with missing data,"Variable selection for high-dimensional data problems, including both regression and classification, has been a subject of intense research activities in recent years. Many promising solutions have been proposed. However, less attention has been given to the case when some of the data are missing. This paper proposes a general approach to high-dimensional variable selection with the presence of missing data when the missing fraction can be relatively large (e.g., 50%). Both regression and classification are considered. The proposed approach iterates between two major steps: the first step uses matrix completion to impute the missing data while the second step applies adaptive lasso to the imputed data to select the significant variables. Methods are provided for choosing all the involved tuning parameters. As fast algorithms and software are widely available for matrix completion and adaptive lasso, the proposed approach is fast and straightforward to implement. Results from numerical experiments and applications to two real data sets are presented to demonstrate the efficiency and effectiveness of the approach. HighlightsA fast method for high-dimensional regression and classification with missing data is proposed.The proposed method combines matrix completion and adaptive lasso.It provides promising empirical results.",2017,Signal Process.
Sparse Reconstruction Based on the ADMM and Lasso-LSQR for Bearings Vibration Signals,"In this paper, we introduce a novel method for reconstructing roller bearings vibration signals. As well as the sparse reconstruction algorithm, our approach is based on the Lasso via the alternate direction multiplier method (ADMM) and optimized by least square QR-factorization (LSQR), which takes the priority over the Basis Pursuit and Lasso in iterations and errors. First, we use the discrete cosine transformation to achieve sparse signals, then we compress signals by using the Gaussian random matrix, and, finally, we reconstruct the original signals with the Lasso-LSQR by using the ADMM. According to the results, vibration signals can keep sufficient reconstruction accuracy with high compressive ratio, which validates the effectiveness of the method for vibration signals.",2017,IEEE Access
"Identifikasi Keanekaragaman Spesies Ikan Di Ranu Klakah, Ranu Pakis, Dan Ranu Bedali Kawasan Gunung Lamongan Kabupaten Lumajang","ABSTRACT Area Mount of Lamongan there are owning three ranu deepness and also wide of different which is often visited by tourist, so that many people mention him as is trilateral of ranu. The Ranu?s for example that is; Ranu Klakah (Ranu Lamongan), Ranu Pakis, and all Ranu reside in Sub-Province of Lumajang ? East Java and represent area of tourist all natural reside in Sub-Province of Lumajang, residing in at coordinate point 112? 53 ? 113? 23? Longitude East and 7? 54 ? 8? 23? Paralel South and also height Mount of Lamongan itself is 1.668 m above sea level., (Annonymous, 2005). This research aim to know Variety Species Fish and also to know fish type frequency residing in is Trilateral of Ranu Area Mount of Lamongan Kab. Lumajang ? East Java. Type this research is descriptive research, as expressed by Sukmadinata, ( 2006:72). Result of research identified and in descriptive by using Book Taxonomy and Key Identify Fish, bind I and of II Composition of Hasanudin Sa?Anin, 1968. Constructing Creature. Bogor. For the analysis of, parameter the used is frequency and frequency relative. Data collecting of population done at transek as perception band by using method of Standart Walk. Standart Walk interpreted as moving at the same time catch fish by using previous net have in giving bait beforehand to draw attention fish with a purpose to fish will near and can be arrested in gyration apart certain perception alongside band which have been selected, (Et al Cowley., in anzilni 2003). Pursuant to haul and identify fish during activity of research which have can be concluded that fish species variety residing in Ranu Klakah, Ranu Pakis, and Ranu Bedali Mount area of Lamongan Sub-Province of Lumajang there are 10 included in species 2 klas that is: Oisteitchyes class and Agnatha class, for the Oisteichyes class consist of 9 species that is Clarias batrachus, Thalassoma Iunare, Osphronemus Goramy Lac., Cyclocheilichthy Armatus, Cyclocheilichthy Enoplos, Anabas Testudinelis, Ophiocepholus Striatus, Bangila Kuhli , and Eleotridae melanosoma. While for the Class of Agnatha consist of 1 ordo that is Sybrancholdea and consist of 1 species that is Monopterus albus.",2009,
"Molecular Classification Substitutes for the Prognostic Variables Stage, Age, and MYCN Status in Neuroblastoma Risk Assessment","BACKGROUND
Current risk stratification systems for neuroblastoma patients consider clinical, histopathological, and genetic variables, and additional prognostic markers have been proposed in recent years. We here sought to select highly informative covariates in a multistep strategy based on consecutive Cox regression models, resulting in a risk score that integrates hazard ratios of prognostic variables.


METHODS
A cohort of 695 neuroblastoma patients was divided into a discovery set (n=75) for multigene predictor generation, a training set (n=411) for risk score development, and a validation set (n=209). Relevant prognostic variables were identified by stepwise multivariable L1-penalized least absolute shrinkage and selection operator (LASSO) Cox regression, followed by backward selection in multivariable Cox regression, and then integrated into a novel risk score.


RESULTS
The variables stage, age, MYCN status, and two multigene predictors, NB-th24 and NB-th44, were selected as independent prognostic markers by LASSO Cox regression analysis. Following backward selection, only the multigene predictors were retained in the final model. Integration of these classifiers in a risk scoring system distinguished three patient subgroups that differed substantially in their outcome. The scoring system discriminated patients with diverging outcome in the validation cohort (5-year event-free survival, 84.9Â±3.4 vs 63.6Â±14.5 vs 31.0Â±5.4; P<.001), and its prognostic value was validated by multivariable analysis.


CONCLUSION
We here propose a translational strategy for developing risk assessment systems based on hazard ratios of relevant prognostic variables. Our final neuroblastoma risk score comprised two multigene predictors only, supporting the notion that molecular properties of the tumor cells strongly impact clinical courses of neuroblastoma patients.",2017,"Neoplasia (New York, N.Y.)"
Diversity of meiofauna and free-living nematodes in hydrothermal vent mussel beds on the northern and southern East Pacific Rise,"The ecology and biogeography of meiofauna at deep-sea hydrothermal vents have historically received less attention than those of mega- and macrofauna. This study examines the composition of major meiofaunal taxa in beds of the mussel Bathymodiolus thermophilus at hydrothermal vents on the northern and southern East Pacific Rise (EPR) and presents the first comparison of species assemblages of the dominant taxon, the nematodes, among sites spanning 27 degrees of latitude. Meiofaunal samples were collected by submersible from three mussel beds at 9Â°N on the EPR and four mussel beds between 17 and 18Â°S in 1999. Estimated ages of the mussel beds at the time of sampling range from 4 to >20 years, enabling investigation of the influence of mussel bed age on meiofaunal assemblages. Overall, the meiofauna of the mussel beds was dominated by nematodes, with copepods constituting the second most abundant meiofaunal group. There was variation in the ratio of nematodes to copepods between sites, however, with copepods more abundant than nematodes in the youngest mussel beds. Apart from polychaete larvae, other meiofaunal groups were generally present at very low abundance (<1%) in the samples and restricted in diversity to gastropod larvae, acari, foraminifera, ostracoda and turbellaria. Seventeen nematode species from 14 genera and 11 families were found in the samples, with no evidence of endemicity to hydrothermal vents at the generic level. Four genera present were not previously recorded at hydrothermal vents. Nematode species richness, species:genus ratios and abundances were low compared with other deep-sea habitats, though the ecological relevance of comparisons with soft-sediment benthos is discussed. Nematode assemblages exhibited high dominance by a few species, with one species of Thalassomonhystera most abundant at five of the seven vent sites. Multivariate analysis of nematode assemblages reveals similarities among sites that do not match geographical proximity. The youngest mussel beds were most similar to each other and exhibited lower species richness than other sites, consistent with colonization of mussel bed habitat by nematodes over time. Similarity in the composition of nematode assemblages among sites separated by âˆ¼3000 km indicates that they lie within a single biogeographic province, consistent with that proposed for mussel bed macrofauna. At a generic level, samples exhibited some overlap with nematode assemblages at vents elsewhere on the EPR, on the Mid Atlantic Ridge and in the North Fiji Basin.",2007,Journal of the Marine Biological Association of the United Kingdom
From K-Means to Higher-Way Co-Clustering: Multilinear Decomposition With Sparse Latent Factors,"Co-clustering is a generalization of unsupervised clustering that has recently drawn renewed attention, driven by emerging data mining applications in diverse areas. Whereas clustering groups entire columns of a data matrix, co-clustering groups columns over select rows only, i.e., it simultaneously groups rows and columns. The concept generalizes to data â€œboxesâ€ and higher-way tensors, for simultaneous grouping along multiple modes. Various co-clustering formulations have been proposed, but no workhorse analogous to K-means has emerged. This paper starts from K-means and shows how co-clustering can be formulated as a constrained multilinear decomposition with sparse latent factors. For three- and higher-way data, uniqueness of the multilinear decomposition implies that, unlike matrix co-clustering, it is possible to unravel a large number of possibly overlapping co-clusters. A basic multi-way co-clustering algorithm is proposed that exploits multilinearity using Lasso-type coordinate updates. Various line search schemes are then introduced to speed up convergence, and suitable modifications are proposed to deal with missing values. The imposition of latent sparsity pays a collateral dividend: it turns out that sequentially extracting one co-cluster at a time is almost optimal, hence the approach scales well for large datasets. The resulting algorithms are benchmarked against the state-of-art in pertinent simulations, and applied to measured data, including the ENRON e-mail corpus.",2013,IEEE Transactions on Signal Processing
Penalized ensemble feature selection methods for hidden associations in time series environments case study: equities companies in Saudi Stock Exchange Market,"The problem of optimal subset selection from a large number of time series is addressed in this work using machine learning of financial forecasting. This is a persistent problem in stock market that is largely due to the vast amount of daily-basis data points which require sensitive and robust intelligent data analysis techniques for capturing hidden associations between time series features. In this work, we are interested in generalizing the concept of capturing hidden associations between predictors from financial time series data points in the setting of penalized ensemble feature selection techniques. We have shown how recently developed penalized ensemble feature selection methods are capable of revealing hidden and informative dependencies between equity companies that appear in Saudi Stock Exchange Market in different daily time series datasets. The results have shown that our methods outperformed the well-known lasso regularization method particularly for small sample size.",2015,Evolving Systems
Preoperative prediction of cavernous sinus invasion by pituitary adenomas using a radiomics method based on magnetic resonance images,"ObjectivesTo predict cavernous sinus (CS) invasion by pituitary adenomas (PAs) pre-operatively using a radiomics method based on contrast-enhanced T1 (CE-T1) and T2-weighted magnetic resonance (MR) imaging.MethodsA total of 194 patients with Knosp grade two and three PAs (training set: n = 97; test set: n = 97) were enrolled in this retrospective study. From CE-T1 and T2 MR images, 2553 quantitative imaging features were extracted. To select the most informative features, least absolute shrinkage and selection operator (LASSO) was performed. Subsequently, a linear support vector machine (SVM) was used to fit the predictive model. Furthermore, a nomogram was constructed by incorporating clinico-radiological risk factors and radiomics signature, and the clinical usefulness of the nomogram was validated using decision curve analysis (DCA).ResultsThree imaging features were selected in the training set, based on which the radiomics model yielded area under the curve (AUC) values of 0.852 and 0.826 for the training and test sets. The nomogram based on the radiomics signature and the clinico-radiological risk factors yielded an AUC of 0.899 in the training set and 0.871 in the test set.ConclusionsThe nomogram developed in this study might aid neurosurgeons in the pre-operative prediction of CS invasion by Knosp grade two and three PAs, which might contribute to creating surgical strategies.Key Pointsâ€¢ Pre-operative diagnosis of CS invasion by PAs might affect creating surgical strategiesâ€¢ MRI might help for diagnosis of CS invasion by PAs before surgeryâ€¢ Radiomics might improve the CS invasion detection by MR images.",2018,European Radiology
PLS-Based and Regularization-Based Methods for the Selection of Relevant Variables in Non-targeted Metabolomics Data,"Non-targeted metabolomics constitutes a part of the systems biology and aims at determining numerous metabolites in complex biological samples. Datasets obtained in the non-targeted metabolomics studies are high-dimensional due to sensitivity of mass spectrometry-based detection methods as well as complexity of biological matrices. Therefore, a proper selection of variables which contribute into group classification is a crucial step, especially in metabolomics studies which are focused on searching for disease biomarker candidates. In the present study, three different statistical approaches were tested using two metabolomics datasets (RH and PH study). The orthogonal projections to latent structures-discriminant analysis (OPLS-DA) without and with multiple testing correction as well as the least absolute shrinkage and selection operator (LASSO) with bootstrapping, were tested and compared. For the RH study, OPLS-DA model built without multiple testing correction selected 46 and 218 variables based on the VIP criteria using Pareto and UV scaling, respectively. For the PH study, 217 and 320 variables were selected based on the VIP criteria using Pareto and UV scaling, respectively. In the RH study, OPLS-DA model built after correcting for multiple testing, selected 4 and 19 variables as in terms of Pareto and UV scaling, respectively. For the PH study, 14 and 18 variables were selected based on the VIP criteria in terms of Pareto and UV scaling, respectively. In the RH and PH study, the LASSO selected 14 and 4 variables with reproducibility between 99.3 and 100%, respectively. In the light of PLS-based models, the larger the search space the higher the probability of developing models that fit the training data well with simultaneous poor predictive performance on the validation set. The LASSO offers potential improvements over standard linear regression due to the presence of the constrain, which promotes sparse solutions. This paper is the first one to date utilizing the LASSO penalized logistic regression in untargeted metabolomics studies.",2016,Frontiers in Molecular Biosciences
Structured Sparsity and Generalization,"We present a data dependent generalization bound for a large class of regularized algorithms which implement structured sparsity constraints. The bound can be applied to standard squared-norm regularization, the Lasso, the group Lasso, some versions of the group Lasso with overlapping groups, multiple kernel learning and other regularization schemes. In all these cases competitive results are obtained. A novel feature of our bound is that it can be applied in an infinite dimensional setting such as the Lasso in a separable Hilbert space or multiple kernel learning with a countable number of kernels.",2012,J. Mach. Learn. Res.
Connectivity-based parcellation of functional SubROIs in putamen using a sparse spatially regularized regression model,"Abstract In this paper, we present a novel framework for parcellation of a brain region into functional subROIs (Sub-Region-of-Interest) based on their connectivity patterns with other brain regions. By utilising previously established neuroanatomy information, the proposed method aims at finding spatially continuous, functionally consistent subROIs in a given brain region. The proposed framework relies on (1) a sparse spatially-regularized fused lasso regression model for encouraging spatially and functionally adjacent voxels to share similar regression coefficients; (2) an iterative merging and adaptive parameter tuning process; (3) a Graph-Cut optimization algorithm for assigning overlapped voxels into separate subROIs. Our simulation results demonstrate that the proposed method could reliably yield spatially continuous and functionally consistent subROIs. We applied the method to resting-state fMRI data obtained from normal subjects and explored connectivity to the putamen. Two distinct functional subROIs could be parcellated out in the putamen region in all subjects. This approach provides a way to extract functional subROIs that can then be investigated for alterations in connectivity in diseases of the basal ganglia, for example in Parkinson's disease.",2016,Biomed. Signal Process. Control.
Introduction: A Review of Lasso Peptide Research,"Lasso peptides form a unique family of bacterial ribosomally synthesized peptides that are post-translationally modified by dedicated enzymes, which confer them a specific interlocked topology called the â€˜lasso foldâ€™ where a peptidic tail is trapped and locked into a ring. Lasso peptides typically contain around 20 amino acids, with an average size range of 15â€“24 amino acids (i.e. molecular weights in the range of 1500â€“2500 Da). The ring, comprising 7â€“9 amino acids (23â€“29 atoms), is closed by a lactam bond between the N-terminal amino group and the carboxylate side chain of a glutamate or an aspartate. The tail is trapped within the ring either by bulky side chains (steric trapping) or by one or two disulfide bonds, or by both means. This specific lasso (or lariat) topology makes lasso peptides extraordinarily stable and raises intriguing questions about the bacterial capacity to generate such an entropically disfavoured fold and how they acquired this ability in the course of evolution.",2015,
Research on Regional Water Use Economic Efficiency Coefficient Based on Gray Relational Analysis and Lasso Method,"Optimal allocation of water is an effective way to resolve the issue of regional water shortages,while identification of economic efficiency coefficient of the regional water is the basis.Use relational analysis method in gray system theory,the various factors that affect water use economic benefits based on regional historical water use data is analyzed,and the main impact factors is distinguished.Mining the relationship between impact factors and total economic output combined with Lasso regression,and the method is used to solve water use economic efficiency coefficient of industrial water and agricultural water in Zhoukou City.The result shows that the method can calculate the water use economic efficiency coefficient of study area more accurately,and provide a more accurate and quantitative methods in fixing the economic efficiency coefficient of optimal allocation of water.",2013,
Culture-independent study of the diversity of microbial populations in brines during fermentation of naturally-fermented AloreÃ±a green table olives.,"AloreÃ±a table olives are naturally fermented traditional green olives with a denomination of protection (DOP). The present study focused on AloreÃ±a table olives manufactured by small and medium enterprises (SMEs) from Valle del Guadalhorce (Southern Spain) under three different conditions (cold storage, and ambient temperature fermentations in small vats and in large fermentation tanks). The microbial load of brines during fermentation was studied by plate counting, and the microbial diversity was determined by a culture-independent approach based on PCR-DGGE analysis. The viable microbial populations (total mesophilic counts, yeasts and molds, and lactic acid bacteria - LAB) changed in cell numbers during the course of fermentation. Great differences were also observed between cold, vat and tank fermentations and also from one SME to another. Yeasts seemed to be the predominant populations in cold-fermented olives, while LAB counts increased towards the end of vat and tank fermentations at ambient temperature. According to PCR-DGGE analysis, microbial populations in cold-fermented olives were composed mostly by Gordonia sp./Pseudomonas sp. and Sphingomonas sp./Sphingobium sp./Sphingopyxis sp. together with halophilic archaea (mainly by haloarchaeon/Halosarcina pallida and uncultured archaeon/uncultured haloarchaeon/Halorubrum orientalis) and yeasts (Saccharomyces cerevisiae and Candida cf. apicola). Vat-fermented olives stored at ambient temperature included a more diverse bacterial population: Gordonia sp./Pseudomonas sp., Sphingomonas sp./Sphingobium sp./Sphingopyxis sp. and Thalassomonas agarivorans together with halophilic archaea and yeasts (mainly S. cerevisiae and C. cf. apicola, but also Pichia sp., and Pichia manshurica/Pichia galeiformis). Some LAB were detected towards the end of vat fermentations, including Lactobacillus pentosus/Lactobacillus plantarum and Lactobacillus vaccinostercus/Lactobacillus suebicus. Only the tank fermentation showed a clear predominance of LAB populations (Lactobacillus sp., Lactobacillus paracollinoides, and Pediococcus sp.) together with some halophilic archaea and a more selected yeast population (P. manshurica/P. galeiformis). The present study illustrates the complexity of the microbial populations in naturally-fermented AloreÃ±a table olives.",2011,International journal of food microbiology
Minimum Description Length Principle in Supervised Learning with Application to Lasso,"The minimum description length (MDL) principle in supervised learning is studied. One of the most important theories for the MDL principle is Barron and Cover's theory (BC theory), which gives a mathematical justification of the MDL principle. The original BC theory, however, can be applied to supervised learning only approximately and limitedly. Though Barron et al. recently succeeded in removing a similar approximation in case of unsupervised learning, their idea cannot be essentially applied to supervised learning in general. To overcome this issue, an extension of BC theory to supervised learning is proposed. The derived risk bound has several advantages inherited from the original BC theory. First, the risk bound holds for finite sample size. Second, it requires remarkably few assumptions. Third, the risk bound has a form of redundancy of the two-stage code for the MDL procedure. Hence, the proposed extension gives a mathematical justification of the MDL principle to supervised learning like the original BC theory. As an important example of application, new risk and (probabilistic) regret bounds of lasso with random design are derived. The derived risk bound holds for any finite sample size $n$ and feature number $p$ even if $n\ll p$ without boundedness of features in contrast to the past work. Behavior of the regret bound is investigated by numerical simulations. We believe that this is the first extension of BC theory to general supervised learning with random design without approximation.",2016,ArXiv
A One-sided Power Sum Inequality,"In this paper we answer Spijkerâ€™s question in a slightly generalizedand sharpened form. Spijker asked the question because of applica-tions to numerical analysis. Linear multistep methods (LMMs) form awell-known class of numerical step-by-step methods for solving initial-value problems for certain systems of ordinary diï¬€erential equations.In many applications of such methods it is essential that the LMMhas speciï¬c stability properties. An important property of this kindis named boundedness and has recently been studied by Hundsdorfer,Mozartova and Spijker [2]. In that paper the stepsize-coeï¬ƒcient Î³ is acrucial parameter in the study of boundedness. In [3] Spijker attemptsto single out all LMMs with a positive stepsize-coeï¬ƒcient Î³ for bound-edness. By using Corollary 1 below he is able to nicely narrow the classof such LMMs.Theorem1. Let n be a positive integer. Put m = âŒŠn/2âŒ‹. Let be givennonzero complex numbers b",2011,arXiv: Number Theory
Polygenic scores via penalized regression on summary statistics.,"Polygenic scores (PGS) summarize the genetic contribution of a person's genotype to a disease or phenotype. They can be used to group participants into different risk categories for diseases, and are also used as covariates in epidemiological analyses. A number of possible ways of calculating PGS have been proposed, and recently there is much interest in methods that incorporate information available in published summary statistics. As there is no inherent information on linkage disequilibrium (LD) in summary statistics, a pertinent question is how we can use LD information available elsewhere to supplement such analyses. To answer this question, we propose a method for constructing PGS using summary statistics and a reference panel in a penalized regression framework, which we call lassosum. We also propose a general method for choosing the value of the tuning parameter in the absence of validation data. In our simulations, we showed that pseudovalidation often resulted in prediction accuracy that is comparable to using a dataset with validation phenotype and was clearly superior to the conservative option of setting the tuning parameter of lassosum to its lowest value. We also showed that lassosum achieved better prediction accuracy than simple clumping and P-value thresholding in almost all scenarios. It was also substantially faster and more accurate than the recently proposed LDpred.",2017,Genetic epidemiology
Bayesian Lassos for spatial durbin error model with smoothness prior: Application to detect spillovers of China's treaty ports,"Abstract In this paper we consider a generalized spatial durbin error model with spatial spillovers that are flexible and subject to abrupt change arising from zero spillover effects. We propose a new class of Bayesian lasso-type prior, the Bayesian elastic net with smoothness prior, to both tackle the multicollinearity among spatial lags of explanatory variables and capture both zero and nonzero spillover effects. We develop a computationally tractable Markov Chain Monte Carlo (MCMC) algorithm to estimate the model under the new prior. We also study the corresponding model selection issue among the generalized spatial durbin error model and its two special cases: 1) the spatial error model and 2) the spatial autoregressive type model. Simulation results suggest that the new prior can outperform many existing Bayesian priors in terms of in-sample predictive performance. We apply the model with the new prior to investigate the influence and spillover effects of China's historical treaty ports in the 19th century on prefectures' population and economic growth in the long-run. We find that prefectures with treaty ports tend to grow faster in terms of population size and GDP level. We also detect positive and significant spillovers when one's neighbors become treaty ports.",2019,Regional Science and Urban Economics
Classification of mesh fiber exposure: reply,"Dear Editor,On behalf of the authors, I thank Dr Al-Badr for his interestin the document [1]: ""An International UrogynecologicalAssociation (IUGA) / International Continence Society(ICS) joint Terminology and Classification of complicationsrelated directly to the insertion of prostheses (meshes,implants, tapes) and grafts in female pelvic floor surgery"".It is pleasing the report has been found to be useful.The main point made by Dr Al-Badr [ 2] appears to concernthe inclusion of ""mesh fibre palpation"" in category 1 of theclassification [1] rather than category 2. The issue rests on thedefinition of (vaginal) ""separation"", which is currentlyapplicable, to ""exposures"" in categories 2 and 3 of theclassification but not to category 1 complications. Dr Al-Badrappears to argue that a ""separation"" of vaginal epithelium byone fibre is still a ""separation"". The definition of ""separation""used in the Terminology section of the Report [ 1]isthatof""physically disconnected"". It may be hard to assert thatvaginal epithelium pierced by one or more than one fibre of aprosthesis is ""physically disconnected"". The Report maintainsthat there needs to be clear physical disconnection (""separa-tion"") of vaginal epithelium with visualization of vaginalmesh to create an exposure (categories 2 and 3).Dr Al-Badr makes a further point [2] that the classifica-tion [1] does not distinguish between mesh fibre palpationunder the vaginal epithelium and mesh palpation and/orvisualization through the epithelium. The suggested argu-ment is that the management may well be different, whichmay perhaps, at times, be the case. It is agreed that meshfibres felt under the epithelium without being seen (or felt)in the vagina qualifies for category 1A (especially as it islikely to be asymptomatic and generally requiring notreatment). For the reasons outlined above in relation tothe definition of ""separation"", mesh fibres seen or feltthrough the vaginal epithelium would still only qualify ascategory 1. The category would be 1A if there were nosymptoms or 1B is there were symptoms (possiblyrequiring treatment), with a common symptom beingdyspareunia to the partner. The classification does thendistinguish between the scenarios presented by Dr Al-Badron the basis of the likely presence or absence of symptomsand the possible associated need for treatment.",2011,International Urogynecology Journal
Quasi-linear score for capturing heterogeneous structure in biomarkers,"BackgroundLinear scores are widely used to predict dichotomous outcomes in biomedical studies because of their learnability and understandability. Such approaches, however, cannot be used to elucidate biodiversity when there is heterogeneous structure in target population.ResultsOur study was focused on describing intrinsic heterogeneity in predictions. Because heterogeneity can be captured by a clustering method, integrating different information from different clusters should yield better predictions. Accordingly, we developed a quasi-linear score, which effectively combines the linear scores of clustered markers. We extended the linear score to the quasi-linear score by a generalized average form, the Kolmogorov-Nagumo average. We observed that two shrinkage methods worked well: ridge shrinkage for estimating the quasi-linear score, and lasso shrinkage for selecting markers within each cluster. Simulation studies and applications to real data show that the proposed method has good predictive performance compared with existing methods.ConclusionsHeterogeneous structure is captured by a clustering method. Quasi-linear scores combine such heterogeneity and have a better predictive ability compared with linear scores.",2017,BMC Bioinformatics
Exact Post-Selection Inference for Changepoint Detection and Other Generalized Lasso Problems,"We study tools for inference conditioned on model selection events that are defined by the generalized lasso regularization path. The generalized lasso estimate is given by the solution of a penalized least squares regression problem, where the penalty is the l1 norm of a matrix D times the coefficient vector. The generalized lasso path collects these estimates for a range of penalty parameter ({\lambda}) values. Leveraging a sequential characterization of this path from Tibshirani & Taylor (2011), and recent advances in post-selection inference from Lee et al. (2016), Tibshirani et al. (2016), we develop exact hypothesis tests and confidence intervals for linear contrasts of the underlying mean vector, conditioned on any model selection event along the generalized lasso path (assuming Gaussian errors in the observations). By inspecting specific choices of D, we obtain post-selection tests and confidence intervals for specific cases of generalized lasso estimates, such as the fused lasso, trend filtering, and the graph fused lasso. In the fused lasso case, the underlying coordinates of the mean are assigned a linear ordering, and our framework allows us to test selectively chosen breakpoints or changepoints in these mean coordinates. This is an interesting and well-studied problem with broad applications, our framework applied to the trend filtering and graph fused lasso serves several applications as well. Aside from the development of selective inference tools, we describe several practical aspects of our methods such as valid post-processing of generalized estimates before performing inference in order to improve power, and problem-specific visualization aids that may be given to the data analyst for he/she to choose linear contrasts to be tested. Many examples, both from simulated and real data sources, are presented to examine the empirical properties of our inference methods.",2016,arXiv: Methodology
Gene Network Reconstruction by Integration of Prior Biological Knowledge,"With the development of high-throughput genomic technologies, large, genome-wide datasets have been collected, and the integration of these datasets should provide large-scale, multidimensional, and insightful views of biological systems. We developed a method for gene association network construction based on gene expression data that integrate a variety of biological resources. Assuming gene expression data are from a multivariate Gaussian distribution, a graphical lasso (glasso) algorithm is able to estimate the sparse inverse covariance matrix by a lasso (L1) penalty. The inverse covariance matrix can be seen as direct correlation between gene pairs in the gene association network. In our work, instead of using a single penalty, different penalty values were applied for gene pairs based on a priori knowledge as to whether the two genes should be connected. The a priori information can be calculated or retrieved from other biological data, e.g., Gene Ontology similarity, protein-protein interaction, gene regulatory network. By incorporating prior knowledge, the weighted graphical lasso (wglasso) outperforms the original glasso both on simulations and on data from Arabidopsis. Simulation studies show that even when some prior knowledge is not correct, the overall quality of the wglasso network was still greater than when not incorporating that information, e.g., glasso.",2015,G3: Genes|Genomes|Genetics
On feature selection for supervised learning problems involving high-dimensional analytical information,"Several computational methods were applied to feature selection for supervised learning problems that can be encountered in the field of analytical chemistry. Namely, Genetic Algorithm (GA), Firefly Algorithm (FA), Particle Swarm Optimization (PSO), Least Absolute Shrinkage and Selection Operator (LASSO), Least Angle Regression Algorithm (LARS), interval Partial Least Squares (iPLS), sparse PLS (sPLS), and Uninformative Variable Elimination-PLS (UVE-PLS). Methods were compared in two case studies which cover both supervised learning cases; (i) regression: multivariate calibration of soil carbonate content using Fourier transform mid-infrared (FT-MIR) spectral information, and (ii) classification: diagnosis of prostate cancer patients using gene expression information. Beside quantitative performance measures: error and accuracy often used in feature selection studies, a qualitative measure, the selection index (SI), was introduced to evaluate the methods in terms of quality of selected features. Robustness was evaluated introducing artificially generated noise variables to both datasets. Results of the first case study have shown that in order of decreasing predictive ability and robustness: GA > FA â‰ˆ PSO > LASSO > LARS (errors of 1.775, 4.504, 4.055 mg gâˆ’1, 10.085, and 10.510 mg gâˆ’1) are recommended for application in regression involving spectral information. In the second case study, the following trend: GA > PSO > FA â‰ˆ LASSO > LARS (accuracies of 100, 95.12 and 90.24%) has been observed. Strong robustness has been observed in the regression case with no decrease in SI for GA, and SI decreasing from 28.85 to 10.26, and 36.11 to 21.05%, for FA and PSO, respectively. In the classification case, only LARS exhibited a considerable decrease in accuracy upon introduction of noise features. Major sources of errors were identified and mostly originated from the analytical methods themselves, which confirmed strong applicability of the evaluated feature selection methods.",2016,RSC Advances
Forecasting Macroeconomic Time Series: LASSO-Based Approaches and Their Forecast Combinations with Dynamic Factor Models,"In a data-rich environment, forecasting economic variables amounts to extracting and organizing useful information from a large number of predictors. So far, the dynamic factor model and its variants have been the most successful models for such exercises. In this paper, we investigate a category of LASSO-based approaches and evaluate their predictive abilities for forecasting twenty important macroeconomic variables. These alternative models can handle hundreds of data series simultaneously, and extract useful information for forecasting. We also show, both analytically and empirically, that combing forecasts from LASSO-based models with those from dynamic factor models can reduce the mean square forecast error (MSFE) further. Our three main findings can be summarized as follows. First, for most of the variables under investigation, all of the LASSO-based models outperform dynamic factor models in the out-of-sample forecast evaluations. Second, by extracting information and formulating predictors at economically meaningful block levels, the new methods greatly enhance the interpretability of the models. Third, once forecasts from a LASSO-based approach are combined with those from a dynamic factor model by forecast combination techniques, the combined forecasts are significantly better than either dynamic factor model forecasts or the naive random walk benchmark.",2014,International Journal of Forecasting
The Poems of Orlando di Lasso's Prophetiae Sibyllarum and Their Sources,"O RLANDO DI LASSO'S Prophetiae Sibyllarum (Sibylline Prophecies) is a cycle of motets in which are set twelve six-line Latin poems and a three-line prologue, all of which are in dactylic hexameter throughout.' Each of the twelve poems contains what purport to be prophecies of the coming, life and mission of Christ as foreseen by the sibyls of antiquity, and the title of each poem identifies by location the sibyl who presumably delivered that prophecy. The style of the poems is oblique, allusive, even obscure; no progression of mood or idea through the cycle is apparent. Particular ideas do recur, such as the birth of the Savior to the Virgin Mary and the salvation Christ brings to sinful man. Lasso's music is notable for its extraordinary chromaticism, which goes far beyond the norm for most of his other music, and discussion of the work has tended to center on this aspect to the exclusion of any other, with the partial exception of the chapter in Wolfgang Boetticher's study of the composer.2 The literary background of the poems and the iconographic symbolism associated with them are of considerable interest in their own right, in addition to what they reveal about the chronology and sources of Lasso's music, and these will be the subject of the present study. The Prophetiae are set apart from most of Lasso's work by the nature of their sources as well as their style. The cycle was one of the compositions which Lasso presented to his employer and patron, Albrecht V of Bavaria, as a private gift, like the seven Penitential Psalms. The primary source is the set of four partbooks now in the Oesterreichisches Nationalbibliothek in Vienna, Ms. mus. 18744, which contain the Prophetiae and also the Sacrae lectiones ex propheta Job (Sacred readings from the prophet Job), the earlier of the composer's settings of the latter texts. Lasso copied the music himself, and each partbook was decorated with a portrait of him and miniatures of each of the twelve sibyls (see Fig. i) by Hans Mielich, the Bavarian court painter who later supplied the famous illuminations in the manuscript of the",1979,Journal of the American Musicological Society
Group-Personalized Regression Models for Predicting Mental Health Scores From Objective Mobile Phone Data Streams: Observational Study,"BACKGROUND
Objective behavioral markers of mental illness, often recorded through smartphones or wearable devices, have the potential to transform how mental health services are delivered and to help users monitor their own health. Linking objective markers to illness is commonly performed using population-level models, which assume that everyone is the same. The reality is that there are large levels of natural interindividual variability, both in terms of response to illness and in usual behavioral patterns, as well as intraindividual variability that these models do not consider.


OBJECTIVE
The objective of this study was to demonstrate the utility of splitting the population into subsets of individuals that exhibit similar relationships between their objective markers and their mental states. Using these subsets, ""group-personalized"" models can be built for individuals based on other individuals to whom they are most similar.


METHODS
We collected geolocation data from 59 participants who were part of the Automated Monitoring of Symptom Severity study at the University of Oxford. This was an observational data collection study. Participants were diagnosed with bipolar disorder (n=20); borderline personality disorder (n=17); or were healthy controls (n=22). Geolocation data were collected using a custom Android app installed on participants' smartphones, and participants weekly reported their symptoms of depression using the 16-item quick inventory of depressive symptomatology questionnaire. Population-level models were built to estimate levels of depression using features derived from the geolocation data recorded from participants, and it was hypothesized that results could be improved by splitting individuals into subgroups with similar relationships between their behavioral features and depressive symptoms. We developed a new model using a Dirichlet process prior for splitting individuals into groups, with a Bayesian Lasso model in each group to link behavioral features with mental illness. The result is a model for each individual that incorporates information from other similar individuals to augment the limited training data available.


RESULTS
The new group-personalized regression model showed a significant improvement over population-level models in predicting mental health severity (P<.001). Analysis of subgroups showed that different groups were characterized by different features derived from raw geolocation data.


CONCLUSIONS
This study demonstrates the importance of handling interindividual variability when developing models of mental illness. Population-level models do not capture nuances in how different individuals respond to illness, and the group-personalized model demonstrates a potential way to overcome these limitations when estimating mental state from objective behavioral features.",2018,Journal of Medical Internet Research
Model for Vehicle Routing Plan with Mixed-Demand and Its Lasso Solution,"When customers have a mixed demand for delivering and fetching goods, the solution can not be obtained using the traditional TSP (travelling salesman problem) algorithms because of the restraint of the demand for delivery and fetching and the capacity of vehicles. To solve this problem, a model of customer subset distribution is set up. Based on the customer subset distribution, the lasso solution is proposed to select the route with the minimum distribution cost.",2003,Journal of Southwest Jiaotong University
Real-time motion-adjusted augmented fluoroscopy system for navigation during electrophysiology procedures,"Electrophysiology (EP) procedures are conducted by cardiac specialists to help diagnose and treat abnormal heart rhythms. Such procedures are conducted under mono-plane and bi-plane x-ray fluoroscopy guidance to allow the specialist to target ablation points within the heart. Ablations lesions are usually set by applying radio-frequency energy to endocardial tissue using catheters placed inside a patient's heart. Recently we have developed a system capable of overlaying information involving the heart and targeted ablation locations from pre-operational image data for additional assistance. Although useful, such information offers only approximate guidance due to heart beat and breathing motion. As a solution to this problem, we propose to make use of a 2D lasso catheter tracking method. We apply it to bi-plane fluoroscopy images to dynamically update fluoro overlays. The dynamic overlays are computed at 3.5 frames per second to offer real-time updates matching the heart motion. During the course of our experiments, we found an average 3-D error of 1.6 mm on average. We present the workflow and features of the motion-adjusted, augmented fluoroscopy system and demonstrate the dramatic improvement in the overlay quality provided by this approach.",2012,
FROM AGRO-TOWNS TO â€˜ TERRITORIAL POLES â€™ IN THE FRENCH DECADE : REINTERPRETING THE URBAN PROCESSES OF SOUTHERN ITALY IN THE MODERN AGE Emilia SARNO,"This contribution, which references the most accredited literature on the subject, discusses the urban question of modern Southern Italy with all its particular aspects and problems and highlights how the 18 century and the subsequent French Decade (1806-1815) are a watershed for the formation and consolidation of the urban identity of a number of Southern Italy centres. The question is particularly complex and has been the subject of study in research documented by Sarno (2012). The results of the research pertaining to two pivotal aspects are encapsulated in this paper. The first concerns the peculiarities of the Southern agrotown called lands in the Modern Age. The second aspect is the particular significance the French government gave to the cities between 1806 and 1815 as central hubs for the state organisation, envisaging them as functional poles. Therefore we intend to show how various towns in Southern Italy tried to construct an urban identity in the modern age, by means of a compromise between the feudal set-up and autonomist urges at first and then thanks to the French presence. Although such attempts were often undermined by the 19 century historicaleconomical processes, they deserve to be examined as representing a fundamental, albeit discontinuous, stage in the urban history of various towns. We need to recommence from such discontinuities in order to fully understand the complexity of the urban phenomenon in Southern Italy, to put into focus the effective identity of several towns and to start up real processes for territorial planning. 1. THE URBAN QUESTION IN MODERN SOUTHERN ITALY The urban question of Southern Italy has been widely debated over several decades now. In the 1960s the issue was addressed almost simultaneously by Giuseppe Galasso, Francesco Compagna e Lucio Gambi. The former sustained the idea (1969) that the absence of a Commune civilization prevented the development of cities in Southern Italy and that the feudal political approach, from Angioini to the Spanish, Sarno, E. From agro-towns to 'territorial poles' in the French decade 70 glorified solely the capital city, Naples. Such a standpoint remains a leitmotiv from Villari (1984) to Romeo (1990), so summarized by Musi (2000b, p. 7): â€œThe introduction of the feudal regime by the Normans blends in a context characterized by the absence of the commune as a city-stateâ€. In his turn, Francesco Compagna even anticipated the origin of the issue: ""Apparently, the origins of the crisis, that made the town institutions of Southern Italy palely cede in the XI century, must be sought in the period prior to that of the Normans monarchy advent and the establishment of a rigid form of feudalism. Apparently, the beautiful flowering the cities of Campania (and the Southern ones) seemed to be headed for in the Early Middle Ages was a vain one, gone untested towards powerful opposing forces"" (Compagna, 1967, p. 56). Later studies confirm such a vision, in fact Rombai considers ""the age-old and powerful feudal organization as the primary cause for the failed formation of a network of cities which could have added value to the entire territory with its bourgeoisie, as happened in Centre-North of Italy"" (Rombai, 2002, p. 195). Therefore, the city in the South of Italy was born ""subject"", since continually dealing with the central power (Corciulo, 2009). For his part, Lucio Gambi (1965), by studying Calabria centres, wondered whether they were to be considered real towns, highlighting how poor urbanization remained in Southern Italy as a whole. In other words, the lack of autonomy and the absolutist structure of the Kingdom of Naples stigmatised Southern cities, which levelled on a ""bureaucratic"" status, even after the Unification of Italy, as explained by Talia (2004), thus leaving unchanged the differences between North and South. In fact, the same scholar points out that the disparity existing until the Unity was replaced by the subsequent formation of a denser network but not ""less balanced and weak"" (Talia, 2007a, p. 118). One of the reasons for such an imbalance is the unsteady and frail development of industrialization. Therefore, the South was late at the appointment with the urban question and with a negative legacy (Dematteis, 2008; Dâ€™Aponte, Mazzetti, 2011), but over the last decade it has come up the necessity of a more articulate reinterpretation of the phenomenon, in order to put into focus regional transformations and differentiations (Viganoni, 2007; Sommella, 2008; Amato, 2011). However, it seems equally scientifically urgent to understand the past, in such a way as to focus on urban processes which formed over the long term, albeit inconsistently, and clarify paths already begun, though undone by later factors, but still tenaciously present in so many cities' identity. The Modern age is particularly complex but also interesting because it is the period when a number of towns in Southern Italy try to overcome the condition of inferiority and activate productive processes on a certain level. However such a period is also complex due to the following reasons: the first is demographic, the second juridical and the third one scientific. In the past the demographic factor appeared to be fundamental as for recognizing a town as such, but its importance has to be scaled down because, as showed by the studies collected by Clark (2002a) on small and medium-sized European towns in the Modern age, the functions acquired are more relevant than the mere amount of population. After all, it had already been illustrated by Gambi (1982). The second issue the juridical one made the phenomenon difficult to interpret because, for instance, in the Kingdom of Naples there were the royal towns, 1 Differences and inadequacies are summarized by the 2008 Report of the Italian Geographical Society in the article The urban question in Southern Italy and then addressed again in the 2011 Report dedicated to Southern Italy. Sarno, E. From agro-towns to 'territorial poles' in the French decade 71 which benefited from a certain extent of autonomy and were directly contingent upon the Crown, but there also were the lands on a much larger scale, that is feuds held by noble families and subject to trade. But the lands, although in such a condition of inferiority, were still capable of achieving a remarkable productive value, as it will be showed later on. Such an ambiguity is well condensed in some definitions: they are almost towns (Chittolini, 1990) or peasant towns (Poli, 2004). If you want a summary of a compromise between the feudal system and the productive activities, it seems coherent to their status the definition of urban land (Sarno, 2012). But it is necessary to put into focus the peculiarities of the agrotown in the Modern Age rather than looking for a proper denomination. Finally third issue small and medium-sized towns have been ignored for a long time due to the difficulty in gathering data and case studies both in the Italian and European context, as clarified by Clark (2002b), who collects interesting contributions for a reinterpretation of the phenomenon. As for Southern Italy, it is opportune to start again from the hefty study of Gerard Labrot (1991) about the cities in Southern Italy in the Modern Age, in which, while stressing their limits, he also pinpoints the hidden tensions within urban bodies and how these latter gradually emerge between the XVII and XVIII century, affecting small centers as well. A later collection of works collected by Musi (2000a), focused on a multiplicity of ways and functions realized in the Modern Age, from the urbanization â€˜cellsâ€™ in Basilicata to the different layout of agro-towns in what is today's Apulia, from small and medium-sized towns of Abruzzi to the super-rural entities of Calabria. The curator himself so describes his standpoint: ""Southern Italy didn't see the formation of an urban system, but rather developed urban hierarchies according to some typologies and economical, religious, political-administrative and service functions, all linked to the urban settlementsâ€ (Musi, 2000b, p. 9). With reference to such an hypothesis, a research has been started, whose results are collected in Sarno (2012), in order to analyze the peculiarities of Southern Italy's urbanization both in the modern era and in the French Decade. It was examined the case of Campobasso in the province of Molise, later broadening the outlook of the research to other cities of the Kingdom of Naples in order to have a significant case study database (fig.1). It has been showed that in the Modern Age several small and medium-sized towns â€“ generally called lands â€“ fulfilled a commercial or administrative role and that they achieved an urban identity between the XVII and XVIII century with a different 2 In the XVIII century the citizens of some of them pay a release fee to the Royal Inland Revenue and some of the lands acquire juridical rank of cities according to the legislation of the Royal Revenue. However they still had to continually deal with the central authority. The formulations adopted for the release were varied: normally the high society people of the lands agreed with the Royal Revenue the sum for the release in such a way as not to be subject to a feudatory but directly to the Crown. In many cases the business was conducted by a noble Ã©lite, which would pay part of the amount, while the remaining sum was collected through the taxation of the whole community. In other cases, the Universities of the cities were free of release and the sum is paid by a group of well-off families. 3 The volume edited by P. Clark (2002a) presents a broad-spectrum research on a European scale; from the outskirts of small Norwegian towns to small Spanish rural villages, from the cultural role of English towns to the Northern Italy situation. More in detail, he examines the case of small Venetian villages which take advantage of the Verona decadence an",2017,
A mass spectrometry-guided genome mining approach for natural product peptidogenomics,"Peptide natural products show broad biological properties and are commonly produced by orthogonal ribosomal and nonribosomal pathways in prokaryotes and eukaryotes. To harvest this large and diverse resource of bioactive molecules, we introduce here natural product peptidogenomics (NPP), a new MS-guided genome-mining method that connects the chemotypes of peptide natural products to their biosynthetic gene clusters by iteratively matching de novo tandem MS (MS(n)) structures to genomics-based structures following biosynthetic logic. In this study, we show that NPP enabled the rapid characterization of over ten chemically diverse ribosomal and nonribosomal peptide natural products of previously unidentified composition from Streptomycete bacteria as a proof of concept to begin automating the genome-mining process. We show the identification of lantipeptides, lasso peptides, linardins, formylated peptides and lipopeptides, many of which are from well-characterized model Streptomycetes, highlighting the power of NPP in the discovery of new peptide natural products from even intensely studied organisms.",2011,Nature chemical biology
A feature-based soft sensor for spectroscopic data analysis,"Abstract In the last few decades, spectroscopic techniques such as near-infrared (NIR) and UV/vis spectroscopies have gained wide applications. As a result, various soft sensors have been developed to predict sample properties from its spectroscopic readings. Because the readings at different wavelengths are highly correlated, it has been shown that variable selection could significantly improve a soft sensorâ€™s prediction performance and reduce the model complexity. Currently, almost all variable selection methods focus on how to select the variables (i.e., wavelengths or wavelength segments) that are strongly correlated with the dependent variable to improve the prediction performance. Although many successful applications have been reported, such variable selection methods do have their limitations, such as high sensitivity to the choice of training data, and deteriorated performance when testing on new samples. One possible reason is the removal of useful wavelengths or segments of wavelengths during the calibration process, which could be â€œtiltedâ€ to overfit or capture the noise or unknown disturbances contained in the calibration data. As a result, the model prediction performance may deteriorate significantly when the model is extrapolated or applied to new samples. To address this limitation, we propose a feature-based soft sensor approach utilizing statistics pattern analysis (SPA). Instead of selecting certain wavelengths or wavelength segments, the SPA-based method considers the whole spectrum which is divided into segments, and extracts different features over each spectrum segment to build the soft sensor. In other words, the SPA model contains the complete information from the full spectrum without any selection or removal, which we believe is the main reason for the high robustness of the SPA-based method. In addition, we propose a Monte Carlo validation and testing (MCVT) procedure and three MCVT-based performance indices for consistent and fair comparison of different soft sensor methods across different datasets. The MCVT procedure and indices are generally applicable for model comparison in other applications. Four case studies are presented to demonstrate the performance of the feature-based soft sensor and to compare it with a full partial least squares (PLS), a least absolute shrinkage and selection operator (Lasso), and a synergy interval PLS (SiPLS) based models following the proposed MCVT procedure. In addition, we examine the potential of kernel PLS (KPLS) based soft sensor approaches, examine their performances, and discuss their pros and cons.",2019,Journal of Process Control
"Update article / Mise au point Neuropathic pain in spinal cord injury: Identification, classification, evaluation La douleur neuropathique chez le blessÃ© mÃ©dullaire: identification, classification, Ã©valuation","Objective. â€ Chronic pain is very frequent after spinal cord injury, recent data showing that at least 80% of the patients experience pain, one-third at a severe level. The main objective of the present work is to report and discuss data regarding tools and procedures for the screening, diagnosis, and evaluation of neuropathic pain in spinal cord injury patients. Material and method. â€ The method used is that developed by the SOFMER, which associated a systematic review of the literature and a selection of published works by a scientific commitee, an analysis of data performed by a binom neuropathic pain/physical medicine and rehabilitation (PM&R) specialists, an evaluation of current practices during an expert consensus conference and via Internet, and finally a validation of thewhole work by a pluridisciplinary expert panel. Results. â€ The literature provides an important series of studies on pain in spinal injury, but without specific data about neuropathic pain in this population. Some specific diagnostic and evaluation tools for neuropathic pain have been developed these last years, while numerous classifications, based on various criteria, have been proposed, some of them exhibiting some advantages for a pragmatic application and being in parallel in accordance with recent nosological and physiopathological advances. Discussion. â€ TheDN4questionnairecanbeusedforthescreeningandidentificationofneuropathicpaininthispopulationofpatients,oftensuffering fromvarioustypesofpain.TheuseoftheSpinalCordInjuryPainTaskForceoftheInternationalAssociationoftheStudyofPainclassification(SCIPâ€ IASP), although some limitations, is recommended since taking into account physiopathology, localisation, and nature of pain. Daily uses of Visual Analogic Scale (VAS) or Numeric Scale (NS) are an obvious need and that of the questionnaire Douleur de Saint-Antoine (QDSA) for global evaluation and more specifically of the Neuropathic Pain Symptom Inventory (NPSI) for neuropathic pain are highly recommended. # 2009 Elsevier Masson SAS. All rights reserved.",2009,
Fused Group Lasso Regularized Multi-Task Feature Learning and Its Application to the Cognitive Performance Prediction of Alzheimerâ€™s Disease,"Alzheimerâ€™s disease (AD) is characterized by gradual neurodegeneration and loss of brain function, especially for memory during early stages. Regression analysis has been widely applied to AD research to relate clinical and biomarker data such as predicting cognitive outcomes from MRI measures. Recently, multi-task based feature learning (MTFL) methods with sparsity-inducing â„“2,1$ \ell _{2,1} $-norm have been widely studied to select a discriminative feature subset from MRI features by incorporating inherent correlations among multiple clinical cognitive measures. However, existing MTFL assumes the correlation among all tasks is uniform, and the task relatedness is modeled by encouraging a common subset of features via sparsity-inducing regularizations that neglect the inherent structure of tasks and MRI features. To address this issue, we proposed a fused group lasso regularization to model the underlying structures, involving 1) a graph structure within tasks and 2) a group structure among the image features. To this end, we present a multi-task feature learning framework with a mixed norm of fused group lasso and â„“2,1$ \ell _{2,1} $-norm to model these more flexible structures. For optimization, we employed the alternating direction method of multipliers (ADMM) to efficiently solve the proposed non-smooth formulation. We evaluated the performance of the proposed method using the Alzheimerâ€™s Disease Neuroimaging Initiative (ADNI) datasets. The experimental results demonstrate that incorporating the two prior structures with fused group lasso norm into the multi-task feature learning can improve prediction performance over several competing methods, with estimated correlations of cognitive functions and identification of cognition-relevant imaging markers that are clinically and biologically meaningful.",2018,Neuroinformatics
Outâ€ofâ€Sample Return Predictability: A Quantile Combination Approach,"Summary 
This paper develops a novel forecasting method that minimizes the effects of weak predictors and estimation errors on the accuracy of equity premium forecasts. The proposed method is based on an averaging scheme applied to quantiles conditional on predictors selected by LASSO. The resulting forecasts outperform the historical average, and other existing models, by statistically and economically meaningful margins. Copyright Â© 2016 John Wiley & Sons, Ltd.",2017,Journal of Applied Econometrics
2D QSAR and Virtual Screening based on Pyridopyrimidine Analogs of Epidermal Growth Factor Receptor Tyrosine Kinase.,"BACKGROUND
Epidermal Growth Factor Receptor tyrosine kinase (EGFR) is an important anticancer drug target. Series of pyridopyrimidine analogs have been reported as EGFR inhibitors and they inhibit by binding to the ATP binding pocket of the tyrosine kinase domain.


OBJECTIVE
To identify key properties of pyridopyrimidine analogs involved in the inhibition of the EGFR protein tyrosine kinase by developing 2D QSAR model.


METHODS
Variable selection was performed by least absolute shrinkage and selection operator (LASSO) method and multiple linear regression (MLR) method was applied by using Build QSAR software to develop QSAR model. Model validation was done by Leave One Out method (LOO). Further, based on the bioactive and structural similarity, virtual screening was performed using Pubchem database. Using the developed QSAR model and Molinspiration server, PIC50 values and kinase inhibition activity were predicted for all the virtually screened compounds respectively.


RESULTS
The best QSAR model consists of two descriptors namely Basak and MOE type descriptors, and has R2 = 0.8205, F= 57.129 & S = 0.308 and the validation results show significant statistics of R2/cv = 0.655, Average standard deviation = 0.416. 140 compounds were obtained from virtual screening and the predicted PIC50 of all these compounds are in the range of 4.73 - 6.78. All the compounds produce positive scores which suggest that the compounds may have good kinase inhibitory profile.


CONCLUSION
This developed model may be useful to predict EGFR inhibition activity (PIC50) for the newly synthesized pyridopyrimidines analogs.",2016,Current computer-aided drug design
Forecasting tree mortality using change metrics derived from MODIS satellite data,"Insect-induced tree mortality can cause substantial timber and carbon losses in many regions of the world. There is a critical need to forecast tree mortality to guide forest management decisions. Moderate Resolution Imaging Spectroradiometer (MODIS) satellite imagery provides inexpensive and frequent coverage over large areas, facilitating forest health monitoring. This study examined time series of MODIS satellite images to forecast tree mortality for a Pinus radiata plantation in southern New South Wales, Australia. Dead tree density derived from ADS40 aerial imagery was used to evaluate the performance of change metrics derived from time series of MODIS-based vegetation indices. Continuous subset selection by LASSO regression and model assessment using a variant of the bootstrap were used to select the best performing change metrics out of a large amount of predictor variables to account for over-fitting. The results suggest that 250 m 16-daily MODIS images are effective for forecasting tree mortality. Seasonal change metrics derived from the Normalized Difference Vegetation Index (NDVI) outperformed the Enhanced Vegetation Index (EVI) and the Normalized Difference Infrared Index (NDII). Temporal analysis illustrated that optimal forecasting power was obtained using change metrics based on three years of satellite data for this population. The forecast could be used to optimise the scheduling of detailed forest health surveys and silvicultural operations which currently are planned based on stratified, annual assessments. This coarse-scale, spatio-temporal analysis represents a potentially cost-effective early warning approach to forecasting tree mortality in pine plantations by identifying compartments that require more detailed investigation.",2009,Forest Ecology and Management
"Amphibacillus fermentum sp. nov. and Amphibacillus tropicussp. nov., New Alkaliphilic, Facultatively Anaerobic, Saccharolytic Bacilli from Lake Magadi","New alkaliphilic, saccharolytic, rod-shaped, gram-positive bacteria resistant to heating and drying and phylogenetically affiliated to the Bacilluslineage were isolated under strictly anaerobic conditions from sediments of the alkaline and highly mineralized Lake Magadi. Strain Z-7792 forms endospores; in strain Z-7984, endospore formation was not revealed. The strains are capable of both anaerobic growth (at the expense of fermentation of glucose and certain mono- and disaccharides with the formation of formate, ethanol, and acetate) and aerobic growth. Among polysaccharides, the strains hydrolyze starch, glycogen, and xylan. Yeast extract or methionine are required for growth. The strains are strict alkaliphiles exhibiting obligate requirement for Na+and carbonate ions, but not for Clâ€“ions. Growth occurs at a total mineralization as high as 3.3â€“3.6 M Na+, with an optimum at 1â€“1.7 M Na+. Strain Z-7792 is an obligate alkaliphile with a pH growth range of 8.5â€“11.5 and an optimum of 9.5â€“9.7. Strain Z-7984 grows in a pH range of 7.0â€“10.5 with an optimum at 8.0â€“9.5. Both strains are mesophiles having a growth optimum at 37â€“38Â°C. The G+C contents of the DNA of strains Z-7792 and Z-7984 are 39.2 and 41.5 mol %, respectively. These isolates of facultatively anaerobic, strictly alkaliphilic, Na+-dependent bacilli can be considered representatives of the ecological group adapted to life at drying-up shoals of soda lakes. Because of their independence of NaCl and lack of obligate dependence on sodium carbonates, the isolates are to be assigned to athalassophilic organisms. According to their physiological and phylogenetic characteristics, they taxonomically belong to group 1 of the species of bacilli with a low G+C content and occupy a position intermediate between the genera Amphibacillusand Gracilibacillus.The isolates are described as new species of Amphibacillus: A. fermentum(type strain, Z-7984T) and A. tropicus(type strain, Z-7792T).",2004,Microbiology
Abstract LB-296: Tumor tissue microRNA expression in association with triple negative breast cancer recurrence and mortality,"Proceedings: AACR Annual Meeting 2014; April 5-9, 2014; San Diego, CA

Background Triple-negative breast cancer (TNBC) accounts for 15-20% of breast cancers in the United States1. Compared with other breast cancer patients, TNBC displays high rates of metastasis, has poorer prognosis, and has no targeted therapies. microRNAs are small non-coding RNAs that function in transcriptional and post-transcriptional regulation of gene expression. Recent studies, primarily based on cell-line and animal studies, suggest that miRNA expression may be related to cancer metastasis and prognosis1-5.

Purpose To systematically investigate associations of tumor expression of 38 miRNAs that have been previously implicated in breast cancer prognosis with TNBC recurrence and cancer-specific mortality.

Method Included in the study were 456 TNBC cases recruited by the Shanghai Breast Cancer Survival Study between March 2002 and April 2006 and aged 20 to 75 years at diagnosis. Information on breast cancer diagnosis, treatment, demographics, lifestyle factors, and disease progression was collected approximately 6 months after diagnosis and reassessed at 18, 36, and 60 months after diagnosis in follow-up interviews. Information on disease recurrence and mortality was collected via in-person follow-up surveys and linkages with population-based cancer registry and vital statistics databases. miRNA expression levels in formalin-fixed, paraffin-embedded breast cancer tissue sections were measured using the NanoString nCounter assay. The association of miRNA expression with breast cancer recurrence and mortality was evaluated by Cox regression analysis with adjustment for age at diagnosis and TNM stage (I-IV).

Results Of the 38 miRNAs evaluated, expression levels of miR-374b (P=0.0022), miR-148a (P=0.0029), miR-126 (P=0.0059), and miR-218 (P=0.0087) were significantly and inversely associated with recurrence and breast cancer mortality among TNBC patients independent of age and TNM stage. The directions of association were consistent with those previously reported in the literature. A composite score derived from the expression levels of these four miRNAs was more significantly associated with breast cancer recurrence and mortality (P=0.0001), with hazard ratios (95% confidence interval) of 1.2 (0.77-2.0), 0.53 (0.30-0.94), and 0.23 (0.11-0.48) for the second to fourth quartiles compared with the lowest quartile of scores.

Conclusion In this, the largest study to date of tumor miRNA expression and TNBC outcomes, we found that miR-374b, miR-148a, miR-126, and miR-218, were individually and jointly associated with TNBC prognosis.

1. Cascione L, Gasparini P, Lovat F et al., Integrated MicroRNA and mRNA Signatures Associated with Survival in Triple Negative Breast Cancer. PLoS ONE 2013 8(2): e55910

2. Voliniaa S, Galassoa M, Sanaa M, et al., Breast cancer signatures for invasiveness and prognosis defined by deep sequencing of microRNA, PNAS 2012 109, 3024-3029

3. Png K, Halberg N, Yoshida M et al. A microRNA regulon that mediates endothelial recruitment and metastasis by cancer cells, Nature 2012 481:190-194

4. Zhang Y, Yang P, Sun T et al., miR-126 and miR-126* repress recruitment of mesenchymal stem cells and inflammatory monocytes to inhibit breast cancer metastasis. Nature Cell Biology 2013 15, 284-294

5. Pencheva N & Tavazoie S Control of metastatic progression by microRNA regulatory networks. Nature Cell Biology 2013 15, 546-554

Citation Format: Yan Liu, Qiuyin Cai, Fei Ye, Ying Zheng, Jie Wu, Yinghao Su, Hui Cai, Ping-Ping Bao, Wei Zheng, Wei Lu, Xiao-Ou Shu. Tumor tissue microRNA expression in association with triple negative breast cancer recurrence and mortality. [abstract]. In: Proceedings of the 105th Annual Meeting of the American Association for Cancer Research; 2014 Apr 5-9; San Diego, CA. Philadelphia (PA): AACR; Cancer Res 2014;74(19 Suppl):Abstract nr LB-296. doi:10.1158/1538-7445.AM2014-LB-296",2014,Cancer Research
Variation in gene transcript profiles of two V1a-type arginine vasotocin receptors among sexual phases of bluehead wrasse (Thalassoma bifasciatum).,"The neurohypophyseal hormone arginine vasotocin (AVT) mediates behavioral and reproductive plasticity in vertebrates, and has been linked to the behavioral changes associated with protogyny in the bluehead wrasse (Thalassoma bifasciatum). In this study, we sequenced full-length cDNAs encoding two distinct V1a-type AVT receptors (v1a1 and v1a2) from the bluehead wrasse, and examined variation in brain and gonadal abundance of these receptor transcripts among sexual phases. End point RT-PCR revealed that v1a1 and v1a2 transcripts varied in tissue distribution, with v1a1 receptor mRNAs at greatest levels in the telencephalon, hypothalamus, optic tectum, cerebellum and testis, and v1a2 receptor transcripts most abundant in the hypothalamus, cerebellum and gills. In the brain, v1a1 and v1a2 mRNAs both localized by in situ hybridization to the dorsal and ventral telencephalon, the preoptic area of the hypothalamus, the ventral hypothalamus and lateral recess of the third ventricle. Quantitative real-time RT-PCR revealed that relative abundance of these two receptor mRNAs varied significantly in brain and gonad with sexual phase. Relative levels of v1a2 mRNAs were greater in whole brain and isolated hypothalamus of terminal phase (TP) male wrasse compared to initial phase (IP) males or females. In the gonad, v1a1 mRNAs were at levels 2.5-fold greater in the testes of IP males - and 4-5-fold greater in the testes of TP males - compared to the ovaries of females. These results provide evidence that V1a-type AVT receptor transcript abundance in the hypothalamus and gonads of bluehead wrasse varies in patterns linked to sexual phase, and bestow a foundation for future studies investigating how differential expression of v1a1 and v1a2 teleost AVT receptors links to behavioral status and gonadal function in fish more broadly.",2012,General and comparative endocrinology
Phillips-Inspired Machine Learning for Band Gap and Exciton Binding Energy Prediction.,"Here in this work, inspired by Phillips' ionicity theory in solid-state physics, we directly sort out the critical factors of the band gap's feature correlations in the machine learning architected with the Lasso algorithm. Even based on a small 2D materials dataset, we can fundamentally approach an accurate and rational model about the band gap and exciton binding energy with robust transferability to other databases. Our machine learning outputs can reveal the exact physics pictures behind the predicted quantity as well as the ""secondary understanding"" of the correlation between the approximated physics models in exciton. This work stressed the significant value of physics endorsement on the ML algorithm and provided a symbolic-regression solution for the ""Few-Shot"" training scheme for the ML technology in materials science. Moreover, physics-inspired secondary understanding could be an essential supplement for machine learning in scientific research fields.",2019,The journal of physical chemistry letters
[Stellar Alpha Element Abundance Estimation Using LASSO Algorithm].,"In this paper, a new method based on LASSO algorithm is studied for the estimation of stellar alpha element abundance. The information of alpha elements (O, Mg, Ca, Si, and Ti) of massive stars will help us to better understand the evolution of the galaxy. Presently the main method of determining the alpha element abundances from the low resolution spectra is the template matching method. However, it is difficult for us to optimize the algorithm parameters and the algorithm is sensitive to the noise. Thus, it is necessary to study the new method to determine the abundance. The experimental results show that the accuracy of LASSO algorithm on ELODIE spectra is 0.003 (0.078) dex. To explore the impact of the spectral resolution variation, we use ELODIE spectra to generate the spectral data sets with following resolutions: 42 000, 21 000, 10 500, 4 200 and 2 100 by using the Gaussian convolution. The results of the LASSO algorithm on these data sets are 0.003 3 (0.078) dex, -0.05 (0.059) dex, -0.007 (0.069) dex and -0.004 5 (0.067) dex, respectively. These results show that the LASSO algorithm is not sensitive to the change of the resolution. In order to verify the robustness of LASSO algorithm against the change of SNRs, we use ELODIE to generate the spectral data sets with following SNRs: 30, 25, 20, 15 and 5. The results of LASSO algorithm on the above data sets are: -0.002 (0.076) dex, -0.090 (0.073) dex, 0.003 6 (0.075) dex, 0.007 6 (0.078) dex and -0.009 (0.080) dex, respectively. Thus, LASSO algorithm is not sensitive to the change of SNR. Therefore, the LASSO algorithm is suitable for low resolution and low SNR spectra such as LAMOST and SDSS spectra. The accuracy of Lasso algorithm on the SDSS spectra is 0.003 7 (0.097) dex, and the results of LASSO on globular and open clusters show good agreement with literature values (within 1Ïƒ). Therefore, the LASSO algorithm can be used to estimate the alpha element abundances of stars.",2017,Guang pu xue yu guang pu fen xi = Guang pu
Toward creating simpler hydrological models: A LASSO subset selection approach,"A formalised means of simplifying hydrological models concurrent with calibration is proposed for use when nonlinear models can be initially formulated as over-parameterised constrained absolute deviation regressions of nonlinear expressions. This provides a flexible modelling framework for approximation of nonlinear situations, while allowing the models to be amenable to algorithmic simplification. The degree of simplification is controlled by a user-specified forcing parameter Î». That is, an original over-parameterised linear model is reduced to a simpler working model which is no more complex than required for a given application. The degree of simplification is a compromise between two factors. With weak simplification most parameters will remain, risking calibration overfitting. On the other hand, a high degree of simplification generates inflexible models. The linear LASSO (Least Absolute Shrinkage and Selection Operator) is utilised for the simplification process because of its ability to deal with linear constraints in the over-parameterised initial model. Models are first formulated as linearly-constrained linear functions.The linear functions can be linear combinations of pre-calculated nonlinear functions.The degree of simplification is controlled by a user-specified forcing parameter.Simplification and calibration are carried out by linear programming minimisation.",2015,Environ. Model. Softw.
"Palynology of the umia plant beds of Kutch, Western India, 1: Stratigraphic palynology of the Bhuj exposures near Walkamata (Kutch district, Gujarat State)","The present paper deals with the stratigraphic palynology of the Bhuj exposures near Walkamata on the bank of the Bhukhi nala (rivulet). 
 
The palynological assemblage is dominated by Araucariacites, Callialasporites, Alisporites and hystrichosphaeres. Among the other, important components are: Aequitriradites,? Appendicisporites, Contignisporites, Klukisporites, Cicatricosisporites, Staplinisporites, Polycingulatisporites, Coronatispora, Classopollis, and Schizosporis. 
 
The Bhuj palynological assemblage described here and the assemblage reported by H. P. Singh et al. (1964) from Trambau and Ghuneri is comparable with the Lower Cretaceous (Neocomian-Aptian) assemblages described by Balme (1957), Cookson and Dettmann (1957), Pocock (1962), Dettmann (1963) and C. Singh (1964).",1967,Review of Palaeobotany and Palynology
How to use the rbsurv Package,"The rbsurv package is designed to select survival-associated genes, based on a likelihood function. It utilizes the partial likelihood of the Cox model which has been the basis for many of the existing methods. Our algorithm is simple and straight-forward, but its functions such as the generation of multiple gene models and the incorporation of significant risk factors are practical. For robustness, this package also selects survivalassociated genes by separating train and validation sets of samples because such a crossvalidation technique is essential in predictive modeling for data with large variability. It employs forward selection, the limitation of which is mitigated by generating a series of gene models and selecting an optimal model. Furthermore, iterative runs after putting aside the previously selected genes can discover the masked genes that may be missed by forward selection (see Cho et al. for details). The rbsurv package employs libraries survival and Biobase.",2007,
A Multilevel Framework for Sparse Optimization with Application to Inverse Covariance Estimation and Logistic Regression,"Solving l1 regularized optimization problems is common in the fields of computational biology, signal processing and machine learning. Such l1 regularization is utilized to find sparse minimizers of convex functions. A well-known example is the LASSO problem, where the l1 norm regularizes a quadratic function. A multilevel framework is presented for solving such l1 regularized sparse optimization problems efficiently. We take advantage of the expected sparseness of the solution, and create a hierarchy of problems of similar type, which is traversed in order to accelerate the optimization process. This framework is applied for solving two problems: (1) the sparse inverse covariance estimation problem, and (2) l1-regularized logistic regression. In the first problem, the inverse of an unknown covariance matrix of a multivariate normal distribution is estimated, under the assumption that it is sparse. To this end, an l1 regularized log-determinant optimization problem needs to be solved. This task is challenging especially for large-scale datasets, due to time and memory limitations. In the second problem, the l1-regularization is added to the logistic regression classification objective to reduce overfitting to the data and obtain a sparse model. Numerical experiments demonstrate the efficiency of the multilevel framework in accelerating existing iterative solvers for both of these problems.",2016,SIAM J. Scientific Computing
Visualization of Nucleic Acids,"The Classic Methods of Nucleic Acid Visualization for Light Microscopy, J.-M. Exbrayat Imaging Nucleic Acids with Scanning Probe Microscopes, W.M. Heckl and A. Engel The Spreading of Nucleic Acids, E. Delain and E. Le Cam DNA in Its Aqueous Environment, A. Leforestier and J. Dubochet Ultrastructural Cytochemistry, M. Derenzini In Situ Detection of Nucleic Acids by the Nuclease-Gold Method, C. Cheniclet, S. Garzon, and M. Bendayan Ultrastructural Detection of Nucleic Acids by Immunocytology, M. Thiry Visualization of DNA in Living Cells: Cytometric Approaches, S. Paillasson, J.M. Millot, M. Manfait, and X. Ronot Dynamical Study of Nucleic Acids by Autoradiography, Thomas, Cavalier, Gouranton Molecular Biological Techniques Used in the Visualization of Nucleic Acids, C. Perrett In Situ Hybridization on Chromosomes: Clinical Applications, J. Chiesa and J.P. Bureau Ultrastructural In Situ Hybridization on Chromosomes, M. Wu Detection of Nucleic Acid Sequences on Whole Cells with or without Genomic Amplification, G. Lizard, Y. Chardonnet, and D. Schmitt In Situ Hybridization for Electron Microscopy, G. Morel, D. Le Guellec, H. Mertani, and A. Trembleau Nonisotopic In Situ Hybridization: A Powerful Tool for Diagnosis of Viral Infection in Routine Pathology, P. Brousset, G. Daste, D. Roda, and J. Selves Visualization and Identification of Viral Nucleic Acids, F. Puvion-Dutilleul Ultrastructural Detection of Nucleic Acid in the Glomerular Basement Membrane of Lupus Nephritis, D. Malide and M. Bendayan Nucleic Acids-Ligand Interactions, E. Le Cam and E. Delain",1995,
Books Received,"Anyone involved in recruiting patients for clinical trials understands the importance and frustration of this process. The best-written protocols ~d most meaningful research frequently hinge on whether the right panents are enrolled and remain in the study. It appears that researchers, and es~cially n~w investigators, spend little time in planning appropriate patient recruitment. The inability to effectively recruit subjects can quickly damage both the investigator's as well as the study site's reputation for conducting efficient trials. Therefore, books such as this one are extremely valuable. Although this book is over 300 pages long, it is quite easy to read and is organized in a fashion that lends itself to quick retrieval of information. The text is divided primarily into two major parts: (I) overview and eleme.nts of recruitment and (2) synthesis of these elements. Although there IS some redundancy, the information presented is insightful not only as to what is involved in the recruitment process, but also as to how some of the inevitable obstacles that these authors have obviously endured may be overcome. The major chapters of part I discuss sources of patients for clinical trials, methods of recruiting, ethical issues involved in .rec~itment, and important economic issues. The chapters in part II pnmanly focus on developing a recruitment strategy and overcoming obstacles when recruitment is not going well. Also included in this section is a chapter that deals with publishing data pertaining to the recruitment process. This chapter is quite interesting and should prove helpful to researchers and authors alike. In my opinion, the most useful feature of this book is its many samples of actual brochures, advertisements, letters, and o~er patient-recruitment material. As a result, the text is a very practical guide to recruitment rather than simply a collection of theoretical science that will be read once and then put on the shelf. I know that our clinical research service will find this book very useful, especially when developing new approaches to patient recruitment, advertising, and dealing with recruitment failures. Another major advantage of this text is its well-organized and extensive subject index. The appendix is also insightful and consists of a list of commonly asked questions about recruitment problems as well as the authors' .attempts to answer these questions in a very specific and practical fashion, The only drawback to this section is that it is not long enough, I believe that there are many other questions that are frequently raised and I would have found a more extensive question-and-answer format beneficial. A problem with this book is the overwhelming number of tables and charts. There are 81 tables and 76 figures. The text is interrupted frequently and many times these charts offer little useful information. An issue not addressed in the book is that of recruiting critically ill patients who are unable to give informed consent themselves into clinical trials. This poses an ever-increasing problem for investigators and institutional review bo~ds alike. State laws vary considerably, creating controversy and.confusion. Although a minor point, the book also could be improved by including references at the conclusion of each chapter rather than at the very end of the book. Overall, PatientRecruitmentin ClinicalTrials is an excellent resource for anyone involved in research. We have run across numerous patientrecruitment problems in our research program in the past that this book could have helped us with-it fills a definite void. Most textbooks and articles that deal with patient recruitment are much less practical and applicable in specific situations. This book is both. The authors' writing style should be applauded. MARK W.TODD, Phann.O. AssociateDirector Departmentof Pharmacy University MedicalCenter ClinicalAssociateProfessor CollegeofPharmacy University ofFlorida Jacksonville. Florida32209",1993,Annals of Pharmacotherapy
Did the genomic data flood overrun the statistical levee ? Statistical approaches to analyse genomic data ( without drowning ),"Some practical aspects in design and analysis of biomarker studies Stephan Lehr Baxter Innovations GmbH, Vienna, Austria The aim of this presentation is to set the scene for the workshop from a practical perspective. In particular, some definitions and guidelines will be sketched, possible pitfalls in the development of a prediction rule based on highdimensional data will be demonstrated and clinical trial designs for predictive biomarker validation will be discussed. Test statistics for two-group comparisons of zero-inflated intensity values Andreas Gleiss, Mohammed Dakna , Harald Mischak and Georg Heinze 1 Section for Clinical Biometrics, Center for Medical Statistics, Informatics and Intelligent Systems, Medical University Vienna, Austria 2 Mosaiques Diagnostics GmbH, Hannover, Germany Many experiments conducted in molecular biology compare intensity values obtained by micro-RNA transcriptomics, proteomics or metabolomics ('Omics') procedures between two groups of independent biological samples differing in an experimental condition or in the health status of the subjects. A special characteristic of such data is the frequent occurrence of zero intensity values caused by compounds (e.g., micro RNAs, peptides or metabolites) that cannot be detected in some samples. Zero intensities can arise either by true absence of a compound or by a signal that is below a technical limit of detection. In the literature the distribution of observed signals is viewed either as a mixture of a binomial distribution (absence or presence of a detectable signal) and a continuous distribution (intensity if signal is present) or as a left-censored continuous distribution. While so-called two-part tests compare mixture distributions between groups, one-part tests treat the zero-inflated distributions as left-censored. We propose to employ a Left-Inflated Mixture model to combine these two approaches. We perform a comparative simulation study using the setting of a typical omics experiment with the aim to test differential expression in several hundreds of compounds simultaneously. Both types of distributional assumptions as well as combinations of both are considered when comparing power and effect estimation across the various methods considered. We discuss issues of application using an example from proteomics. We conclude that the considered tests generally show their strengths in scenarios satisfying their respective distributional assumptions. If it is a priori unclear which distributional assumptions best fit the data at hand then a two-part Wilcoxon test can be recommended. Assuming a log-normal distribution the Left-Inflated Mixture model provides direct estimates for the proportions of the two considered types of zero intensities. Stopping rules for sequential trials in high-dimensional data Sonja Zehetmayer Section for Medical Statistics, Center for Medical Statistics, Informatics and Intelligent Systems, Medical University Vienna, Austria Sequential trials have been proposed that allow for an early stopping of the trial in studies involving large scale hypothesis testing as in microarray experiments. To control the False Discovery Rate, multiplicity adjustment is required only for the number of hypotheses but not for the number of interim looks (under suitable assumptions asymptotically for an increasing number of hypotheses). In this talk we introduce novel stopping rules that stop a trial early if a certain success criterion is fulfilled based on the proportion of rejected hypotheses. Next Generation Sequencing Data Analysis: From ChIP-Seq read islands to epigenomics information Markus Jaritz Research Intitute of Molecular Pathology (IMP), Campus Vienna Biocenter Within the Epigenomics Gen-Au project, several hundred samples have been sequenced using ChIP-Seq technology since 2008. Despite powerful open source tools, many scripts, workflows and analysis strategies had to be developed. We present an overview of our analysis pipeline, addressing issues such as sequencing quality measurements, sample similarity, peak calling, peak overlaps and motif finding. The Relevance of Next Generation Sequencing for Personalized Medicine Christoph Bock CeMM Research Center for Molecular Medicine of the Austrian Academy of Sciences, Vienna, Austria Department of Laboratory Medicine, Medical University of Vienna, Vienna, Austria Max Planck Institute for Informatics, SaarbrÃ¼cken, Germany In my presentation, I will summarize the role of next generation sequencing for personalized medicine and highlight the relevance of bioinformatic and biostatistical methods for interpreting the vast amount of genome, epigenome and transcriptome data that are being generated at CeMM and at many genomics institutes worldwide. The talk will also discuss our ongoing work with the European BLUEPRINT project consortium (http://blueprint-epigenome.eu/) aimed at establishing comprehensive epigenome maps of hematopoietic cell types and various types of leukemia cells. I will conclude by outlining an integrated computational/experimental approach toward rational design of epigenetic combination therapies (Bock and Lengauer 2012 Nature Reviews Cancer), which we pursue in collaboration between the CeMM Research Center for Molecular Medicine and the Medical University of Vienna. Contact: cbock@cemm.oeaw.ac.at and http://epigenomics.cemm.oeaw.ac.at. Class-imbalanced class prediction for high-dimensional data Lara Lusa and Rok Blagus Institute for Biostatistics and Medical Informatics, Faculty of Medicine , University of Ljubljana, Slovenia The goal of class prediction studies is to develop rules to accurately predict the class membership of new samples. The rules are derived using the values of the variables available for each subject: the main characteristic of highdimensional data is that the number of variables greatly exceeds the number of samples. Frequently the classifiers are developed using class-imbalanced data, i.e., data sets where the number of samples in each class is not equal. Standard classification methods used on class-imbalanced data often produce classifiers that do not accurately predict the minority class; the prediction is biased towards the majority class. High-dimensionality poses additional challenges when dealing with class-imbalanced prediction. We show how class-imbalance impacts six types of classifiers, using simulated data and a publicly available data set from a breast cancer geneexpression microarray study. We also investigate the effectiveness of some strategies that are available to overcome the effect of class imbalance. We devote special attention to SMOTE, a popular oversampling technique and to boosting methods. Gene selection in microarray survival studies under non-proportional hazards Daniela Dunkler and Georg Heinze Section for Clinical Biometrics, Center for Medical Statistics, Informatics and Intelligent Systems, Medical University Vienna, Austria Many studies aim at finding, among a huge number of candidate genes, those which are possibly linked to survival. With non-proportional hazards Cox regression (CR) could lead to underor overestimation of effects. Given the large number of genes it is not feasible to determine the functional form of the time dependency for each gene. Moreover, researchers are often interested in a risk score, which could be used to identify high and low risk groups at the start of follow-up. Such a score should be interpretable irrespective of time-dependent effects. We consider the odds of concordance, which are defined by OC=c/(1-c) where c is the concordance probability P(T1<T0), the probability that a person randomly selected from group G1 dies earlier than a person randomly selected from G0. Since gene expressions are not binary, we generalize OC to continuous data. Under proportional hazards, OC is estimated by the CR hazard ratio. Under non-proportional hazards OC can be obtained from weighted Cox regression (WCR) or a novel method based on conditional logistic regression, called concordance regression (CCR). The latter has the additional advantage that it has an attractive nonparametric analogue. We demonstrate properties and aspects of application of these novel methods in the analysis of real and simulated studies. We also briefly discuss the possibility of their application in the context of regularized regression models with a high-dimensional predictor space. Concluding, OC and c are concise single numbers useful for clear decisions at time zero. They can be utilized to select genes irrespective of proportional hazards and are obtained by WCR or CCR. WCR and CCR are available as R packages coxphw and concreg, respectiveley, on CRAN. Regularized regression for omics data: Why one size doesnâ€™t fit all, but you nevertheless should try Harald Binder Institute of Medical Biostatistics, Epidemiology and Informatics, University Medical Center Johannes Gutenberg University Mainz, Germany Modern â€œomicsâ€ techniques for molecular measurement, such as SNP microarrays or RNA-Seq, promise improved prognosis for patients or even personalized medicine. For statisticians this means the challenge of linking highdimensional covariate vectors to clinical endpoints, such as survival, for identifying important molecular entities. While univariate techniques are popular for controlling false discovery rates, they do not directly provide risk prediction models. Regularized regression techniques, such as the lasso or componentwise boosting, allow to fit regression models with high-dimensional covariate vectors, providing automatic selection of a small number of potentially important molecular entities, e.g. SNP or gene signatures. Unfortunately, application to different types of molecular platforms is not straightforward. Potential pitfalls will exemplarily be illustrated for componentwise boosting in applications to SNP data and to RNA-Seq data. For both types of molecular measurements, the variance of c",2013,
"Contacts, Contracts, and Green Bean Schemes: Liberalisation and Agro-Entrepreneurship in Burkina Faso","Soon after midnight in early January 1994, an Air Afrique cargo
 jet took off from the airport of Bobo-Dioulasso in Burkina Faso. It roared north over the sleeping city carrying 15 tons of premiere-qualite , extra-fine green beans bound for Paris. Within several hours, the beans would be unloaded and trucked to the sprawling wholesale docks of Rungis, on the outskirts of the French capital, and put up for sale to restaurant and supermarket buyers from throughout Europe. The jet's blast marked the first time in over a decade that a cargo flight had carried the region's garden produce overseas. It represented, perhaps, the opening of an isolated and stagnant economy, the linking of local producers to the global market. It was exactly the kind of â€˜take-offâ€™ the World Bank hoped for from this poor but deadly earnest country when it began a structural adjustment loan programme in Burkina Faso in 1991. The months of negotiations and labour preceding this landmark flight, however, had hardly gone as smoothly as the lift-off from the darkened savannah runway. Indeed, the whole enterprise was so fraught with mishap that simply the arrival of that first shipment in Europe mattered more, especially to those who initiated the â€˜green bean schemeâ€™, than the fact that it made no money.",1997,Journal of Modern African Studies
Publish or perish? Palestrina and print culture in 16th-century Italy,"In 1554 Giovanni Pierluigi da Palestrina had his earliest edition, the Missarum liber primus, printed in Rome. This sumptuous folio choirbook was dedicated to his patron, Pope Julius III. This publication, along with his Primo libro di madrigali a quatro voce of 1555, marked an auspicious publishing debut for the composer. Yet for the next 17 years, Palestrina brought out only a handful of publications, while the works of his distinguished contemporary Orlando di Lasso were printed in great profusion. It was not until some 20 years later, in the 1570s, that Palestrina ' s music, particularly his sacred works, emerged with more frequency from Roman and Venetian presses. Furthermore, it appears that the Roman composer did not gain widespread recognition until his twilight years, when Venetian editions of his sacred music began to appear in rapid succession. Why were so few of Palestrina ' s works published during the prime of his life? Why did he wait so long to see his music in print? What role did he play in the dissemination of his music? This study will address these issues by examining the relationship between the composer, his music printers, and his patrons. In particular, it will explore the differences between the printing industries of 16th- century Rome and Venice, and what infl uence this may have had on the transmission of Palestrina ' s music and the reputation of the composer.",2007,Early Music
