title,abstract,year,journal
Predicting failure risk using financial ratios: Quantile hazard model approach,"Abstract This study examines the role of financial ratios in predicting companiesâ€™ default risk using the quantile hazard model (QHM) approach and compares its results to the discrete hazard model (DHM). We adopt the LASSO method to select essential predictors among the variables mentioned in the literature. We show the preeminence of our proposed QHM through the fact that it presents a different degree of financial ratiosâ€™ effect over various quantile levels. While DHM only confirms the aftermaths of â€œstock return volatilitiesâ€ and â€œtotal liabilitiesâ€ and the positive effects of â€œstock priceâ€, â€œstock excess returnâ€, and â€œprofitabilityâ€ on businesses, under high quantile levels QHM is able to supplement â€œcash and short-term investment to total assetsâ€, â€œmarket capitalizationâ€, and â€œcurrent liabilities ratioâ€ into the list of factors that influence a default. More interestingly, â€œcash and short-term investment to total assetsâ€ and â€œmarket capitalizationâ€ switch signs in high quantile levels, showing their different influence on companies with different risk levels. We also discover evidence for the distinction of default probability among different industrial sectors. Lastly, our proposed QHM empirically demonstrates improved out-of-sample forecasting performance.",2018,The North American Journal of Economics and Finance
Closing the U.S. gender wage gap requires understanding its heterogeneity,"In 2016, the majority of full-time employed women in the U.S. earned significantly less than comparable men. The extent to which women were affected by gender inequality in earnings, however, depended greatly on socio-economic characteristics, such as marital status or educational attainment. In this paper, we analyzed data from the 2016 American Community Survey using a high-dimensional wage regression and applying double lasso to quantify heterogeneity in the gender wage gap. We found that the gap varied substantially across women and was driven primarily by marital status, having children at home, race, occupation, industry, and educational attainment. We recommend that policy makers use these insights to design policies that will reduce discrimination and unequal pay more effectively.",2018,arXiv: Econometrics
Knowledge and practice concerning swallowing disorders in hemiplegic patients among nurses of Boboâ€“Dioulasso urban primary health care centers in Burkina Faso,"Introduction
The quality of management of swallowing disorders (SD) from admission onwards influences the patients' nutritional status and their prognosis. Neurological diseases are the main causes of SD, affecting one in three patients with hemiplegia (Hp). In Burkina Faso (BF), primary health care center (PHCC) nurses are the first to manage these patients, but there are no data related to their management of SD. The study aimed to assess knowledge and practices regarding SD in Hp among PHCC nurses in Bobo-Dioulasso, a main center for care of Hp in BF.


Methods
This cross-sectional study was performed August 1-September 15 2014. Subjects underwent a standardized survey to determine their knowledge and practices concerning SD in Hp.


Results
Of 125 nurses surveyed (83.3% of the targeted workers), 82.4% had experience of caring for Hp. The role of the central nervous system in cases of Hp and SD was recognized by 56.8% of nurses; 42.3% knew that SD can cause aspiration, and 36.0% were aware of rescue techniques to use when aspiration occurs; 39.2% correctly assessed the impact on nutritional status of SD. Knowledge in this area was better among respondents who recently completed training school. 65.6% and 1.6% respectively knew about the impact of posture and the texture of food on the ability to swallow. Among the 103 nurses with experience of treating Hp, 68.0% considered clinical interview the best way to detect SD, and 30.1% did not give the patient advice in this area. In multivariate analysis, detection of SD was associated with good knowledge of the value of voice disorders (ORÂ =Â 3.5, 95% CIÂ =Â 1.4-8.1; pÂ =Â 0.005).


Conclusion
Few nurses had been warned of the connection between Hp and SD, which are classic issues and potential complications. Practices varied, but most were not in accord with what are recognized as good strategies for SD screening and management. In order to improve care of Hp, neurological and nutritional training should be accompanied by specific training in SD, emphasizing screening and simple management.",2016,eNeurologicalSci
OP0021 Draft classification criteria for the anca associated vasculitides,"Background Classification criteria for the ANCA-associated vasculitides (AAVs) were developed in the 1980s prior to the use of ANCA testing and newer imaging techniques. The Diagnostic and Classification of the Systemic Vasculitides (DCVAS) study is an international project to update classification criteria for the systemic vasculitides. Objectives Development of draft classification criteria for Granulomatosis with Polyangiitis (GPA), Microscopic Polyangiitis (MPA) and Eosinophilic Granulomatosis with Polyangiitis (EGPA). Methods Three phases: 1) Expert panel review of cases to identify gold standard set of new cases of small vessel vasculitis; 2) Item reduction of >8000â€‰individual DCVAS items using data-driven and consensus methodology; 3) Lasso logistic regression models within each development set comparing each of the AAV types to other small and medium vessel vasculitides. Final criteria derived through clinical consensus, tested in validation set. The classification project has received financial support from the ACR and EULAR. Results The expert review process approved 2072/2871 (72%) of physician diagnosed DCVAS cases, including [724â€‰GPA, 291â€‰MPA, 226 EGPA, 51 polyarteritis nodose (PAN), 220 other small vessel disease (SVV)]. Data driven and expert consensus resulted in 91 items retained. Draft criteria, and sensitivity and specificity in table 1. Conclusions Draft classification criteria for GPA, MPA and EGPA have been created which reflect current practice and have good sensitivity and specificity. Acknowledgements DCVAS sites and expert panel members Disclosure of Interest None declared",2018,Annals of the Rheumatic Diseases
Oligochaete fauna of estuarine areas and lagoons on the northern Adriatic coast (Italy),"Abstract A survey conducted for several years in estuarine areas and lagoons on the northern coast of the Adriatic Sea shows that the oligochaete fauna in these environments is poor in species number, but the population density of some species sometimes reaches high values. Heterochaeta costata is present only in the estuarine stretch of the examined rivers. Tubificoides vestibulatus and Tubiflcoides swirencowi ate the most abundant and widely distributed species in the lagoons. The genera Aktedrilus, Tbalassodrilides and Limnoâ€driloides are present with two species (A. mediterraneus and A. cuneus), and one species, respectively. Enchytraeids are rare, only Grania sp. being found.",1994,Italian Journal of Zoology
"Sphaericin, a new lasso peptide from a rare actinomycete Planomonospora sphaerica","A new lasso peptide named sphaericin was isolated from the ISP2 agar medium culture of a rare actinomycete species Planomonospora sphaerica. Amino acid composition analysis on sphaericin gave totally 15 mole of amino acids (3 mole each of Gly, Ile, Pro, and 1 mole each of Arg, Glu, Leu, Phe, Ser, Tyr). In addition to the 15 mole of amino acids, NMR experiments indicated the presence of 3 mole of Trp. The structure of sphaericin was determined to be a peptide comprising 18 amino acids, with an additional peptide bond between the amino group of Gly-1 and the gamma-carboxyl group of Glu-9 forming a macrolactam ring, as demonstrated by analyses of TOF-MS/MS and NMR spectra. The solution three-dimensional structural analysis based on NOE experiments revealed that sphaericin possessed a typical lasso structure. Based on the genome data, a biosynthetic gene cluster of sphaericin was determined to consist of four genes including sphA, sphB1, sphB2, and sphC. Sphaericin showed a specific antibacterial activity against Micrococcus luteus at the dosage of 50 micro g /disk.",2016,European Journal of Organic Chemistry
On Concept and Characteristics of Crimes with Gangster Activities,"With reformation and economic development in China,the organized crimes with gangster activities occur one after the other,the crime which is also the peak modality of all of the organized crimes found nowadays in China.These crimes with gangster activities can stimulate the preliminary formation of the Mafia groups.The crimes own some organizational features as well as behavior ones of the Mafia groups.These crimes with gangsters activities indicate that an ordinary crime group is in the middle process of evolving into a gangster group(Mafia).Generally-speaking,the crimes with gangster activities are some delinquencies and criminal activities aiming at snatching illicit huge amounts of economic profits,the crime activities antagonize any country law.The spiritual dynamics of the crimes are driven by some corruptive sub-cultures.The comporting means of the crimes are violence,corrupting and lasso.The organized crimes with gangster activities severely disturb ordinary social and economic rules.",2006,Journal of Yunnan Police Officer Academy
Phylogeny of the snailfishes (Teleostei: Liparidae) based on molecular and morphological data.,"Liparidae (snailfishes) is one of the most diverse and abundant fish families in polar and deep-sea habitats. However, the evolution of this family is poorly known because of the rarity of many species and difficulties in scoring morphological characters. We perform phylogenetic analyses of Liparidae using sequences from two mtDNA genes, 16S (585 bp) and cytochrome b (426 bp), and 84 morphological characters from 24 species of Liparidae and 4 species of Cyclopteridae (outgroup). The present study confirms earlier hypotheses that the shallow-water genera, such as Liparis and Crystallichthys, occupy basal positions and that deep-water genera, such as Careproctus, Elassodiscus, Rhinoliparis, Paraliparis, Rhodichthys and Psednos, are increasingly derived. The later two genera form a terminal clade which does not include Paraliparis. The topology shows that the family has undergone a reductive type of evolution, with a gradual loss of characters (e.g. sucking disc/pelvic fins, pseudobranchial filaments, skin spinules). Nectoliparis, which had previously been placed either as the basal most genus or among the most derived genera, are found to occupy the most basal position among the taxa analyzed. This result indicates that the sucking disc has been lost at least twice during the evolution of the Liparidae. The basal position of Nectoliparis is supported by its plesiomorphic otolith morphology, whereas an advanced overgrown otolith ostium, unique among teleosts, is found to be apomorphic for a clade containing the derived genera: Paraliparis, Psednos, Rhinoliparis and Rhodichthys. We also identify the presence of probable nuclear inserts of mitochondrial DNA (Numts) in three species of Careproctus and in Elassodiscus caudatus.",2007,Molecular phylogenetics and evolution
Egg size in relation to fertilization dynamics in free-spawning tropical reef fishes,"In marine invertebrates that spawn by simply releasing their gametes into the water (free-spawning), fertilization success likely is often limited by low sperm concentrations, due to dispersion of mates and dispersal of gametes by water movements. Production of large, low density eggs might be advantageous when sperm concentrations consistently are low, because large target size might increase egg/sperm encounters, and more low than high density eggs could be produced per clutch. Although average fertilization success in the labrid Thalassoma bifasciatum is âˆ¼95% in both group spawns (in which multiple males compete for fertilizations by producing large quantities of sperm) and pair (mono-male) spawns, it is slightly lower in pair spawns, due to low level sperm limitation that arises because pair-spawning males release near the minimum number of sperm necessary for maximum fertilization. I examined whether variation in egg size and content in T. bifasciatum and other free-spawning fishes is related to variation in spawning mode, to assess whether compensatory production of large, low-density eggs might be contributing to high fertilization success in pair spawns. I found no difference between the volume or density of eggs of (1) pair- and group-spawning females of T. bifasciatum, or (2) pair-and group-spawning congeneric species of labrids, scarids, and serranids, or (3) labrids and scarids with vigorous, rapid spawning movements (which could turbulently diffuse gamete clouds) and those with slow movements. Further, egg density does not decline with increasing egg volume among those fishes. Assuming that egg size can affect fertilization success, then sperm limitation seems unlikely to represent a significant problem for pair-spawning T. bifasciatum, probably because mates place their vents close together during gamete release. The situation regarding sperm limitation in other fishes, and effects of environmentally generated water turbulence on it, are less clear. Interspecific variation in the size and content of these fishes' eggs may relate to provisioning of offspring for different larval life-histories.",2004,Oecologia
Predicting drug-target interactions using Lasso with random forest based on evolutionary information and chemical structure.,"The identification of drug-target interactions has great significance for pharmaceutical scientific research. Since traditional experimental methods identifying drug-target interactions is costly and time-consuming, the use of machine learning methods to predict potential drug-target interactions has attracted widespread attention. This paper presents a novel drug-target interactions prediction method called LRF-DTIs. Firstly, the pseudo-position specific scoring matrix (PsePSSM) and FP2 molecular fingerprinting were used to extract the features of drug-target. Secondly, using Lasso to reduce the dimension of the extracted feature information and then the Synthetic Minority Oversampling Technique (SMOTE) method was used to deal with unbalanced data. Finally, the processed feature vectors were input into a random forest (RF) classifier to predict drug-target interactions. Through 10 trials of 5-fold cross-validation, the overall prediction accuracies on the enzyme, ion channel (IC), G-protein-coupled receptor (GPCR) and nuclear receptor (NR) datasets reached 98.09%, 97.32%, 95.69%, and 94.88%, respectively, and compared with other prediction methods. In addition, we have tested and verified that our method not only could be applied to predict the new interactions but also could obtain a satisfactory result on the new dataset. All the experimental results indicate that our method can significantly improve the prediction accuracy of drug-target interactions and play a vital role in the new drug research and target protein development. The source code and all datasets are available at https://github.com/QUST-AIBBDRC/LRF-DTIs/ for academic use.",2018,Genomics
"Music manuscripts from the seventeenth to the twentieth centuries in stams, bressanone, salburg, and from ""vipiteno""","EnglishAt present the following are online in the RISM-OPAC (www.rism.info, since June 2010): about 6,800 titles from the Music Archives of the Cistercian Monastery Stams (A-st); approximately 4,000 titles from the Diocesan Archives Bressanone (I-BREd), around 1,800 listed titles, mainly music manuscripts, from the Music Archives of the Franscican Monastery of Salzburg (A-Sfr) and about 140 librettos from A-Sfr. These sources were, in part, evaluated in publications already. Identifications of works of significant international importance were made. Systematically, concerts habe been, and are still being staged, and scores and CD editions produced, which are based on sources made available by the RISM. Yet again, there is more to report on about these three musci collections: Recently new and surprising findings came to light during the ongoing work being done by RISM. From Stams, these unique pieces date back to aoound 1700, both sacred works and chamber music. Thay point to relations with the court music in Innsbruck. In Bressanone, choir-books from the early 17th century came to the fore. They were created within the circle of the Innsbruck Court music, and in many cases contain primary pieces fo evidence jor the oldest proof of works, like by Johann Sadlmayr, Rudelph di Lasso and others. They can be ascribed highest authenticity. Also, a rarity from Bressanone is a concentrated pool of about 100 music scores of brass and music from the mid-19th century. Through it we have, for the first time, got unmistakable insight into the history of brass band music in Tyrol, which has been dominant for centuries. The regional and international significance of the Music Archives of the Franscan Monastery of Salzburg is illustrated, for example, in the now, for the fist-time, elicited sources on works of the legenday 19 th century Franscican Father Peter Singer or by Egon Wellesz. A newly-discovered manuscript colection from ca. 1780 from ""Vipiteno""/South Tyrol was found in a private home in the Tyrolean Lachtal. It contains piano music by leading composers from the Southern German-Austrian areas, and Italian area, including an array of first-time substantiated pieces. Athough much has already been accomplished by RISM Tyrol-South Tyrol & OFM Austria, there is no end end sight for the need to coninue crucial documentation research in the future. francaisLe cataogue RISM-OPAC (www.rism.info, depuis Juin 2010) regroupe a present en ligne: environ 6800 titres provenent des archives musicales du monastere cistercien de Stams (A-ST), environ 40000 titres des archives du diocese de Bressanone (I-BREd), environ 1800 titres -principalement ainsi que pres de 140 libretti (A-Sfr). Ces sources ont deja ete en partie evaluees dans des publications, permettant l'identification d'oeuvres d'une importance internationale. Sur la base des sources rendues disponibles par le RISM, des concerts ont ete, et son toujours, systematiquement organises, et des partitions et des CD son produits. Cependant, il y a encore beaucoup a dire sur ces trois collections musicales: des decouvertes surprenantes ont ete recemment realisees au cours du travail du RISM. A Stams ces pieces uniques datant d'environ 1700, oeuvres sacrees ainsi que musique de chambre, indiquent des relations avec la musique de coure d'Innsbruck. A Bressanone, des livres de choeur du debut du XVIIeme siecle ont ete decouverts. Crees dans le cercle de la musique de cour d'Innsbruck, certains contiennent des pieces primaires ou des preuves les plus anciennes des oeuvres de Johann Stadlmayr, de Rudolph di Lasso et autres. Leur authenticite est sans conteste. Une rarete a egalement ete decouverte a Bressassone: un fonds de pres de 100 partitions de fanfares datant du milieu du XIXeme siecle. GrÃ¢ce a lui, nous disposons pour la premiere fois d'un apercu indubitable de la predominance pendant des diecles de la musique de fanfares au Tyrol. L'importance regionale et internationale des archives musicales du monastere fransciscain de Salzbourg est illustree notamment par des sources obtenues pour la premiere fois sur les composiltlions du legendaire pere franscicain du XIXeme siecle, Pere Peter Singer, ou ceux d'Egon Wellesz. Une collection de manuscrits de ""Vipiteno""/Sud Tyrol datant de 1780 a ete decouverte chez un particulier, dans le Lechtal tyrolien. Elle contient des oeuvres pour piano de compositeurs majeurs des regions du Sud de l'Allemagne, d'Autriche et d'Italie, ainsi qu'une serie de pieces trouvees pour la premiere fois. Malgre l'ampleur du travail accompli par le RISM Tyrol-Sudd Tyrol et OFM Autriche, il n'y a pas encore de fin en vue dans la recherche de cette documentation d'une importance capitale.",2012,Fontes Artis Musicae
"CaracterizaciÃ³n de los parÃ¡metros fÃ­sicos y quÃ­micos de los efluentes de agua al rÃ­o Cutuchi en el sector Lasso cantÃ³n Latacunga provincia Cotopaxi, periodo 2015","Water is the most abundant substance on earth and is the ideal and essential for life environment. The quality of this resource depends on natural factors and human action; use in various industrial activities alters the physical chemical characteristics of the water seriously affecting the existence of ecosystems. 
There has been no natural or anthropic recuperation of the river since the industrial growth of the lasso sector, far from having fount a solution, the estate of Cutuchi River has worsened due to the leakage from the industry that has continued to increase, converting the river in to a receptor of residual water. This is one of the principal problems affecting the river, making it a center of contaminationâ€¦.",2015,
"Pembelajaran Tari Menggunakan Tahapan Koreografi Pada Kegiatan Ekstrakurikuler Di Sma Negeri 1 Kalirejo, Lampung Tengahtahun Ajaran 2014/2015","Rumusan masalah pada penelitian ini adalah bagaimana proses pembelajaran tari menggunakan tahap koreografi pada kegiatan ekstrakurikuler di SMA Negeri 1 Kalirejo, Lampung Tengah. Penelitian ini menggunakan penedekatan penelitian deskriptif kualitatif. Objek penelitian adalah pembelajaran gerak tari menggunakan tahap koreografi di SMA Negeri 1 Kalirejo, Lampung Tengah. Subjek penelitian ini adalah 15 siswa yang mengikuti kegiatan ekstrakurikuler tari. 
Teknik pengumpulan data menggunakan observasi, wawancara, dan dokumentasi. Teori yang digunakan pembelajaran nonformal dan koreografi. Instrumen penelitian menggunakan aktivitas siswa menggunakan sistim checklis dan tes praktik. 
Proses pembelajaran tari kreasi Lampung yang diambil sebagai contoh adalah tari tradisi, yaitu menggunakan tahap audio visual pada tahap ini guru memberikan tayangan video tari kreasi dan siswa memperhatikan tayangan video yang diberikan, tahap eksplorasi pada tahap ini guru memberikan contoh gerak tari tradisi kemudian siswa mempraktikkan apa yang ditugaskan oleh guru, untuk tahap imrpovisasi dan tahap pembentukan sudah tidak dilakukan proses pembelajaran karena pada tahap ini sudah dilakukan pengambilan nilai tes praktik. Untuk tahap keseluruhan siswa yang dinyatakan gagal ada 3 orang siswa. Hasil belajar siswa menggunakan tahap koreografi sudah ditunjukan dengan rata-rata nilai tes praktik siswa 67 dengan kriteria lulus. 
Kata kunci : pembelajaran, tahapan koreografi, kegiatan ekstrakurikuler 
 
 
 
 
The formulation of problem in this research was how the activites dance lasson using choreographystep in extracurricular activities in SMA Negeri 1 Kalirejo Central Lampung. The objective of this research is to describe the process and result of dance lesson using coreography step. This study used qualitative descriptive approach to describe the process and result of learning of dance movement using coreography step in SMA Negeri 1 Kalirejo, central Lampung. the subject of this research are 15 student who follow dance extracurricular activites. 
Data collection techniques using observation, interview, and documentation. The instrumen of the research used the activity of students by using cheklis systems and practices test. 
The learning process of dance movement of lampung creation through the coreography step by using audio and visual step, teachers show video dance creation and student watch the video given, in exploration step, the teachers give an example of movement of traditional dance and then students practice the movement that they learned from the teacher. For the improvitation and formation step, the teachers will not give an example because at this step the teacers will take a score for practice test. For the whole, only three students were failed. The result of study using the coreography step showed 67 average score for practice test that categorized to pass. 
Key Word : dance, coreography step, extracurricular activities",2015,
REVERSING THE COLAVITA EFFECT 1 RUNNING HEAD : REVERSING THE COLAVITA EFFECT Reversing the Colavita Visual Dominance Effect,"Many researchers have taken the Colavita effect to represent a paradigm case of visual dominance. Broadly defined, the effect occurs when people fail to respond to an auditory target if they also have to respond to a visual target presented at the same time. Previous studies have revealed the remarkable resilience of this effect to various manipulations. In fact, a reversal of the Colavita visual dominance effect (i.e., auditory dominance) has never been reported. Here, we present a series of experiments designed to investigate whether it is possible to reverse the Colavita effect when the target stimuli consist of repetitions embedded in simultaneously-presented auditory and visual streams of stimuli. In line with previous findings, the Colavita effect was still observed for an immediate repetition task but, when an N-1 repetition detection task was used, a reversal of visual dominance was demonstrated. These results suggest that masking from intervening stimuli between N-1 repetition targets was responsible for the elimination and reversal of the Colavita visual dominance effect. They further suggest that varying the presence of a mask (pattern, conceptual, or absent) in the repetition detection task gives rise to different patterns of sensory dominance (i.e., visual dominance, an elimination of the Colavita effect, or even auditory dominance). REVERSING THE COLAVITA EFFECT 3 Reversing the Colavita visual dominance effect Colavita (1974) has been popularly credited with first reporting the phenomenon whereby people frequently fail to respond to an auditory stimulus if they have to respond to a simultaneously presented visual stimulus. This phenomenon is now commonly referred to as the Colavita visual dominance effect. Researchers studying the Colavita effect have expanded the original demonstration from simple stimuli (beeps and flashes) to include streams of common sounds and pictures, and, for more than three decades attempted to eliminate, or reverse, this particular example of visual dominance (i.e., and show auditory dominance; see Spence, 2009, for a review). Attempts to do this have involved increasing the intensity of the auditory stimulus (Colavita, 1974), increasing the probability of bimodal targets from 20%, as is typical of most earlier studies on the Colavita effect, to 90% (Koppen & Spence, 2007a), varying the stimulus onset asynchrony (SOA) between the visual and auditory stimuli (Koppen & Spence, 2007b), manipulating the spatial coincidence between the visual and auditory stimuli (Koppen & Spence, 2007d), and shifting the relative focus of attention to one modality versus the other (Sinnett, Spence, & Soto-Faraco, 2007). Despite these numerous attempts, only a few studies have been able to eliminate the Colavita effect, while a reversal of the effect has yet to be observed. Sinnett et al. (2007) reported that when the frequency of auditory targets (60%), was greater than visual or bimodal targets (both 20%) in a pre-specified target detection task, participants made just as many auditory as visual responses (i.e., errors) to bimodal targets. That is, the Colavita visual dominance effect was eliminated. Sinnett et al. attributed this result to the introduction of a bias towards attending and responding to the auditory stimuli. Similarly, Moro and Steeves (2010) recently reported that unilaterally enucleated patients (i.e., those individuals who had had early unilateral surgical eye removal due to cancer of the retina), who presumably rely less on vision than other normally-sighted individuals, made just REVERSING THE COLAVITA EFFECT 4 as many unimodal auditory responses as visual responses to bimodal targets in a task requiring the participants to respond to pre-specified targets, again demonstrating an elimination of the Colavita visual dominance effect. Assuming that such patients would rely less on vision and more on audition (Lessard, Pare, Lepore, & Lassonde, 1998), Moro and Steeves concluded that in order to eliminate the Colavita effect there must be some form of degradation in the reliability of the visual information presented to participants. Under such conditions, the enucleated patients may have biased their attention, and in turn their responding, toward the auditory modality. That is, while the percentage of auditory-only responses was approximately equal between both groups, the enucleated patients made significantly fewer visual-only responses to bimodal targets as compared to the normallysighted participants. Ngo, Sinnett, Soto-Faraco, and Spence (2010) recently examined the Colavita effect in the context of a repetition detection task. People typically find it easier to detect auditory repetitions than to detect visual repetitions (e.g., Soto-Faraco & Spence, 2002). Moreover, the modality appropriateness hypothesis (Welch & Warren, 1980, 1986) contends that audition is better suited for temporally demanding tasks such as detecting repetitions. As such, Ngo et al. hypothesized that the temporal demands of the repetition detection task should have led to a bias toward responding to the auditory rather than the visual information. This may ultimately have resulted in the elimination, or even the reversal, of the Colavita effect. In their study, participants had to monitor a stream of simultaneously-presented visual and auditory stimuli and respond whenever they saw or heard the immediate repetition of a picture, a sound, or both. Note that while all of the previously-mentioned studies have been based on the simple detection of predefined targets much like Colavitaâ€™s (1974) original study, the repetition detection task relies on a more abstract, rule-based level of representation. That is, the task required participants to hold the representation of an object in working memory (see REVERSING THE COLAVITA EFFECT 5 Baddeley, 1992, 2000, for a review) and to make a comparison with a subsequently-presented object. As expected on the basis of the previous repetition detection literature, auditory superiority was observed on unimodal target trials. That is, participants missed significantly more unimodal visual than unimodal auditory repetitions. However, despite this unimodal auditory dominance, a strong visual dominance effect for bimodal targets, with participants making more visual-only responses (i.e., errors) than auditory responses on these bimodal trials, was nevertheless still observed. It would therefore appear that the temporal demands of the repetition detection task used in their study were insufficient to bring about a bias toward responding preferentially to stimuli presented in the auditory modality. One known advantage of auditory processing over visual processing is that short-term auditory (echoic) memory is longer lasting than short-term visual (iconic) memory. According to some estimates, echoic memory lasts upwards of 2000 ms (see Cowan, 1984), whereas iconic lasts for only up to a maximum of 1000 ms (Sperling, 1960), with some studies suggesting conservative estimates of only 200-300 ms (Di Lollo, 1977; Long, 1980). Note that Ngo et al. (2010) used an immediate repetition task in which a potential target repetition required participants to retain the visual information for only about 250 ms. It is possible then that the visual dominance effect reported by Ngo et al. may have been related to the persistence of the visual stimulus in participantsâ€™ iconic memory store. This is likely given that the average response latency to repeated targets in Ngo et al.â€™s task were still well-within the 1000 ms upper limit of iconic memory. Rather than detecting immediate repetitions, as in Ngo et al.â€™s (2010) study, we required participants to detect non-adjacent (n-1) repetitions in Experiment 1. This potentially induced a sufficient degradation of the internal memory of the visual signal by way of the rapidly decaying iconic memory trace (Di Lollo, 1977; Long, 1980; Sperling, 1960). As the onset of the repeated n-1 target started at least 979 ms after the first item of the repeated pair, REVERSING THE COLAVITA EFFECT 6 it would be unlikely that any decision would be based on a simple iconic memory trace. Additionally, introducing an intervening stimulus between target n-1 repetitions may also have given rise to potential masking effects (see Enns & Di Lollo, 2000; Intraub, 1984; Loftus & Ginn, 1984; Potter, 1976, 1999). Specifically, an intervening stimulus might mask potential n-1 targets by competing with and making the first part of the target difficult to access from working memory. The participants monitored a stream of simultaneously-presented visual and auditory stimuli and responded as soon as they saw or heard the n-1 repetition of a picture (i.e., separated by an interleaved different picture and sound), a sound, or both. If either the temporal decay of iconic memory, or the masking effects of the intervening stimulus, imposes a limit on visual dominance, then by extending presentations beyond this temporal limit, we would expect to observe an elimination of the Colavita effect as well, or perhaps a reversal (i.e., auditory dominance). EXPERIMENT 1 Methods Participants. Twenty participants from the University of Oxford (12 female) ranging in age from 20-55 years (mean age of 28 years) took part in this experiment. All of the participants reported normal or corrected-to-normal vision, and normal hearing. All but two were right-handed by self-report. The experiment took approximately 20 minutes to complete. The participants received a Â£5 (UK Sterling) gift voucher in return for taking part in the study. The experiment was conducted in accordance with the Declaration of Helsinki. Written informed consent was given by participants prior to the start of the experiment. Apparatus and materials. Fifty line drawings of common objects chosen from the Snodgrass and Vanderwart (1980) database were used as the visual stimuli. Fifty sounds REVERSING THE COLAVITA EFFECT 7 (ident",2015,
Sentinel surveillance of influenza in Burkina Faso: identification of circulating strains during 2010â€“2012,"BACKGROUND
Although influenza surveillance has recently been improved in some sub-Saharan African countries, no information is yet available from Burkina Faso.


OBJECTIVES
Our study was the first to determine the prevalence of influenza viruses circulating in Burkina Faso through a sentinel surveillance system.


METHODS
We conducted sentinel surveillance with oropharyngeal (OP) swabs collected from outpatients (1 month to 83 years) from six sites in Bobo-Dioulasso and Ouagadougou, among patients meeting the WHO/CDC case definition for influenza-like illness (ILI; fever â‰¥38Â°C, and cough and/or sore throat in the absence of other diagnosis) from July 2010 to May 2012. Influenza viruses were detected by real-time RT-PCR using CDC primers, probes, and protocols.


RESULTS
The first three ILI cases were enrolled each day; of 881 outpatients with ILI enrolled and sampled, 58 (6.6%) tested positive for influenza viruses (29 influenza A and 29 influenza B). Among the influenza A viruses, 55.2% (16/29) were influenza A (H1N1)pdm09 and 44.8% (13/29) were seasonal A (H3N2). No cases of seasonal A/H1N1 were detected. Patients within 0-5 years and 6-14 years were the most affected, comprising 41.4% and 22.4% laboratory-confirmed influenza cases, respectively. Influenza infections occurred during both the dry, dusty Harmattan months from November to March and the rainy season from June to October with peaks in January and August.


CONCLUSIONS
This surveillance was the first confirming the circulation of influenza A (H1N1)pdm09, A/H3N2, and influenza B viruses in humans in Burkina Faso.",2014,Influenza and Other Respiratory Viruses
Untersuchung zur Pharmakokinetik des Arzneistoffes Detomidin hinsichtlich der Dopingrelevanz beim Pferd,"The aim
 of this study was to develop and validate a suitable method for the analysis
 of detomidine in equine plasma and urinesamples and evaluate its application
 for
 pharmacocinetic calculations and pharmacodynamic examinations on horses.
 The analytical method was based upon some established routine procedures at
 the
 Institute of Biochemistry at the Deutsche Sporthochschule in Cologne, which
 were
 specially modified for the substance detomidine using samples collected in a
 preliminary study. The horses in the preliminary experiment as well as in the
 main
 expermiment received detomidine-hydrochloride in a middle-ranged
 therapeutical
 dose of 20 Âµg/kg body weight intravenously. The detection of detomidine in
 plasma
 was performed using a HPLC/MS/MS-method after liquid-liquid-extraction. For
 the
 diagnosis of detomidine and its metabolites 3-hydroxydetomidine and
 carboxydetomidine in urine an additional recondition step using
 cation-exchange-cartridges
 was developed. Following evaporation of the liquid volume these samples
 were prepared for analysis in the HPLC/MS/MS as well. In comparison
 urinesamples
 were prepared with or without hydrolysis to determine the unconjugated
 3-hydroxy-
 and carboxydetomidine. Medetomidine and imidazolylbencoicacid were used as
 internal standards.
 The validation of the analytical method was performed on the parameters
 selectivity
 and specitivity, linearity, accuracy, precision, stability and recovery. The
 limit of
 quantification was 2,09 ng/ml in plasma, 10 ng/ml for 3-hydroxydetomidine and
 50
 ng/ml for carboxydetomidine. The limit of detection was fixed at 1,67 ng/ml
 in plasma,
 at 10 ng/ml for 3-hydroxydetomidine and 50 ng/ml for carboxydetomidine.
 Maximum
 concentrations of detomidine in plasma were detected 2 to 5 minutes p. a.
 within the range of 12 and 35 ng/ml plasma. The maximum concentrations for 3-
 hydroxydetomidine in urine were measured between 3 to 6 hours p. a. and
 varied
 between 31 to 130 ng/ml. For carboxydetomidine the highest concentrations
 ranged
 from 450 to 1550 ng/ml urine at 5 to 8 hours p. a. Detomidine in plasma
 samples was
 detectable for only three hours p. a., while the concentration of
 3-hydroxydetomdine
 and carboxydetomidine were below the limit of detection after 24 and 30 hours
 respectively.
 The calculated pharmacocinetic data were integrated into a pharmacocinetic/
 pharmacodynamic model of TOUTAIN and LASSOURD (2002) to calculate the
 effective and irrelevant plasma and urine concentrations. Given a dosage
 interval of 4
 hours within this study, it came clear that irrelevant plasma and
 urinconcentrations
 were far below the detection-limit of the analytical method applied in this
 study.
 Therefore, it has been concluded that any detection of detomidine or its
 metabolites
 has to be considered as a positive dopingresult.
 Additionally to sampling plasma and urine for the pharmacocinetic approach
 there
 were investigated some pharmacodynamic parameters such as heart rate,
 respiration
 rate, body temperature, level of sedation and analgesia were recorded and
 compared
 to the effective and irrelevant plasma and urine concentrations calculated by
 the
 pharmacocinetic/pharmacodynamic model of TOUTAIN and LASSOURD (2002) as
 well as calculated excretion times. With the opportunity of this study to
 compare
 between practically and theoretically investigated data regarding excretion
 times and
 pharmacological effects, it was shown that the thoretical calclation is not
 always
 comparable to the data achieved in an animal experiment. Due to the fact that
 every
 animal experiment has to compromise in the number of animals included,
 therefore
 representing only a small part of the population, and with regards to notable
 individual variation, no defined statement can be made for general excretion
 times.
 Thus, every detection of either detomidine or its metabolites can be counted
 as a
 positive doping result and should be punished according to the law.",2004,
Semiparametric Model Selection in Panel Data Models with Deterministic Trends and Cross-Sectional Dependence By Jia Chen,"In this paper, we consider a model selection issue in semiparametric panel data models with fixed effects. The modelling framework under investigation can accommodate both nonlinear deterministic trends and cross-sectional dependence. And we consider the so-called â€œlarge panelsâ€ where both the time series and cross sectional sizes are very large. A penalised profile least squares method with first-stage local linear smoothing is developed to select the significant covariates and estimate the regression coefficients simultaneously. The convergence rate and the oracle property of the resulting semiparametric estimator are established by the joint limit approach. The developed semiparametric model selection methodology is illustrated by two Monte-Carlo simulation studies, where we compare the performance in model selection and estimation of three penalties, i.e., the least absolute shrinkage and selection operator (LASSO), the smoothly clipped absolute deviation (SCAD), and the minimax concave penalty (MCP). JEL classification: C13, C14, C23.",2014,
Distributed Cartesian Power Graph Segmentation for Graphon Estimation,"We study an extention of total variation denoising over images to over Cartesian power graphs and its applications to estimating non-parametric network models. The power graph fused lasso (PGFL) segments a matrix by exploiting a known graphical structure, $G$, over the rows and columns. Our main results shows that for any connected graph, under subGaussian noise, the PGFL achieves the same mean-square error rate as 2D total variation denoising for signals of bounded variation. We study the use of the PGFL for denoising an observed network $H$, where we learn the graph $G$ as the $K$-nearest neighborhood graph of an estimated metric over the vertices. We provide theoretical and empirical results for estimating graphons, a non-parametric exchangeable network model, and compare to the state of the art graphon estimation methods.",2018,ArXiv
Unsupervised clustering under the Union of Polyhedral Cones (UOPC) model,"Abstract In this paper, we consider clustering data that is assumed to come from a union of finitely many pointed convex polyhedral cones. This model is referred to as the Union of Polyhedral Cones (UOPC) model. Similar to the Union of Subspaces (UOS) model where each data from each subspace is generated from a (unknown) basis, in the UOPC model each data from each cone is assumed to be generated from a finite number of (unknown) extreme rays . To cluster data under this model, we first build an affinity graph with the different edge weights where the edge weights are derived using a K -nearest neighbor (KNN) algorithm. Subsequently, spectral clustering is applied to obtain the clusters, and the proposed algorithm is denoted as KNN-SC. We show that on average KNN-SC outperforms Sparse Subspace Clustering by Non-negative constraints Lasso (NCL), Least squares approximation (LSA), Sparse Subspace Clustering (SSC), robust Subspace Clustering via Thresholding (TSC), and Mutual KNN based Spectral Clustering (KNNM-SC), and we provide deterministic conditions for correct clustering using KNN-SC. We show that on average KNN-SC outperforms NCL, LSA, SSC, TSC, and KNNM-SC, and we provide deterministic conditions for correct clustering using KNN-SC. For an affinity measure between the cones it is shown that as long as the cones are not very coherent and as long as the density of data within each cone exceeds a threshold, KNN-SC leads to accurate clustering. Finally, simulation results on real datasets (MNIST and CMU Motion datasets) depict that the proposed algorithm works well on real data indicating the utility of the UOPC model and the proposed algorithm.",2017,Pattern Recognit. Lett.
Recent Advances in the Chemical Synthesis of Lasso Molecular Switches,"Interlocked and interwoven molecules are intriguing structures that can behave as molecular machines. Among them, the [1]rotaxane molecular architecture is unique, since it defines a lasso-type shape, that, if well designed, can be tightened or loosened depending on an external stimulus. This chapter describes an overview of the main strategies used to reach [1]rotaxanes to date and then focuses on the few examples of [1]rotaxanes reported in the literature that behave as mono-lasso or double-lasso molecular machines. Different motions are illustrated like the looseningâ€“tightening of lassos or the controllable molecular â€œjump ropeâ€ movement which is specific to the double-lasso structure.",2015,
Adaptive Dantzig density estimation,"This paper deals with the problem of density estimation. We aim at building an estimate of an unknown density as a linear combination of functions of a dictionary. Inspired by CandÃ¨s and Taoâ€™s approach, we propose an l1-minimization under an adaptive Dantzig constraint coming from sharp concentration inequalities. This allows to consider a wide class of dictionaries. Under local or global coherence assumptions, oracle inequalities are derived. These theoretical results are also proved to be valid for the natural Lasso estimate associated with our Dantzig procedure. Then, the issue of calibrating these procedures is studied from both theoretical and practical points of view. Finally, a numerical study shows the significant improvement obtained by our procedures when compared with other classical procedures.",2009,
Change points detection and parameter estimation for multivariate time series,"In this paper, we propose a method to estimate the number and locations of change points and further estimate parameters of different regions for piecewise stationary vector autoregressive models. The procedure decomposes the problem of change points detection and parameter estimation along the component series. By reformulating the change point detection problem as a variable selection one, we apply group Lasso method to estimate the change points initially. Then, from the preliminary estimate of change points, a subset is selected based on the loss functions of Lasso method and a backward elimination algorithm. Finally, we propose a LassoÂ +Â OLS method to estimate the parameters in each segmentation for high-dimensional VAR models. The consistent properties of the estimation for the number and the locations of the change points and the VAR parameters are proved. Simulation experiments and real data examples illustrate the performance of the method.",2020,Soft Computing
Twistor-like formulationof superp-branes,Closedsuper(p + 2)-formsin targetsuperspaceare relevantfor the constructionof the usual superp-brane actions. Here we construct closed super (p + 1)-forms on a worldvolumesuperspace.They are built out of the pull-backs of the KaIbâ€”Ramond super (p + 1)-form and its curvature. We proposea twistor-like formulation of a classof super p-braneswhich crucially dependson the existenceof these closedsuper(p + 1)-forms.,2019,
Inferring Networks from Multiple Samples with Consensus LASSO,"Networks are very useful tools to decipher complex regulatory relationships between genes in an organism. Most work address this issue in the context of i.i.d., treated vs. control or time-series samples. However, many data sets include expression obtained for the same cell type of an organism, but in several conditions. We introduce a novel method for inferring networks from samples obtained in various but related experimental conditions. This approach is based on a double penalization: a first penalty aims at controlling the global sparsity of the solution whilst a second penalty is used to make condition-specific networks consistent with a consensual network. This ''consensual network'' is introduced to represent the dependency structure between genes, which is shared by all conditions. We show that different ''consensus'' penalty can be used, some integrating prior (e.g., bibliographic) knowledge and others that are adapted along the optimization scheme. In all situations, the proposed double penalty can be expressed in terms of a LASSO problem and hence, solved using standard approaches which address quadratic problems with $L_1$-regularization. This approach is combined with a bootstrap approach and is made available in the R package therese. Our proposal is illustrated on simulated datasets and compared with independent estimations and alternative methods. It is also applied to a real dataset to emphasize the differences in regulatory networks before and after a low-calorie diet.",2014,Quality Technology and Quantitative Management
Food of Flathead Sole Hippoglossoides elassodon in the Eastern Bering Sea,"The food habits of the flathead sole (Hippoglossoides elassodon) in the eastern Bering Sea were investigated. Our analysis of 4,406 flathead sole stomachs containing food showed that the diet was composed primarily of organisms living on the bottom (epibenthic) and pelagic organisms in close association with the bottom (nektobenthic). Feeding shifted from a crustacean-based diet to an ophiuroid-based diet with increasing fish size. Flathead sole less than 30 cm total length (TL) consumed mainly mysids, gammarid amphipods, and decapod shrimps, whereas flathead sole larger than 30 cm total length (TL) consumed mainly ophiuroids, walleye pollock, and decapod shrimps. Diet composition varied with changes in bottom depth. Feeding in shallow waters (<50 m) was almost exclusively on small crustaceans and fish, but shifted to ophiuroids with increasing bottom depth for both size groups. The diet of flathead sole is indicative of a generalist feeding strategy. Dietary diversity ranged from moderately low to high as measured by Shannon-Weaver and Simpsonâ€™s diversity indices, and the diet appears to be influenced mainly by prey availability and abundance. Lower diversity values for flathead sole larger than 30 cm TL suggest that feeding becomes more selective as fish grow. Competition with other flatfish species in the eastern Bering Sea does not appear to be a major factor influencing the diet of flathead sole.",1998,
"An Associating, Retrieval, and Display System for Archaeological Information using Huge 3D Models of Cultural Heritage","Recent advancements in digital archiving technologies have enabled us to store greater amounts of priceless digital data related to cultural properties. However, accessing this information by using conventional database systems is too difficult for general users. To solve this, this paper proposes an associating, retrieval and display system for archeological information using huge 3D models of cultural heritage as interfaces to access information. To define target regions on 3D models, users can quickly select specific regions from huge models by using an interface that combines a splitting method by graph-cut and a lasso tool. In the display process, we achieved highly interactive rendering of huge 3D models by using an efficient 3D rendering algorithm on the basis of multi-resolution meshes.",2010,The Journal of The Institute of Image Information and Television Engineers
Penalized Estimation of Panel Vector Autoregressive Models : A Lasso Approach,"This paper proposes a new least absolute shrinkage and selection operator (lasso) for estimating panel vector autoregressive (PVAR) models. By allowing for interdependencies and heterogeneities across cross-sectional units, typically the number of parameters of PVAR models is too large to estimate using ordinary least squares. The penalized regression this paper introduces ensures the feasibility of the estimation by specifying a shrinkage penalty that contains time series and cross section characteristics; thereby, accounting for the inherent panel structure within the data. Furthermore, using the weighted sum of squared residuals as the loss function enables the lasso for PVAR models to take into account correlations between cross-sectional units in the penalized regression. Given large and sparse models, simulation results point towards advantages of using lasso for PVARs over OLS, standard lasso techniques as well as Bayesian estimators in terms of mean squared errors and forecast accuracy. Empirical forecasting applications with up to ten countries and four variables support these findings.",2017,
"Palynology and paleoenvironment of the Jurassic lacustrine CaÃ±adÃ³n Asfalto Formation at CaÃ±adÃ³n LahuincÃ³ locality, Chubut Province, Central Patagonia, Argentina","espanolEn el contexto de la extension jurasica del Gondwana sudoccidental, los materiales de la Formacion Canadon Asfalto rellenaron cuencas de semigraben ubicadas en el area central de la provincia de Chubut. Los principales afloramientos estudiados se encuentran en el valle medio del Rio Chubut, donde alternan volcanitas y depositos bioquimicos, piroclasticos y epiclasticos. En este trabajo se presenta un estudio palinologico y palinofacial de las pelitas gris oscuras de la parte inferior de esta Formacion en la localidad Canadon Lahuinco del Depocentro Cerro Condor. La abundancia de materia organica amorfa (60-90%) en todas las muestras palinologicas estudiadas es caracteristica de condiciones de fondo. El material obtenido corresponde en su mayor parte a palinomorfos destruidos que incluyen microplancton y Botryococcus. Los fitoclastos opacos que escasos, consisten en materia equidimensional no estructurada de color negro. La presencia de Botryococcus indica niveles lacustres someros y, probablemente, condiciones de salinidad. Procesos diageneticos como son la degradacion, corrosion y ausencia de pirita en todas las muestras indican que las condiciones del fondo lacustre fueron mayormente aerobicas. En el conjunto de los granos de polen, los de las Cheirolepidiaceae dominan el espectro polinico (hasta 80% de Classopollis spp.), junto con los de las Araucariaceae (hasta un 20 %). Los altos porcentajes de Cheirolepidiaceae que fueron termofilas, y Araucariaceae que ocuparon ambientes relativamente humedos, caracterizan el paleoambiente como calido y humedo. Asimismo la presencia de esporas de briofitos (Nevesisporites cf. radiatus) y granos de polen de pteridospermas (Alisporites similis) sugieren condiciones de humedad, al menos local, para la parte inferior de la Formacion. La distribucion estratigrafica de los palinomorfos indica una edad jurasica media (del Bajociense al Bathoniense temprano). EnglishIn the context of the Jurassic extension of southwestern Gondwana, the Canadon Asfalto Formation filled the semigrabens located in the central area of the Chubut province. The principal outcrops are in the middle Chubut river valley, where volcanites, biochemical, pyroclastic and epiclastic deposits alternate. The palynologic and palynofacial study of dark gray pelites of the lower part of the Canadon Asfalto Formation at the Canadon Lahuinco locality, Cerro Condor Depocenter, is presented. The abundance of amorphous organic matter (60-90%) in all the palynologic samples studied is characteristic of stagnant bottom conditions. The material mostly corresponds to destroyed palynomorphs, including microplancton and Botryococcus. The scarce opaque phytoclasts consist of black, equidimensional, structureless material. The presence of Botryococcus indicates shallow lake levels and probably saline conditions. Diagenetic processes such as degradation, corrosion and the absence of pyrite in all the samples indicate that bottom conditions were mostly aerobic. The Cheirolepidiaceae dominate the spectrum (up to 80% of Classopollis spp.), associated with Araucariaceae (up to 20%). Warm and relatively humid climatic conditions are indicated by these high percentages of the thermophilic Cheirolepidiaceae, together with the Araucariaceae that grow under relatively humid conditions. Also, the presence of Bryophyta (Nevesisporites cf. radiatus) and pteridosperms (Alisporites similis) suggest probable local humid conditions for the lower part of the Formation. The stratigraphic range of the palynomorphs indicates a Middle Jurassic (Bajocian to early Bathonian) age for the lower part of the Canadon Asfalto Formation at the Canadon Lahuinco locality.",2008,
Identifying miRNA-mRNA regulatory relationships in breast cancer with invariant causal prediction,"microRNAs (miRNAs) regulate gene expression at the post-transcriptional level and they play an important role in various biological processes in the human body. Therefore, identifying their regulation mechanisms is essential for the diagnostics and therapeutics for a wide range of diseases. There have been a large number of researches which use gene expression profiles to resolve this problem. However, the current methods have their own limitations. Some of them only identify the correlation of miRNA and mRNA expression levels instead of the causal or regulatory relationships while others infer the causality but with a high computational complexity. To overcome these issues, in this study, we propose a method to identify miRNA-mRNA regulatory relationships in breast cancer using the invariant causal prediction. The key idea of invariant causal prediction is that the cause miRNAs of their target mRNAs are the ones which have persistent causal relationships with the target mRNAs across different environments. In this research, we aim to find miRNA targets which are consistent across different breast cancer subtypes. Thus, first of all, we apply the Pam50 method to categorise BRCA samples into different â€˜â€˜environmentâ€ groups based on different cancer subtypes. Then we use the invariant causal prediction method to find miRNA-mRNA regulatory relationships across subtypes. We validate the results with the miRNA-transfected experimental data and the results show that our method outperforms the state-of-the-art methods. In addition, we also integrate this new method with the Pearson correlation analysis method and Lasso in an ensemble method to take the advantages of these methods. We then validate the results of the ensemble method with the experimentally confirmed data and the ensemble method shows the best performance, even comparing to the proposed causal method. Functional enrichment analyses show that miRNAs in the regulatory relationship predicated by the proposed causal method tend to synergistically regulate target genes, indicating the usefulness of these methods, and the identified miRNA targets could be used in the design of wet-lab experiments to discover the causes of breast cancer. Author summary Cancer is a disease of cells in human body and it causes a high rate of deaths world wide. There has been evidence that non-coding RNAs are key players in the development and progression of cancer. Among the different types of non-coding RNAs, miRNAs, which are short non-coding RNAs, regulate gene expression and play an important role in different biological processes as well as various cancer types. To design better diagnostic and therapeutic plans for cancer patients, we need to know the roles of miRNAs in cancer initialisation and development, and their regulation mechanisms in the human body. In this study, we propose algorithms to identify miRNA-mRNA regulatory relationships in breast cancer. Comparing our methods with existing methods in predicting miRNA targets, our methods show a better performance. The estimated miRNA targets from our methods could be a potential source for further wet-lab experiments to discover the causes of breast cancer.",2018,bioRxiv
Risk factors and Predictors of Mortality in Streptococcal Necrotizing Soft-Tissue Infections: A Multicenter Prospective Study.,"BACKGROUND
Necrotizing soft-tissue infections (NSTI) are life-threatening conditions often caused by Î²-hemolytic streptococci, group A streptococcus (GAS) in particular. Optimal treatment is contentious. The INFECT cohort includes the largest set of prospectively enrolled streptococcal NSTI cases to date.


METHODS
Â From the INFECT cohort of 409 adults admitted with NSTI to five clinical centers in Scandinavia, patients culture-positive for GAS or Streptococcus dysgalactiae (SD) were selected. Risk factors were identified by comparison with a cohort of non-necrotizing streptococcal cellulitis. The impact of baseline factors and treatment on 90-day mortality was explored using Lasso regression. Whole-genome sequencing of bacterial isolates was used for emm typing and virulence gene profiling.


RESULTS
Â The 126 GAS NSTI cases and 27 cases caused by SD constituted 31% and 7% of the whole NSTI cohort, respectively. When comparing to non-necrotizing streptococcal cellulitis, streptococcal NSTI was associated to blunt trauma, absence of pre-existing skin lesions, and a lower BMI. Septic shock was significantly more frequent in GAS (65%) compared to SD (41%) and polymicrobial, non-streptococcal NSTI (46%). Age, male sex, septic shock, and no administration of intravenous immunoglobulin (IVIG) were among factors associated with 90-day mortality. Predominant emm types were emm1, emm3 and emm28 in GAS and stG62647 in SD.


CONCLUSIONS
Â  Streptococcal NSTI was associated with several risk factors, including blunt trauma. Septic shock was more frequent in NSTI caused by GAS than in cases due to SD. Factors associated with mortality in GAS NSTI included age, septic shock and no administration of IVIG.",2020,Clinical infectious diseases : an official publication of the Infectious Diseases Society of America
Prognostic value of tissueâ€based biomarker signature in clear cell renal cell carcinoma,"OBJECTIVE
To improve risk stratification for recurrence prognostication in patients with localised clear cell renal cell carcinoma (ccRCC).


PATIENTS AND METHODS
In all, 367 patients with non-metastatic ccRCC were included. The cohort was divided into a training and validation set. Using tissue microarrays, immunostaining was performed for 24 biomarkers representative of key pathways in ccRCC. Using Least Absolute Shrinkage and Selection Operator (LASSO) Cox regression, we identified several markers that were used to construct a risk classifier for risk of disease recurrence.


RESULTS
The median (interquartile range) follow-up was 63.5 (24.0-85.3) months. Five out of 24 markers were selected by LASSO Cox regression for the risk classifier: N-cadherin, E-cadherin, Ki67, cyclin D1 and phosphorylated eukaryotic initiation factor 4E binding protein-1 (p-4EBP1). Patients were classified as either low, intermediate or high risk of disease recurrence by tertiles of risk score. The 5-year recurrence-free survival (RFS) was 93.8%, 87.7% and 70% for patients with low-, intermediate- and high-risk scores, respectively (P < 0.001). Patients with a high marker score had worse RFS on multivariate analysis adjusted for age, gender, race and the Mayo Clinic Stage, Size, Grade, and Necrosis (SSIGN) score (hazard ratio 3.66, 95% confidence interval 1.58-8.49, P = 0.003 for high vs low marker score in the overall cohort). The five-marker classifier increased the concordance index of the clinical model in both the training and validation sets.


CONCLUSION
We developed a five-marker-based prognostic tool that can effectively classify patients with ccRCC according to risk of disease recurrence after surgery. This tool, if prospectively validated, could provide individualised risk estimation for patients with ccRCC.",2017,BJU International
A study of variable selection using g-prior distribution with ridge parameter,"In the Bayesian stochastic search variable selection framework, a common prior distribution for the regression coefficients is the g-prior of Zellner. However there are two standard cases where the associated covariance matrix does not exist and the conventional prior of Zellner cannot be used: if the number of observations is lower than the number of variables (large p and small n paradigm), or if some variables are linear combinations of others. In such situations, a prior distribution derived from the prior of Zellner can be considered by introducing a ridge parameter. This prior is a flexible and simple adaptation of the g-prior and its influence on the selection of variables is studied. A simple way to choose the associated hyper-parameters is proposed. The method is valid for any generalized linear mixed model and particular attention is paid to the study of probit mixed models when some variables are linear combinations of others. The method is applied to both simulated and real datasets obtained from Affymetrix microarray experiments. Results are compared to those obtained with the Bayesian Lasso.",2012,Comput. Stat. Data Anal.
"[Point of view of older adults on the potentially inappropriate medications prescribing in primary care facilities in Bobo-Dioulasso, Burkina Faso].","BACKGROUND
Little is known about the organization of primary care facilities in sub-Saharan Africa that might lead to potentially inappropriate prescribing. The aim of this study was to analyze the factors that could lead to potentially inappropriate prescribing in primary care facilities in Bobo-Dioulasso (Burkina Faso), taking into consideration the patient's perspective.


METHODS
A cross-sectional qualitative study was conducted in primary care facilities from November 2013 to February 2014. People aged 60 years or more with at least one chronic disease were included. Individual interviews were conducted. An analysis of the thematic content of the interviews was conducted.


RESULTS
Our results showed that the patient referral system was insufficient. We also found many different prescribers for older people seeking care and poor communication between prescribers and patients. This caused some consequences such as the absence of review of drugs consumed before a new prescription, a lack of exchange on medication changes and repeated treatment change during hospitalization. Most of the persons who prescribed potentially inappropriate medications were nurses.


CONCLUSION
The poor communication between prescribers and patients is a challenge for the prevention of prescribing potentially inappropriate medications. Teamwork is an important feature of the organizational care system, strengthening it could be a way to improve rational prescription.",2016,Revue d'epidemiologie et de sante publique
Multivariate Discrimination by Shape I N Relation T O S I Z E,"Huinphries, J . M., F . L. Bookstein, B. Chernoff, G . R. Smith, R. L. Elder, and S. G. Poss (Museum of Zoology, Centerfor Human Growth and Development, Museuiiz of Paleontology, and Division of Biological Sciences, The University of Michigan, Ann Arbor, Michigan 48109) 1981. Multivariate discrimination by shape in relation to size. Syst. Zool., 30:291308.--The diverse methods for analyzing size-free shape differences tend to be guided by computational expediency rather than geometric principles. We question the use of ratios and ad hoc combinations of spatially unrelated measures. Neither are linear discriminant functions or series of independent regressions helpful to the visualization of shape differences. A bridge is needed between traditional quantitative methods and the geometrical analysis of shape. In principle any measured transects between landmarks of a form can serve as characters in a morpholnetric analysis. Systematic studies use a highly non-random sample of these, particularly biased regarding geometrical infolmation. We suggest defining size and shape in terms of factors-estimates of information comrnon to a universe of measured distances. The model presented here calculates a linear combination of variables that quantifies shape differences among populations, independent of size. In analyses in which the first two principal cornponents confound size and shape, size is removed from one axis with shear coefficients derived from regression of general size on principal cornponents centered by group. The general size factor is estimated by the principal axis of the within-group covariance matrix of the log-transformed data. Residuals from the regression of general size on the transfolmed axes approximate a shape-discriminating factor that is uncorrelated with size within group and displays the interpopulation shape differences borne by the first two principal components. The results bear a direct and interpretable correspondence to biorthogonal analysis of shape difference. [Multivariate analysis; principal components; discriminant functions; morphometrics; size-free shape; allometry; fishes.] Svsteinatists need ~rocedures that alassociations among the distance mealow them to discriminate ainong groups sures. Size, in particular, is not a single of organisms that vary in size. The groups variable such as biomass or a standard included in a studv can be chosen a length, but a factor which, when called priori (e.g., several species or geographic upon to predict all the distance measures populations within a species) or a poswithin a population, leaves the smallest teriori (as a conclusion resulting from mean squared residual. We prefer a factor some method of analysis). However the whose algebraic form acknowledges the groups are chosen, it has long been conallometric relationship (Jolicoeur, 1963). sidered desirable to discriminate ainong Our shape discriininators need to be inthem on the basis of size-free s h a ~ e dedependent of size (Flessa and Bray, 1977; rived from distance measures. Mosiinann and James, 1979) in order to The terms shape and size have been partition out the effects of growth (e.g., used in various and sometimes conflictindividuals of differing age and size). In ing ways (Huxley, 1932; Thompson, general, shape can be defined as the ge1942; Simpson, Roe and Lewontin, 1960; ometry of the organism after ""information Gould, 1966; Mosimann, 1970; Sprent, about position, scale, and orientation"" 1972: Bookstein. 1978). We construe size has been removed (Bookstein, 1978:8). and s'hape not as ineas'ured variables, but There is then an endless variety of shape as general factors, linear combinations information remaining. While the quanmost parsiinoniously accounting for the tification of size as a general factor de292 SYSTEMATIC ZOOLOGY VOL. 30 pends on the population under study, a measure of shape will depend on the research context as well. Our shape descriptors will always be shape discriminators defined in the context of multiple groups. Size can be a significant component of among-group differences (Calhoon and Jameson, 1970; Gould, 1977; Harding and Barnes, 1977; Mosiinann and James, 1979). Therefore, size coinparisons should not be automatically excluded from study (we disagree with Thorpe, 1976), but rather should be an independent part of the analysis. Three pr i~nary methods have been used to compare shape among groups while removing size: ratios, regressions, and factor or co~nponent analyses. The use of ratios has long been entrenched in the practice of morphometsics, and there is ample debate concerning the appropriateness of their use (Atchley et al., 1976; Corruccini, 1977; Mosimann and James, 1979; Hills, 1978; Dodson, 1978; Albrecht, 1978; Atchley and Anderson, 1978; Atchley, 1978). We agree with the position taken by Karl Pearson (1897), Atchley e t al. (1976), Atchley and Anderson (1978) and others that ratios should be avoided in morphometric studies because of statistical and conceptual difficulties which may seriously affect conclusions. These studies have demonstrated (1)that ratios can behave spuriously depending upon the correlation of the numerator and denominator; (2) that the ratio is not necessarily independent of the denominator; and (3) that the use of ratios alters the factor structure of the covariance matrix, especially for small sample sizes. Contrary to Blackith and Reyment (1971) and Dodson (1978), we believe that these with ratios are not automatically ameliorated by their logtransformation. Mosimann and James (1979), for instance, note that not all shape variables (ratios) are jointly lognormally distributed. Also, the purpose of constructing a ratio-to approxiinately ~ a r t i a l out the effect of size-is not autoinatically attained. Different nurnerators must be divided by different size variables to achieve the desired independence of ratios from denominators. A further danger is that ratios are not always interpretable as ineasures of shape. For example, Mosimann and James (1979:452) list log (toe + tarsus length/bill length) and log (tail lengthhoe + tarsus length) as shape variables. A second procedure used to standardize distance measures by size is univariate regression analysis of the distance measures on some measure of size (Mosimann, 1956; Gould, 1966; Thorpe, 1976, 1980). The regression can be calculated either separately by groups, or jointly using the pooled within-group covariance matrix. Each distance variable is replaced by its residual after the regression. If the pooled matrix is used, the underlying assumption is that the withingroup regression slopes are equal (Thorpe, 1976); if not, then size has not been removed. Also, regression analysis simply partials out the effect of the independent variable from the dependent variable. If size is designated as a single variable, then only that variable is partialed out. However, size is not equal to any single length, and those studies that regress distance ineasures against a single standard variable (e.g., snout-vent length in reptiles, standard length in fishes, or wing length in birds) do not necessarily remove the effects of size. For among-group comparisons, analysis of either ratios or regression residuals may be considered a univariate method that does not attend to the entire covariance matrix. This univariate approach is, perhaps, suitable for small numbers of variables, but as the number of variables becomes large (e.g., 111variables, Moss et al., 1977) the problems of describing the differences among the groups become increasingly difficult. We differ with the univariate approach on a inore fundamental level and agree with Sprent (1972) that the analysis of shape requires a multivariate context. A third technique for comparing shape 1981 SHAPE IN RELATION TO SIZE 293 and shape change among groups is inultivariate ordination (see Blackith and Reyment, 1971; Sneath and Sokal, 1973; Thorpe, 1976, 1980). Discriminant functions, with canonical axes, maximize the differences among groups with respect to the within-group covariance structure. The method requires a priori assignment of individuals to groups. When size is "" removed"" before discriminant analysis, the resulting functions are considered shape discriminators. When size is not removed the resulting discriminators are mixtures of size and shape. These functions are highly sample-dependent because the coefficients of the functions all have the determinant of the covariance matrix in the denominator, and as most variables, even ratios, are highly correlated, this determinant is close to zero even for large samples. Discriminant functions lose information abdut the correlations among the variables because the eigenvalues are derived by maximizing a function of the ratio of the amonggroup to within-group covariance matrices. The use of an optimization criterion does not constrain the resulting eigenvectors, and therefore the variableweights are spurious in relation to shape. From within a set of correlated characters only the variable with the highest F-statistic will be weighted heavily. Within that set, variables that do not contribute added discrimination will have low coefficients even though they contain nearly as much information about shape as the variable with the high F-statistic. In the analysis of shape it is imperative to include factors which accurately represent the degree to which the distance measures covary. We turn to principal components analysis which was specifically designed to analyze sets of correlated variables (Morrison, 1967). Principal component or factor analyses do not presume multiple groups and thus allow for their discovery. Furthermore, their coefficients, being ordinary regression coefficients of the indicators on the factors, are more easily interpretable (Stroud, 1953). In morphometric studies of groups differing in size the first factor or component has sometimes been interpreted as s",2007,
Quantile regression and variable selection for partially linear single-index models with missing censoring indicators,"Abstract Partially linear single-index models have been studied extensively under censorship setting, but typically all of the censoring indicators are assumed to be observed. This paper focuses on the quantile regression (QR) estimation for the partially linear single-index models where the data are right censored and the censoring indicators are missing at random. We propose weighted QR estimators of unknown parameters and link function based on the regression calibration, imputation and inverse probability weighting approaches. The asymptotic properties of the proposed weighted QR estimators for unknown parameters and the link function are established. Moreover, to select the important predictors, a variable selection procedure is introduced by applying adaptive LASSO penalized and the oracle property of the proposed weighted penalized estimators is obtained simultaneously. The finite sample performance of the proposed estimation methods and variable selection procedure are evaluated via simulation study. We also illustrate the proposed methods by using a dataset from a breast cancer clinical trial.",2019,Journal of Statistical Planning and Inference
[Preoperative prediction for lymph node metastasis of rectal nonmucinous adenocarcinoma based on radiomics classifier].,"OBJECTIVE
To determine the value of radiomics in identifying lymph node (LN) metastasis in patients with rectal nonmucinous adenocarcinoma.â€© Methods: Imaging data of 91 patients were retrospectively analyzed (61 in the training set and 30 in the test set). A total of 1 301 radiomics features were extracted from high-resolution T2-weighted images of the whole primary tumor. The least absolute shrinkage and selection operator (LASSO) logistic regression was performed to choose the optimal features and construct a radiomics classifier in the training set. Its discrimination performance was compared with that of morphological criteria by receiver operating characteristic (ROC) curve analysis, which was validated in the test set.â€© Results: The radiomics classifier combined with five key features was significantly associated with LN metastasis, which distinguished LN metastasis with an area under curve (AUC) at 0.874 (95% CI 0.787 to 0.960) in the training set, and the performance was similar in the test set (AUC 0.878, 95% CI 0.727 to 1.000). The AUCs according to the morphological criteria in the training set and test set were 0.619 (95% CI 0.487 to 0.752) and 0.556 (95% CI 0.355 to 0.756), respectively. Discrimination of the radiomics classifier was superior to that of morphological criteria in both the two datasets (both P <0.05).â€© Conclusion: The radiomics classifier provides individualized risk estimation for LN metastasis in rectal nonmucinous adenocarcinoma patients and it has the advantage over the morphological criteria.",2019,Zhong nan da xue xue bao. Yi xue ban = Journal of Central South University. Medical sciences
Epidemiologia dos acidentes por Thalassophryne nattereri (niquim) no Estado do CearÃ¡ (1992-2002),"In Ceara State (1992 to 2002) 16 cases of envenomation by Thalassophyne nattereri occurred in the seaside of Ceara, 87.5% of cases in the region of Fortaleza and 12.5% in the interior of Ceara State. Ninety four percent were men and 6% women. Age range: 75% between 21 and 40 years and 19% between 41 and 60 years old. The time between medical assistance and the accident varied from 1 to 5 hours (4 cases), 6 to 12 hours (3 cases), over 12 hours in 4 cases and 5 patients did not know. Clinical manifestations observed were pain, local edema, transitory ischemia, paresthesia, ecchymosis and burned skin sensation. Anti inflammatory and analgesic drugs were used. In some cases, anesthetic, hot water, surgical peeling and anti-histaminic drugs were used. In 75% of cases cure was confirmed and in 12% cure was not confirmed. The number of accidents is probably higher than was found due to subnotification.",2005,Revista Da Sociedade Brasileira De Medicina Tropical
Discriminative Regression Machine: A Classifier for High-Dimensional Data or Imbalanced Data,"We introduce a discriminative regression approach to supervised classification in this paper. It estimates a representation model while accounting for discriminativeness between classes, thereby enabling accurate derivation of categorical information. This new type of regression models extends existing models such as ridge, lasso, and group lasso through explicitly incorporating discriminative information. As a special case we focus on a quadratic model that admits a closed-form analytical solution. The corresponding classifier is called discriminative regression machine (DRM). Three iterative algorithms are further established for the DRM to enhance the efficiency and scalability for real applications. Our approach and the algorithms are applicable to general types of data including images, high-dimensional data, and imbalanced data. We compare the DRM with currently state-of-the-art classifiers. Our extensive experimental results show superior performance of the DRM and confirm the effectiveness of the proposed approach.",2019,ArXiv
Multi-Layer Feature Reduction for Tree Structured Group Lasso via Hierarchical Projection,"Tree structured group Lasso (TGL) is a powerful technique in uncovering the tree structured sparsity over the features, where each node encodes a group of features. It has been applied successfully in many real-world applications. However, with extremely large feature dimensions, solving TGL remains a significant challenge due to its highly complicated regularizer. In this paper, we propose a novel Multi-Layer Feature reduction method (MLFre) to quickly identify the inactive nodes (the groups of features with zero coefficients in the solution) hierarchically in a top-down fashion, which are guaranteed to be irrelevant to the response. Thus, we can remove the detected nodes from the optimization without sacrificing accuracy. The major challenge in developing such testing rules is due to the overlaps between the parents and their children nodes. By a novel hierarchical projection algorithm, MLFre is able to test the nodes independently from any of their ancestor nodes. Moreover, we can integrate MLFreâ€”that has a low computational costâ€”with any existing solvers. Experiments on both synthetic and real data sets demonstrate that the speedup gained by MLFre can be orders of magnitude.",2015,
Long-Term Results of Catheter Ablation in Paroxysmal Atrial Fibrillation,"Backgroundâ€”Paroxysmal atrial fibrillation (AF) naturally progresses toward chronic AF at an estimated rate of 15% to 30% over a 1- to 3-year period. Pulmonary vein (PV) isolation is increasingly performed for the treatment of drug-refractory paroxysmal AF. The long-term data on clinical outcome after circumferential PV isolation are limited. Methods and Resultsâ€”From 2003 to late 2004, 161 patients (121 men; age, 59.8Â±9.7 years) with symptomatic paroxysmal AF and normal left ventricular function underwent circumferential PV isolation guided by 3-dimensional mapping and double Lasso technique. Right-sided and left-sided continuous circular lesions encircling the ipsilateral PVs were placed with irrigated radiofrequency energy. The procedure end point was the absence of all PV spikes for at least 30 minutes after PV isolation verified by 2 Lasso catheters placed within the ipsilateral PVs. Sinus rhythm was present in 75 patients (46.6%) after the initial procedure during a median follow-up period of 4.8 year...",2010,Circulation
"Object-Parallel Infrastructure for Implementing First-Order Methods , with an Example Application to LASSO","We describe the design of a C++ vector-manipulation substrate that allows firstorder optimization algorithms to be expressed in a concise and readable manner, yet still achieve high performance in parallel computing environments. We use standard object-oriented techniques of encapsulation and operator overloading, combined with a novel â€œsymbolic temporariesâ€ delayed-evaluation system that greatly reduces the overhead induced by compiler temporaries and economizes on memory references. We also provide infrastructure to support line-search methods by caching function values and gradients at previously-visited points in a transparent manner that does not â€œclutterâ€ the principal implementation. We demonstrate the usefulness of our vector-substrate tools by employing them to efficiently solve large-scale LASSO problems using hundreds of processor cores. We reformulate the LASSO problem as a bound-constrained quadratic optimization, and then solve it using the Spectral Projected Gradient (SPG) method implemented through our vector-manipulation substrate. Acknowledgements. This research was supported in part by National Science Foundation grant CCF-1115638. The authors acknowledge the Texas Advanced Computing Center (TACC) at The University of Texas at Austin for providing HPC resources that have contributed to the research results reported within this paper. See http://www.tacc.utexas.edu.",2015,
Balancing Performance and Interpretability: Selecting Features with Bootstrapped Ridge Regression,"Informctticists sometimes attempt to predict chronic healthcare events that are not fully understood. The resulting models often incorporate copious numbers of predictors derived across diverse datasets. This approach may yield desirable performance characteristics, but it sacrifices interpretability and portability. The Bootstrapped Ridge Selector (BoRidge) offers a tool to balance performance with interpretability. Compared to two modern feature selection methods, Bootstrapped LASSO regression (BoLASSO) and a minimal-redundancy-maximal-relevance selector (mRMR), the BoRidge bested them for binary classification on artificially generated data (sensitivity: 0.83, specificity:0.72) versus BoLASSO (sensitivity: 0.1, specificity:1) and mRMR (sensitivity: 0.69, specificity: 0.69). On a dataset used to validate a published suicide risk prediction model, the BoRidge selected an equally precise model to the publication, with far fewer predictors (114 versus the 1,538 used in the published model). The BoRidge has the potential to simplify classification models for complex problems, making them easier to translate and act upon.",2018,AMIA ... Annual Symposium proceedings. AMIA Symposium
The Mathematizable Properties of Human Bodies in Relation to Meillassouxâ€™s Discussion of Primary Qualities,"One of the goals of Meillassoux's philosophy is to secure the claim that the mathematizable properties of a thing can be thought as real properties of that thing. He explicitly says that he has not accomplished this goal yet. What the claim implies is that those properties remain the same whether there is a subject that thinks of them or not. However, such a goal runs into a series of difficulties which, nonetheless, can be resolved. Specifically, it encounters the difficulty that it is possible to mathematize the properties of non-real entities. A more serious difficulty is represented by the fact that the properties of human bodies, such as weight and height, can be mathematized.",2018,Cosmos and history: the journal of natural and social philosophy
Toward formalizing a validation methodology using simulation coverage,"The biggest obstacle in the formal verification of large designs istheir very large state spaces, which cannot be handled even bytechniques such as implicit state space traversal. The only viablesolution in most cases is validation by functional simulation. Unfortunately, this has the drawbacksof high computationalrequirementsdue to the large number of test vectors needed, and the lack of adequate coverage measures to characterize the quality of a given testset. To overcome these limitations, there has been recent interest inhybrid techniques which combine the strengths of formal verification and simulation. Formal verification-based techniques are usedon a test model (usually much smaller than the design) to derive a setof functional test vectors, which are then used for design validationthrough simulation. The test set generated typically satisfies somecoverage measure on the test model. Recent research has proposedthe use of state or transition coverage. However, no effort has beenmade to relate these measures to the coverage of design errors. Furthermore, the derivation of the test model remains largely ad-hoc,with few formal guidelines.We demonstrate that under a given set of assumptions, transitiontours on test models can be used for complete validation of an implementation against a specification, for a large and important classof designs that includes many programmable/hardwired, general-purpose processors/DSPs. A by-product of this study is specificguidelines for deriving the test model, motivated by the requirement of providing complete coverage of all errors. We illustrate theapplication of our methodology on a pipelined implementation of the DLX processor.",1997,
Variable Selection for Functional Logistic Regression in fMRI Data Analysis,"ABS TRACT This study was motivated by classification problem in Functional Magnetic Resonance Imaging (fMRI), a noninvasive imaging technique which allows an experimenter to take images of a subjectâ€™s brain over time. As fMRI studies usually have a small number of subjects and we assume that there is a smooth, underlying curve describing the observations in fMRI data, this results in incredibly high-dimensional datasets that are functional in nature. High dimensionality is one of the biggest problems in statistical analysis of fMRI data. There is also a need for the development of better classification methods. One of the best things about fMRI technique is its noninvasiveness. If statistical classification methods are improved, it could aid the advancement of noninvasive diagnostic techniques for mental illness or even degenerative diseases such as Alzheimerâ€™s. In this paper, we develop a variable selection technique, which tackles high dimensionality and correlation problems in fMRI data, based on L1 regularization-group lasso for the functional logistic regression model where the response is binary and represent two separate classes; the predictors are functional. We assess our method with a simulation study and an application to a real fMRI dataset.",2015,Turkiye Klinikleri Journal of Biostatistics
High-throughput metabolite profiling: identification of plasma taurine as a potential biomarker of functional outcome after aneurysmal subarachnoid hemorrhage.,"OBJECTIVE
Metabolite profiling (or metabolomics) can identify candidate biomarkers for disease and potentially uncover new pathways for intervention. The goal of this study was to identify potential biomarkers of functional outcome after subarachnoid hemorrhage (SAH).


METHODS
The authors performed high-throughput metabolite profiling across a broad spectrum of chemical classes (163 metabolites) on plasma samples taken from 191 patients with SAH who presented to Massachusetts General Hospital between May 2011 and October 2016. Samples were drawn at 3 time points following ictus: 0-5, 6-10, and 11-14 days. Elastic net (EN) and LASSO (least absolute shrinkage and selection operator) machine learning analyses were performed to identify metabolites associated with 90-day functional outcomes as assessed by the modified Rankin Scale (mRS). Additional univariate and multivariate analyses were then conducted to further examine the relationship between metabolites and clinical variables and 90-day functional outcomes.


RESULTS
One hundred thirty-seven (71.7%) patients with aneurysmal SAH met the criteria for inclusion. A good functional outcome (mRS score 0-2) at 90 days was found in 79 (57.7%) patients. Patients with good outcomes were younger (p = 0.002), had lower admission Hunt and Hess grades (p < 0.0001) and modified Fisher grades (p < 0.0001), and did not develop hydrocephalus (p < 0.0001) or delayed cerebral ischemia (DCI) (p = 0.049). EN and LASSO machine learning methods identified taurine as the leading metabolite associated with 90-day functional outcome (p < 0.0001). Plasma concentrations of the amino acid taurine from samples collected between days 0 and 5 after aneurysmal SAH were 21.9% (p = 0.002) higher in patients with good versus poor outcomes. Logistic regression demonstrated that taurine remained a significant predictor of functional outcome (p = 0.013; OR 3.41, 95% CI 1.28-11.4), after adjusting for age, Hunt and Hess grade, modified Fisher grade, hydrocephalus, and DCI.


CONCLUSIONS
Elevated plasma taurine levels following aneurysmal SAH predict a good 90-day functional outcome. While experimental evidence in animals suggests that this effect may be mediated through downregulation of pro-inflammatory cytokines, additional studies are required to validate this hypothesis in humans.",2019,Journal of neurosurgery
Smooth and Sparse Optimal Transport,"Entropic regularization is quickly emerging as a new standard in optimal transport (OT). It enables to cast the OT computation as a differentiable and unconstrained convex optimization problem, which can be efficiently solved using the Sinkhorn algorithm. However, entropy keeps the transportation plan strictly positive and therefore completely dense, unlike unregularized OT. This lack of sparsity can be problematic in applications where the transportation plan itself is of interest. In this paper, we explore regularizing the primal and dual OT formulations with a strongly convex term, which corresponds to relaxing the dual and primal constraints with smooth approximations. We show how to incorporate squared $2$-norm and group lasso regularizations within that framework, leading to sparse and group-sparse transportation plans. On the theoretical side, we bound the approximation error introduced by regularizing the primal and dual formulations. Our results suggest that, for the regularized primal, the approximation error can often be smaller with squared $2$-norm than with entropic regularization. We showcase our proposed framework on the task of color transfer.",2018,
Template-mediated synthesis of lariat RNA and DNA.,"Nucleic acid ""lariats"" have been of great interest to the biological community since their discovery two decades ago as splicing intermediates in the biosynthesis of messenger RNA (lariat RNA introns). We report here the first synthesis of lariat DNA and RNA via template-mediated chemical ligation of Y-shaped oligonucleotides. The method allows for the synthesis of lariat DNA of any base composition as well as the more biologically relevant lariat RNA. Typically, branched precursors and complementary linear templates (""splints"") were dissolved in an equimolar ratio at a total concentration of 10(-4) M, and ligation was promoted by addition of cyanogen bromide in a pH 7.6 buffer. The template-directed cyclization was very efficient, since the amount of circularized lariat product observed in all cases was in the 40-60% range. The lariats were purified by polyacrylamide gel electrophoresis, and their structure and nucleotide composition confirmed by MALDI-TOF mass spectrometry. Thermal denaturation and circular dichroism studies of lariat:RNA and lariat:DNA duplexes were fully supportive of the isolated ""lasso"" structures. Further characterization was conducted by enzymatic degradation with spleen phosphodiesterase (a 3'-exonuclease) and the RNA lariat debranching enzyme, a specific 2',5'-phosphodiesterase.",2003,The Journal of organic chemistry
Thalassomyxa australis rhythmicity III. Entrainment by combination of different Zeitgeber,"Abstract The rhythmic change between an actively moving phase and a rounded up resting phase of the marine plasmodial rhizopod Thalassomyxa australis, sustained by the diatom Amphiprora, can be synchronized (1) By a combination of lightâ€darkâ€cycles and temperature cycles. This method was successful in 1/3 of the cases (2) By shaking the cultures every 12 hours for 15 or 30 minutes. This method was successful in half of the cases (3) By combining lightâ€darkâ€cycles, temperature cycles and periodic shaking. This method is synchronizing in all cases, but the phase relationship of the shaking to the other Zeitgeber is important for successful entrainment.",1988,Biological Rhythm Research
Efficient Lasso training from a geometrical perspective,"The Lasso (L1-penalized regression) has drawn great interests in machine learning and statistics due to its robustness and high accuracy. A variety of methods have been proposed for solving the Lasso. But for large scale problems, the presence of L1 norm constraint significantly impedes the efficiency. Inspired by recent theoretical and practical contributions on the close relation between Lasso and SVMs, we reformulate the Lasso as a problem of finding the nearest point in a polytope to the origin, which circumvents the L1 norm constraint. This problem can be solved efficiently from a geometric perspective using the Wolfe's method. Comparing with least angle regression (LARS), which is a conventional method to solve Lasso, the proposed algorithm is advantageous in both efficiency and numerical stability. Experimental results show that the proposed approach is competitive with other state-of-the-art Lasso solvers on large scale problems.",2015,Neurocomputing
Variable selection in nonparametric additive models with measurement errors,"In this article, we are interested in variable selection for nonparametric additive models with covariates being measured with errors. Without specifying any error model, a two-stage variable selection procedure is proposed with assistance of proper validation data. Briefly, each nonparametric component is approximated by a linear combination of basis functions, and the conditional expectations of these basis functions given the surrogate covariates are estimated via the validation data in the first stage. Selection of nonzero components using the group Lasso via the surrogate data is performed in the second stage. With appropriate selection of the tuning parameters, consistency of the proposed variable selection procedure and the oracle results are established. Some simulation studies will be used to demonstrate the finite sample performance of the proposed method.",2017,
"Examining the Correlates of Sexually Transmitted Infection Testing Among Men Who Have Sex With Men in Ouagadougou and Bobo-Dioulasso, Burkina Faso.","BACKGROUND
Men who have sex with men (MSM) are a population at risk for HIV acquisition and transmission and other sexually transmitted infections (STIs). In Burkina Faso, the prevalence of HIV among MSM is higher than that of other reproductive-aged adults. Early and frequent STI testing and treatment can help prevent HIV acquisition and transmission and may improve linkage to care.


METHODS
A cross-sectional study used respondent-driven sampling of MSM in the urban centers of Ouagadougou and Bobo-Dioulasso, Burkina Faso, to complete a questionnaire and HIV and syphilis testing. The binary-dependent variable in these analyses was self-reported prior STI testing in the past 12 months. Independent variables included sociodemographic characteristics, sexual behaviors, and psychosocial factors, selected according to the modified social ecological model. Bivariate associations at the P<0.05 level were used to create a manual forward stepwise multivariable logistic regression.


RESULTS
Seventy-six percent of participants (511/672) did not test for STIs in the last 12 months. Testing for STIs was associated with STI symptoms (odds ratio [OR], 2.56; 95% confidence interval [95% CI], 1.39-4.76) and independently associated with depressive symptoms (adjusted OR, 1.49; 95% CI, 1.01-2.20) and discussing HIV and STIs with main male partners (adjusted OR, 1.73; 95% CI, 1.23-1.76).


CONCLUSIONS
These data suggest that periodic targeted STI screening for MSM in Burkina Faso may represent an important component of comprehensive HIV prevention programming. The relationship between depression and STI risks is well established, and these data further indicate that screening for depression may be warranted during these clinical encounters.",2016,Sexually transmitted diseases
"Why LASSO, EN, and CLOT: Invariance-Based Explanation","In many practical situations, observations and measurement results are consistent with many different models â€“ i.e., the corresponding problem is ill-posed. In such situations, a reasonable idea is to take into account that the values of the corresponding parameters should not be too large; this idea is known as regularization. Several different regularization techniques have been proposed; empirically the most successful are LASSO method, when we bound the sum of absolute values of the parameters, and EN and CLOT methods in which this sum is combined with the sum of the squares. In this paper, we explain the empirical success of these methods by showing that they are the only ones which are invariant with respect to natural transformations â€“ like scaling which corresponds to selecting a different measuring unit. 1 Formulation of the Problem Need for solve the inverse problem. Once we have a model of a system, we can use this model to predict the systemâ€™s behavior, in particular, to predict the results of future measurements and observations of this system. The problem of estimating future measurement results based on the model is known as the forward problem.",2019,
Comments on Tainter and Lucas's â€œEpistemology of the Significance Conceptâ€,"In their discussion of the significance concept as used in Federal historic preservation programs, Tainter and Lucas (1983) accuse me of misunderstanding the relationship between theory and measurement in my article on significance evaluation (Glassow 1977). In this article, I argued that significance evaluations should go beyond relating archaeological resources to current regional research problems by attempting to assess the relevance of data to general concerns of archaeology. To do this, I proposed that research relevance might best bee considered in terms of five dimensions: variety, quantity, clarity, integrity, and environmental context. According to Tainter and Lucas (1983:715), I suggest that observation and evaluation in terms of these dimensions be theory-neutral. I said nothing of the sort, and taking my discussion as a whole, there is no justification for such an interpretation. In fact, I agree with Tainter and Lucas: dimensions can never be completely theory neutral.",1985,American Antiquity
"Tasmanitachoides belongs to Trechini (Coleoptera : Carabidae): discovery of the larva, its phylogenetic implications and revised key to Trechitae genera","This study is aimed at solving the long-standing ambiguity about the phylogenetic placement of the Australian ground-beetle genus Tasmanitachoides. A recently published phylogeny of the supertribe Trechitae using morphological characters of larvae is re-examined in light of new discoveries. The results of the phylogenetic analysis of 65 informative characters for 36 taxa reject the previously maintained opinion of affinities between Tasmanitachoides and Tachyini. Instead it is hypothesised that the genus is a member of the monophyletic tribe Trechini and most likely belongs to the Trechodina radiation, represented in the analysis by the genera Perileptus and Thalassophilus. Older-instar larvae of Tasmanitachoides, Kenodactylus and Mioptachys, as well as the first-instar larva of Pachydesus, are described. An updated identification key to all analysed Trechitae genera is provided.",2008,Invertebrate Systematics
Support Vector Data Description,"This book is based on the basis that machine learningalgorithms and rank based statistical methods are abetter choice to develop a robust model in logicalsituations. We designed experimental setup for datacollection, developed unique class of model includingvariable selection, and detection methods. Theselected significant variables provide a unique classof model for all six participants. We emphasize thebest selected variables have good information formodel development, and each selected variable have noerror i.e.; AUC=1, with forward selection and supportvector data description classifier. Basically, wedeveloped a unique class of model using six differentclasses of subjects, predicting elderly fallprevention, and after doing external validation withseventh class of subject, we reached a uniquesolution. Sections one is research introduction,section two is all about research design and dataanalysis, section three and four give extensivedevelopment of model for variable selection and oneclass classifier. Then finally given the conclusionand future aspect of whole study.",2011,
Conduction Patterns in the Cardiac Veins: Electrophysiologic Characteristics of the Connections Between Left Atrial and Coronary Sinus Musculature,"AbstractIntroduction: Fractionated electrograms and double potentials have been well described within the coronary sinus (CS) in humans. The pattern of circumferential activation in the CS has not been investigated. Furthermore, no data exist on conduction characteristics within the great cardiac vein (GCV) or the middle cardiac vein (MCV).
Methods and Results: Twenty patients underwent catheter mapping of the CS, the MCV, and the GCV. Anatomical areas were verified by cannulation of the left superior pulmonary vein. The pattern of circumferential muscle activation within the proximal CS was also studied with a circular mapping catheter (Lasso 12 mm). At conventional mapping during sinus rhythm and high right atrial pacing, discrete double potentials or fractionated electrograms were recorded during left, right atrial and CS pacing at the CS ostium, mid-CS, and distal CS-ligament of Marshall area, in 2 (10%), 1 (5%), and 9 (45%) patients, respectively, whereas no patient displayed such signals in the MCV or GCV (p < 0.001). Proximal CS mapping with the Lasso was accomplished in 10 patients, 7 of whom had no evidence of multicomponent potentials in the CS at conventional mapping. Specific CS potentials dissociated from the atrial electrograms were recorded in all patiens with the use of circumferential mapping. The perimetric distribution of electrograms within the CS suggested an oblique course of conduction across the CS musculature.
Conclusion: Potentials representing activation of the CS musculature, with an oblique course of conduction across the CS, can be recorded in human CS but not in the GCV or MCV. This is compatible with anatomical observations of sinus venosus musculature covering the CS but not other cardiac veins, and supports the rationale for the role of CS musculature in the generation of atrial arrhythmias.",2004,Journal of Interventional Cardiac Electrophysiology
Cultivating soil health field lab (meeting 2),"Interested in whether reduced tillage really works? Come along to find out how we have been getting on with this field lab, trying out different organic methods of weed control like the use of black plastic, and exploring the impact on soil health. Itâ€™ll be a great chance to see whatâ€™s really worked, and to find out more about how tillage, soil health and biology can impact yield. Read our reports and notes so far, and be sure to join us for the meeting itself: free of charge to farmers and land managers (Â£40.00 plus VAT to others). Booking is essential as places will go quickly, For further information please contact David on 07718 570 946 or dmichie@soilassociation.org",2016,
"Inter-relationships among psychopathology, premorbid adjustment, cognition and psychosocial functioning in first-episode psychosis: a network analysis approach.","BACKGROUND
Better understanding of interplay among symptoms, cognition and functioning in first-episode psychosis (FEP) is crucial to promoting functional recovery. Network analysis is a promising data-driven approach to elucidating complex interactions among psychopathological variables in psychosis, but has not been applied in FEP.


METHOD
This study employed network analysis to examine inter-relationships among a wide array of variables encompassing psychopathology, premorbid and onset characteristics, cognition, subjective quality-of-life and psychosocial functioning in 323 adult FEP patients in Hong Kong. Graphical Least Absolute Shrinkage and Selection Operator (LASSO) combined with extended Bayesian information criterion (BIC) model selection was used for network construction. Importance of individual nodes in a generated network was quantified by centrality analyses.


RESULTS
Our results showed that amotivation played the most central role and had the strongest associations with other variables in the network, as indexed by node strength. Amotivation and diminished expression displayed differential relationships with other nodes, supporting the validity of two-factor negative symptom structure. Psychosocial functioning was most strongly connected with amotivation and was weakly linked to several other variables. Within cognitive domain, digit span demonstrated the highest centrality and was connected with most of the other cognitive variables. Exploratory analysis revealed no significant gender differences in network structure and global strength.


CONCLUSION
Our results suggest the pivotal role of amotivation in psychopathology network of FEP and indicate its critical association with psychosocial functioning. Further research is required to verify the clinical significance of diminished motivation on functional outcome in the early course of psychotic illness.",2019,Psychological medicine
Interpretable visual models for human perception-based object retrieval,"Understanding the results returned by automatic visual concept detectors is often a tricky task making users uncomfortable with these technologies. In this paper we attempt to build humanly interpretable visual models, allowing the user to visually understand the underlying semantic. We therefore propose a supervised multiple instance learning algorithm that selects as few as possible discriminant local features for a given object category. The method finds its roots in the lasso theory where a L1-regularization term is introduced in order to constraint the loss function, and subsequently produce sparser solutions. Efficient resolution of the lasso path is achieved through a boosting-like procedure inspired by BLasso algorithm. Quantitatively, our method achieves similar performance as current state-of-the-art, and qualitatively, it allows users to construct their own model from the original set of patches learned, thus allowing for more compound semantic queries.",2011,
Analisis Proses Pembelajaran Mata Dilkat Gambar Dasar Teknik Siswa Kelas 1 Jurusan Teknik Bangunansmk Negeri 2 Payakumbuh,"ABSTRACT Forconductingstudythe teacher is notonlypreparethemselvesphysicallyandmentally, but they also prepare the scenarioorthe Rencana Proses Pembelajaran(RPP). Thisstudyaimstoanalyze thelearning processin the classroomwithlesson planscreated byteachers.The type of thisresearchisdescriptive. Populationin this studyis thefirstclassof studentsmajoring inconstructionengineeringandthe studysamplewas takenbyrandom sampling techniquewith atotal sample of83students.The type of datainthisresearchisprimary dataobtaineddirectlyfromobservationsusingthe observation sheetandsecondary dataobtainedfromschoolrecordsrelated tothe number of studentsin that class. Data analysis techniquesimplementationprocessof learningis donetoanalyzethe learningprocesswith descriptive analysistechniquewhichanalyzesthe implementationof learningin accordancewithlesson planscreated byteachersandtranslatedin narrative form.The results ofthe analysis shows that the learning process is good categories and suitable with RPP, percentage of students attended the TGB, TKK and TKB 66.66% and Â 69.11%, 70.59% and 75.05%, 70.26% and 69.28% for 1 st class and 2 nd class respectively for each subject. Keywords : Rencana Proses Pembelajaran",2015,
Bayesian Regularized Quantile Regression Analysis Based on Asymmetric Laplace Distribution,"In recent years, variable selection based on penalty likelihood methods has aroused great concern. Based on the Gibbs sampling algorithm of asymmetric Laplace distribution, this paper considers the quantile regression with adaptive Lasso and Lasso penalty from a Bayesian point of view. Under the non-Bayesian and Bayesian framework, several regularization quantile regression methods are systematically compared for error terms with different distributions and heteroscedasticity. Under the error term of asymmetric Laplace distribution, statistical simulation results show that the Bayesian regularized quantile regression is superior to other distributions in all quantiles. And based on the asymmetric Laplace distribution, the Bayesian regularized quantile regression approach performs better than the non-Bayesian approach in parameter estimation and prediction. Through real data analyses, we also confirm the above conclusions.",2020,Journal of Applied Mathematics and Physics
Forced-air Cooling Reduces 1-mcp Application Duration on Plums (prunus Salicina Lindl.) without Reducing Effectiveness,"A new application technology of applying 1-MCP during forced-air cooling (FAC) was tested in plums. The application time for 1-MCP was reduced from 24 h to 6 h without affecting treatment performance. 1-MCPâ€“FAC treatment followed by storage at 10Â°C showed promise as a new methodology to avoid chilling temperatures and provide considerable energy savings without reducing postharvest life and consumer quality. This new 1-MCP application system is compatible with current postharvest handling, rendering it easy to adopt by the tree fruit industry. Our results encourage testing of this new technology at the commercial scale to accurately quantify energy savings and consumer reactions for specific operations and markets. INTRODUCTION Japanese plum (Prunus salicina L.) is a highly perishable temperate fruit and cold storage at 0ï‚°C is recommended to extend fruit postharvest life and maintain quality (Thompson et al., 2008). Most plum cultivars are susceptible to postharvest disorders such as chilling injury (CI) symptoms after prolonged cold storage and express CI symptoms during ripening at room temperature (Manganaris et al., 2008). The onset of these symptoms determines postharvest storage/shipping potential because CI development reduces consumer acceptance. Susceptibility of fruit to CI mainly varies according to genetic background and storage temperature (Crisosto et al., 1999; Crisosto et al., 2008). Plum storage or transport at temperatures higher than 7.5ï‚°C to avoid CI has been tested in several cultivars and provided successful control of cold storage disorders, but fruit over-ripening, senescence, and softening overcame the benefits (Crisosto and Garner, 2008). 1-Methylcyclopropene (1-MCP) inhibits ethylene and prevents ethylenedependent responses such as softening and senescence of vegetative and fruit tissues (Sisler and Serek, 1997). Its ability to inhibit plum ripening is well demonstrated (Abdi et al., 1998; Martinez-Romero et al., 2003; Candan et al., 2006), making it a promising approach for plum storage above chilling temperatures without undesired softening. The recommended application for stone fruit is 0.5 Î¼l L for 24 h in a sealed room or tent at 0Â°C. The 24-h application period recommended for stone fruits, which delays storage and packaging, is a potential barrier for use of 1-MCP. Postharvest forced-air cooling (FAC) is a commercial practice used worldwide on stone fruits to reduce disease development, softening, and weight loss of fresh fruit (Thomson et al., 2008). Forced-air cooling is a powerful tool that allows perishable produce to be marketed over long distances because it can cool produce quickly after harvest. It is the primary cooling method used for fresh fruits and vegetables in California prior to placing them in longer term cold storage (Thomson et al., 2008). This study attempted to avoid development of cold storage disorders during plum fruit storage by applying 1-MCP during forced-air cooling (~6 to 9 h). This method could eliminate the currently required 24 h application time and would not alter current plum postharvest operations and thus should be easily adopted by the stone fruit industry. Proc. X IS on Plum & Prune Genetics, Breed. & Pomol. Eds.: T.M. DeJong and C.J. DeBuse Acta Hort. 985, ISHS 2013 258 MATERIALS AND METHODS Mid-season â€˜Fortuneâ€™ (red) plums were commercially harvested, packed and delivered on the same day to the Gordon Mitchell Postharvest Lab at UC Kearney, Parlier, CA. Immediately after arrival, five replications of five fruits were used to measure fruit quality at harvest. Fruit were randomized and divided into three treatments: 1) untreated (control); 2) treated with 0.5 Î¼l L1-MCP for 24 h at 0Â°C in sealed, 330-L aluminum tanks; and 3) treated with 0.5 Î¼l L1-MCP for 6 h at 0Â°C in a forced-air cooler (1 L skg) fitted in a sealed, 4000-L tent. Immediately after treatment, fruit from each treatment were split into two groups and stored at: 1) 0Â°C or 2) 10Â°C for up to 10 d. After storage at 0 or 10Â°C, five replicates of five fruits per treatment were transferred to room temperature (20Â°C, RH 90%) to evaluate fruit condition. Ethylene production, respiration rate, tissue firmness, soluble solids content (SSC), titratable acidity (TA), and skin and flesh color of fruit were monitored during ripening at 20Â°C after removal from storage. Ethylene production and respiration rate were measured on five fruits sampled from each treatment using a gas chromatograph (model Carle AGC-211, EG&G Chandler Engineering, Tulsa, OK, USA). Respiration rate was calculated by carbon dioxide concentration in the gas phase of storage jars, measured by an infrared gas analyzer (Horiba PIR-2000R, Horiba Instruments Inc., Irvine, CA, USA). Fruit firmness was measured at the two opposite cheeks of each fruit after removal of peel (1 mm thick) using a UC Firmness Tester with a 8-mm probe. Five replicates of five fruits were used to analyze soluble solids content (SSC) and acidity (TA). Fruit skin and flesh color was measured with a portable colorimeter (Minolta CR200, Minolta, Osaka, Japan) according to previous published protocols (Crisosto et al., 1997). Data were subjected to analysis of variance and least significant differences (LSD) at the 5% level were used for comparing means using SPSS 17.0 for Windows (SPSS, Chicago, IL, USA). RESULTS The standard 1-MCP treatment (applied for 24 h at 0Â°C) and the novel methodology of applying 1-MCP during FAC (applied for 6 h at 0ï‚°C), both delayed ripening changes at both storage temperatures in â€˜Fortuneâ€™ plums (Fig. 1). The efficacy of 1-MCP applied during FAC was similar to the standard 24 h application in both temperatures tested. Additionally, 1-MCP treated fruit stored at both temperatures showed reduced and delayed respiration rates compared to untreated fruit (Data non shown). Both 1-MCP application approaches (24-h standard and 6-h FAC) were significantly effective at protecting fruit from rapid softening during ripening after 10 d storage at 0 or 10Â°C. It must be emphasized that the reduced duration of 1-MCP application during FAC combined with storage at 10Â°C was very effective at inhibiting softening of â€˜Fortune plumsâ€™, which exhibited better firmness retention than untreated, cold-stored (0Â°C) fruit during ripening after 10 d storage. In general, both 1-MCP application protocols extended fruit shelf life (days to reach â€˜ready to eatâ€™ â‰¤13 N firmness) four to six days beyond untreated fruit stored for 10 d at 0 or 10Â°C. Thus the alternate treatment strategy during FAC appeared to be very promising and this technology should be able to be adopted easily by growers because of the reduced time required by not adding an extra step to the current postharvest handling of plums. CONCLUSIONS 1-MCP application during forced-air cooling reduced treatment application time without affecting performance and postharvest handling operations. Thus, this novel 1MCP-FAC application system can replace the current, 24 h application, making it easy to adopt by the tree fruit industry. Literature Cited Abdi, N., McGlasson, W.B., Holford, P., Williams, M. and Mizrahi, Y. 1998. Responses",2013,
Structured sparse model based feature selection and classification for hyperspectral imagery,"Sparse modeling is a powerful framework for data analysis and processing. It is especially useful for high-dimensional regression and classification problems in which a large number of feature variables exist but the amount of training samples is limited. In this paper, we address the problems of feature description, feature selection and classifier design for hyperspectral images using structured sparse models. A linear sparse logistic regression model is proposed to combine feature selection and pixel classification into a regularized optimization problem with the constraint of sparsity. To explore the structured features, three-dimensional discrete wavelet transform (3D-DWT) is employed, which processes the hyperspectral data cube as a whole tensor instead of adapting the data to a vector or matrix. This allows more effective capturing of the spatial and spectral structure. The structure of the 3D-DWT features is imposed on the sparse model by group LASSO which selects the features on the group level. The advantages of our method are validated on the real hyperspectral data.",2011,2011 IEEE International Geoscience and Remote Sensing Symposium
Equivalency Between Strapdown Inertial Navigation Coning and Sculling Integrals/Algorithms,"This paper develops a generic equivalency between strapdown inertial navigation coning and sculling integrals and algorithms. The equivalency allowsa previously derived coning algorithm to be converted to itscorresponding sculling algorithm using a simple mathematical formula. Two examples are provided illustrating the coning-to- sculling algorithm conversion process. The results are verie ed by comparing them against previously derived coning and sculling algorithms. WO key calculations performed in strapdown inertial naviga- tion systems are updating the body frame (inertial sensor axes ) attitudeandupdating thevehiclevelocity.The attitudeupdatecalcu- lation includes an integral term (denotedas coning) that is nonzero when the vehicle' s angular rate vector is rotating. The velocity up- date calculation includes an integral term (denotedas sculling) that is nonzero when the vehicle' s angular rate or specie c force accel- eration vector is rotating, or when the ratio of the angular rate to specie c force acceleration magnitude is not constant. To improvetheaccuracy ofthe attitudeand velocityupdatecalcu- lations, particularly in environments where the angular rate vector or specie c force acceleration vector rotation rate is large, high-rate algorithms have been developed for the coning and sculling inte- grals. The e rst detailed optimization of algorithms for the coning integral appeared in a paper by R. Miller. 1 Miller' s procedure was then applied and extended in a variety of papers, two of which are Refs. 2 and 3. A detailed description of the coning integral algo- rithm design process is provided in Ref. 4. Work on the design of sculling algorithms has not been as extensive as that of coning algo- rithms.Somerecentworkdetailingthedesignofscullingalgorithms is provided in Refs. 5 -7. In Ref. 5 Savage provides an analytical de- scription of sculling in two forms; the e rst having only one term, denoted as the composite sculling/velocity rotation compensation integral, and the second having two terms, denoted as velocity rota- tioncompensationandthescullingintegral.Anexampleisprovided that develops a digital algorithm for calculating the sculling inte- gral term. In Ref. 6 Ignagni derives a class of optimized sculling algorithms for the composite sculling/velocity rotation compensa- tionintegral and demonstrates aduality between the derived classof sculling algorithms and a previously derived class of coning algo- rithms. In addition, Ref. 6 provides a detailed example illustrating the derivation of one sculling algorithm solution and compares it to a previously derived coning algorithm solution (Ref. 2, algorithm 3). In Ref. 7 Mark and Tazartes develop a sculling algorithm using a different approach than that in Refs. 5 and 6. Both approaches are valid and have been successfully applied in strapdown systems. Thispaperonlydeals with sculling algorithmforms found inRefs.5 and 6. This paper develops a generic equivalency between the coning andsculling integrals and extends it to algorithms that take the same form as those in Refs. 5 and 6. The equivalency allows one to con- vert an already derived coning algorithm to its sculling algorithm counterpart using a simple mathematical formula. The paper e rst introduces the coning and sculling integral equations. Generic inte- gral/algorithm equivalencies are then developed showing how con-",2001,Journal of Guidance Control and Dynamics
Forecasting macro-economic variables using relevant predictors,"This paper expands on the factor model based forecasts by allowing for more 
 
exibility in the factor model. First a non-linear relationship between the predictors 
and the factors is allowed by expanding the dataset with the squared predictors. 
Second a subset of relevant predictors is selected based on their association with the 
series to be forecast. Hard thresholding, LARS and adaptive lasso techniques are 
used to select the relevant predictors. Factors are then estimated by applying prin- 
cipal components to these relevant predictors. These relevant predictors change for 
dierent dependent variables, forecast horizons and over time. Improvements over 
the normal factor model forecasts are found for all forecast horizons and variables.",2013,
Consistency of trace norm minimization,"Regularization by the sum of singular values, also referred to as the trace norm, is a popular technique for estimating low rank rectangular matrices. In this paper, we extend some of the consistency results of the Lasso to provide necessary and sufficient conditions for rank consistency of trace norm minimization with the square loss. We also provide an adaptive version that is rank consistent even when the necessary condition for the non adaptive version is not fulfilled.",2008,J. Mach. Learn. Res.
Design and analysis of delimiters for selection-action pen gesture phrases in scriboli,"We present a quantitative analysis of delimiters for pen gestures. A delimiter is ""something different"" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.",2005,
Class-imbalanced subsampling lasso algorithm for discovering adverse drug reactions,"Background All methods routinely used to generate safety signals from pharmacovigilance databases rely on disproportionality analyses of counts aggregating patientsâ€™ spontaneous reports. Recently, it was proposed to analyze individual spontaneous reports directly using Bayesian lasso logistic regressions. Nevertheless, this raises the issue of choosing an adequate regularization parameter in a variable selection framework while accounting for computational constraints due to the high dimension of the data. Purpose Our main objective is to propose a method, which exploits the subsampling idea from Stability Selection, a variable selection procedure combining subsampling with a high-dimensional selection algorithm, and adapts it to the specificities of the spontaneous reporting data, the latter being characterized by their large size, their binary nature and their sparsity. Materials and method Given the large imbalance existing between the presence and absence of a given adverse event, we propose an alternative subsampling scheme to that of Stability Selection resulting in an over-representation of the minority class and a drastic reduction in the number of observations in each subsample. Simulations are used to help define the detection threshold as regards the average proportion of false signals. They are also used to compare the performances of the proposed sampling scheme with that originally proposed for Stability Selection. Finally, we compare the proposed method to the gamma Poisson shrinker, a disproportionality method, and to a lasso logistic regression approach through an empirical study conducted on the French national pharmacovigilance database and two sets of reference signals. Results Simulations show that the proposed sampling strategy performs better in terms of false discoveries and is faster than the equiprobable sampling of Stability Selection. The empirical evaluation illustrates the better performances of the proposed method compared with gamma Poisson shrinker and the lasso in terms of number of reference signals retrieved.",2018,Statistical Methods in Medical Research
A Nonlinear Acceleration Method for Iterative Algorithms,"Iterative methods have led to better understanding and solving problems such as missing sampling, deconvolution, inverse systems, impulsive and Salt and Pepper noise removal problems. However, the challenges such as the speed of convergence and or the accuracy of the answer still remain. In order to improve the existing iterative algorithms, a non-linear method is discussed in this paper. The mentioned method is analyzed from different aspects, including its convergence and its ability to accelerate recursive algorithms. We show that this method is capable of improving Iterative Method (IM) as a non-uniform sampling reconstruction algorithm and some iterative sparse recovery algorithms such as Iterative Reweighted Least Squares (IRLS), Iterative Method with Adaptive Thresholding (IMAT), Smoothed l0 (SL0) and Alternating Direction Method of Multipliers (ADMM) for solving LASSO problems family (including Lasso itself, Lasso-LSQR and group-Lasso). It is also capable of both accelerating and stabilizing the well-known Chebyshev Acceleration (CA) method. Furthermore, the proposed algorithm can extend the stability range by reducing the sensitivity of iterative algorithms to the changes of adaptation rate.",2020,Signal Process.
"The feeding strategies of a facultative cleanerfish, Thalassoma bifasciatum (Pisces: Labridae)","The adult Bluehead wrasse (Thalassoma bifasciatum) is a facultative cleanerfish that can change its colouration into any one of three: patterns. These patterns correspond to several modes of feeding behaviour which, in turn, can be correlated with the movements of host fishes. The barred pattern occurred on individuals that are far ranging and also on those that formed unstable cleaning groups. These groups tended to form at locations having sharp drops in depth of several metres. Here these groups serviced large groups of host fishes. The striped pattern occurred on solitary individuals with a limited home range. They occurred in very shallow areas and serviced small groups of host fishes. The bright yellow pattern developed when a large food source was discovered and may be related to the attraction of conspecifics.",2009,Journal of Zoology
Bayesian method for inferring the impact of geographical distance on intensity of communication,"Both theoretical models and empirical findings suggest that the intensity of communication among groups of people declines with their degree of geographical separation. There is some evidence that rather than decaying uniformly with distance, the intensity of communication might decline at different rates for shorter and longer distances. Using Bayesian LASSO for model selection, we introduce a statistical model for estimating the rate of communication decline with geographic distance that allows for discontinuities in this rate. We apply our method to an anonymized mobile phone communication dataset. Our results are potentially useful in settings where understanding social and spatial mixing of people is important, such as in cluster randomized trials design.",2018,arXiv: Applications
"Thalassorhabdomicrobium marinisediminis gen. nov., sp. nov., a member of the family Hyphomonadaceae isolated from the Bohai Sea.","A novel Gram-stain-negative bacterium, designated strain BH-SD16T, was isolated from a marine sediment sample collected in the Bohai Sea. Cells of strain BH-SD16T are aerobic, non-flagellated oval-shaped rods, showing oxidase- and catalase-positive activities. Growth occurs between 15-45â€‰Â°C (optimum, 30â€‰Â°C), at pH 6.0-9.0 (pH 7.0-7.5) and with 1-10â€Š% (w/v) NaCl (3.0â€Š%). Strain BH-SD16T contains C18â€Š:â€Š1Ï‰7c (49.2â€Š%), C16â€Š:â€Š0 (17.7â€Š%) and C18â€Š:â€Š1Ï‰7c 11-methyl (16.6â€Š%) as the predominant fatty acids and ubiquinone-10 as the major respiratory quinone. The major polar lipids comprise phosphatidylglycerol, phosphatidylcholine, phosphatidylethanolamine, diphosphatidylglycerol and two glycolipids. The size of the draft genome is 3â€Š442â€Š538â€‰bp, including 3213 protein-coding genes, 40 tRNA genes and three rRNA genes, and the DNA G+Câ€‰content is 63.4â€‰mol%. Strain BH-SD16T shows the highest 16S rRNA gene sequence similarity to Pseudooctadecabacter jejudonensis (95.7â€Š%), strains of the genus Octadecabacter(95.4-95.6â€Š%) and strains of the genus Loktanella(93.8-95.4â€Š%). Phylogenetic trees based on 16S rRNA gene sequences show that strain BH-SD16T forms a distinct lineage within the family Hyphomonadaceae, which is also confirmed in the multigenic phylogenetic tree calculated by RAxML. Based on the results of phenotypic, chemotaxonomic and phylogenetic analysis, strain BH-SD16T is considered to represent a novel genus and species in the family Hyphomonadaceae, for which the name Thalassorhabdomicrobium marinisediminis gen. nov., sp. nov. is proposed. The type strain is BH-SD16T (=CCTCCâ€‰AB 2017073T=KCTC 62201T).",2019,International journal of systematic and evolutionary microbiology
A gut microbiota score predicting acute graftâ€versusâ€host disease following myeloablative allogeneic hematopoietic stem cell transplantation,"Although studies have reported that intestinal microbiota is associated with aGVHD, they lacked a satisfactory method for predicting aGVHD. We collected stool and blood samples at day 15 post-transplantation from 150 patients, who underwent myeloablative conditioning allogeneic hematopoietic stem cell transplantation (allo-HSCT) from two centers. Stool microbiota was detected by 16S rRNA gene sequencing, inflammatory factors and T lymphocyte were detected by multiplex immunoassays and flow cytometry respectively. A gut microbiota score (GMS) from a LASSO (least absolute shrinkage and selection operator) model was developed and validated to predict aGVHD. In the discovery cohort, the GMS could predict II-IV aGVHD (area under the ROC curve, AUC = 0.904, P < 0.0001). Furthermore, the validation model was consistent with the discovery set (AUC = 0.887, P < 0.0001). Treg/Th17 cells ratio in the low GMS subgroup was higher compared with the high GMS (P = 0.012), and the validation set consisted with the discovery set (P = 0.003). In addition, high cytokine levels were associated with high GMS. In conclusions, the GMS at neutrophil engraftment could predict aGVHD, and it was a potential and novel method. The GMS was associated with the inflammatory factor and Treg/Th17 balance.",2019,American Journal of Transplantation
Multi-model ensemble for short-term traffic flow prediction under normal and abnormal conditions,"Accurate traffic flow prediction under abnormal conditions, such as accidents, adverse weather, work zones, and holidays, is significant for proactive traffic control. Here, the authors focus on a special challenge of how to develop robust responsive algorithms and prediction models for short-term traffic forecasting in different traffic conditions. To this end, this study presents an ensemble learning algorithm for the short-term traffic flow prediction via the integration of gradient boosting regression trees (GBRT) and the least absolute shrinkage and selection operator (Lasso). Four different model structures whether considering the feature selection are proposed and tested for multi-step-ahead prediction under both normal and abnormal conditions. The results indicate that the proposed multi-model ensemble models are superior to the benchmark algorithms, i.e., support vector regression, and random forests, the GBRT model outperforms the Lasso model under normal traffic conditions, and the Lasso model has a better prediction accuracy under abnormal traffic conditions. In addition, the Lasso model with the feature selection is superior to the full feature model under either normal or abnormal conditions, while the GBRT model is not always better under normal conditions. The proposed integration framework is general and flexible to assemble various traffic prediction algorithms.",2019,Iet Intelligent Transport Systems
Prediction of the onset of epileptic seizures from iEEG data CS 229 Final Report,"Seizures in epileptic patients can be anxiety-inducing, and the resulting medical and social issues can cause distress to a patient. A predictive mechanism to anticipate the onset of a seizure could help a patient prepare for a seizure and take medication. The literature has shown that the onset of a seizure is directly correlated with a distinct neurological change that can be detected using iEEG measurements. Thus the development of a classification model based on IEEG data can be created to aid epileptic patients. In this project we develop a feature set based on spectral and statistical features of the IEEG data, with and without ICA pre-processing of the data. Several classication algorithms were trained on the resulting data sets, including Naive-Bayes, SVM, logistic regression, and lasso-regularized logistic regression. It was found that the optimal results were given for regularized logistic regression on PIB features without ICA pre-processing, though generally all algorithms performed better than a random naive predictor model.",2014,
Instrumental Variable Selection in Generalized Calibration,"Calibration is a procedure to incorporates auxiliary information for estimation of finite population parameters. The target of calibration is to obtain a system of weights for constructing estimators of finite population parameters. Calibration weights can be derived by: the minimum distance method (Deville & Sarndal (1992)), the instrument vector method (Generalized Estimator) (Devilee, 1998 Estevao & Sandal, 2006). The Generalized Estimator depends on the choice of the calibration funztion and of the instrument. Choosen a linear calibration function, we use typical econometric method for variables selection in order to select the instruments. Caner & Fan (2010) proposed to use the adaptive lasso for variable selection because of its oracle properties when instruments are irrelevant. We show adaptive lasso can select the instruments for which the MSE is smaller.",2013,
A Partial Correlation Screening Approach for Controlling the False Positive Rate in Sparse Gaussian Graphical Models,"Gaussian Graphical Models (GGMs) are extensively used in many research areas, such as genomics, proteomics, neuroimaging, and psychology, to study the partial correlation structure of a set of variables. This structure is visualized by drawing an undirected network, in which the variables constitute the nodes and the partial correlations the edges. In many applications, it makes sense to impose sparsity (i.e., some of the partial correlations are forced to zero) as sparsity is theoretically meaningful and/or because it improves the predictive accuracy of the fitted model. However, as we will show by means of extensive simulations, state-of-the-art estimation approaches for imposing sparsity on GGMs, such as the Graphical lasso, â„“1 regularized nodewise regression, and joint sparse regression, fall short because they often yield too many false positives (i.e., partial correlations that are not properly set to zero). In this paper we present a new estimation approach that allows to control the false positive rate better. Our approach consists of two steps: First, we estimate an undirected network using one of the three state-of-the-art estimation approaches. Second, we try to detect the false positives, by flagging the partial correlations that are smaller in absolute value than a given threshold, which is determined through cross-validation; the flagged correlations are set to zero. Applying this new approach to the same simulated data, shows that it indeed performs better. We also illustrate our approach by using it to estimate (1) a gene regulatory network for breast cancer data, (2) a symptom network of patients with a diagnosis within the nonaffective psychotic spectrum and (3) a symptom network of patients with PTSD.",2019,Scientific Reports
Sparse estimation of large covariance matrices via a nested Lasso penalty,"The paper proposes a new covariance estimator for large covariance matrices when the variables have a natural ordering. Using the Cholesky decomposition of the inverse, we impose a banded structure on the Cholesky factor, and select the bandwidth adaptively for each row of the Cholesky factor, using a novel penalty we call nested Lasso. This structure has more flexibility than regular banding, but, unlike regular Lasso applied to the entries of the Cholesky factor, results in a sparse estimator for the inverse of the covariance matrix. An iterative algorithm for solving the optimization problem is developed. The estimator is compared to a number of other covariance estimators and is shown to do best, both in simulations and on a real data example. Simulations show that the margin by which the estimator outperforms its competitors tends to increase with dimension.",2008,The Annals of Applied Statistics
Self-adaptive Lasso and its Bayesian Estimation,"In this paper, we proposed a self-adaptive lasso method for variable selection in regression problems. Unlike the popular lasso method, the proposed method introduces a specific tuning parameter for each regression coefficient. We modeled self-adaptive lasso in a Bayesian framework and developed an efficient Gibbs sampling algorithm to automatically select these tuning parameters and estimate the parameters. This algorithm also brings in some convenience for conducting statistical inference for selected variables. Several synthetic and real examples in this paper demonstrate flexibility of the tuning parameters enhance the performance of self-adaptive lasso in terms of both prediction and variable selection. Finally, we also extend the self-adaptive lasso to account for elastic net and fused lasso.",2010,
General rules of fragmentation evidencing lasso structures in CID and ETD.,"Lasso peptides constitute a structurally unique class of ribosomally synthesized and post-translationally modified peptides (RiPPs) characterized by a mechanically interlocked structure in which the C-terminal tail of the peptide is threaded and trapped within an N-terminal macrolactam ring. Tandem mass spectrometry using collision induced dissociation (CID) and electron capture dissociation (ECD) have shown previously different fragmentation patterns for capistruin, microcin J25 and their corresponding branched-cyclic forms in which the C-terminal tail is unthreaded. In order to develop general rules that unambiguously discriminate the lasso and branched-cyclic topologies, this report presents experimental evidence for a set of twenty-one lasso peptides analyzed by CID and electron transfer dissociation (ETD). CID experiments on lasso peptides specifically yielded mechanically interlocked species with associated bi and yj fragments. For class II lasso peptides, these lasso-specific fragments were observed only for peptides in which the loop, located above the macrolactam ring, was strictly longer than four amino acid residues. For class I and III lasso peptides, part of the C-terminal tail remains covalently linked to the macrolactam ring by disulfide bonds; associated bi and yj fragments therefore do not clearly constitute a signature of the lasso topology. ETD experiments of lasso peptides showed a significant increase of hydrogen migration events in the loop region when compared to their branched-cyclic topoisomers, leading to the formation of specific ciË™/z'j fragments for all lasso peptides, regardless of their class and loop size. Our experiments enabled us to establish general rules for obtaining structural details from CID and ETD fragmentation patterns, obviating the need for structure determination by NMR or X-ray crystallography.",2018,The Analyst
"Changes in the taxonomic diversity of the reef fish community of San JosÃ© Island, Gulf of California, Mexico","Although San JosÃ© Island is considered one of the most important islands in the lower Gulf of California due to its commercial fishing activities, few studies have evaluated their fish taxonomic diversity. The aim of this study was to determine the variation in the taxonomic diversity of the conspicuous fish community in eight locations around San JosÃ© Island from March 2001 to February 2002. We assessed the changes in the diversity of rocky reef fish based on the taxonomic distances between species, using Fisherâ€™s alpha diversity index, average taxonomic distinctiveness (AvTD Î”+), and taxonomic distinctiveness (Î”*). Visual censuses were conducted in 48 transects consisting of 100Â Ã—Â 5Â m quadrants (500Â m2 sampling area) at an average depth of 5Â m, from 09:00 to 16:00. A total of 26,608 fishes belonging to 112 species and 76 genera were found. The index of relative abundance was used to determine the most important species, which were in order of abundance: Abudefduf troschelii, Thalassoma lucasanum, Stegastes rectifraenum, Mulloidichthys dentatus, Chromis atrilobata, Lutjanus argentiventris, and Scarus ghobban. According to Fisherâ€™s alpha diversity index, the highest diversity of species was found in July and the lowest in February. The indices of Î”+ and Î”* indicated significant temporal and spatial differences.",2012,Biodiversity and Conservation
Gully erosion spatial modelling: Role of machine learning algorithms in selection of the best controlling factors and modelling process,"Abstract This investigation assessed the efficacy of 10 widely used machine learning algorithms (MLA) comprising the least absolute shrinkage and selection operator (LASSO), generalized linear model (GLM), stepwise generalized linear model (SGLM), elastic net (ENET), partial least square (PLS), ridge regression, support vector machine (SVM), classification and regression trees (CART), bagged CART, and random forest (RF) for gully erosion susceptibility mapping (GESM) in Iran. The location of 462 previously existing gully erosion sites were mapped through widespread field investigations, of which 70% (323) and 30% (139) of observations were arbitrarily divided for algorithm calibration and validation. Twelve controlling factors for gully erosion, namely, soil texture, annual mean rainfall, digital elevation model (DEM), drainage density, slope, lithology, topographic wetness index (TWI), distance from rivers, aspect, distance from roads, plan curvature, and profile curvature were ranked in terms of their importance using each MLA. The MLA were compared using a training dataset for gully erosion and statistical measures such as RMSE (root mean square error), MAE (mean absolute error), and R-squared. Based on the comparisons among MLA, the RF algorithm exhibited the minimum RMSE and MAE and the maximum value of R-squared, and was therefore selected as the best model. The variable importance evaluation using the RF model revealed that distance from rivers had the highest significance in influencing the occurrence of gully erosion whereas plan curvature had the least importance. According to the GESM generated using RF, most of the study area is predicted to have a low (53.72%) or moderate (29.65%) susceptibility to gully erosion, whereas only a small area is identified to have a high (12.56%) or very high (4.07%) susceptibility. The outcome generated by RF model is validated using the ROC (Receiver Operating Characteristics) curve approach, which returned an area under the curve (AUC) of 0.985, proving the excellent forecasting ability of the model. The GESM prepared using the RF algorithm can aid decision-makers in targeting remedial actions for minimizing the damage caused by gully erosion.",2020,Geoscience frontiers
Distributionally Robust Optimization and its Applications in Machine Learning,"Distributionally Robust Optimization and its Applications in Machine Learning Yang Kang The goal of Distributionally Robust Optimization (DRO) is to minimize the cost of running a stochastic system, under the assumption that an adversary can replace the underlying baseline stochastic model by another model within a family known as the distributional uncertainty region. This dissertation focuses on a class of DRO problems which are data-driven, which generally speaking means that the baseline stochastic model corresponds to the empirical distribution of a given sample. One of the main contributions of this dissertation is to show that the class of data-driven DRO problems that we study unify many successful machine learning algorithms, including square root Lasso, support vector machines, and generalized logistic regression, among others. A key distinctive feature of the class of DRO problems that we consider here is that our distributional uncertainty region is based on optimal transport costs. In contrast, most of the DRO formulations that exist to date take advantage of a likelihood based formulation (such as Kullback-Leibler divergence, among others). Optimal transport costs include as a special case the so-called Wasserstein distance, which is popular in various statistical applications. The use of optimal transport costs is advantageous relative to the use of divergencebased formulations because the region of distributional uncertainty contains distributions which explore samples outside of the support of the empirical measure, therefore explaining why many machine learning algorithms have the ability to improve generalization. Moreover, the DRO representations that we use to unify the previously mentioned machine learning algorithms, provide a clear interpretation of the so-called regularization parameter, which is known to play a crucial role in controlling generalization error. As we establish, the regularization parameter corresponds exactly to the size of the distributional uncertainty region. Another contribution of this dissertation is the development of statistical methodology to study data-driven DRO formulations based on optimal transport costs. Using this theory, for example, we provide a sharp characterization of the optimal selection of regularization parameters in machine learning settings such as square-root Lasso and regularized logistic regression. Our statistical methodology relies on the construction of a key object which we call the robust Wasserstein profile function (RWP function). The RWP function similar in spirit to the empirical likelihood profile function in the context of empirical likelihood (EL). But the asymptotic analysis of the RWP function is different because of a certain lack of smoothness which arises in a suitable Lagrangian formulation. Optimal transport costs have many advantages in terms of statistical modeling. For example, we show how to define a class of novel semi-supervised learning estimators which are natural companions of the standard supervised counterparts (such as square root Lasso, support vector machines, and logistic regression). We also show how to define the distributional uncertainty region in a purely data-driven way. Precisely, the optimal transport formulation allows us to inform the shape of the distributional uncertainty, not only its center (which given by the empirical distribution). This shape is informed by establishing connections to the metric learning literature. We develop a class of metric learning algorithms which are based on robust optimization. We use the robust-optimization-based metric learning algorithms to inform the distributional uncertainty region in our data-driven DRO problem. This means that we endow the adversary with additional which force him to spend effort on regions of importance to further improve generalization properties of machine learning algorithms. In summary, we explain how the use of optimal transport costs allow constructing what we call double-robust statistical procedures. We test all of the procedures proposed in this paper in various data sets, showing significant improvement in generalization ability over a wide range of state-of-the-art procedures. Finally, we also discuss a class of stochastic optimization algorithms of independent interest which are particularly useful to solve DRO problems, especially those which arise when the distributional uncertainty region is based on optimal transport costs.",2017,
DiffGRN: differential gene regulatory network analysis.,"Identification of differential gene regulators with significant changes under disparate conditions is essential to understand complex biological mechanism in a disease. Differential Network Analysis (DiNA) examines different biological processes based on gene regulatory networks that represent regulatory interactions between genes with a graph model. While most studies in DiNA have considered correlation-based inference to construct gene regulatory networks from gene expression data due to its intuitive representation and simple implementation, the approach lacks in the representation of causal effects and multivariate effects between genes. In this paper, we propose an approach named Differential Gene Regulatory Network (DiffGRN) that infers differential gene regulation between two groups. We infer gene regulatory networks of two groups using Random LASSO, and then we identify differential gene regulations by the proposed significance test. The advantages of DiffGRN are to capture multivariate effects of genes that regulate a gene simultaneously, to identify causality of gene regulations, and to discover differential gene regulators between regression-based gene regulatory networks. We assessed DiffGRN by simulation experiments and showed its outstanding performance than the current state-of-the-art correlation-based method, DINGO. DiffGRN is applied to gene expression data in asthma. The DiNA with asthma data showed a number of gene regulations, such as ADAM12 and RELB, reported in biological literature.",2018,International journal of data mining and bioinformatics
"A 100-Year History of Floods Determined from Tree Rings in a Small Mountain Stream in the Tatra Mountains, Poland","Dendrochronological methods enable the dating of episodes with sudden disturbance events such as forest fires, tree uprooting, rockfall, and snow avalanches in time and space (e.g. Denneler and Schweingruber 1993; Fantucci 1999; Lang et al. 1999; Niklasson and Granstrom 2000; Storaunet and Rolstad 2004; Stoffel and Perret 2006). Tree rings have also been used to identify floods and raised water levels (Harrison and Reid 1967; Begin and Payette 1988; Hupp 1988; Gottesfeld and Gottesfeld 1990; Tardif and Bergeron 1997; Begin 2001). Information on past activity might be preserved in living trees or dead stumps, thus allowing a long-term reconstruction of past flood events (LePage and Begin 1996; Yanoski 1999; St George and Nielsen 2003). The time window accessible using tree scars is probably wider than that achieved by dating coarse woody debris accumulated in stream channels. This seems to be especially true for small, steep mountain streams with water flow causing redistribution, fragmentation and abrasion of tree trunks shortly after their delivery to the channel.",2010,
Spatial Subspace Clustering for Hyperspectral Data Segmentation,"We propose a novel method called spatial subspace clustering (SpatSC) for 1D hyperspectral data segmentation problem, e.g. hyperspectral data taken from a drill hole. Addressing this problem has several practical uses such as improving interpretability of the data, and especially a better understanding of the mineralogy. Spatial subspace clustering is a combination of subspace learning and the fused lasso. As a result, it is able to produce spatially smooth clusters. From this point of view, it can be simply interpreted as a spatial information guided subspace learning algorithm. SpatSC has flexible structures that embrace the cases with and without library of pure spectra. It can be further extended, for example, using different error structures, such as including rank operator. We test this method on a real drill hole thermal infrared hyperspectral data set called DDH9. SpatSC produces stable and continuous segments, which are more interpretable. This property is not shared by other state-of-the-art subspace learning algorithms.",2013,
Evaluation of DysLexML ; A Screening Tool for Dyslexia Using Machine Learning,"Eye movements during text reading can provide insights about reading disorders. Via eye-trackers, we can measure when, where and how eyes move with relation to the words they read. Machine Learning (ML) algorithms can decode this information and provide differential analysis. In our earlier work 1 , we developed DysLexML, a screening tool for developmental dyslexia that applies various ML algorithms to analyze fixation points recorded via eye-tracking during silent reading of children. We had evaluated its performance using measurements collected in the first systematic field study with 69 native Greek speakers, children, 32 of which were diagnosed as dyslexic by the official governmental agency for diagnosing learning and reading difficulties in Greece. In that field study, the measurements were collected using a custom-made eye-tracker developed by Medotics AG 2 . Here, we evaluate our system using a larger dataset from the second field study which consists of 135 children, 62 of which were diagnosed as dyslexic. In both works, we examined a large set of features based on statistical properties of fixations and saccadic movements and identified the ones with prominent predictive power, performing dimensionality reduction. I. DYSLEXML The main modules of the DysLexML algorithm include the feature extraction, the feature selection for identifying the dominant features, and its classifiers that employ these dominant features. DysLexML extracts general (non-wordspecific) features and word-specific ones that take into account the word the subject is looking at. Examples of non-word specific features are the number of fixations on the screen, mean and median duration of fixations and related to saccades, the mean and median length of saccades, i.e., the Euclidean distance between consecutive fixations, and characterization of the types of eye movements. DysLexML creates a feature vector of 35 features in total. DysLexML consists of two phases: It first employs the LASSO Regression five-fold crossvalidation to identify the dominant features. Based on the dominant features, it applies various classification algorithms. Â¶Contact author: Maria Papadopouli (mgp@ics.forth.gr) 1T. Asvestopoulou, V. Manousaki, A. Psistakis, I. Smyrnakis, V. Andreadakis, I. Aslanides, M. Papadopouli, â€DysLexML: Screening Tool for Dyslexia Using Machine Learningâ€ submitted at Eusipco, 2019 2I. Smyrnakis, V. Andreadakis, V. Selimis, M. Kalaitzakis, T. Bachourou, G. Kaloutsakis, G. D. Kymionis, S. Smirnakis, I. M. Aslanides, RADAR: A novel fast-screening method for reading difficulties with special focus on dyslexia., PLoS ONE, 2017. II. PERFORMANCE ANALYSIS Field Study: A commercial tracker was employed for the acquisition of data. The model of the eye tracker was the Tobii 4C eye tracker, and was designed and manufactured by Tobii AB. This tracker has 90Hz frequency, whether the tracker in our previous study was 60Hz. In addition, the use of chin rest is not necessary anymore, hence the participants can freely move their head making the procedure completely noninvasive. Moreover, this study is much larger than the previous one, almost double in participants number. We have acquired data from 135 participants in total, 73 of them classified as typical readers and 62 of them classified as dyslexics. All the participants were native Greek speakers and the age span was from 7 years old to 17 years old. Fig. 1. Reading â€pathâ€ from a typical reader (top) and from a reader with dyslexia (bottom). The blue circles are the fixations and the orange lines the saccadic movements. The larger the circle, the longer the fixation. III. CONCLUSION Our system achieves its best performance using linear SVM model, with an accuracy of 97% for the small dataset and 74% using the K-means algorithm for the larger dataset. This performance is achieved over a small feature set, namely saccade length, number of short forward movements, and number of multiply fixated words. Furthermore, we analyzed the impact of noise on the fixation positions and showed that DysLexML is accurate and robust in the presence of noise. These encouraging results set the basis for developing screening tools in less controlled, larger-scale environments, with inexpensive eye-trackers, potentially reaching a larger population for early intervention.",2019,
Gap Safe screening rules for sparsity enforcing penalties,"In high dimensional regression settings, sparsity enforcing penalties have proved useful to regularize the data-fitting term. A recently introduced technique called screening rules propose to ignore some variables in the optimization leveraging the expected sparsity of the solutions and consequently leading to faster solvers. When the procedure is guaranteed not to discard variables wrongly the rules are said to be safe. In this work, we propose a unifying framework for generalized linear models regularized with standard sparsity enforcing penalties such as $\ell_1$ or $\ell_1/\ell_2$ norms. Our technique allows to discard safely more variables than previously considered safe rules, particularly for low regularization parameters. Our proposed Gap Safe rules (so called because they rely on duality gap computation) can cope with any iterative solver but are particularly well suited to (block) coordinate descent methods. Applied to many standard learning tasks, Lasso, Sparse-Group Lasso, multi-task Lasso, binary and multinomial logistic regression, etc., we report significant speed-ups compared to previously proposed safe rules on all tested data sets.",2017,J. Mach. Learn. Res.
Student Outcomes Across Collaborative-Learning Environments,"The Learning Assistant (LA) model supports instructors in implementing research-based teaching practices in their own courses. In the LA model, undergraduate students are hired to help facilitate research-based collaborative-learning activities. Using the Learning About STEM Student Outcomes (LASSO) database, we examined student learning from 112 first-semester physics courses that used either lecture-based instruction, collaborative instruction without LAs, or LA supported instruction. We measured student learning using 5959 students' responses on the Force and Motion Conceptual Evaluation (FMCE) or Force Concept Inventory (FCI). Results from Hierarchical Linear Models (HLM) indicated that LA supported courses had higher posttest scores than collaborative courses without LAs and that LA supported courses that used LAs in laboratory and recitation had higher posttest scores than those that used LAs in lecture.",2018,
The Economics and Politics of Carbon Taxes and Regulations: Evidence from Voting on Washington Stateâ€™s Initiative 732,"In November 2016, Washington State voters were presented with a ballot initiative (Initiative 732) advancing the first carbon tax on production and use of fossil fuels in the United States. Initiative 732 promised to reduce fossil fuel consumption by taxing carbon emissions, while remaining revenue-neutral by lowering taxes on businesses, consumers, and working families. In promising revenue-neutrality, Initiative 732 sought support beyond environmentalists and similarly sympathetic voters. It failed to pass, achieving 41.2 percent of votes cast. To investigate this initiativeâ€™s failure at the ballot, we analyzed zip code-level voting patterns and demographic data. Relying on a two-step LASSO (Least Absolute Shrinkage and Selection Operator) + OLS (Ordinary Least Squares) procedure, our results suggest that the framing of revenue-neutrality did not sufficiently satisfy moderate right-leaning voters regarding perceived costs of the carbon tax. We also found evidence suggesting not only that some voting segments may have opposed revenue-neutrality, but that those facing higher climate change risk did not appear to see the initiativeâ€™s value net of expected costs.",2019,Sustainability
"Proposal to build a neutrino observatory in Sudbury, Canada","SummaryThe proposal to build a heavy-water ÄŒerenkov detector deep underground is discussed. The main physics objectives are to measure the8B solar neutrino flux, to identify neutrino oscillations and to watch for gravitational collapse. The measurements of the sources of background and the optical properties of heavy water, which are necessary to prove the feasibility of the detector, are reported. The present status of the project is indicated.RiassuntoSi discute il progetto di costruire un rivelatore ÄŒerenkov ad acqua pesante a grande profonditÃ . Gli obiettivi fisici principali sono quelli di misurare il flusso di neutrini solati di8B, d'identificare le oscillazioni neutriniche e di osservare il collasso gravitazionale. Si riportano le misure delle sorgenti di background e le proprietÃ  ottiche dell'acqua pesante, che sono necessarie per provare la fattibilitÃ  del rivelatore. Si indica lo stato attuale del progetto.Ð ÐµÐ·ÑŽÐ¼ÐµÐžÐ±ÑÑƒÐ¶Ð´Ð°ÐµÑ‚ÑÑ Ð¿Ñ€ÐµÐ»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ð¾ ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²Ðµ Ñ‡ÐµÑ€ÐµÐ½ÐºÐ¾Ð²ÑÐºÐ¾Ð³Ð¾ Ð´ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€Ð° Ð½Ð° Ñ‚ÑÐ¶ÐµÐ»Ð¾Ð¹Ð²Ð¾Ð´Ðµ. ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸â€”Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°8B ÑÐ¾Ð»Ð½ÐµÑ‡Ð½Ñ‹Ñ… Ð½ÐµÐ¹Ñ‚Ñ€Ð¸Ð½Ð¾, Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð½ÐµÐ¹Ñ‚Ñ€Ð¸Ð½Ð½Ñ‹Ñ… Ð¾ÑÑ†Ð¸Ð»Ð»ÑÑ†Ð¸Ð¹ Ð¸ Ð½Ð°Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð°Ð²Ð¸Ñ‚Ð°Ñ†Ð¸Ð¾Ð½Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð»Ð»Ð°Ð¿ÑÐ° Ð¡Ð¾Ð¾Ð±Ñ‰Ð°ÑŽÑ‚ÑÑ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ñ„Ð¾Ð½Ð° Ð¸ Ð¾Ð¿Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… ÑÐ²Ð¾Ð¹ÑÑ‚Ð² Ñ‚ÑÐ¶ÐµÐ»Ð¾Ð¹ Ð²Ð¾Ð´Ñ‹, Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ðµ Ð´Ð»Ñ Ð²ÑŒÑˆÐ¾Ð»Ð½ÐµÐ½Ð¸Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð´ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€Ð°. ÐžÐ¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ÑÑ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð² Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ.",1986,Il Nuovo Cimento C
Construction and Validation of a 9-Gene Signature for Predicting Prognosis in Stage III Clear Cell Renal Cell Carcinoma,"Purpose: Aim of this study was to develop a multi-gene signature to help better predict prognosis for stage III renal cell carcinoma (RCC) patients. Methods: Fourteen pairs of stage III tumor and normal tissues mRNA expression data from GSE53757 and 16 pairs mRNA expression data from TCGA clear cell RCC database were used to analyze differentially expressed genes between tumor and normal tissues. Common different expressed genes in both datasets were used for further modeling. Lasso Cox regression analysis was performed to select and build prognostic multi-gene signature in TCGA stage III kidney cancer patients (N = 122). Then, the multi-gene signature was validated in stage III renal cancer cases in Fudan University Shanghai Cancer Center (N = 77). C-index and time-dependent ROC were used to test the efficiency of this signature in predicting overall survival. Results: In total, 1,370 common different expressed genes were found between tumor and normal tissues in both datasets. After Lasso Cox modeling, nine mRNAs were finally identified to build a classifier. Using this classifier, we could classify stage III clear cell RCC patients into high-risk group and low-risk group. Prognosis was significantly different between these groups in discovery TCGA cohort, validation FUSCC cohort and entire set (All P < 0.001). Multivariate cox regression in entire set (N = 199) revealed that risk group classified by 9-gene signature, age of diagnosis, pN stage and ISUP grade were independent prognostic factor of overall survival in stage III kidney cancer patients. Conclusion: We developed a robust multi-gene classifier that can effectively classify stage III RCC patients into groups with low and high risk of poor prognosis. This signature may help select high-risk patients who require more aggressive adjuvant target therapy or immune therapy.",2019,Frontiers in Oncology
Variable selection in the cox regression model with covariates missing at random.,"We consider variable selection in the Cox regression model (Cox, 1975, Biometrika 362, 269-276) with covariates missing at random. We investigate the smoothly clipped absolute deviation penalty and adaptive least absolute shrinkage and selection operator (LASSO) penalty, and propose a unified model selection and estimation procedure. A computationally attractive algorithm is developed, which simultaneously optimizes the penalized likelihood function and penalty parameters. We also optimize a model selection criterion, called the IC(Q) statistic (Ibrahim, Zhu, and Tang, 2008, Journal of the American Statistical Association 103, 1648-1658), to estimate the penalty parameters and show that it consistently selects all important covariates. Simulations are performed to evaluate the finite sample performance of the penalty estimates. Also, two lung cancer data sets are analyzed to demonstrate the proposed methodology.",2010,Biometrics
"Levels of5,5-Diphenylhydantoin andItsMajorMetabolite inHumanSerum, Saliva, andHyperplastic Gingiva","(DPH)and itspara-hydroxy metabolite (HPPH)were measured inserum,saliva, andinsegments ofhyperplastic gingiva frompatients receivingchronic drugtherapy. Theseverity of gingival hyperplasia tendstobeassociated withhigher DPH levels ingingiva andwith lowertissue levels ofHPPH. SinceKimball' in1939first described diphenylhydantoin (DPH)-induced gingival hyperplasia inpatients receiving chronic drug therapy, many theories'-9 havebeenproposedtoexplain thecauseofthisadverse drugreaction. However, noneofthese proposedmechanisms hasyetexplained the phenomenonsatisfactorily, nor has any mechanism satisfactorily explained whyother tissues arenotsimilarly affected. Clinical reports7-9 dealing withtheincidence ofgingival hyperplasia haveshownthatapproximately a thirdofthepatients receiving chronic DPH therapy develop this oralpathosis.Previous investigators7-"" havesuggested thatgoodoralhygiene andtheprevention ofgingival inflammation areimportantfactors incontrolling thedrug-induced gingival proliferation. Babcock andNelson6 havestudied institutionalized epileptics and suggested a direct relationship betweenthe degree ofhyperplasia andtheconcentration ofDPH insaliva. Datahavebeenreported Thisinvestigation was supported inpartbyUSPHS General Research Support GrantRR 05689fromthe National Institute ofDentalResearch, National InstitutesofHealth, Bethesda, Md,bytheEpilepsy Foundation ofAmerica, Washington, DC,andbytheAmericanDentalAssociation, Chicago, Ill. Thisstudy waspresented, inpart,atthe50thgeneralsession oftheIADR inLasVegas,Nev,March 1972. Received forpublication November12,1973.",1973,
"Anti-nociceptive Effect of Rhizome of Zingiber Officinale(ginger),apple Vinger and Their Combination on Animal Models of Pain in Laboratory Rats.","This study was performed to investigate the anti-nociceptive effect of aqueous extract of Zingiber officinale rhizomes by three animal models of pain (hot plate test , tail flick and formalin test. The results showed that the oral administration of aqueous extract of ginger caused (81%) increase in hot plate time,(100%)increase in tail flick time and (41%)decrease in number of licking and biting with respect to pre-administration number. While the rats that given apple vinegar only caused (79%)increase in hot plate time, (83%)increase in tail flick time and (47%)decrease in number of licking and biting with respect to pre-administration levels. When the ginger was mixed with vinegar, it showed only (85%)increase in hot plate test,(77%)increase in tail flick test and(63%)in formalin test. INTRODUCTION The growth in patient use of complementary and alternative medicine has an impaction conventional medical practice (1).Clinical investigation of complementary and alterative medicine are made difficulte by factor such as use of complex, individualized treatment and lack of standardization of herbal medicine(2). Many types of practices was paid attention by World Health Organization, it issueds a number of publications(3) and these deals with available experimental and clinical evidence for the effectiveness of several herbs in treatment of disease(4).Rhizome of Zingiber officinal used in treatment of toothache, rheumatic and muscular disorders, migraine headache, cold and flu, poor circulation in the hands and feet, headache .Comfrey cream when combined with Zingiber officinal rhizome for treating muscular disorders(5) When 5-10% Zingiber offcinale extract injected in to the painful joint or reaction nodules in number of patient in china with rheumatic pain and chronic lower back pain. experienced full or partial relief of pain and adecrease in joint swelling(6)The ethanolic extract of the rhizome of Zingiber officinale.reduced the carrageen-induced paw swelling and yeast induced fever in rats. This extract produced dose dependent inhibition of prostaglandin release using rat peritoneal leucocytes as a model (7). Ginger administration was found to relieve pain and associated symptoms in patients suffering from rheumatic disorders (8),and also ginger used in treatment of migraine (9).Powdered ginger relieved pain to a varying degree in about three quartered of 38 patients with rheumatoid arthritis and osteoarthritis. Ginger extract was found in standardized, placebo-controlled clinical trail on 261 patients with knee osteoarthritis, to be modera but significantly effective(10). Bas.J.Vet.Res.,Vol.7,No.1,2008 29 Ginger was found to be an effective antioxidant in a similar way to ascorbic acid (11).It had also antifungal activity(12)and as mixture of herbs,it stimulated upper gastro-intestinal tract(13). Materials and Methods The rhizome of Zingiber offcinale and apple vinegar were donated from Dr.Abdul-Basit Khalid Ahmed.Collage of Education. University of Basrah. Preparation of the aqueous extract: the required quantity(4gm)of the powder of Zinghber offcinale rhizome boiled in 200ml distilled water for five minutes, The clear supernatants were used(14). Animal Husbandry:laboratory rats were purchased in Education Collage /University of Basrah. The technique used in breading and maintaining rats was based on that described by (15).Rats were kept in opaque polypropylene cage with stainless steed lids(north kent plastic,U.K)and saw dust substrate was changed weekly. The rats were housed in a separate room in light controlled room(white fluorescent light in from6.00-18.00 hr and darkness for the rest of the days and temperature(25+3c) throught the study period.Food and water were supplied at libitum. Foods was prepared in the laboratory by mixing crude protin (15%), ground soya bean (6%),wheat flour (50%), wheat bran (25%) regetabl oil(2%), milk powder(2%) and minerals and vitamins (1g/kg) of the mixture .These materials were mixed with water, suitable from were prepared(as pollute)and put in oven 40c to dry.(15). Models of pain Three animal models of pain were used to test the analgesic effect, hot plate test, tail flick test and formaline test. Hot plate test:Animals were placed on a metal plate (Lasso company ,India) maintained at(55%) and the latency period for nociceptive responses which appear as licking ,flicking of the hind limb or jumping was measured in seconds. Rats that showed nociceptive responses within 18 seconds were used in the experinment (16)and(17). Tail flick test:Two centimeters of the end of rat tail was placed in a water bath at 50 c(Scientific Technical Supplies,Frankfort, Germany).Four groups,6 male rats each weighing (500gm).Group(1) received distilled water, group(2) received aqueous extract of ginger rhizome .group(3)received aqueous extract of Zingiber offcinale rhizome.Group 4 received aqueous extract of Zingiber offcinale mixed with vinegar. The nociceptive response appeared as flicking of the tail. The rats which showed a nociceptive response within 18 seconds were used(18). Formalin Test:-Briefly, each rat was placed in a transparent plastic cage and left for 5 minutes before formalin injection to allow habituation to the new environment 30 micro liters of 2% formalin was injected s/c to the planter region of hind paw of the rats the number of licking and/or biting of injected paw was recorded (19);(20). All tests were performed before one hour after administration of the aqueous extract of ginger , vinegar or their combination. Each animal recived a final volume a final 3ml orally. This consisted of 1.5ml distilled water or vinegar. Bas.J.Vet.Res.,Vol.7,No.1,2008 30 Statistical analysis The results were analyzed by one-way ANOVA and independent T-test by using spss (special program for statistical system) vession 9.0.All data are expressed as mean and SD ,the least significant difference(LSD)test was used to determine the differences between groups in ANOVA test(21). RESULTS 1-Hotplate test :Oral administration of aqueous extract of ginger resulted (81%) increase in hot plate time compared to pre-administration measurement (p <0.01). similarly ,apple vinegar resulted in (79%) increase in hot plate latency (p<0.01). When ginger extract was mixed with vinegar . it caused ( 85%) increment in hot plate time (Table l). 2Tail flick test :Oral administration of aqueous extract of Zingiber officnale rhizome resulted (100) increase in tail flick time compared to pre-administration measurement ( p<0.01) . when apple vinegar alone was used .it gave astatistically significant increase in tail flick time by (83%) with respect to pre-administration level .when ginger extract was mixed with vinegar, it increased tail flick time by (77%) (table 2). 3-Formalin test:Oral administration of aqueous extract of ginger rhizome resulted in (41%) decrease in the number of lickings and biting compared to control (P<0.05) . Apple vinegar alone resulted in (47%) decrease . when ginger extract was mixed with vinegar ,it decreased the number of licking and biting by (63%)(Table 3).. DISCUSSION Pain is the most commen medical complaint among civilized population.(22).A search for effective, safe and cheep agent from natural sources, for example herbs of worthwhile. In addition, traditional herbal remedies are usually not used alone but usually mixed with other agents such as vinegar.This gives the basis for standing vinegar in our investigaton. In models utilizing thermally induced pain (hot plate and tail flick test) the aqueous extract of Zingiber offcinal rhizome resulted 81% and 100% increase in hot plate and tail flick times respectively. This is agreed with that reported by (23) who found Zingibar offcinale to have anti nocieptive effect, acetic acid-induced formalin test and hot plate test.Apple vinegar gave anti nociceptive effect comparable to that aqueous extract of ginger rhizome in three pain models used in this study. It increase the hot plate and tail flick latencies by 79% and 83% respectively. It also reduced the number of licking and biting in formalin by 47% in comparison to a 41% reduction by Zingiber offcinale extract. Vinegar made by fermenting the juice of sweat fruits or grains such as apple ,grape, dates or barely, is not only a diluted acetic acid but contains more than thirty important nutrients, minerals, vitamins essential amino acids and several enzymes, and large amount of pectin (24) . It was found effective in patients with poly arthritis ( 25) and to have antiinflammatory activity (24) . We, in this present study, report it to have a significant analgesic effect against the three types of pain stimuli; two forms of thermal stimulation and one by local chemical irritation through the use of formalin. Bas.J.Vet.Res.,Vol.7,No.1,2008 31 The aqueous extract of Zingiber offcinale and apple vinegar together did not result in enhancement of the anti nociceptive effect to compared with those given alone in hot plate and tail flick tests. However , the combination resulted in a slight increase in the reduction of the number of licking and biting in formalin test from 41% and 47% to 63%. Among the constituents of Zingiber offcinale is an aqueous extract which has calming effect on joint swelling ( 6 ) and relieve of pain, treated migraine headache ( 9). Treatment of knee osteoarthritis (10). Antioxidant,antifungal(11)and(12). Therefore , future investigation should aim to identify the constituents that are responsible for this analgesic effect in ginger as well as apple vinegar .",2008,
Book Review: Clinical Handbook of Psychotropic Drugs. 6th Revised Edition,"This handbookprovides an exhaustive and impeccably organized presentationof psychotropic agents.Presentedin a horizontallypaged format, information is easy to retrieveat a glance.Each psychotherapeutic class is reviewedunder the headings of indications (approved and off-label), pharmacology, dosing,pharmacokinetics, onset and duration of action, adverse effects by organ system, withdrawal symptoms, precautions, toxicity, drug interactions, pediatric considerations, and considerations for use in pregnancy and lactation. Also included are patient instructions and nursingimplications for each classof agents.This book is replete with tables. The information provided is up to date and is of potentialuse to nurses, pharmacists, and physicians who practicein psychiatry. Also includedis a sectionon substances of abuseand theirpharmacologic and psychiatric effects, withdrawal symptoms, and treatment, as well as possible drug interactions.A table of 34 nonpsychotropics and their potentialpsychotherapeutic activitiesbased on case reports is also included, as is a chapteron electroconvulsive therapy. It is not clear whether the indicationslisted are for the US as well as Canada, as this work was edited at the Clarke Instituteof Psychiatry in Toronto.Anotherarea that may need clarificationis the clinical significanceof the drug interactions provided. Althoughthe natureof the in~erÂ­ actions is described and listed as clinicallysignificant, the presentation does not indicatethe frequency of occurrence. Pharmacoeconomic considerations and treatments of choiceare not included. Unfortunately, unlike other availablehandbooksin this field, the information presentedis not referenced. Overall,this is a complete, well-organized, reasonably priced,easy-touse reference that is undoubtedlyuseful for psychiatrichealthcareprofessionals.",1997,Annals of Pharmacotherapy
Manifold-Regularized Adaptive Lasso,"Adaptive Lasso preserves oracle properties comparing to classical Lasso. It performs as well as if the true underlying model is provided in advance. In order to let feature subset selected by Adaptive Lasso preserve more local information, which is discriminative and benefit for classification, Manifold-regularized Adaptive Lasso (MrALasso) is proposed for feature selection. Reconstructing response by linear sum of features is considered in manifold embedded in high-dimensional space. A similarity graph of data points is built. Connected points are restricted to stay together as close as possible so that the intrinsic geometry of the data and the local structure are preserved. An effective iterative algorithm, with detailed proof of convergence, is proposed to solve the optimization problem. Experimental results of feature selection on several classical gene datasets show the effectiveness and superiority of the proposed method.",2018,
Can EU high indebted countries manage to fulfill fiscal sustainability? Some evidence from the solvency constraint,"The public finance constraints introduced by the Maastricht Treaty have been subject to numerous debates among economists. Balassone and Franco (2000) pointed out, for instance, that the fulfillment of these constraints allows for fiscal discipline and flexibility and excludes any bias from an unsustainable fiscal policy in the long run. But data shows that many of the advanced economies have exceeded the limits for budgetary deficits and public debt since 1993. Therefore, the question on whether fiscal policy is sustainable naturally arises. The aim of this paper is to investigate the achievement of the solvency constraint for the European Union high indebted countries using a simple public debt dynamic model. The required primary surplus is estimated under different scenarios, namely: (i) a baseline that aims at stabilizing public debt; (ii) a 60% of GDP scenario; and (iii) a minimum public debt scenario that differs among the countries under analysis. From results, we try to draw conclusions on what really matters for fiscal sustainability.",2012,
The evolution of sex-change mechanisms in fishes,"SynopsisFive distinct sex-change mechanisms are identified among sequentially hermaphroditic fishes based on socio-ecological characteristics. The primary determinants of the sex-change mechanisms appear to be social organization and mating system, which in turn depend on resource distribution in space and time. The ability of a single individual to control all mating in the social unit, which is related to the size of the social unit, differentiates three suppression mechanisms from two induction mechanisms. Sex-change suppression, which is characteristic of species with small group size and rigid dominance hierarchies, refers to inevitable sex change in the absence of group dominance. Ability to migrate between resource patches differentiates protogynous suppression (e.g. inLabroides dimidiatus) from protandrous suppression (e.g. inAmphiprion spp.). Early sex change appears to have evolved from protogynous suppression under special conditions involving the loss of mating control by a single dominant individual in certain species (e.g.Centropyge spp. ). Sex-change induction, which is characteristic of species with large social groups lacking rigid dominance hierarchies, refers to the requirement that sex change must be induced by specific characteristics of (or changes in) the social group, regardless of dominance status. Ability to distinguish sex, or its importance, differentiates sex-ratio induction (e.g.Anthias squamipinnis) from size-ratio induction (e.g.Thalassoma spp.). Alternative models account for the possibility that all cases of sex change require stimulation from smaller conspecifics (universal induction-inhibition model) or that all fish have the genetic capacity to switch mechanisms, depending on changing ecological conditions and resulting changes in mating system (behavioral-scaling model). Neurophysiological models suggest that induction mechanisms, which require at least two categories of environmental stimuli, may have evolved from the simpler suppression mechanisms, which require only one kind of input from the environment.",2004,Environmental Biology of Fishes
"A Lasso-Inspired Bicyclic Peptide: Synthesis, Structure and Properties.","The chemical synthesis of a bicycle inspired by the natural lasso peptide sungsanpin using a combination of solid-phase and in-solution chemistries is described. The bicyclic-derived topoisomer was designed by introducing a covalent linkage between the ring and the loop, which allowed the tying of these two parts of the peptide, rendering the bicyclic structure. Several structural techniques, such as MS fragmentation, ion-mobility and NMR spectroscopic analysis were used to characterize the bicycle. Ion-mobility spectroscopy studies revealed that it showed lasso-like behavior. Its 3D structure was predicted on the basis of the NMR restraints. In addition, the high proteolytic and thermal stability of the bicycle potentially make it a suitable scaffold for epitope grafting.",2018,Chemistry
Regularizers for structured sparsity,"We study the problem of learning a sparse linear regression vector under additional conditions on the structure of its sparsity pattern. This problem is relevant in machine learning, statistics and signal processing. It is well known that a linear regression can benefit from knowledge that the underlying regression vector is sparse. The combinatorial problem of selecting the nonzero components of this vector can be â€œrelaxedâ€ by regularizing the squared error with a convex penalty function like the â„“1 norm. However, in many applications, additional conditions on the structure of the regression vector and its sparsity pattern are available. Incorporating this information into the learning method may lead to a significant decrease of the estimation error. In this paper, we present a family of convex penalty functions, which encode prior knowledge on the structure of the vector formed by the absolute values of the regression coefficients. This family subsumes the â„“1 norm and is flexible enough to include different models of sparsity patterns, which are of practical and theoretical importance. We establish the basic properties of these penalty functions and discuss some examples where they can be computed explicitly. Moreover, we present a convergent optimization algorithm for solving regularized least squares with these penalty functions. Numerical simulations highlight the benefit of structured sparsity and the advantage offered by our approach over the Lasso method and other related methods.",2013,Advances in Computational Mathematics
