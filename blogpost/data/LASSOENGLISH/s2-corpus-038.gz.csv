title,abstract,year,journal
Wound Activation of Protoxins in Marine Sponge Aplysina aerophoba,"The marine sponge Aplysina aerophoba accumulates brominated isoxazoline alkaloids, which include aerophobin-2, aplysinamisin-1, and isofistularin-3 as major constituents. Following disruption of compartmentalization, the isoxazoline alkaloids are enzymatically converted to aeroplysinin-1, which in turn gives rise to a dienone. The described bioconversions were demonstrated for the first time in vitro using an enzyme preparation from A. aerophoba. Cell-free extracts of other Aplysina species were capable of performing the same bioconversions, whereas enzyme extracts of sponges from other orders, which lack isoxazoline alkaloids, were inactive with regard to the reactions analyzed. These findings suggest that the enzyme activities studied are linked to the accumulation of suitable substrates and hence represent a specific biochemical property of sponges from the genus Aplysina. Time-course experiments with A. aerophoba, performed in situ, demonstrated that wound-induced bioconversions of isoxazoline alkaloids proceeded rapidly. Within 40 sec after mechanical damage of a tube of A. aerophoba, both aerophobin-2 and aplysinamisin-1 were completely converted to the dienone. The wound activation of protoxins results in a pronounced increase of the fish deterrent activity of A. aerophoba as shown in bioassays employing the common Caribbean wrasse Thalassoma bifasciatum.",2004,Journal of Chemical Ecology
Protective Ability of Biogenic Antimicrobial Peptide Microcin J25 Against Enterotoxigenic Escherichia Coli-Induced Intestinal Epithelial Dysfunction and Inflammatory Responses IPEC-J2 Cells,"Poison of intestinal induce severe health problems in human infants and young animals due to contaminating foods and feedstuffs. With the emergence of public health concerns and high-speed diffuse of drug-opposition of bacteria, the adoption of antimicrobial peptides as potential candidates in treating pathogen infections raised up. Nature Microcin J25 (MccJ25), a class of lasso peptides separated from a fecal strain of E. coli, has been replied to display powerful antimicrobial behavior. Herein, the study was to assess the usefulness of biogenic MccJ25 in the prophylaxis of ETEC K88 infection in IPEC-J2 cells. In vitro antimicrobial activity against ETEC K88 and cytotoxicity of biogenic MccJ25 were determined first. To further understand how biogenic MccJ25 mediates its impact, ETEC K88 adhesion in cells, membrane permeability [as indicated by reduced release of lactate dehydrogenase (LDH)], transepithelial electrical resistance (TEER), barrier function, and proinflammatory cytokines levels were determined in IPEC-J2 cells after treatment with biogenic MccJ25 and challenge with ETEC K88. Biogenic MccJ25 had a minimum inhibitory concentration of 0.25 Î¼g/mL against ETEC K88, decreased ETEC K88 adhesion in cells and did not cause cytotoxicity toward cells. Furthermore, biogenic MccJ25 protects against ETEC-induced barrier dysfunction by increasing the TEER, decreasing the LDH and promoting tight junction proteins (TJPs) by promoting the assembly of occludin and claudin-1 in the tight junction complex. Biogenic MccJ25 was further found to relieve inflammation responses through modulation of interleukine-6, IL-8 and tumor necrosis factor-Î± levels via inhibition of mitogen-activated protein kinase (MAPK) and nuclear factor ÎºB activation. In summary, biogenic MccJ25 can protects against ETEC K88-induced intestinal damage and inflammatory response, recommend the hidden adoption of biogenic MccJ25 as a novel prophylactic agent to reduce pathogen infection in animals, food or humans.",2018,Frontiers in Cellular and Infection Microbiology
On proximal gradient method for the convex problems regularized with the group reproducing kernel norm,"We consider a class of nonsmooth convex optimization problems where the objective function is the composition of a strongly convex differentiable function with a linear mapping, regularized by the group reproducing kernel norm. This class of problems arise naturally from applications in group Lasso, which is a popular technique for variable selection. An effective approach to solve such problems is by the proximal gradient method. In this paper we derive and study theoretically the efficient algorithms for the class of the convex problems, analyze the convergence of the algorithm and its subalgorithm.",2014,Journal of Global Optimization
Directing Nest Site Selection of Least Terns and Piping Plovers,"Abstract Endangered Interior Least Terns (Sterna antillarum athalassos) and threatened Piping Plovers (Charadrius melodus) nest in Nebraska at gravel mines where they are vulnerable to disturbance and nest loss. Conflicts occur when their nesting and protected status delay mining activities. The possibility of shifting nesting from active to inactive mining areas by using a deterrent (mylar flagging), an attractant (gravel and driftwood spread on bare sand), and a control (untreated sand) was evaluated. Experimental plots (mean 0.36 ha) were established at 18 different gravel mines, twelve in 2000 and seven (one repeat) in 2001 along the Platte and Elkhorn rivers prior to nesting season. Of 117 tern nests, 73% were in attractant, 2% in deterrent, and 26% in control plots. Of 23 plover nests, 61% were in attractant, 9% in deterrent, and 30% in control. Colonies used plots containing less vegetation and more driftwood than unused plots. Within control plots, both tern and plover nests were surrounded by more large (>15 mm) gravel and less coarse sand than was available at random points. Within attractant plots, substrate at the nest did not differ from random points. In all plots, Least Tern nests were more likely to have driftwood by the nest than was available at random points. Hatching rates did not differ between attractant and control plots. To attract Least Terns and Piping Plovers, sand covered with 15% small gravel, 5-10% large gravel, <3% vegetation, and about ten pieces driftwood/1,000 m2 was found to be effective. As deterrents, mylar streamers 7 m long, 30 mm wide, and 0.025 mm thick, attached to 1 m poles arranged in a 7 m grid were used. The combination of attractant and deterrent treatments provided a mechanism to protect nesting birds and avoid conflicts.",2007,
Functional Genomics of Heavy Metal Resistance in the Foodborne Pathogen Listeria monocytogenes.,"PARSONS, CAMERON TYLER. Functional Genomics of Heavy Metal Resistance in the Foodborne Pathogen Listeria monocytogenes. (Under the direction of Dr. Sophia Kathariou). Listeria monocytogenes is a Gram-positive facultative intracellular pathogen that is found ubiquitously in nature. To be able to survive in diverse environments, L. monocytogenes has acquired adaptations such as the ability to grow in the cold, to form biofilms, and to tolerate a variety of toxic compounds. L. monocytogenes also possesses adaptations that enable it to survive and proliferate inside an animal host, such as the ability to evade the host immune system, spread cell-to-cell and invade normally sterile sites such as the placenta and central nervous system. One of the adaptations that plays a role in both environmental and in vivo survival of L. monocytogenes, is its tolerance to heavy metals. In the environment L. monocytogenes can encounter extremely low levels of the essential metals it needs to function, or extremely high levels of both essential and toxic metals; either can prove to be fatal for the cell. Inside an animal host, L. monocytogenes can also encounter extremely high or low levels of essential metals, making the ability to tightly regulate intracellular metal levels of key importance to both saprophyte and pathogen. Here, transposon (mariner-based) mutagenesis was employed to investigate the genetic basis for the tolerance of L. monocytogenes to both essential, as well as toxic metals. Mutant libraries for two produce-related strains F8027 and 2011l-2858 were screened for mutants that had an increased susceptibility to arsenic, cadmium, and copper. Four mutants were isolated with decreased tolerance to cadmium, and one mutant with a decreased tolerance to copper. One of the cadmium-sensitive mutants was found to have a transposon insertion in cadA4, a novel member of the CadA family of cadmium-effluxing P-type ATPases, harbored on a larger mobile genetic element (MGE). Genetic complementation of this mutant with chromosomally integrated cadA4 restored cadmium tolerance. Furthermore, heterologous expression in two unrelated cadmium-susceptible L. monocytogenes strains conferred cadmium tolerance comparable to that of F8027, confirming the role of cadA4 in cadmium resistance. Assessments in the Galleria mellonella model suggested that cadA4 was negatively correlated with virulence, serving to suppress virulence. Another transposon mutant of strain F8027 with decreased tolerance to cadmium was found to have a transposon insertion in an intergenic region between a previously uncharacterized cell wallassociated protein and a gene of unknown function, on the same MGE as cadA4. This mutant was found to have reduced tolerance to zinc as well. Construction of deletion mutants suggested that the cell wall-associated protein was responsible for the decreased tolerance to zinc, and genetic complementation suggested that the inactivation of one of the downstream genes was responsible for the decreased tolerance of this mutant to cadmium. Assessments in the Galleria mellonella model suggested that, in addition to its role in zinc tolerance, the cell wall-associated protein was required for full virulence potential. The cell wall-associated protein was also found to mediate wild type levels of biofilm formation. The one mutant found to have a decreased tolerance to copper, was a derivative of strain 2011L-2858, and harbored a transposon insertion in the intergenic region just before the start codon of pbp4, encoding a penicillin binding protein. While previous work had associated this gene with susceptibility to Î²-lactam antibiotics and bacteriocins, this was the first time that a link between this gene and copper tolerance was noted. This gene was also found to be required for full virulence potential in the Galleria mellonella model, and to impact biofilm formation at 25 and 37 ÌŠC. In summary, three novel determinants associated with metal homeostasis have been identified, and a previously unknown association has been established between a well-characterized gene for a penicillin-binding protein and copper homeostasis. Functional Genomics of Heavy Metal Resistance in the Foodborne Pathogen Listeria monocytogenes. by Cameron Tyler Parsons A dissertation submitted to the Graduate Faculty of North Carolina State University in partial fulfillment of the requirements for the Degree of Doctor of Philosophy",2016,
A group LASSO-based method for robustly inferring gene regulatory networks from multiple time-course datasets,"BackgroundAs an abstract mapping of the gene regulations in the cell, gene regulatory network is important to both biological research study and practical applications. The reverse engineering of gene regulatory networks from microarray gene expression data is a challenging research problem in systems biology. With the development of biological technologies, multiple time-course gene expression datasets might be collected for a specific gene network under different circumstances. The inference of a gene regulatory network can be improved by integrating these multiple datasets. It is also known that gene expression data may be contaminated with large errors or outliers, which may affect the inference results.ResultsA novel method, Huber group LASSO, is proposed to infer the same underlying network topology from multiple time-course gene expression datasets as well as to take the robustness to large error or outliers into account. To solve the optimization problem involved in the proposed method, an efficient algorithm which combines the ideas of auxiliary function minimization and block descent is developed. A stability selection method is adapted to our method to find a network topology consisting of edges with scores. The proposed method is applied to both simulation datasets and real experimental datasets. It shows that Huber group LASSO outperforms the group LASSO in terms of both areas under receiver operating characteristic curves and areas under the precision-recall curves.ConclusionsThe convergence analysis of the algorithm theoretically shows that the sequence generated from the algorithm converges to the optimal solution of the problem. The simulation and real data examples demonstrate the effectiveness of the Huber group LASSO in integrating multiple time-course gene expression datasets and improving the resistance to large errors or outliers.",2014,BMC Systems Biology
A Spatio - Temporal Hedonic House Regression Model,"This work focuses on an algorithmic investigation of the housing market spanning 11 years using the hedonic pricing theory. An improved pricing model will benefit home buyers and sellers, real estate agents and appraisers, government and mortgage lenders. Hedonic pricing theory is an econometric concept that explains the market value of a differentiated commodity using implicit pricing. Exploiting the spatial dependent nature of the housing market, we created new submarkets. A model was built with the new submarket, while another one was built using the existing submarket. Random forest and LASSO were trained with the two models. We argue that our approach has a considerable impact on the dimension of a spatioâ€“temporal hedonic house pricing model without a significant reduction in its performance.",2017,2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)
ConstrucciÃ³ del nom propi i convenciÃ³ de les majÃºscules amb ulls d'infants,"Els objectius daquesta recerca son explorar el proces dapropiacio, per part dels infants, de lus de les majuscules en funcio demarcativa i distintiva i la relacio entre la majuscula dinici del nom personal i lapropiacio dels components de la categoria linguistica de nom propi.
La investigacio consta dun estudi psicolinguistic el qual es porta a terme mitjancant un conjunt de tasques per poder indagar com interpreten els infants participants els noms propis en tres situacions distintes: a) el reconeixement de noms propis amb la imatge present, en un conte en llengua catalana, (la llengua habitual) i en un conte en angles (llengua desconeguda) per poder detectar el proces evolutiu de reconeixement de les majuscules en els noms propis, b) lus de la majuscula en un text de produccio espontania per poder observar lus que els infants en fan espontaniament i les explicitacions dels infants participants i c) el desenvolupament dels components del nom propi, una conversa dialogada i estructurada sobre els components del nom propi personal ens forneix les dades pertinents.
Lanalisi dels resultats dels noms propis mostren que hi ha uns noms mes facils de reconeixer que daltres. Els infants als anys interpreten les grafies (minuscules i majuscules) emprant justificacions perceptives que no sempre coincideixen amb l convencio normativa, ja que relacionen lalcada dels trets ascendent i descendent de les grafies amb lalcada de lobjecte, fet que sol superar-se als 6 anys. Aixi mateix, interpreten els noms propis personals mitjancant justificacions perceptives, coincidint amb la interpretacio convencional de les grafies, fent-ne la segmentacio fonologica adequada. Els infants, a partir dels 6 anys, solen explicitar les normes dus convencional de les majuscules en els noms propis sense fer-ne lus apropiat.
El reconeixement de noms propis personals en un text en llengua anglesa mostra que identifiquen, en un inici, les dues funcions de les majuscules en una unica funcio: la majuscula en funcio distintiva que inicia els noms propis personals. Posteriorment, els infants reconeixen la doble funcionalitat de les majuscules i assenyalen la successio de noms propis personals per la majuscula i els signes de puntuacio propis de lenumeracio (la coma, els dos punts i el punt que tanca la frase).
El reconeixement de noms propis en un conte en llengua catalana ens mostra que els noms propis per excellencia son els noms propis personals. Pero els noms personals que pertanyen al doble ambit denominatiu (nom propi i nom comu) ofereixen dubtes de sentit, fet que sembla demostrar que la majuscula no es lunic aspecte que els fa decidir que un nom es un nom propi. A mes a mes, la mencio de la semblanca a un altre nom personal i les distintes interpretacions lexiques dalgunes paraules grafiques els fan interpretar paraules daltres categories com a nom propi. Els noms de toponims urbans i locals, aparentment, no resulten estranys pel nom en ell mateix, sino pel fet de no ser emprat en el context de comunicacio familiar i social, segons les respostes dels infants. Els noms comuns que son susceptibles de ser especificats amb un nom propi tambe requereixen un proces dapropiacio perque el nom propi sigui interpretat com a tal. Els adjectius proposats com a nom propi han estat acceptats i refusats tant en el text escrit com en el text oral.
Lus de la majuscula en funcio demarcativa es gairebe absent en la majoria de textos. Val a dir que sinicia en lescriptura de textos tant de la frase com del conte. En els inicis lus daquesta funcio desequilibra lus de la majuscula en funcio distintiva. De fet, la majuscula en funcio demarcativa requereix alguns coneixements de lorganitzacio del text: han de reconeixer linici del text i linici de la frase, i la possible relacio entre les frases que van organitzant laddicio de frases que formen el text. Lus de lapostrof produeix hiposegmentacio entre larticle de presentacio i el nom propi, larticle de presentacio en coincidir amb la majuscula en funcio demarcativa presenta dubtes de lus de la majuscula en els noms propis personals.
Els onze components indagats que formen la categoria de nom propi estan uns desenvolupats i daltres desenvolupant-se. Els desenvolupats als 5 anys son: designacio i permanencia i estabilitat; als 6 anys els anteriors mes el referent i als 7 anys els anteriors mes el nom propi pot tenir diferents posseidors, dos noms propis designen un mateix subjecte, larbitrarietat, la funcio danomenar i la didentificar. Els components que estan desenvolupant-se als 7 anys son els limits entre el nom comu i el nom propi, la relacio de simetria del nom propi i ladjectiu en qualitat de nom propi personal.
Com a conclusio podem dir que el proces dapropiacio de les majuscules en funcio distintiva es diferent que el de les majuscules en funcio demarcativa. Cada funcio de les majuscules requereix un tipus de coneixement textual. El proces dapropiacio dels elements que componen el nom propi es independent de lus de la majuscula en els noms propis.
Es constata que els processos dapropiacio dus de la majuscula en funcio distintiva estan relacionats amb les paraules que fan de referent del nom propi (el sentit lexic), amb els signes de puntuacio (coma, dos punts, punt i (apostrof) i amb la interpretacio de les grafies de lalfabet. Aixi mateix lus de la majuscula en funcio demarcativa es constata que requereix lassoliment de linici i lacabament de la frase i, per aixo, cal que estableixen relacions entre les frases.
La principal aportacio didactica es la constancia que els infants son sensibles a les caracteristiques grafiques de les grafies (els trets ascendents i descendents) i les utilitzen per justificar la distincio entre majuscules i minuscules. Es a partir daquests coneixements que shauria dorganitzar la intervencio didactica.
"" SUMMARY:
How do children adapt to the use of capital letters? This is the question under research; consisting of a psycholinguistic study by means of tasks of recognition of pairs of homograph names: the image and the nominal category (proper name and common name), recognition of proper names in a story in Catalan and in another in English and in spontaneous production, and recognition of the components of the linguistic category of the proper name.
Analysis of the results of proper names shows that some names are more easily recognised than others. The 5-year-olds taking part interpret the graphemes by means of perceptive justifications, relating the height of the grapheme with that of the object.
Recognition of personal proper names in the English text shows that they notice the capital letter graphemes, but that, at first, they only recognise the distinctive function. Later, at 6 years, they recognise the dual function of the use of capitals and also the properties of punctuation signs with regard to lists.
The recognition of proper names in a story in Catalan shows us that the capital letter is the formal indicator noticed; however personal names belonging to the double denominative ambit (proper and common name) offer doubts in meaning. This also happens with place names and with adjectives, in both written and oral texts.
In their own productions the use of the capital letter with a defining function is absent in the majority of texts, in both sentences and in stories. At first the use of this function produces an imbalance with the use of the capital letter in its distinctive function; and the use of the apostrophe produces hypo-segmentation between the presenting article and the proper name.
We have found that the process of understanding of capital letters in the distinctive function is different from that for capital letters in the defining function, since each capital letter function requires a type of textual knowledge. The process of appropriating the elements composing the linguistic category of the proper name is independent of the use of capitals for proper names. """,2004,
Application of Machine Learning Techniques to High-Dimensional Clinical Data to Forecast Postoperative Complications,"OBJECTIVE
To compare performance of risk prediction models for forecasting postoperative sepsis and acute kidney injury.


DESIGN
Retrospective single center cohort study of adult surgical patients admitted between 2000 and 2010.


PATIENTS
50,318 adult patients undergoing major surgery.


MEASUREMENTS
We evaluated the performance of logistic regression, generalized additive models, naÃ¯ve Bayes and support vector machines for forecasting postoperative sepsis and acute kidney injury. We assessed the impact of feature reduction techniques on predictive performance. Model performance was determined using the area under the receiver operating characteristic curve, accuracy, and positive predicted value. The results were reported based on a 70/30 cross validation procedure where the data were randomly split into 70% used for training the model and the 30% for validation.


MAIN RESULTS
The areas under the receiver operating characteristic curve for different models ranged between 0.797 and 0.858 for acute kidney injury and between 0.757 and 0.909 for severe sepsis. Logistic regression, generalized additive model, and support vector machines had better performance compared to NaÃ¯ve Bayes model. Generalized additive models additionally accounted for non-linearity of continuous clinical variables as depicted in their risk patterns plots. Reducing the input feature space with LASSO had minimal effect on prediction performance, while feature extraction using principal component analysis improved performance of the models.


CONCLUSIONS
Generalized additive models and support vector machines had good performance as risk prediction model for postoperative sepsis and AKI. Feature extraction using principal component analysis improved the predictive performance of all models.",2016,PLoS ONE
A hybrid Bayesian-network proposition for forecasting the crude oil price,"This paper proposes a hybrid Bayesian Network (BN) method for short-term forecasting of crude oil prices. The method performed is a hybrid, based on both the aspects of classification of influencing factors as well as the regression of the out-of-sample values. For the sake of performance comparison, several other hybrid methods have also been devised using the methods of Markov Chain Monte Carlo (MCMC), Random Forest (RF), Support Vector Machine (SVM), neural networks (NNET) and generalized autoregressive conditional heteroskedasticity (GARCH). The hybrid methodology is primarily reliant upon constructing the crude oil price forecast from the summation of its Intrinsic Mode Functions (IMF) and its residue, extracted by an Empirical Mode Decomposition (EMD) of the original crude price signal. The Volatility Index (VIX) as well as the Implied Oil Volatility Index (OVX) has been considered among the influencing parameters of the crude price forecast. The final set of influencing parameters were selected as the whole set of significant contributors detected by the methods of Bayesian Network, Quantile Regression with Lasso penalty (QRL), Bayesian Lasso (BLasso) and the Bayesian Ridge Regression (BRR). The performance of the proposed hybrid-BN method is reported for the three crude price benchmarks: West Texas Intermediate, Brent Crude and the OPEC Reference Basket.",2019,Financial Innovation
Development of Grammatical Structures in Pre-Schocl,"Nurss, Joanne F.; Day, David E. Development of Grammatical Structures in Pre-Schocl Age Children. Mar 70 6p.; Paper presented at the Annual Meeting of the American Educational Research Association, Minneapolis, Minnesota, March, 1970 EDRS Price ME-$0.25 HC-$0.40 Comprehension, *Educational Experiments, Imitation, *Language Development, *Preschool Programs, *Program Evaluation, Socioeconomic Status, Validity The purpose of this study was to describe the level of language maturity and the effect of a preschool language program on the language development of urban, Southern 4-year-olds. The 147 subjects (57 lower status blacks, 40 lower status.wLitzs,-and 53 lippc?r status white) all participated in five-day per week prekindergarten programs. Dependent variables were measured by use of the Day Language Screen and the Brown, Fraser, Bellugi Test of Grammatical Contrasts. The Day Language Screen measures proficiency in certain receptive and expressive aspects of standard American English, while the Test of Grammatical Contrasts assesses ability to imitate, comprehend, and produce selected grammatical structures. Analysis of the Language Screen data revealed that, while no significant sex or sex-status-race interaction effects occurred, there were significant status-race effects on pretest, posttest, and gain scores. Upper class subjects had higher preand posttest scores, but lower class subjects of both races had larger gain scores. The upper class group scored significantly higher on all three tasks of the Test of Grammatical Contrasts, while, between the two lower class groups, the whites scored higher on the comprehension task, blacks on the imitation, and there was no significant difference on the production. (MH) Lr1 CX) Joanne R. Nurss David E. Day CN.1 Development of Grammatical Structures in Pre-School Age Children O tiC=5 The inter-relationship between the language development of children and success in school has been well documented. In addition, the wide variations in level of language maturity when children enter school are familiar to most educators. Little is known, however, of the differences in acquisition of grammatical structures in higher and lower status children. The purpose of this study was to describe the level of language maturity and the effect of pre-school education on the language growth of Southern urban four-year old boys and girls. The sample included higher status white, lower status white, and lower status black children. Two measures were obtained: the children-s proficiency in certain receptive and expressive aspects of standard American English as assessed by the Day Language Screen; and their ability to imitate, zomprehend, and produce selected grammatical structures as assessed by the Brown, Fraser, Bellugi Test of Grammatical Contrasts. U.S. DEPARTMENT OF HEALTH, EDUCATION & WELFARE OFFICE OF THIS DOCUMENT HAS BEEN EDUCATION REPRODUCED EXACTLY AS RECEIVED FROM THE PERSON OR ORGANIZATION ORIGINATING IT. POINTS OF VIEW OR OPINIONS STATED DO NOT NECES SA RILY REPRESENT OFFICIAL OFFICE OF EDU CATION POSITION OR POLICY AERA March, 1970 The 147 subjects were all enrolled in five-day per week pre-kindergarten IT414 programs. They represented higher and lower status groups, as defined by a modification of Warner's scale for ordering occupations of heads of households. rimq The children were divided into three status-race groups: 57 lower status CeD black, 40 lower status white, and 50 higher status white. The sample consisted of 83 boys and 64 girls with a mean chronological age of 51.8 months. 0 Presented at the 1970 American Educational Research Association convention at Minneapolis, Minnesota, March, 1970. The Day Language Screen is an individually administered instrument designed to assess both receptive and expressive facility with complete sentences, identity statements, singular/plural and negative forms, prepositions, polar opposites, and classofications. It contains 46 items, scored correct/incorrect. Each item makes use of small toys, colored cards, wooden shapes, or pictures of objects which the subject is asked either to identify, select, describe, or manipulate. Approximately 15 minutes are required to administer the screen. Using another group of 19 children, comparable to the sample in the present study, a test-retest reliability correlation coefficient of .81 was obtained for the Language Screen. With this same group of children, a correlation coefficient of .46 was obtained between the Language Screen and the Peabody Picture Vocabulary Test. The Language Screen was given to all three groups of subjects as a pretest during the fall of 1968 and as a post-test during the spring of 1969. In the intervening five-month period observations were made of the language program in each classroom. The results of the Language Screen were analyzed by three two-way analyses of variance assessing the effects of sex and status-race upon the pre-test, post-test, and gain scores. The results of these analyses are given in Table of the handout. No significant effects were found due to sex or to the interaction of sex with status-race. Significant effects due to status-race, however, were found for all three scores. Planned comparisons were made among the means and these comparisons are given in Table 2. The higher status white group obtained significantly higher preand post-test scores than either of the two lower status groups. However, both the lower status white and the lower status black gtoups obtained significantly larger gain scores than did the higher status white group. Gordon (1968) and John (1965) have reviewed many studies assessing the influence of socio-economic status on language. They have concluded that children from lower socio-economic level backgrounds tend to be less fluent and less proficient in their language development than their peers from higher socio-economic level backgrounds. The Language Screen scores for the present sample support this conclusion. The higher status white children gave evidence of significantly greater proficiency in the aspects of standard American English which were assessed by the screen. However, an important finding was the fact that both of the lower status groups gained significantly more on the Language Screen that did the higher status group. A language development program was used in the pre-kindergarten classes attended by these children. It was designed to improve their proficiency in several aspects of standard American English, including mastery of plural subjects and verbs, comparative adjectives, past tense of verbs, opposites, negative forms, and prepositions. The significant gains which these children made may be attributed, in part, to this formal language program. The higher status white group's smaller gain over the year is probably a result of their continued language development rather than any direct language instruction in their schools. In fact, the language program in their classes was much more informal and less direct than that in the lower status children's classes. The Brown, Fraser, Bellugi Test of Grammatical Contrasts was also administered to all subjects during the winter of 1969. This test measures the ability to imitate, comprehend, and produce selected grammatical structures. It has two equivalent forms each of which contains two pairs of sentences for each of the 12 grammatical contrasts. The contrasts assessed include number, tense, voice, negation, mass nouns, indirect objects, prepositions, and adjectives in two positions. Each sentence is illustrated by a picture. For the comprehension task, the subject points to the picture which illustrates the sentence just read. For the imitation task, no picutres are shown, but the subject repeats the sentence which the examiner has just read. For the production task, the examiner ""names"" the two pictures and then asks the subject to ""name"" first one and then the other. Form A was used for the imitation task for all subjects. One-half of the subjects were given Form A for the comprehension task and Form L for the production task. The forms were reversed for the other half of the subjects. The three tasks were presented in cach of the six possible orders, une to every sixth subject. the 48 items on each task were scored correct/incorrect using a modification of the scoring procedure given by Fraser, Bellugi and Brown (1963). They give no reliability or validity data, but they do indicate 99% agreement among scorers. This test was also given to the subjects individually, taking approximately 15 minutes to administer. A series of one-way analyses of variance were performed to determine the effects of status-race upon the children's performance on the three tasks of this test: imitation, comprehension, and production. The results of these analyses are given in Table 3 of the handout. Significant main effects due to status -race were obtained for all three tasks. Tests of planned comparisons were then made in order to locate the source of these significant effects. These comparisons are given in Table 4. The higher status white group performed significantly better than both of the lower status groups on all three tasks. The lower status white group performed significantly better than the lower status black group on comprehension. In contrast, the lower status black group scored significantly higher than the lower status white group on imitation. There was no significant difference between the scores of the two lower status groups on production. t-tests were computed between the mean scores on the three tasks for the total group and for the three status-race groups. The results of these tests are given in Table 5. In each case the children scored significantly better on both the imitation and comprehension tasks than they did on the production task. Thera was no significant difference between the imitation and comprehension tasks in the higher status white and the",2011,
"Voluntary associations in a metropolis : the case of Lagos, Nigeria","Voluntary associations are significant mechanisms by which migrants can be integrated into a new urban milieu, yet not all individuals or sectors of city populations belong to them. While it is widely accepted that associations have a role to play in urban west Africa by offering welfare services (Little, 1965), providing political outlets in the broad sense of that term (Wallerstein, 1966), or defining status (Eisenstadt, 1956), little is known about the configurations of membership (but see Meillassoux, 1968). In order to understand more fully the part that voluntary associations play in the lives of city dwellers it is still necessary to ask fundamental questions. For example: 1) What percentages of urban populations actually belong to, and are active in, voluntary associations? 2) What kinds of voluntary associations are preferred? 3) Who belongs to what kinds of associations? In other words we still need to know to whom voluntary associations are important and to whom they are relatively unimportant. This essay addresses itself to these questions by examining voluntary association behavior among residents of one suburban neighborhood of Lagos, Nigeria. In so doing it argues that membership varies substantially according to ethnicity and sex. Yoruba and Ibo-speaking residents are known for their high level of participation in several types of voluntary associations, yet Hausa-speaking residents rarely join any but religious groups. The same contrast can be made between men and women, whose membership preferences are not necessarily similar. Examination of the variables of sex and ethnicity, therefore, begins to provide membership profiles of the various types of associations, but these factors do not stand alone.",1975,African Studies Review
Onbegrepen hoeken in de Nederlanden en overzee. De zoektocht naar het ideaal in de zestiende-eeuwse vestingbouw,"The notion of a â€˜homogeneity of styleâ€™ in the historiography of military architecture carries the risk that those forms that are not directly traceable in modern historiography are too easily dismissed as out of bound or simply as the results of external factors. This article is about fortifications that stand out because the walls between the bastions are not straight but concave. An essay by Renty and Philippeville about structures along the Habsburg-French border and the Portuguese overseas fortifications at Mazagao in Morocco and the Sao Sebastiao fortress in Mozambique demonstrates that this is a recurring element in the ground plans of various sixteenth-century strongholds. The external factors to which this phenomenon has sometimes been ascribed are not convincing in any of these cases, which is why the need for a theoretical foundation arose. An analysis of contemporary treatises on architecture reveals that the concept was discussed and even propagated as an ideal defense system by various theorists, in different variations. Niccolo Tartaglia appears to have been the first author who wrote about the idea of providing covering fire from both the bastions and from inward bending walls. In his treatise Quesiti et inventioni diverse , first published in Venice in 1546, he criticized the traditional square ground plan of fortresses because, in his view, it did not offer the ideal cover and was too vulnerable. The two publications that most extensively discussed alternative concepts were the works by Jacomo Fusto Castriotto Galasso and Alghisi da Carpi, which were published in 1564 and 1570, respectively. Using concave curtain walls can be understood as an attempt to combine the advantages of the tenaille and bastion systems. In particular around the middle of the sixteenth century, when assailants would aim their cannon fire more at the bastions instead of at the well-covered curtain walls, the need for extra cover for the faces arose. Whereas Alghisiâ€™s work remained highly theoretical, Castriottoâ€™s suggestions are of a more pragmatic nature. He referred, for instance, to the fortress at Mazagao, demonstrating how this exceptional ground plan related to theories about building fortifications. The current analysis shows how the bastion system was constantly discussed and refined and how authors of treatises and engineers arrived at different designs. By comparing forms and searching for theoretical foundations, hitherto misunderstood angles can now be explained.",2014,
Prediction of overall survival time in patients with colon adenocarcinoma using DNA methylation profiling of long non-coding RNAs,"Long non-coding RNAs (lncRNAs) are a subgroup of RNAs able to regulate gene expression at the epigenetic level, and are therefore central to the regulation of numerous biological processes and the progression of multiple cancer types. However, lncRNAs have not been identified to considerably influence overall survival (OS) outcome in numerous different types of cancer. The majority of studies investigating the association between lncRNAs and epigenetic regulation have focused on their altered expression levels in cancerous cells, and few studies have focused on determining the correlation between lncRNAs and OS time. In the present study, comprehensive lncRNA expression analysis was performed on a cohort of patients diagnosed with colon adenocarcinoma (COAD) using the least absolute shrinkage and selection operator method (LASSO). Subsequently, the construction of a prognostic methylation-based predictive system was performed based on the results of LASSO analysis. Functional enrichment analysis of lncRNA co-expression genes was also performed. According to the results of the present study, the classifier was able to significantly predict the prognosis of patients with COAD, and the investigation of the relevant elucidated genes further revealed the mechanism of COAD pathogenesis.",2020,Oncology Letters
New Paleobotanical Data on Origin and Early Evolution of Angiospermy,"The author's contributions to the problem of angiosperm origin since 1975 are summarized. Jurassic Hirmerella is assigned to proangiosperms based on its fruit-like diaspores. Achenes with persistent receptacles bearing long trusses of hairs came from the Lower Cretaceous of Lake Baikal province. They resemble cyperaceous achenes but could have arisen from bennettitalean ovulate receptacles by reduction of ovules to one and fusion of interseminal scales. Angiosperm fruits, grass-like leaves, and several kinds of spikes and spiked heads are found in the Lower Cretaceous of Mongolia. A middle Albian fructification from Kazakhstan with bitegmic ovules is related to Ranunculidae. Some minor findings are mentioned in discussion. The ""spotted layer"" of Caytonia is interpreted as inner integument. Mesegenous stomata and incipient vessel members are revealed in bennettites. Possible links of proangiospermous Caytonia, Dirhopalostachys, and Leptostrobus with angiosperms are indicated. I have reported on proangiosperms-a rather loose group, comprising Caytonia, Leptostrobus, and Dirhopalostachys which, together with some other plants, such as bennettites, formally not included in the group, provided a ""character pool"" for arising angiosperms (Krassilov, 1 977a). Since then another proangiosperm plant, supposedly of bennettitalean affinity, was found in Baisa, Lake Baikal province. Early Cretaceous angiosperms and angiosperm-like plants were found in Mongolia. Some Albian angiosperm fructifications from Kazakhstan have been restudied (Vakhrameev & Krassilov, 1979). Some new data on Hirmerella, Caytonia, and bennettites are also, I believe, relevant to the problem of angiosperm ancestry. These results and their implications are discussed below. ""OVULIFEROUS SCALES"" OF HIRMERELLA This name is applied to ovulate cones of a Jurassic plant that produced pollen grains of Classopollis type. Classopollis shows some angiosperm-like features (columellate ectexine, striated belt) comparable with equatorial harmomegathus of Nymphaea. Ovulate organs of this genus also have angiosperm-like features. Hirmerella dispersed rather bulky winged bodies conventionally described as seed scales. However, seeds occurred not on, but within these bodies, which are fruits rather than scales. Harris (1979) found two megaspore membranes within the ""scales"" and I found two overlapping nucelli in a ""scale"" from the Lower Jurassic of Poland (courtesy of Dr. Maria Reymanowna, Krakow and Dr. Maya Doludenko, Moscow). My interpretation is that there were two ovules per fruit, closely packed and filling a locule. In both British and Polish fruits there were cuticles of the locule adnate to integumental cuticles (Fig. 1). If the ovules were merely embedded in the ""scales"" there would be no internal cuticle lining the locule. A lot of pollen grains stick to the papillate surface of the ""scales,"" but none have been observed within the nucelli, which had inconspicuous beaks. Hirmerella radically differs from all known conifers and is perhaps closer to Ephedra, which sometimes show two ovules per cupule (Mehra, 1950). Based on its fruit-like diaspores, Hirmerella can be included in proangiosperms. It may represent an extinct order of gnetophytes.",1984,Annals of the Missouri Botanical Garden
Smartphone-Assessed Movement Predicts Music Properties: Towards Integrating Embodied Music Cognition into Music Recommender Services via Accelerometer Motion Data,"Numerous studies have shown a close relationship between movement and music [7], [17], [11], [14], [16], [3], [8]. That is why Leman calls for new mediation technologies to query music in a corporeal way [9]. Thus, the goal of the presented study was to explore how movement captured by smartphone accelerometer data can be related to musical properties. Participants (N = 23, mean age = 34.6 yrs, SD = 13.7 yrs, 13 females, 10 males) moved a smartphone to 15 musical stimuli of 20s length presented in random order. Motion features related to tempo, smoothness, size, regularity, and direction were extracted from accelerometer data to predict the musical qualities ""rhythmicity"", ""pitch level + range"" and ""complexity"" assessed by three music experts. Motion features selected by a 20-fold lasso predicted the musical properties to the following degrees ""rhythmicity"" (R2: .47), pitch level and range (R2: .03) and complexity (R2: .10). As a consequence, we conclude that music properties can be predicted from the movement it evoked, and that an embodied approach to Music Information Retrieval is feasible.",2018,Proceedings of the 5th International Conference on Movement and Computing
European mergers and merger policy,"Mergers and economic performance in the UK - a survey of the empirical evidence 1950-1990, Alan Hughes the market for corporate control - divestments and buy-outs, Mike Wright et al shareholder wealth effects of UK take-overs - implications for merger policy, Julian Franks and Robert Harris European capital markets and corporate control, Julian Franks and Colin Mayer corporate governance, take-overs and the role of the non-executive director, Evan Davis and John Kay the empirical analysis of market structure and performance, James Fairburn and Paul Geroski the evolution of merger policy in Britain, James Fairburn free trade in companies - does nationality matter?, Leslie Hannah European or national? - the Community's new merger regulation, Matthew Bishop recent patterns of European merger activity, Paul Geroski and Anastassios Vlassopoulos continental mergers are different, Evan Davis et al. Appendix: the Commission's merger reports.",1993,
Quick Review: Laryngomalacia & Asthma,"One of the most common causes of Stridor in children. LM is a congenital deformity (the most common congenital larngeal abnormality) causing laxity of the epiglottis and supraglottic aperture with an accompanying weakness of the tracheal wall. This leads to varying degrees of airway collapse during inspiration. Males are affected twice as often as females. LARYNGOMALACIA (LM) One of the most common causes of Stridor in children. LM is a congenital deformity (the most common congenital larngeal abnormality) causing laxity of the epiglottis and supraglottic aperture with an accompanying weakness of the tracheal wall. This leads to varying degrees of airway collapse during inspiration. Males are affected twice as often as females. Clinically, LM presents as noisy, harsh inspiratory sounds that may not be very evident during the first 1 2 months of life (given that this type of breathing is very common in the first few months of life). The symptoms can be intermittent but become worse when the baby lies on his or her back. The symptoms can range from noisy breathing, â€œcrowingâ€, hoarseness, dyspnea, and inspiratory retractions (in the supraclavicular, intercostal, or subcostal spaces). Patients with severe forms can have difficulty in nursing to result in general malnutrition and poor weight gain; the weight gain was not a problem with our pt given his premature birth and the â€œcatching upâ€ that he has done since. The stridor should, classically, slowly disappear as the child grows and develops; with normal maturation, the airway stiffens to take up the â€œextra slackâ€ in the folds. LM DIAGNOSIS Established by direct laryngoscopy. Differential diagnosis should include malformations of the laryngeal cartilage or vocal cords, intraluminal webs, generalized severe chondromalacia of the larynx and trachea, tumors of the larynx, mucus retention cysts, thyroglossal duct cysts amongst others. LM PROGNOSIS Fairly good for this condition with the far majority of cases resolving completely by the age of 18 months. However, there may be some degree of inspiratory obstruction that persists but treatment is usually not required. LM TREATMENT Primarily involves supportive therapy and parental reassurance because this condition resolves spontaneously. Feedings should be slow and careful with attention to possible aspiration. Most infants seem more comfortable and â€œless noisyâ€ in a prone position. Severe forms may require intubation but tracheostomy is rare. ASTHMA A discussion of a disorder must begin with a definition of that condition; however, with Asthma there is no universally accepted definition ! Asthma may be considered as a â€œdiffuse, obstructive lung disease with (1) hyperactivity of the airways to a variety of stimuli and (2) a high degree of reversibility of the obstructive process, which may occur Quick Review: Laryngomalacia & Asthma 2 of 4 either spontaneously or as a result of treatment.â€. This disease carries a variety of other names, including: Reactive Airway Disease, â€œWheezy Bronchitisâ€, â€œViralassociated wheezingâ€, and â€œAtopic related Asthmaâ€, and â€œChronic Desquamating Eosinophilic Bronchitisâ€. On a more-basic level, the pathophysiology involves two components: Bronchoconstriction;",2001,The Internet Journal of Dermatology
A Note on Machine Learning Methods,"1 Ptolemyâ€™s Epicycle and Gauss Paradigm 4 1.1 The model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2 Boosting machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.3 Lasso, ridge and kernel machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.4 Neural network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.5 Model complexity and regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.6 Ptolemy or Newton? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.7 Eulerâ€™s linear model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.8 Laplaceâ€™s estimating equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.9 Gauss paradigm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.10 Continuing Gauss paradigm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.11 Three modes of learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9",2019,
Carbon and Nitrogen Distribution in Aggregates from Cultivated and Native Grassland Soils,"Long-term cultivation of grassland soils reduces soil organic C and N content and has been associated with a deterioration in the aggregate structure of the soil. This study examined the effects of bare fallow (moldboard plow), stubble mulch fallow (subtill), and no-till fallow management on aggregate size distribution and aggregate organic C and N contents compared with a native (virgin) grassland soil. Aggregate size fractions were separated by wet sieving and the proportion of soil was quantified for each aggregate size class. Mineralassociated (silt and clay) organic matter was isolated by dispersing aggregates in sodium hexametaphosphate and removing the sand and particulate organic matter (POM) by passing the dispersed aggregates through a 53-/un sieve. The POM fraction is composed primarily of partially decomposed root fragments and has an average C/N ratio of about 16. A large proportion of the total soil dry weight (50-60%) was isolated in the small macroaggregate (250-2000 fan) size class. The native grassland soil was more stable than the cultivated soils when slaked, and the no-till soil was more stable than the stubble mulch and bare fallow soil when slaked. Reduced tillage management is effective at increasing the proportion of macroaggregates and results in the accumulation of wheat (Triticum aestivum L.) derived POM within the aggregate structure compared with bare fallow soil. It has previously been shown that the POM fraction accounts for the majority of the soil organic matter (SOM) initially lost as a result of cultivation of grassland soils. The data reported in this study relates the loss of structural stability from cultivation to losses of organic C and N from the POM fraction. N GRASSLAND SOILS are generally highly structured and rich in SOM. Cultivation reduces SOM content (Jenny, 1941; Haas et al., 1957) and results in a deterioration of the aggregate structure (Chancy and Swift, 1984). The POM fraction, which is composed primarily of partially decomposed root fragments, accounts for the majority of the SOM initially lost as a result of cultivation of grassland soils (Cambardella and Elliott, 1992). Reductions in aggregate stability after cultivation are most pronounced in soil macroaggregates, while the stability of soil microaggregates remains unchanged (Tisdall and Oades, 1982; Oades, 1984). As macroaggregates disintegrate with tillage, the proportion of microaggregates increases, since microaggregates are not destroyed by cultivation (Tisdall and Oades, 1980; Elliott, 1986). Microaggregates have a lower organic matter concentration than macroaggregates (Dormaar, 1983) and this organic matter is less labile than that associated with macroaggregates (Elliott, 1986; Gupta and Germida, 1988). The disintegration of macroaggregates with cultivation into nutrient-poor microaggregates and the subsequent release of plant-available nutrients may be one explanation for the observed pattern of lower orC.A. Cambardella, USDA-ARS, National Soil Tilth Lab., 2150 Pammel Drive, Ames, IA 50011; and E.T. Elliott, Natural Resource Ecology Lab., Colorado State Univ., Fort Collins, CO 80523. Received 30 June 1992. ""Corresponding author. Published in Soil Sci. Soc. Am. J. 57:1071-1076 (1993). ganic matter contents and reduced nutrient-supplying efficiencies in cultivated soils when compared with grassland soils (Elliott, 1986). Sustainable production has become a key issue in the management of cropping systems. Reduced tillage and no-till management have been initiated to mitigate some of the detrimental effects of intensive cultivation, such as reduction of soil organic matter and the concomitant increase in erosion and decrease in soil fertility (Fenster and Peterson, 1979). Little information exists in the literature on the effect of reduced tillage or no-till management on the nutrient contents of soil aggregates and their associated organic matter. This study examined the effects of bare fallow (moldboard plow), stubble mulch fallow (subtill), and notill management on aggregate size distributions and aggregate organic C and N contents compared with native grassland. MATERIALS AND METHODS",1993,Soil Science Society of America Journal
Risk classification in high dimensional survival models,"Sparse regression models are an actively burgeoning area of statistical learning research. A subset of these models seek to separate out significant and non-trivial main effects from noise effects within the regression framework (yielding so-called â€œsparseâ€ coefficient estimates, where many estimated effects are zero) by imposing penalty terms on a likelihood-based estimator. As this area of the field is relatively recent, many published techniques have not yet been investigated under a wide range of applications. Our goal is to fit several penalty-based estimators for the Cox semiparametric survival model in the context of genomic covariates on breast cancer survival data where there are potentially many more covariates than observations. We use the elastic net family of estimators, special cases of which are the LASSO and ridge regression. Simultaneously, we aim to investigate whether the finer resolution of next-generation genetic sequencing techniques adds improved predictive power to the breast cancer patient survival models. Models are compared using estimates of concordance, namely the c-statistic and a variant which we refer to as Unoâ€™s C. We find that ridge regression models best fit our dataset. Concordance estimates suggest finer resolution genetic covariates improve model predictions, though further work with more observations is required.",2016,
Machine Learning Approach for Data Analysis of Magnetic Orbital Moments and Magnetocrystalline Anisotropy in Transition-Metal Thin Films on MgO(001),"Using the Least Absolute Shrinkage and Selection Operator (LASSO) technique, we analyze a long-standing issue in the field of magnetism: the relationship between orbital magnetic moments and magnetocrystalline anisotropy (MCA) energy in transition-metal thin films. Our LASSO regression utilizes the data obtained from first principles calculations for single slabs with six atomic-layers of binary Au-Fe, Au-Co, and Fe-Co films on MgO(001). In the case of Fe-Co thin films, we have successfully regressed the MCA energy against the anisotropy of orbital moments along the in-plane and the perpendicular plane directions, giving a linear behavior. For the Au-Fe and Au-Co thin films, however, our data-driven analysis shows no relation between the MCA energy and the anisotropy of orbital moments.",2018,Journal of Electronic Materials
Ãœber katalytische einflÃ¼sse bei der polykondensation des p-kresoldialkohols,"Wird natriumfreier p-Kresoldialkohol in Silber- oder Platingeraten bei 130Â°C kondensiert, so ist durch den Geruch kein Formaldehyd wahrnehmbar. 
 
 
 
p-Kresoldialkohol enthalt oft von seiner Darstellung uber das Natriumsalz her geringe Mengen an Natrium, dessen Anteil im Bereich von 0,0 bis 5,00/00 liegt (0,000 bis 0,037 Mol Natrium je Mol Phenolalkohol). 
 
 
 
Die bei der Hartung des p-Kresoldialkohols in Platin- oder Silbergeraten beobachteten Gewichtsverluste und die Formaldehydabspaltung sind umso hoher, je groser der Natriumgehalt ist. 
 
 
 
Natriumfreier p-Kresoldialkohol in Gefasen aus Jenaer Gerateglas 20 und aus gewohnlichem Glas gehartet zeigt in Ubereinstimmung mit der Abgabefahigkeit an Alkali der letzteren Glassorte neben groserem Gewichtsverlust auch grosere Formaldehydabspaltung. 
 
 
 
In Quarzgefasen zeigt auch natriumfreier p-Kresoldialkohol bei 130Â°C schwachen Formaldehydverlust und grosere Gewichtsverluste als bei der entsprechenden Kondensation in Geraten aus Jenaer Gerateglas 20. 
 
 
 
Schlieslich zeigen Hartungen unter Luft gegenuber Kondensationen unter Stickstoff bei sonst gleichen Bedingungen einen beschleunigten Verlauf. 
 
 
 
p-cresol dialcohol, which is free from sodium and is condensed in silver or platinum vessels at 130Â°C, looses no formaldehyde perceptible by smell. 
 
 
 
Often p-cresol dialcohol contains sodium in small amounts as a result of its preparation via its sodium salt. The proportion of sodium is within the range of 0.0 to 5.00/00 (0.000 to 0.037 mole pro mole phenol alcohol). 
 
 
 
The loss of weight and formaldehyde during the condensation of p-cresol dialcohol in platinum and silver vessels increases with the proportion of sodium. 
 
 
 
p-cresol dialcohol, free from sodium and hardened in Jena glass (Jenaer Gerateglas 20) and common glass, has a greater loss of weight and a greater loss of formaldehyde corresponding to the capacity of the glass to loose alkali. 
 
 
 
At 130Â°C p-cresol dialcohol, free of sodium and hardened in quartz, shows also a weak loss of formaldehyde and a greater loss of weight than in Jena glass. The sodium of the preparation has different effect on the course of the reaction curves. 
 
 
 
Finally the hardening is accelerated in air in opposition to the condensation in nitrogen the conditions being otherwise the same.",1952,Macromolecular Chemistry and Physics
IDENT: Identifying Differential Equations with Numerical Time evolution,"Identifying unknown differential equations from a given set of discrete time dependent data is a challenging problem. A small amount of noise can make the recovery unstable, and nonlinearity and differential equations with varying coefficients add complexity to the problem. We assume that the governing partial differential equation (PDE) is a linear combination of a subset of a prescribed dictionary containing different differential terms, and the objective of this paper is to find the correct coefficients. 
We propose a new direction based on the fundamental idea of convergence analysis of numerical PDE schemes. We utilize Lasso for efficiency, and a performance guarantee is established based on an incoherence property. The main contribution is to validate and correct the results by Time Evolution Error (TEE). The new algorithm, called Identifying Differential Equations with Numerical Time evolution (IDENT), is explored for data with non-periodic boundary conditions, noisy data and PDEs with varying coefficients. From the recovery analysis of Lasso, we propose a new definition of Noise-to-Signal ratio, which better represents the level of noise in the case of PDE identification. We systematically analyze the effects of data generations and downsampling, and propose an order preserving denoising method called Least-Squares Moving Average (LSMA), to preprocess the given data. For the identification of PDEs with varying coefficients, we propose to add Base Element Expansion (BEE) to aide the computation. Various numerical experiments from basic tests to noisy data, downsampling effects and varying coefficients are presented.",2019,arXiv: Numerical Analysis
Bayesian model combining linkage and linkage disequilibrium analysis for low density-based genomic selection in animal breeding,"ABSTRACTWe combined linkage (LA) and linkage disequilibrium (LDA) analyses (emerging the term â€˜LALDAâ€™) for genomic selection (GS) purposes. The models were fitted to a simulated dataset and to a real data of feed conversion ratio in pigs. Firstly, the significant QTLs (quantitative trait locus) were identified through LA-based mixed models considering the QTL-genotypes as random effects by means of genotypic identity by descent matrix. This matrix was calculated at the positions of significant QTLs (based on LA) allowing to include the QTL-genotype effects additionally to SNP (single nucleotide polymorphism) markers (based on LDA) and additive polygenic effects in several GS models (Bayesian Ridge Regression â€“ BRR; Bayes A â€“ BA; Bayes B â€“ BB; Bayes C â€“ BC and Bayesian LASSOÂ â€“ BL). These models combing all mentioned effects were denominated LALDA. Goodness-of-fit and predictive ability analyses were performed to evaluate the efficiency of these models. For the real data, although slightly, the superiority ...",2018,Journal of Applied Animal Research
Fused estimation of sparse connectivity patterns from rest fMRI,"Functional magnetic resonance imaging (fMRI) is a powerful tool to analyze brain development and neuronal activity. Identifying discriminative brain regions between various groups within a population has generated great interest in recent years. In this work, we consider the problem of estimating multiple sparse, co-activated brain regions from fMRI observations belonging to different classes. More precisely, we propose a method to analyze functional connectivity differences between children and young adults. Often, analysis is conducted on each class separately. Here, we propose to rely on a generalized fused Lasso penalty to extract both class-specific and shared co-expressed regions. In order to validate our method, experiments are performed on an fMRI dataset comprised of normally developing children from 8 to 21. The results demonstrate that the proposed method is able to properly extract meaningful sub-networks, which results in improved classification accuracy between the two classes.",2017,"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
A genomic-clinical nomogram predicting recurrence-free survival for patients diagnosed with hepatocellular carcinoma,"Liver resection surgery is the most commonly used treatment strategy for patients diagnosed with hepatocellular carcinoma (HCC). However, there is still a chance for recurrence in these patients despite the survival benefits of this procedure. This study aimed to explore recurrence-related genes (RRGs) and establish a genomic-clinical nomogram for predicting postoperative recurrence in HCC patients. A total of 123 differently expressed genes and three RRGs (PZP, SPP2, and PRC1) were identified from online databases via Cox regression and LASSO logistic regression analyses and a gene-based risk model containing RRGs was then established. The Harrell's concordance index (C-index), receiver operating characteristic (ROC) curves and calibration curves showed that the model performed well. Finally, a genomic-clinical nomogram incorporating the gene-based risk model, AJCC staging system, and Eastern Cooperative Oncology Group performance status was constructed to predict the 1-, 2-, and 3-year recurrence-free survival rates (RFS) for HCC patients. The C-index, ROC analysis, and decision curve analysis were good indicators of the nomogram's performance. In conclusion, we identified three reliable RRGs associated with the recurrence of cancer and constructed a nomogram that performed well in predicting RFS for HCC patients. These findings could enrich our understanding of the mechanisms for HCC recurrence, help surgeons predict patients' prognosis, and promote HCC treatment.",2019,PeerJ
Excess and Withdrawal: Critical Phenomenology and Speculative Realism,"This paper takes up the problem of correlationism from a phenomenological perspective. Speculative realists, such as Quentin Meillassoux and Graham Harman, seek to establish new forms of Continental realism largely because, in their view, phenomenology cannot adequately account for the real. To counter these claims, I will use what I call a â€œcritical phenomenological approachâ€, which critically delimits the real from the intentional relation, and thus makes possible a phenomenological theory of the real. This approach to realism establishes not only that the real is independent from the intentional relation but also that the intentional relation itself is contingent with regard to the real. Furthermore, it also shows that the human being is exposed to the real in an originary way that calls into question the adequacy of Meillassouxâ€™s and Harmanâ€™s forms of realism.",2018,
Methods of plant breeding in the genome era.,"Methods of genomic value prediction are reviewed. The majority of the methods are related to mixed model methodology, either explicitly or implicitly, by treating systematic environmental effects as fixed and quantitative trait locus (QTL) effects as random. Six different methods are reviewed, including least squares (LS), ridge regression, Bayesian shrinkage, least absolute shrinkage and selection operator (Lasso), empirical Bayes and partial least squares (PLS). The LS and PLS methods are non-Bayesian because they do not require probability distributions for the data. The PLS method is introduced as a special dimension reduction scheme to handle high-density marker information. Theory and methods of cross-validation are described. The leave-one-out cross-validation approach is recommended for model validation. A working example is used to demonstrate the utility of genome selection (GS) in barley. The data set contained 150 double haploid lines and 495 DNA markers covering the entire barley genome, with an average marker interval of 2Â·23 cM. Eight quantitative traits were included in the analysis. GS using the empirical Bayesian method showed high predictability of the markers for all eight traits with a mean accuracy of prediction of 0Â·70. With traditional marker-assisted selection (MAS), the average accuracy of prediction was 0Â·59, giving an average gain of GS over MAS of 0Â·11. This study provided strong evidence that GS using marker information alone can be an efficient tool for plant breeding.",2010,Genetics research
Sparse Volterra and Polynomial Regression Models: Recoverability and Estimation,"Volterra and polynomial regression models play a major role in nonlinear system identification and inference tasks. Exciting applications ranging from neuroscience to genome-wide association analysis build on these models with the additional requirement of parsimony. This requirement has high interpretative value, but unfortunately cannot be met by least-squares based or kernel regression methods. To this end, compressed sampling (CS) approaches, already successful in linear regression settings, can offer a viable alternative. The viability of CS for sparse Volterra and polynomial models is the core theme of this work. A common sparse regression task is initially posed for the two models. Building on (weighted) Lasso-based schemes, an adaptive RLS-type algorithm is developed for sparse polynomial regressions. The identifiability of polynomial models is critically challenged by dimensionality. However, following the CS principle, when these models are sparse, they could be recovered by far fewer measurements. To quantify the sufficient number of measurements for a given level of sparsity, restricted isometry properties (RIP) are investigated in commonly met polynomial regression settings, generalizing known results for their linear counterparts. The merits of the novel (weighted) adaptive CS algorithms to sparse polynomial modeling are verified through synthetic as well as real data tests for genotype-phenotype analysis.",2011,IEEE Transactions on Signal Processing
Sparse Contingency Tables and High-Dimensional Log-Linear Models for Alternative Splicing in Full-Length cDNA Libraries,"Human protein diversity is partly due to a process called alternative splicing which enables different exon/intron combinations arising from a single gene. We know that the prevalence of these combinations is development and tissue specific but we are far from understanding the mechanism of alternative splicing and what causes the spliceosome to produce an array of different proteins from the same genetic information in changing frequencies over time and different tissues. A first step in the understanding of this process is the statistical analysis of the exon interaction structure. If we know which exons interact with each other, we might be able to draw conclusions about the associated functional domains. At present, the most advanced molecular technique to investigate this issue is to generate large-scale single-gene transcriptome data, so-called full-length cDNA libraries. Not all theoretically possible exon/intron combinations can be observed in these libraries, both due to functional restrictions at the protein level as well as to the sheer number of possible combinations. Statistically this poses the challenge of learning interactions in sparse contingency tables. To this end, we develop methods to perform model selection and parameter estimation in high-dimensional log-linear models. These include Bayesian methods as well as penalization approaches which generalize to this context the Lasso algorithm. We compare these procedures in a simulation study and we apply the proposed methods to full-length cDNA libraries, yielding valuable insight into the biological process of alternative splicing.",2006,
Predicting Visual Acuity by Using Machine Learning in Patients Treated for Neovascular Age-Related Macular Degeneration.,"PURPOSE
To predict, by using machine learning, visual acuity (VA) at 3 and 12 months in patients with neovascular age-related macular degeneration (AMD) after initial upload of 3 anti-vascular endothelial growth factor (VEGF) injections.


DESIGN
Database study.


PARTICIPANTS
For the 3-month VA forecast, 653 patients (379 female) with 738 eyes and an average age of 74.1 years were included. The baseline VA before the first injection was 0.54 logarithm of the minimum angle of resolution (logMAR) (Â±0.39). A total of 456 of these patients (270 female, 508 eyes, average age: 74.2 years) had sufficient follow-up data to be included for a 12-month VA prediction. The baseline VA before the first injection was 0.56 logMAR (Â±0.42).


METHODS
Five different machine-learning algorithms (AdaBoost.R2, Gradient Boosting, Random Forests, Extremely Randomized Trees, and Lasso) were used to predict VA in patients with neovascular AMD after treatment with 3 anti-VEGF injections. Clinical data features came from a data warehouse (DW) containing electronic medical records (41 features, e.g., VA) and measurement features from OCT (124 features, e.g., central retinal thickness). The VA of patient eyes excluded from machine learning was predicted and compared with the ground truth, namely, the actual VA of these patients as recorded in the DW.


MAIN OUTCOME MEASURES
Difference in logMAR VA after 3 and 12 months upload phase between prediction and ground truth as defined.


RESULTS
For the 3-month VA forecast, the difference between the prediction and ground truth was between 0.11 logMAR (5.5 letters) mean absolute error (MAE)/0.14 logMAR (7 letters) root mean square error (RMSE) and 0.18 logMAR (9 letters) MAE/0.2 logMAR (10 letters) RMSE. For the 12-month VA forecast, the difference between the prediction and ground truth was between 0.16 logMAR (8 letters) MAE/0.2 logMAR (10 letters) RMSE and 0.22 logMAR (11 letters) MAE/0.26 logMAR (13 letters) RMSE. The best performing algorithm was the Lasso protocol.


CONCLUSIONS
Machine learning allowed VA to be predicted for 3 months with a comparable result to VA measurement reliability. For a forecast after 12 months of therapy, VA prediction may help to encourage patients adhering to intravitreal therapy.",2018,Ophthalmology
Differential co-expression analysis reveals early stage transcriptomic decoupling in alzheimerâ€™s disease,"Alzheimerâ€™s disease (AD) is one of the leading causes of death in the US and there is no validated drugs to stop, slow or prevent AD. Despite tremendous effort on biomarker discovery, existing findings are mostly individual biomarkers and provide limited insights into the transcriptomic decoupling underlying AD. We propose to explore the gene co-expression patterns in multiple AD stages, including cognitively normal (CN), early mild cognitive impairment (EMCI), late MCI and AD. We modified traiditonal joint graphical lasso to model our asusmption that the co-expression networks in consecutive disease stages are largely similar with critical differences. In addition, we performed subsequent network comparison analysis for identification of stage specific transcriptomic decoupling. We focused our analysis on top AD-enriched pathways. We observed that 419 edges in CN, 420 edges in EMCI, 381 edges in LMCI and 250 edges in AD were frequently estimated with non zero weights. With modified JGL, the weight of all estimated edges in CN, EMCI and LMCI are zero. In AD group, 299 edges were occasionally estimated to be nonzero and the average correlation between genes was 0.0023. For co-expression change during AD progression, there are 66 pairs of genes that demonstrated a continuously decreasing or increasing co-expression from CN to EMCI, LMCI and AD.The network level clustering coefficient remains stable from CN to LMCI and then decreases significantly when progressing to AD. When evaluating edge level differences, we identified eight gene modules with continuously decreasing or increasing co-expression patterns during AD progression. Five of them shows significant changes from CN to EMCI and thus have the potential to serve system biomarkers for early screening of AD. We employed a modified joint graphical lasso for estimation of co-expression networks for multiple stages of AD. Comparing with graphical lasso, our modified joint graphical lasso model accounts for the similarity in consecutive disease stages. Our results on real data set revealed five gene clusters with obvious co-expression pattern change from CN to EMCI, which could be used as potential system-level biomarkers for early screening of AD.",2020,BMC Medical Genomics
"Effective Use of Rice Husk Ash to Treat Highly Polluted Water: Case Study in the Dhalassori River, Bangladesh","Abstract. In Dhaka city the source of surface waters as like as Dhalassori, Sitalakha, Buriganga rivers are frequently deteriorating due to the discharging of heavily toxic wastes into the water by the various industries and factories. The major source of drinking water is the underground which is rapidly decreasing due to the frequent use. If quality of surface water like Dhalassori river is such that it is too difficult to treat the water for the drinking purpose then a catastrophe may happen one time because the people who are wasting this valuable source of water may not know that how much days they can survive without potable water. In this research it is successfully shown by through laboratory and statistical analysis that a bio adsorbent called Rice Husk Ash obtained from the burning of Rice husk has the COD removal efficiency 99.33 .3% ~ 99.99% and color removal efficiency of 99.96% with respect to the raw water of Dhalassori river if the factors influencing adsorption that is investigated for the Rice Husk Ash, can be properly maintained.Keywords: Wastes, Waste water. River, Pollution, Economical, Biosorbents, Bacteria, Rice husk ash, Biomass1. INTRODUCTIONThe River Dhalassori is the life line of the Dhaka city and flanked in its southern side. Unlike many other rivers in the world, the Dhalassori River is not only important for providing vital ecological function, but also for various other purposes such as drinking water supply, transportation, cleaning, washing, recreation, ground water recharge, flood control and also as a means of disposing wastes within the assimilation capacity of the river. The Dhalassori River receives wastewater and storm water along its course through many point sources such as sluice gates, city drains and effluent outfall of the Pagla Sewage Treatment Plant (PSTP). The study by Kamal (1996) and Magumdar (2005) have identified this particular sluice gate to be the most susceptible to discharge highly polluted wastewater from tanneries in Hazaribagh area along with municipal wastewater from the neighbouring areas of Katasur and Ramchandrapur klial.These are mostly located within very densely populated areas near the river like Islambagh, Shahidnagar and Kamrangir Char. Because of this scattered and unpredictable drainage pattern, the Dhalassori River basin has been subdivided into a number of wastewater and storm water drainage zones by previous studies in order to compute wastewater flow rates and pollution loadings (JICA 1991; Browder 1992; Kamal 1996; Rahman and Rana 1996).The major drainage channels (locally known as Klial) in the City are Dholai klial, Gerani khal, Segunbagicha klial and Begunbari klial, which collect catchment's runoff as well as wastewater and drain to the peripheral rivers. According to a recent estimate, about 70,000 tons of raw hides and skins are processed in these tanneries every year polluting the environment and the quantity of untanned solid wastes namely raw trimming, we lime fleshing, pelt trimming generated in these tanneries is estimated to be 28,000 tons. Statistics provided by various sources suggest that a big tannery of the Hazaribagh area releases 2,500 gallons of chemicals wastes each day, polluting the city's air in addition to contaminating the water of the river Dhalassori. (Ahmad et al.. 2009)Therefore, for the necessity of time and to save our future generation from a certain catastrophe, finding a highly sustainable treatment option for the Dhalassori river waste water is obvious. The technology used in this research is bio adsorption and the bio adsorbent used for the treatment is rice husk ash. An integrated approach has been taken in this study to characterize and to evaluate the efficiency of rice husk ash and to give the most cost effective solution for the treatment of Dhalassori river waste water. Treatment of Dhalassori river waste water by RHA under several treatment processes. To select the most effective treatment processes for the treatment of Dhalassori river waste water which is highly sustainable and economical in the context of Bangladesh. â€¦",2013,American academic & scholarly research journal
"PrÃ©valence et connaissances de lâ€™hypertension artÃ©rielle chez les personnes Ã¢gÃ©es: Ã©tude transversale menÃ©e Ã  Bobo-Dioulasso, Burkina Faso","This study aims to determine the prevalence of arterial hypertension (AH) in the elderly people as well as their knowledge of this disease. We conducted a cross-sectional, descriptive study in the town of Bobo-Dioulasso from October to November 2015 at the intervention sites of the Association of Medical Assistance to elderly people ""KAFOLI"". Patients aged 60 years and more, with or without hypertension, who wished to participate in the study were included. Subjects were considered to be hypertensive when they had systolic blood pressure â‰¥ 140 mmHg and/or diastolic blood pressure â‰¥90 mmHg or when they were under antihypertensive treatment. Socio-demographic and clinical data as well as the risk factors associated with the disease were collected. Knowledges on arterial hypertension were based on general knowledges about arterial hypertension as sources of information about it. A total of 88 subjects were included in this study. The study involved 56 women and 32 men (sexÂ ratio 0.57). The average age of patients was 71 years (IQR:66-76). The prevalence of arterial hypertension was 61,36% and it was associated with knowledges about AH and with alcohol consumption; 68.18 % of patients had knowledge of AH. The majority of them were followed up in firstlevel health care nursing centres (64,81%). This study highlighted a high prevalence of hypertension in elderly people living in Bobo-Dioulasso. The majority of these persons were aware of this disease. In the majority of cases follow-up was ensured by nursing staff. Keywords: Hypertension, elderly, Bobo-Dioulasso",2018,The Pan African Medical Journal
A descent method for least absolute deviation lasso problems,"Variable selection is an important method to analyze large quantity of data and extract useful information. Although least square regression is the most widely used scheme for its flexibility in obtaining explicit solutions, least absolute deviation (LAD) regression combined with lasso penalty becomes popular for its resistance to heavy-tailed errors in response variable, denoted as LAD-LASSO. In this paper, we consider the LAD-LASSO problem for variable selection. Based on a dynamic optimality condition of nonsmooth optimization problem, we develop a descent method to solve the nonsmooth optimization problem. Numerical experiments are conducted to confirm that the proposed method is more efficient than existing methods.",2019,Optimization Letters
Dictionary LASSO: Guaranteed Sparse Recovery under Linear Transformation,"We consider the following signal recovery problem: given a measurement matrix $\Phi\in \mathbb{R}^{n\times p}$ and a noisy observation vector $c\in \mathbb{R}^{n}$ constructed from $c = \Phi\theta^* + \epsilon$ where $\epsilon\in \mathbb{R}^{n}$ is the noise vector whose entries follow i.i.d. centered sub-Gaussian distribution, how to recover the signal $\theta^*$ if $D\theta^*$ is sparse {\rca under a linear transformation} $D\in\mathbb{R}^{m\times p}$? One natural method using convex optimization is to solve the following problem: $$\min_{\theta} {1\over 2}\|\Phi\theta - c\|^2 + \lambda\|D\theta\|_1.$$ This paper provides an upper bound of the estimate error and shows the consistency property of this method by assuming that the design matrix $\Phi$ is a Gaussian random matrix. Specifically, we show 1) in the noiseless case, if the condition number of $D$ is bounded and the measurement number $n\geq \Omega(s\log(p))$ where $s$ is the sparsity number, then the true solution can be recovered with high probability; and 2) in the noisy case, if the condition number of $D$ is bounded and the measurement increases faster than $s\log(p)$, that is, $s\log(p)=o(n)$, the estimate error converges to zero with probability 1 when $p$ and $s$ go to infinity. Our results are consistent with those for the special case $D=\bold{I}_{p\times p}$ (equivalently LASSO) and improve the existing analysis. The condition number of $D$ plays a critical role in our analysis. We consider the condition numbers in two cases including the fused LASSO and the random graph: the condition number in the fused LASSO case is bounded by a constant, while the condition number in the random graph case is bounded with high probability if $m\over p$ (i.e., $#text{edge}\over #text{vertex}$) is larger than a certain constant. Numerical simulations are consistent with our theoretical results.",2013,arXiv: Machine Learning
Development and Validation of Predictive Indices for a Continuous Outcome Using Gene Expression Profiles,"There have been relatively few publications using linear regression models to predict a continuous response based on microarray expression profiles. Standard linear regression methods are problematic when the number of predictor variables exceeds the number of cases. We have evaluated three linear regression algorithms that can be used for the prediction of a continuous response based on high dimensional gene expression data. The three algorithms are the least angle regression (LAR), the least absolute shrinkage and selection operator (LASSO), and the averaged linear regression method (ALM). All methods are tested using simulations based on a real gene expression dataset and analyses of two sets of real gene expression data and using an unbiased complete cross validation approach. Our results show that the LASSO algorithm often provides a model with somewhat lower prediction error than the LAR method, but both of them perform more efficiently than the ALM predictor. We have developed a plug-in for BRB-ArrayTools that implements the LAR and the LASSO algorithms with complete cross-validation.",2010,Cancer Informatics
In silico Prioritization of Transporterâ€“Drug Relationships From Drug Sensitivity Screens,"The interplay between drugs and cell metabolism is a key factor in determining both compound potency and toxicity. In particular, how and to what extent transmembrane transporters affect drug uptake and disposition is currently only partially understood. Most transporter proteins belong to two protein families: the ATP-Binding Cassette (ABC) transporter family, whose members are often involved in xenobiotic efflux and drug resistance, and the large and heterogeneous family of Solute carriers (SLCs). We recently argued that SLCs are collectively a rather neglected gene group, with most of its members still poorly characterized, and thus likely to include many yet-to-be-discovered associations with drugs. We searched publicly available resources and literature to define the currently known set of drugs transported by ABCs or SLCs, which involved ~500 drugs and more than 100 transporters. In order to extend this set, we then mined the largest publicly available pharmacogenomics dataset, which involves approximately 1000 molecularly annotated cancer cell lines and their response to 265 chemical compounds, and used regularized linear regression models (Elastic Net, LASSO) to predict drug responses based on SLC and ABC data (expression levels, SNVs, CNVs). The most predictive models included both known and previously unidentified associations between drugs and transporters. To our knowledge, this represents the first application of regularized linear regression to this set of genes, providing an extensive prioritization of potentially pharmacologically interesting interactions.",2018,Frontiers in Pharmacology
Sterol and Diterpenoid Production by Zooxanthellae in Coral Reefs: A Review,"AbstractMost shallow-water coelenterates, such as the hard corals, soft corals, and gorgonians, contain symbiotic algae, zooxanthellae, which are the nonmotile â€œvegetativeâ€ forms of dinoflagellates included in the genus Symbiodinium. The zooxanthellae play an important part in the nutrition and calcification of their hosts. They may also contribute defensive chemicals which assist the host in surviving predation and the intensive competition for space on coral reefs. The zooxanthellae contribute considerable organic matter to the sediments, some of which may serve as thalasso-biogeochemical markers. A wide variety of sterols are found in zooxanthellae. Some have been used as tracers to identify predators on coelenterates. The sterol patterns of zooxanthellae isolated from various hosts vary and indicate the occurrence of many different species of the genus Symbiodinium. The chemistry of the algal symbiont in the host differs from that of the motile form grown in axenic culture.",2013,Biological oceanography
The archaeological site of Sagalassos (Turkey): exploring the mysteries of the invisible layers using geophysical methods,"The archaeological site of Sagalassos is a very important settlement located in a magnificent mountain landscape, 7â€‰km north from a village named AÄŸlasun (province of Burdur, south-west Turkey). Since 1990, the University of Leuven (Belgium) has carried out an interdisciplinary archaeological research program that studies >1000 years of uninterrupted human occupation in Sagalassos, concerning all historical aspects of daily life from architecture, to trade and its mechanisms and environmental conditions. The ancient Roman city is covered by layers of eroded soil that has preserved many secrets waiting to be revealed. A geophysical campaign was planned along the south facing terraces of the mountain slopes to highlight the structure of the city that remains covered in soil. Site conditions (high slope, high grass, several obstacles) and the need to investigate to depths greater than 20â€‰m influenced the choice of geophysical methods; we chose to use both passive and active electrical resistivity tomography. Three different areas, labelled Area 1, Area 2 and Area 3, were investigated, with results revealing information about the location, depth, size and extent of buried archaeological features. Of particular interest is the presence of: (i) a deep depression in Area 1, thought to be a clay quarry; (ii) a number of tombs related to the Byzantine period in Area 2; and (iii) defensive walls in Area 3. The ancient Roman city of Sagalassos (Turkey) is covered by layers of eroded soil that have preserved many secrets waiting to be revealed. A geophysical campaign was planned to highlight the buried structure. Geophysics revealed evidence of a clay quarry, a number of tombs related to the Byzantine period and defensive walls.",2017,Exploration Geophysics
Pulp tooth ratio in the estimation of age: A study on mandibular premolars,"The aim of the study was to use Cameriereâ€™s radiographic method of age estimation 
using pulp/tooth ratio of mandibular premolars on a South Indian sample and derive 
population-specific equations for a more accurate estimation of age. This retrospective 
study was carried out using 150 digital orthopantomograms of patients (age between 20- 
70 years) of Indian origin from the records of our institution. Approval from the 
institutional ethics committee was obtained prior to commencing the study. The images of 
the orthopantomograms were recorded on computer files. Following the technique 
proposed by Cameriere et al. the radiographic images were saved as high resolution JPEG 
files and imported to Photoshop Image processing software and Image J (NIH USA). The 
focus of the study was the mandibular first and second premolar. A lasso tool was used to 
delineate the external perimeter of the tooth as well as the pulpal perimeter and two 
variables obtained. Linear regression equations were derived for predicting the age of the 
individuals separately for each gender. The pulp/tooth area ratio of mandibular premolar 
was seen to decrease significantly with age. Multiple regression equations were derived 
based on age as the dependent variable and the tooth/pulp ratios as predictors. Thus, the 
pulp/tooth ratio is a valuable method in the estimation of age of subjects of Indian origin.",2017,
Antibiotics prescribed to febrile under-five children outpatients in urban public health services in Burkina Faso,"Appropriate use of antibiotics remains critical for success in achieving MDG4. The aim of this study was to investigate antibiotics prescribing practices to febrile under-five children outpatients in urban public health services in a low income country. Methods: From March to April 2013, a cross-sectional epidemiological study of care facilities visit by under-five age, for febrile illness, was carried out in urban health services in Bobo-Dioulasso, Burkina Faso. Patient demographics, diagnoses and medications were recorded. We calculated for each diagnoses several indicators for antibiotics use. Results: Our study showed an over-prescription of antibiotics at the university teaching hospital (78.08%) and at the first level facilities (57.71%) for under-five outpatients for febrile illness. There was evidence of high antibiotic prescription in children with diarrhea (more than 9 on 10 at university teaching hospital of diarrhea cases and 60% at the first level facilities), in children with Upper respiratory tract infections (respectively 60% and 85.2% of cases at university teaching hospital and at the first level facilities) and in children with malaria (respectively 47.5% and 17.6% of cases at university teaching hospital and at the first level facilities). Overuse, misuse and inappropriately prescribed antibiotic coexisted in our results: at university teaching hospital 90.9% of diarrhea cases, 60% of URTI cases, 47.5% of malaria cases received antibiotic prescription; at first level heath care facilities 85.2% of URTI, 17.6% of malaria cases received an prescribed antibiotic and 11.8% of LRTI did not received a prescribed antibiotic. Developing countries have poor access to newer antibiotics and irrational antibiotics use remains a global problem. Overuse and misuse of antibiotics combat, rigorous infectious diseases diagnosis, antimicrobial resistance consequences education of users and health professionalâ€™s prescribers, and improved surveillance of antimicrobial resistance, must be strengthened.",2014,Health
Regularization and Model Selection with Categorical Covariates,"The challenge in regression problems with categorical covariates is the high number of parameters involved. Common regularization methods like the Lasso, which allow for selection of predictors, are typically designed for metric predictors. If independent variables are categorical, selection strategies should be based on modified penalties. For categorical predictor variables with many categories a useful strategy is to search for clusters of categories with similar effects. We focus on generalized linear models and present L 1-penalty approaches for factor selection and clustering of categories. The methods proposed are investigated in simulation studies and applied to a real world classification problem.",2013,
Treatment of childhood steroid-restistant nephrotic syndrome with pulse methylprednisolone and cyclophosphamide,"1. Robson WmLM, Leung AKCF, Woodman RC, Trevenen CL (1995) Anti-neutrophil cytoplasmic antibody associated glomerulonephritis in a patient with Down's syndrome. Pediatr Nephrol 9: 204205 2. Reznik VM, Griswold WR, Lemire JM, Mendoza SA (1995) Pulmonary hemorrhage in children with glomerulonephritis. Pediatr Nephrol 9:83-86 3. Falk RJ, Hogan S, Carey TS, Jennette C (1990) Clinical course of anti-neutrophil cytoplasmatic autoantibody-associated glomerulonephritis and systemic vasculitis. Ann Intern Med 113:656 4. Gross WL, Rasmussen N (1994) Treatment of Wegener's granulomatosis: the view from non-nephrologists. Nephrol Dial Transplant 9: 1219-1225 5. Zeier M, Z611er L, Weinreich T, Padberg-Wolf E, Andrassy K, Ritz E (1992) Severe hemorrhagic complications from infection with nephropathia epidemica strain of Hanta-virus. Clin Nephrol 4: 190-192 6. Niklasson S (1992) Haemorrhagic fever with renal syndrome, virological and epidemiological aspects. Pediatr Nephrol 6:201--204 7. Aberle DR, Gamsu G, Lynch D (1990) Thoracic manifestations of Wegener granulomatosis. Diagnosis and course. Radiology 174: 703 -709",2004,Pediatric Nephrology
Four new species of monhysterids (Nematoda: Monhysterida) from mangroves of the Mekong river estuaries of Vietnam,"Four new free-living nematode species of the order Monhysterida from Me Kong River estuaries of Vietnam are described. Thalassomonhystera tenuis sp. nov. resembles to Thalassomonhystera pusilla (Boucher, Heleouet, 1977) but differs from it by the high, isolated labial region, longer outer labial setae, shorter oesophagus, shorter spicules, absence of gubernaculumâ€™s dorso-caudal apophysis and presence of subterminal setae on the tip. Diplolaimelloides elegans sp. nov. resembles to Diplolaimelloides meyli Timm, 1961, but it differs in having longer and slender tail and vulva position located in more anterior body end. Sphaerotheristus supplementatus sp. nov. comes close to Sphaerotheristus parvus Gagarin, Nguyen Vu Thanh, 2006, it differs in having the longer and thinner body and papillae-shaped supplements in males. Terschellingia obesa sp. nov. similar to Terschellingia monohystera Wieser, Hopper 1967 and Terschellingia brevicaudata Ott, 1972, but it differs from T. monhystera in having shorter cephalic setae, others vulva position and absence of oesophagus basal bulb; it also differs from T. brevicaudata in having shorter body, shorter cephalic setae, shorter spicules and presence of one ovary.",2008,
A CpG-methylation-based assay to predict survival in clear cell renal cell carcinoma,"Clear cell renal cell carcinomas (ccRCCs) display divergent clinical behaviours. Molecular markers might improve risk stratification of ccRCC. Here we use, based on genome-wide CpG methylation profiling, a LASSO model to develop a five-CpG-based assay for ccRCC prognosis that can be used with formalin-fixed paraffin-embedded specimens. The five-CpG-based classifier was validated in three independent sets from China, United States and the Cancer Genome Atlas data set. The classifier predicts the overall survival of ccRCC patients (hazard ratio=2.96-4.82; P=3.9 Ã— 10(-6)-2.2 Ã— 10(-9)), independent of standard clinical prognostic factors. The five-CpG-based classifier successfully categorizes patients into high-risk and low-risk groups, with significant differences of clinical outcome in respective clinical stages and individual 'stage, size, grade and necrosis' scores. Moreover, methylation at the five CpGs correlates with expression of five genes: PITX1, FOXE3, TWF2, EHBP1L1 and RIN1. Our five-CpG-based classifier is a practical and reliable prognostic tool for ccRCC that can add prognostic value to the staging system.",2015,Nature Communications
Hypoglycaemia with tramadol,"Analysis of reports to the US FDAâ€™s Adverse Event Reporting System (FAERS) suggests ""a potential signal between hypoglycaemia and tramadol use in patients not taking diabetes medications and patients <4 years old"", according to study results reported in the Annals of Pharmacotherapy. The study found 605 reported cases of tramadolassociated hypoglycaemia, which was the strongest association with hypoglycaemia among medications with Î¼-opioid agonist properties. The number of cases increased over time, and although the fifth percentile of the Empirical Bayesian geometric mean distribution (EB05) was elevated at 1.590, this was not statistically significant (>2). There were 352 cases in patients also taking antidiabetes medications, but no signal was detected, as the fifth percentile of the logistic regression odds ratio [LR05] was 1.5631 (significant value >2) and the EB05 was 0.856. There were 253 cases in patients not taking antidiabetes medications, which resulted in a significant signal (EB05=2.256; LR05=2.2104). The authors note that ""the signal for hypoglycaemia in the database is likely masked because of the use of diabetic medications"". There were 10 cases in patients with renal impairment, but this was not significant (EB05=1.572; Interaction Signal Score [INTSS]=0.865). Age did not increase the odds of tramadol-associated hypoglycaemia overall (LR05=1.6425), but hypoglycaemia was more likely in patients 0â€“1 years of age (LR05=3.0240) or 2â€“4 years of age (LR05=2.6853). ""The results of our study suggest that the 3 subpopulations noted to have a predisposition for tramadol-associated hypoglycemia in the package insert â€”patients with renal insufficiency, increasing age, and/ or diabetesâ€”did not have an increased risk"", note the authors. They add that ""it is important to note that our findings do not indicate causality and require further epidemiological studies for confirmation in these subpopulations"".",2019,Reactions Weekly
"Three Essays on Model Selection, Modulation Estimators and Herd Behavior under Asymmetric Beliefs","This thesis is organized in three chapters. In the first two chapters, an econometric model selection procedure and a method to improve some existing estimators are proposed. In the third chapter, a theoretical microeconomic analysis of herd behavior is performed under a fairly new set of assumptions. In chapter one, a model selection procedure based on the Penalized Empirical Likelihood(PEL) technique is developed, and guidelines are provided for the extensionof the procedure to the setting of Generalized Empirical Likelihood (GEL). The procedurewas initially applied to linear models and was called ""Least Absolute Shrinkage and Selection Operator"" (LASSO). It was subsequently extended to Generalized Method of Moments models in, and we now extend it to Empirical Likelihood (EL)models. Its main advantage over classical methods is in the combination of model selection and model estimation into a single step, while improving the post-selection properties of the resulting estimators. This procedure is easy to implement, and it remains computationally feasible even in models with a large number of parameters. A simulation study is performed to compare the newly proposed procedure to someclassical methods such as AIC, BIC, and DT. The simulation results show a better performance of the new procedure. In chapter two, we define the modulation technique for the EL estimator modulation technique pertains to the class of methods generally known as ""shrinkage methods"".Shrinkage methods are frequently used to improve the properties, in particular smallsampleproperties, of existing estimators. In this paper, a general theoretical analysisof modulation estimators is developed for EL models, along with a discussion of howthey can be implemented in special cases.In chapter three, a theoretical model of imitation and herd behavior is considered.It is assumed in that some participating agents have specific abilities to affect otherpeoples behavior. Results are provided on how ""stars"" or celebrity players can impactherd formation. In the particular setting of a financial market with a single traded asset,results are provided on the consequences of this celebrity effect on bubble formationin the financial market.",2009,
Multiple Heterogeneous Structural Breaks Models and Estimation Methods for Panel Data Analysis,"T 
his paper introduces three panel data models and their estimation methods that take heterogeneous structural breaks in the slope coefficients into consideration. Despite the fact that many empirical studies in various domains suggest the effects of certain factors may be unstable and different across clusters, not many studies have considered the development of such techniques in panel data analysis. Thus, this paper seeks to fill this gap. We model the heterogeneities through a latent group structure and consider both the case of a static group pattern and the case when the group pattern changes after each break. For the static group case, we introduce the grouped adaptive group fused lasso (GAGFL) algorithm with a penalized least squares (PLS) method to estimate the exogenous model, and propose the incorporation with a penalized GMM (PGMM) method to estimate the endogenous model. To deal with the dynamic group pattern, we propose the dynamically grouped heterogeneous structural breaks (DGHB) estimation method. Through two sets of Monte Carlo simulations, we demonstrate that our methods give high accuracy in classifications, breaks detections and coefficients estimations. We further apply our GAGFL with PGMM method to investigate the effect of foreign direct investment (FDI) inflow on economic growth. The new evidence we obtained in this application confirms the usefulness of our methods in empirical studies.",2018,
Correcting Bias in Crowdsourced Data to Map Bicycle Ridership of All Bicyclists,"Traditional methods of counting bicyclists are resource-intensive and generate data with sparse spatial and temporal detail. Previous research suggests big data from crowdsourced fitness apps offer a new source of bicycling data with high spatial and temporal resolution. However, crowdsourced bicycling data are biased as they oversample recreational riders. Our goals are to quantify geographical variables, which can help in correcting bias in crowdsourced, data and to develop a generalized method to correct bias in big crowdsourced data on bicycle ridership in different settings in order to generate maps for cities representative of all bicyclists at a street-level spatial resolution. We used street-level ridership data for 2016 from a crowdsourced fitness app (Strava), geographical covariate data, and official counts from 44 locations across Maricopa County, Arizona, USA (training data); and 60 locations from the city of Tempe, within Maricopa (test data). First, we quantified the relationship between Strava and official ridership data volumes. Second, we used a multi-step approach with variable selection using LASSO followed by Poisson regression to integrate geographical covariates, Strava, and training data to correct bias. Finally, we predicted bias-corrected average annual daily bicyclist counts for Tempe and evaluated the modelâ€™s accuracy using the test data. We found a correlation between the annual ridership data from Strava and official counts (R2 = 0.76) in Maricopa County for 2016. The significant variables for correcting bias were: The proportion of white population, median household income, traffic speed, distance to residential areas, and distance to green spaces. The model could correct bias in crowdsourced data from Strava in Tempe with 86% of road segments being predicted within a margin of Â±100 average annual bicyclists. Our results indicate that it is possible to map ridership for cities at the street-level by correcting bias in crowdsourced bicycle ridership data, with access to adequate data from official count programs and geographical covariates at a comparable spatial and temporal resolution.",2019,
"Elysia timida (Risso, 1818) (Gastropoda, Opisthobranchia): relationship and feeding deterrence to a potential predator on the south-western Mediterranean coast","Abstract. The relationship between the sacoglossan Elysia timida and the ornate wrasse Thalassoma pavo was studied in two laboratory experiments using artificial models. A feeding-preference experiment was conducted to determine whether mollusc extract deterred feeding by T. pavo, by using a ""realistic"" mollusc model (imitating the colour pattern of E. timida) coated with mollusc extract, and a reference model (without imitation or extract), and fishes collected from two locations. It was observed that fish approached, attacked and ate more reference models than mollusc models. A second feeding-preference experiment was designed with four different coloured models: ""realistic"" (W), green (G), red (R) and chequered (S) pattern. Both fish populations clearly rejected the S model, and differed in their colour preferences. Although both populations seemed to prefer the R and G models equally, the W model was clearly rejected by the fish that coexist with the mollusc at one site (MazarrÃ³n), but was not rejected by the other population of fish which does not coexist with it (Cabo de Palos). MazarrÃ³n fishes would identify the W model with the presence of a toxic compound during their coexistence, and therefore avoid attacking conspicuously coloured E. timida models as a response to their visual signals. Therefore, it was concluded that extract of E. timida is a deterrent for T. pavo, and its effect is sufficiently noxious that the fish tend to avoid it, so that the ability of the fishes to learn to recognise colours and identify certain colour patterns associated with obnoxious prey provides the molluscs the opportunity to survive by exhibiting a conspicuous coloration.",2002,Marine Biology
Corrosion Behavior of Duplex Stainless Steels in Acidic-Chloride Solutions Studied with Micrometer Resolution,"The local corrosion behavior of duplex stainless steel (DSS)is affected by a wide variety of factors. Localized corrosionof DSS frequently starts at micrometer scale inclusions orprecipitates, which are often segregated in theaustenite-ferrite boundary regions. Moreover, due to thepartitioning of the key alloying elements of ferrite (Cr andMo) and austenite (N and Ni), the local interactions betweenthe phases must also be considered.The aim of this doctoral study was to increase the knowledgeabout the local dissolution behavior of DSS in acidic-chlorideenvironments. The recent developments of new local probingtechniques have opened a new frontier in corrosion science,providing valuable local information not accessible in thepast. The local techniques used include electrochemicalscanning tunneling microscopy (EC-STM), scanning probe forcemicroscopy (SKPFM), magnetic force microscopy (MFM), andscanning Auger electron Spectroscopy (SAES), all withmicrometer or sub-micrometer resolution.With EC-STM, it was possible to monitor local dissolutionprocesses on DSS in situ, and in real time. MFM was capable ofimaging the phase distribution in DSS without the need of thetraditional surface etching, while SKPFM revealed that theVolta potential difference between the two phases wasmeasurable and significant. SAES showed that the compositiongradient at the phase boundaries is narrower than 2Âµm.Different types of DSSs have been studied, from low-alloyedDSS to superduplex. Higher contents of Cr, Mo and Nstrengthened both phases as well as the phase boundaries,resulting in phases having similar corrosion resistance thatshowed a more uniform dissolution behavior. However, the Voltapotential difference between the phases proved to be of thesame order for all the DSSs studied. Austenite was in generalassociated to regions displaying a more noble Volta potentialthan ferrite, resulting in a higher dissolution rate of theferrite next to the austenite phase.Key words:In situ, local dissolution, electrochemical,STM, SKPFM, MFM, SAES, duplex stainless steel, acidic-chloridesolution.",2003,
Cultivation of Diverse Microorganisms from Hypersaline Lake and Impact of Delay in Sample Processing on Cell Viability,"The Sambhar Salt Lake is a halite rich athalassohaline basin, provides a unique opportunity for microbial ecologists to study halophiles. The lake has a high proportion of Na+ and Clâˆ’ ions making it a hypersaline ecosystem. In the current study, archaea and bacteria from Sambhar Lake were isolated using two cultivation approaches. A total of 449 isolates were obtained, out of which 13 represent archaeal while 12 represent bacterial genera. Natronococcus and Alkalibacillus were found predominant groups among archaea and bacteria, respectively. Apart from the common genera in both the approaches Alteribacillus, Halobacillus, Halorubrum, Lentibacillus, Natronorubrum, Piscibacillus and Thalassobacillus were found only in the samples processed onsite however only three genera Aliidiomarina, Natrinema and Natronolimnobius were isolated when samples were processed in the laboratory after transportation using the same growth conditions. Other than the isolation of diverse group of organisms 13 putative novel taxa with similarity less than 98% were identified using 16S rRNA gene sequencing.",2020,Current Microbiology
Time-Varying Gaussian Graphical Models of Molecular Dynamics Data,"We introduce an algorithm for learning sparse, time-varying undirected probabilistic graphical models of Molecular Dynamics (MD) data. Our method computes a maximum a posteriori (MAP) estimate of the topology and parameters of the model (i.e., structure learning) using L1regularization of the negative log-likelihood (aka â€˜Graphical Lassoâ€™) to ensure sparsity, and a kernel to ensure smoothly varying topology and parameters over time. The learning problem is posed as a convex optimization problem and then solved optimally using block coordinate descent. The resulting model encodes the time-varying joint distribution over all the dihedral angles in the protein. We apply our method to three separate MD simulations of the enzyme Cyclophilin A, a peptidylprolyl isomerase. Each simulation models the isomerization of a different substrate. We compare and contrast the graphical models constructed from each data set, providing insights into the differences in the dynamics experienced by the enzyme for the different substrate.",2010,
Development of an Algorithm to Classify Colonoscopy Indication from Coded Health Care Data,"INTRODUCTION
Electronic health data are potentially valuable resources for evaluating colonoscopy screening utilization and effectiveness. The ability to distinguish screening colonoscopies from exams performed for other purposes is critical for research that examines factors related to screening uptake and adherence, and the impact of screening on patient outcomes, but distinguishing between these indications in secondary health data proves challenging. The objective of this study is to develop a new and more accurate algorithm for identification of screening colonoscopies using electronic health data.


METHODS
Data from a case-control study of colorectal cancer with adjudicated colonoscopy indication was used to develop logistic regression-based algorithms. The proposed algorithms predict the probability that a colonoscopy was indicated for screening, with variables selected for inclusion in the models using the Least Absolute Shrinkage and Selection Operator (LASSO).


RESULTS
The algorithms had excellent classification accuracy in internal validation. The primary, restricted model had AUC= 0.94, sensitivity=0.91, and specificity=0.82. The secondary, extended model had AUC=0.96, sensitivity=0.88, and specificity=0.90.


DISCUSSION
The LASSO approach enabled estimation of parsimonious algorithms that identified screening colonoscopies with high accuracy in our study population. External validation is needed to replicate these results and to explore the performance of these algorithms in other settings.",2015,eGEMs
"Quantitative observations of predation during spawning rushes of the labrid fishThalassoma cupido at Miyake-jima, Japan","A rapid upward spawning rush is a nearly universal phenomenon among reef fishes that spawn pelagic eggs. Although spawning rushes have long been considered to have evolved as a defense against egg predators and/or attacks on the spawning fishes by piscivores, these hypotheses have never been tested in the field. We analysed piscivore attacks during three motor patterns associated with group spawning of the labrid fishThalassoma cupido at Miyake-jima, Izu Islands, Japan. Egg predation on group spawnings was also quantified. Of 206 piscivore attacks on spawning fishes by seven predator species, 17.1 (83.1%) occurred during 461 spawning rushes (1/2.7 spawning rushes). No attacks were successful during spawning rushes, and only four kills were made in 206 attacks summed from all three motor patterns associated with spawning, amounting to a piscivore success rate of only 1.9 %. In contrast, gametes from 90 of 213 spawnings (42.3 %) were consumed by nine species of planktivorous fishes. Spawning fish seemed not to recognize egg predators and made no attempt to avoid them, often spawning in the midst of waiting aggregations of damselfishes. Our data indicate that the rapidly of the spawning rush ofT. cupido serves as an excellent defense against piscivores, but is ineffective against egg predators. Evidence is presented from observations of seven other species suggesting that spawning ascents provide little protection against water column egg predators in predator-rich environments.",1987,Japanese Journal of Ichthyology
Sperm washing with intrauterine insemination and preexposure prophylaxis: an innovative approach to treating HIVâ€serodiscordant couples,"OBJECTIVE: Sperm washing (SW) with intrauterine insemination (IUI) has been advocated as a safe, efficacious way to achieve pregnancy and to reduce the risk of human immunodeficiency virus (HIV) transmission in HIV-serodiscordant couples in which the male partner is HIV-infected. HIV is present as free virions in seminal plasma and as cellassociated virus in non-spermatic cells. Using sperm concentrate prepped free of these cell types provides safety from sexual transmission. In the United States, few centers provide fertility care for HIV-serodiscordant couples. SW with intracytoplasmic sperm injection of sperm into mature eggs harvested for in vitro fertilization has been used as a first-line assisted reproduction treatment, although this method is often cost prohibitive and requires dedicated in vitro fertilization laboratory equipment. The US Department of Health and Human Services recommends preexposure prophylaxis (PrEP) antiretroviral therapy for sexually active couples to reduce infection transmission rates. For HIV-serodiscordant couples in which the female partner is seronegative, we initiated an innovative therapy of SW-IUI combined with PrEP to further reduce the risk of HIV transmission.",2017,American Journal of Obstetrics and Gynecology
Representation of WHAT-Knowledge Structures as Ontology Design Patterns,"Considering any complex object several different aspects and layers can be investigated. WHAT-knowledge is one of the question-based aspects of knowledge that implies a conceptual representation of knowledge and is a major priority in learning. WHAT-knowledge key concepts are Entity, Concept, Class, Instance, Property. WHAT-knowledge key relationships are subClassOf, hasPart/isPartOf, type, classifies/isClassifiedBy. A classical way of teaching assumes that the studied concept definition is given first, then the concept properties are studied, and only after that - the relations with other concepts. To improve semantic interoperability, knowledge can be represented using description logics, however, it is a non-trivial task. As a consequence, created ontologies are often not scientific, i.e. they contain disproportionate concepts, tautologies, concepts with undefined disjoint relations, and so on. To provide an accurate representation of WHAT-knowledge, we proposed to represent WHAT-Knowledge Structures as Ontology Design Patterns. Typical WHAT-knowledge structures are the follows: determinables, contrast sets, genus/differentiate, taxonomies, faceted taxonomies, cluster concepts, family resemblances, graded concepts, frames, definitions, rules, rules with exceptions, essence and state assertions, opposites and contraries, relevance, and so on. To represent these structures we developed the following patterns: concept existence, incomparable concepts, concept properties, comparable concepts (contrast set (ordered and disordered), individual as an example of the class, intensional definition of concept, extensional definition of concept (implicational definition of concept, definitional concept description, rule-like definition of concept), concept exclusion, concepts intersection). Also, we proposed to use the following roles (non-taxonomic relations) that are defined as WHAT-Knowledge Structures through Ontology Design Patterns: existence role, existence role between the concepts, inverse roles, disjoint roles, roles inclusion, and chain of roles. The proposed approach allows increasing efficiency of the domain conceptual modeling, and model intelligibility for end-users. It can be used for the conceptual modeling and information retrieval in a wide range of domains and particularly in education and scientific research.",2018,"2018 9th International Conference on Information, Intelligence, Systems and Applications (IISA)"
[Quality of chronic patient care according to the Chronic Care Model inÂ Burkina Faso].,"INTRODUCTION
There is a lack of organizational knowledge concerning optimal management by the health care system for patients with chronic health conditions in sub-Saharan Africa. The objective of this study was to describe the quality of chronic patient care at first-line heath facilities in Bobo-Dioulasso, Burkina Faso.


METHODS
We conducted a cross-sectional study in six health facilities in Bobo-Dioulasso from October to November 2013. The chronic care model was used as a reference to describe the care of hypertensive patients. A score was calculated for each item in the model, and the strengths and weaknesses of health care organization were identified


RESULTS
The overall level of support for the management of hypertensive patients was ""basic"" for all surveyed structures: median score and IQR 3.7 (3.4, 4.4). The level of support was basic for primary health facilities (median score 4.4), district hospitals (median score 4.1) and the University health center (median score 5.4). The relationship with the community and support to decision-making were identified as weak components of the model.


CONCLUSIONS
To improve the quality of chronic patient care in first-line health facilities in Burkina Faso, efforts must be made to strengthen clinical governance and partnership with the community.",2014,Sante publique
Developing a Sustainable Agricultural Curriculum in Malawi: Reconciling a Colonial Legacy with Indigenous Knowledge and Practices,"A profit motive of the colonial system stole respect of nature from the culture of Africans. Animals were hunted and killed with no thought for the future. Bushes were cleared for tea plantations, and a new system of agriculture [was established] based on monoculture. Arable cropping was introduced which later ensured ecological degradation (cited in Glasson et al. 2006, p. 671).",2010,
Multi-Task Learning for Spatio-Temporal Event Forecasting,"Spatial event forecasting from social media is an important problem but encounters critical challenges, such as dynamic patterns of features (keywords) and geographic heterogeneity (e.g., spatial correlations, imbalanced samples, and different populations in different locations). Most existing approaches (e.g., LASSO regression, dynamic query expansion, and burst detection) are designed to address some of these challenges, but not all of them. This paper proposes a novel multi-task learning framework which aims to concurrently address all the challenges. Specifically, given a collection of locations (e.g., cities), we propose to build forecasting models for all locations simultaneously by extracting and utilizing appropriate shared information that effectively increases the sample size for each location, thus improving the forecasting performance. We combine both static features derived from a predefined vocabulary by domain experts and dynamic features generated from dynamic query expansion in a multi-task feature learning framework; we investigate different strategies to balance homogeneity and diversity between static and dynamic terms. Efficient algorithms based on Iterative Group Hard Thresholding are developed to achieve efficient and effective model training and prediction. Extensive experimental evaluations on Twitter data from four different countries in Latin America demonstrated the effectiveness of our proposed approach.",2015,
A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups,"We deal with the problem of variable selection when variables must be selected group-wise, with possibly overlapping groups defined a priori. In particular we propose a new optimization procedure for solving the regularized algorithm presented in [12], where the group lasso penalty is generalized to overlapping groups of variables. While in [12] the proposed implementation requires explicit replication of the variables belonging to more than one group, our iterative procedure is based on a combination of proximal methods in the primal space and projected Newton method in a reduced dual space, corresponding to the active groups. This procedure provides a scalable alternative with no need for data duplication, and allows to deal with high dimensional problems without pre-processing for dimensionality reduction. The computational advantages of our scheme with respect to state-of-the-art algorithms using data duplication are shown empirically with numerical simulations.",2010,
New estimation and inference procedures for a single-index conditional distribution model,"This article employs a more flexible single-index regression model to characterize the conditional distribution. The pseudo least integrated squares approach is proposed to estimate the index coefficients. As shown in the numerical results, our estimator outperforms the existing ones in terms of the mean squared error. Moreover, we provide the generalized cross-validation criteria for bandwidth selection and utilize the frequency distributions of weighted bootstrap analogues for the estimation of asymptotic variance and the construction of confidence intervals. With a defined residual process, a test rule is built to check the correctness of an applied single-index conditional distribution model. To tackle the problem of sparse variables, a multi-stage adaptive Lasso algorithm is developed to enhance the ability of identifying significant variables. All of our procedures are found to be easily implemented, numerically stable, and highly adaptive to a variety of data structures. In addition, we assess the finite sample performances of the proposed estimation and inference procedures through extensive simulation experiments. Two empirical examples from the house-price study in Boston and the environmental study in New York are further used to illustrate applications of the methodology.",2012,J. Multivar. Anal.
Sparse Reduced-Rank Regression for Simultaneous Dimension Reduction and Variable Selection,"The reduced-rank regression is an effective method in predicting multiple response variables from the same set of predictor variables. It reduces the number of model parameters and takes advantage of interrelations between the response variables and hence improves predictive accuracy. We propose to select relevant variables for reduced-rank regression by using a sparsity-inducing penalty. We apply a group-lasso type penalty that treats each row of the matrix of the regression coefficients as a group and show that this penalty satisfies certain desirable invariance properties. We develop two numerical algorithms to solve the penalized regression problem and establish the asymptotic consistency of the proposed method. In particular, the manifold structure of the reduced-rank regression coefficient matrix is considered and studied in our theoretical analysis. In our simulation study and real data analysis, the new method is compared with several existing variable selection methods for multivariate regression...",2012,Journal of the American Statistical Association
"Element-specific magnetic moments and spin-resolved density of states in CoFeMnZ (Z = Al, Ga; Si, Ge)","Using circular dichroism in x-ray-absorption spectroscopy (XAS/XMCD), we determined element-specific magnetic moments and spin-resolved unoccupied densities of states (DOS) for Co, Fe, and Mn in the quaternary HeuslercompoundsCoFeMnZ (Z = Al,Ga;Si,Ge).Thesecompoundsbelongtoaclassofhighlyspin-polarized materials with cubic LiMgPdSn-type structure. Different structure models for the sublattice occupation leading to similar average magnetization values can be distinguished by comparison of element-specific moments with theory. We find that the compounds form similar structures, where Co, Fe, Mn, and Z occupy the X, X ï¿½ , Y, and Z sublattice of the related X2 YZ L21-Heusler structure, for which half-metallic behavior was predicted. The unoccupied partial DOS as derived from the XAS/XMCD spectra for Co, Fe, and Mn are compared to theoretical results. A good agreement is found for Co and Fe, while Mn spectra reveal additional final-state effects (multiplets).",2011,Physical Review B
Livestock-Associated Staphylococcus aureus: The United States Experience,"Staphylococcus aureus is a gram-positive bacterium that colonizes a variety of animal species [1]. S. aureus infections in animals are most commonly reported as a cause of mastitis in dairyproducing animals (including cattle and goats) and â€œbumblefootâ€ in chickens [2], as well as being identified as a pathogen of farmed rabbits [3]. Most reports characterizing animalassociated S. aureus have demonstrated that strains affecting animals are distinct from those infecting humans, suggesting that there are host-specific lineages which only rarely cross species boundaries [4]. Livestock-associated strains may evolve on farms because of the use of antibiotics in animal husbandry. These may be used as feed additives for growth promotion in industrial livestock and poultry [5], for prevention of disease within a herd, or for treatment of an existing disease outbreak. Agricultural-use antibiotics include many classes that are relevant for human health, including tetracyclines, macrolides, penicillins, and sulfonamides, among others. Antimicrobial resistance generated during animal husbandry may then be spread to the general human population in a number of different manners: contact with contaminated meat products (via handling or ingestion); occupational contact (farmers, meat packers, butchers, etc.) and potential secondary spread into the larger community from those who are occupationally exposed; entry into and transmission via hospitals or other health care facilities; or spread via environmental routes including air, water, or manure in areas in proximity to live animal farms or crop farms where manure has been used as a fertilizer (Fig. 1). While methicillin resistance has been the most commonly investigated phenomenon and will be the main topic of this review, resistance to any of these antibiotics can occur and can potentially be a threat to successful treatment of S. aureus infections and therefore to human health outcomes. As such, my research group and others have begun to look more broadly at any S. aureus present on farms, including those that may be susceptible to methicillin but resistant to other antibiotics.",2015,PLoS Pathogens
Necessary and Sufficient Conditions of Solution Uniqueness in 1-Norm Minimization,"This paper shows that the solutions to various 1-norm minimization problems are unique if, and only if, a common set of conditions are satisfied. This result applies broadly to the basis pursuit model, basis pursuit denoising model, Lasso model, as well as certain other 1-norm related models. This condition is previously known to be sufficient for the basis pursuit model to have a unique solution. Indeed, it is also necessary, and applies to a variety of 1-norm related models. The paper also discusses ways to recognize unique solutions and verify the uniqueness conditions numerically. The proof technique is based on linear programming strong duality and strict complementarity results.",2015,Journal of Optimization Theory and Applications
Predicting student's psychomotor domain on the vocational senior high school using linear regression,"The educational data can be mined to produce the useful knowledge. This paper focuses on the educational data processing to predict student's psychomotor domain. Here, we apply linear regression method to do it. On process stage, we use 4 regularizations, namely: no regularization, ridge regression, lasso regression and elastic net regression. Furthermore, we exploit 2 sampling methods as the evaluation technique, for examples: cross-validation sampling and random sampling. The experimental result indicates that the best regularization on cross-validation and random sampling are an elastic net regression because this regularization achieves the lowest predicting error. On cross-validation, values of MSE, RMSE, and MAE are 40.079, 6.330 and 5.183, respectively. Additionally, for random sampling, respectively, values of MSE, RMSE, and MAE are 86.910, 8.428 and 6.511.",2018,2018 International Conference on Information and Communications Technology (ICOIACT)
Assessment of intratumoral heterogeneity with mutations and gene expression profiles,"Intratumoral heterogeneity (ITH) refers to the presence of distinct tumor cell populations. It provides vital information for the clinical prognosis, drug responsiveness, and personalized treatment of cancer patients. As genomic ITH in various cancers affects the expression patterns of genes, the expression profile could be utilized for determining ITH level. Herein, we present a novel approach to directly detect high ITH defined as a larger number of subclones from the gene expression pattern through machine learning approaches. We examined associations between gene expression profile and ITH of 12 cancer types from The Cancer Genome Atlas (TCGA) database. Using stomach adenocarcinoma (STAD) showing high association, we evaluated the performance of our method in predicting ITH by employing three machine learning algorithms using gene expression profile data. We classified tumors into high and low heterogeneity groups using the learning model through the selection of LASSO feature. The result showed that support vector machines (SVMs) outperformed other algorithms (AUC = 0.84 in SVMs and 0.82 in NaÃ¯ve Bayes) and we were able to improve predictive power by using both combined data from mutation and expression. Furthermore, we evaluated the prediction ability of each model using simulation data generated by mixing cell lines of the Cancer Cell Line Encyclopedia (CCLE), and obtained consistent results with using real dataset. Our approach could be utilized for discriminating tumors with heterogeneous cell populations to characterize ITH.",2019,PLoS ONE
"Graph Signal Processing - Part III: Machine Learning on Graphs, from Graph Topology to Applications","Many modern data analytics applications on graphs operate on domains where graph topology is not known a priori, and hence its determination becomes part of the problem definition, rather than serving as prior knowledge which aids the problem solution. Part III of this monograph starts by addressing ways to learn graph topology, from the case where the physics of the problem already suggest a possible topology, through to most general cases where the graph topology is learned from the data. A particular emphasis is on graph topology definition based on the correlation and precision matrices of the observed data, combined with additional prior knowledge and structural conditions, such as the smoothness or sparsity of graph connections. For learning sparse graphs (with small number of edges), the least absolute shrinkage and selection operator, known as LASSO is employed, along with its graph specific variant, graphical LASSO. For completeness, both variants of LASSO are derived in an intuitive way, and explained. An in-depth elaboration of the graph topology learning paradigm is provided through several examples on physically well defined graphs, such as electric circuits, linear heat transfer, social and computer networks, and spring-mass systems. As many graph neural networks (GNN) and convolutional graph networks (GCN) are emerging, we have also reviewed the main trends in GNNs and GCNs, from the perspective of graph signal filtering. Tensor representation of lattice-structured graphs is next considered, and it is shown that tensors (multidimensional data arrays) are a special class of graph signals, whereby the graph vertices reside on a high-dimensional regular lattice structure. This part of monograph concludes with two emerging applications in financial data processing and underground transportation networks modeling.",2020,ArXiv
Dynamic Screening with Approximate Dictionaries,"Various strategies to accelerate the Lasso optimization have been recently proposed. Among them, screening rules provide a way to safely eliminate inactive variables, thus reducing the problemâ€™s dimensionality. Another line of work consists in replacing the dictionary matrix by a structured approximation of it, which is faster to manipulate. This paper proposes a method to conciliate both strategies. First, we show how to obtain safe screening rules for the exact problem while manipulating an approximate dictionary. We then adapt an existing screening rule to this new framework and define a general procedure to leverage the advantages of both strategies. Significant complexity reductions are obtained in comparison to screening rules alone.",2017,
"Species composition, habitat configuration and seasonal changes of coral reef fish assemblages in western Mexico","Summary 
 
In spite of their ecological and economic importance, reef fishes from the coast of Oaxaca, Mexico are rarely studied, therefore precluding their management and conservation. In order to identify the set of habitat characteristics/environmental conditions that predict major shifts in fish assemblages in space and time, a stationary census (5â€², Ï†Â =Â 5Â m) was conducted on a semi-monthly basis from 2006 to 2009 at patch reefs along the coast. Habitat configuration was gathered using 25Â m long point-intersect transects (data every 25Â cm), recording all underlying coral species and substrate characteristics (rocks, sand, algal mats, rubble or dead corals). Recorded were 65Â 452 fishes grouped in 11 orders, 36 families, 65 genera and 89 species. Labridae (nine species), Pomacentridae (eight species) and Serranidae (seven species) were the most frequent families. Abundance is severely skewed among species; four species Thalassoma lucasanum, Chromis atrilobata, Apogon pacificus and Stegastes acapulcoensis comprise nearly 59% of the fish abundance, 11 species contribute 30%, whereas most of the species (75) can be considered as rare since they contribute <1% each to the total. Species richness and family-level assemblage composition are similar to those recorded elsewhere in the eastern Pacific. Non-parametric multivariate analysis of variance demonstrated that changes of diversity metrics might be associated with environmental differences on the scale of hundreds of meters to kilometers, as well as coupled with major changes on oceanographic variables throughout time, exerting meaningful changes on reef-related fish assemblages.",2013,Journal of Applied Ichthyology
High-Dimensional Inference for Personalized Treatment Decision.,"Recent development in statistical methodology for personalized treatment decision has utilized high-dimensional regression to take into account a large number of patients' covariates and described personalized treatment decision through interactions between treatment and covariates. While a subset of interaction terms can be obtained by existing variable selection methods to indicate relevant covariates for making treatment decision, there often lacks statistical interpretation of the results. This paper proposes an asymptotically unbiased estimator based on Lasso solution for the interaction coefficients. We derive the limiting distribution of the estimator when baseline function of the regression model is unknown and possibly misspecified. Confidence intervals and p-values are derived to infer the effects of the patients' covariates in making treatment decision. We confirm the accuracy of the proposed method and its robustness against misspecified function in simulation and apply the method to STAR*D study for major depression disorder.",2018,Electronic journal of statistics
From Protestant Supremacy to Christian Supremacy,"Over the last generation, historians have begun to explain Christianity's impact on developing ideas of race and slavery in the early modern Atlantic. Jon Sensbach's A Separate Canaan: The Making of an Afro-Moravian World in North Carolina, 1763â€“1840 showed how Moravians struggled with both race and slavery, ultimately concluding that Moravians adopted the racist attitudes of their non-Pietist North Carolina neighbors. Travis Glasson's Mastering Christianity: Missionary Anglicanism and Slavery in the Atlantic World showed how the Anglican church accustomed itself to slavery in New York and the Caribbean. Richard Bailey's Race and Redemption in Puritan New England unraveled changing puritan ideas about race and belonging in New England. My own book, The Baptism of Early Virginia: How Christianity Created Race , argued that Protestant ideas about heathenism and conversion were instrumental to how English Virginians thought about the bodies and souls of enslaved Africans and Native people, and to how they developed a nascent idea of race in seventeenth-century Virginia. Heather Kopelson's Faithful Bodies: Performing Religion and Race in the Puritan Atlantic traced puritan ideas about race, the soul, and the body in New England and Bermuda. From a different angle, Christopher Cameron's To Plead Our Own Cause: African Americans in Massachusetts and the Making of the Antislavery Movement outlined the influence of puritan theologies on black abolitionism. Engaging all this scholarly ferment is Katharine Gerbner's new book, Christian Slavery: Conversion and Race in the Protestant Atlantic World . Gerbner's work both synthesizes and transforms this extended scholarly conversation with a broad and inclusive look at Protestantsâ€”broadly defined as Anglicans, Moravians, Quakers, Huguenots, and othersâ€”and race in the seventeenth and eighteenth centuries over a geography stretching from New York to the Caribbean. The book is synthetic in that it builds on the regional and confessionally specific work of earlier scholars, but innovative in its argument that Protestants from a variety of European backgrounds and sometimes conflicting theologies all wrestled with questions of Christian conversion of enslaved peoplesâ€”could it be done? Should it be done? And, of overarching concern: how could Protestant Christians in good conscience hold fellow African and Native Christians as slaves?",2019,Church History
[Understanding and reaching young clandestine sex workers in Burkina Faso to improve response to HIV].,"In 1998, researchers in Burkina Faso enrolled 300 women more or less involved in commercial sex work in an open cohort to determine whether adequate management of their sexually transmitted infections and exposure to well-designed, well-delivered, and plentiful communication for behaviour change (CBC) might reduce their vulnerability to HIV. In 2000, they observed that the non-professional sex workers (occasional or clandestine sex workers) were more difficult to reach, to mobilize and to keep involved in the project's different activities. This group was also infected at the same or higher rates than professional sex workers because they did not use condoms routinely. To accomplish the project objectives, they therefore chose to recruit more non-professional sex workers in the new cohort of 700 women. This social-anthropological study was conducted to help them to enrol young clandestine sex workers. The overall objective of this study was to understand the life of this category of sex workers and to identify strategic actors to reach them. Using a qualitative method, social anthropologists reviewed literature, identified and geo-referenced all local places suitable to encountering these women, obtained life stories from some of them and interviewed key informants and participants in the field. The results showed that in Bobo-Dioulasso (Burkina Faso): - most young women who are clandestine sex workers are Burkinabe, and girls entering the sex trade are increasingly young and increasingly uneducated; - most of them come from families with low capital (financial, cultural, or social). The parents' socioeconomic status (contextual poverty) results in unmet financial needs, which in turn exposes them to starting work early, including commercial sex work; - of all the income-generating activities available to unskilled young girls, commercial sex work is one of the most profitable and easily accessible; - in the three-fold context of an HIV epidemic, poverty, and unemployment, clandestine commercial sex work is a rational action, insofar as condom use reduces the risk of HIV infection, ""clandestinity"" reduces the risk of social stigma, and earnings increase financial capital; - girls are coopted into sex work through an initiation process and the initiator explains to the initiate how sex workers think, act, and live, as well as the rules of the trade; - young clandestine commercial sex workers use various strategies to do their work in secret, unidentified, by changing the time, place, period, district, city or country of their work; - young clandestine commercial sex workers maintain friendly relations with men or boys in but have no or conflictual relationships with women and girls. Thus, only other participants in this trade, peer counsellors, and room renters can serve as strategic actors to reach, mobilize and keep these young girls in HIV programmes. Social anthropologists have concluded that one problem in the fight against official or professional commercial sex work is the development of clandestine commercial sex work, which is more dangerous, firstly for its practitioners, who are harder to reach by messages about HIV and thus do not change their behaviour, secondly, for their sexual partners who do not use condoms systematically, and finally for society as a whole, to the extent that social actors are embedded in an informal network, more or less extensive, of sexual partners.",2008,Sante
Aberrant Classopollis pollen reveals evidence for unreduced (2n) pollen in the conifer family Cheirolepidiaceae during the Triassicâ€“Jurassic transition,"Polyploidy (or whole-genome doubling) is a key mechanism for plant speciation leading to new evolutionary lineages. Several lines of evidence show that most species among flowering plants had polyploidy ancestry, but it is virtually unknown for conifers. Here, we study variability in pollen tetrad morphology and the size of the conifer pollen type Classopollis extracted from sediments of the Triassicâ€“Jurassic transition, 200 Ma. Classopollis producing Cheirolepidiaceae were one of the most dominant and diverse groups of conifers during the Mesozoic. We show that aberrant pollen Classopollis tetrads, triads and dyads, and the large variation in pollen size indicates the presence of unreduced (2n) pollen, which is one of the main mechanisms in modern polyploid formation. Polyploid speciation may explain the high variability of growth forms and adaptation of these conifers to different environments and their resistance to extreme growth conditions. We suggest that polyploidy may have also reduced the extinction risk of these conifers during the End-Triassic biotic crisis.",2013,Proceedings of the Royal Society B: Biological Sciences
Robust and sparse tensor analysis with Lp-norm maximization,"Tensor PCA, which can make full use of the spatial relationship of images/videos, plays an important role in computer vision and image analysis. The proposed method is robust to outliers because of using the adjustable Lp-norm. The elastic net, which generalizes the sparsity-inducing lasso penalty by combining the ridge penalty, is integrated into the objective function to develop a sparse model, which is beneficial for features extraction. We propose a greedy algorithm to extract basic features one by one and optimize projection matrices alternatively. The monotonicity of the iterative procedure are theoretically guaranteed. Experimental results upon several face databases demonstrate the advantages of the proposed approach.",2017,2017 8th IEEE International Conference on Software Engineering and Service Science (ICSESS)
"A User-Friendly, Web-Based Integrative Tool (ESurv) for Survival Analysis: Development and Validation Study.","BACKGROUND
Prognostic genes or gene signatures have been widely used to predict patient survival and aid in making decisions pertaining to therapeutic actions. Although some web-based survival analysis tools have been developed, they have several limitations.


OBJECTIVE
Taking these limitations into account, we developed ESurv (Easy, Effective, and Excellent Survival analysis tool), a web-based tool that can perform advanced survival analyses using user-derived data or data from The Cancer Genome Atlas (TCGA). Users can conduct univariate analyses and grouped variable selections using multiomics data from TCGA.


METHODS
We used R to code survival analyses based on multiomics data from TCGA. To perform these analyses, we excluded patients and genes that had insufficient information. Clinical variables were classified as 0 and 1 when there were two categories (for example, chemotherapy: no or yes), and dummy variables were used where features had 3 or more outcomes (for example, with respect to laterality: right, left, or bilateral).


RESULTS
Through univariate analyses, ESurv can identify the prognostic significance for single genes using the survival curve (median or optimal cutoff), area under the curve (AUC) with C statistics, and receiver operating characteristics (ROC). Users can obtain prognostic variable signatures based on multiomics data from clinical variables or grouped variable selections (lasso, elastic net regularization, and network-regularized high-dimensional Cox-regression) and select the same outputs as above. In addition, users can create custom gene signatures for specific cancers using various genes of interest. One of the most important functions of ESurv is that users can perform all survival analyses using their own data.


CONCLUSIONS
Using advanced statistical techniques suitable for high-dimensional data, including genetic data, and integrated survival analysis, ESurv overcomes the limitations of previous web-based tools and will help biomedical researchers easily perform complex survival analyses.",2020,Journal of medical Internet research
Learning from MOM's principles: Le Cam's approach,"We obtain estimation error rates for estimators obtained by aggregation of reg-ularized median-of-means tests, following a construction of Le Cam. The results hold with exponentially large probability, under only weak moments assumptions on data. Any norm may be used for regularization. When it has some sparsity inducing power we recover sparse rates of convergence. The procedure is robust since a large part of data may be corrupted, these outliers have nothing to do with the oracle we want to reconstruct. Our general risk bound is of order max minimax rate in the i.i.d. setup, number of outliers number of observations. In particular, the number of outliers may be as large as (number of data) Ã—(minimax rate) without affecting this rate. The other data do not have to be identically distributed but should only have equivalent L 1 and L 2 moments. For example, the minimax rate s log(ed/s)/N of recovery of a s-sparse vector in R d is achieved with exponentially large probability by a median-of-means version of the LASSO when the noise has q 0 moments for some q 0 > 2, the entries of the design matrix should have C 0 log(ed) moments and the dataset can be corrupted up to C 1 s log(ed/s) outliers.",2019,Stochastic Processes and their Applications
Fecal Calprotectin Evaluation in Patients with Ulcerative Colitis,"Dear Editor, We read with great interest the article by Burri et al. [1] entitled â€˜â€˜Fecal calprotectin and the clinical activity index are both useful to monitor medical treatment in patients with ulcerative colitisâ€™â€™ in which the investigators suggested that fecal calprotectin (FC) was useful to monitor disease activity of ulcerative colitis during medical treatment and identified endoscopic disease activity reliably. However, there are some points that should be discussed. FC is a confirmed noninvasive biomarker in inflammatory bowel diseases. Previous studies showed that various medications such as nonsteroidal anti-inflammatory drugs, aspirin, and statins could alter FC levels beside stated medications [2]. Also, dietary supplements such as zinc, vitamin D, fatty acids, and several probiotics can affect FC levels too [3, 4]. We believe above contributing factors have to be stated to provide robust study population. Lasson et al. [5] suggested that there was a great instability in the concentrations of FC in stool samples collected during a single day. Body mass indices of participants and pregnancy status of female participants should be expressed due to being other contributing factors [6, 7]. We believe these variables could be effective on the measurement of FC. These confounders should be expressed, and multivariate regression analysis has to be applied to obtain meaningful data. Single measurement of FC may not be sufficiently accurate to evaluate the disease activity of ulcerative colitis, and other markers such as platelet and leukocyte count, albumin, C-reactive protein, lactoferrin, alpha-1 acid glycoprotein, and polymorphonuclear elastase may be required [8, 9]. In conclusion, clarifying above concerns will certainly provide a clearer picture to the readers.",2015,Digestive Diseases and Sciences
Mob rulers and part-time cleaners: two reef fish associations at the isolated Ascension Island,"Isolated oceanic islands may give rise not only to new and endemic species, but also to unique behaviours and species interactions. Multi-species fish interactions, such as cleaning, following, mob-feeding and others are understudied in these ecosystems. Here we present qualitative and quantitative observations on cleaning and mob-feeding reef fish associations at the isolated Ascension Island, South Atlantic Ocean. Cleaning interactions were dominated by juveniles of the facultative fish cleaners Bodianus insularis and Pomacanthus paru , with lesser contributions of Chaetodon sanctaehelenae, Thalassoma ascensionis and the cleaner shrimp Lysmata grabhami . Two types of feeding mobs were consistently identified: less mobile mobs led by the surgeonfish Acanthurus bahianus and A. coeruleus and the more mobile mobs led by the African sergeant Abudefduf hoefleri . This is the first record of A. hoefleri from outside of the Eastern Atlantic and also the first report of this species displaying mob-feeding behaviour. The principal follower of both mob types was the extremely abundant Melichthys niger , but the main aggressor differed: Stegastes lubbocki , a highly territorial herbivore, was the main aggressor of Acanthurus mobs; and Chromis multilineata a territorial fish while engaged in egg parental care, was the principal aggressor towards Abudefduf mobs. Our study enhances the scarce information on reef fish feeding associations at the isolated Ascension Island and at oceanic islands in the Atlantic in general.",2017,Journal of the Marine Biological Association of the United Kingdom
"Comparison of Supervised , Semi-supervised and Unsupervised Learning Methods in Network Intrusion Detection System ( NIDS ) Application","With the emergence of the fourth industrial revolution (Industrie 4.0) of cyber physical systems, intrusion detection systems are highly necessary to detect industrial network attacks. Recently, the increase in application of specialized machine learning techniques is gaining critical attention in the intrusion detection community. A wide variety of learning techniques proposed for different network intrusion detection system (NIDS) problems can be roughly classified into three broad categories: supervised, semi-supervised and unsupervised. In this paper, a comparative study of selected learning methods from each of these three kinds is carried out. In order to assess these learning methods, they are subjected to investigate network traffic datasets from an Airplane Cabin Demonstrator. In addition to this, the imbalanced classes (normal and anomaly classes) that are present in the captured network traffic data is one of the most crucial issues to be taken into consideration. From this investigation, it has been identified that supervised learning methods (logistic and lasso logistic regression methods) perform better than other methods when historical data on former attacks are available. The results of this study have also showed that the performance of semisupervised learning method (One class support vector machine) is comparatively better than unsupervised learning method (Isolation Forest) when historical data on former attacks are not available.",2017,
Compressed Anomaly Detection with Multiple Mixed Observations,"We consider a collection of independent random variables that are identically distributed, except for a small subset which follows a different, anomalous distribution. We study the problem of detecting which random variables in the collection are governed by the anomalous distribution. Recent work proposes to solve this problem by conducting hypothesis tests based on mixed observations (e.g., linear combinations) of the random variables. Recognizing the connection between taking mixed observations and compressed sensing, we view the problem as recovering the â€œsupportâ€ (index set) of the anomalous random variables from multiple measurement vectors (MMVs). Many algorithms have been developed for recovering jointly sparse signals and their support from MMVs. We establish the theoretical and empirical effectiveness of these algorithms in detecting anomalies. We also extend the LASSO algorithm to an MMV version for our purpose. Further, we perform experiments on synthetic data, consisting of samples from the random variables, to explore the trade-off between the number of mixed observations per sample and the number of samples required to detect anomalies.",2018,ArXiv
Assessing anti-predatory chemical defences among ten eastern Mediterranean sponges,"The palatability of organic chemical extracts from ten of the most abundant sponge species along the Israeli (shallow) coast, eastern Mediterranean Sea ( Axinella sp., Axinella polypoides , Chondrilla nucula , Ircinia sp., Psammocinia sp. 1, Psammocinia sp. 2, Psammocinia sp. 3, Psammocinia sp. 4, Sarcotragus sp. and Tetilla sp.) was tested. To examine the generality of the phenomenon, it was evaluated with two types of potential predators, a fish and a gastropod. It was determined that the extracts of only two species ( Psammocinia sp. 1 and Psammocinia sp. 3) deterred feeding of the omnivorous ornate Mediterranean wrasse Thalassoma pavo . On the other hand, extracts of five other sponges ( Chondrilla nucula , Axinella sp., Ircinia sp., Sarcotragus sp. and Psammocinia sp. 2) were non-palatable to the omnivorous gastropod Strombus persicus (the extracts that deterred the fish did not deter the gastropod and vice versa). We also determined the capacity of extracts from six Red Sea sponges to deter T. pavo , and compared it with these extracts' effect on the Red Sea wrasse T. klunzingeri . All the extracts that deterred the Red Sea wrasse (from Amphimedon chloros , Crella cyatophora , Negombata magnifica and Theonella swinhoei ) were also non-palatable to the Mediterranean wrasse. In addition to these four species, also Diacarnus erythraenus deterred Thalassoma pavo while being palatable to T. klunzingeri , whereas food pellets with extracts of Niphates rowi were eaten by both wrasse species.",2007,Journal of the Marine Biological Association of the United Kingdom
Decompositionand integral representation of Cauchy interactions associatedwith measures âˆ—,"It is well-knownthatthemodelizationof interactionsin ContinuumPhysicsdealswith setfunctionsassociated with physicalquantitiesrather than with functionsevaluatedat single points (seee.g. [7]). Very important examplesof theseare the stressand the heatflux. This, in turn, implies that the conceptof subbodyof a material body B has to be taken into account.However,subbodiesare not completelyphysical (although they may be usedto describethe situationarising in the body in a very satisfactoryway), sincethe classof subsetswhich haveto representhemis a matterof choice. For suchsetfunctionsshouldsatisfysomereasonableadditivity condition,it is naturalto put theapproach into theframeworkof MeasureTheory.An exampleof how this way of thinking hasbeendevelopedis given by the CauchyStressTheorem,leadingin [3] to the notion of Cauchyflux. For further developments, we refer the readerto [3, 8, 5, 1] andthe referencesquotedtherein. In [4], Gurtin,Williams andZiemerproposedto choosethenormalizedsetsof finite perimeterassubbodies and introducedthe conceptof Cauchyinteraction in order to representan interactionbetweentwo disjoint subbodies,possiblyhavinga part of their boundaryin common.This is, roughly speaking,a set function I of two variables,the subbodies,which is additive on eachvariableand which is Lipschitz continuouswith respectto the areameasureof the commonpart of the boundariesand the volumemeasure.In that paperit is provedthat:",2000,
The Chen-Tindall system and the lasso operator: improving automatic model performance,"Using U.S. monthly macroeconomic data, the automatic model system presented in Chen and Tindall [2016] outperforms the lasso automatic system, but the lasso is improved where Bayesian model averaging is employed to combine its forecasts with those from autoregressive schemes. The best performance is obtained using Bayesian model averaging to combine the Chenâ€“Tindall system, the lasso, and autoregressive schemes. Performance is virtually the same using this combined approach where the elastic-net operator is substituted for the lasso. Similar overall outcomes are found for France and Germany treated as a single economic system and for Canada.",2016,
Jung After Speculative Realism,"This review discusses After Finitude: An Essay on the Necessity of Contingency, a key text by Quentin Meillassoux in the new philosophical movement of speculative realism. Speculative realism is critical of Kant and Kant's legacy to contemporary philosophy, correlationism. Kant heavily influenced Jung. The review opens a discussion of the implications of speculative realism for the correlationist aspects of Jung's writings. Paradoxically, After Finitude opens some space for Jung's synchronicity beyond current scientific and philosophical thinking.",2014,
Multiparametric Magnetic Resonance Imaging in the Assessment of Primary Brain Tumors Through Radiomic Features: A Metric for Guided Radiation Treatment Planning,"Purpose The definition of radiotherapy target volume is a critical step in treatment planning for all tumor sites. Conventional magnetic resonance imaging (MRI) pulse sequences are used for the definition of theÂ gross target volume (GTV) and the contouring of glioblastoma multiforme (GBM) and meningioma. We propose the use of multiparametric MRI combined with radiomic features to improve the texture-based differentiation of tumor from edema for GTV definitionÂ and to differentiate vasogenic from tumor cell infiltration edema. Methods Twenty-five patients with brain tumor and peritumoral edema (PTE) were assessed. Of the enrolled patients, 17 (63 Â± 10 years old, six female and 11 male patients) were diagnosed with GBM and eight (64 Â± 14 years old, five female and three male patients) with meningioma. A 3 Tesla (3T) MRI scanner was used to scan patients using a 3D multi-echo Gradient Echo (GRE) sequence. After the acquisition process, two experienced neuroradiologists independently used an in-house semiautomatic algorithm to conduct a segmentation of two regions of interest (ROI;Â edema and tumor) in all patients using functional MRI sequences, apparent diffusion coefficient (ADC), and dynamic contrast-enhanced MRI (DCE-MRI), as well as anatomical MRI sequences-T1-weighted, T2-weighted and fluid-attenuated inversion recovery (FLAIR).Â Radiomic (computer-extracted texture) features were extracted from all ROIs through different approaches, including first-, second-, and higher-order statistics, both with and without normalization, leading to the calculation of around 300 different texture parameters for each ROI. Based on the extracted parameters, a least absolute shrinkage and selection operator (LASSO) analysis was used to isolate the parameters that best differentiated edema from tumors while irrelevant parameters were discarded. Results and conclusions The parameters chosen by LASSO were used to perform statistical analyses which allowed identification of the variables with the best discriminant ability in all scenarios. Receiver operating characteristic results showcase both the best single discriminator and the discriminant capacity of the model using all variables selected by LASSO. Excellent results were obtained for patients with GBMÂ with all MRI sequences, with and without normalization; a T1-weighted sequence postcontrast (T1W+C) with normalization offered the best tumor classification (area under the curve, AUC > 0.97). For patients with meningioma, a good model of tumor classification was obtained through the T1-weighted sequence (T1W) without normalization (AUC > 0.71). However, there was no agreement between the results of both radiologists for some MRI sequences analyzed for patients with GBM and meningioma. In conclusion, a small subset of radiomic features showed anÂ excellent ability to distinguish edema from tumor tissue through its most discriminating features.",2018,Cureus
A dynamic model of size-dependent reproductive effort in a sequential hermaphrodite: a counterexample to Williams's conjecture.,"In 1966, G. C. Williams showed that for iteroparous organisms, the level of reproductive effort that maximizes fitness is that which balances the marginal gains through current reproduction against the marginal losses to expected future reproduction. When, over an organism's lifetime, the value of future reproduction declines relative to the value of current reproduction, the level of effort allocated to current reproduction should always increase with increasing age. Conversely, when the value of future reproduction increases relative to the value of current reproduction, the level of effort allocated to current reproduction should decrease or remain at zero. While this latter pattern occurs commonly in species that exhibit a delayed age at first reproduction, it may also occur following an initial period of reproduction in some sex-changing organisms that experience a dramatic increase in reproductive potential as they grow larger. Indeed, this schedule of reproductive effort is predicted by models of ""early"" sex change; however, these models may arrive at this result incidentally because they consider only two reproductive states: on and off. In order to examine the schedule of reproductive effort in greater detail in a system where the potential reproductive rate increases sharply, we adapt the logic and methods of time-dependent dynamic-programming models to develop a size-dependent model of reproductive effort for an example species that experiences a dramatic increase in reproductive potential at large sizes: the bluehead wrasse, Thalassoma bifasciatum. Our model shows that the optimal level of reproductive effort will decline with increasing size or age when increases to the residual reproductive value outpace the increases to current reproductive potential. This result confirms the logic of Williams's analysis of optimal life histories, while offering a realistic counterexample to his conjecture of ever-increasing allocation to current reproduction.",2001,The American naturalist
Exact Posterior Simulation from the Linear Lasso Regression,"The current popular method for approximate simulation from the posterior distribution of the linear Bayesian LASSO is a Gibbs sampler. It is well-known that the output analysis of an MCMC sampler is difficult due to the complex dependence amongst the states of the underlying Markov chain. Practitioners can usually only assess the convergence of MCMC samplers using heuristics. In this paper we construct a method that yields an independent and identically distributed (iid) draws from the LASSO posterior. The advantage of such exact sampling over the MCMC sampling is that there are no difficulties with the output analysis of the exact sampler, because all the simulated states are independent. The proposed sampler works well when the dimension of the parameter space is not too large, and when it is too large to permit exact sampling, the proposed method can still be used to construct an approximate MCMC sampler.",2018,2018 Winter Simulation Conference (WSC)
A Palynological Method for Stratigraphical Correlations,"Abstract A method for the stratigraphical correlation and dating of Lower Cretaceous deposits from south-eastern France and north-eastern Spain is proposed, on the basis of a morphological analysis of pollen grains belonging to the form-genus Classopollis (Pflug) Pocock & Jansonius. This method has made possible correlations between microfloristic assemblages from various regions and it solves the problem of the age of the Wealden and Utrillas facies in the region studied. The correlation between these facies and the levels associated with bauxite suggests that a biostratigraphical interpretation would be possible by further application of the method described.",1970,Grana
Identifying risk of poor physical and mental health recovery following a road traffic crash: An industry-specific screening tool.,"This study aimed to develop an industry-specific tool to identify risk of poor physical and mental recovery following minor to moderate injuries sustained in a road traffic crash (RTC). Existing tools are often designed for implementation by health professionals rather than insurer case managers who may not have a background in health. This study is a secondary analysis of a longitudinal cohort study using data collected at 2-6 months and 24 months post-RTC. Participants were claimants (nâ€¯=â€¯254; Mean ageâ€¯=â€¯50 years; 65% female) with mild-moderate injuries recruited through the common-law 'fault-based' compulsory third party scheme in Queensland, Australia. Sociodemographic, functional and psychological health factors were collected at baseline (2-6 months post RTC) and used as potential predictors for physical and mental health-related quality of life (Short Form 36 v2) at the 2-year follow-up. The LASSO (Least Absolute Shrinkage and Selection Operator) analysis identified six disability items (from the World Health Organization Disability Assessment Schedule 2) to predict poor physical and one item to predict poor mental health-related quality of life. Logistic regressions of these items in addition to age and gender were used to develop a screening tool. Using the tool, 90% of those at risk of poor physical and 80% of those at risk of poor mental health-related quality of life were identified correctly. To conclude, this study presents an 8-item, context-specific tool to help injury managers identify individuals at risk of poor physical and mental health recovery following mild-moderate RTC-related injuries. The tool requires validation in a new cohort and confirmation of acceptability by end-users.",2019,Accident; analysis and prevention
Coronary Atherosclerosis and Cardiovascular Risk in Masters Male Marathon Runners,"Background:Regular physical exercise is recommended to reduce cardiovascular mortality. And yet, atherosclerosis is the main cause of exercise-associated death in persons beyond age 35. The need for risk stratification in marathon runners is under discussion. The predictive value of modern imaging- and non-imaging-based markers of risk that can be used for risk stratification in masters endurance athletes still deserves exploration.Methods:Male runners > 50 years who have completed at least five marathon races during the preceding 3 years and do not suffer from coronary artery disease, angina nor diabetes mellitus are studied to assess the predictive value of established and modern imaging- based and biochemical cardiovascular risk factors. Laboratory parameters including clinical chemistry, hematology and hormone measurements are determined. Lifestyle-related risk factors, psychosocial and socioeconomic variables are explored using standardized questionnaires. Coronary, carotid, femoral and aortic atherosclerosis is measured using electronbeam computed tomography and ultrasound. In addition, a resting ECG, a bicycle stress test and heart rate variability are performed. Myocardial morphology and function are assessed using echocardiography and magnetic resonance imaging. Participants are invited to compete in a marathon race to quantify the association of coronary atherosclerosis with marathon-related changes of cardiac troponin levels and the extent of marathon-induced inflammation. At the cellular level, the effect on the amount of circulating progenitor cells (EPCs) is determined by FACS analysis. Changes in laboratory parameters and hormone levels are also studied. Annual long-term follow-up including hospital records and death certificates is performed. Data are compared with those from a general unselected cohort from the Heinz Nixdorf Recall Study.Conclusion:This study should contribute to cardiovascular risk assessment in the growing number of masters marathon runners with a focus on assessing the predictive value of modern imaging techniques and biochemical markers for comprehensive risk stratification.ZusammenfassungHintergrund:RegelmÃ¤ÃŸige kÃ¶rperliche AktivitÃ¤t eignet sich zur PrÃ¤vention der Arteriosklerose und kardiovaskulÃ¤rer Ereignisse. Und dennoch ist die Arteriosklerose die Hauptursache sportassoziierter TodesfÃ¤lle jenseits des 35. Lebensjahrs. Der prÃ¤diktive Nutzen moderner bildgebender Verfahren und biochemischer Marker, die fÃ¼r eine Risikostratifizierung in Frage kommen, wurde bei Ã¤lteren Ausdauersportlern bislang nicht hinreichend untersucht.Methodik:Es werden MÃ¤nner > 50 Jahre untersucht, die in den vergangenen 3 Jahren mindestens fÃ¼nf MarathonlÃ¤ufe absolviert haben und keine bekannte Herzkrankheit oder Angina pectoris und keinen Diabetes mellitus aufweisen. Etablierte Risikofaktoren sowie moderne bildgebende und biochemische Risikomarker werden gemessen. Lebensstilassoziierte, psychosoziale und sozioÃ¶konomische Risikofaktoren werden mit standardisierten FragebÃ¶gen erhoben. Die Arteriosklerose der Koronararterien, der Karotiden, der Femoralarterien und der Aorta wird mittels Elektronenstrahltomographie und Ultraschall quantifiziert. ZusÃ¤tzlich werden ein Ruhe-EKG, eine Fahrradergometrie und eine Messung der HerzfrequenzvariabilitÃ¤t durchgefÃ¼hrt. Morphologie und Funktion des linken Ventrikels werden echokardiographisch und magnetresonanztomographisch erfasst. Die Teilnehmer wurden gebeten, an einem Marathonwettkampf teilzunehmen, um die Assoziation von Koronarsklerose und dem marathoninduzierten Anstieg von kardialem Troponin in AbhÃ¤ngigkeit von der erwarteten EntzÃ¼ndungsreaktion zu untersuchen. Auf zellulÃ¤rer Ebene wird der Effekt auf die Anzahl zirkulierender endothelialer VorlÃ¤uferzellen (EPCs) mittels FACS-Analyse bestimmt. Die Ereignisrate im Verlauf wird jÃ¤hrlich erfragt. Es werden auch Krankenhausdokumente und Sterbeunterlagen ausgewertet. Die Daten kÃ¶nnen im Vergleich zur AllgemeinbevÃ¶lkerung aus der Heinz-Nixdorf-Recall-Studie analysiert werden.Schlussfolgerung:Diese Studie kann einen Beitrag zur kardiovaskulÃ¤ren Risikostratifikation in der wachsenden Gruppe Ã¤lterer MarathonlÃ¤ufer leisten. Der prÃ¤diktive Wert der bildgebenden und biochemischen Marker fÃ¼r kardiovaskulÃ¤re Ereignisse wird untersucht.",2006,Herz KardiovaskulÃ¤re Erkrankungen
Crustacea Decapoda: les Cyclodorippidae et Cymonomidae de l'Indo-Ouest-Pacifique Ã  l'exclusion du genre Cymonomus,"This is part of a sÃ©ries of papers (TAVARES, 1991a, 1991b, 1992a, 1992b, 1992c) reviewing the Cyclodorippidae Ortmann, 1892, and Cymonomidae Bouvier, 1897, of the world. It contains a review of ail the Cyclodorippidae from the Indo-West Pacific as well as one genus of Cymonomidae. This is a systematic approach preceding a more detailed study of the Cyclodorippoidea morphology and of the phylogenetic relationships within the superfamily. The prÃ©sent work was based upon large collections from the Indo-West Pacific (Madagascar, Japan, Vietnam, Philippines, Indonesia, Australia, Chesterfield Islands, New Caledonia, Loyalty Islands, and Wallis and Futuna Islands) carried out by the following French expÃ©ditions : MUSORSTOM 1-7, BIOCAL, CHALCAL 2, CORAIL 2, KARUBAR, LAGON, and SMIB 6. Also included is the material collected by the ""Siboga"" ExpÃ©dition, 1899, CRUSTACEA DECAPODA : CYCLODORIPPIDAE ET CYMONOMIDAE 255 ""Albatross"", 1908, the material collected by the Russian ocÃ©anographie ships ""Orlik"" in 1960 on the coast of Vietnam and ""Vytiatz"" on the west coast of Australia, two samples made by Raoul SERÃˆNE in Indonesia in during the RUMPHIUS I expÃ©dition in 1973 and RUMPHIUS IV in 1975, as well as collections made by the Australian ship ""Soela"" in 1984 on the north coast of Australia, and others made during the expÃ©dition CiDARis I under the auspices of the James Cook University on the Great Barrier Reef. Additional material from the collections of The Natural History MusÃ©um (British MusÃ©um), London ; MusÃ©um of Comparative Zoology, Massachusetts ; Zoological MusÃ©um of Moscow University ; National Science MusÃ©um, Tokyo ; Northern Territory MusÃ©um of Arts and Science, Darwin ; Queensland MusÃ©um, Brisbane ; South African MusÃ©um, Cape Town ; National MusÃ©um of Natural History, Smithsonian Institution, Washington and ZoÃ´logisch MusÃ©um, Amsterdam was also examined. Because of insufficient original descriptions, the re-examination of ail type spÃ©cimens [except for Tymolus truncatus (Ihle, 1916) which is apparently lost and Genkaia gordonae MiyakÃ© and Takeda, 1970] and most of the spÃ©cimens cited in the literature, was required to properly establish the correspondence between species and the names introduced in the literature. Until now, seven gÃªnera (Tymolus, Corycodus, Xeinostoma, Genkaia, Krangalangia, Ketamia, and Cymonomus) and 23 species of Cyclodorippidae and Cymonomidae were known from the Indo-west Pacific. They are as foUows : Cyclodorippidae : Tymolus japonicus Stimpson, 1858, T. uncifer (Ortmann, 1892), T. dromioides (Ortmann, 1892), T. similis (Grant, 1905), T. truncatus (Ihle, 1916), T. brucei Tavares, 1991, Corycodus disjunctipes (Stebbing, 1910), Xeinostoma eucheir Stebbing, 1920, Krangalangia rostrata (Ihle, 1916), K. spinosa (Zarenkov, 1970), Ketamia depressa (Ihle, 1916), Genkaia gordonae MiyakÃ© and Takeda, 1970. Cymonomidae : Cymonomus valdiviae Lankaster, 1903, C. andamanicus Alcock, 1905, C. indicus Ihle, 1916, C. trifurcus Stebbing, 1920, C. japonicus Balss, 1922, C. curvirostris Sakai, 1965, C. aequilonius Dell, 1971, C. bathamae Dell, 1971, C. delli Griffin and Brown, 1976, C. umitake Takeda, 1981, C. hakuhoae Takeda and Moosa, 1990. From this study : â€” Two new gÃªnera {Phyllotymolinum and Elassopodus) and 11 new species of Cyclodorippoidea are herein described : Cyclodorippidae : Corycodus merweae, C. decorus, Xeinostoma richeri, X. sakaii, Krangalangia orstom, Ketamia handokoi, K. limatula, K. proxima, Genkaia keijii, Phyllotymolinum crosnieri. Cymonomidae : Elassopodus stellatus. â€” Two species are resurrected : Corycodus bouvieri Ihle, 1916, from the synonymy of C. disjunctipes (Stebbing, 1910) and Krangalangia spinosa (Zarenkov, 1970) from the synonymy of A"", rostrata (Ihle, 1916). â€” Four lectotypes are designated hÃ¨re for the following species : Corycodus disjunctipes, Xeinostoma eucheir, Krangalangia rostrata, and Ketamia depressa. Presently, a total of 9 gÃªnera (7 Cyclodorippidae and 2 Cymonomidae) and 34 species (22 Cyclodorippidae and 12 Cymonomidae) are known from the Indo-West Pacific. Ail thÃ¨se species are studied hÃ¨re except those belonging to the genus Cymonomus which will be treated in a future publication. Keys for families, gÃªnera and species are provided as well as illusfrations for ail species.",1993,
High-Dimensional Covariates in the Joint Frailty-Copula Model,"The concerns for over-fitting, high computational cost, and large estimation error arise when the number of covariates is large in a model. We introduce a simple and effective strategy to handle high-dimensional covariates based on Tukeyâ€™s compound covariate method. We then demonstrate how the compound covariate method is applied to the joint frailty-copula model, and how patient-level survival is predicted. Using simulations, we compare the compound covariate method with ridge- and Lasso-based methods in a prediction setting. We analyze the ovarian cancer data for illustration.",2019,
Tuning-Free Heterogeneity Pursuit in Massive Networks,"Heterogeneity is often natural in many contemporary applications involving massive data. While posing new challenges to effective learning, it can play a crucial role in powering meaningful scientific discoveries through the understanding of important differences among subpopulations of interest. In this paper, we exploit multiple networks with Gaussian graphs to encode the connectivity patterns of a large number of features on the subpopulations. To uncover the heterogeneity of these structures across subpopulations, we suggest a new framework of tuning-free heterogeneity pursuit (THP) via large-scale inference, where the number of networks is allowed to diverge. In particular, two new tests, the chi-based test and the linear functional-based test, are introduced and their asymptotic null distributions are established. Under mild regularity conditions, we establish that both tests are optimal in achieving the testable region boundary and the sample size requirement for the latter test is minimal. Both theoretical guarantees and the tuning-free feature stem from efficient multiple-network estimation by our newly suggested approach of heterogeneous group square-root Lasso (HGSL) for high-dimensional multi-response regression with heterogeneous noises. To solve this convex program, we further introduce a tuning-free algorithm that is scalable and enjoys provable convergence to the global optimum. Both computational and theoretical advantages of our procedure are elucidated through simulation and real data examples.",2016,arXiv: Methodology
Weighted SPICE: A unifying approach for hyperparameter-free sparse estimation,"Abstract In this paper we present the SPICE approach for sparse parameter estimation in a framework that unifies it with other hyperparameter-free methods, namely LIKES, SLIM and IAA. 1 Specifically, we show how the latter methods can be interpreted as variants of an adaptively reweighted SPICE method. Furthermore, we establish a connection between SPICE and the l 1 -penalized LAD estimator as well as the square-root LASSO method. We evaluate the four methods mentioned above in a generic sparse regression problem and in an array processing application.",2014,Digit. Signal Process.
Multicenter Development and Validation of a Novel Risk Nomogram for Early Prediction of Severe 2019-Novel Coronavirus Pneumonia,"Background: Severe cases of coronavirus disease 2019 (COVID-19) rapidly develop acute respiratory distress leading to respiratory failure, with remarkably high short-term mortality rates. At present, there is no reliable risk stratification tool for COVID-19 patients. We aimed to construct and validate a model for early identification of severe cases of COVID-19. 
 
Methods: SARS-CoV-2 infected patients from two centers in Guangzhou and one center in Wuhan were included retrospectively, and divided into the train and external validation cohorts. All patients with non-severe COVID-19 during hospitalization were followed for more than 15 days following admission and patients who deteriorated to severe COVID-19 were assigned to the severe group. Least absolute shrinkage and selection operator (LASSO) algorithm and logistic regression model were used to construct a nomogram for risk prediction in the train cohort. The predictive accuracy and discriminative ability of nomogram were evaluated by area under the curve (AUC) and calibration curve. Decision curve analysis (DCA) and clinical impact curve analysis (CICA) were conducted to evaluate the clinical applicability of our nomogram. 
 
Findings: The train cohort consisted of 189 patients, while the two independent validation cohorts consisted of 165 and 18 patients. Among all cases, 72 (19.35%) patients developed severe COVID-19. We generated the nomogram containing one clinical and six serological indicators (age, serum lactate dehydrogenase, C-reactive protein, the coefficient of variation of red blood cell distribution width, blood urea nitrogen, albumin, direct bilirubin) that could early identify severe COVID-19 patients. The nomogram showed remarkably high diagnostic accuracy in distinguishing individuals with severe COVID-19 from non-severe COVID-19 (AUC 0.914 [95% CI 0.852â€“0.976] in the train cohort; 0.856 [0.795-0.916] in validation cohort 1. The calibration curve for probability of severe COVID-19 showed optimal agreement between prediction by nomogram and actual observation. DCA and CICA further indicated that our nomogram conferred significantly high clinical net benefit. 
 
Interpretation: Our nomogram is a potentially useful prediction tool for risk assessment of COVID-19 patients and early identification of severe COVID-19 patients. Risk stratification will enable better management and optimal use of medical resources via patient prioritization and thus significantly reduce mortality rates. 
 
Funding Statement: Science and Technology Program of Guangzhou, China (201804010474) 
 
Declaration of Interests: The author(s) declare(s) that there is no conflict of interest regarding the publication of this paper. 
 
Ethics Approval Statement: The study was approved by the Ethics Committee of the Eighth People's Hospital of Guangzhou (20200547). Written informed consent was waived by the Ethics Commission of the Third Affiliated Hospital of Sun Yat-sen University for emerging infectious diseases.",2020,
Feature Relevance for Kernel Logistic Regression and Application to Action Classification,"An approach is proposed for incorporating feature relevance in mutinomial kernel logistic regression (MKLR) for classification. MKLR is a supervised classification method designed for separating classes with non-linear boundaries. However, it assumes all features are equally important, which may decrease classification performance when dealing with high-dimensional or noisy data. We propose a feature weighting algorithm for MKLR which automatically tunes features contribution according to their relevance for classification and reduces data over-fitting. The proposed algorithm produces more interpretable models and is more generalizable than MKLR, Kernel-SVM and LASSO methods. Application to simulated data and video action classification has provided very promising results compared to the aforementioned classification methods.",2014,2014 22nd International Conference on Pattern Recognition
Combining heterogeneous data sources for civil unrest forecasting,"Detecting and forecasting civil unrest events (protests, strikes, etc.) is of key interest to social scientists and policy makers because these events can lead to significant societal and cultural changes. We analyze protest dynamics in six countries of Latin America on a daily level, from November 2012 through August 2014, using multiple data sources that capture social, political and economic contexts within which civil unrest occurs. We use logistic regression models with Lasso to select a sparse feature set from our diverse datasets, in order to predict the probability of occurrence of civil unrest events in these countries. The models contain predictors extracted from social media sites (Twitter and blogs) and news sources, in addition to volume of requests to Tor, a widely-used anonymity network. Two political event databases and country-specific exchange rates are also used. Our forecasting models are evaluated using a Gold Standard Report (GSR), which is compiled by an independent group of social scientists and experts on Latin America. The experimental results, measured by F1-scores, are in the range 0.68 to 0.95, and demonstrate the efficacy of using a multi-source approach for predicting civil unrest. Case studies illustrate the insights into unrest events that are obtained with our methods.",2015,2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)
Asymptotic Analysis of MAP Estimation via the Replica Method and Compressed Sensing,"The replica method is a non-rigorous but widely-accepted technique from statistical physics used in the asymptotic analysis of large, random, nonlinear problems. This paper applies the replica method to non-Gaussian maximum a posteriori (MAP) estimation. It is shown that with random linear measurements and Gaussian noise, the asymptotic behavior of the MAP estimate of an n-dimensional vector ""decouples"" as n scalar MAP estimators. The result is a counterpart to Guo and Verdu's replica analysis of minimum mean-squared error estimation. 
 
The replica MAP analysis can be readily applied to many estimators used in compressed sensing, including basis pursuit, lasso, linear estimation with thresholding, and zero norm-regularized estimation. In the case of lasso estimation the scalar estimator reduces to a soft-thresholding operator, and for zero norm-regularized estimation it reduces to a hard-threshold. Among other benefits, the replica method provides a computationally-tractable method for exactly computing various performance metrics including mean-squared error and sparsity pattern recovery probability.",2009,
ArCo: An artificial counterfactual approach for high-dimensional panel time-series data,"We consider a new, flexible and easy-to-implement method to estimate thecausal effects of an intervention on a single treated unit when a control group is not available and which nests previous proposals in the literature. It is a two-step methodology where in the first stage, a counterfactual is estimated based on a large-dimensional set of variables from a pool of untreated units by means of shrinkage methods, such as the least absolute shrinkage and selection operator (LASSO). In the second stage, we estimate the average intervention effect on a vector of variables, which is consistent and asymptotically normal. Our results are valid uniformly over a wide class of probability laws. We show that these results hold even when the exact date of the intervention is unknown. Tests for multiple interventions and for contamination effects are derived. By a simple transformation of the variables, it is possible to test for multivariate intervention effects on several moments of the variables of interest. Existing methods in the literature usually test for intervention effects on a single variable and assume that the time of the intervention is known. In addition, high-dimensionality is frequently ignored and inference is either conducted under a set of more stringent hypotheses and/or by permutation tests. A Monte Carlo experiment evaluates the properties of the method in finite samples and compares it with other alternatives. As an application, we evaluate the effects on inflation, GDP growth, retail sales and credit of an anti tax-evasion program.",2018,Journal of Econometrics
Publications en libre accÃ¨s des universitÃ©s du Burkina Faso: analyse dâ€™impact et visibilitÃ© internationale,"Nous avons rendu disponibles, en libre acces sur internet, les collections de memoires et de theses soutenues a lâ€™Universite de Bobo Dioulasso et a lâ€™Universite de Ouagadougou 1 (Burkina Faso). Lâ€™analyse des donnees de consultation (Â« fichiers de log Â» presents sur le serveur hote) permet de produire plusieurs indicateurs concernant lâ€™impact et la visibilite internationale des documents constituants les collections. Nous presentons la repartition temporelle et geographique des consultations, les frequences des acces specifiques a chaque document, la nature des questions, lâ€™impact des moteurs de recherche. Ces resultats montrent quâ€™en mettant a disposition sur Internet des documents scientifiques produits par des institutions africaines, lâ€™importance de leur visibilite et de leur impact peuvent etre demontres en utilisant les donnees de consultation disponibles sur le serveur. La comparaison de ces donnees avec celles disponibles pour les documents en libre acces de lâ€™Institut francais pour le developpement (IRD) permet de conclure que les niveaux de consultation pour les publications scientifiques des pays du Â« Nord Â» et du Â« Sud Â» sont assez similaires. Two major collections of dissertations and theses defended at the University of Bobo Dioulasso and the University of Ouagadougou 1 have been made available open access on the Internet. The data analysis of accesses available via the host server makes it possible to produce several indicators concerning the impact and the international visibility of the available documents. We will present the temporal and geographical distribution of the consultations, the specific frequencies for each document, the nature of the questions, the impact of the search engines. These results seem to show that by making available on the Internet scientific documents produced by African institutions their visibility and impact are demonstrable with the data collected by the server. A comparison of these data with those available for the open access documents of the French Institute for Development (IRD) show that the levels of consultation for scientific publications from ""Northern"" and ""Southern"" countries are quite similar.",2018,027.7 : Zeitschrift fÃ¼r Bibliothekskultur
The linearized alternating direction method of multipliers for sparse group LAD model,"While the least absolute shrinkage and selection operator (LASSO) became a popular method due to its wide applications in high dimensional settings, some generalized LASSO models were developed. The sparse group LASSO is one of the important lasso-type methods, which aims to solve the linear regression problems with grouped covariates and tends to produce a solution with sparse effects both on a group and within group level. At the same time, we know that the least absolute deviation (LAD) is a useful and robust method when the noise distribution may be heavy-tailed or heterogeneous. In this paper, we combine these two classical ideas together to develop sparse group LAD model. We show that the sparse group LAD estimator achieves near oracle performance, i.e., with high probability, the $$L_2$$L2 norm of the estimation error is of order $$O(\sqrt{k\text{ log }p/n}).$$O(klogp/n). Moreover, with the help of the linearization technique we propose the linearized alternating direction method of multipliers to solve the sparse group LAD estimator and establish its convergence. Numerical experiments are reported to illustrate the efficiency of the proposed algorithm.",2019,Optimization Letters
Pushing the Limits of Sparse Support Recovery Using Correlation Information,"A new framework for the problem of sparse support recovery is proposed, which exploits statistical information about the unknown sparse signal in the form of its correlation. A key contribution of this paper is to show that if existing algorithms can recover sparse support of size s, then using such correlation information, the guaranteed size of recoverable support can be increased to O(s2), although the sparse signal itself may not be recoverable. This is proved to be possible by (a) formulating the sparse support recovery problem in terms of the covariance matrix of the measurements, and (b) designing a suitable measurement/sampling matrix which inherently exploits the correlation priors. The so-called Khatri-Rao product of the measurement matrix is shown to play an important role in deciding the level of recoverable sparsity. A systematic analysis of the proposed framework is also presented for the cases when the covariance matrix is only approximately known, by estimating it from finite number of measurements, obtained from the Multiple Measurement Vector (MMV) model. In this case, the use of LASSO on the estimated covariance matrix is proposed for recovering the support. However, the recovery may not be exact and hence a probabilistic guarantee is developed both for sources with arbitrary distribution as well as for Gaussian sources. In the latter case, it is shown that such recovery can happen with overwhelming probability as the number of available measurement vectors increases.",2015,IEEE Transactions on Signal Processing
Markowitz minimum variance portfolio optimization using new machine learning methods,"The use of improved covariance matrix estimators as an alternative to the sample covariance is considered an important approach for enhancing portfolio optimization. In this thesis, we propose the use of sparse inverse covariance estimation for Markowitz minimum variance portfolio optimization, using existing methodology known as Graphical Lasso [16], which is an algorithm used to estimate the inverse covariance matrix from observations from a multivariate Gaussian distribution. We begin by benchmarking Graphical Lasso, showing the importance of regularization to control sparsity. Experimental results show that Graphical Lasso has a tendency to overestimate the diagonal elements of the estimated inverse covariance matrix as the regularization increases. To remedy this, we introduce a new method of setting the optimal regularization which shows performance that is at least as good as the original method by [16]. Next, we show the application of Graphical Lasso in a bioinformatics gene microarray tissue classification problem where we have a large number of genes relative to the number of samples. We perform dimensionality reduction by estimating graphical Gaussian models using Graphical Lasso, and using gene group average expression levels as opposed to individual expression levels to classify samples. We compare classification performance with the sample covariance, and show that the sample covariance performs better. Finally, we use Graphical Lasso in combination with validation techniques that optimize portfolio criteria (risk, return etc.) and Gaussian likelihood to generate new portfolio strategies to be used for portfolio optimization with and without short selling constraints. We compare performance on synthetic and real stock market data with existing covariance estimators in literature, and show that the newly developed portfolio strategies perform well, although performance of all methods depend on the ratio between the estimation period and number of stocks, and on the presence or absence of short selling constraints.",2016,
"Palynology of the Las Curtiembres Formation (Late Cretaceous, Salta Group Basin), Las Conchas Creek area, northwestern Argentina","This study provides the first palynologic record of the Las Curtiembres Formation (Late 
Cretaceous, Salta Group Basin) in northwestern Argentina. Two palynologically productive samples were 
obtained from the Morales Member in the area of the Las Conchas creek, Salta Province. Nineteen morphospecies 
are recorded for the Formation. The samples show poor preservation of the specimens and low 
diversity. The palynomorph association is characterized by the prevalence of species that belong to the 
Ephedraceae (6 species with 57% of total abundance), possibly suggesting semiarid conditions and a 
warm-dry paleoclimate at the time of deposition. Low humidity could also be inferred from the low abundance 
and diversity of pteridophyte species and the presence of Cheirolepidiaceae (Classopollis sp.) and 
Proteaceae (Peninsulapollis gillii (Cookson) Dettmann and Jarzen). The pollen grain Peninsulapollis gillii is 
a chronostratigraphic indicator of an age not older than Campanian-Maastrichtian, which would be coincident 
with the previous dating (77Â±5 Ma) of the Las Conchas Basalt effusions.",2008,Ameghiniana
Machine Learning based Predicting House Prices using Regression Techniques,"Predictive models for determining the sale price of houses in cities like Bengaluru is still remaining as more challenging and tricky task. The sale price of properties in cities like Bengaluru depends on a number of interdependent factors. Key factors that might affect the price include area of the property, location of the property and its amenities. In this research work, an analytical study has been carried out by considering the data set that remains open to the public by illustrating the available housing properties in machine hackathon platform. The data set has nine features. In this study, an attempt has been made to construct a predictive model for evaluating the price based on the factors that affect the price. Modeling explorations apply some regression techniques such as multiple linear regression (Least Squares), Lasso and Ridge regression models, support vector regression, and boosting algorithms such as Extreme Gradient Boost Regression (XG Boost). Such models are used to build a predictive model, and to pick the best performing model by performing a comparative analysis on the predictive errors obtained between these models. Here, the attempt is to construct a predictive model for evaluating the price based on factors that affects the price.",2020,2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)
"Palynology of Jurassic (Bathonian) sediments from Donbas, northeast Ukraine","A palynological and sedimentological study of an outcrop succession adjacent to the village of Kamyanka within the Kharkiv region of northeast Ukraine was carried out. The successions occur within the Dnieperâ€“Donets Basin, which hosts vast successions (>â€‰20Â km) of post mid-Devonian strataÂ and is one of the main hydrocarbon-producing basins in Europe. Middle Jurassic sandstones, siltstones and claystones represent the sedimentary successions at the Kamyanska locality.Â Few palynological studies have been performed on the Jurassic of Ukraine and even fewer presented in the international literature. Thirty spore taxa and 21 pollen taxa were identified, together with taxa kept in open nomenclature (e.g. bisaccate pollen). Two palynological assemblages were identified within the Kamyanska succession (assemblages A and B) dated as Bathonian. Assemblage A is dominated by the fern spores (Cyathidites and Osmundacidites) and gymnosperm pollen produced by Cupressaceae (Perinopollenites elatoides), ginkgophytes/Cycadales/Bennettitales (monosulcates) and Cheirolepidiaceae (Classopollis). Assemblage BÂ differs in also comprising high abundances of GleicheniiditesÂ and higher percentages of Pinuspollenites and AraucariacitesÂ compared toÂ assemblage A. Another difference between the two units is the high relative abundance of seed fern pollen (Alisporites) in the upper part of assemblage B.Â The thermal alteration index (TAI) of the palynomorphs is estimated to range from 3 to 3.5, indicating a burial depth corresponding to the mature main phase of liquid petroleum and, to some extent, gas generation. Comparisons between the miospore and macrofloral assemblages show that the palynoflora and macroflora are strongly similar at broad taxonomic levels. Importantly, the miospore assemblages described here compare well with European Middle Jurassic assemblages indicating limitedÂ provincialism, withÂ similar vegetation extending from eastern Ukraine and across most of Western Europe.",2018,Palaeobiodiversity and Palaeoenvironments
Robust Lasso Variable Selection for Factorial Experiments Analysis with Application,"Many experiments have encountered problems in selecting the best model when the responses are non-normally distributed and especially when the number of factors is small. In this article, we propose to combine the lasso variable selection and robust method (Huber loss function), when the responses are distributed according to epsilon-skew-Laplace (ESL) distribution. The proposed modification (robust lasso) is compared to the traditional lasso and adaptive lasso for the analysis factorial experiment with two level for each factor. A simulation study and real data are conducted to investigate the performance of the proposed method. We employed the mean square errors to select the best model and the results show that the proposed method using robust lasso variable selection performs well.",2018,International journal of statistics and applications
"An evaluation of machine-learning for predicting phenotype: studies in yeast, rice, and wheat","In phenotype prediction the physical characteristics of an organism are predicted from knowledge of its genotype and environment. Such studies, often called genome-wide association studies, are of the highest societal importance, as they are of central importance to medicine, crop-breeding, etc. We investigated three phenotype prediction problems: one simple and clean (yeast), and the other two complex and real-world (rice and wheat). We compared standard machine learning methods; elastic net, ridge regression, lasso regression, random forest, gradient boosting machines (GBM), and support vector machines (SVM), with two state-of-the-art classical statistical genetics methods; genomic BLUP and a two-step sequential method based on linear regression. Additionally, using the clean yeast data, we investigated how performance varied with the complexity of the biological mechanism, the amount of observational noise, the number of examples, the amount of missing data, and the use of different data representations. We found that for almost all the phenotypes considered, standard machine learning methods outperformed the methods from classical statistical genetics. On the yeast problem, the most successful method was GBM, followed by lasso regression, and the two statistical genetics methods; with greater mechanistic complexity GBM was best, while in simpler cases lasso was superior. In the wheat and rice studies the best two methods were SVM and BLUP. The most robust method in the presence of noise, missing data, etc. was random forests. The classical statistical genetics method of genomic BLUP was found to perform well on problems where there was population structure. This suggests that standard machine learning methods need to be refined to include population structure information when this is present. We conclude that the application of machine learning methods to phenotype prediction problems holds great promise, but that determining which methods is likely to perform well on any given problem is elusive and non-trivial.",2019,Machine Learning
Accompervising: a grounded theory on the LaSallian Supervision of De La Salle Supervised Schools in the Philippines.,"Title of the Research: ACCOMPERVISING: A GROUNDED THEORY ON THE LASALLIAN SUPERVISION OF DE LA SALLE SUPERVISED SCHOOLS IN THE PHILIPPINES Author: BROTHER DENNIS M. MAGBANUA FSC Degree: Doctor of Philosophy Major: Educational Management Date of Completion: February 2015 The purpose of this grounded theory study is to uncover the understanding of Lasallian school supervision in the Philippines. The classical Grounded Theory method of Glaser and Strauss (1967) using Open Coding, Constant-Comparison, Axial Coding, Memoing, Selective Coding and the constructivist approach of Charmaz (2006) to Grounded Theory were used as guides to answer how Lasallian supervision is understood and lived by the major stakeholders (La Salle Brothers, LASSSAI Board members, LASSO regional superintendents, supervisors, school owners, school heads, faculty, staff and students) of the De La Salle supervised schools system. A total of 25 major stakeholders were interviewed and non-technical literature such as minutes of the Board meetings, assessment reports, and other significant documents were analyzed with the aid of a qualitative analysis software known as HyperResearch by Researchware and the Conditional Matrix of Strauss and Corbin (1998).",2015,
