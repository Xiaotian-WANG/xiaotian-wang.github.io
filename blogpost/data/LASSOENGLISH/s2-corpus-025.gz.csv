title,abstract,year,journal
Comparison of Penalized Cox Regression Methods in Low-Dimensional Data with Few-Events: An Application to Dialysis Patients' Data.,"BACKGROUND
Dialysis is a dominant therapeutic method in patients with chronic renal failure. The ratio of those who experienced the event to the predictor variables is expressed as event per variable (EPV). When EPV is low, one of the common techniques which may help to manage the problem is penalized Cox regression model (PCRM). The aim of this study was to determine the survival of dialysis patients using the PCRM in low-dimensional data with few events.


STUDY DESIGN
A cross-sectional study.


METHODS
Information of 252 dialysis patients of Bandar Abbas hospitals, southern Iran, from 2010-16 were used. To deal with few mortality cases in the sample, the PCRM (lasso, ridge and elastic net, adaptive lasso) were applied. Models were compared in terms of calibration and discrimination.


RESULTS
Thirty-five (13.9%) mortality cases were observed. Dialysis data simulations revealed that the lasso had higher prediction accuracy than other models. For one unit of increase in the level of education, the risk of mortality was reduced by 0.32 (HR=0.68). The risk of mortality was 0.26 (HR=1.26) higher for the unemployed than the employed cases. Other significant factors were the duration of each dialysis session, number of dialysis sessions per week and age of dialysis onset (HR=0.93, 0.95 and 1.33).


CONCLUSION
The performance of penalized models, especially the lasso, was satisfying in low-dimensional data with low EPV based on dialysis data simulation and real data, therefore these models are the good choice for managing of this type of data.",2019,Journal of research in health sciences
Differentialequationswithstate-dependentpiecewise constantargument,"a b s t r a c t Anewclassofdifferentialequationswithstate-dependentpiecewiseconstantargumentis introduced.Itisanextensionofsystemswithpiecewiseconstantargument.Fundamental theoretical results for the equationsthe existence and uniqueness of solutions, the existence of periodic solutions, and the stability of the zero solutionare obtained. Appropriateexamplesareconstructed. â€™2010ElsevierLtd.Allrightsreserved.",2010,
Lost in Translation: On the Problem of Data Coding in Penalized Whole Genome Regression with Interactions,"Mixed models can be considered as a type of penalized regression and are everyday tools in statistical genetics. The standard mixed model for whole genome regression (WGR) is ridge regression best linear unbiased prediction (RRBLUP) which is based on an additive marker effect model. Many publications have extended the additive WGR approach by incorporating interactions between loci or between genes and environment. In this context of penalized regressions with interactions, it has been reported that translating the coding of single nucleotide polymorphisms -for instance from -1,0,1 to 0,1,2- has an impact on the prediction of genetic values and interaction effects. In this work, we identify the reason for the relevance of variable coding in the general context of penalized polynomial regression. We show that in many cases, predictions of the genetic values are not invariant to translations of the variable coding, with an exception when only the sizes of the coefficients of monomials of highest total degree are penalized. The invariance of RRBLUP can be considered as a special case of this setting, with a polynomial of total degree 1, penalizing additive effects (total degree 1) but not the fixed effect (total degree 0). The extended RRBLUP (eRRBLUP), which includes interactions, is not invariant to translations because it does not only penalize interactions (total degree 2), but also additive effects (total degree 1). This observation implies that translation-invariance can be maintained in a pair-wise epistatic WGR if only interaction effects are penalized, but not the additive effects. In this regard, approaches of pre-selecting loci may not only reduce computation time, but can also help to avoid the variable coding issue. To illustrate the practical relevance, we compare different regressions on a publicly available wheat data set. We show that for an eRRBLUP, the relevance of the marker coding for interaction effect estimates increases with the number of variables included in the model. A biological interpretation of estimated interaction effects may therefore become more difficult. Consequently, comparing reproducing kernel Hilbert space (RKHS) approaches to WGR approaches modeling effects explicitly, the supposed advantage of an increased interpretability of the latter may not be real. Our theoretical results are generally valid for penalized regressions, for instance also for the least absolute shrinkage and selection operator (LASSO). Moreover, they apply to any type of interaction modeled by products of predictor variables in a penalized regression approach or by Hadamard products of covariance matrices in a mixed model.",2019,G3: Genes|Genomes|Genetics
Response of nematode communities after largeâ€scale iceâ€shelf collapse events in the Antarctic Larsen area,"Owing to large-scale ice-shelf disintegration events, the Antarctic Larsen A and B areas recently became ice-free. During the ANT-XXIII/8 Polarstern campaign, this region was sampled for the first time. Our study is the first to investigate benthic communities in this area and their response to the collapse of ice shelves in the Antarctic. The nematofauna appears to be strongly influenced by the sudden ice-cover removal, although its response differs from that of the macro- and megabenthos. Our results indicate that precollapse, sub-ice communities were impoverished and characterized by low densities, low diversity and high dominance of a few taxa. This might still be visible at a station located deep inside the Larsen B embayment, where Halomonhystera was dominant. Post-collapse recolonization of the â€˜innerâ€™ stations, i.e. those located furthermost from the former ice-shelf edge, is believed to be a long-time process. At the time of sampling, community structure at the inner stations was not or only slightly influenced by colonization, and might be structured by local environmental conditions. Our results indicate that a locally increased food supply after ice-cover removal could provoke a faster, local response of the nematode assemblages compared with the response due to recolonization. Thalassomonhystera is recognized as an opportunist, taking advantage of increased food supply at inner stations A_South and B_North. Communities living close to the former ice-shelf edge are believed to be at an intermediate or late stage of succession, with a dominance of Microlaimus, a common Antarctic genus and quick colonizer. Densities here were comparable with those at other Antarctic stations, whereas they were considerably decreased at the inner stations. In general, the collapse of the Larsen ice shelves initially has a positive effect on the shelf nematode fauna in the area, both in terms of abundance and diversity.",2010,Global Change Biology
Distributed cognitive spectrum sensing via group sparse total least-squares,"Dynamic re-use of licensed bands under the hierarchical spectrum access paradigm calls for innovative network-level sensing algorithms for spectrum opportunity awareness in the frequency, time, and space dimensions. Toward this direction, the present paper develops a distributed spectrum sensing algorithm whereby cognitive radios (CRs) cooperate to localize active primary user (PU) transmitters, and estimate their transmit-power spectral densities. The sensing scheme relies on a parsimonious linear system model that accounts for two forms of sparsity: one due to the narrow-band nature of PU transmissions compared to the large swath of monitored frequencies; and another one emerging when employing a spatial grid of candidate PU locations. Capitalizing on this dual sparsity, and combining the merits of Lasso, group Lasso, and total least-squares (TLS), a group sparse (GS) TLS problem is formulated to obtain hierarchically-sparse model estimates, and cope with model uncertainty induced by channel randomness, and grid-induced model offsets. The GS-TLS problem is collaboratively solved by the CRs in a distributed fashion, using only local message exchanges among neighboring nodes. In spite of the non-convexity of the GS-TLS criterion, the novel distributed algorithm has guaranteed convergence to (at least) a locally optimal solution. The analytical findings are corroborated by numerical tests.",2011,2011 4th IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)
Two-stage LASSO ADMM signal detection algorithm for large scale MIMO,"This paper explores the benefit of using some of the machine learning techniques and Big data optimization tools in approximating maximum likelihood (ML) detection of Large Scale MIMO systems. First, large scale MIMO detection problem is formulated as a LASSO (Least Absolute Shrinkage and Selection Operator) optimization problem. Then, Alternating Direction Method of Multipliers (ADMM) is considered in solving this problem. The choice of ADMM is motivated by its ability of solving convex optimization problems by breaking them into smaller sub-problems, each of which are then easier to handle. Further improvement is obtained using two stages of LASSO with interference cancellation from the first stage. The proposed algorithm is investigated at various modulation techniques with different number of antennas. It is also compared with widely used algorithms in this field. Simulation results demonstrate the efficacy of the proposed algorithm for both uncoded and coded cases.",2017,"2017 51st Asilomar Conference on Signals, Systems, and Computers"
"Distribution , density , and sequestration of host chemical defenses by the specialist nudibranch Tritonia hamnerorum found at high densities on the sea fan","The dendronotid nudibranch Tritonia hamnerorurn was observed on some reefs In the Flonda Keys, USA, at very high densities dunng the summer of 1992 T hamnerorum specializes on the sea fan Gorgonia vental~na and sequesters the furano-germacrene lulieannafuran from its host, this compound effectively protects the nudibranch from consumption by the common predatoiy reef f ~ s h Thalassoma bifasciatum T hamnerorum densit~es were extremely hlgh at some locations, with as Inany as 1700 nudibranchs found on a single G ventalina colony At high densities, nudibranch feeding killed large areas on some sea fan colonies by stnpping all tissue from portions of the sea fan and allowing fllamentous algae and other epibionts to colonize The density of T hamnerorum on G ventahna vaned greatly on scales of centimeters meters and k~lometers High density patches of nudlbranchs on individual sea fans were usually composed of equivalent-sized nudtbranchs These observations suggest that pelagic vellgers have an incredible capabil~ty to find and settle synchronously on one portion of a sea fan or that the larvae or luveniles hatch from egg masses and develop without leaving the sea fan This study adds to a growlng number of manne examples suggesting that feeding specialization occurs pnmardy among small sedentary consumers that deter or escape predators by associating w t h defended hosts",2006,
Adherence to therapy for Barrettâ€™s esophagus-associated neoplasia,"Objectives Multiple endoscopic sessions may be necessary for treatment and surveillance of Barrettâ€™s esophagus (BE)-associated neoplasia. Adherence to an endoscopic therapeutic regimen is important for longitudinal management of BE. The objective of this study was to identify the factors associated with adherence to therapy for BE-associated neoplasia. Methods We retrospectively identified patients with BE whom were referred to a tertiary center for endoscopic mucosal resection (EMR) or radiofrequency ablation (RFA) between 2009 and 2012. Demographic and clinical data were extracted from the medical record. Results We had 69 subjects meet our inclusion criteria. Referral diagnosis was low-grade dysplasia in 9 (13%) subjects, high-grade dysplasia in 33 (48%) subjects and adenocarcinoma in 26 (38%) subjects. The majority (55%) lived more than 100 miles from the treatment center. The primary third-party payer was US Medicare for 54% of the subjects and private insurance for 36% of them; 45% of the subjects were seen in the clinic by the treating endoscopist, prior to endoscopic therapy and 71% underwent EMR as the initial treatment, while 29% underwent RFA without prior EMR. We found that 72% of subjects were adherent to therapy, including: 23 (33%) completing endoscopic therapy with documented post-treatment surveillance, 18 (26%) with ongoing endoscopic therapy, and 9 (13%) whom underwent esophagectomy. Subjects seen in gastroenterology clinical consultation were significantly more likely to demonstrate adherence than those referred for open access endoscopy (Lasso OR 2.31). Conclusions Patients seen in a clinical consultation prior to endoscopic therapy for BE-associated neoplasia were more likely to demonstrate treatment adherence, compared to patients referred for open-access endoscopy. A clinic visit prior to therapy may define expectations regarding treatment course and increase the likelihood of patient adherence.",2016,United European Gastroenterology Journal
Black holes with quantum massive spin-2 hair,"We show that black holes can posses a long range quantum-mechanical hair associated with a massive spin-2 field, which can be detected by a stringy generalization of the Aharovon-Bohm effect, in which a string loop lassoes the black hole. The long distance effect persist for arbitrarily high mass of the spin-2 field. An analogous effect is exhibited by a massive antisymmetric two-form field. We make a close parallel between the two and the ordinary Aharonov-Bohm phenomenon, and also show that in the latter case the effect can be experienced even by the electrically-neutral particles, provided some boundary terms are added to the action.",2006,Physical Review D
Projective Splitting with Forward Steps: Asynchronous and Block-Iterative Operator Splitting,"This work is concerned with the classical problem of finding a zero of a sum of maximal monotone operators. For the projective splitting framework recently proposed by Combettes and Eckstein, we show how to replace the fundamental subproblem calculation using a backward step with one based on two forward steps. The resulting algorithms have the same kind of coordination procedure and can be implemented in the same block-iterative and potentially distributed and asynchronous manner, but may perform backward steps on some operators and forward steps on others. Prior algorithms in the projective splitting family have used only backward steps. Forward steps can be used for any Lipschitz-continuous operators provided the stepsize is bounded by the inverse of the Lipschitz constant. If the Lipschitz constant is unknown, a simple backtracking linesearch procedure may be used. For affine operators, the stepsize can be chosen adaptively without knowledge of the Lipschitz constant and without any additional forward steps. We close the paper by empirically studying the performance of several kinds of splitting algorithms on the lasso problem.",2018,ArXiv
"Geoarchaeological investigations of the â€œpotters' quarterâ€ at Sagalassos, southwest Turkey","The potters' quarter of the ancient city of Sagalassos, southwest Turkey, was one of the largest and most enduring ceramic-producing manufactories in the eastern Mediterranean. The objective of our study was to determine environmental circumstances that favored development of different clay resources in the territory of Sagalassos and to assess utilization of these resources in the local pottery manufactory. The potters' quarter was established where, owing to favorable geological circumstances, a large clay body had developed. The bedrock in the potters' quarter, a tectonized ophiolite sequence, has synclinal structure; hence, surface runoff and groundwater tend to accumulate in its center. The weathering of the basic rock formed a smectite-rich clay with vertic properties. This clay was mined in antiquity, and mineralogical and chemical analyses indicate that it was used for the production of local ceramics from Hellenistic to Byzantine times. It is likely that colluvium on top of the ophiolitic clay at the potters' quarter is related to deforestation and slope processes after the potters' quarter was abandoned. In sum, environmental circumstances determined the location of the artisanal quarter of Sagalassos, with its clay quarrying operation and ceramic manufactory. However, for the local mass-produced Sagalassos red slip ware, the results of our chemical and mineralogical analyses indicate that a different, more suitable clay was used: detrital lake sediments, rich in chlorite and chlorite/smectite mixed layers, located about 8 km from the original artisanal quarter. The choice for this clay was determined both by the presence of a suitable clay deposit, as well as socio-economic circumstances such as land ownership. The site of Sagalassos yielded unique evidence of mining of clay at a ceramic production site, as well as import of nearby clays. The local and imported clays were used side-by-side, but one for the production of common wares and building ceramics, and the other for the manufacturing of luxury fine tablewares. Â© 2003 Wiley Periodicals, Inc.",2003,Geoarchaeology-an International Journal
"Gaetbulicola byunsanensis gen. nov., sp. nov., isolated from tidal flat sediment.","A Gram-negative, non-motile and pleomorphic bacterial strain, SMK-114(T), which belongs to the class Alphaproteobacteria, was isolated from a tidal flat sample collected in Byunsan, Korea. Strain SMK-114(T) grew optimally at pH 7.0-8.0 and 25-30 degrees C and in the presence of 2 % (w/v) NaCl. A neighbour-joining phylogenetic tree based on 16S rRNA gene sequences showed that strain SMK-114(T) formed a cluster with Octadecabacter species, with which it exhibited 16S rRNA gene sequence similarity values of 95.2-95.4 %. This cluster was part of the clade comprising Thalassobius species with a bootstrap resampling value of 76.3 %. Strain SMK-114(T) exhibited 16S rRNA gene sequence similarity values of 95.1-96.3 % to members of the genus Thalassobius. It contained Q-10 as the predominant ubiquinone and C(18 : 1)omega7c as the major fatty acid. The DNA G+C content was 60.0 mol%. On the basis of phenotypic, chemotaxonomic and phylogenetic data, strain SMK-114(T) is considered to represent a novel species in a new genus for which the name Gaetbulicola byunsanensis gen. nov., sp. nov. is proposed. The type strain of Gaetbulicola byunsanensis is SMK-114(T) (=KCTC 22632(T) =CCUG 57612(T)).",2010,International journal of systematic and evolutionary microbiology
Identifying Genetic Associations with MRI-derived Measures via Tree-Guided Sparse Learning,"In recent imaging genetic studies, much work has been focused on regression analysis that treats large-scale single nucleotide polymorphisms (SNPs) and quantitative traits (QTs) as association variables. To deal with the weak detection and high-throughput data problem, feature selection methods such as the least absolute shrinkage and selection operator (Lasso) are often used for selecting the most relevant SNPs associated with QTs. However, one problem of Lasso as well as many other feature selection methods for imaging genetics is that some useful prior information, i.e., the hierarchical structure among SNPs throughout the whole genome, are rarely used for designing more powerful model. In this paper, we propose to identify the associations between candidate genetic features (i.e., SNPs) and magnetic resonance imaging (MRI)-derived measures using a tree-guided sparse learning (TGSL) method. The advantage of our method is that it explicitly models the priori hierarchical grouping structure among the SNPs in the objective function for feature selection. Specifically, two kinds of hierarchical structures, i.e., group by gene and group by linkage disequilibrium (LD) clusters, are imposed as a tree-guided regularization term in our sparse learning model. Experimental results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database show that our method not only achieves better predictions on the two MRI measures (i.e., left and right hippocampal formation), but also identifies the informative SNPs to guide the disease-induced interpretation compared with other reference methods.",2014,Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention
"SuchtreizreaktivitÃ¤t bei Patienten mit AlkoholabhÃ¤ngigkeit, gemessen mittels Nah-Infrarot-Spektroskopie (NIRS)","22 alkoholabhangige Probanden und 24 gesunde Kontrollpersonen wurden im Rahmen von Expositionssitzungen, sowohl mit neutralen als auch mit alkoholassoziierten Reizen unterschiedlicher Modalitaten (in vivo, visuell, taktil, imaginar) konfrontiert. Ziel der Studie war, die neuralen hamodynamischen Reaktionen der Versuchsteilnehmer wahrend den Expositionssitzungen anhand der NIRS (Nah-Infrarot Spektroskopie) in bestimmten Kortexregionen zu messen und unter Berucksichtigung der unterschiedlichen Suchtreizmodalitaten, der zeitlichen Persistenz, des Cravings und der Gruppenunterschiede in Bezug auf mogliche Suchtreiz-Reaktivitatsphanomene zu prufen und zu vergleichen. Das Craving vor und nach den Expositionssitzungen wurde anhand der deutschen Version des ACQ (Alcohol Craving Questionnaire) erhoben. Zusammenfassend ist zu bestatigen, dass alkoholabhangige Patienten eine sich von gesunden Normen unterscheidende neurale Reaktion auf suchtbezogene Reize aufweisen â€“ im Sinne einer ROI-bezogenen Cue-Reaktivitat. Diese lasst sich jedoch anhand der vorliegenden Ergebnisse nur schwer prazisieren oder quantifizieren. Die bestehende Divergenz der erzielten Ergebnisse deutet auf mogliche reiz- bzw. sinnesspezifische Suchtreiz-Reaktivitatsmechanismen, welche in einem agonisierenden-antagonisierenden Zusammenspiel eine wesentliche Rolle bei der Entstehung von Cue-Clustering-Phanomenen und der Entwicklung von Craving spielen konnten. Es gibt auch Hinweise fur eine abnehmende ACR uber die Zeit unter abstinenten Bedingungen. Dieses wird durch die Feststellung uber die progrediente Reduktion von subjektivem Craving gestutzt.%%%%22 alcohol-dependent patients and 24 healthy controls, were confronted with neutral and alcohol associated stimuli or ""cues"" in different modalities (in vivo, visual, tactile, imaginative). The main goal of the study was to measure the neural haemodynamic reactions of the participants by means of Near-Infrared-Spectroscopy during the exposure sessions. Different cue modalities, the persistence over time of a possible cue reactivity, differences in craving and between both groups were considered and compared. Craving was assessed before and after the exposure sessions by menas of the german version of the ACQ (Alcohol Craving Questionnaire). We could confirm that patients showed a different neural reaction to dependancy related stimuli in terms of a ROI-related Cue-Reactivity. A divergence of results suggest specific and individual cue-reactivity-mechanisms for different cue-modalities, which may be in agonistic and antagonistic interactions and thus play a substantial role in the developement of cue-clustering-phenomena and craving. Results also suggest a decreasing alcohol-cue-reactivity (ACR) over time under abstinence. These results are confirmed by an accompanying decrease of self-reported craving.",2010,
Supplement to â€œ on Cross-validated Lasso in High Dimensions,"7. Simulations. In this section, we present results of our simulation experiments. The purpose of the experiments is to investigate finite-sample properties of the cross-validated Lasso estimator. In particular, we are interested in (i) comparing the estimation error of the cross-validated Lasso estimator in different norms to the Lasso estimator based on other choices of Î»; (ii) studying sparsity properties of the cross-validated Lasso estimator; and (iii) estimating probability of the event (6) for Î» = Î»Ì‚, the cross-validation choice of Î». We consider two data generating processes (DGPs). In both DGPs, we simulate the vector of covariatesX = (X1, . . . , Xp) â€² from the Gaussian distribution with mean zero and variance-covariance matrix given by E[XjXk] = Ï|jâˆ’k| for all j, k = 1, . . . , p with Ï = 0.5 and 0.75. Also, we set Î² = (1,âˆ’1, 2,âˆ’2, 01Ã—(pâˆ’4)). We simulate Îµ from the standard Gaussian distribution in DGP1 and from the uniform distribution on [âˆ’3, 3] in DGP2. For both DGPs, we take Îµ to be independent of X. Further, for each DGP, we consider samples of size n = 100 and 400. For each DGP and each sample size, we consider p = 40, 100, and 400. To construct the candidate set Î›n of values of the penalty parameter Î», we use Assumption 4 with a = 0.9, c1 = 0.005 and C1 = 500. Thus, the set Î›n contains values of Î» ranging from 0.0309 to 500 when n = 100 and from 0.0071 to 500 when n = 400, that is, the set Î›n is rather large in both cases. In all experiments, we use 5-fold cross-validation (K = 5). We repeat each experiment 5000 times. As a comparison to the cross-validated Lasso estimator, we consider the Lasso estimators with Î» chosen according to [12] and [2], i.e., Î» = nâˆ’1/2Ïƒ âˆš 2 log p and Î» = nâˆ’1/2Ïƒ âˆš 2 log(p/s)",2020,
"High-Dimensional LASSO-Based Computational Regression Models: Regularization, Shrinkage, and Selection","Regression models are a form of supervised learning methods that are important for machine learning, statistics, and general data science. Despite the fact that classical ordinary least squares (OLS) regression models have been known for a long time, in recent years there are many new developments that extend this model significantly. Above all, the least absolute shrinkage and selection operator (LASSO) model gained considerable interest. In this paper, we review general regression models with a focus on the LASSO and extensions thereof, including the adaptive LASSO, elastic net, and group LASSO. We discuss the regularization terms responsible for inducing coefficient shrinkage and variable selection leading to improved performance metrics of these regression models. This makes these modern, computational regression models valuable tools for analyzing high-dimensional problems.",2019,Machine Learning and Knowledge Extraction
Adaptive boosting of weak regressors for forecasting of crop production considering climatic variability: An empirical assessment,"Abstract Crop yield forecasting based on different climatic conditions for coastal regions is a critical process. In this study, regression based adaptive boosting prediction model is presented, using the datasets of Kharif and Rabi seasons along with the climatic features of three coastal districts belonging to Odisha located in India. This study discusses and experiments on the different weak regressors, such as: linear, lasso, ridge, SVR regression, proposes strong predictors by avoiding the shortcomings of individual weak regressors and propagating the benefits of AdaBoost to improve the predictive accuracy on learning problems. AdaBoost helps to get a combined output of the weak regressors into a weighted sum that represents the final output of the boosted strong regressor and also the output of the weak regressors which is likely to be twisted in favour of wrongly predicted instances adaptively. It has been observed from the experiments that, the decision of weak regressors vary due to frequent, inherent attributes of climatic conditions for crop production. Obtained numerical simulation results in terms of errors, various performance measures and statistical analysis demonstrated have highlighted the attractiveness of the proposed strong regressors compared to weak regressors forecasting methods for crop production.",2017,Journal of King Saud University - Computer and Information Sciences
New Algorithms andMethodology forAnalysing Distances,"Distances arise in a wide variety of diï¿½erent contexts, one of which is partitional clustering, 
that is, the problem of ï¿½nding groups of similar objects within a set of objects.?ese 
groups are seemingly very easy to ï¿½nd for humans, but very diï¿½cult to ï¿½nd for machines 
as there are two major diï¿½culties to be overcome: the ï¿½rst deï¿½ning an objective criterion 
for the vague notion of â€œgroups of similar objectsâ€, and the second is the computational 
complexity of ï¿½nding such groups given a criterion. In the ï¿½rst part of this thesis, we focus 
on the ï¿½rst diï¿½culty and show that even seemingly similar optimisation criteria used 
for partitional clustering can produce vastly diï¿½erent results. In the process of showing 
this we develop a new metric for comparing clustering solutions called the assignment 
metric. We then prove some new NP-completeness results for problems using two related 
â€œsum-of-squaresâ€ clustering criteria. 
Closely related to partitional clustering is the problem of hierarchical clustering. We 
extend and formalise this problem to the problem of constructing rooted edge-weighted 
X-trees, that is trees with a leafset X. It is well known that an X-tree can be uniquely 
reconstructed from a distance on X if the distance is an ultrametric. But in practice the 
complete distance on X may not always be available. In the second part of this thesis we 
look at some of the circumstances under which a tree can be uniquely reconstructed from 
incomplete distance information. We use a concept called a lasso and give some theoretical 
properties of a special type of lasso. We then develop an algorithm which can construct 
a tree together with a lasso from partial distance information and show how this can be 
applied to various incomplete datasets.",2014,
Nondegenerate Piecewise Linear Systems: A Finite Newton Algorithm and Applications in Machine Learning,"We investigate Newton-type optimization methods for solving piecewise linear systems (PLSs) with nondegenerate coefficient matrix. Such systems arise, for example, from the numerical solution of linear complementarity problem, which is useful to model several learning and optimization problems. In this letter, we propose an effective damped Newton method, PLS-DN, to find the exact (up to machine precision) solution of nondegenerate PLSs. PLS-DN exhibits provable semiiterative property, that is, the algorithm converges globally to the exact solution in a finite number of iterations. The rate of convergence is shown to be at least linear before termination. We emphasize the applications of our method in modeling, from a novel perspective of PLSs, some statistical learning problems such as box-constrained least squares, elitist Lasso (Kowalski & Torreesani, 2008), and support vector machines (Cortes & Vapnik, 1995). Numerical results on synthetic and benchmark data sets are presented to demonstrate the effectiveness and efficiency of PLS-DN on these problems.",2012,Neural Computation
Title Support for a Simplified Uplink-Only Relaying Mode Date Submitted 11 / 07 / 2006 Source ( s ),"Providing support for a simplified uplink-only relaying mode in the P802.16j context. Purpose Adoption of proposed text into P802.16j Notice This document has been prepared to assist IEEE 802.16. It is offered as a basis for discussion and is not binding on the contributing individual(s) or organization(s). The material in this document is subject to change in form and content after further study. The contributor(s) reserve(s) the right to add, amend or withdraw material contained herein. Release The contributor grants a free, irrevocable license to the IEEE to incorporate material contained in this contribution, and any modifications thereof, in the creation of an IEEE Standards publication; to copyright in the IEEEâ€™s name any IEEE Standards publication even though it may include portions of this contribution; and at the IEEEâ€™s sole discretion to permit others to reproduce in whole or in part the resulting IEEE Standards publication. The contributor also acknowledges and accepts that this contribution may be made public by IEEE 802.16. Patent Policy and Procedures The contributor is familiar with the IEEE 802.16 Patent Policy and Procedures , including the statement ""IEEE standards may include the known use of patent(s), including patent applications, provided the IEEE receives assurance from the patent holder or applicant with respect to patents essential for compliance with both mandatory and optional portions of the standard."" Early disclosure to the Working Group of patent information that might be relevant to the standard is essential to reduce the possibility for delays in the development process and increase the likelihood that the draft publication will be approved for publication. Please notify the Chair  as early as possible, in written or electronic form, if patented technology (or technology under patent application) might be incorporated into a draft standard being developed within the IEEE 802.16 Working Group. The Chair will disclose this notification via the IEEE 802.16 web site . 2006-11-07 IEEE C802.16j-06_160 1 Support for a Simplified Uplink-Only Relaying Mode K. Baum, B. Classon, M. Cudak, S. Ramachadran, P. Sartori, E. Visotsky Motorola Introduction The introduction of relaying for IEEE802.16 can serve several purposes, such as range extension, gap filling, and increased data rates near the edge of a cell. As explained in [1] and [2], relaying is especially beneficial for the uplink, since a SS transmits at a much lower power level than a BS. Because of this power difference, the downlink is often interference-limited while the uplink is often thermal-noise-limited even for a reasonable cell radius (e.g., 2 km). Therefore, although the standard must in general be capable of supporting relaying on both the downlink and uplink, there is significant value in including support for a simplified uplink-only relaying mode as well. The main purpose of this contribution is to propose a simplified uplink-only relaying mode for inclusion in the overall 802.16j standard. In this simplified mode, downlink transmissions are not relayed at all, which can significantly reduce the complexity of the relay station, reduce downlink overhead, and simplify route management and handoff. The solution presented here has the following advantages: 1. The uplink-only RS (U-RS) is a simplified unit that only needs to perform a few layer-one operations and a minimal set of layer-two tasks. 2. One or more U-RS can be deployed in each sector. A particular U-RS does not need to be aware of other U-RS. 3. The BS always remains in control of the transmission, thereby resulting in increased transmission reliability. 4. The architecture still permits hybrid-ARQ (HARQ) to be performed on the uplink. As a side benefit, the signaling and route selection methods developed for the uplink-only relaying mode may also be used as part of the full two-way relaying mode. In particular, for a two-way relaying scheme that chooses uplink and downlink routes independently, the uplink-only mode described here can be used for managing the uplink part of the relaying. Moreover, if a two-way relay is deployed where downlink relaying would not be particularly helpful, it should be possible to completely turn off the downlink relaying portion of the relay and have it act as an uplink-only relay. General Description The disparity in PA power between SS and BS suggests that a solution can be tailored to provide the necessary assistance to the uplink while not being involved in the downlink. As a result, cost efficiencies can be achieved by creating a subordinate relationship between relays and the BS allowing the RS to be low cost while ensuring robust reliable transmission supervised by a central authority. The cost efficiencies may be realized by reducing RS complexity such that it only focuses on layer-one operations and a minimal set of layer-two tasks. System Configuration and Operation Figure 1 depicts the possible communication pathways between BSs, SS, and U-RS. Figure 1a) shows the typical communication paths in a cellular system with the U-RS disabled. A BS coordinates the resources in the cell by distributing control information and arbitrating access requests. In addition, the BS transmits data directly to the SS and receives data directly from an SS. Figure 1b) shows the communication paths with the URS enabled. In this case, the BS still coordinates resources in the cell by distributing control information and arbitrating access requests. Additionally, the BS continues to transmit data directly to the SS. However, the 2006-11-07 IEEE C802.16j-06_160 2 uplink data from the SS follows a triangular path first being received and detected by the U-RS then re-encoded and transmitted to the BS by the U-RS. Figure 1 c) and d) show two variations on the U-RS configuration. Figure 1c) shows multiple active U-RS simultaneously repeating the SS data to the BS. Figure 1d) shows the simultaneous co-existence of a relayed and non-relayed uplink communication. In accordance with the 802.16j requirements, the SS is completely unaware of the existence of a relay within in the system. Note that in Figure 1, and throughout this contribution, another intermediate RS may play the role of the BS. U-RS BS SS control data",2006,
A Data-Driven Approach for Detecting and Quantifying Modeling Biases in Geo- Ontologies by Using a Discrepancy Index,"GIScience 2016 Short Paper Proceedings A Data-Driven Approach for Detecting and Quantifying Modeling Biases in Geo-Ontologies Using a Discrepancy Index Bo Yan, Krzysztof Janowicz, and Yingjie Hu STKO Lab, Department of Geography, University of California, Santa Barbara, USA {boyan,jano,yingjiehu}@geog.ucsb.edu Abstract Geo-ontologies play an important role in fostering the publication, retrieval, reuse, and integration of geographic data within and across domains. The status quo of geo-ontology engineering often follows a centralized top-down approach, namely a group of domain experts collaboratively formalizing key concepts and their relationships. On the one hand, such an approach makes use of the invaluable knowledge and experience of subject matter experts and captures their perception of the world. On the other hand, however, it can introduce biases and ontological commitments that do not well correspond to the data that will be semantically lifted using these ontologies. In this work, we propose a data-driven method to calculate a Discrepancy Index in order to identify and quantify the potential modeling biases in current geo-ontologies. In other words, instead of trying to measure quality, we determine how much the ontology diâ†µers from what would be expected when looking at the data alone. Keywords: geo-ontology; ontology engineering; DBpedia; Linked Data; Discrepancy Index Introduction Due to the diverse and eclectic nature of geographic information, geographic data usually comes from diâ†µerent sources, in diâ†µerent formats, and are conceptualized from diâ†µerent perspectives. These hetero- geneities in terms of provenance and standards create a barrier for integrating data to perform more comprehensive analysis. Geo-ontologies provide a promising way to alleviate this long-standing issue by enabling a flexible integration of geographic information based on semantics, i.e., regardless of represen- tational choices and syntax. However, the common ways in which geo-ontologies are developed top-down by a team of knowledge engineers and domain experts carry the risk of generating biased or unsuitable geo-ontologies (Hu and Janowicz, 2016). To give a concrete example, in the current version of DBpediaâ€™s ontology (DBpedia 2015-10), the class Canal is classified as a sibling class of River, and both are defined as subclasses of Stream. This seems to be a rational classification at first glance since canals are usually channels of water. However, Stream is a subclass of BodyOfWater and BodyOfWater is a subclass of NaturalPlace. Due to the transitivity of the rdfs:subClassOf relationship, canals become natural places. However, this seems like an odd modeling choice as canals are defined as â€œan artificial waterway constructed to allow the passage of boats or ships inland or to convey water for irrigationâ€ according to the Oxford dictionary. Words such as â€œartificialâ€ and â€œconstructedâ€ make canals man-made features rather than natural place. This example indicates that top-down geo-ontologies may suâ†µer from the issues such as modeling biases, oversights, and ontological commitments that do not well represent the real data needs. Scrutinizing the geo-ontologies and making revisions manually on a regular basis are common solutions to such problems. But such methods are usually labor-intensive and create a gap between the geo-ontology and its corresponding Linked Dataset. In this research, we introduce initial results on a Discrepancy Index that helps geo-ontology engineers by detecting and quantifying potential issues using a series of data mining steps. Proposed Method Our approach consists of two parallel threads. The first thread comes from Linked Datasets that are transformed from unstructured data, such as Wikipedia pages. This thread focuses on the bottom-up",2016,
A no-reference bitstream-based perceptual model for video quality estimation of videos affected by coding artifacts and packet losses,"In this work, we propose a No-Reference (NR) bitstream-based model for predicting the quality of H.264/AVC video sequences, affected by both compression artifacts and transmission impairments. The proposed model is based on a feature extraction procedure, where a large number of features are calculated from the packet-loss impaired bitstream. Many of the features are firstly proposed in this work, and the specific set of the features as a whole is applied for the first time for making NR video quality predictions. All feature observations are taken as input to the Least Absolute Shrinkage and Selection Operator (LASSO) regression method. LASSO indicates the most important features, and using only them, it is possible to estimate the Mean Opinion Score (MOS) with high accuracy. Indicatively, we point out that only 13 features are able to produce a Pearson Correlation Coefficient of 0.92 with the MOS. Interestingly, the performance statistics we computed in order to assess our method for predicting the Structural Similarity Index and the Video Quality Metric are equally good. Thus, the obtained experimental results verified the suitability of the features selected by LASSO as well as the ability of LASSO in making accurate predictions through sparse modeling.",2015,
â€œPreconditioningâ€ for feature selection and regression in high-dimensional problems,"We consider regression problems where the number of predictors greatly exceeds the number of observations. We propose a method for variable selection that first estimates the regression function, yielding a ""preconditioned"" response variable. The primary method used for this initial regression is supervised principal components. Then we apply a standard procedure such as forward stepwise selection or the LASSO to the preconditioned response variable. In a number of simulated and real data examples, this two-step procedure outperforms forward stepwise selection or the usual LASSO (applied directly to the raw outcome). We also show that under a certain Gaussian latent variable model, application of the LASSO to the preconditioned response variable is consistent as the number of predictors and observations increases. Moreover, when the observational noise is rather large, the suggested procedure can give a more accurate estimate than LASSO. We illustrate our method on some real problems, including survival analysis with microarray data.",2008,Annals of Statistics
"Biochemical characterization of a novel cold-adapted agarotetraose-producing Î±-agarase, AgaWS5, from Catenovulum sediminis WS1-A","Although many Î²-agarases that hydrolyze the Î²-1,4 linkages of agarose have been biochemically characterized, only three Î±-agarases that hydrolyze the Î±-1,3 linkages are reported to date. In this study, a new Î±-agarase, AgaWS5, from Catenovulum sediminis WS1-A, a new agar-degrading marine bacterium, was biochemically characterized. AgaWS5 belongs to the glycoside hydrolase (GH) 96 family. AgaWS5 consists of 1295 amino acids (140 kDa) and has the 65% identity to an Î±-agarase, AgaA33, obtained from an agar-degrading bacterium Thalassomonas agarivorans JAMB-A33. AgaWS5 showed the maximum activity at a pH and temperature of 8 and 40 Â°C, respectively. AgaWS5 showed a cold-tolerance, and it retained more than 40% of its maximum enzymatic activity at 10 Â°C. AgaWS5 is predicted to have several calcium-binding sites. Thus, its activity was slightly enhanced in the presence of Ca2+, and was strongly inhibited by EDTA. The Km and Vmax of AgaWS5 for agarose were 10.6 mg/mL and 714.3 U/mg, respectively. Agarose-liquefication, thin layer chromatography, and mass and NMR spectroscopic analyses demonstrated that AgaWS5 is an endo-type Î±-agarase that degrades agarose and mainly produces agarotetraose. Thus, in this study, a novel cold-adapted GH96 agarotetraose-producing Î±-agarase was identified.",2019,Applied Microbiology and Biotechnology
LASSO Experiment Intercalibration Trip for the Two LASSO Ranging Stations,"Abstract : In order to achieve the accuracy of the LASSO time transfer between OCA, Grasse, France and McDonald Observatory, Texas, USA, an intercalibration of the two Laser Ranging Stations was made. At the same stations, GPS receivers were set up and the GPS to Laser epoch differences were also monitored. In addition to the principle and the results of the measurements, the cause of the difficulties met during the campaign will be described.",1994,
Atrial fibrillation ablation in a patient with a peculiar common postero-inferior pulmonary vein trunk,"A 76-year-old woman was referred for symptomatic drug resistant atrial fibrillation catheter ablation. Before the procedure, contrastenhanced, ECG-synchronized, computed tomography angiography (CTA; Lightspeed VCT 64, General Electric, USA) was performed showing an atypical pulmonary vein (PV) anatomy: the two superior (right and left) PVs had normal separate ostia, while the two inferior PVs had a common postero-inferior trunk (Figure 1A,B); supernumerary PVs were absent. The oesophagus was located close to the posterior portion of this unusual common postero-inferior trunk (Figure 1C). Transoesophageal echocardiogram was performed the day before the procedure to exclude the presence of left atrial/ appendage thrombi. A 3D reconstruction of the left atrium (LA) was performed through a circular mapping catheter (LassoR , Biosense Webster, USA) and an irrigated ablation catheter (ThermoCool SmartTouchR SF, Biosense Webster, USA) using the CartoR 3 electroanatomic mapping system (Biosense Webster, USA) and then merged with the CTA acquisition. In the absence of pre-acquired atrial imaging, as in more than half of the Electrophysiology labs in Europe, it would surely have been highly challenging to correctly recognize this atypical anatomy and to perform a safe and efficacious ablation procedure. In addition, given the wide diameter (27 35 mm), this atypical trunk would have likely caused a puzzling procedure if approached by cryoballoon (maximum balloon diameter 28 mm). Superior PVs isolation was performed by point-by-point radiofrequency (RF) ablation in power control mode (Smartablate RF generator, Stockert, Germany) at 40 W (irrigation flow 15 mL/min), ablation index (AI) value of 500 in the anterior wall and 35 W, AI of 380â€“400 in the posterior wall. Considering the peculiar anatomy and proximity to the oesophagus, electrical isolation of the common postero-inferior trunk was obtained by RF application on the ridge of the posterior LA wall (Figure 1Dâ€“F) using reduced energy (15â€“20 W, irrigation flow 8 mL/ min) and AI of 380. The endpoint was complete PV isolation, confirmed by the absence of PV potentials on the LassoR catheter after RF delivery. Following the procedure, the patient was stable and, therefore discharged asymptomatic in second post-operative day. At 120-day follow-up, she remained asymptomatic and no arrhythmic relapses have been reported.",2019,European Heart Journal: Case Reports
The group fused Lasso for multiple change-point detection,"We present the group fused Lasso for detection of multiple change-points shared by a set of co-occurring one-dimensional signals. Change-points are detected by approximating the original signals with a constraint on the multidimensional total variation, leading to piecewise-constant approximations. Fast algorithms are proposed to solve the resulting optimization problems, either exactly or approximately. Conditions are given for consistency of both algorithms as the number of signals increases, and empirical evidence is provided to support the results on simulated and array comparative genomic hybridization data.",2011,arXiv: Quantitative Methods
Data-Driven-Based Approach to Identifying Differentially Methylated Regions Using Modified 1D Ising Model,"Background
DNA methylation is essential for regulating gene expression, and the changes of DNA methylation status are commonly discovered in disease. Therefore, identification of differentially methylation patterns, especially differentially methylated regions (DMRs), in two different groups is important for understanding the mechanism of complex diseases. Few tools exist for DMR identification through considering features of methylation data, but there is no comprehensive integration of the characteristics of DNA methylation data in current methods.


Results
Accounting for the characteristics of methylation data, such as the correlation characteristics of neighboring CpG sites and the high heterogeneity of DNA methylation data, we propose a data-driven approach for DMR identification through evaluating the energy of single site using modified 1D Ising model. Applied to both simulated and publicly available datasets, our approach is compared with other popular methods in terms of performance. Simulated results show that our method is more sensitive than competing methods. Applied to the real data, our method can identify more common DMRs than DMRcate, ProbeLasso, and Wang's methods with a high overlapping ratio. Also, the necessity of integrating the heterogeneity and correlation characteristics in identifying DMR is shown through comparing results with only considering mean or variance signals and without considering relationship of neighboring CpG sites, respectively. Through analyzing the number of DMRs identified in real data located in different genomic regions, we find that about 90% DMRs are located in CGI which always regulates the expression of genes. It may help us understand the functional effect of DNA methylation on disease.",2018,BioMed Research International
Quantitative Biomarkers for Prediction of Epidermal Growth Factor Receptor Mutation in Non-Small Cell Lung Cancer,"OBJECTIVES
To predict epidermal growth factor receptor (EGFR) mutation status using quantitative radiomic biomarkers and representative clinical variables.


METHODS
The study included 180 patients diagnosed as of non-small cell lung cancer (NSCLC) with their pre-therapy computed tomography (CT) scans. Using a radiomic method, 485 features that reflect the heterogeneity and phenotype of tumors were extracted. Afterwards, these radiomic features were used for predicting epidermal growth factor receptor (EGFR) mutation status by a least absolute shrinkage and selection operator (LASSO) based on multivariable logistic regression. As a result, we found that radiomic features have prognostic ability in EGFR mutation status prediction. In addition, we used radiomic nomogram and calibration curve to test the performance of the model.


RESULTS
Multivariate analysis revealed that the radiomic features had the potential to build a prediction model for EGFR mutation. The area under the receiver operating characteristic curve (AUC) for the training cohort was 0.8618, and the AUC for the validation cohort was 0.8725, which were superior to prediction model that used clinical variables alone.


CONCLUSION
Radiomic features are better predictors of EGFR mutation status than conventional semantic CT image features or clinical variables to help doctors to decide who need EGFR tyrosine kinase inhibitor (TKI) treatment.",2018,Translational Oncology
Prospective validation of the Glasgow Meningococcal Septicaemia Prognostic Score. Comparison with other scoring methods,"Abstract. A prospective observational study was done to derive performance characteristics for the Glasgow Meningococcal Septicaemia Prognostic Score (GMSPS) and compare it with nine other severity scores (Stokland, Stiehm and Damrosch, Ansari, Niklasson, Leclerc, Kahn and Blum, Lewis, Istanbul and Bjark) and laboratory markers of disease severity. In the paediatric departments of six hospitals in Merseyside, UK, 278 children with confirmed or probable meningococcal disease were admitted between November 1988 and August 1990 (n=152) and between September 1992 and April 1994 (n=126); 26 of whom died. GMSPS was recorded on admission and again if there was clinical deterioration. Laboratory markers of disease severity (including endotoxin and cytokine levels) were measured on admission. The nine other scores were recorded on the first cohort. ""Maximum"" GMSPS (before referral to the paediatric intensive care unit) was achieved within 12Â h of arrival in 97% of children. A GMSPS â‰¥8 had sensitivity 100%, specificity 75% and positive predictive value for death of 29%, GMSPS â‰¥10 had 100%, 88% and 46% respectively. All 26 who died scored >10, before referral to the paediatric intensive care unit. GMSPSs calculated by other medical staff had similar characteristics to those calculated by research fellows. All scores correlated significantly with white cell count, coagulopathy, endotoxin and cytokine levels. However, the predominantly clinical scores were the most robust. GMSPS had amongst the best performance characteristics of all scores and was more sensitive than laboratory markers. Conclusion: the Glasgow Menigoccocal Septicaemia Prognostic Score is an easily performed, repeatable, clinical score that can rapidly identify children with fulminant meningococcal disease. When performed prospectively, a score â‰¥8 had a positive predictive value for death of 29%. This score can identify those children who should be offered intensive care and can select those who may benefit from novel therapies.",2002,European Journal of Pediatrics
Large-Scale Spatiotemporal Density Smoothing with the Graph-fused Elastic Net: Application to Ride-sourcing Driver Productivity Analysis.,"Ride-sourcing or transportation network companies (TNCs) provide on-demand transportation service for compensation, connecting drivers of personal vehicles with passengers through the use of smartphone applications. This article considers the problem of estimating the probability distribution of the productivity of a driver as a function of space and time. We study data consisting of more than 1 million ride-sourcing trips in Austin, Texas, which are scattered throughout a large graph of 223k vertices, where each vertex represents a traffic analysis zone (TAZ) at a specific hour of the week. We extend existing methods for spatial density smoothing on very large general graphs to the spatiotemporal setting. Our proposed model allows for distinct spatial and temporal dynamics, including different degrees of smoothness, and it appropriately handles vertices with missing data, which in our case arise from a fine discretization over the time dimension. Core to our method is an extension of the Graph-Fused Lasso that we refer to as the Graph-fused Elastic Net (GFEN).",2019,arXiv: Applications
Effect of color on some geometric attributes of visual appearance of non-effect coatings,"The aim of the present study was to investigate the effect of color attributes of appearance on the corresponding geometric attributes of appearance of non-effect coatings. Three scales, namely gloss, distinctness of image, and orange peel for three achromatic (black, gray, and white) and four chromatic (red, green, blue, and yellow) basecoats, each at varying levels, were prepared. The gloss and the distinctness of image scales had a sample with a maximum degree of gloss and distinctness of image, respectively, and the orange peel scale had a sample with a minimum degree of orange peel, which was considered to be the standard sample. The visual differences between the standard sample and those remaining in each scale were assessed by a panel of 28 observers using a prepared one-dimensional lightness scale based on the CIELAB and CIEDE2000 color difference equations. The correlations between visual and instrumental measurements of scales were checked, and instrumental performance with respect to visually assessed equivalent differences in gloss, distinctness of image, and orange peel were determined, giving STRESS (standardized residual sum of squares) valuesâ€‰=â€‰24.3, 11.6, and 9.7, respectively, in terms of CIELAB. ANOVA together with simple, lasso, and ridge regressions were applied to test the effect of color on the geometric attributes of appearance. The results illustrate that color attributes of appearance have no adverse significant effect on the main geometric attributes of appearance for non-effect coatings.",2020,Journal of Coatings Technology and Research
"Eastern Caribbean Circulation and Island Mass Effect on St. Croix, US Virgin Islands: A Mechanism for Relatively Consistent Recruitment Patterns","The northeastern Caribbean Sea is under the seasonal influence of the Trade Winds but also of the Orinoco/Amazon freshwater plume. The latter is responsible for intensification of the Caribbean Current in general and of its eddy activity in the northern part of the Caribbean Sea. More importantly, we show in this study that the front of the freshwater plume drives a northward flow that impinges directly on the island of St. Croix in the United States Virgin Islands. The angle of incidence of the incoming flow controls the nature of the wake on both sides and ends of the island, which changes from cyclonic to anticylonic wake flow, with either attached or shed eddies. Using an off-line bio-physical model, we simulated the dispersal and recruitment of an abundant Caribbean coral reef fish, the bluehead wrasse (Thalassoma bifasciatum) in the context of the wake flow variability around St. Croix. Our results revealed the role played by the consistent seasonal forcing of the wake flow on the recruitment patterns around the island at the interannual scale. The interannual variability of the timing of arrival and northward penetration of the plume instead controls the nature of the wake, hence the regional spatial recruitment patterns.",2016,PLoS ONE
Mapping mineral chemistry of a lateritic outcrop in new Caledonia through generalized regression using Sentinel-2 and field reflectance spectra,"Abstract Mining is fundamental for human development, yet it currently requires innovative spatial techniques as it faces diverse environmental and social pressures. With the free Sentinel-2 data of the Copernicus programme, new opportunities arise for studies related to nickel laterite, especially with its reported potential in mapping iron-oxide. This work utilizes samples from drill-holes extracted from Tiebaghi, New Caledonia. The chemical composition and the hyperspectral reflectance of each sample are obtained. The reflectance spectra are resampled to Sentinel-2's characteristics, and generalized linear regression was used to accurately predict Fe2O3, MgO, SiO2, Al2O3, and nickel content where three regression approaches were compared: Ridge, Elastic Net, and the Least Absolute Shrinkage and Selection Operator (LASSO). With the resulting regression models, mineral chemistry of an outcrop in the vicinity of the drill-holes is mapped by a scene of Sentinel-2. The work shows the great potential of free satellite imagery in mapping chemical characteristics of minerals and rocks. It opens up great opportunities for monitoring outcrops and for achieving more efficient mineral exploration.",2018,Int. J. Appl. Earth Obs. Geoinformation
"Community Values, Domestic Tranquility, and Customary Law in Upper Volta","The theme of this article is the decline of customary law in Upper Volta where, like most countries in Africa, customary courts operate side by side with the modern, ex-colonial legal system. 1 My study of Le Tribunal de Premier Instance in Bobodioulasso suggests that customary courts may not in fact apply customary law. An examination of the criteria and the process by which decisions are reached here may help us to gain an insight into the function the Court serves for the community.",1978,Journal of Modern African Studies
The methodological study of segmental isolation of pulmonary veins during atrial fibrillation,"Objective To investigate the efficacy and safety of segmental electrical isolation of pulmonary veins (PVs) during atrial fibrillation (AF) Methods Nine patients were included, of whom 4 had recently persistent AF (3ï½ž4 months) and 5 suffored from paroxysmal AF occurred AF frequently We adopted one transseptal procedure Lasso mapping catheter and ablation catheter were positioned into target pulmonary vein ostium through the same site of atrial septum RF ablation was applied at the pulmonary vein potential (PVP) breakthrough using thermo control RF catheter during AF Results Twenty nine PVs were targeted for segmental RF ablation and isolated completely PVPs in target PVs were in higher spike and more frequent than left atrial potentials There were no complications associated with the procedure Seven patients were converted to sinus rhythm during the procedure Two patients restored sinus rhythm by cardioversion Conclusion It is suggested that the method of segmental PV isolation during AF is safe and has higher success rate It is not necessary to stop antiarrhymic drugs before RF ablation This study provides a reliable method for segmental electrical isolation of pulmonary veins in patients with persistent AF",2004,Chinese Journal of Interventional Cardiology
Detection of BRAF V 600 mutations in melanoma : evaluation of concordance between the Cobas Â® 4800 BRAF V 600 mutation test and the methods used in French National Cancer Institute ( INCa ) platforms in a real-life setting,"Vemurafenib is approved for the treatment of metastatic melanoma in patients with BRAF V600 mutation. In pivotal clinical trials, BRAF testing has always been done with the approved cobas 4800 BRAF test. In routine practice, several methods are available and are used according to the laboratories usual procedures. A national, multicenter, non-interventional study was conducted with prospective and consecutive collection of tumor samples. A parallel evaluation was performed in routine practice between the cobas 4800 BRAF V600 mutation test and home brew methods (HBMs) of 12 national laboratories, labelled and funded by the French National Cancer Institute (INCa). For 420 melanoma samples tested, the cobas method versus HBM showed a high concordance (93.3%; kappa = 0.86) in BRAF V600 genotyping with similar mutation rates (34.0% versus 35.7%, respectively). Overall, 97.4% and 98.6% of samples gave valid results using the cobas and HBM, respectively. Of the 185 samples strictly fulfilling the cobas guidelines, the concordance rate was even higher (95.7%; kappa = 0.91; 95%CI [0.85; 0.97]). Out of the 420 samples tested, 28 (6.7%) showed discordance between HBM and cobas. This prospective study shows a high PLOSONE | DOI:10.1371/journal.pone.0120232 March 19, 2015 1 / 12 OPEN ACCESS Citation: Mourah S, Denis MG, Narducci FE, Solassol J, Merlin J-L, Sabourin J-C, et al. (2015) Detection of BRAF V600 Mutations in Melanoma: Evaluation of Concordance between the Cobas 4800 BRAF V600 Mutation Test and the Methods Used in French National Cancer Institute (INCa) Platforms in a Real-Life Setting. PLoS ONE 10(3): e0120232. doi:10.1371/journal.pone.0120232 Academic Editor: John Matthew Koomen, Moffitt Cancer Center, UNITED STATES Received: July 21, 2014 Accepted: January 20, 2015 Published: March 19, 2015 Copyright: Â© 2015 Mourah et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Data Availability Statement: All relevant data are within the paper. Funding: Roche France and INCa for funding tests. The funders participated in study design, data collection and analysis, decision to publish, or preparation of the manuscript. Competing Interests: The authors have read the journal's policy and have the following competing interests: SM: Scientific committee board concordance rate between the cobas 4800 BRAF V600 test and home brew methods in the routine detection of BRAF V600E mutations.",2018,
Taxonomic Study of Agar-degrading Bacteria from Deep-sea,"The main source of agar in Japan is Gelidtum amansii (Rhodophyceae). Agarose consists of a linear chain of alternating residues 3-O-linked !-D-galactopyranose and 4-O-linked 3,6-anhydro-""-L-galactose. A range of genera of agar-degrading bacteria including Proteobactera, Bacteroides-Flavobacterium-Cytophaga, Gram-positive bacteria and Actinobacteria are currently known. Most of these bacteria have been isolated from marine coastal environments. A number of agar-degrading bacteria produce !-agarase and hydrolyze only !-1,4 linkages in agarose. In contrast, ""-agarase, which hydrolyzes ""-1,3 linkages, are poorly understood, and to date there has been few report of ""-agarase. In addition, there have been no reports of agar-degrading bacteria isolated from the deep-sea environment. In this study, we attempted to isolate agar-degrading bacteria from environmental samples from various depths from the deep-sea. Phylogenetic analyses and identification of these isolated bacteria were performed. We collected 34 samples depths of 200-7400 m of the vicinity of Japan and isolated 60 strains of agar-degrading bacteria from these samples. Isolated bacteria were in two different forms; a cone-shaped hollow form and a column-shaped hollow form. Comparative analysis of 16S rRNA gene sequences showed that all isolated strains were included in #-Proteobacteria, and the majority of isolates were identified as genus Microbulbifer, with a minority of isolates identified as Agarivorans or Thalassomonas. Detailed identification to the species level was performed on samples from Microbulbifer and Thalassomonas. Our results describe three novel species in the genus Microbulbifer and one novel species in the genus Thalassomonas.",2007,
Methods for Analyzing the 12 Run Plackett-Burman Design,"In the early stages of an experimental analysis it is often of interest to determine the most important factors. The main goal of this master thesis is to study and compare different methods for determining the active factors in a 12 run Plackett-Burman experiment. The methods discussed in this thesis are the Dantzig selector, a graphical Dantzig selector, a projection based Dantzig selector, the Lasso, a projection based method, the partial F-test, a graphical method using orthogonalization and the residual variance of fitted models. The methods were implemented in R and applied to data generated from a total of 15 different models. The form of these models vary in terms of the number of active factors and the presence of interaction effects. This diversity of models facilitate exposure of strengths, weaknesses and limitations of the methods. From the study conducted in this thesis it was confirmed that methods using the Dantzig selector perform significantly better for designs following the uniform uncertainty principle. The results produced by the Lasso were found to be relatively close to what was obtained by the Dantzig selector. Further, it was found that a combination of the projection based method, residual variance of fitted models and the graphical method using orthogonalization together form a highly valuable procedure for determining active factors.",2014,
Modified concatemeric oligonucleotide complexes: new system for efficient oligonucleotide transfer into mammalian cells.,"Antisense oligonucleotides and double-stranded small interfering RNAs have become an important instrument for the manipulation of gene expression in molecular biology experiments and a promising tool for the development of gene-targeted therapeutics. One of the main impediments in the use of oligonucleotide-based therapeutics is their poor uptake by target cells. The formation of supramolecular concatemeric complexes by oligonucleotides was shown to promote their binding to various mammalian cells [Simonova, O.N.,Vladimirova, A.V., Zenkova, M.A., and Vlassov, V.V. (2006). Biochim. Biophys. Acta 1758, 413-418]. We attempted to improve the efficiency of oligonucleotide concatemer delivery into cells by the attachment of lipophilic cholesterol molecules to the components of concatemeric complexes. Uptake, cellular distribution, and biological activity of the supramolecular complexes formed by delivered antisense oligonucleotides and cholesterol-modified ""carrier"" oligonucleotides were studied. Our results demonstrate that incorporation of an antisense oligonucleotide into the self-assembling concatemeric system promotes its delivery into cells without the addition of any supplementary transfection agents and allows achieving specific inhibition of the target gene expression.",2008,Human gene therapy
Incorporating LASSO effects into a mixed model for quantitative trait loci detection,The identification of quantitative trait loci (QTL) can be viewed as a subset selection problem. In a simulation study the least absolute selection and shrinkage operator (LASSO) is shown to be a useful and powerful tool for QTL identification. LASSO effects are embedded into a mixed model allowing simultaneous modeling of genetic and experimental effects. This provides the flexibility to model the experiment in conjunction with the power of LASSO QTL identification. Estimation is performed using an approximation to the restricted likelihood and modified Gaussian elimination. The extended mixed model is used to analyze a cattle gene mapping dataset.,2007,"Journal of Agricultural, Biological, and Environmental Statistics"
Selective sampling after solving a convex problem,"We consider the problem of selective inference after solving a (randomized) convex statistical learning program in the form of a penalized or constrained loss function. Our first main result is a change-of-measure formula that describes many conditional sampling problems of interest in selective inference. Our approach is model-agnostic in the sense that users may provide their own statistical model for inference, we simply provide the modification of each distribution in the model after the selection. 
Our second main result describes the geometric structure in the Jacobian appearing in the change of measure, drawing connections to curvature measures appearing in Weyl-Steiner volume-of-tubes formulae. This Jacobian is necessary for problems in which the convex penalty is not polyhedral, with the prototypical example being group LASSO or the nuclear norm. We derive explicit formulae for the Jacobian of the group LASSO. 
To illustrate the generality of our method, we consider many examples throughout, varying both the penalty or constraint in the statistical learning problem as well as the loss function, also considering selective inference after solving multiple statistical learning programs. Penalties considered include LASSO, forward stepwise, stagewise algorithms, marginal screening and generalized LASSO. Loss functions considered include squared-error, logistic, and log-det for covariance matrix estimation. 
Having described the appropriate distribution we wish to sample from through our first two results, we outline a framework for sampling using a projected Langevin sampler in the (commonly occuring) case that the distribution is log-concave.",2016,arXiv: Statistics Theory
Selective Inhibition Of Histone Deacetylases,"Reversible lysine acetylation serves as a critical regulatory pathway for diverse cellular processes. As a result, the dysregulation of proteinaceous acetyl-L-lysine hydrolysis is connected to severe medical conditions including neurological disorders, immune dysfunction, and cancer. Inhibition of the enzymes responsible for catalyzing this reaction, histone deacetylases (HDACs), has demonstrated promising results as a route to clinical intervention in many of these diseases. Of the 18 known HDACs, 11 are metal-dependent enzymes that have similar mechanisms and each regulates the function of numerous protein substrates in vivo. This frustrates the design of small molecules targeting a single isozyme, meaning that modern FDA-approved HDAC inhibitors exhibit various side effects that make them less-than-optimal for broad clinical application. This thesis describes the characterization of HDACâ€“inhibitor complexes by crystallography, supported by thermodynamic and enzymological measurements, focusing on a class I enzyme, HDAC8, and a class IIb enzyme, HDAC6. Structural analysis of complexes with inhibitors exhibiting classor isozyme-selective activity has illuminated the structural underpinnings of isozyme-selective HDAC inhibition. For instance, irreversible inhibition of class I HDACs by the epoxyketone-based inhibitor trapoxin A is due to the conformation of the epoxide group, rather than a long-presumed covalent modification in the active site. With regard to HDAC6, selective hydroxamates exhibit an unusual monodentate metal-coordination mode mediated by steric interactions at the protein surface. HDAC6 is also predisposed to be inhibited by hydroxamates over other isozymes due to a unique entropic gain associated with inhibitor binding. Finally, mercaptoacetamides serve as an alternative, non-genotoxic zinc-binding group that can exploit subtle mechanistic differences between isozymes. Taken together, these studies have constructed a framework for the design of selective HDAC inhibitors for better-targeted therapeutics. Degree Type Dissertation Degree Name Doctor of Philosophy (PhD) Graduate Group Chemistry First Advisor David W. Christianson",2019,
A Framework to Incorporate D-trace Loss into Compositional Data Analysis,"The development of high-throughput sequencing technologies for 16S rRNA gene profiling provides higher quality compositional data for microbe communities. Inferring the direct interaction network under a specific condition and understanding how the network structure changes between two different environmental or genetic conditions are two important topics in biological studies. However, the compositional nature and high dimensionality of the data are challenging in the context of network and differential network recovery. To address this problem in the present paper, we proposed a framework to incorporate the data transformations developed for compositional data analysis into D-trace loss for network and differential network estimation, respectively. The sparse matrix estimators are defined as the minimizer of the corresponding lasso penalized loss. This framework is characterized by its straightforward application based on the ADMM algorithm for numerical solution. Simulations show that the proposed method outperforms other state-of-the-art methods in network and differential network inference under different scenarios. Finally, as an illustration, our method is applied to a mouse skin microbiome data. Author summary Inferring the direct interactions among microbes and how these interactions change under different conditions are important to understand community-wide dynamics. The compositional nature and high dimensionality are two distinctive features of microbial data, which invalidate traditional correlation analysis and challenge interaction network estimation. In this study, we set up a framework that combines data transformation with D-trace loss to infer the direct interaction network and differential network from compositional data. Simulations and real data analysis show that our proposed methods lead to results with higher accuracy and stability.",2018,bioRxiv
"Religionsfrihet enligt den nya skollagen, en analys av vilken syn SFS 2010:800: s reglering av konfessionella friskolor ger pÃ¥ religionsfrihet","The secularization of formerly Christian countries in Europe and the immigration to these countries has led to a great religious diversity. This new situation has made the question about religious freedom a highly debated topic. It concerns that of what freedom of religion should consist of, i.e. whose and what religious freedom should prevail? 
According to Maria Klasson Sundin, clergyman and PhD in philosophy of religion at the theological department at Uppsala University, then a person, organization or government views on what should be included in religious freedom depends on how it looks on the concepts of religion, freedom and autonomy. Sundin has developed three models for religious freedom which this paper uses to analyze the view on freedom of religion that the new Swedish Education Act's regulations of denominational schools convey. The law says that confessional element may occur in the education but not in the teaching. 
The conclusion of this thesis is that the law primarily conveys a functionalist view of religion and religious freedom. The law can be seen as a pragmatic compromise between two more idealistic approaches.",2011,
Determination of General Circulation Model Domain Using LASSO to Improve Rainfall Prediction Accuracy in West Java,The Statistical downscaling technique has often been used to predict rainfall. This technique needsa domain of general circulation model (GCM) data. The selection of GCM domain is an important factor to improvepredictionaccuracy.The goal of this study is to determine the optimum domain. This study uses GCM data from CFSRv2 with gridresolution 2.5Â°Ã—2.5Â°and local rainfall data in West Java. The GCM domain is determined basedon minimum correlation value of 0.3 between GCM data and local rainfall data. Correlations are calculated for the grid in the four directions of the compass with one grid as the reference that straightly above the local rainfall station. The domains are evaluated using the regression model with L1 (LASSO) regularization. The result showed that the optimum domain was 8Ã—5 grids.,2020,
"[Fishes of the Cabo Pulmo reef, Gulf of California, Mexico: systematic list and aspects of abundance and biogeography].","The Cabo Pulmo reef is the most important coral formation of the Gulf of California; however, its ichthyological fauna has been poorly studied. To produce a systematic list with data on relative abundance and frequency, and biogeographical affinities, we relied on visual census, field observations, analysis of commercial and sport fisheries (from 1986 to 1998), and the literature. A total of 236 species have been recorded at Cabo Pulmo (155 genera and 60 families). This number doubles previous compilations and represents 65.1% of all reef fishes known from the Gulf of California, and about 35% of its entire shallow-water fishes. Of the total species number, 68.3% are from the Panamic Province, 11.0% Indo Pacific colonizers and the same percentage gulf endemics, 7.6% are circumtropical, 1.7% Atlantic and 0.5% cosmopolitan; none are endemic to the reef. The most abundant taxa are the labrids Thalassoma lucasanum, T. grammaticum and the pomacentrid Chromis atrilobata. Only eleven species (4.7% of total) appeared in 75% to 100% of census, and 36 (15.3% of total) had high levels of both abundance and frequency, evidencing that the community is dominated by few taxa. Local species richness exceeds the number reported for most rocky or coral reefs of the Pacific coast of MÃ©xico, and indicates that Cabo Pulmo is a key area in the gulf and the entire Mexican Pacific, from the ichthyological point of view.",2000,Revista de biologia tropical
Cold active Î²-galactosidase from Thalassospira sp. 3SC-21 to use in milk lactose hydrolysis: a novel source from deep waters of Bay-of-Bengal,"The cold active Î²-galactosidase from psychrophilic bacteria accelerate the possibility of outperforming the current commercial Î²-galactosidase production from mesophilic sources. The present study is carried out to screen and isolate a cold active Î²-galactosidase producing bacterium from profound marine waters of Bay-of-Bengal and to optimize the factors for lactose hydrolysis in milk. Isolated bacterium 3SC-21 was characterized as marine psychrotolerant, halophile, gram negative, rod shaped strain producing an intracellular cold active Î²-galactosidase enzyme. Further, based upon the 16S rRNA gene sequence, bacterium 3SC-21 was identified as Thalassospira sp. The isolated strain Thalassospira sp. 3SC-21 had shown the enzyme activity between 4 and 20Â Â°C at pH of 6.5 and the enzyme was completely inactivated at 45Â Â°C. The statistical method, central composite rotatable design of response surface methodology was employed to optimize the hydrolysis of lactose and to reveal the interactions between various factors behind this hydrolysis. It was found that maximum of 80.18Â % of lactose in 8Â ml of raw milk was hydrolysed at pH of 6.5 at 20Â Â°C in comparison to 40Â % of lactose hydrolysis at 40Â Â°C, suggesting that the cold active Î²-galactosidase from Thalassospira sp. 3SC-21would be best suited for manufacturing the lactose free dairy products at low temperature.",2012,World Journal of Microbiology and Biotechnology
Approximate kernel reconstruction for time-varying networks,"BackgroundMost existing algorithms for modeling and analyzing molecular networks assume a static or time-invariant network topology. Such view, however, does not render the temporal evolution of the underlying biological process as molecular networks are typically â€œre-wiredâ€ over time in response to cellular development and environmental changes. In our previous work, we formulated the inference of time-varying or dynamic networks as a tracking problem, where the target state is the ensemble of edges in the network. We used the Kalman filter to track the network topology over time. Unfortunately, the output of the Kalman filter does not reflect known properties of molecular networks, such as sparsity.ResultsTo address the problem of inferring sparse time-varying networks from a set of under-sampled measurements, we propose the Approximate Kernel RecONstruction (AKRON) Kalman filter. AKRON supersedes the Lasso regularization by starting from the Lasso-Kalman inferred network and judiciously searching the space for a sparser solution. We derive theoretical bounds for the optimality of AKRON. We evaluate our approach against the Lasso-Kalman filter on synthetic data. The results show that not only does AKRON-Kalman provide better reconstruction errors, but it is also better at identifying if edges exist within a network. Furthermore, we perform a real-world benchmark on the lifecycle (embryonic, larval, pupal, and adult stages) of the Drosophila Melanogaster.ConclusionsWe show that the networks inferred by the AKRON-Kalman filter are sparse and can detect more known gene-to-gene interactions for the Drosophila melanogaster than the Lasso-Kalman filter. Finally, all of the code reported in this contribution will be publicly available.",2019,BioData Mining
Identification of three m6Aâ€related mRNAs signature and risk score for the prognostication of hepatocellular carcinoma,"Hepatocellular carcinoma (HCC) is the most common type of liver cancer and is extremely harmful to human health. In recent years, N6-methyladenosine (m6A) RNA methylation in eukaryotic mRNA has been increasingly implicated in cancer pathogenesis and prognosis. In this study, we downloaded the expression profile and clinical information of 307 patients from The Cancer Genome Atlas database and 64 patients from the Gene Expression Omnibus (GEO) database, and univariate Cox analysis revealed that METTL14 was a prognostic m6A RNA methylation regulator. For further study on the related genes of METTL14, weighted gene co-expression network analysis was used to find the relationship between METTL14 and gene expression, and univariate Cox analysis and least absolute shrinkage and selection operator (LASSO) methods were used to identify hub genes that may be associated with HCC prognosis. The results indicated that cysteine sulfinic acid decarboxylase, glutamic-oxaloacetic transaminase 2, and suppressor of cytokine signaling 2 were key genes affecting the prognosis of HCC patients, and m6A methylation of these mRNAs may be regulated by METTL14. Finally, a nomogram was constructed based on the hub gene expression levels, and its prediction accuracy and discriminative ability were measured by the C-index and a calibration curve. In conclusion, METTL14, an m6A RNA methylation regulator, may participate in the malignant progression of HCC by adjusting the m6A of cysteine sulfinic acid decarboxylase, glutamic-oxaloacetic transaminase 2, and suppressor of cytokine signaling 2, and these genes are useful for prognostic stratification and treatment strategy development.",2020,Cancer Medicine
The Discovery and Division of the Mesozoic Strata in the Southwest of Donghai Shelf Basin,"The Mesozoic strata containing some littoral layers are well developed in the Fuzhou sag of Donghai shelf basin. They were considered as of Tertiary age before drilling. According to the analysis and contrast of lithology and sporo pollen ( Cyathidites Klukisporites Dictyophyllidites, Classopollis annulatus Schizaeoisporites Exesipollenites tumulus) assemblages and the morphological feature of ostracodes ( Eucypris? sp., Metacypris sp.), we think that they can be analogous to the strata of the same age in East China, especially in the areas of Zhejiang and Fujian. Based on the isotopic dating, property of seismic reflections and diplog data, we divide it in ascending order into the Fuzhou, Yushan and Minjiang Formations, respectively belonging to Lower-Middle Jurassic, Upper Jurassic-Lower Cretaceous and Upper Cretaceous series.",2000,Journal of stratigraphy
Improving the efficiency of genomic selection,"Abstract We investigate two approaches to increase the efficiency of phenotypic prediction from genome-wide markers, which is a key step for genomic selection (GS) in plant and animal breeding. The first approach is feature selection based on Markov blankets, which provide a theoretically-sound framework for identifying non-informative markers. Fitting GS models using only the informative markers results in simpler models, which may allow cost savings from reduced genotyping. We show that this is accompanied by no loss, and possibly a small gain, in predictive power for four GS models: partial least squares (PLS), ridge regression, LASSO and elastic net. The second approach is the choice of kinship coefficients for genomic best linear unbiased prediction (GBLUP). We compare kinships based on different combinations of centring and scaling of marker genotypes, and a newly proposed kinship measure that adjusts for linkage disequilibrium (LD). We illustrate the use of both approaches and examine their performances using three real-world data sets with continuous phenotypic traits from plant and animal genetics. We find that elastic net with feature selection and GBLUP using LD-adjusted kinships performed similarly well, and were the best-performing methods in our study.",2013,
"Genome Mining, Isolation and Characterization of Novel Lasso Peptides and Their Utilization in Drug Development","Integrins moderate diverse important functions in the human body and are promising targets in cancer therapy. Hence, the selective inhibition of specific integrins is of great medicinal interest. Here, we report the optimization of a grafted lasso peptide, yielding MccJ25(RGDF), which is a highly potent and selective inhibitor of the ï¡vï¢3 integrin. Furthermore, its elucidated structure was employed in a molecular dynamics approach, revealing information about the integrin binding mode and selectivity profile of MccJ25(RGDF).",2014,
"Genome-wide prediction of maize single-cross performance, considering non-additive genetic effects.","The prediction of single-cross hybrids in maize is a promising technique for optimizing the use of financial resources in a breeding program. This study aimed to evaluate Genomic Best Linear Unbiased Predictors models for hybrid prediction and compare them with the Bayesian Ridge Regression, Bayes A, Bayesian LASSO, Bayes C, Bayes B, and Reproducing Kernel Hilbert Spaces Regression models, with inclusion or absence of non-additive effects under three heritability scenarios. Data from a maize germplasm bank belonging to USDA were used to determine the effects of molecular markers, which were considered to be parametric, to build 400 single-cross hybrids between two line groups via simulation. The following parameters were used to compare the models: predictive ability, estimation of variance components, heritability of genetic effects present in all situations, and the sum of squares of the predicted errors. The models responded positively when dominance effects were included in non-additive models, with all models tending to show an increase in the values of heritability parameters under all scenarios. Differences occur between models depending on the heritability range considered. Estimates of additive and dominant effects were better than estimates of epistatic effects. Estimates increased in accuracy for all models when non-additive effects for maize cob weight were considered.",2015,Genetics and molecular research : GMR
Lasso with long memory regression errors,"Abstract Lasso is a computationally efficient approach to model selection and estimation, and its properties are well studied when the regression errors are independent and identically distributed. We study the case, where the regression errors form a long memory moving average process. We establish a finite sample oracle inequality for the Lasso solution. We then show the asymptotic sign consistency in this setup. These results are established in the high dimensional setup ( p > n ) where p can be increasing exponentially with n. Finally, we show the consistency, n 1 / 2 âˆ’ d - consistency of Lasso, along with the oracle property of adaptive Lasso, in the case where p is fixed. Here d is the memory parameter of the stationary error sequence. The performance of Lasso is also analysed in the present setup with a simulation study.",2014,Journal of Statistical Planning and Inference
Machine Learningâ€“Based Prediction of Clinical Outcomes for Children During Emergency Department Triage,"Importance
While machine learning approaches may enhance prediction ability, little is known about their utility in emergency department (ED) triage.


Objectives
To examine the performance of machine learning approaches to predict clinical outcomes and disposition in children in the ED and to compare their performance with conventional triage approaches.


Design, Setting, and Participants
Prognostic study of ED data from the National Hospital Ambulatory Medical Care Survey from January 1, 2007, through December 31, 2015. A nationally representative sample of 52â€¯037 children aged 18 years or younger who presented to the ED were included. Data analysis was performed in August 2018.


Main Outcomes and Measures
The outcomes were critical care (admission to an intensive care unit and/or in-hospital death) and hospitalization (direct hospital admission or transfer). In the training set (70% random sample), using routinely available triage data as predictors (eg, demographic characteristics and vital signs), we derived 4 machine learning-based models: lasso regression, random forest, gradient-boosted decision tree, and deep neural network. In the test set (the remaining 30% of the sample), we measured the models' prediction performance by computing C statistics, prospective prediction results, and decision curves. These machine learning models were built for each outcome and compared with the reference model using the conventional triage classification information.


Results
Of 52â€¯037 eligible ED visits by children (median [interquartile range] age, 6 [2-14] years; 24â€¯929 [48.0%] female), 163 (0.3%) had the critical care outcome and 2352 (4.5%) had the hospitalization outcome. For the critical care prediction, all machine learning approaches had higher discriminative ability compared with the reference model, although the difference was not statistically significant (eg, C statistics of 0.85 [95% CI, 0.78-0.92] for the deep neural network vs 0.78 [95% CI, 0.71-0.85] for the reference; Pâ€‰=â€‰.16), and lower number of undertriaged critically ill children in the conventional triage levels 3 to 5 (urgent to nonurgent). For the hospitalization prediction, all machine learning approaches had significantly higher discrimination ability (eg, C statistic, 0.80 [95% CI, 0.78-0.81] for the deep neural network vs 0.73 [95% CI, 0.71-0.75] for the reference; Pâ€‰<â€‰.001) and fewer overtriaged children who did not require inpatient management in the conventional triage levels 1 to 3 (immediate to urgent). The decision curve analysis demonstrated a greater net benefit of machine learning models over ranges of clinical thresholds.


Conclusions and Relevance
Machine learning-based triage had better discrimination ability to predict clinical outcomes and disposition, with reduction in undertriaging critically ill children and overtriaging children who are less ill.",2019,JAMA Network Open
Reply to 'Society's needs cannot be met by applied science alone: A response to Cochrane et al. (2019)',"Glassom et al.2 misinterpret our paper in their title: â€˜Societyâ€™s needs cannot be met by applied science aloneâ€™: a statement of the obvious and unrelated to any of our arguments. Another misinterpretation occurs in their comment: â€˜It makes no sense to sacrifice strong disciplinary research because of a perceived imperative for interdisciplinary workâ€™. We actually wrote that â€˜Disciplinary science should therefore not be discouraged but much greater emphasis must be placed on....interdisciplinary scienceâ€™ and other statements recognising the role of disciplinary science. They wrote â€˜they assume an unrealistic linearity in the way that science translates to policy and managementâ€™. We make no such assumption and the stakeholder model, our recommended scientific approach, encourages an interactive, evolutionary and non-linear approach in addressing problems and searching for understanding and solutions.",2019,South African Journal of Science
Chapter 13 A Positive Approach to Workplace Bullying: Lessons from the Victorian Public Sector,"Over the past decades the devastating issue of workplace bullying and its â€œcancerousâ€ impact on workplace emotions has seen â€œtoday's costliest secretâ€ become exposed (Einarsen, Hoel, Zapf & Cooper, 2003, p. 32; Glendinning, 2001, p. 296; Needham, 2003, p. 12). Bullying at work has become so prevalent within today's workplace that 1 of the 4 of us are estimated to suffer the crippling abuse of the workplace bully, costing Australian organizations between $17 billion and $36 billion each year (Clarke, J. (2005). Working with monsters: How to identify and protect yourself from the workplace psychopath. Sydney: Random House Australia; Rayner, C. (2000). Building a business case for tackling bullying in the workplace: Beyond a cost-benefit analysis. In: Sheehan, M., Ramsey, C., & Patrick, J. (Eds), Transcending boundaries. Proceedings of the 2000 Conference, September, Brisbane). The impending doom faced by the target of the bully demeans the individual to such an extent that bullying has been associated with suicide, post-traumatic stress disorder, and even increased risk of coronary heart disease and has been demonstrated to sever â€œat homeâ€ relationships, with grave implications on work-life balance (Archer, 1999; Geffner, Braverman, Galasso & Marsh, 2004; Lewis, 2006). Yet despite the significant loseâ€“lose outcomes of workplace bullying for both the individual and the well-documented consequences of decreased productivity for the organization, there seems to be little progress toward meaningfully addressing the issues that actually create, promote, and sustain workplace bullying (Bolton, 2007; Dutton & Ragins, 2007; Heames & Harvey, 2006; Peyton, 2003). Rather than narrowly concentrating on bullying and its drivers which limits workplace bullying to an occupational health and safety issue, this chapter demonstrates the practical implementation across five Victorian public sector organizations of a tool developed using the principles of positive psychology. This approach places bullying in the wider context of positive workplace emotions, allowing for consideration of the broader organizational characteristics and the subtle negative behaviors which are suggested to underlie the deep seated and pervasive nature of workplace bullying. The preliminary findings suggests that the tool was seen as valuable in creating a bully-free culture and resonates practically by offering insights into some of the issues organizations should consider to ensure such initiatives provide a genuine source of competitive advantage.",2011,
Prognostic and Predictive Value of Three DNA Methylation Signatures in Lung Adenocarcinoma,"Background: Lung adenocarcinoma (LUAD) is the leading cause of cancer-related mortality worldwide. Molecular characterization-based methods hold great promise for improving the diagnostic accuracy and for predicting treatment response. The DNA methylation patterns of LUAD display a great potential as a specific biomarker that will complement invasive biopsy, thus improving early detection. Method: In this study, based on the whole-genome methylation datasets from The Cancer Genome Atlas (TCGA) and several machine learning methods, we evaluated the possibility of DNA methylation signatures for identifying lymph node metastasis of LUAD, differentiating between tumor tissue and normal tissue, and predicting the overall survival (OS) of LUAD patients. Using the regularized logistic regression, we built a classifier based on the 3616 CpG sites to identify the lymph node metastasis of LUAD. Furthermore, a classifier based on 14 CpG sites was established to differentiate between tumor and normal tissues. Using the Least Absolute Shrinkage and Selection Operator (LASSO) Cox regression, we built a 16-CpG-based model to predict the OS of LUAD patients. Results: With the aid of 3616-CpG-based classifier, we were able to identify the lymph node metastatic status of patients directly by the methylation signature from the primary tumor tissues. The 14-CpG-based classifier could differentiate between tumor and normal tissues. The area under the receiver operating characteristic (ROC) curve (AUC) for both classifiers achieved values close to 1, demonstrating the robust classifier effect. The 16-CpG-based model showed independent prognostic value in LUAD patients. Interpretation: These findings will not only facilitate future treatment decisions based on the DNA methylation signatures but also enable additional investigations into the utilization of LUAD DNA methylation pattern by different machine learning methods.",2019,Frontiers in Genetics
Can we eradicate gastric MALT-lymphoma?,"The incidence of primary gastric lymphoma in Italy is considerably higher than that observed in the rest of Europe. It is widely accepted that gastric B-cell, low-grade mucosalassociated lymphoid tissue (MALT) lymphoma is caused by specific host-bacterial interactions that occur during Helicobacter pylori infection. This review examines recent findings on the origins, diagnosis, treatment, and follow-up of gastric MALT lymphomas. Clinical and endoscopic findings at diagnosis vary widely. In a substantial number of cases, the patient presents only vague dyspeptic symptoms or poorly defined abdominal pain with no macroscopic lesions on the gastric mucosa. Review of data from 32 trials in which a total of 1,387 MALT-lymphoma patients of the stomach were treated solely with H. pylori eradication revealed high remission rates when the disease is treated early (stage I-II1). Neoplasia confined to the submucosa, antral localization of tumors, and negativity for the API2-MALT1 translocation were associated with a high probability of remission following H. pylori eradication. When the latter approach is not sufficient, radiotherapy, chemotherapy and, in selected cases, surgery are associated with high success rates; data on the efficacy of monoclonal antibody therapy (rituximab) are still limited. Five-year survival rates are higher than 90%. Patients whose tumors have been eliminated require close, long-term endoscopic follow-up since recurrence has been reported in some cases. Broader clinical follow-up is also advisable because the incidence of other solid tumors and of cardiovascular events is reportedly increased in these patients.",2013,Italian Journal of Medicine
Prediction of radiation-induced mucositis of H&N cancer patients based on a large patient cohort.,"PURPOSE/OBJECTIVE
Radiation-induced mucositis is a severe acute side effect, which can jeopardize treatment compliance and cause weight loss during treatment. The study aimed to develop robust models to predict the risk of severe mucositis.


MATERIALS/METHODS
Mucosal toxicity scores were prospectively recorded for 802 consecutive Head and Neck (H&N) cancer patients and dichotomised into non-severe event (grade 0-2) and severe event (grade 3+) groups. Two different model approaches were utilised to evaluate the robustness of the models. These used LASSO and Best Subset selection combined with 10-fold cross-validation performed on two-thirds of the patient cohort using principal component analysis of DVHs. The remaining one-third of the patients were used for validation. Model performance was tested through calibration plot and model performance metrics.


RESULTS
The main predicted risk factors were treatment acceleration and the first two principal dose components, which reflect the mean dose and the balance between high and low doses to the oral cavity. For the LASSO model, gender and current smoker status were also included in the model. The AUC values of the two models on the validation cohort were 0.797 (95%CI: 0.741-0.857) and 0.808 (95%CI: 0.749-0.859), respectively. The two models predicted very similar risk values with an internal Pearson coefficient of 0.954, indicating their robustness.


CONCLUSIONS
Robust prediction models of the risk of severe mucositis have been developed based on information from the entire dose distribution for a large cohort of patients consisting of all patients treated H&N for within our institution over a five year period.",2020,Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology
"Complex SANS SAXS data evaluation, simulation and interpretation with regard to statistical inference","This work presents an in-depth discussion of different methods used for Small-Angle Scattering (SAS) data analysis, and especially for the first time within a precisely defined statistical framework. Inferring structural information from SAS data via physical model fitting and free-form model fitting is discussed within two different statistical inference approaches, namely Bayesian and frequentist statistics, which put the analysis and interpretation of SAS data on well founded theories, hence showing how to draw optimal inferences. The discussion shows the importance of having enough of scattering system information (a priori knowledge about the system and information contained in the experimental SAS data) available in order to infer structural information. As an example, simultaneous physical model fitting is performed on contrast variation data of an InterPolyElectrolyte Complex (IPEC) system. Moreover, statistical inference is applied to the Indirect Fourier Transform (IFT) in order to get objectively a free-form solution, and additionally, modern machine learning methods (RVM, SVR, LASSO) are employed to determine a more robust solution. A new and homemade program, called SASET, is presented that easily allows to efficiently evaluate comprehensive and coupled 1-dimensional SAS data sets/series, hence allowing to include a lot of information in the evaluation process. 2-dimensional data sets/series can also",2015,
Characterization of Weighted Quantile Sum Regression for Highly Correlated Data in a Risk Analysis Setting,"In risk evaluation, the effect of mixtures of environmental chemicals on a common adverse outcome is of interest. However, due to the high dimensionality and inherent correlations among chemicals that occur together, the traditional methods (e.g. ordinary or logistic regression) suffer from collinearity and variance inflation, and shrinkage methods have limitations in selecting among correlated components. We propose a weighted quantile sum (WQS) approach to estimating a body burden index, which identifies â€œbad actorsâ€ in a set of highly correlated environmental chemicals. We evaluate and characterize the accuracy of WQS regression in variable selection through extensive simulation studies through sensitivity and specificity (i.e., ability of the WQS method to select the bad actors correctly and not incorrect ones). We demonstrate the improvement in accuracy this method provides over traditional ordinary regression and shrinkage methods (lasso, adaptive lasso, and elastic net). Results from simulations demonstrate that WQS regression is accurate under some environmentally relevant conditions, but its accuracy decreases for a fixed correlation pattern as the association with a response variable diminishes. Nonzero weights (i.e., weights exceeding a selection threshold parameter) may be used to identify bad actors; however, components within a cluster of highly correlated active components tend to have lower weights, with the sum of their weights representative of the set.Supplementary materials accompanying this paper appear on-line.",2015,"Journal of Agricultural, Biological, and Environmental Statistics"
Automatic deconvolution of isotope-resolved mass spectra using variable selection and quantized peptide mass distribution.,"We present an algorithm for the deconvolution of isotope-resolved mass spectra of complex peptide mixtures where peaks and isotope series often overlap. The algorithm formulates the problem of mass spectrum deconvolution as a classical statistical problem of variable selection, which aims to interpret the spectrum with the least number of peptides. The LASSO method is used to perform automatic variable selection. The algorithm also makes use of the quantized distribution of peptide masses in the NCBInr database after in silico trypsin digestion as filters to aid the deconvolution process. Errors in the expected isotope pattern are accounted for to avoid spurious isotope series. The effectiveness of the algorithm is demonstrated with annotated ESI spectrum of known peptides for which the peaks and isotope series are highly overlapping. The algorithm successfully finds all correct masses in the experimental spectrum, except for one spectrum where an additional refinement procedure is required to obtain the correct results. Our results compare favorably to those from a widely used commercial program.",2006,Analytical chemistry
CG-Lasso Estimator for Multivariate Adaptive Regression Spline,"Multivariate adaptive regression spline (MARS) denotes a modern methodology from statistical learning which is important in both classification and regression. It is very useful for high-dimensional problems and shows a great promise for fitting nonlinear multivariate functions by using its ability to estimate the contributions of the basis functions so that both the additive and the interactive effects of the predictors are allowed to determine the response variable. The MARS algorithm for estimating the model function consists of two sub-algorithms. In our paper, we propose not to use second algorithm. Instead, we construct a penalized residual sum of squares (PRSS) for MARS as a higher-order Tikhonov regularization problem which is also known as ridge regression that shrinks coefficients and make them more stable. But it cannot perform variable selection in the model and, hence, does not give an easily interpretable model (especially, if the number of variable p is large). For this reason, we change the Tikhonov penalty function with the generalized Lasso penalty for solving the problem PRSS, taking an advantage for feature selection. We treat this problem using continuous optimization techniques which we consider to become an important complementary technology and model-based alternative to the concept of the backward stepwise algorithm. In particular, we apply the elegant framework of conic quadratic programming (CQP), and we call the solution as CG-Lasso. Here, we gain from an area of convex optimization whose programs are very well-structured, herewith, resembling linear programming and, hence, permitting the use of powerful interior point methods (IPMs).",2019,
Recurrent atrial tachyarrhythmias after left atrial linear ablation surrounding ipsilateral pulmonary veins,"Objective To investigate the probable mechanism of recurrent atrial tachyarrhymias after left atrial linear ablation surrounding ipsilateral pulmonary veins(PVs). Methods Ten patients with paroxysmal atrial fibrillation(AF) and 18 patients with persistent AF underwent left atrial linear ablation surrounding ipsilateral PVs guided by Carto electroanatomic mapping system and double Lasso catheters technique. The end point of ablation was defined as absence of all PV spikes documented with the 2 Lasso catheters within the ipsilateral PVs at least 30 minutes after isolation and bidirectional conduction block between left atrial and PVs. For the patients with recurrent atrial tachyarrhymias, double Lasso technique was used to find the gap of the original circle lines in the repeat ablation. Activation mapping and entrainment mapping were performed with or without Carto system to identify the earliest activated area or reentrant circuit. Cavotricuspid isthmus was ablated for patients with documented commen-type atrial flutter(AFL). Results After a median of (245Â±65) days of follow-up, eighteen patients were free of AF with or without antiarrhythmic drugs. Two patients with persistent AF remaining PV spikes in left superior PV failured being translated to sinus rhythm by cardioversion.Eight patients with recurrent atrial tachyarrhymias, including5 typical AFL, two atrial tachycardia and 1 parox-ysmal AF, underwent repeat ablation. Recovered conduction between left atrium and PVs were documented inall of them. Except1 patient with atrial tachycardia related to both atria, all the other8 patients were cured bythe second procedure and free of atrial tachyarrhythmia after (192Â±92) days follow-up.Conclusion Recov-ered conduction between left atrium and PVs was an important factor for the recurrent atrial tachyarrhytmia afterleft atrial linear ablation and additional ablation lines on cavotricuspid isthmus in the initial procedure could re-duce the secondary atrial tachycardia.",2006,Chinese Journal of Cardiac Arrhythmias
Detoxification of the Fusarium mycotoxin zearalenone is an important trait of Clonostachys rosea in biocontrol of Fusarium foot rot of barley,"only Development, stability and biocontrol activity of a formulation based on Pseudomonas fluorescens Ps06 Jenny Carolina RuÃ­z, Luisa Fernanda Izquierdo, Carlos AndrÃ©s Moreno, Martha Isabel GÃ³mez, Laura Fernanda Villamizar .................................................. 25-30 Abstract: A Colombian strain of Pseudomonas fluorescens Ps06 was formulated as a powder which stabilized cells viability during six months at 8Â°C Â± 2. This formulation significantly reduced (P < 0.05) incidence and severity of first symptoms of tomato crown rot in 86% and 50%, respectively. Developed biopesticide could be a useful tool to control F. oxysporum in tomato crop. Dynamics of yeasts in the phylloplane of strawberry Jane Debode, Wendy Van Hemelrijck, Piet Creemers, Martine Maes .................... 31-32 Abstract: Examination of the dynamics of the phylloplane yeast populations revealed immature fruits showed significantly larger populations than mature fruits or leaves. The dominant yeasts belong to the genera Cryptococcus, Rhodotorula, as well as Sporobolomyces and showed resistance to the two major fungicides applied to strawberry cultures. This suggests potential use of phylloplane yeasts in the integrated control of fungal diseases in strawberry. Characterization of an alkaline serine protease of Aureobasidium pullulans involved in the biocontrol of postharvest diseases Davide Spadaro, Dianpeng Zhang, Angelo Garibaldi, Maria Lodovica Gullino ....... 33-35 Abstract: An alkaline protease gene was amplified and characterized from genomic DNA and cDNA of Aureobasidium pullulans PL5. Expression of ALP5 in Escherichia coli BL21 (DE3) yielded an homogeneous recombinant ALP5 which hydrolysed the substrate casein and inhibited the mycelial growth of the pathogens. This study provided the direct evidence that extracellular proteases secreted by the antagonist A. pullulans PL5 played a role in the biocontrol activities against some postharvest pathogens of apple and peach. What if it doesn't work? An example for a promising biological control agent that negatively influence the plant instead of helping it Tami Gat, Beni Kirshner, David Ezra ...................................................................... 37-38 Abstract: Plants were inoculated with the endophytic Penicillium sp. and then appeared to be over sensitive to phytopathogens, which is quite original in terms of biocontrol. In this case the inoculated plants displayed stronger symptoms than the control. On the other hand an extraction of the growth medium was found to be active and provided protection to plants against pathogens. It is likely that the benefit coming from the described endophyte will not be due to introduction of the endophyte into the plant rather using its secondary metabolites as ""natural pesticides"". Effectiveness of beneficial bacteria-mediated ISR against Botrytis cinerea in relation to priming of defense responses in grapevine Patricia Trotel-Aziz, Bas Verhagen, Charlotte Gruau, Maryline Magnin-Robert, Michel Couderchet, Christophe ClÃ©ment, Fabienne Baillieul, Aziz Aziz .................. 39-43 Abstract: Plants have evolved the ability to enhance their basal resistance after perception of specific stimuli, such as root colonization by selective rhizobacteria or derived microbialassociated molecular patterns. In this study, we examined the differences and similarities in term of the effectiveness of various bacteria with different origins to trigger ISR and to induce or prime some defence responses in grapevine. We especially focused on oxidative burst in grapevine cell suspensions and systemic production of stilbenic phytoalexins, trans-resveratrol and its dehydrodimer Îµ-viniferin in plants. First evidence of a Lysobacter member as a biological control agent of Plasmopara viticola Gerardo Puopolo, Emmanuel Jourdan, Marc Ongena, Ilaria Pertot ........................ 45-48 Abstract: With the climate change, the temperature is going to play a key role in the effectiveness of microbial biocontrol agents. The influence of this environmental factor on the ecology and biocontrol activity of Bacillus amyloliquefaciens strain S499 has been investigated in this work. On this purpose, the effect of temperature on the ability to move onto solid surface, to form biofilm, to persist onto plant rhizosphere and to induce systemic resistance in plants have been evaluated in vitro and in vivo. Biocontrol of fruit postharvest diseases by Aureobasidium pullulans Marta Mari, Wafa Rouissi, Camilla Martini, Alice Spadoni ....................................... 49-54 Abstract: The activity of a biological control agent, strain LL, previously identified as Aureobasidium pullulans, was tested for the first time on peach, apple and orange artificially inoculated with Monilinia laxa, M. fructicola, M. fructigena (peach) and Botrytis cinerea, Colletotrichum acutatum, Penicillium expansum (apple) and P. digitatum, P. italicum (orange). The washed cells of the antagonist were effective against all eight pathogens, inhibiting decay by over 94%; in particular the antagonist completely controlled M. laxa, M. fructicola, C. acutatum, P. digitatum and P. italicum. To our knowledge this is the first study considering the biocontrol of eight postharvest fruit pathogens with an A. pullulans strain in the same experimental conditions. Under postharvest conditions, in peaches inoculated with Monilinia spp., treated with the antagonist and stored at 0Â°C for 21 days plus 7 days of shelf-life, the antagonist was able to completely inhibit M. laxa and M. fructicola. In the same way, blue mould caused by P. expansum was significantly reduced on apple, after 120 days at 0Â°C, plus 7 days at 20Â°C. In in vitro trials, the VOCs released by the antagonist significantly inhibited the growth of all seven tested pathogens compared to the control, although with a different rate depending on the pathogen. These preliminary data, showing the efficacy of the A. pullulans LL strain in the control of the main postharvest fruit diseases, are promising for the development of a biofungicide for postharvest applications on a wide range of species and pathogens. Efficacy of a biological control agent and four fungicides in the control of postharvest decay in the pear cultivar Forelle Pieter Janse van Rensberg, Cheryl Lennox ........................................................... 55-57 Abstract: Main pathogens isolated from symptomatic Forelle pears were Botrytis cinerea, Penicillium expansum and Alternaria spp. Iprodione and pyrimethanil significantly reduced total decay in 2010. In 2011 fludioxonil, iprodione, pyrimethanil and pyrimethanil plus imazalil were also efficient. These fungicides decreased Penicillium expansum, Alternaria spp. effects and secondary decay caused by Botrytis cinerea. The biological control agent Cryptococcus albidus significantly reduced decay associated with a combined group of minor pathogens in 2011but was not efficient against the major pathogens in either year, indicating that postharvest fungicides tested are effective in controlling postharvest decay of pear fruit surface. However, these fungicides do not control calyx end decay caused by latent infections of Botrytis cinerea. In this context Cryptococcus albidus does not appear as an effective biological control agent for postharvest decay of Forelle pear. Induced systemic resistance in tomato (Solanum lycopersicum) by biochar soil amendment Yael Meller Harel, Zeraye Haile Mehari, Yigal Elad, Dalia Rav-David, Menahem Borenstein, Ran Shulchani, Ellen R. Graber .......................................... 59-64 Abstract: Grey mould, caused by Botrytis cinerea, is a major fungal disease of tomato (Solanum lycopersicum) world-wide. The aim of this study was to explore the molecular pathways involved in the induced resistance against B. cinerea in tomato plants grown on biochar amended medium. We observed that similar pathways of induction of defence-related gene expression take place in leaves of plants grown in biochar-amended medium independently of the biochar type and that the effect of biochar on gene expression increases with incubation time. In addition, a mutant def1, deficient in jasmonic acid lost its induced resistance ability when grown in a greenhouse biochar amended soil. This correlated with a loss of induction of expression of the genes belonging to the salicylic and jasmonic acid pathways. We conclude that Induced resistance by biochar amendment in tomato against grey mould depends on jasmonic acid synthesis. Genomic/transcriptomic studies to optimize the biocontrol effect of Stenotrophomonas rhizophila Mohammadali Alavi, Christin Zachow, Henry MÃ¼ller, Gabriele Berg ....................... 65-69 Abstract: The genus Stenotrophomonas is of high medical, ecological and biotechnological interest due to the versatility of the different species. For example, Stenotrophomonas rhizophila is a model for a rhizosphereand phylloplanecompetent, salt-tolerant biocontrol agent. One of the most effective strains S. rhizophila DSM 14405 T showed biocontrol activity on various crops (e.g. pepper, oilseed rape, cucumber) under salinated conditions in greenhouse and field trials. Strain DSM 14405 T does not only show rhizosphere competence and antagonistic activity; it also produces high amounts of osmoprotective substances allowing it to survive under saline conditions. New insights into its mode of action are presented from transcriptomic studies based on the genome. Furthermore, this information will be used to optimise the fermentation, formulation and efficiency of the biocontrol agent. Understanding patulin role in blue mould of apples as a tool to improve its biological control Simona Marianna Sanzani, Massimo Reverberi, Marta Punelli, Antonio Ippolito, Corrado Fanelli ............................................................................ 71-73 Abstract: Patulin ecological role has never been elucidated. Gene disru",2013,
Deviance residuals based PLS regression for censored data in high dimensional setting,"Abstract The PLS Cox regression has been proposed in the framework of PLS generalized linear regression as an alternative to the Cox model when dealing with highly correlated covariates. However, in high dimensional settings the algorithm becomes computer-intensive and a more efficient algorithm must be used. In this article we propose an alternative both faster and easier to carry out by the direct use of standard procedures which are available in most statistical softwares. Recently, Segal suggested a solution to the Coxâ€“Lasso algorithm when dealing with high dimensional data. Following Segal, we propose a Deviance Residuals based PLS regression (PLSDR) as an alternative to the PLSâ€“Cox model in high dimensional settings. The PLSDR algorithm only needs to carry out null deviance residuals using a simple intercept Cox model and use these as outcome in a standard PLS regression. This algorithm which can be extended to kernels to deal with non-linearity can also be viewed as a variable selection method in a threshold penalized formulation. An application carried out on gene expression from patients with diffuse large B-cell lymphoma shows the practical interest of using deviance residuals as outcomes in PLS regression when dealing with very many descriptors and censored data.",2008,Chemometrics and Intelligent Laboratory Systems
Thalassodendretum ciliati in Sinai (northern Red Sea) with special reference to quantitative aspects,"Abstract Thalassodendretum ciliati is one of the most common seagrass communities in the northern Red Sea. It ranges from just below low-water level to at least 30-m depth. This is a typically subtidal seagrass community, although at the shallowest levels the uppermost leaves are sometimes exposed during exceptionally low water and become â€œbruntâ€. It is the seagrass community with the highest standing crop in the northern Red Sea. Highest densities occur at c. 6 m, but tallest vegetation and largest leaves occur at the deepest levels reached by the community. The high standing stock stems from the extensive woody tissues the plants contain on one hand, and from the many â€˜tannin cellsâ€™ in their leaves on the other, which deter grazers and prevent consumption of the plant. Sciaphilic epiphytic algal assemblages develop on the vertical stems of the seagrass beneath the canopy, where they are sheltered from grazing fishes, and photophilic assemblages inhabit the exposed leaves. Both are rich in species, but contribute only a little to the high standing crop of the community.",1988,Aquatic Botany
Adenosine administration following pulmonary vein isolation: what is occurring?,"Figure 1. Sinus rhythm with transient atrioventricular (AV) block following adenosine administration. Shown are electrocardiogram leads I, aVF, and V1, as well as bipolar electrocardiogram recordings from a Lasso catheter (LSO) positioned in the left superior pulmonary vein, the coronary sinus (CS), and the ablation catheter (ABL) positioned on the left atrial anterior wall. Complete heart block is evident for the first two sinus beats while the remaining beats display AV nodal recovery with an atrial signal following the QRS complex (arrow).",2015,Pacing and clinical electrophysiology : PACE
Development and validation of a predictive model for predicting cardiovascular morbidity in patients after pheochromocytoma surgery.,"OBJECTIVE
Although surgical resection is the primary treatment method for pheochromocytoma, it carries a high risk of morbidity, especially cardiovascular-related morbidity. There are no models for predicting cardiovascular morbidity after pheochromocytoma surgery. Thus, we developed and validated a model for the pre-operative prediction of cardiovascular morbidity after pheochromocytoma surgery.


DESIGN
The development cohort consisted of 262 patients who underwent unilateral laparoscopic or open pheochromocytoma surgery at our center between 1 January 2007 and 31 December 2016. Patient's clinicopathologic data were recorded. The Lasso regression was used for data dimension reduction and feature selection, then multi-variable logistic regression analysis was used to develop the prediction model. An independent cohort consisting of 112 consecutive patients from 1 January 2017 and 31 December 2018 was used for validation. The performance of this prediction model was assessed with respect to discrimination, calibration, and clinical usefulness.


RESULTS
The predictors in this prediction model included body mass index, history of coronary heart disease, tumor size, intra-operative hemodynamic instability, and use of crystal/colloid fluids pre-operatively. In the validation cohort, the model showed good discrimination with an AUROC of 0.869 (95% CI, 0.797, 0.940) and good calibration (Unreliability test, p=0.852). Decision curve analysis demonstrated that the model was also clinically useful.


CONCLUSION
This study presented a good nomogram that could facilitate the pre-operative individualized prediction of cardiovascular morbidity after pheochromocytoma surgery, which may help improve peri-operative strategy and good treatment outcomes. This article is protected by copyright. All rights reserved.",2019,Clinical endocrinology
Sparse NIR optimization method (SNIRO) to quantify analyte composition with visible (VIS)/near infrared (NIR) spectroscopy (350â€¯nm-2500â€¯nm).,"Visual-Near-Infra-Red (VIS/NIR) spectroscopy has led the revolution in high-throughput phenotyping methods used to determine chemical and structural elements of organic materials. In the current state of the art, spectrophotometers used for imaging techniques are either very expensive or too large to be used as a field-operable device. In this study we developed a Sparse NIR Optimization method (SNIRO) that selects a pre-determined number of wavelengths that enable quantification of analytes in a given sample using linear regression. We compared the computed complexity time and the accuracy of SNIRO to Marten's test, to forward selection test and to LASSO all applied to the determination of protein content in corn flour and meat and octane number in diesel using publicly available datasets. In addition, for the first time, we determined the glucose content in the green seaweed Ulva sp., an important feedstock for marine biorefinery. The SNIRO approach can be used as a first step in designing a spectrophotometer that can scan a small number of specific spectral regions, thus decreasing, potentially, production costs and scanner size and enabling the development of field-operable devices for content analysis of complex organic materials.",2019,Analytica chimica acta
Application of Multi-task Sparse Lasso Feature Extraction and Support Vector Machine Regression in the Stellar Atmospheric Parameterization,"Abstract The multi-task learning takes the multiple tasks together to make analysis and calculation, so as to dig out the correlations among them, and therefore to improve the accuracy of the analyzed results. This kind of methods have been widely applied to the machine learning, pattern recognition, computer vision, and other related fields. This paper investigates the application of multi-task learning in estimating the stellar atmospheric parameters, including the surface temperature (Teff), surface gravitational acceleration (lg g), and chemical abundance ([Fe/H]). Firstly, the spectral features of the three stellar atmospheric parameters are extracted by using the multi-task sparse group Lasso algorithm, then the support vector machine is used to estimate the atmospheric physical parameters. The proposed scheme is evaluated on both the Sloan stellar spectra and the theoretical spectra computed from the Kurucz's New Opacity Distribution Function (NEWODF) model. The mean absolute errors (MAEs) on the Sloan spectra are: 0.0064 for lg (Teff /K), 0.1622 for lg (g/(cm Â· sâˆ’2)), and 0.1221 dex for [Fe/H]; the MAEs on the synthetic spectra are 0.0006 for lg (Teff /K), 0.0098 for lg (g/(cm Â· sâˆ’2)), and 0.0082 dex for [Fe/H]. Experimental results show that the proposed scheme has a rather high accuracy for the estimation of stellar atmospheric parameters.",2017,Chinese Astronomy and Astrophysics
Secret intake of antiretroviral treatment and HIV-1 viremia in a public routine clinic in Burkina Faso: a surprising relationship,"ABSTRACT In sub-Saharan Africa, where people living with HIV are frequently stigmatized, the intake of antiretroviral treatment (ART) remains a critical issue for many patients. Although the secret intake of ART may hinder the adherence to treatment, data on its specific impact on therapeutic effectiveness are lacking. We therefore assessed the association between secret intake of ART (i.e., hidden from family) and HIV-1 viremia among patients treated in a public routine clinic in Burkina Faso. We performed a cross-sectional study from December 2012 to September 2013 among patients on ART at the Day Care Unit in Bobo Dioulasso. Patients were eligible for the study if they were 15 years old or over, infected with HIV-1 or HIV-1â€‰+â€‰2, and on ART for at least six months. HIV-1 viral load was measured using Biocentric or Abbott Real Time assay. Study-specific data were collected by social workers using face-to-face interviews, and medical data using the routine electronic database. The association between secret intake of ART and viral load >300 copies/mL was assessed using a multivariate logistic regression. Of 771 patients (women 81.4%; median age 41 years; median time on ART 51 months), 408 reported secret intake of ART and 363 declared open intake. Compared to the latter, patients who hid their intake were younger, more likely to be women and to be involved in a polygamist or in a non-cohabiting union. Viremia was observed in 4.4% of patients hiding ART intake and 9.4% of those taking it openly. By multivariate analysis, secret intake of ART was significantly associated with a lower risk of viremia (adjusted odds ratio 0.41, 95% confidence interval 0.22â€“0.76). The unexpected relation between secret intake of ART and viremia found in this study requires further investigations. Quantitative and qualitative studies need to be performed.",2018,AIDS Care
Normalized and standard Dantzig estimators: Two approaches,"We reconsider the definition of the Dantzig estimator and show that, in contrast to the LASSO, standardization of an experimental matrix leads in general to a different estimator than in the case when it is based on the original data. The properties of the first method, resulting in what is called here the normalized Dantzig estimator are studied and the results on its estimation and prediction error are compared with similar results for the standard version. It is shown that in general the normalized version yields tighter estimation and prediction bounds than the other approach. In the correct specification case tighter bounds are obtained for the normalized Dantzig estimator than for the LASSO. Numerical examples indicate that in the case of imbalanced data the normalized estimator also performs better than the standard version. MSC 2010 subject classifications: Primary 62J05, 62J07; secondary 90C25.",2015,Electronic Journal of Statistics
Sparsity is a means and not an aim in inference of gene regulatory networks,"Availability of high-throughput gene expression data has lead to numerous attempts to infer network models of gene regulation based on expression changes. The low number of observations compared to the number of genes, the low signal-to-noise ratios, and the system being interampatte make the inference problem ill-posed and challenging. To solve the problem a majority of all published approaches resort to regularization, e.g. the LASSO penalty is used to find a sparse model. Regularization is known to introduce a bias, but its effect on inferred gene regulatory networks has hardly been investigated. In machine learning and compressed sensing, where regularization has been widely applied and studied, the objective is to reproduce a signal and the actual variable selection is of minor importance as long as the signal is reproduced well. In network inference, on the other hand, the variable selection is crucial since we want to identify the true topology of the network and a minimal number of links is not an aim per se. We first study the inference problem in a deterministic setting in order to gain insight and derive conditions on when the regularization causes false negative and positive links. By viewing the problem as a parameter identifiability problem, we establish three cases in which a subset of the parameters can be uniquely determined. Finally we devise conditions for invalidation of the inferred links using existing or additional data; resulting in an iterative procedure of inference and experiment design that significantly increases the confidence in the inferred network model.",2010,
Regularized Linear Models in Stacked Generalization,"Stacked generalization is a flexible method for multiple classifier combination; however, it tends to overfit unless the combiner function is sufficiently smooth. Previous studies attempt to avoid overfitting by using a linear function at the combiner level. This paper demonstrates experimentally that even with a linear combination function, regularization is necessary to reduce overfitting and increase predictive accuracy. The standard linear least squares regression can be regularized with an L2 penalty (Ridge regression), an L1 penalty (lasso regression) or a combination of the two (elastic net regression). In multi-class classification, sparse linear models select and combine individual predicted probabilities instead of using complete probability distributions, allowing base classifiers to specialize in subproblems corresponding to different classes.",2009,
Feature Selection and Negative Binomial Regression for Predicting Number of Defects in Wire Mesh Production,"In wire mesh production, many types of defects are found. When the factors related to the number of defects occurring are correctly identified, various improvement methods can then be applied to reduce or control the number of defects. In this paper, the features that are strongly linked with the number of defects are identified by the feature selection process and then used in the prediction process. LASSO method and random forest are applied in the feature selection process. Using selected features from feature selection, a negative binomial generalized linear model (GLM) is employed to predict the number of defects in the mesh manufacturing process. A negative binomial regression is used since the nature of the mesh defect data in this study is count data and over-dispersed. Quality of the selected features from LASSO and random forest are compared using RMSE and RMSLE of the predicted results from the negative binomial regression.",2019,2019 8th International Conference on Industrial Technology and Management (ICITM)
Gene Regulatory Network Inference Using Time-Stamped Cross-Sectional Single Cell Expression Data,"Abstract: In this paper we presented a novel method for inferring gene regulatory network (GRN) from time-stamped cross-sectional single cell data. Our strategy, called SNIFS (Sparse Network Inference For Single cell data) seeks to recover the causal relationships among genes by analyzing the evolution of the distribution of gene expression levels over time, more specifically using Kolmogorov-Smirnov (KS) distance. In the proposed method, we formulated the GRN inference as a linear regression problem, where we used Lasso regularization to obtain the optimal sparse solution. We tested SNIFS using in silico single cell data from 10 - and 20-gene GRNs, and compared the performance of our method with Time Series Network Inference (TSNI), GEne Network Inference with Ensemble of trees (GENIE3), and an extension of GENIE3 for time series data called JUMP3. The results showed that SNIFS outperformed existing algorithms based on the Area Under the Receiver Operating Characteristic (AUROC) and Area Under the Precision-Recall (AUPR) curves.",2016,IFAC-PapersOnLine
Subgroup analysis based on prognostic and predictive gene signatures for adjuvant chemotherapy in early-stage non-small-cell lung cancer patients,"ABSTRACT In treating patients diagnosed with early Stage I non-small-cell lung cancer (NSCLC), doctors must choose surgery alone, Adjuvant Cisplatin-Based Chemotherapy (ACT) alone or both. For patients with resected stages IB to IIIA, clinical trials have shown a survival advantage from 4â€“15% with the adoption of ACT. However, due to the inherent toxicity of chemotherapy, it is necessary for doctors to identify patients whose chance of success with ACT is sufficient to justify the risks. This research seeks to use gene expression profiling in the development of a statistical decision-making algorithm to identify patients whose survival rates will improve from ACT treatment. Using the data from the National Cancer Institute, the lasso method in the Cox-Proportional-Hazards regression model is used as the main method to determine a feasible number of genes that are strongly associated with the treatment-related patient survival. Considering treatment groups separately, the patients are assigned a risk category based on the estimation of survival times. These risk categories are used to develop a Random Forests classification model to identify patients who are likely to benefit from chemotherapy treatment. This model allows the prediction of a new patientâ€™s prognosis and the likelihood of survival benefit from ACT treatment based on a feasible number of genomic biomarkers. The proposed methods are evaluated using a simulation study.",2018,Journal of Biopharmaceutical Statistics
Sparse solution of overdetermined linear systems when the columns of $A$ are orthogonal,"In this paper, we consider the problem of obtaining the best $k$-sparse solution of $Ax=y$ subject to the constraint that the columns of $A$ are orthogonal. The naive approach for obtaining a solution to this problem has exponential complexity and there exist $l_1$ regularization methods such as Lasso to obtain approximate solutions. In this paper, we show that we can obtain an exact solution to the problem, with much less computational effort compared to the brute force search when the columns of $A$ are orthogonal.",2012,arXiv: Other Statistics
Orthogonal Matching Pursuit for Text Classification,"In text classification, the problem of overfitting arises due to the high dimensionality, making regularization essential. Although classic regularizers provide sparsity, they fail to return highly accurate models. On the contrary, state-of-the-art group-lasso regularizers provide better results at the expense of low sparsity. In this paper, we apply a greedy variable selection algorithm, called Orthogonal Matching Pursuit, for the text classification task. We also extend standard group OMP by introducing overlapping Group OMP to handle overlapping groups of features. Empirical analysis verifies that both OMP and overlapping GOMP constitute powerful regularizers, able to produce effective and very sparse models. Code and data are available online: this https URL .",2018,ArXiv
Data-driven assessment of eQTL mapping methods,"BackgroundThe analysis of expression quantitative trait loci (eQTL) is a potentially powerful way to detect transcriptional regulatory relationships at the genomic scale. However, eQTL data sets often go underexploited because legacy QTL methods are used to map the relationship between the expression trait and genotype. Often these methods are inappropriate for complex traits such as gene expression, particularly in the case of epistasis.ResultsHere we compare legacy QTL mapping methods with several modern multi-locus methods and evaluate their ability to produce eQTL that agree with independent external data in a systematic way. We found that the modern multi-locus methods (Random Forests, sparse partial least squares, lasso, and elastic net) clearly outperformed the legacy QTL methods (Haley-Knott regression and composite interval mapping) in terms of biological relevance of the mapped eQTL. In particular, we found that our new approach, based on Random Forests, showed superior performance among the multi-locus methods.ConclusionsBenchmarks based on the recapitulation of experimental findings provide valuable insight when selecting the appropriate eQTL mapping method. Our battery of tests suggests that Random Forests map eQTL that are more likely to be validated by independent data, when compared to competing multi-locus and legacy eQTL mapping methods.",2010,BMC Genomics
Post-selection point and interval estimation of signal sizes in Gaussian samples,"We tackle the problem of the estimation of a vector of means from a single vector-valued observation $y$. Whereas previous work reduces the size of the estimates for the largest (absolute) sample elements via shrinkage (like James-Stein) or biases estimated via empirical Bayes methodology, we take a novel approach. We adapt recent developments by Lee et al (2013) in post selection inference for the Lasso to the orthogonal setting, where sample elements have different underlying signal sizes. This is exactly the setup encountered when estimating many means. It is shown that other selection procedures, like selecting the $K$ largest (absolute) sample elements and the Benjamini-Hochberg procedure, can be cast into their framework, allowing us to leverage their results. Point and interval estimates for signal sizes are proposed. These seem to perform quite well against competitors, both recent and more tenured. 
Furthermore, we prove an upper bound to the worst case risk of our estimator, when combined with the Benjamini-Hochberg procedure, and show that it is within a constant multiple of the minimax risk over a rich set of parameter spaces meant to evoke sparsity.",2014,arXiv: Methodology
BP Neural Network Calculus in Economic Growth Modelling of the Group of Seven,"In this paper, the adaptive lasso method is used to screen variables, and different neural network models of seven countries are established by choosing variables. Gross domestic product (GDP) is a function of land area in the country, cultivated land, population, enrollment rate, total capital formation, exports of goods and services, and the general governmentâ€™s final consumption of collateral and broad money. Based on the empirical analysis of the above factors from 1973 to 2016, the results show that the BP neural network model has better performance based on multiple summary statistics, without increasing the number of parameters and better predicting short-term GDP. In addition, the change and the error of the model are small and have a certain reference value.",2020,
Variable selection in multivariate multiple regression,"Multivariate analysis is a common statistical tool for assessing covariate effects 
when only one response or multiple response variables of the same type are collected 
in experimental studies. However with mixed continuous and discrete outcomes, 
traditional modeling approaches are no longer appropriate. The common approach 
used to make inference is to model each outcome separately ignoring the potential 
correlation among the responses. However a statistical analysis that incorporates association 
may result in improved precision. Coffey and Gennings (2007a) proposed 
an extension of the generalized estimating equations (GEE) methodology to simultaneously 
analyze binary, count and continuous outcomes with nonlinear functions. 
Variable selection plays a pivotal role in modeling correlated responses due to large 
number of covariate variables involved. Thus a parsimonious model is always desirable 
to enhance model predictability and interpretation. To perform parameter 
estimation and variable selection simultaneously in the presence of mixed discrete and continuous outcomes, we propose a penalized based approach of the extended 
generalized estimating equations. This approach only require to specify the first two 
marginal moments and a working correlation structure. An advantageous feature of 
the penalized GEE is that the consistency of the model holds even if the working 
correlation is misspecified. However it is important to use appropriate working correlation 
structure in small samples since it improves the statistical efficiency of the 
regression parameters. We develop a computational algorithm for estimating the parameters 
using local quadratic approximation (LQA) algorithm proposed by Fan and 
Li (2001). For tuning parameter selection, we explore the performance of unweighted 
Bayesian information criterion(BIC) and generalized cross validation (GCV) for least 
absolute shrinkage and selection operator(LASSO) and smoothly clipped absolute 
deviation (SCAD). We discuss the asymptotic properties for the penalized GEE estimator 
when the number of subjects n goes to infinity. Our simulation studies reveal 
that when correlated mixed outcomes are available, estimates of regression parameters 
are unbiased regardless of the choice of correlation structure. However, estimates 
obtained from the unstructured working correlation (UWC) have reduced standard 
errors. SCAD with BIC tuning criteria works well in selecting important variables. 
Our approach is applied to concrete slump test data set.",2015,
When does more regularization imply fewer degrees of freedom? Sufficient conditions and counterexamples,"Regularization aims to improve prediction performance by trading an increase in training error for better agreement between training and prediction errors, which is often captured through decreased degrees of freedom. In this paper we give examples which show that regularization can increase the degrees of freedom in common models, including the lasso and ridge regression. In such situations, both training error and degrees of freedom increase, making the regularization inherently without merit. Two important scenarios are described where the expected reduction in degrees of freedom is guaranteed: all symmetric linear smoothers and convex constrained linear regression models like ridge regression and the lasso, when compared to unconstrained linear regression.",2014,Biometrika
Elucidation of the roles of conserved residues in the biosynthesis of the lasso peptide paeninodin.,"Substrate binding assays, in vitro proteolytic processing assays, and heterologous lasso peptide production were used to investigate the roles of conserved precursor peptide residues during paeninodin maturation. Specifically, we delineate which residues are important for substrate recognition, proteolysis, and lasso peptide macrocyclization.",2018,Chemical communications
Project proposals 2016,"1. LASSO-based pitch estimation Sparse reconstruction modeling is a currently active area of research. In this project, you will work with the so-called LASSO to estimate the fundamental frequency of a signal consisting of a number of superimposed pitches. The pitch model is useful for signals for which the spectrum can be decomposed into a sum of spectral lines or sinusoids such that each sinusoid has a frequency that is an integer multiple of the fundamental frequency. You will investigate if the LASSO can be used to solve the fundamental frequency estimation problem alternating between updating the relative amplitudes within each possible pitch and using the LASSO to choose which pitches are in the signal.",2016,
"Simulation Studies as Designed Experiments: The Comparison of Penalized Regression Models in the â€œLarge p, Small nâ€ Setting","New algorithms are continuously proposed in computational biology. Performance evaluation of novel methods is important in practice. Nonetheless, the field experiences a lack of rigorous methodology aimed to systematically and objectively evaluate competing approaches. Simulation studies are frequently used to show that a particular method outperforms another. Often times, however, simulation studies are not well designed, and it is hard to characterize the particular conditions under which different methods perform better. In this paper we propose the adoption of well established techniques in the design of computer and physical experiments for developing effective simulation studies. By following best practices in planning of experiments we are better able to understand the strengths and weaknesses of competing algorithms leading to more informed decisions about which method to use for a particular task. We illustrate the application of our proposed simulation framework with a detailed comparison of the ridge-regression, lasso and elastic-net algorithms in a large scale study investigating the effects on predictive performance of sample size, number of features, true model sparsity, signal-to-noise ratio, and feature correlation, in situations where the number of covariates is usually much larger than sample size. Analysis of data sets containing tens of thousands of features but only a few hundred samples is nowadays routine in computational biology, where ""omics"" features such as gene expression, copy number variation and sequence data are frequently used in the predictive modeling of complex phenotypes such as anticancer drug response. The penalized regression approaches investigated in this study are popular choices in this setting and our simulations corroborate well established results concerning the conditions under which each one of these methods is expected to perform best while providing several novel insights.",2014,PLoS ONE
Dynamic Brain Connectivity Alternation Detection via Matrix-variate Differential Network Model,"Motivation Nowadays brain connectivity analysis has attracted tremendous attention and has been at the foreground of neuroscience research. Brain functional connectivity reveals the synchronization of brain systems through correlations in neurophysiological measures of brain activity. Growing evidence now suggests that the brain connectivity network experiences alternations with the presence of numerous neurological disorders, thus differential brain network analysis may provides new insights into disease pathologies. For the matrix-valued data in brain connectivity analysis, existing graphical model estimation methods assume a vector normal distribution that in essence requires the columns of the matrix data to be independent. It is obviously not true, they have limited applications. Among the few solutions on graphical model estimation under a matrix normal distribution, none of them tackle the estimation of differential graphs across different populations. This motivates us to consider the differential network for matrix-variate data to detect the brain connectivity alternation. Results The primary interest is to detect spatial locations where the connectivity, in terms of the spatial partial correlation, differ across the two groups. To detect the brain connectivity alternation, we innovatively propose a Matrix-Variate Differential Network (MVDN) model. MVDN assumes that the matrix-variate data follows a matrix-normal distribution. We exploit the D-trace loss function and a Lasso-type penalty to directly estimate the spatial differential partial correlation matrix where the temporal information is fully excavated. We propose an ADMM algorithm for the Lasso penalized D-trace loss optimization problem. We investigate theoretical properties of the estimator. We show that under mild and regular conditions, the proposed method can identify all differential edges accurately with probability tending to 1 in high-dimensional setting where dimensions of matrix-valued data p, q and sample size n are all allowed to go to infinity. Simulation studies demonstrate that MVDN provides more accurate differential network estimation than that achieved by other state-of-the-art methods. We apply MVDN to Electroencephalography (EEG) dataset, which consists of 77 alcoholic individuals and 45 controls. The hub genes and differential interaction patterns identified are consistent with existing experimental studies. Contact heyong@sdufe.edu.cn Supplementary information Supplementary data are available online.",2018,bioRxiv
Structural changes in Ba(Sr1/3Ta2/3)O3-type perovskite compounds upon tilting of oxygen octahedra,"Since the early study by Galasso and Pyle, the structure of complex perovskite compounds with 1:2 ordering of B-site ions, ordered perovskite compounds, has been thought to be Ba(Sr1/3Ta2/3)O3-type hexagonal. Recently, a structural phase transformation has been found in A-site substituted ordered perovskite compounds, (Ba,Sr)(B'1/3B""2/3)O3. The structural change due to the phase transformation has been connected with the tilting of oxygen octahedra in the perovskite cell. However, the structure of the transformed phase has not been clarified because there has not been any model to treat the crystal structure of ordered perovskite compounds having tilted oxygen octahedra. In this paper, Glazer's model for structural changes in cubic perovskite due to the tilting of oxygen octahedra has been expanded to the 1:2 ordered perovskite. Based on the model, electron diffraction and X-ray diffraction of (Ba1-xSrx)(Mg1/3Ta2/3)O3 are discussed. A monoclinic unit cell in space group C2h6 with an angle Î³ > 90 Â°, which is derived from antiphase tilting of oxygen octahedra, successfully explains the experimental results.",1997,Japanese Journal of Applied Physics
Presence of sauvagine-like epitopes in the interrenal gland of the bullfrog Rana catesbeiana,"Abstract.Immunocytochemistry was used to investigate the presence of corticotropin-releasing factor-like peptides in the interrenal (adrenal) glands of the bullfrog Rana catesbeiana by using specific antisera raised against synthetic nonconjugated rat/human corticotropin-releasing factor, urotensin I, and sauvagine. From these three antisera, covering a broad range of corticotropin-releasing factor-like immunoreactivities, only the sauvagine antiserum gave positive immunoreactivity. Sauvagine immunoreactivity was found in cortical cells grouped into cords in the renal zone of the interrenal gland. The central and subcapsular cords were less stained. Tyrosine hydroxylase-positive chromaffin cells were not sauvagine-immunoreactive. The immunoreactivity was abolished, in all cases, by previous immunoabsorption of the sauvagine antiserum with synthetic sauvagine (0.1 Î¼M), but it was not eliminated by sucker (Catostomus commersoni) urotensin I, sole (Hippoglossoides elassodon) urotensin I, sucker corticotropin-releasing factor, rat/human corticotropin-releasing factor, or ovine corticotropin-releasing factor (0.1â€“10 Î¼M). In a sauvagine radioimmunoassay, interrenal extracts displaced 125I-sauvagine from antiserum only partially, and not in parallel with the sauvagine standard curve. The results suggest that the sauvagine immunoreactivity in the R. catesbeiana interrenal gland may represent a novel sauvagine-like peptide.",1995,Cell and Tissue Research
Comparative Genomics Analysis of a New Exiguobacterium Strain from Salar de Huasco Reveals a Repertoire of Stress-Related Genes and Arsenic Resistance,"The Atacama Desert hosts diverse ecosystems including salt flats and shallow Andean lakes. Several heavy metals are found in the Atacama Desert, and microorganisms growing in this environment show varying levels of resistance/tolerance to copper, tellurium, and arsenic, among others. Herein, we report the genome sequence and comparative genomic analysis of a new Exiguobacterium strain, sp. SH31, isolated from an altiplanic shallow athalassohaline lake. Exiguobacterium sp. SH31 belongs to the phylogenetic Group II and its closest relative is Exiguobacterium sp. S17, isolated from the Argentinian Altiplano (95% average nucleotide identity). Strain SH31 encodes a wide repertoire of proteins required for cadmium, copper, mercury, tellurium, chromium, and arsenic resistance. Of the 34 Exiguobacterium genomes that were inspected, only isolates SH31 and S17 encode the arsenic efflux pump Acr3. Strain SH31 was able to grow in up to 10 mM arsenite and 100 mM arsenate, indicating that it is arsenic resistant. Further, expression of the ars operon and acr3 was strongly induced in response to both toxics, suggesting that the arsenic efflux pump Acr3 mediates arsenic resistance in Exiguobacterium sp. SH31.",2017,Frontiers in Microbiology
Multidimensional analysis and detection of informative features in diffusion MRI measurements of human white matter,"The white matter contains long-range connections between different brain regions and the organization of these connections holds important implications for brain function in health and disease. Tractometry uses diffusion-weighted magnetic resonance imaging (dMRI) data to quantify tissue properties (e.g. fractional anisotropy (FA), mean diffusivity (MD), etc.), along the trajectories of these connections [1]. Statistical inference from tractometry usually either (a) averages these quantities along the length of each bundle in each individual, or (b) performs analysis point-by-point along each bundle, with group comparisons or regression models computed separately for each point along every one of the bundles. These approaches are limited in their sensitivity, in the former case, or in their statistical power, in the latter. In the present work, we developed a method based on the sparse group lasso (SGL) [2] that takes into account tissue properties measured along all of the bundles, and selects informative features by enforcing sparsity, not only at the level of individual bundles, but also across the entire set of bundles and all of the measured tissue properties. The sparsity penalties for each of these constraints is identified using a nested cross-validation scheme that guards against over-fitting and simultaneously identifies the correct level of sparsity. We demonstrate the accuracy of the method in two settings: i) In a classification setting, patients with amyotrophic lateral sclerosis (ALS) are accurately distinguished from matched controls [3]. Furthermore, SGL automatically identifies FA in the corticospinal tract as important for this classification â€“ correctly finding the parts of the white matter known to be affected by the disease. ii) In a regression setting, dMRI is used to accurately predict â€œbrain ageâ€ [4, 5]. In this case, the weights are distributed throughout the white matter indicating that many different regions of the white matter change with development and contribute to the prediction of age. Thus, SGL makes it possible to leverage the multivariate relationship between diffusion properties measured along multiple bundles to make accurate predictions of subject characteristics while simultaneously discovering the most relevant features of the white matter for the characteristic of interest.",2019,bioRxiv
A Research On Bitcoin Price Prediction Using Machine Learning Algorithms,"In this paper, we proposed to predict the Bitcoin price accurately taking into consideration various parameters that affect the Bitcoin value. By gathering information from different reference papers and applying in real time ,I found the advantages and disadvantages of bitcoin price prediction. Each and every paper has its own set of methodologies of bitcoin price prediction. Many papers has accurate price but some other donâ€™t, but the time complexity is higher in those predictions, so to reduce the time complexity here in this paper we use an algorithm linked to artificial intelligence named LASSO(least absolute shrinkage selection operator. The other papers used different algorithms like SVM(support vector machine),coinmarkupcap, Quandl, GLM, CNN(Convolutional Neural Networks)and RNN(Recurrent neural networks) etc.. which do not have a great time management, but in LASSO finding of the results from a larger database is quick and fast..so for this purpose we draw a comparison between other algorithms and the LASSO algorithm, this survey paper helps the upcoming researchers to make an impact in the their papers. The process happens in the paper is first moment of the research, we aim to understand and find daily trends in the Bitcoin market while gaining insight into optimal features surrounding Bitcoin price. Our data set consists of various features relating to the Bitcoin price and payment network over the course of every years, recorded daily. By preprocessing the dataset, we apply the some data mining techniques to reduce the noise of data. Then the second moment of our research, using the available information, we will predict the sign of the daily price change with highest possible accuracy.",2020,
Image restoration using L1 norm penalty function,"The process of estimating an original image from a given blurred and noisy image is known as image restoration. It is an ill-posed inverse problem, since one of the ways of solving it requires finding a solution to a Fredholm integral equation of convolution type in two-dimensional space. The focus of the article is to achieve a quality edge preserving image restoration using a less expensive (fast) regularization technique with L 1 norm penalty function. L 1 norm based approaches do not penalize edges or high frequency contents in the restored image compared to L 2 norm based approaches. Total variation (TV) is an established L 1 norm regularization approach that performs edge preserving image restoration, but at a high computational cost. TV regularization requires linearization of a highly nonlinear penalty term, which increases the restoration time considerably for large scale images. In order to reduce the computational cost, we extend least absolute shrinkage and selection operator (LASSO), an L 1 norm minimization statistical modeling technique to image restoration. The penalty function of LASSO is an identity matrix so it is computationally fast. The metrics, like, residual error, peak signal to noise ratio (PSNR), restoration time, edge map of the restored image, and subjective visual evaluation are used to assess the performances of both methods. Based on our experimental results, we show that LASSO achieves similar quality of edge preserving restoration as TV regularization, and is approximately two times faster in computation compared to TV regularization on the same set of images. We also analyze the impact of the different degree of blurring caused by point spread functions (PSFs) corrupted by different signal to noise ratios (SNRs) on image restoration.",2007,Inverse Problems in Science and Engineering
Icebound Modernity: The Shipwreck as Metaphor in Dan Simmonsâ€™ The Terror,"Abstract In this article, I seek to present a â€œmetaphorologyâ€ of the shipwreck through a literary example. As Hans Blumenberg has noted, the shipwreck has served as a metaphor for the contingency of human existence in Western culture. Building on Blumenbergâ€™s ideas, I argue that modernity heightens contingency and destroys the possibility of a coherent, anthropocentric discourse. For Quentin Meillassoux, the modern outlook exposes the contingency and inhumanity of reality. Building on Meillassoux and Blumenbergâ€™s work, I address ideas pertaining to contingency and the metaphor of modernity-as-shipwreck by engaging with Dan Simmonsâ€™ historical novel, The Terror (2007), based on events surrounding the failed Franklin Expedition of 1845-48. The sinister, frozen wastelands of the Arctic figure as the limit of both European humanity and rationality. In Simmonsâ€™ novel, the traumatic encounter with cultural otherness conjures up visions of an implosion of colonial ambitions, as the crew members are gradually consumed by both the harsh environment and the ancient Inuit ice demon Tuunbaq and must confront the indifferent frozen wastes of a mythological, gothic North. Simmonsâ€™ gothic North Pole constitutes an example of â€œextro-science fiction,â€ situated beyond the limits of all knowledge.",2019,"American, British and Canadian Studies"
Identification of a Five-Gene Signature and Establishment of a Prognostic Nomogram to Predict Progression-Free Interval of Papillary Thyroid Carcinoma,"Background: The incidence of papillary thyroid carcinoma (PTC) is high and increasing worldwide. Although prognosis is relatively good, it is important to select the minority of patients with poorer prognosis to avoid side effects associated with unnecessary over-treatment in low-risk patients; this requires accurate prognostic predictions. Materials and Methods: Six PTC expression datasets were obtained from the gene expression omnibus (GEO) database. Level 3 mRNA expression and clinicopathological data were obtained from The Cancer Genome Atlas Thyroid Cancer (TCGA-THCA) database. Through integrated analysis of these datasets, highly reliable differentially-expressed genes (DEGs) between tumor and normal tissue were identified and lasso Cox regression was applied to identify DEGs related to the progression-free interval (PFI) and to establish a prognostic gene signature. The performance of a five-gene signature was evaluated based on a Kaplan-Meier curve, receiver operating characteristic (ROC), and Harrell's concordance index (C-index). Multivariate Cox regression analysis was used to identify factors associated with PTC prognosis. Finally, a prognostic nomogram was established based on the TCGA-THCA dataset. Results: A novel five-gene signature was established to predict the PTC PFI, which included PLP2, LYVE1, FABP4, TGFBR3, and FXYD6, and the ROC curve and C-index showed good performance in both training and validation datasets. This could classify patients into high- and low-risk groups with distinct PFIs and differentiate PTC tumors from normal tissue. Univariate Cox regression revealed that this signature was an independent prognostic factor for PTC. The established nomogram, incorporating the prognostic gene signature and clinical parameters, was able to predict the PFI with high efficiency. The gene signature-based nomogram was superior to the American Thyroid Association (ATA) risk stratification to predict PTC PFI. Conclusions: Our study identified a five-gene signature and established a prognostic nomogram, which were reliable in predicting the PFI of PTC; this could be beneficial for individualized treatment and medical decision making.",2019,Frontiers in Endocrinology
