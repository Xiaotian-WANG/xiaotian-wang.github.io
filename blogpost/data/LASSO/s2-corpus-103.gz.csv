title,abstract,year,journal
Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations,"We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.",2009,IEEE Transactions on Visualization and Computer Graphics
Structureâ€“Activity Relationship of Inhibition of Fish Feeding by Sponge-derived and Synthetic Pyrroleâ€“Imidazole Alkaloids,"We investigated the relationship between the structures of pyrrole-containing alkaloids from marine sponges of the genus Agelas and their capacity to deter feeding by the omnivorous Caribbean reef fish, Thalassoma bifasciatum. Seven natural products were assayed at volumetric concentrations of 1, 5, and 10 mg/ml: dispacamide A, keramadine, oroidin, midpacamide, 4,5-dibromopyrrole-2-carboxylic acid, 4,5-dibromopyrrole-2carboxamide, and racemic longamide A. We also assayed 14 structural analogs obtained mostly by chemical synthesis. Of the seven natural products, only rac-longamide A was not significantly deterrent at any of the assay concentrations. The pyrrole moiety was required for feeding inhibition activity, while the addition of the imidazole group enhanced this activity. Variously functionalized imidazoles lacking the pyrrole moiety were not deterrent. Combinations of the natural products appeared to have an additive effect on feeding inhibition; there was no evidence of synergy. Given their high concentrations in sponge tissue, dispacamide A and oroidin most probably serve as the primary chemical defenses of many Agelas sp., while minor compounds such as keramadine are not present in high enough concentrations to contribute much to chemical defense.",2004,Journal of Chemical Ecology
Finite convergence of proximal-gradient inertial algorithms with dry friction damping,"In a Hilbert space H, based on inertial dynamics with dry friction damping, we introduce a new class of proximal-gradient algorithms with finite convergence properties. The function f : H â†’ R to minimize is supposed to be differentiable (not necessarily convex), and enters the algorithm via its gradient. The dry friction damping function Ï† : H â†’ R + is convex with a sharp minimum at the origin, (typically Ï†(x) = r x with r > 0). It enters the algorithm via its proximal mapping, which acts as a soft threshold operator on the velocities. This algorithm naturally occurs as a discrete temporal version of an inertial differential inclusion involving viscous and dry friction together. The convergence results tolerate the presence of errors, under the sole assumption of their asymptotic convergence to zero. Then, replacing the potential function f by its Moreau envelope, we extend the results to the case of a nonsmooth convex function f. In this case, the algorithm involves the proximal operators of f and Ï† separately. Several variants of this algorithm are considered, including the case of the Nesterov accelerated gradient method. We then consider the extension in the case of additive composite optimization, thus leading to new splitting methods. Numerical experiments are given for Lasso-type problems. The performance profiles, as a comparison tool, highlight the effectiveness of two variants of the Nesterov accelerated method with dry friction. Mathematics Subject Classifications: 37N40, 34A60, 34G25, 49K24, 70F40.",2019,
Situation Aware Multi-task Learning for Traffic Prediction,"Due to the recent vast availability of transportation traffic data, major research efforts have been devoted to traffic prediction, which is useful in many applications such as urban planning, traffic management and navigations systems. Current prediction methods that independently train a model per traffic sensor cannot accurately predict traffic in every situation (e.g., rush hours, constructions and accidents) because there may not exist sufficient training samples per sensor for all situations. To address this shortcoming, our core idea is to explore the commonalities of prediction tasks across multiple sensors who behave similarly in a specific traffic situation. Instead of building a model independently per sensor, we propose a Multi-Task Learning (MTL) framework that aims to first automatically identify the traffic situations and then simultaneously build one forecasting model for similar-behaving sensors per traffic situation. The key innovation here is that instead of the straightforward application of MTL where each ""task"" corresponds to a sensor, we relate each MTL's ""task"" to a traffic situation. Specifically, we first identify these traffic situations by running clustering algorithms on all sensors' data. Subsequently, to enforce the commonalities under each identified situation, we use the group Lasso regularization in MTL to select a common set of features for the prediction tasks, and we adapt efficient FISTA algorithm with guaranteed convergence rate. We evaluated our methods with a large volume of real-world traffic sensor data; our results show that by incorporating traffic situations, our proposed MTL framework performs consistently better than naively applying MTL per sensor. Moreover, our holistic approach, under different traffic situations, outperforms all the best traffic prediction approaches for a given situation by up to 18% and 30% in short and long term predictions, respectively.",2017,2017 IEEE International Conference on Data Mining (ICDM)
"Nerillidae (annelida: Polychaeta) from the White Sea, with Description of a New Species of Micronerilla Jouin","Abstract Nerillids are recorded for the first time from the White Sea. Four species were found: Meganerilla swedmarki Boaden, 1961, Nerillidium gracile Remane, 1925, Thalassochaetus palpifoliaceus Ax, 1954, and Micronerilla brevis sp. n. All four species are described and figured. The new species differs from the only other known member of the genus, M. minuta (Swedmark, 1959), in having seven rather than eight segments.",1997,Ophelia
Challenges in High-throughput Data Analysis: Proteomic Data Pre-processing and Network Methods for Integrating Multiple Data Types,"Author(s): Liao, Eileen | Advisor(s): Elashoff, Robert M | Abstract: 1) Proteomic Data Pre-processing: Quantification and Normalization of Luminex Assay System High through-put genomic and proteomic technologies allow rapid analysis of molecular targets of thousands of genes at a time, either at the DNA, RNA or protein level. In these type of experiments variations in expression measurements can occur from a variety of sources. Our goal was to examine measurement and normalization techniques to reduce the experimental variation in data derived from a bead-based multiplex Luminex assay system which allows simultaneous measurements of proteins. Normalization for the Luminex assay system requires a fundamentally different approach than the case of traditional microarrays. In the Luminex assay system, each experimental unit is a plate and each plate has results for multiple subjects and analytes. We quantified performance among different measurement systems (fluorescent intensity, background in fluorescent intensity, and observed concentration) in both high and standard scanning systems. Various normalization techniques (scale normalization, quantile normalization, lowess curve normalization) were adapted to the Luminex data scenario and their performance was compared in two datasets. We used the coefficient of variation across plates to compare the performance of normalization methods. Median and Lowess normalizations appeared to result in reducing plate- to-plate variation the most. Quantile normalization does not appear to work well for these datasets. Our results suggest that simple normalizations such as scale and lowess curve normalizations perform better than complex methods such as quantile normalization. Complex methods may add noise and bias to the normalized adjustment when the assumptions are not met. 2) Integration of microRNA and mRNA by Weighted Gene Co-expression Network AnalysisWe focus on the step-by-step network construction and module detection of mRNAs by weighted gene co-expression network analysis (WGCNA), followed by identifying the strong correlation between miRNA and module eigengenes. We then evaluate whether the predicted mRNA targets are differentially present between a given module and other modules by using the Fisher's exact test. We retained miRNAs who are significant in the fisher exact test, and are strongly correlated with eigengenes in a module.Next we relate modules to disease status by using eigengene network methodology, we found that 11 out of 13 modules are significantly related with disease status. Enrichment analyses by DAVID software are implemented for the 11 modules. We also run step-by-step network construction and module detection of miRNAs and found 6 modules. We used LASSO regression to explore the relationship between miRNA and mRNAs. The predictors are module eigengene of miRNA and the outcome is the eigengene from each mRNA module. We found that 1 miRNA ""hsa_miR_25"" is significantly anti-correlated with mRNA Magenta module. ""hsa_miR_25"" belongs to the miRNA module ""blue"" that is also predictive to Magenta mRNA module through LASSO regression. Its putative mRNA targets are found and integrated from the renal dataset. In conclusion, the weighted co-expression network analysis provides a novel integrative view of miRNA and their putative genes. It also greatly alleviates the multiple testing problems that plague standard gene-centric methods.",2012,
FEAST: An Automated Feature Selection Framework for Compilation Tasks,"Modern machine-learning techniques greatly reduce the efforts required to conduct high-quality program compilation, which, without the aid of machine learning, would otherwise heavily rely on human manipulation as well as expert intervention. The success of the application of machine-learning techniques to compilation tasks can be largely attributed to the recent development and advancement of program characterization, a process that numerically or structurally quantifies a target program. While great achievements have been made in identifying key features to characterize programs, choosing a correct set of features for a specific compiler task remains an ad hoc procedure. In order to guarantee a comprehensive coverage of features, compiler engineers usually need to select excessive number of features. This, unfortunately, would potentially lead to a selection of multiple similar features, which in turn could create a new problem of bias that emphasizes certain aspects of a program's characteristics, hence reducing the accuracy and performance of the target compiler task. In this paper, we propose FEAture Selection for compilation Tasks (FEAST), an efficient and automated framework for determining the most relevant and representative features from a feature pool. Specifically, FEAST utilizes widely used statistics and machine-learning tools, including LASSO, sequential forward and backward selection, for automatic feature selection, and can in general be applied to any numerical feature set. This paper further proposes an automated approach to compiler parameter assignment for assessing the performance of FEAST. Intensive experimental results demonstrate that, under the compiler parameter assignment task, FEAST can achieve comparable results with about 18% of features that are automatically selected from the entire feature pool. We also inspect these selected features and discuss their roles in program execution.",2017,2017 IEEE 31st International Conference on Advanced Information Networking and Applications (AINA)
Credit Risk Calibration Based on CDS Spreads,"As observed in the financial crisis, CDS spreads tend to increase simutaneously as a reaction to common shocks. Focusing on the spillover effects triggered by extreme events, we propose a credit risk analysis tool by applying credit default swap spread returns to the concept of 4CoVaR suggested by Adrian and Brunnermeier (2011). The interconnection and mutual impact on credit spreads are investigated based on CDS spreads of the biggest derivative dealers in the market. By including factors identified as determinants of CDS spreads to the set of explanatory variables such as equity return and equity volatility and implementing the variable selection technique least absolute shrinkage and selection operator (LASSO), the results demonstrate an improved performance in CDS spread VaR calculation. The enhancement is more significant in pre-crisis period but both methodologies tend to overestimate risk in turbulent period. Further, non-linear effects between CDS spreads in extreme events are captured by the introduction of a partial linear model in the CoVaR calculation.",2014,
Supplemental Material to â€œmodel Selection and Structure Specification in Ultra-high Dimensional Generalised Semi-varying,"In this paper, we study the model selection and structure specification for the generalised semi-varying coefficient models (GSVCMs), where the number of potential covariates is allowed to be larger than the sample size. We first propose a penalised likelihood method with the LASSO penalty function to obtain the preliminary estimates of the functional coefficients. Then, using the quadratic approximation for the local log-likelihood function and the adaptive group LASSO penalty (or the local linear approximation of the group SCAD penalty) with the help of the preliminary estimation of the functional coefficients, we introduce a novel penalised weighted least squares procedure to select the significant covariates and identify the constant coefficients among the coefficients of the selected covariates, which could thus specify the semiparametric modelling structure. The developed model selection and structure specification approach not only inherits many nice statistical properties from the local maximum likelihood estimation and nonconcave penalised likelihood method, but also computationally attractive thanks to the computational algorithm that is proposed to implement our method. Under some mild conditions, we establish the asymptotic properties for the proposed model selection and estimation procedure such as the sparsity and oracle property. We also conduct simulation studies to examine the finite sample performance of the proposed method, and finally apply the method to analyse a real data set, which leads to some interesting findings.",2015,
"The discovery of Lake Hephaestus, the youngest athalassohaline deep-sea formation on Earth","Hydrated, magnesium-rich minerals and subglacial brines exist on the martian surface, so the habitability of high-Mg2+ environments on Earth has extraterrestrial (as well as terrestrial) implications. Here, we report the discovery of a MgCl2-dominated (4.72â€‰M) brine lake on the floor of the Mediterranean Ridge that underlies a 3500-m water column, and name it Lake Hephaestus. Stable isotope analyses indicated that the Hephaestus brine is derived from interactions between ancient bishofite-enriched evaporites and subsurface fluids. Analyses of sediment pore waters indicated that the Hephaestus depression had contained the MgCl2 brine for a remarkably short period; only 700 years. Lake Hephaestus is, therefore, the youngest among currently known submarine athalassohaline brine lakes on Earth. Due to its biologically hostile properties (low water-activity and extreme chaotropicity), the Hephaestus brine is devoid of life. By contrast, the seawater-Hephaestus brine interface has been shown to act as refuge for extremely halophilic and magnesium-adapted stratified communities of microbes, even at MgCl2 concentrations that approach the water-activity limit for life (0.653).",2019,Scientific Reports
"Kennett: The Island Chumash, Behavioral Ecology of a Maritime Society","Author(s): Glassow, Michael A. | Abstract: The Island Chumash, Behavioral Ecology of a Maritime Society Douglas J. Keimett. Berkeley and Los Angeles: University of California Press, 2005.310 pp., 22 b/w photographs, 23 line illustrations, 15 maps, 20 tables, $60 (cloth).",2005,Journal of California and Great Basin Anthropology
Brain Regions Involved in Arousal and Reward Processing are Associated with Apathy in Alzheimer's Disease and Frontotemporal Dementia.,"BACKGROUND
Apathy is a common and problematic symptom of several neurodegenerative illnesses, but its neuroanatomical bases are not understood.


OBJECTIVE
To determine the regions associated with apathy in subjects with mild Alzheimer's disease (AD) using a method that accounts for the significant co-linearity of regional atrophy and neuropsychiatric symptoms.


METHODS
We identified 57 subjects with mild AD (CDRâ€Š=â€Š1) and neuropsychiatric symptoms in the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. We performed a multivariate multiple regression with LASSO regularization on all symptom subscales of the Neuropsychiatric Inventory and the whole-brain ROI volumes calculated from their baseline MRIs with FreeSurfer. We compared our results to those from a previous study using the same method in patients with frontotemporal dementia (FTD) and corticobasal syndrome (CBS).


RESULTS
Of neuropsychiatric symptoms, apathy showed the most robust neuroanatomical associations in the AD subjects. Atrophy of the following regions were independently associated with apathy: the ventromedial prefrontal cortex; ventrolateral prefrontal cortex; posterior cingulate cortex and adjacent lateral cortex; and the bank of the superior temporal sulcus. These results replicate previous studies using FTD and CBS patients, mostly agree with the previous literature on apathy in AD, and correspond to the Medial and Orbital Prefrontal Cortex networks identified in non-human primates.


CONCLUSION
The current study, previous studies from our laboratory, and the previous literature suggest that impairment of the same brain networks involved in arousal, threat response, and reward processing are associated with apathy in AD and FTD.",2017,Journal of Alzheimer's disease : JAD
Neurinoma Pelvico Retroperitoneale a Derutto Clinico Urologico,"L'ubicazione dei neurinorni, III quanto tumori originantisi dalle strutture dei nervi cerebro-spinali, e delle pill varie. In pratica, le sedi elettive sono: I) l'angolo ponto-cerebellare (dalla branca vestibolare del n. acustico): .2) il torace (dalle radici posteriori spinali caratteristici, tra questi, i neurinomi (( a clessidra Â» costituiti da due propaggini, una rachidiana ed una toracica, riunite da un ponte attraverso il forame di coniugazione vertebrate): 3) gli ani (dai tronchi nervosi periferici, specie dallo sciatico, e loro diramazioni). Relativamente frequenti sono anche i neurinomi del tubo digerente: 58 casi di n. gastrico in una statistica elaborata anni addietro da RONZINI. Singoli casi di neurinoma di stretto interesse urologico sono stati descritti: in Spagna da PERAI. ARANDA (neurinoma del pene), negli U.S.A. da PHILLIPS e BAUMRUCKER (neurinoma del rene). da FEIN e HAM1\( (n. maligno del bacinetto renale), da CARI.SON (neurinoma del perineo maschile) e da COWEN (n. della vaginale del testicolo), in Francia da MARTINOT e colI. (n. maligno del rene) e da RO~IETTI e RAnlOND (n. pararenale). Neurinomi di tessuti ed organi adiacenti all'apparato urogenitale sono riportati da FOWLER (n. della cauda equina), daGRoNBAECK (n. del setto retto-vaginale], da SYRED (n. del muscolo psoas) e, per la localizzazione retroperitoneale, da MEI.ICOW. da PACK e TABAH, da DEMING e NEUMANN, da MELASSONoS e coll., da FOOTE e coll, In questa categoria rientrano, evidentemente, i neurinomi endopelvici sottoperitoneali: nella letteratura ne esistono alcune osservazioni (in Italia: CAROZZINI. 1956; MANARA e IJEDROITI, 1962) rna si tratta di casi assai sporadici a paragone dei tumori di pill frequenteriscontro nella regione (cordomi, teratomi e teratoidi, lipomi, ecc.), Abbiamo ritenuto, pertanto, di dover segnalare il casu occorso alia nostra osservazione, anche per le manifestazioni urologiche che gli hanno conferito una fisionomia particolare e che, indirettamente, hanno tradito la presenza del tumore extraurinario di per se clinicamente muto,",1966,Urologia Journal
"Peri-urban farming, Grugliasco","INTRODUZIONE 
Il fenomeno di peri-urbanizzazione e in aumento da diversi decenni in Europa. La comunita scientifica sta cercando di definire i paradigmi teorici al fine di individuare i driver e di sviluppare strumenti di analisi per interpretarli. Le autorita pubbliche stanno cercando di implementare procedure di regolamentazione efficaci per superare gli effetti collaterali di peri-urbanizzazione, come ad esempio l'espansione urbana, il paesaggio informe, e, piu recentemente, il danno ambientale di maggiore mobilita e dispersione. Allo stesso tempo, l'agricoltura sta cambiando in modo da rispondere ai problemi multifunzionali ad in modo da generare nuove opportunita di sviluppo. Se le nuove forme di agricoltura stanno emergendo e i sistemi lasciati alle spalle dopo la modernizzazione dell'agricoltura stanno riemergendo, lo sviluppo agricolo nelle zone peri-urbane rimane in gran parte sconosciuto. Ci sono diverse dinamiche periurbane che si esprimono a diversi livelli organizzativi. La differenziazione delle aree peri-urbane e una qualita intrinseca che le statistiche di zonizzazione o i modelli di sviluppo settoriali non spiegano pienamente. I processi di peri-urbanizzazione portano alle zone ibride che possono essere concentrate o limitate ai bordi delle periferie, secondo diverse configurazioni spaziali. Spesso viene preso in considerazione dal punto di vista urbanistico ma senza alcun riferimento alla percezione rurale di queste aree marginali. 
principali risultati indicano che l'agricoltura del territorio periurbano, per la qualita della vita nelle regioni urbane, soddisfa le ampie gamme di funzioni e servizi per le aree urbane circostanti. Questo include la produzione alimentare, nonche la fornitura di servizi ricreativi e di altri servizi connessi alla gestione del paesaggio culturale, che a sua volta contribuisce alla capacita ecologica del paesaggio. Si e trovato che PUA si distingue dalla prevalenza tramite due elementi di produzione intensificata, alto valore produttivo, da un lato, e stile di vita estensivo e uso guidato del suolo ambientale dall'altro. I ricavi ad alto reddito, le strutture aziendali di piccole dimensioni e il parallelismo di orticoltura e coltivazione pratiera rappresentano le sue tipiche caratteristiche. 
La tecnologia moderna ha consentito un ulteriore separazione fra il settore agricolo e la citta; tuttavia, il nuovo pensiero e la sperimentazione hanno mostrato un rapporto simbiotico tra i due. L'agricoltura verticale e l'agricoltura urbana e peri-urbana sono i nuovi movimenti che cercano di ridurre l'impatto umano sulla terra e di consentire alle citta di diventare piu resistenti al collasso ambientale. Teoricamente, incorporando l'agronomia nelle nostre citta, l'agricoltura sara in grado di trasformare il nostro approccio allo sviluppo urbano e di consentire alle persone di diventare autosufficienti utilizzando la progettazione urbana e architettonica come strumenti didattici per il cibo. L'agricoltura e l'urbanistica non sono piu considerate mutualmente esclusive, ma piuttosto, la loro giustapposizione offre l'opportunita di sponsorizzare la crescita delle citta. Nel Global City Blues, Daniel Solomon afferma che, ""Il cibo e l'urbanistica sono entrambi fondamentali per l'esperienza umana"". Inserendo il paesaggio agrario nell'ambiente urbano, la comunita e la collaborazione sono sostenute nella sfera pubblica attraverso il loro servizio produttivo. Recentemente riconosciuto attraverso una teoria contemporanea, ""l'agricoltura urbana attiva spazio urbano"". Con la crescita di popolarita di orti urbani e Slow Food Movement, l'agricoltura puo essere un unificatore comune all'interno della citta. 
Si prevede che la specie umana probabilmente dovra affrontare una serie di difficolta sia ambientali sia economiche derivanti dalla nostra attuale mancanza di preoccupazione per l'ambiente. L'agricoltura urbana e peri-urbana sono strumenti che possono permettere di lavorare in simbiosi con I processi naturali. Il dottor Dickson Despommier afferma, ""cio che e piu necessario a questo punto della nostra storia, non e ancora un'altra tecnosoluzione rapida, ma piuttosto una revisione permanente nel modo In cui ci comportiamo come una specie"". L'agricoltura urbana e il prossimo passo verso questo atteggiamento. Con l'inclusione dell'agricoltura nell'ambiente urbano, essa puo rimodellare la sfera pubblica e consentire alle persone di diventare piu autosufficienti. 
L'obiettivo di questa tesi e quello di contribuire a un dibattito piu generale e completo, proponendo le definizioni specifiche e le nuove proposte progettuali in queste aree.",2017,
The SgLasso and its cousins for selective genotyping and extreme sampling: application to association studies and genomic selection,"We introduce a new variable selection method, called SgLasso, that handles extreme data, and suitable when the correlation between regressors is known. It is appropriate in genomics since once the genetic map has been built, the correlation is perfectly known. Besides, we prove that the signal to noise ratio is largely increased by considering the extremes. Our method relies on the construction of a specific statistical test, a transformation of the data and by the knowledge of the correlation between regressors. This new technique is inspired by stochastic processes arising from statistical genetics. Our approach and existing methods are compared for simulated and real data, and the results point to the validity of our approach.",2019,
Verlasso Launches Save the Fish | Verlasso,"Verlasso today launched Save the Fish, a consumer campaign to help sustainable seafood purchasers at retailers understand their impact.",2015,
Die later with ESCRT!,"The consequences of necroptosis depend on immunomodulatory molecules, the expression of which requires time before the burst of a cell. Gong et al. now provide evidence for ESCRT-III-mediated plasma membrane repair to extend the time to death during necroptosis. Regulated cell death is not restricted to apoptosis, but includes several forms of regulated necrosis. The best characterized signaling pathway of regulated necrosis is necroptosis. Diverse signaling pathways, such as TNFR1-signaling, TLR-signaling and others may result in receptor-interacting protein kinase 3 (RIPK3)dependent phosphorylation and oligomerization of the pseudokinase mixed-lineage kinase domain-like (MLKL). It has been proposed that pMLKL may form pores in the plasma membrane, but the actual processes following plasma membrane translocation remain unclear [1]. In a recent report published in Cell, Gong et al. discovered the ESCRT-III-machinery as an active counterpart of pMLKLassociated membrane damage [2]. As necroptosis actively shapes the immune response [3], ESCRT-III indirectly controls the immunogenicity of necroptotically dying cells. Applying a system to artificially dimerize RIPK3 or MLKL, Gong et al. detected cells that rapidly expose phosphatidylserine (PS) at the outer leaflet of the plasma membrane, a cell death feature that had been associated with apoptosis for the last decades. Single cell analysis revealed the shedding of PS-positive â€œbubblesâ€. Unlike apoptotic bodies, these â€œbubblesâ€ did not contain cytosolic remnants but consisted of broken membranes, as they are permeable to 10 kDa dextran-NH2. These bubbles formed at sites of pMLKL-accumulation, quite similar to what had been previously reported about viral budding in dependence of the ESCRT complex machinery [4]. Indeed, the ESCRT-III-protein CHMP4B co-localized with MLKL at the basis of â€œbubblesâ€. A previous study demonstrated ESCRT-mediated repair of laser-damaged membranes [4], but a link to necroptosis was not provided. In line with this, silencing of ESCRT-III-proteins CHMP2A or CHMP4B resulted in spontaneous necroptosis which was prevented by silencing of RIPK3 or MLKL, or by addition of RIPK1-inhibitor Nec-1s. Conversely, silencing of ESCRT-III-proteins CHMP4B, VPS4B, CHMP2A or ESCRT-I-proteins TSG101 or VPS37B sensitized cells to TNF-induced necroptosis even with active caspase-8 which appears to prevent necroptosis independently of this mechanism. Therefore, this study demonstrates the complex interplay between the ESCRT-III machinery and necroptosis execution, prompting the hypothesis of ESCRT-III to delay the time to plasma membrane rupture and release of damage associated molecular patterns (DAMPs). Indeed, even hardly detectable levels of pMLKL were sufficient to induce necroptosis if ESCRT-III was compromised. Along similar lines, active ESCRT-III delayed membrane breakdown resulting in less chemokine production and less efficient cross-priming of T cells as a consequence of a delay in DAMP release. MLKL was recently demonstrated to trigger processing and release of both anti-inflammatory cytokines, such as IL-33 and CXCL1, as well as the proinflammatory cytokine IL-1Î² [5]. It will be of interest to precisely unravel the proand anti-inflammatory components released by necroptotically dying cells, especially in comparison with cellular cytokines released during distinct pathways of regulated necrosis, such Editorial: Autophagy and Cell Death",2017,Oncotarget
Feature selection and survival modeling in The Cancer Genome Atlas,"PURPOSE
Personalized medicine is predicated on the concept of identifying subgroups of a common disease for better treatment. Identifying biomarkers that predict disease subtypes has been a major focus of biomedical science. In the era of genome-wide profiling, there is controversy as to the optimal number of genes as an input of a feature selection algorithm for survival modeling.


PATIENTS AND METHODS
The expression profiles and outcomes of 544 patients were retrieved from The Cancer Genome Atlas. We compared four different survival prediction methods: (1) 1-nearest neighbor (1-NN) survival prediction method; (2) random patient selection method and a Cox-based regression method with nested cross-validation; (3) least absolute shrinkage and selection operator (LASSO) optimization using whole-genome gene expression profiles; or (4) gene expression profiles of cancer pathway genes.


RESULTS
The 1-NN method performed better than the random patient selection method in terms of survival predictions, although it does not include a feature selection step. The Cox-based regression method with LASSO optimization using whole-genome gene expression data demonstrated higher survival prediction power than the 1-NN method, but was outperformed by the same method when using gene expression profiles of cancer pathway genes alone.


CONCLUSION
The 1-NN survival prediction method may require more patients for better performance, even when omitting censored data. Using preexisting biological knowledge for survival prediction is reasonable as a means to understand the biological system of a cancer, unless the analysis goal is to identify completely unknown genes relevant to cancer biology.",2013,International Journal of Nanomedicine
"Palynofacies, palaeoenvironmental change and sequence stratigraphy of the Middle Jurassic, Cleveland Basin and Brent Group of the UK","Palynofacies analysis, which is the study of microscopic organic matter can, in association with sedimentolog- ical and palaeoecological data, provide temporal and spatial resolution in the characterisation of sedimentary environments and potentially, vegetation and climate. However, the reliability of palynofacies analysis as a tool for environmental reconstruction has been questioned recently. This uncertainty is due a number of factors, including the lack of standardisation in the processing and counting of organic matter, subjective and vague terminology used to classify organic matter, and existence of numerous classification schemes. These have all restricted comparison between studies and hence hampered the advance of palynofacies analysis. The most important factor is, however, limited understanding of the controls which govern the genesis of particular associations of particulate organic matter. These issues were addressed using a two-fold approach. Firstly, the particulate organic matter classification scheme created by Lewis in 1995 was tailored to produce a robust hierarchical classification scheme. Secondly, multivariate statistical analysis was applied to a Middle Jurassic data set. This revealed that the primary control upon the nature of the organic matter associations is preservation potential which is affected by redox status, and to a lesser extent by the degree and duration of transportation and disturbance to which the organic-matter has been subjected. The secondary influence was determined to be a change in the nature of organic matter through time. Following this analysis 19 different organic-matter assemblage groups were defined to decipher palaeoenvironmental changes during the Middle Jurassic. Variations in the associations of organic matter through the Aalenian to Bathonian reflect changes in the redox status, proximity to source, salinity and hydrodynamics. This investigation suggests that aridity and/or pronounced seasonality commenced during the early Bajocian of the region which is earlier than the findings of previous investigations. This is based principally on the concomitant increase in black fragments (charcoal) and acme of Classopollis pollen in both the Cleveland Basin and Brent Group. The black fragments are probably charcoal rather than post-depositionally altered fragments because they occur in a range of oxic and anoxic environments, in conjunction with brown fragments, and in a range of lithofacies. These results not only permit the characterisation of the environment of deposition but also illustrate that palynofacies yields a discernible climatic signal.",1999,
The economic value of children: a case study from rural India.,"
 This study compares the theses of Mamdami, that India's poor have large families as an investment, and Vlassoff, that only a weak connection exists between a child's economic utility and household fertility. Data used in the study were based on a sample of 18 children in Bihar state, India, on 1) expenditures on children, 2) opportunity costs of raising children, 3) child earnings, 4) child earnings given to parents, 5) alternative investments, 6) discount rates appropriate for parents to use, 7) parents' perceptions of the economic value of children, and 8) family size. Costs estimated included food, clothing, schooling, health, other, and opportunity costs in bearing and raising children. Benefits include estimated values for work within and outside the family. 2 balances indicate that 7 or 8 children, aged 6 to 15, provide more labor than they cost to keep. Data suggest that children become valuable to parents at about age 9 or 10. From this age on, benefits increasingly outweigh costs; by the age of 16 or 17, children have repaid their initial costs to parents. Comparing the value of children against local bank interest rates shows that in all cases but one, children provided a better economic investment than savings accounts. The authors suggest that children are an even greater economic investment in poorer households. Doling out condoms and pills is no substitute for child wealth. In Bihar, improving people's economic well-being may be a prerequisite to fertility decline.
",1985,Applied geography
New Algorithms for Predicting Conformational Polymorphism and Inferring Direct Couplings for Side Chains of Proteins,"Protein crystals populate diverse conformational ensembles. Despite much evidence that there is widespread conformational polymorphism in protein side chains, most of the xray crystallography data are modelled by single conformations in the Protein Data Bank. The ability to extract or to predict these conformational polymorphisms is of crucial importance, as it facilitates deeper understanding of protein dynamics and functionality. This dissertation describes a computational strategy capable of predicting side-chain polymorphisms. The applied approach extends a particular class of algorithms for side-chain prediction by modelling the side-chain dihedral angles more appropriately as continuous rather than discrete variables. Employing a new inferential technique known as particle belief propagation (PBP), we predict residue-specific distributions that encode information about side-chain polymorphisms. The predicted polymorphisms are in relatively close agreement with results from a state-of-the-art approach based on x-ray crystallography data. This approach characterizes the conformational polymorphisms of side chains using electron density information, and has successfully discovered previously unmodelled conformations. Furthermore, it is known that coupled fluctuations and concerted motions of residues can reveal pathways of communication used for information propagation in a molecule and hence, can help in understanding the â€œallosteryâ€ phenomenon in proteins. In order to characterize the coupled motions, most existing methods infer structural dependencies among a proteinâ€™s residues. However, recent studies have highlighted the role of coupled side-chain fluctuations alone in the allosteric behaviour of proteins, in contrast to a common belief that the backbone motions play the main role in allostery. These studies and the aforementioned recent discoveries about prevalent alternate side-chain conformations (conformational polymorphism) accentuate the need to devise new computational approaches that acknowledge side chainsâ€™ roles. As well, these approaches must consider the polymorphic nature of the side chains, and incorporate effects of this phenomenon (polymorphism) in the study of information transmission and functional interactions of residues in a molecule. Such frameworks can provide a more accurate understanding of the allosteric behaviour. Hence, as a topic related to the conformational polymorphism, this dissertation addresses the problem of inferring directly coupled side chains, as well. First, we present a novel approach to generate an ensemble of conformations and an efficient computational method to extract direct couplings of side chains in allosteric proteins. These direct couplings are used to provide sparse network representations of the coupled side chains. The framework is based on a fairly new statistical method, named graphical lasso (GLASSO),",2015,
Der ultraviolette und ultrarote Teil des Spektrums,"Die Erforschung des ultravioletten Spektralbereichs gestaltet sich, je weiter man einzudringen sucht, immer schwieriger, und mehr als einmal zwangen scheinbar unuberwindliche Hindernisse zu einer langeren Pause. Erfahrungen und Ergebnisse aber auf anderen Gebieten im Verein mit verfeinerten spektroskopischen Hilfsmitteln kamen der Forschung zu Hilfe, und es gelang namentlich in neuerer Zeit, den Anschlus an die kurzesten Wellen, die Rontgenstrahlen, wenn auch nicht zu erreichen, so doch sich ihm wesentlich zu nahern. Schon im Bereich Î» = 3000 A.-E. scheidet die direkte Beobachtung mit dem Auge aus; da indessen heute fast alle Beobachtungen mittels der Photographie ausgefuhrt werden, so fallt dies nicht so sehr ins Gewicht. Wegen der Absorption der Strahlen in gewohnlichem Glas unterhalb Î» = 3400 hilft man sich mit besonderen Glassorten zur Ausrustung des optischen Teils oder man nimmt Quarz und endlich Flusspath. Uviolglas der. Firma Schott und Genossen in Jena last das Strahlengebiet bis etwa Î» = 2600 A.-E. durch, wahrend Quarz noch die Untersuchung bis 1800 gestattet. Fur noch kleinere Wellen mus man Flusspat nehmen. Allein man wurde damit auch nicht viel weiter kommen, da fur derartig kleine Wellen die Luft und die in ihr enthaltenen Gase und Dampfe stark absorbieren, wenn man diese Storung nicht beseitigen konnte. Nun aber absorbiert die Gelatine der gebrauchlichen Trockenplatten in dunnster Schicht bereits alles kurzwellige Licht von dieser Grosenordnung.",1926,
A data-driven approach to prostate cancer detection from dynamic contrast enhanced MRI,"Magnetic resonance imaging (MRI), particularly dynamic contrast enhanced (DCE) imaging, has shown great potential in prostate cancer diagnosis and staging. In the current practice of DCE-MRI, diagnosis is based on quantitative parameters extracted from the series of T1-weighted images acquired after the injection of a contrast agent. To calculate these parameters, a pharmacokinetic model is fitted to the T1-weighted intensities. Most models make simplistic assumptions about the perfusion process. Moreover, these models require accurate estimation of the arterial input function, which is challenging. In this work we propose a data-driven approach to characterization of the prostate tissue that uses the time series of DCE T1-weighted images without pharmacokinetic modeling. This approach uses a number of model-free empirical parameters and also the principal component analysis (PCA) of the normalized T1-weighted intensities, as features for cancer detection from DCE MRI. The optimal set of principal components is extracted with sparse regularized regression through least absolute shrinkage and selection operator (LASSO). A support vector machine classifier was used with leave-one-patient-out cross validation to determine the ability of this set of features in cancer detection. Our data is obtained from patients prior to radical prostatectomy and the results are validated based on histological evaluation of the extracted specimens. Our results, obtained on 449 tissue regions from 16 patients, show that the proposed data-driven features outperform the traditional pharmacokinetic parameters with an area under ROC of 0.86 for LASSO-isolated PCA parameters, compared to 0.78 for pharmacokinetic parameters. This shows that our novel approach to the analysis of DCE data has the potential to improve the multiparametric MRI protocol for prostate cancer detection.",2015,Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society
The LASSO for generic design matrices as a function of the relaxation parameter,"The LASSO is a variable subset selection procedure in statistical linear regression based on $\ell_1$ penalization of the least-squares operator. Its behavior crucially depends, both in practice and in theory, on the ratio between the fidelity term and the penalty term. We provide a detailed analysis of the fidelity vs. penalty ratio as a function of the relaxation parameter. Our study is based on a general position condition on the design matrix which holds with probability one for most experimental models. Along the way, the proofs of some well known basic properties of the LASSO are provided from this new generic point of view.",2011,arXiv: Statistics Theory
Breeding biology of the Atlantic Least Tern (Sternula antillarum antillarum) in a colony of the south of the Gulf of Mexico: new perspectives for its threat status,"Although the Atlantic Least Tern ( Sternula antillarum antillarum ) faces the same threats that caused the California Least Tern ( S. antillarum browni ) and the Interior Least Tern ( S. antillarum athalassos ) to be declared threatened, it is considered as â€œLeast concernâ€ globally, mainly because of its wide geographic distribution. However, many populations are threatened and the conservation status of several others is unknown. We evaluate, for the first time, the breeding biology of a colony of Atlantic Least Terns in the southern Gulf of Mexico. During the 2010 breeding season we censused and analyzed some relevant breeding variables for the stability of a colony at Terminos Lagoon. The starting date of egg laying and breeding peak, the clutch size variation during the breeding season and the main causes of eggs loss are similar to those reported for other colonies of this species. However, we found that the size of first (A) and single (S) eggs did not change throughout the season, but second (B) eggs size decreased. The number of breeding pairs and its higher hatching success in comparison with other colonies allow us to affirm that the colony of the Terminos Lagoon must be taken into account in conservation programs of this species. These results will settle the basis to reconsider its threat status globally and to compare breeding parameters with other colonies from the region.",2016,Revista Brasileira de Ornitologia - Brazilian Journal of Ornithology
Book Review: Patient Recruitment in Clinical Trials,"Anyone involved in recruiting patients for clinical trials understands the importance and frustration of this process. The best-written protocols ~d most meaningful research frequently hinge on whether the right panents are enrolled and remain in the study. It appears that researchers, and es~cially n~w investigators, spend little time in planning appropriate patient recruitment. The inability to effectively recruit subjects can quickly damage both the investigator's as well as the study site's reputation for conducting efficient trials. Therefore, books such as this one are extremely valuable. Although this book is over 300 pages long, it is quite easy to read and is organized in a fashion that lends itself to quick retrieval of information. The text is divided primarily into two major parts: (I) overview and eleme.nts of recruitment and (2) synthesis of these elements. Although there IS some redundancy, the information presented is insightful not only as to what is involved in the recruitment process, but also as to how some of the inevitable obstacles that these authors have obviously endured may be overcome. The major chapters of part I discuss sources of patients for clinical trials, methods of recruiting, ethical issues involved in .rec~itment, and important economic issues. The chapters in part II pnmanly focus on developing a recruitment strategy and overcoming obstacles when recruitment is not going well. Also included in this section is a chapter that deals with publishing data pertaining to the recruitment process. This chapter is quite interesting and should prove helpful to researchers and authors alike. In my opinion, the most useful feature of this book is its many samples of actual brochures, advertisements, letters, and o~er patient-recruitment material. As a result, the text is a very practical guide to recruitment rather than simply a collection of theoretical science that will be read once and then put on the shelf. I know that our clinical research service will find this book very useful, especially when developing new approaches to patient recruitment, advertising, and dealing with recruitment failures. Another major advantage of this text is its well-organized and extensive subject index. The appendix is also insightful and consists of a list of commonly asked questions about recruitment problems as well as the authors' .attempts to answer these questions in a very specific and practical fashion, The only drawback to this section is that it is not long enough, I believe that there are many other questions that are frequently raised and I would have found a more extensive question-and-answer format beneficial. A problem with this book is the overwhelming number of tables and charts. There are 81 tables and 76 figures. The text is interrupted frequently and many times these charts offer little useful information. An issue not addressed in the book is that of recruiting critically ill patients who are unable to give informed consent themselves into clinical trials. This poses an ever-increasing problem for investigators and institutional review bo~ds alike. State laws vary considerably, creating controversy and.confusion. Although a minor point, the book also could be improved by including references at the conclusion of each chapter rather than at the very end of the book. Overall, PatientRecruitmentin ClinicalTrials is an excellent resource for anyone involved in research. We have run across numerous patientrecruitment problems in our research program in the past that this book could have helped us with-it fills a definite void. Most textbooks and articles that deal with patient recruitment are much less practical and applicable in specific situations. This book is both. The authors' writing style should be applauded. MARK W.TODD, Phann.O. AssociateDirector Departmentof Pharmacy University MedicalCenter ClinicalAssociateProfessor CollegeofPharmacy University ofFlorida Jacksonville. Florida32209",1993,Annals of Pharmacotherapy
Artistic Director and Conductor of Adelaide Chamber Singers 2003 Subscription Series 'Diverse Natures',"The series involved 8 performances of 4 programs and was sponsored and supported by Arts SA and the Australia Council. The series included three new works : the world premiere of Six Holy Sonnets by Adelaide composer Diana Weekes (texts by John Donne) ; the performance of Carl Crossin's own edition of Banchieriâ€™s Festino, made for the Adelaide Chamber Singers ; and the performance of Carl Crossin's own edition of of Lassoâ€™s Lagrime di San Pietro, also made for the Adelaide Chamber Singers.",2003,
Nonconvex selection in nonparametric additive models,"High-dimensional data offers researchers increased ability to find useful factors in predicting a response. However, determination of the most important factors requires careful selection of the explanatory variables. In order to tackle this challenge, much work has been done on single or grouped variable selection under the penalized regression framework. Although the topic of variable selection has been extensively studied under the parametric framework, its extensions to more flexible nonparametric models are yet to be explored. In order to implement the variable selection in nonparametric additive models, I introduce and study two nonconvex selection methods under the penalized regression framework, namely the group MCP and the adaptive group LASSO, aiming at improvements on the selection performances of the more widely known group LASSO method in such models. One major part of the dissertation focuses on the theoretical properties of the group MCP and the adaptive group LASSO. I derive their selection and estimation properties. The application of the presently proposed methods to nonparametric additive models are further examined using simulation. Their applications to areas such as the economics and genomics are presented as well. Under both the simulation studies and data applications, the group MCP and the adaptive group LASSO have shown their advantages over the more traditionally used group LASSO method. For the proposed adaptive group LASSO that uses the newly proposed weights,",2014,
Analyzing Risk Factors for Morbidity and Mortality after Lung Resection for Lung Cancer Using the NSQIP Database.,"BACKGROUND
Our goal was to develop a predictive model that identifies how preoperative risk factors and perioperative complications lead to mortality after anatomic pulmonary resections.


STUDY DESIGN
This was a retrospective cohort study. The American College of Surgeons NSQIP database was examined for all patients undergoing elective lobectomies for cancer from 2005 through 2012. Fifty-eight pre- and intraoperative risk factors and 13 complications were considered for their impact on perioperative mortality within 30 days of surgery. Multivariate logistic regression and a logistic regression model using least absolute shrinkage and selection operator (LASSO) selection methods were used to identify preoperative risk factors that were significant for predicting mortality, either through or independent of complications. Only factors that were significant under both the multivariate logistic regression and LASSO-selected models were considered to be validated for the final model.


RESULTS
There were 6,435 lobectomies identified. After multivariate logistic regression modeling, 28 risk factors and 5 complications were found to be predictors for mortality. This was then tested against the LASSO method. There were 7 factors shared between the LASSO and multivariate logistic regressions that predicted mortality based on comorbidity: age (pÂ = 0.007), male sex (pÂ = 0.011), open lobectomy (pÂ = 0.001), preoperative dyspnea at rest (p < 0.001), preoperative dyspnea on exertion (pÂ = 0.003), preoperative dysnatremia (serum sodium <135 mEq/L or >145 mEq/L) (pÂ = 0.011), and preoperative anemia (pÂ = 0.002). Of these, 3 variables predicted mortality independent of any complications: dyspnea at rest, dyspnea on exertion, and dysnatremia.


CONCLUSIONS
The clinical factors that predict postoperative complications and mortality are multiple and not necessarily aligned. Efforts to improve quality after anatomic pulmonary resections should focus on mechanisms to address both types of adverse outcomes.",2016,Journal of the American College of Surgeons
Data Science for Delamination Prognosis and Online Batch Learning in Semiconductor Assembly Process,"The transformation of wafers into chips is a complex manufacturing process involving literally thousands of equipment parameters. Delamination, a leading cause of defective products, can occur between die and epoxy molding compound (EMC), epoxy and substrate, lead frame and EMC, and so on. Troubleshooting is generally on a case-by-case basis and is both time-consuming and labor-intensive. We propose a three-phase data science (DS) framework for process prognosis and prediction. The first phase is for data preprocessing. The second phase uses least absolute shrinkage and selection operator (LASSO) regression and stepwise regression to identify the key variables affecting delamination. The third phase develops a backpropagation neural network (BPNN), support vector regression (SVR), partial least squares (PLS), and gradient boosting machine (GBM) to predict the ratio of the delamination area in a die. We also investigate the imbalance between a false positive rate and a false negative rate after quality classification with BPN and GBM models to improve the tradeoff between the two types of risks. We conducted an empirical study of a semiconductor manufacturer, and the results show that the proposed framework provides an effective delamination prediction supporting the troubleshooting. In addition, for online prediction, it is necessary to determine the batch size for the timing of retraining the model, and we suggest the cost-oriented method to solve the issue.",2020,"IEEE Transactions on Components, Packaging and Manufacturing Technology"
Fixed and random effects selection in nonparametric additive mixed models,"This paper considers the problem of model selection in a nonparametric additive mixed modeling framework. The fixed effects are modeled nonpaxametrically using truncated series expansions with B-spline basis. Estimation and selection of such nonparametric fixed effects are simultaneously achieved by the adaptive group lasso methodology, while the random effects axe selected by a traditional backward selection mechanism. To facilitate the automatic selection of model dimension, computable expressions for the degrees of freedom for both the fixed and random effects components are derived, and the Bayesian Information criterion (BIC) is used to select the final model choice. Theoretically it is shown that this BIC model selection is consistent, while computationally a practical algorithm is developed for solving the BIC optimization problem. Simulation results show that the proposed methodology is often capable of selecting the correct significant fixed and random effects components, especially when the sample size and/or signal to noise ratio are not too small. The new method is also applied to some real data sets.",2012,Electronic Journal of Statistics
"Vix and the Surrounding Area Vix, France 21400 Outline Geophysical Survey Report.","Paul Cheetham and Ashely Green were commissioned by Charge de recherche CNRS, Universite de Bourgogne to carry out a programme of geophysical survey at three sites in Vix and the surrounding area. Over 50 individual surveys were undertaken in the two week survey period utilised combinations of electromagnetic induction (EMI), electrical imaging (sometimes termed geoelectrical imaging or electrical tomography), and ground penetrating radar (GPR) techniques (not included in this report), to investigate areas of archaeological potential. The results from these surveys have improved our archaeological understanding of all three sites. Specifically we can confidently state: 1. That the structure of the â€œLady of Vixâ€ tumulus is shown to be complex in terms of either the original structure, later disturbances, or a combination of both. 2. On the river floodplain northeast of the village of Vix, a triple linear feature was defined in an area poorly defined on the magnetic gradiometry due to the depth of the archaeological remains, as well as finding evidence of associated settlement activities. 3. That the major ditch and rampart system on the eastern flank of Mont Lassois can be delineated effectively by electrical imaging techniques, making further study of the system possible using non-invasive approaches..",2019,
Assumptionless consistency of the Lasso,"The Lasso is a popular statistical tool invented by Robert Tibshirani for linear regression when the number of covariates is greater than or comparable to the number of observations. The purpose of this note is to highlight the simple fact (noted in a number of earlier papers in various guises) that for the loss function considered in Tibshirani's original paper, the Lasso is consistent under almost no assumptions at all.",2013,arXiv: Statistics Theory
Felix Loewenhardt,"Knolls Pharmaka. Knell & Co. 8 ~ Ludwigshafen a. Rhein, 1911. Prof. Or. Fr. Salzer. Diagnose und Fehldiagnose yon Gebirnerkrankungen aus der Papilla nervi optici. 8 ~ l'reis Mk. 1""50. Mit 99 Abbildungen auf 2 farbigen Tafeln. J. F. Lehmanns Verlag, Mfinehen 1911. Or. Gennerieb. 3. Bericht fiber Salvarsanbehandlung aus dem Kaiserlichen Marinelazarett Kiel-Wik. 8 ~ Preis Mk. 240. Mit ~ Kurventafeln. Verlag yon August Hirschwald, Berlin 1911. Dr. Wilh. Karo. Die Gonorrhoe des Mannes. Ihre Pathologic and Therapie. Ein Leitfaden ftir Arzte und Studierende. 8 ~ Preis Mk. 2""80, geb. Mk. 3'40. Ver]ag yon Julius Springer, Berlin 1911. S. yon Prowazek. Handbuch der pathogenen Protozoen. 8 ~ I. Bd. Lieferung mit 1 farb. und 2 sehwarzen Tafeln und 76 Figuren im Text. Preis Mk. 6""40. II. Lieferung mit 2 farbigen Tafeln und 4~ Figuren im 1""ext. Preis Mk. 7""20. Verlag yon Johann Ambrosias Barth~ Leipzig 1911. Finger, Jaflassohn, Ehrmann und GroB. Handbuch der Geschlechtskrankheiten. 8 e, IX. Lieferung. (II. Band, Bogen 25--31 und Tafel III bis VI.) Preis K 6""---~ Mk. 5""~. Veriag yon Alfred HSlder, Wien und Leipzig 1911.",2005,Archiv fÃ¼r Dermatologie und Syphilis
Protein disulfide isomerases are promising targets for predicting the survival and tumor progression in glioma patients,"The present study focused on the expression patterns, prognostic values and potential mechanism of the PDI family in gliomas. Most PDI family members' mRNA expressions were observed significantly different between gliomas classified by clinical features. Construction of the PDI signature, cluster and risk score models of glioma was done using GSVA, consensus clustering analysis, and LASSO Cox regression analysis respectively. High values of PDI signature/ risk score and cluster 1 in gliomas were associated with malignant clinicopathological characteristics and poor prognosis. Analysis of the distinctive genomic alterations in gliomas revealed that many cases having high PDI signature and risk score were associated with genomic aberrations of driver oncogenes. GSVA analysis showed that PDI family was involved in many signaling pathways in ERAD, apoptosis, and MHC class I among many more. Prognostic nomogram revealed that the risk score was a good prognosis indicator for gliomas. The qRT-PCR and immunohistochemistry confirmed that P4HB, PDIA4 and PDIA5 were overexpressed in gliomas. In summary, this research highlighted the clinical importance of PDI family in tumorigenesis and progression in gliomas.",2020,Aging (Albany NY)
Integration Analysis of Three Omics Data Using Penalized Regression Methods: An Application to Bladder Cancer,"Omics data integration is becoming necessary to investigate the genomic mechanisms involved in complex diseases. During the integration process, many challenges arise such as data heterogeneity, the smaller number of individuals in comparison to the number of parameters, multicollinearity, and interpretation and validation of results due to their complexity and lack of knowledge about biological processes. To overcome some of these issues, innovative statistical approaches are being developed. In this work, we propose a permutation-based method to concomitantly assess significance and correct by multiple testing with the MaxT algorithm. This was applied with penalized regression methods (LASSO and ENET) when exploring relationships between common genetic variants, DNA methylation and gene expression measured in bladder tumor samples. The overall analysis flow consisted of three steps: (1) SNPs/CpGs were selected per each gene probe within 1Mb window upstream and downstream the gene; (2) LASSO and ENET were applied to assess the association between each expression probe and the selected SNPs/CpGs in three multivariable models (SNP, CPG, and Global models, the latter integrating SNPs and CPGs); and (3) the significance of each model was assessed using the permutation-based MaxT method. We identified 48 genes whose expression levels were significantly associated with both SNPs and CPGs. Importantly, 36 (75%) of them were replicated in an independent data set (TCGA) and the performance of the proposed method was checked with a simulation study. We further support our results with a biological interpretation based on an enrichment analysis. The approach we propose allows reducing computational time and is flexible and easy to implement when analyzing several types of omics data. Our results highlight the importance of integrating omics data by applying appropriate statistical strategies to discover new insights into the complex genetic mechanisms involved in disease conditions.",2015,PLoS Genetics
Identifying Associations Between Brain Imaging Phenotypes and Genetic Factors via a Novel Structured SCCA Approach,"Brain imaging genetics attracts more and more attention since it can reveal associations between genetic factors and the structures or functions of human brain. Sparse canonical correlation analysis (SCCA) is a powerful bi-multivariate association identification technique in imaging genetics. There have been many SCCA methods which could capture different types of structured imaging genetic relationships. These methods either use the group lasso to recover the group structure, or employ the graph/network guided fused lasso to find out the network structure. However, the group lasso methods have limitation in generalization because of the incomplete or unavailable prior knowledge in real world. The graph/network guided methods are sensitive to the sign of the sample correlation which may be incorrectly estimated. We introduce a new SCCA model using a novel graph guided pairwise group lasso penalty, and propose an efficient optimization algorithm. The proposed method has a strong upper bound for the grouping effect for both positively and negatively correlated variables. We show that our method performs better than or equally to two state-of-the-art SCCA methods on both synthetic and real neuroimaging genetics data. In particular, our method identifies stronger canonical correlations and captures better canonical loading profiles, showing its promise for revealing biologically meaningful imaging genetic associations.",2017,Information processing in medical imaging : proceedings of the ... conference
An Adaptive LASSO-Penalized BIC,"Mixture models are becoming a popular tool for the clustering and classification of high-dimensional data. In such high dimensional applications, model selection is problematic. The Bayesian information criterion, which is popular in lower dimensional applications, tends to underestimate the true number of components in high dimensions. We introduce an adaptive LASSO-penalized BIC (ALPBIC) to mitigate this problem. This efficacy of the ALPBIC is illustrated via applications of parsimonious mixtures of factor analyzers. The selection of the best model by ALPBIC is shown to be consistent with increasing numbers of observations based on simulated and real data analyses.",2014,arXiv: Methodology
An interdisciplinary study of Middle Cycladic white wares from Akrotiri on Thera,"Few archaeological sites have drawn, and held the imagination and attention of the range of scholars as the prehistoric settlement of Akrotiri on Thera in the southern Cyclades, currently excavated by Athens University and the Greek Archaeological Society [1,2]. The archaeological significance of Akrotiri can hardly be overstated from any perspective. With respect to the controversial question of a Minoan hegemony, it lies on a particularly strategic point in Bronze Age trading routes between the mainland, the Cycladic islands and Crete [3\. By the sixteenth century BC the many Minoan features present in Theran material culture (such as fresco iconography, Linear A tablets, ceramic motifs and architectural details) continue to provoke debate concerning the existence, or extent of a Minoan thalassocracy. Thus characterizations of what may be distinguished as truly â€œlocalâ€ attributes of Theran crafts in the earlier periods are increasingly important.",1995,MRS Proceedings
Discovering graphical Granger causality using the truncating lasso penalty,"MOTIVATION
Components of biological systems interact with each other in order to carry out vital cell functions. Such information can be used to improve estimation and inference, and to obtain better insights into the underlying cellular mechanisms. Discovering regulatory interactions among genes is therefore an important problem in systems biology. Whole-genome expression data over time provides an opportunity to determine how the expression levels of genes are affected by changes in transcription levels of other genes, and can therefore be used to discover regulatory interactions among genes.


RESULTS
In this article, we propose a novel penalization method, called truncating lasso, for estimation of causal relationships from time-course gene expression data. The proposed penalty can correctly determine the order of the underlying time series, and improves the performance of the lasso-type estimators. Moreover, the resulting estimate provides information on the time lag between activation of transcription factors and their effects on regulated genes. We provide an efficient algorithm for estimation of model parameters, and show that the proposed method can consistently discover causal relationships in the large p, small n setting. The performance of the proposed model is evaluated favorably in simulated, as well as real, data examples.


AVAILABILITY
The proposed truncating lasso method is implemented in the R-package 'grangerTlasso' and is freely available at http://www.stat.lsa.umich.edu/~shojaie/.",2010,Bioinformatics
Proximal approaches for matrix optimization problems: Application to robust precision matrix estimation,"Abstract In recent years, there has been a growing interest in mathematical models leading to the minimization, in a symmetric matrix space, of a Bregman divergence coupled with a regularization term. We address problems of this type within a general framework where the regularization term is split into two parts, one being a spectral function while the other is arbitrary. A Douglasâ€“Rachford approach is proposed to address such problems, and a list of proximity operators is provided allowing us to consider various choices for the fitâ€“toâ€“data functional and for the regularization term. Based on our theoretical results, two novel approaches are proposed for the noisy graphical lasso problem, where a covariance or precision matrix has to be statistically estimated in presence of noise. The Douglasâ€“Rachford approach directly applies to the estimation of the covariance matrix. When the precision matrix is sought, we solve a non-convex optimization problem. More precisely, we propose a majorizationâ€“minimization approach building a sequence of convex surrogates and solving the inner optimization subproblems via the aforementioned Douglasâ€“Rachford procedure. We establish conditions for the convergence of this iterative scheme. We illustrate the good numerical performance of the proposed approaches with respect to stateâ€“ofâ€“theâ€“art approaches on synthetic and real-world datasets.",2020,Signal Process.
Prognostic value of long non-coding RNA signatures in bladder cancer,"Bladder cancer (BLCA) is a devastating cancer whose early diagnosis can ensure better prognosis. Aim of this study was to evaluate the potential utility of lncRNAs in constructing lncRNA-based classifiers of BLCA prognosis and recurrence. Based on the data concerning BLCA retrieved from TCGA, lncRNA-based classifiers for OS and RFS were built using the least absolute shrinkage and selection operation (LASSO) Cox regression model in the training cohorts. More specifically, a 14-lncRNA-based classifier for OS and a 12-lncRNA-based classifier for RFS were constructed using the LASSO Cox regression. According to the prediction value, patients were divided into high/low-risk groups based on the cut-off of the median risk-score. The log-rank test showed significant differences in OS and RFS between low- and high-risk groups in the training, validation and whole cohorts. In the time-dependent ROC curve analysis, the AUCs for OS in the first, third, and fifth year were 0.734, 0.78, and 0.78 respectively, whereas the prediction capability of the 14-lncRNA classifier was superior to a previously published lncRNA classifier. As for the RFS, the AUCs in the first, third, and fifth year were 0.755, 0.715, and 0.740 respectively. In summary, the two-lncRNA-based classifiers could serve as novel and independent prognostic factors for OS and RFS individually.",2019,Aging (Albany NY)
REMAS: a new regression model to identify alternative splicing events from exon array data,"BackgroundAlternative splicing (AS) is an important regulatory mechanism for gene expression and protein diversity in eukaryotes. Previous studies have demonstrated that it can be causative for, or specific to splicing-related diseases. Understanding the regulation of AS will be helpful for diagnostic efforts and drug discoveries on those splicing-related diseases. As a novel exon-centric microarray platform, exon array enables a comprehensive analysis of AS by investigating the expression of known and predicted exons. Identifying of AS events from exon array has raised much attention, however, new and powerful algorithms for exon array data analysis are still absent till now.ResultsHere, we considered identifying of AS events in the framework of variable selection and developed a regression method for AS detection (REMAS). Firstly, features of alternatively spliced exons were scaled by reasonably defined variables. Secondly, we designed a hierarchical model which can represent gene structure and transcriptional influence to exons, and the lasso type penalties were introduced in calculation because of huge variable size. Thirdly, an iterative two-step algorithm was developed to select alternatively spliced genes and exons. To avoid negative effects introduced by small sample size, we ranked genes as parameters indicating their AS capabilities in an iterative manner. After that, both simulation and real data evaluation showed that REMAS could efficiently identify potential AS events, some of which had been validated by RT-PCR or supported by literature evidence.ConclusionAs a new lasso regression algorithm based on hierarchical model, REMAS has been demonstrated as a reliable and effective method to identify AS events from exon array data.",2009,BMC Bioinformatics
ET-Lasso: Efficient Tuning of Lasso for High-Dimensional Data,"The L1 regularization (Lasso) has proven to be a versatile tool to select relevant features and estimate the model coefficients simultaneously. Despite its popularity, it is very challenging to guarantee the feature selection consistency of Lasso. One way to improve the feature selection consistency is to select an ideal tuning parameter. Traditional tuning criteria mainly focus on minimizing the estimated prediction error or maximizing the posterior model probability, such as cross-validation and BIC, which may either be time-consuming or fail to control the false discovery rate (FDR) when the number of features is extremely large. The other way is to introduce pseudo-features to learn the importance of the original ones. Recently, the Knockoff filter is proposed to control the FDR when performing feature selection. However, its performance is sensitive to the choice of the expected FDR threshold. Motivated by these ideas, we propose a new method using pseudo-features to obtain an ideal tuning parameter. In particular, we present the Efficient Tuning of Lasso (ET-Lasso) to separate active and inactive features by adding permuted features as pseudo-features in linear models. The pseudo-features are constructed to be inactive by nature, which can be used to obtain a cutoff to select the tuning parameter that separates active and inactive features. Experimental studies on both simulations and real-world data applications are provided to show that ET-Lasso can effectively and efficiently select active features under a wide range of different scenarios.",2018,ArXiv
Decoding force from deep brain electrodes in Parkinsonian patients.,"Limitations of many Brain Machine Interface (BMI) systems using invasive electrodes include reliance on single neurons and decoding limited to kinematics only. This study investigates whether force-related information is present in the local field potential (LFP) recorded with deep brain electrodes using data from 14 patients with Parkinson's disease. A classifier based on logistic regression (LR) is developed to classify various force stages, using 10-fold cross validation. Least Absolute and Shrinkage Operator (Lasso) is then employed in order to identify the features with the most predictivity. The results show that force-related information is present in the LFP, and it is possible to distinguish between various force stages using certain frequency-domain (delta, beta, gamma) and time-domain (mobility) features in real-time.",2016,Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference
"Dagli appartamenti di Vittorio Amedeo I e Cristina di Francia a quelli di Carlo Emanuele II e Francesca dâ€™Orleans.Distribuzione, spazi e funzioni alla corte di Torino (1620-1663).","Le texte veut explorer, face aux etudes deja developpes sur le XVIIIe siecle pour la meme cour piemontaise, le rapport entre espace, fonctions, genre, influences des cours etrangeres, architecture et decoration dans les residences ducales a Turin et aux alentours. L'arrivee a Turin en 1620 de Christiane de France comme epouse de Victor Amedee I emmene dans la capitale du duche - deja liee aux modeles espagnols a cause de la femme de Charles Emmanuel I, Catalina Micaela, infanta d'Espagne - des claires influences francaises, qui se melent aux traditions locales dans l'architecture, la decoration, la distribution. La duchesse, veuve en 1637 et apres regente, organise un reseau de residences : le chÃ¢teau a Turin, une villa a la romaine dans la colline et une maison de plaisance le long du Po, le Valentino, projete par Carlo di Castellamonte comme un chÃ¢teau a la francaise, avec pavillons (proche au pavillon de Flore du Louvre), galeries, et toits en ardoise avec une pente tres forte. C'est difficile la reconstruction des appartements au chÃ¢teau en ville et aux chÃ¢teau de Moncalieri et Mirafiori, a cause des transformations et des destructions, mais il y a quelques inventaires concernant le Valentino, et beaucoup de paiements lies a l'amenagement de la villa. En melant les inventaires, les regles du ceremonial, les lettres et les paiement de la Maison on peut tracer un portrait des appartements et du rapport entre espace et fonctions. La condition de veuve de la duchesse regente entre 1637 et 1663, en presence d'un fils heritier au trone en 1658 qui se marie en 1663, donne un caractere particulier a la situation (on a en tout cas la liste des employes des Maisons), ma c'est juste ce mariage qui donne l'occasion pour une vraie comparaison entre deux appartements, masculin et feminin. Les appartements au Palais Royal viennent d'etre acheves exactement pour Charles Emmanuel II et sa femme francaise. Une partie des decorations est encore a sa place, avec sujets lies a la fonction des chambres. Le Inventario del Pallasso Nuovo, redige en 1682, nous donne les denominations des chambres et la liste des tableaux et des sujets, en revelant aussi un changement dans la distribution : l'appartement meilleur, expose au sud et destine au duc (mort en 1675) est utilise par la duchesse veuve Maria Giovanna Battista, nouvelle regente. C'est une transformation dans la distribution qui sera renversee seulement en 1831, par le roi Carlo Alberto. L'analyse de l'interieur aujourd'hui, par contre, nous revele la permanence de solutions architecturales et fonctionnels peut etre d'importation francaise : dans quelques salles il y encore des portes a battant double, au contraire de la majorite des chambres dans tout le reseau des residences ducales et apres royales. La Â« porta volante Â» (une porte avec un seul battant, typiquement piemontaise, ni italienne, ni francaise) c'est partout la regle pour le XVIIIe siecle, mais aussi au Valentino, le chÃ¢teau de Madame Royale, il y avait - au XVIIe - un systeme de portes different, a battant double",2014,
A landmark year for PBN,"Subtitle: Erwin Lassooij, ICAO PBN programme manager, reports on the ongoing priorities for ICAO and the industry and the win-win aspects of this important component of ICAO's Communications Navigation and Surveillance/Air Traffic Management (CNS/ATM) strategy.",2009,ICAO journal
Sharp thresholds for high-dimensional and noisy recovery of sparsity,"The problem of consistently estimating the sparsity pattern of a vector $\betastar \in \real^\mdim$ based on observations contaminated by noise arises in various contexts, including subset selection in regression, structure estimation in graphical models, sparse approximation, and signal denoising. We analyze the behavior of $\ell_1$-constrained quadratic programming (QP), also referred to as the Lasso, for recovering the sparsity pattern. Our main result is to establish a sharp relation between the problem dimension $\mdim$, the number $\spindex$ of non-zero elements in $\betastar$, and the number of observations $\numobs$ that are required for reliable recovery. For a broad class of Gaussian ensembles satisfying mutual incoherence conditions, we establish existence and compute explicit values of thresholds $\ThreshLow$ and $\ThreshUp$ with the following properties: for any $\epsilon > 0$, if $\numobs > 2 (\ThreshUp + \epsilon) \log (\mdim - \spindex) + \spindex + 1$, then the Lasso succeeds in recovering the sparsity pattern with probability converging to one for large problems, whereas for $\numobs < 2 (\ThreshLow - \epsilon) \log (\mdim - \spindex) + \spindex + 1$, then the probability of successful recovery converges to zero. For the special case of the uniform Gaussian ensemble, we show that $\ThreshLow = \ThreshUp = 1$, so that the threshold is sharp and exactly determined.",2006,ArXiv
Verfahren und Vorrichtung zur Erzeugung eines teerfreien Brenngases,"Thermischer Vergaser bestehend aus â€“ einem durch eine Heizvorrichtung (40) indirekt beheizten Pyrolysereaktor (10) mit einer Vorrichtung (14) zum zwangsbewegten Vorschub eines Brennstoffbettes (51) von einer Eintragsoffnung (11) durch eine Reaktionszone (50) zu einer Austrittsoffnung (12), â€“ einem Vergasungsreaktor (20) mit einer Durchgangsoffnung (21) zum Eintrag von Feststoff, mit Eintrittsoffnungen (23) fur Vergasungsmittel und einer Auslassoffnung fur Reststoffe (22) an einer der Offnung (21) abgewandten Seite und â€“ einem Konverter (30), der mindestens ein Schuttbett (54) enthalt, der eine Eintrittsoffnung (31) an einer Stelle in unmittelbarer Nahe der Austrittsoffnung (12) des Pyrolysereaktors (10) oder einer an diese angeschlossenen Rohrleitung (19) besitzt und der mit dem wesentlichen Teil seines Querschnitts oder zumindest mit derselben Eintrittsoffnung (31) in unmittelbarer Nahe der Durchgangsoffnung (21) des Vergasungsreaktors (20) oder eines an diese angeschlossenen Einleitungsbauteils (42) mit diesem in Stromungsverbindung steht.",2008,
Solar Flare Forecasting from Magnetic Feature Properties Generated by the Solar Monitor Active Region Tracker,"We study the predictive capabilities of magnetic-feature properties (MF) generated by the Solar Monitor Active Region Tracker (SMART: Higgins etÂ al. in Adv. Space Res.47, 2105, 2011) for solar-flare forecasting from two datasets: the full dataset of SMART detections from 1996 to 2010 which has been previously studied by Ahmed etÂ al. (Solar Phys.283, 157, 2013) and a subset of that dataset that only includes detections that are NOAA active regions (ARs). The main contributions of this work are: we use marginal relevance as a filter feature selection method to identify the most useful SMART MF properties for separating flaring from non-flaring detections and logistic regression to derive classification rules to predict future observations. For comparison, we employ a Random Forest, Support Vector Machine, and a set of Deep Neural Network models, as well as lasso for feature selection. Using the linear model with three features we obtain significantly better results (True Skill Score: TSS = 0.84) than those reported by Ahmed etÂ al. (Solar Phys.283, 157, 2013) for the full dataset of SMART detections. The same model produced competitive results (TSS = 0.67) for the dataset of SMART detections that are NOAA ARs, which can be compared to a broader section of flare-forecasting literature. We show that more complex models are not required for this data.",2018,Solar Physics
Generalized Laplacian precision matrix estimation for graph signal processing,"Graph signal processing models high dimensional data as functions on the vertices of a graph. This theory is constructed upon the interpretation of the eigenvectors of the Laplacian matrix as the Fourier transform for graph signals. We formulate the graph learning problem as a precision matrix estimation with generalized Laplacian constraints, and we propose a new optimization algorithm. Our formulation takes a covariance matrix as input and at each iteration updates one row/column of the precision matrix by solving a non-negative quadratic program. Experiments using synthetic data with generalized Laplacian precision matrix show that our method detects the nonzero entries and it estimates its values more precisely than the graphical Lasso. For texture images we obtain graphs whose edges follow the orientation. We show our graphs are more sparse than the ones obtained using other graph learning methods.",2016,"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
A Bayesian mixture of lasso regressions with t-errors,"The following article considers a mixture of regressions with variable selection problem. In many real-data scenarios, one is faced with data which possess outliers, skewness and, simultaneously, one would like to be able to construct clusters with specific predictors that are fairly sparse. A Bayesian mixture of lasso regressions with t-errors to reflect these specific demands is developed. The resulting model is necessarily complex and to fit the model to real data, a state-of-the-art Particle Markov chain Monte Carlo (PMCMC) algorithm based upon sequential Monte Carlo (SMC) methods is developed. The model and algorithm are investigated on both simulated and real data.",2014,Comput. Stat. Data Anal.
Flexible HAR model for realized volatility,"Abstract The Heterogeneous Autoregressive (HAR) model is commonly used in modeling the dynamics of realized volatility. In this paper, we propose a flexible HAR(1, . . . , p) specification, employing the adaptive LASSO and its statistical inference theory to see whether the lag structure (1, 5, 22) implied from an economic point of view can be recovered by statistical methods. The model differs from Audrino and Knaus (2016) [Audrino, F. and S. D. Knaus. 2016. â€œLassoing the HAR model: A model selection perspective on realized volatility dynamics.â€ Econometrics Review 35: 1485â€“1521]. where the authors apply LASSO on the AR(p) model, which does not necessarily lead to a HAR model. Adaptive LASSO estimation and the subsequent hypothesis testing results fail to show strong evidence that such a fixed lag structure can be recovered by a flexible model. We also apply the group LASSO and related tests to check the validity of the classic HAR, which is rejected in most cases. The results justify our intention to use a flexible lag structure while still keeping the HAR frame. In terms of the out-of-sample forecasting, the proposed flexible specification works comparably to the benchmark HAR(1, 5, 22). Moreover, the time-varying model combinations show that when the market environment is not stable, the fixed lag structure (1, 5, 22) is not particularly accurate and effective.",2018,Studies in Nonlinear Dynamics & Econometrics
Parsimonious modeling with Information Filtering Networks,"We introduce a methodology to construct parsimonious probabilistic models. This method makes use of information filtering networks to produce a robust estimate of the global sparse inverse covariance from a simple sum of local inverse covariances computed on small subparts of the network. Being based on local and low-dimensional inversions, this method is computationally very efficient and statistically robust, even for the estimation of inverse covariance of high-dimensional, noisy, and short time series. Applied to financial data our method results are computationally more efficient than state-of-the-art methodologies such as Glasso producing, in a fraction of the computation time, models that can have equivalent or better performances but with a sparser inference structure. We also discuss performances with sparse factor models where we notice that relative performances decrease with the number of factors. The local nature of this approach allows us to perform computations in parallel and provides a tool for dynamical adaptation by partial updating when the properties of some variables change without the need of recomputing the whole model. This makes this approach particularly suitable to handle big data sets with large numbers of variables. Examples of practical application for forecasting, stress testing, and risk allocation in financial systems are also provided.",2016,Physical review. E
RDF/RDFS-based Relational Database Integration,"We study the problem of answering queries through a RDF/RDFS ontology, given a set of view-based mappings between one or more relational schemas and this target ontology. Particularly, we consider a set of RDFS semantic constraints such as rdfs:subClassof, rdfs:subPropertyof, rdfs:domain, and rdfs:range, which are present in RDF model but neither XML nor relational models. We formally define the query semantics in such an integration scenario, and design a novel query rewriting algorithm to implement the semantics. On our approach, we highlight the important role played by RDF Blank Node in representing incomplete semantics of relational data. A set of semantic tools supporting relational data integration by RDF are also introduced. The approach have been used to integrate 70 relational databases at China Academy of Traditional Chinese Medicine.",2006,22nd International Conference on Data Engineering (ICDE'06)
"Evidencia cientÃ­fica de la hidroterapia, balneoterapia, termoterapia, crioterapia y talasoterapia","Objective: To answer the question: Is there scientific evidence with the techniques of hydrotherapy?
Methods: Bibliographic search of evidence-based medicine in clinical trials published until February 2008. To this end, use
the Tripdatabase, which links to databases of medical quality. It also search the clinical trials indexed by PubMed. The
degrees of evidence are classified according to the table of the Agency for Healthcare Research and Quality USA; grades
in this recommendation are: A (high evidence: at least obtained from a randomized clinical trial), B (moderate evidence:
from quasi-experimental studies) and C (low evidence: clinical experience or opinions of experts).
Main results: The balneology is recommended with the Grade A: chronic low back pain, arthrosis, rheumatoid arthritis and
fibromyalgia; and with the grade B: Ankylosing spondylitis, respiratory infections tracks high, hypertension, hypercholesterolemia, heart failure, venous insufficiency, periferic arteriopathy and atopic dermatitis. The cure hydroponic, with the grade A: nephrolithiasis; and with the grade B: postural hypotension, osteoporosis, hypertension, dyslipidemia and iron-deficiency anemia. The thalassotherapy with de grade B: Psoriasis, artrosis and fibromyalgia. The thermotherapy, grade A: Fibromyalgia; and grade B: Newborns, labour, anal fissure, insect bites, chronic low back pain, arthrosis, spasticity, neuromotor pathology, insomnia, infections tracks high. Cryotherapy, with the grade A: Fever; and the grade B: Prevention of
heatstroke and wounds. The hydrotherapy temperature alternating, with the grade B: muscle pain after exercise, heart failure. The exercises in the aquatic environment, with Grade A: Arthrosis, fibromyalgia; and with the grade B: Quality of life
and balance, chronic obstructive pulmonary disease, heart failure and rheumatoid arthritis.
Conclusions: There are already indications of hydrotherapy with high and moderate grades of evidence.",2008,
Uncertainty Quantification for Modern High-Dimensional Regression via Scalable Bayesian Methods,"ABSTRACTTremendous progress has been made in the last two decades in the area of high-dimensional regression, especially in the â€œlarge p, small nâ€ setting. Such sample starved settings inevitably lead to models which are potentially very unstable and hence quite unreliable. To this end, Bayesian shrinkage methods have generated a lot of recent interest in the modern high-dimensional regression and model selection context. Such methods span the wide spectrum of modern regression approaches and include among others, spike-and-slab priors, the Bayesian lasso, ridge regression, and global-local shrinkage priors such as the Horseshoe prior and the Dirichletâ€“Laplace prior. These methods naturally facilitate tractable uncertainty quantification and have thus been used extensively across diverse applications. A common unifying feature of these models is that the corresponding priors on the regression coefficients can be expressed as a scale mixture of normals. This property has been leveraged extensively to devel...",2019,Journal of Computational and Graphical Statistics
Environment and Sustainability Authors and Journalists on Twitter | Verlasso,A list of authors and journalists to follow on Twitter to get the latest on environmental and sustainability topics that are important to Verlasso.,2013,
"Cheirolepidiacees du Jurassique inferieur de Saint-Fromond, bassin de Carentan (Manche, France)","ResumeLe materiel vegetal recolte dans des niveaux de gres calcareux du Jurassique inferieur de la carriere de Saint-Fromond (Bassin de Carentan-Manche) est constitue d'axes feuilles, de cones mÃ¢les, d'ecailles ovuliferes isolees ou d'inflorescences femelles incompletes et de nombreux fragments de bois carbonises ou lignitises. L'etude au MEB des cuticules des differentes empreintes a permis de constater une identite des structures epidermiques. Les axes (Hirmeriella airelensis Muir et Van Konijnenburg-Van Cittert), les cones mÃ¢les (Classostrobus sp) contenant des grains de pollen du type Classopollis, les ecailles ovuliferes isolees (Hirmeriella sp) sont attribues a une meme plante. Il en est de meme pour les axes carbonises ou lignitises recoltes dans les memes niveaux que les empreintes. Etudies au MEB ils ont ete determines comme appartenant a une nouvelle espece: Protocupressinoxylon carentanensis.Des considerations generales sur la famille des Cheirolepidiacees a laquelle se rapporte le materiel fos...",1987,
Some Remarks on the Position of the Rhenish Massif Between the Variscides and the Caledonides,"On the background of the repeated discussion on the mid-European Caledonides, their relations to the Variscides and the present plate-tectonic models a simplified synopsis of selected geological facts is presented including the Proterozoic-Palaeozoic development in a section from the Bohemian massif/Upper Rhine region through the Rhenohercynian zone to the Brabant massif. An attempt is made to demonstrate that the polarity within the Variscan zones involves subsidence, magmatism and deformation processes of the Cadomian, Caledonian and Variscan stages of development, thus showing the intimate relations between them. More or less limited pre-Carboniferous molassoid sedimentation, indicating the beginning cratonization and marking the following transition to the Variscan stage, are decreasing in age from the internides (Cambrian â€” Tremadocian, concluding a restricted Cadomian development) to the externides and the foreland (Old red, concluding the Caledonian development). With increasing duration and importance of the Caledonian cycle, the Variscan development is diminishing in time and intensity from south to north. The Variscan externides developed, in this view, in a rather mobile area without a coherent or widespread Cadomian or Caledonian basement. Processes in the internides synchronous to the Caledonian development in the north should be considered as belonging to the Variscan cycle.",1987,
Retrieval of ureteral stents in children.,"An endoscopic technique to remove ureteral stents in children is described. The technique is simple and reproducible. A snare or lasso is created by looping a polypropylene suture through a ureteral catheter. The snare is advanced under vision through the working channel of a pediatric cystoscope. The loop of the suture is placed over the intravesical portion of the indwelling ureteral stent. It is tied to create a noose, thus securing the stent. The stent can then be removed easily.",1995,Techniques in urology
sigLASSO: optimizing cancer mutation signatures jointly with sampling likelihood,"Multiple mutational processes drive carcinogenesis, leaving characteristic signatures on tumor genomes. Determining the active signatures from the full repertoire of potential ones can help elucidate mechanisms underlying cancer initiation and development. This task in-volves decomposing the counts of cancer mutations, tabulated according to their trinucleotide context, into a linear combination of known mutational signatures. We formulate it as an optimization problem and develop sigLASSO, a software tool, to carry it out efficiently. (An R package implementation is available at github.com/gersteinlab/siglasso). sigLASSO features four key aspects: (1) It jointly optimizes the likelihood of sampling and signature fitting, by explicitly adding multinomial sampling into the overall objective function. This is particularly important when mutation counts are low and sampling variance is high, such as in exome sequencing. (2) sigLASSO uses L1 regularization to parsimoniously assign signatures to mutation profiles, leading to sparse and more biologically interpretable solutions resembling previously well-characterized results. (3) sigLASSO fine-tunes model complexity, informed by the scale of the data and biological-knowledge based priors. In particular, instead of hard thresholding and choosing a priori a discrete subset of active signatures, sigLASSO allows continuous priors, which can be effectively learned from auxiliary information. (4) Because of this, sigLASSO can assess model uncertainty and abstain from making certain assignments in low-confidence contexts. Finally, to evaluate sigLASSO signature assignments in comparison to other approaches, we develop a set of reasonable expectations (e.g. sparsity, the ability to abstain, and robustness to noise) that we apply consistently in a variety of contexts.",2020,bioRxiv
Eu Etsç¢³æŽ’æ”¾æœŸè´§ä»·æ ¼çš„å‡å€¼å›žå½’â€”â€”åŸºäºŽcklsæ¨¡åž‹çš„å®žè¯ç ”ç©¶,"åˆ©ç”¨LASSOæ–¹æ³•ä¼°è®¡CKLSæ¨¡åž‹,ç»“åˆä¼¼ç„¶çŽ‡æ£€éªŒ,ç ”ç©¶EU ETSç¢³æŽ’æ”¾æœŸè´§ä»·æ ¼çš„è¿è¡Œç‰¹å¾ã€‚ç ”ç©¶å‘çŽ°,åœ¨EU ETSç¬¬ä¸€é˜¶æ®µäº¤æ˜“çš„DEC07æœŸè´§ä»·æ ¼ä¸å­˜åœ¨å‡å€¼å›žå½’ç‰¹å¾,è¿™æ˜¯å› ä¸ºä»·æ ¼å—åˆ°æ”¿ç­–ã€å®è§‚ç»æµŽã€èƒ½æºä»·æ ¼ä»¥åŠå¼‚å¸¸å¤©æ°”ç­‰å› ç´ å½±å“è€Œå‘ˆå‘æ•£è¶‹åŠ¿;è€ŒEU ETSç¬¬äºŒé˜¶æ®µäº¤æ˜“çš„DEC09ã€DEC10å’ŒDEC11æœŸè´§ä»·æ ¼å‡æœ‰å‡å€¼å›žå½’çš„ç‰¹å¾,è¿™è¡¨æ˜Ž,éšç€è¯¥ç¢³æŽ’æ”¾äº¤æ˜“æœºåˆ¶çš„æˆç†Ÿ,å°½ç®¡å—åˆ°ä¼—å¤šå› ç´ çš„å½±å“,ä½†EUAæœŸè´§ä»·æ ¼çš„å…·æœ‰å¯é¢„æµ‹çš„é•¿æœŸè¶‹åŠ¿ã€‚å› æ­¤,ç ”ç©¶EUAæœŸè´§çš„é•¿æœŸè¶‹åŠ¿,å¯ä»¥ä¸ºæˆ‘å›½èˆªç©ºä¸šç­‰ç›´æŽ¥æˆ–é—´æŽ¥ä¸ŽEUETSç›¸å…³ä¼ä¸šå’Œæ¸…æ´å‘å±•æœºåˆ¶é¡¹ç›®ï¼ˆCDMï¼‰è§„é¿é£Žé™©æä¾›æœ‰ç›Šå‚è€ƒã€‚",2012,
SINGLE Package Vignette,"Given multiple longitudinal time series we are often interested in quantifying the relationship between the time series over time. For example, given fMRI data corresponding to various regions of interest in the brain we may be interested in measuring their statistical dependencies over time. These relationships can subsequently be summarised as graphs or networks where each node corresponds to a time series (e.g., a BOLD time series for a region of interest) and edges between nodes (or their absence) provide information regarding the nature of the pairwise relationship. Here we present a short tutorial and introduction to using the R package SINGLE to estimate such dynamic graphs over time from noisy time series data. The SINGLE package provides an implementation of the Smooth Incremental Graphical Lasso Estimation algorithm, full details of which can be found in [Monti et al., 2013].",2014,
[New-onset seizures in patients with immunodeficiency virus infection in Bobo-Dioulasso Hospital (Burkina Faso)].,"Seizures are common in advanced stages of immunodeficiency virus (HIV) infection. HIV-infected outpatients and inpatients in the national hospital in Bobo-Dioulasso among whom seizures occurred had been recruited over four years. There were mainly male (30/13) with an average age of 35 years with extremes ranging from 22 to 60 years. New-onset generalised seizures occurred in all cases of cryptococcal meningitis or partial motor secondary generalised in 64% among patients with suspected cerebral toxoplasmosis due to the efficiency of the treatment of the antitoxoplasmic proof. Identified causes such as suspected cerebral toxoplasmosis (65%), suspected tuberculous meningitis (7%) as CSF culture is not available, cryptococcal meningitis (16%) were found in this study. In four cases among 43 patients, no identified causes could be determined. CD4 lymphocytes count which was available in 24 patients was under 200/41 in 74% of the cases. This study indicates clearly that seizures in young adults are strongly associated with focal brain lesions and cerebral toxoplasmosis is becoming an important cause of seizure in tropical area. This should imply a screening of toxoplasmosis with new-onset seizure in young people.",2004,Bulletin de la Societe de pathologie exotique
Shrinkage and absolute penalty estimation in linear regression models,"In predicting a response variable using multiple linear regression model, several candidate models may be available which are subsets of the full model. Shrinkage estimators borrow information from the full model and provides a hybrid estimate of the regression parameters by shrinking the full model estimates toward the candidate submodel. The process introduces bias in the estimation but reduces the overall prediction error that offsets the bias. In this article, we give an overview of shrinkage estimators and their asymptotic properties. A real data example is given and a Monte Carlo simulation study is carried out to evaluate the performance of shrinkage estimators compared to the absolute penalty estimators such as least absolute shrinkage and selection operator (LASSO), adaptive LASSO and smoothly clipped absolute deviation (SCAD) based on prediction errors criterion in a multiple linear regression setup. WIREs Comput Stat 2012, 4:541â€“553. DOI: 10.1002/wics.1232",2012,Wiley Interdisciplinary Reviews: Computational Statistics
Mixture model and subgroup analysis in nationwide kidney transplant center evaluation,"Five year post-transplant survival rate is an important indicator on quality of care delivered by kidney transplant centers in the United States. To provide a fair assessment of each transplant center, an effect that represents the center-specific care quality, along with patient level risk factors, is often included in the risk adjustment model. In the past, the center effects have been modeled as either fixed effects or Gaussian random effects, with various merits and demerits. We propose two new methods that allow flexible random effects distributions. The first one is a Generalized Linear Mixed Model (GLMM) with normal mixture random effects. By allowing random effects to be non homogeneous, the shrinkage effects is reduced and the predicted random effects are much closer to the truth. In addition, modeling random effects as normal mixture will essentially clustering it into different groups, which provides a natural way of evaluating the performance in the transplant center case. To decide the number of components, we do a sequential hypothesis tests. In the second method, we propose a subgroup analysis on the random effects under the framework of GLMM. Each level of the random effect is allowed to be a cluster by itself, but clusters that are close to each other will be merged into big ones. This method provides more precise and stable estimation than fixed effects model while it has a much more flexible distributions for random effects than a GLMM with Gaussian assumption. In addition, the other effects in the model will be selected via lasso type penalty.",2017,
Pengaruh Kontrol Diri Terhadap Kenakalan Remaja Pada Peserta Didik Kelas Xi Sekolah Menengah Kejuruan (smk) Bina Teknologi Purwokerto,"Penelitian ini bertujuan untuk menguji pengaruh kontrol diri terhadap kenakalan remaja pada peserta didik kelas XI Sekolah Menengah Kejuruan (SMK) Bina Teknologi Purwokerto. Hipotesis yang peneliti ajukan dalam penelitian ini adalah ada Pengaruhkontrol diri terhadap kenakalan remaja. 
 Penelitian ini menggunakan subjek peserta didik kelas XI SMK Bina Teknologi Purwokerto yang berjumlah 261 dan menjadi sampel penelitian sejumlah 78 dengan menggunakan teknik proportional random sampling. Metode pengumpulan data menggunakan instrumentskalaKontroldiridanskalakenakalanremaja sebagai alat ukurnya. Hasil uji validitas dan reliabilitas, 49 butir aitem valid dan 11 buir aitem gugur pada skala kontrol diri bergerak dari 0,312 sampai 0,653 dengan reliabilitas sebesar 0,891. Sedangkan 51 butir aitem valid dan 9 butir aitem gugur pada skala kenakalan remaja bergerak dari 0,312 sampai 0,657 dengan reliabilitas sebesar 0,894. 
 Berdasarkan hasil analisis data dengan teknik analisis regresi sederhana diperoleh nilai F= 42,617 dengan signifikansinya 0,000, artinya hipotesis yang diajukan diterima yaitu ada pengaruh kontrol diri terhadap kenakalan remaja pada peserta didik kelas XI Sekolah Menengah Kejuruan (SMK) Bina Teknologi Purwokerto. Koefisien yang ditunjukan oleh R Square 0, 359. Angka tersebut menunjukan bahwa dalam penelitian ini, kontrol diri memberikan sumbangan efektif sebesar 35,9%dan 64,1% faktor lain yang berpengaruh terhadap kenakalan remajasepertiidentitas, usia, jeniskelamin, harapanterhadappendidikan, proses keluarga, pengaruhtemansebaya, kelassosialekonomi, dankualitaslingkungansekitartempattinggal.",2015,
Hypergraph regularized sparse feature learning,"As an important pre-processing stage in many machine learning and pattern recognition domains, feature selection deems to identify the most discriminate features for a compact data representation. As typical feature selection methods, Lasso and its variants using the l1-norm based regularization have received much attention in recent years. However, most of existing l1-norm based sparse feature selection methods ignore the structure information of data or only consider the pairwise relationships among samples. In this paper, we propose a hypergraph regularized sparse feature learning method, where the high-order relationships among samples are modeled and incorporated into the learning process. Specifically, we first construct a hypergraph with multiple hyperedges to capture the high-order relationships among samples, followed by the computation of a hypergraph Laplacian matrix. Then, we propose a hypergraph regularization term, and a hypergraph regularized Lasso model. We conduct a series of experiments on a number of data sets from UCI machine learning repository, and two real-world neuroimaging based classification tasks. Experimental results demonstrate that the proposed method achieves promising classification results, compared with several well known feature selection approaches.",2017,Neurocomputing
Adaptive LASSO model selection in a multiphase quantile regression,"We propose a general adaptive LASSO method for a quantile regression model. Our method is very interesting when we know nothing about the first two moments of the model error. We first prove that the obtained estimators satisfy the oracle properties, which involves the relevant variable selection without using hypothesis test. Next, we study the proposed method when the (multiphase) model changes to unknown observations called change-points. Convergence rates of the change-points and of the regression parameter estimators in each phase are found. The sparsity of the adaptive LASSO quantile estimators of the regression parameters is not affected by the change-points estimation. If the number of phases is unknown, a consistent criterion is proposed. Numerical studies by Monte Carlo simulations show the performance of the proposed method, compared to other existing methods in the literature, for models with a single phase or for multiphase models. The adaptive LASSO quantile method performs better than known...",2016,Statistics
Enhancing the prediction of acute kidney injury risk after percutaneous coronary intervention using machine learning techniques: A retrospective cohort study,"BACKGROUND
The current acute kidney injury (AKI) risk prediction model for patients undergoing percutaneous coronary intervention (PCI) from the American College of Cardiology (ACC) National Cardiovascular Data Registry (NCDR) employed regression techniques. This study aimed to evaluate whether models using machine learning techniques could significantly improve AKI risk prediction after PCI.


METHODS AND FINDINGS
We used the same cohort and candidate variables used to develop the current NCDR CathPCI Registry AKI model, including 947,091 patients who underwent PCI procedures between June 1, 2009, and June 30, 2011. The mean age of these patients was 64.8 years, and 32.8% were women, with a total of 69,826 (7.4%) AKI events. We replicated the current AKI model as the baseline model and compared it with a series of new models. Temporal validation was performed using data from 970,869 patients undergoing PCIs between July 1, 2016, and March 31, 2017, with a mean age of 65.7 years; 31.9% were women, and 72,954 (7.5%) had AKI events. Each model was derived by implementing one of two strategies for preprocessing candidate variables (preselecting and transforming candidate variables or using all candidate variables in their original forms), one of three variable-selection methods (stepwise backward selection, lasso regularization, or permutation-based selection), and one of two methods to model the relationship between variables and outcome (logistic regression or gradient descent boosting). The cohort was divided into different training (70%) and test (30%) sets using 100 different random splits, and the performance of the models was evaluated internally in the test sets. The best model, according to the internal evaluation, was derived by using all available candidate variables in their original form, permutation-based variable selection, and gradient descent boosting. Compared with the baseline model that uses 11 variables, the best model used 13 variables and achieved a significantly better area under the receiver operating characteristic curve (AUC) of 0.752 (95% confidence interval [CI] 0.749-0.754) versus 0.711 (95% CI 0.708-0.714), a significantly better Brier score of 0.0617 (95% CI 0.0615-0.0618) versus 0.0636 (95% CI 0.0634-0.0638), and a better calibration slope of observed versus predicted rate of 1.008 (95% CI 0.988-1.028) versus 1.036 (95% CI 1.015-1.056). The best model also had a significantly wider predictive range (25.3% versus 21.6%, p < 0.001) and was more accurate in stratifying AKI risk for patients. Evaluated on a more contemporary CathPCI cohort (July 1, 2015-March 31, 2017), the best model consistently achieved significantly better performance than the baseline model in AUC (0.785 versus 0.753), Brier score (0.0610 versus 0.0627), calibration slope (1.003 versus 1.062), and predictive range (29.4% versus 26.2%). The current study does not address implementation for risk calculation at the point of care, and potential challenges include the availability and accessibility of the predictors.


CONCLUSIONS
Machine learning techniques and data-driven approaches resulted in improved prediction of AKI risk after PCI. The results support the potential of these techniques for improving risk prediction models and identification of patients who may benefit from risk-mitigation strategies.",2018,PLoS Medicine
Justice for all? The pattern of skills in Britain,"This paper was published as Working Paper 23 by the Centre for Labour Market Studies, University of Leicester. it is also available from http://www.clms.le.ac.uk/research/wpapers.lasso",1999,
Granger Lasso Causal Models in Higher Dimensions-Application to Gene Expression Regulatory Networks,"Granger causality (GC), based on a vector autoregressive model, is one of the most popular methods in uncovering the temporal dependencies among time series. The original Granger model is able to detect only linear causal dependencies and many approaches were recently developed to extend it to the non-linear modeling. The method Copula-Granger from Bahadori and Liu in 2012 introduces non-linearity into the causality modeling by representing the data distribution by copulas. The detection of causality of gene regulatory networks (GRN) from experimental data, such as gene expression measurements, is a challenging problem, being solved by various computational methods with various success. We applied the Granger Lasso method, the Copula Granger method and the combination of dynamic Bayesian Networks with ordinary differential equation method (ODE-DBN) to cell division cycle gene expression data from the human cancer cell line (HeLa) for a regulatory network of 19 selected genes. We tested the causal detection ability of the methods with respect to the selected benchmark network. We compared the performance of the mentioned methods or various statistical measures. All three methods are scalable and can be easily extended to higher dimensions. The results of both Granger Lasso and Copula Granger outperformed the ODE-DBN both in terms of precision and the computational time. We conclude that the DBN combined with ODE method are not feasible for large GRN because of the computational intensity of the methods and surprisingly low precision. This type of methods is more feasible for modeling of local dynamics within a small genetic regulatory networks, rather than for detection of causal relationships in a large genetic regulatory network. We believe that the assumption of Gaussian processes, on which are DBN based, is in larger genetic regulatory networks violated.",2013,
"Barry Alpha Ousmane (dir.), 2009, Pour une sÃ©miotique du discours littÃ©raire postcolonial dâ€™Afrique francophone. Paris, Lâ€™Harmattan","Cet ouvrage comprend huit articles, extraits des contributions au Colloque international Configurations discursives et identites africaines de la periode postcoloniale qui sâ€™est tenu a Besancon en mars 2007. Ils Â«Â interrogent les problematiques esthetiquesÂ Â» (p. 10), et sont suivis dâ€™une dizaine de pages de bibliographie sur ce sujet. Musanji Ngalasso-Mwatha traite de Â«Â lâ€™imaginaire linguistique (IL) [...] dans les (meta) discours litteraires francophonesÂ Â» (p.13) et propose, comme le mention...",2014,Journal Des Africanistes
Lo histÃ³rico del mito,"Mitos de armonia racial. Raza y republicanismo durante la era de la revolucion, Colombia 1795-1831.Â  Marixa Lasso. Universidad de los Andes, Banco de la Republica, Bogota, 2013, 183 pags.",2016,BoletÃ­n Cultural y BibliogrÃ¡fico
Joint blind calibration and time-delay estimation for multiband ranging,"In this paper, we focus on the problem of blind joint calibration of multiband transceivers and time-delay (TD) estimation of multipath channels. We show that this problem can be formulated as a particular case of covariance matching. Although this problem is severely ill-posed, prior information about radio-frequency chain distortions and multipath channel sparsity is used for regularization. This approach leads to a biconvex optimization problem, which is formulated as a rank-constrained linear system and solved by a simple group Lasso algorithm.Numerical experiments show that the proposed algorithm provides better calibration and higher resolution for TD estimation than current state-of-the-art methods.",2020,ArXiv
Russula farinipes Romell apud Britzelmayr in Finland,"In the summer of 1965 Dr. HANS HAAS from Stuttgart visited Finland. At that time he presented me with a fungus, which he had found in Turku, Ruissalo, and which I had not seen before. The fungus concerned was Russula farinipes Rom. In September 1966 I became more familiar with the species, both in a beech forest in Southwest Germany as well as under the microscope, again with the introduction of Dr. HAAS. In the autumn of 1966 I also got in my hands two specimens represented in the Turku University Herbarium with the provisory names R . fellea Fr.? and R. sp., which can presumably be taken to refer to the same species. R . fellea Fr. and R. farinipes Rom. came at once into my mind. The species proved to be the latter one. Because there are no earlier notes of its existence in Finland it might be useful to record it. ScHAEFFER (s. 267) defines the species as follows. Â«Ein scharfer Weissporer. Blassocker-semme1ge1b Â± kornigrauh, scharfrandig. Lamellen schmal sichelig. Stiel blass, flockig, ausspitzend. Fleisch hart und sehr elastisch, sehr scharf, geruchlos . Sporen i:soliert punktiert, I a. Cystiden in Lamellen, Hut und Stiel pfriemlich spitz. Laubwald.Â« According to the literature and the specimens I have seen R. farinipes could be described as follows . The pellicle of the cap is chamois-like, not only because of the colour,",1969,
â€˜Uurga shigâ€™ â€“ What is it like to be a lasso? Drawing figureâ€“ground reversals between art and anthropology:,"How might a singular object, a herdsmanâ€™s lasso known as the â€˜uurgaâ€™, facilitate a fresh understanding of cosmology and humanâ€“animal relationships in nomadic Mongolia? â€˜Uurga shigâ€™ re-evaluates the...",2016,Journal of Material Culture
Spas in Britain and in France in the Eighteenth and Nineteenth Centuries,"Originating from the age-old belief that water springing from the depths was endowed with healing properties, spas, which first blossomed in the West during the heyday of the Roman Empire, again gained importance and fame in the 18th and 19th centuries, as the increasing medicalisation of thermal water drew crowds to the best-sited or best-organised watering places of European economically developed countries. As, in most cases, none but the social elites could afford to spend time and money in such spots, investment followed, both in terms of architecture and of leisure, since visitors, after having been convinced by their physicians, high society journals or word of mouth, had to be kept happy as well as made fit. Simultaneously competition grew as spas vied for patronage, both within national borders and across Europe, the alleged quality of their waters being flaunted in the jingoistic battles of words which served as forerunners to the grislier actions of WW1. Being the major lieus of high society leisure and pleasure, spas underwent the same decline as the prewar moneyed classes which patronized them and lost ground, both to more exotic destinations and to seaside resorts, which, likewise, promoted health and well-being, but in a less elitist environment and at a cheaper price. Thalassotherapy, grafting on the success of the latter and making much of the relaxation and physical fitness derived from natural elements such as seawater or seaweeds, is the latest avatar of that long story which the papers of the conference held in Brest (France) in May 2005 here purport to tell.",2006,
Human debranching enzyme 1 deficiency : a novel genetic etiology of herpes simplex encephalitis,"Une approche de criblage du genome entier a permis lâ€™identification de la mutation faux-sens I120T dans lâ€™enzyme de debranchement 1 (DBR1) chez deux enfants dâ€™une meme famille consanguine. DBR1 hydrolyse les ponts phosphodiester 2â€™â€”5â€™ au site de branchement des introns excises sous forme de lasso lors de lâ€™epissage de lâ€™ARN pre-messager. La souche mutante nulle dbr1 de S. Cerevisiae presente un phenotype dâ€™accumulation dâ€™introns, complemente par transfection du cDNA DBR1 humain sauvage. Une souche mutee a la meme position presente une accumulation moderee dâ€™introns, suggerant que lâ€™allele mutant est hypomorphe chez la levure. Une souche mutante nulle dbr1 de S. Cerevisiae a ete transformee avec le cDNA DBR1 humain WT ou mutant, pour determiner si lâ€™allele mutant est fonctionnel. Lâ€™allele mutant confere une expression normale de lâ€™ARN dans les fibroblastes immortalises-SV40 dâ€™un patient, et lâ€™expression proteique est reduite. Les fibroblastes du patient presentent une production reduite dâ€™IFN en reponse a une stimulation extracellulaire par poly(I:C) et un fort taux de replication du virus HSV-1. Le defaut de reponse a TLR3 et la forte susceptibilite a HSV-1 dans les fibroblastes DBR1 I120T suggerent un lien entre DBR1 et la voie TLR3, et suggerent quâ€™une deficience dans DBR1 puisse etre a la base de la pathogenese a HSE chez les deux patients, par un defaut de controle de HSV-1 dans le CNS. Le mecanisme de ce defaut de reponse a TLR3 et de cette permissivite a la replication de HSV-1 dans les cellules deficientes pour DBR1 nâ€™est pas completement compris, et sera caracterise dans des cellules du systeme nerveux central derivees de cellules souches pluripotentes induites",2012,
"DNA methylation-driven genes for constructing diagnostic, prognostic, and recurrence models for hepatocellular carcinoma","In this study, we performed a comprehensively analysis of gene expression and DNA methylation data to establish diagnostic, prognostic, and recurrence models for hepatocellular carcinoma (HCC). Methods: We collected gene expression and DNA methylation datasets for over 1,200 clinical samples. Integrated analyses of RNA-sequencing and DNA methylation data were performed to identify DNA methylation-driven genes. These genes were utilized in univariate, least absolute shrinkage and selection operator (LASSO), and multivariate Cox regression analyses to build a prognostic model. Recurrence and diagnostic models for HCC were also constructed using the same genes. Results: A total of 123 DNA methylation-driven genes were identified. Two of these genes (SPP1 and LCAT) were chosen to construct the prognostic model. The high-risk group showed a markedly unfavorable prognosis compared to the low-risk group in both training (HR = 2.81; P < 0.001) and validation (HR = 3.06; P < 0.001) datasets. Multivariate Cox regression analysis indicated the prognostic model to be an independent predictor of prognosis (P < 0.05). Also, the recurrence model successfully distinguished the HCC recurrence rate between the high-risk and low-risk groups in both training (HR = 2.22; P < 0.001) and validation (HR = 2; P < 0.01) datasets. The two diagnostic models provided high accuracy for distinguishing HCC from normal samples and dysplastic nodules in the training and validation datasets, respectively. Conclusions: We identified and validated prognostic, recurrence, and diagnostic models that were constructed using two DNA methylation-driven genes in HCC. The results obtained by integrating multidimensional genomic data offer novel research directions for HCC biomarkers and new possibilities for individualized treatment of patients with HCC.",2019,Theranostics
Sozialklima â€“ die Beziehungen zwischen den SchÃ¼lerInnen,"Spatestens seit Mitte der 1970er-Jahre zahlt das Sozialklima innerhalb von Schulklassen mit zu den Forschungsschwerpunkten in der Schul- und Unterrichtsforschung. Entscheidende Impulse gingen dabei u. a. von den Arbeiten von Moos (â€žClassroom Environment Scale, CESâ€œ; vgl. Moos 1979a, b; Moos/Trickett 1974), Fend (1977) und von Saldern (â€žLandauer Skalen zum Sozialklima LASSOâ€œ; von Saldern/Littig 1987) aus, in neuerer Zeit fortgesetzt etwa von Eder (â€žLinzer Fragebogen zum Schul- und Klassenklima, LFSKâ€œ; Eder 1996, 1998; Eder/Mayr 2000) und Holtappels (2003). Die AutorInnen gehen dabei ubereinstimmend davon aus, dass die Qualitat der sozialen Beziehungen â€“ deren atmospharische â€žGrundtonungâ€œ (Eder) â€“ eine der zentralen Dimensionen mit Blick auf die Erlebnisqualitat schulischer Situationen und Ereignisse fur die SchulerInnen darstellt und nicht nur das unmittelbare Wohlfuhlen der Heranwachsenden in der Klasse bzw. der Schule beeinflusst, sondern mittelbar auch die Entwicklung der Schulleistungen und anderer Verhaltensmerkmale der SchulerInnen in der Klasse (vgl. Zumhasch 2006, S. 144; Raufelder 2010).",2010,
The Study on Impact Factors of Foreign Direct Investment Based on Lasso,"Among the many factors affecting foreign direct investment,the market size,infrastructure conditions,tariffs,trade openness and labor productivity are the five main impact factors of foreign direct investment,and the influence of market size is far greater than the influence of other factors.In the meantime,Lasso method,least squares method and stepwise regression method are compared.From the results we can see that the Lasso method is better than the other two methods in terms of variable selection.",2014,Journal of Hunan University
Progettazione tecnologica parametrica di sistemi ad armatura diffusa,"INTRODUZIONE 
Il punto di partenza sulla quale e stata sviluppata la tesi di Laurea Magistrale consiste nell'intenzione di accentuare la conoscenza di tecnologie edilizie, oltre a quelle studiate durante l'intero corso di laurea, con particolare attenzione a metodologie costruttive industriali. 
IL SEGUENTE DOCUMENTO SI PROPONE DI APPROFONDIRE UNA TIPOLOGIA COSTRUTTIVA COADIUVATA DALL IMPLEMENTO DI ELEMENTI DI MATRICE POLIMERICA, TRACCIANDO POI IPOTESI DI MIGLIORAMENTO TECNOLOGICO DELLA STESSA. 
Il seguente documento si propone di approfondire una tipologia costruttiva coadiuvata dall'implemento di elementi di matrice polimerica, tracciando poi ipotesi di miglioramento tecnologico della stessa. 
Tale percorso si e sviluppato in quattro momenti: 
1 - Conoscenza e approfondimento delle caratteristiche dei Sistemi Ad Armatura Diffusa (SAAD), tecnologia che prevede l'utilizzo di doppi ""casseri a perdere"" al fine di creare strutture a setti murari portanti. 
Esistono due diverse tipologie di SAAD, di piccole o grandi dimensioni: nel primo caso parliamo di ""blocchi"", nel secondo di ""pannelli"". 
I pannelli hanno larghezza modulare pari a 120 cm e altezza di circa 300 cm, comunque variabili a seconda delle necessita di progetto. Il peso e pari a 20-22 Kg per pannello. 
I blocchi misurano circa 100 cm di larghezza, 30/40 di altezza e una profondita variabile tra i 25 e i 45 cm, con un peso di circa di Kg ciascuno. 
I due ""casseri"" che costituiscono l'elemento costruttivo sono realizzati in EPS (Polistirene Espanso) autoestinguente e sono collegati ad incastro da distanziali specifici che vanno ad inserirsi in apposite guide presenti nei due elementi, creando cosi l'intercapedine d'accoglienza del calcestruzzo. 
L'affiancamento e la sovrapposizione dei vari blocchi sono facilitati attraverso spine di incastro che si trovano ai lati dei blocchi: tali processi consentono il montaggio delle casseforme a perdere all'interno delle quali verra gettato il calcestruzzo. 
I distanziali, di materiale polimerico o metallico, assolvono anche al compito di inclusione delle armature verticali e orizzontali mediante idonei vani di alloggiamento. 
Con la gettata di calcestruzzo si andra cosi a creare una struttura monolitica armata, isolata dal polistirene espanso. 
Oltre che per la creazione di strutture portanti verticali, i SAAD comprendono elementi per la realizzazione di strutture di solai portanti alleggeriti o coperture. 
Le metodologie di utilizzo e i dati riguardanti SAAD sono stati acquisiti durante un tirocinio presso AIPE, lAssociazione Italiana Polistirene Espanso, sita in Milano. 
Oltre alla divulgazione tecnologica dei Sistemi Ad Armatura Diffusa, AIPE si occupa di una promozione del Polistirene a 360Â°, coinvolgendo aspetti come l'imballaggio, elementi costruttivi per l'ingegneria civile fino ad arrivare a temi come lo smaltimento e il riciclo del materiale. 
2- Approfondimento del ""Parametricismo"", metodologia che consente la gestione complessa di dati per la modellazione 3D e l'analisi. 
""2- Approfondimento del ""Parametricismo"" (...) 
SI TRATTA DI UN SISTEMA GENERATIVO CHE PERMETTE LA CREAZIONE DI ELEMENTI COMPLESSI, MEDIANTE PROCESSI ALGORITMICI E ASSOCIAZIONI DI DATI CHE POSSONO ESSERE VARIATI SINGOLARMENTE E IN OGNI MOMENTO."" 
Si tratta di un sistema generativo che permette la creazione di elementi complessi, mediante processi algoritmici e associazioni di dati che possono essere variati singolarmente e in ogni momento. 
Tali dati possono essere di diversa natura, ad esempio geometrica, piuttosto che bioclimatica o urbanistica. 
Il Parametricismo e cosi presentato dalle sue origini ancora senza l'ausilio di mezzi informatici, fino ad arrivare agli odierni risvolti architettonici consentiti dai moderni software. 
Tra questi, particolare attenzione viene prestata a Grasshopper Â®, forse il software parametrico piu diffuso e utilizzato oggi. 
3 - Proprio tramite l'utilizzo di Grasshopper Â® si sviluppa la terza parte della tesi. 
Attraverso una modellazione parametrica, si e cercato di plasmare il blocco di piccole dimensioni SAAD, concentrandosi sul componente esterno. 
Tra le tante strade percorribili, l'obbiettivo perseguito a titolo esemplificativo consiste nell'ottenimento di una morfologia quanto piu possibile auto ombreggiante del blocco. 
Ne consegue che le variabili introdotte in GrasshopperÂ® saranno dati come l'altezza solare, l'azimuth oltre che il periodo dell'anno, analizzati per tre casi dimostrativi sviluppati nelle localita di Torino, Roma e Catania. 
I risultati ottenuti confermano il concetto chiave che si intende dimostrare con questa tesi, cioe l'enorme potenzialita che comporta l'applicazione del metodo parametrico in contesti diversi da quelli in cui viene solitamente applicata. 
Abitualmente utilizzato per architetture di grande scala, si vuole mostrare come tale approccio possa essere positivo anche in un ambito maggiormente ridotto seppure gia utilizzato, come SAAD, e in generale per applicazioni di innovazione tecnologica.",2014,
Verlasso distribution expands again | Verlasso,SeafoodSource shares the announcement of Verlasso's new partnership introducing sustainable salmon to Colorado.,2012,
The political future of social security in aging societies,"Doubts about the ability of industrialized countries to continue to provide a sufficient level of retirement benefits to a growing number of retirees has fueled much recent debate and inspired a variety of recommendations for reform. Few major reforms, however, have actually been implemented. In The Political Future of Social Security in Aging Societies, Vincenzo Galasso argues that the success of any reform proposals depends on political factors rather than economic theory. He offers a comparative analysis of the future political sustainability of social security in six countries with rapidly aging populations--France, Germany, Italy, Spain, the United Kingdom, and the United States. Using a quantitative approach, he finds that an aging population has political as well as economic effects: an older electorate will put pressure on politicians and policy-makers to maintain or even increase benefits. Galasso evaluates how each country's different political constraints shape its social security system, considering such country-specific factors as the proportion of retirees in the population, the redistributive feature of each system, and the existing retirement policy in each country. He concludes that an aging population will lead to more pension spending; yet postponing retirement mitigates the impact of this, and may be the only politically viable alternative for social security reform.",2006,
Fused Multiple Graphical Lasso,"In this paper, we consider the problem of estimating multiple graphical models simultaneously using the fused lasso penalty, which encourages adjacent graphs to share similar structures. A motivating example is the analysis of brain networks of Alzheimer's disease using neuroimaging data. Specifically, we may wish to estimate a brain network for the normal controls (NC), a brain network for the patients with mild cognitive impairment (MCI), and a brain network for Alzheimer's patients (AD). We expect the two brain networks for NC and MCI to share common structures but not to be identical to each other; similarly for the two brain networks for MCI and AD. The proposed formulation can be solved using a second-order method. Our key technical contribution is to establish the necessary and sufficient condition for the graphs to be decomposable. Based on this key property, a simple screening rule is presented, which decomposes the large graphs into small subgraphs and allows an efficient estimation of multiple independent (small) subgraphs, dramatically reducing the computational cost. We perform experiments on both synthetic and real data; our results demonstrate the effectiveness and efficiency of the proposed approach.",2015,SIAM Journal on Optimization
Functional and phylogenetic components in cercarial nervous systems.,"Studies involving comparisons of taxa that vary in their degree of relatedness may allow the distinction of functional and phylogenetic components in cercarial sensory systems. In this study, cercariae of allocreadiids Bunodera Railliet, 1896 and Crepidostomum Braun, 1900, lecithodendriid Allassogonoporus Olivier, 1938 and opecoelid Allopodocotyle Pritchard, 1966 were compared as regards ultrastructure and chaetotaxy of sensory receptors as well as neuromorphology. Cercariae were treated with acetylthiocholine iodide and silver nitrate and some were processed for scanning and transmission electron microscopy. The types of cercarial sensory receptors differed in the presence of a tegumentary sheath, a dome-like base and a tegumentary collar, number of cilia (0, 1, 2 or more), cilium length (short, moderately long or long) and tegumentary collar length (low to moderately low, high or very high). Chaetotaxic patterns were consistent at the family level in all taxa studied. Irregular cholinergic nerve networks were identified. The present study indicates that the major categories of cercarial sensory receptors are nonciliated (including sheathed and subtegumentary types) and ciliated (including uncollared and collared types) receptors. It also allows the distinction of functional and phylogenetic components in the sensory systems of the cercariae studied. Functional components were reflected in the numbers of sensory receptors associated with each nerve region and in the ultrastructure and site-specificity of receptor types. Phylogenetic components included taxon-specific chaetotaxic patterns and receptor types.",2004,Folia parasitologica
Transductive Prostate Segmentation for CT Image Guided Radiotherapy,"Accurate 3-D prostate segmentation is a significant and challenging issue for CT image guided radiotherapy. In this paper, a novel transductive method for 3-D prostate segmentation is proposed, which incorporates the physicianâ€™s interactive labeling information, to aid accurate segmentation, especially when large irregular prostate motion occurs. More specifically, for the current treatment image, the physician is first asked to manually assign the labels for a small subset of prostate and non-prostate (background) voxels, especially in the first and last slices of the prostate regions. Then, transductive Lasso (tLasso) is proposed to select the most discriminative features slice-by-slice. With the selected features, our proposed weighted Laplacian regularized least squares (wLapRLS) is adopted to predict the prostate-likelihood for each remaining unlabeled voxel in the current treatment image. The final segmentation result is obtained by aligning the manually segmented prostate regions of the planning and previous treatment images, onto the estimated prostate-likelihood map of the current treatment image for majority voting. The proposed method has been evaluated on a real prostate CT dataset including 11 patients with more than 160 images, and compared with several state-of-the-art methods. Experimental results indicate that the promising results can be achieved by our proposed method.",2012,
Meta-Analysis of Genomic and Transcriptomic Variations in Lung Adenocarcinoma,"Lung cancer is the leading cause of the largest number of deaths worldwide and lung adenocarcinoma (LUAD) is the most common form of lung cancer. In this study, we carried out an integrated meta-analysis of the mutations including single-nucleotide variations (SNVs), the copy number variations (CNVs), RNA-seq and clinical data of patients with LUAD downloaded from The Cancer Genome Atlas (TCGA). We integrated significant SNV and CNV genes, differentially expressed genes (DEGs) and the DEGs in active subnetworks to construct a prognosis signature. Cox proportional hazards model (LOOCV) with Lasso penalty was used to identify the best gene signature among different gene categories. The patients in both training and test data were clustered into high-risk and low-risk groups by using risk scores of the patients calculated based on selected gene signature. We generated a 12-gene signature (DEPTOR, ZBTB16, BCHE, MGLL, MASP2, TNNI2, RAPGEF3, SGK2, MYO1A, CYP24A1, PODXL2, CCNA1) for overall survival prediction. The survival time of high-risk and low-risk groups was significantly different. This 12-gene signature could predict prognosis and they are potential predictors for the survival of the patients with LUAD.",2019,arXiv: Genomics
"Provenance of the Oadby Till at Buddon Wood Quarry, Mountsorrel, Leicestershire","A sample of the Oadby Till from Buddon Wood Quarry, Mountsorrel, Leicestershire was 
examined for its microfossil and palynomorph content, in order to determine the age and 
provenance of this deposit. Early Jurassic (Hettangian) Foraminiferida and Ostracoda were 
found, together with Late Cretaceous (late Coniacian-Santonian) Foraminiferida. The Early 
Jurassic microfauna was probably relatively locally derived from the east or northeast, but the 
late Cretaceous taxa must have been derived from the Chalk outcrop again to the east or 
northeast. The palynoflora indicates input from the Carboniferous, Late Triassic (Rhaetian), 
Jurassic (late Sinemurian, late Callovian-Oxfordian and Kimmeridgian) and Late Cretaceous. 
The dominant species, Classopollis classoides, is likely to be largely from the Triassic, so the 
dominant reworked element in this till is Rhaetian. The occurrence of Jurassic and Cretaceous 
palynomorphs from the east/northeast suggests that the relatively minor Carboniferous 
reworking is probably from the underlying Thrussington Till. This is as opposed to locally from 
the Swadlincote coalfield to the northwest, or from further away such as the northeast of 
England. The Rhaetian reworking is assumed to have been sourced locally, again from an 
easterly or northeasterly direction. The Blue Anchor Formation is typically organic-poor, hence 
the source of these palynomorphs is considered to be from the Westbury and/or Lilstock 
formations. The Jurassic input is assumed to be from the north or northeast. The principal 
Jurassic outcrop belt in the UK could have potentially sourced all the late Sinemurian, late 
Callovian-Oxfordian and Kimmeridgian input. The Chalk Group dinoflagellate cysts are also 
interpreted as having being sourced from the east or the northeast. Integration of the calcareous 
microfaunal and palynological evidence indicates that the Oadby Till from this locality contains 
stratal units of Carboniferous, Triassic, Jurassic and Late Cretaceous age. Because of the 
presence of Jurassic and Late Cretaceous elements, the ice apparently travelled to Mountsorrel 
from the east or northeast.",2008,
"Society for Pediatric Pathology Fall Meeting, Banff, Alberta, Canada, September 2010","Society for Pediatric Pathology Fall Meeting, Banff, Alberta, Canada, September 2010 Platform Presentations: 1. Ljungan Virus Antigen Detected in Brain and Spinal Cord from Cases of Stillbirth. E Sbrana, HK Hawkins, JE Moss, GR Saade, B Niklasson, University of Texas Medical Branch, Galveston, TX, USA; Uppsala University, Uppsala, Sweden; Apodemus AB, Stockholm, Sweden. Background: Current estimates of the incidence of stillbirth in the United States are of about 27 000 cases per year, making stillbirth accountable for approximately half of all perinatal deaths. An association of cyclic wild rodent abundance with incidence of intrauterine fetal death (IUFD) in humans has been reported in Sweden, which supports the hypothesis of a zoonotic disease as causative agent of stillbirth. Ljungan virus (LjV) was detected by immunohistochemistry (IHC) in placenta and brain of approximately half of the Swedish IUFD cases investigated. Ljungan virus, a parechovirus in the Picornaviridae family, has been isolated from wild rodents and is present not only in Sweden but also in many other countries including the US. This study reports a preliminary investigation of LjV in a stillbirth case series from the Texas Gulf Coast region. Design: Seventeen cases of stillbirth and 14 controls (therapeutic abortions or accidental deaths) were selected from an autopsy case series and examined by IHC. Unstained sections were prepared from paraffin blocks of brain and spinal cord collected at the time of post-mortem examination. Immunostaining was performed as previously described. Presence of LjV specific antigen was detected with two different mouse monoclonal antibodies, using normal mouse serum as a control. Tissues from LjV infected and non-infected animals were also included as antigen staining controls. Two-tailed Fisherâ€™s exact test was used to determine statistically significant differences between cases and controls. Results: Immunostaining performed on the brain sections detected LjV antigen in 8 out of 17 cases of IUFD, as opposed to none of the controls (p-value 0.003). When sections of spinal cord were also included, 11 of 17 IUFD cases tested positive, compared to 3 of 14 controls (p-value 0.029). Intense staining was mostly localized in nerve processes, and occasional staining was observed in neuronal cell bodies in the medulla. Conclusions: As previously described in a Swedish case series, Ljungan virus appears to be more prevalent among cases of stillbirth, compared to cases of terminations/ accidental deaths. However, it is unclear exactly which strain of LjV was detected â€“ whether the original stain isolated in Sweden or a â€˜Ljungan-likeâ€™ virus like those previously isolated in wild rodent populations in the U.S. Future investigations will include virus isolation and sequencing to determine the exact strain of LjV circulating in the area. 2. Immunohistochemical Expression of SALL4 in Wilms Tumors, Nephrogenic Rests, and Fetal and Postnatal",2010,Pediatric and Developmental Pathology
Nonclassical Symmetries of Benney Equation and Compatibility,The nonclassical symmetries of Benney equation is studied.A partial differential equation is quoted to get the conclusion that the nonclassocal symmetries of the nonlinear partial differential equations can be derived by using the compatibility between the original equation and the invariant surface condition.,2008,Science Technology and Engineering
"EIA, Decision-making Theory and Screening and Scoping in UK Practice","As an aid to decision making Environmental Impact Assessment (EIA) is seen as a rational and systematic process which is often held to be holistic and proactive in its approach to environmental protection (Glasson et al., 1999). The roots of EIA are firmly located within the 1960s' demand for a more systematic and objective approach to environmental decision making and hence within the rationalist model of decision making theory. This paper examines the key stages of the EIA process to assess how far EIA conforms to the rationalist model today. Most research in EIA decision making has focused on the project authorization process and not the crucial decisions made at the earlier stages of screening and scoping. This study examines those early stages within the context of UK EIA practice. From this examination the paper attempts to locate EIA within decision-making theory.",2000,Journal of Environmental Planning and Management
Probability genotype imputation method and integrated weighted lasso for QTL identification,"BackgroundMany QTL studies have two common features: (1) often there is missing marker information, (2) among many markers involved in the biological process only a few are causal. In statistics, the second issue falls under the headings â€œsparsityâ€ and â€œcausal inferenceâ€. The goal of this work is to develop a two-step statistical methodology for QTL mapping for markers with binary genotypes. The first step introduces a novel imputation method for missing genotypes. Outcomes of the proposed imputation method are probabilities which serve as weights to the second step, namely in weighted lasso. The sparse phenotype inference is employed to select a set of predictive markers for the trait of interest.ResultsSimulation studies validate the proposed methodology under a wide range of realistic settings. Furthermore, the methodology outperforms alternative imputation and variable selection methods in such studies. The methodology was applied to an Arabidopsis experiment, containing 69 markers for 165 recombinant inbred lines of a F8 generation. The results confirm previously identified regions, however several new markers are also found. On the basis of the inferred ROC behavior these markers show good potential for being real, especially for the germination trait Gmax.ConclusionsOur imputation method shows higher accuracy in terms of sensitivity and specificity compared to alternative imputation method. Also, the proposed weighted lasso outperforms commonly practiced multiple regression as well as the traditional lasso and adaptive lasso with three weighting schemes. This means that under realistic missing data settings this methodology can be used for QTL identification.",2013,BMC Genetics
Catalogue et affinitÃ©s gÃ©ographiques des Odonata des Ã®les voisines de Madagascar (Insecta: Pterygota),"Resume Une analyse bibliographique exhaustive revele que 71 especes et sous-especes dâ€™Odonates sont presentes sur lâ€™ensemble des iles voisines de Madagascar appartenant aux archipels des Mascareignes, des Comores et des Seychelles. Le taux dâ€™endemisme maximal pour lâ€™ensemble des iles voisines de Madagascar est de 34 %. Le taux dâ€™endemisme est sensiblement plus important dans les Mascareignes (34 %) quâ€™aux Comores (23 %) ou aux Seychelles (19 %). Le peuplement odonatologique y est domine par les Libellulidae (36 taxons) et les Coenagrionidae (18 taxons). Chaque archipel possede au moins un des 23 taxons endemiques presents sur ces iles. Les Seychelles comptent deux genres monospecifiques endemiques: Allolestes et Leptocnemis. Les Mascareignes abritent deux genres endemiques: Thalassothemis et Coenagriocnemis. Ce dernier a subi une radiation evolutive au sein de lâ€™archipel. Les iles voisines de Madagascar se caracterisent par une radiation evolutive des genres Hemicordulia et Gynacantha a lâ€™echelle de la re...",2012,Annales De La Societe Entomologique De France
"Twentyâ€eight additions to the lengthâ€weight and lengthâ€length relationships of Indoâ€Pacific fishes from the Davao Gulf, Philippines","Summary 
Selected fish were measured on markets along the Davao Gulf, Philippines between 2009 and 2016, augmenting the number of Length-Weight relationships (LWR) published earlier for the same area. LWRs were calculated for 28 fishes including those of 12 firstly reported, rare species. SL-TL and SL-FL relationships were determined for 28 and 25 species (also including 8 and 12 newly reported relationships, respectively). Minimum size at which individuals start developing forked tails are provided for Cheilinus fasciatus (SLÂ =Â 15.0Â cm), Plectorhinchus polytaenia (SLÂ =Â 27.0Â cm), Pseudobalistes flavimarginatus (SLÂ =Â 18.0Â cm) and Thalassoma hardwicke (SLÂ =Â 11.5Â cm). The flatfish Psettodes erumei had a right-left eyed ratio of 0.55.",2018,Journal of Applied Ichthyology
Bayesian inputâ€“output table update using a benchmark LASSO prior,"We propose updating a multiplier matrix subject to final demand and total output constraints, where the prior multiplier matrix is weighted against a LASSO prior. We update elements of the Leontief...",2020,Economic Systems Research
"Significant predictors of mathematical literacy for top-tiered countries/economies, Canada, and the United States on PISA 2012: Case for the sparse regression model.","BACKGROUND
National ranking from the triennial Programme of International Student Assessment (PISA) often serves as a barometer of national performance and human capital. Though excessive student- and school-level covariates (nÂ >Â 700) may prove intractable for traditional least-squares estimate procedures, shrinkage methods may be more suitable for subset selection.


AIMS
With a focus on the United States, this paper proposes sparse regression for PISA 2012 to discover salient student- and school-level predictor variables for mathematical literacy achievement.


SAMPLE
The sparse regression analysis was conducted on 10 top-tiered OECD countries/economies, Canada, and the United States in mathematical literacy on the 2012 PISA. Two- and three-level hierarchical regression analyses were performed on Canadian and US students (NÂ =Â 26,522) along with five of the ten top-tiered countries/economies (NÂ =Â 58,385).


METHODS
Using the 'least absolute shrinkage and selection operator' (LASSO) technique, the study (1) identified salient predictor variables of mathematical literacy performance for the top-tiered countries/economies, Canada, and the United States and (2) used these salient variables to perform two- and three-level hierarchical regression on data from Canada and the United States along with five top-tiered countries/economies. Weights and replicates were used to account for complex sample design. A weighted, two-level confirmatory factor analysis was performed to identify latent constructs. Missing data were handled through multiple imputation.


RESULTS
Separate two-level hierarchical models accounted for 32-35% student-level and 58-70% school-level variance in Canada and the United States, respectively; three-level models accounted for 33% of level-one variance, 62-65% level-two variance, and 13-44% of level-three variance for the US/Canada and US/Canada/top-tiered students, respectively. Following top-tiered countries/economies, Canadian students had high levels of self-efficacy, were more likely to encounter advanced concepts in class, were less activity/small group-centred, and were more likely to consider truancy a learning hindrance. Factor analyses revealed a positive relation with rigour and class organization (teacher-centred) for top-tiered countries and Canada, though not for the United States. For all countries, there was a strong relation between rigour and self-beliefs.


CONCLUSION
Compared to top performers, a less rigorous curriculum, coupled with class and school factors, may explain lag in US performance.",2018,The British journal of educational psychology
Glomerulonephritis and vasculitis . Tubulointerstitial disease,Section I: Glomerulonephritis and Vasculitis Introduction: Richard J Glassock and Arthur H Cohen Chapter 1 Normal Vascular and Gomerular Anatomy Arthur H Cohen and Richard J Glassock Chapter 2 The Primary Glomerulopathies Arthur H Cohen and Richard J Glassock Minimal Change Disease Focal Segmental Glomerulosclerosis Membranous Glomerulonephritis Membranoproliferative Glomerulonephritis Mesangial Proliferative Glomerulonephritis Crescentic Glomerulonephritis Immunoglobulin A Nephropathy Fibrillary and Immunotactoid Glomerulonephritis Collagenofibrotic Glomerulopathy Chapter 3 Heredofamilial and Congenital Glomerular Disorders Arther H Cohen and Richard J Glassock Chapter 4 Infection-Associated Glomerulopathies Arther H Cohen and Richard J Glassock Chapter 5 Vascular Disorders Arther H Cohen and Richard J Glassock Section II: Tubulointerstitial Disease Introduction: Jean Pierre Grunfeld Chapter 6 Renal Interstitium and Major Features of Chronic Tubulointerstitial Nephritis Garabed Eknoyan and Luan D Truong Stucture of the Interstitium Function of the Interstitium Pathologic Features of Chronic TIN Pathogenesis of Chronic TIN Patterns of Tubular Dysfunction Correlates of Tubular Dysfunction with Severity of Chronic TIN Correlates of Chronic TIN with Progressive Renal Failure Drugs Heavy Metals Ischemic Vascular Disease Obstruction Hematopoietic Diseases Hematologic Diseases Metabolic Disorders Granulomatous Diseases Endemic Diseases Hereditary Diseases Papillary Necrosis Chapter 7 Unrinary Tract Infection Alain Meyrier Diagnosis Bacteriology Virulence Factors of Uropathogenic Strains Classification of Urinary Tract Infection Imaging Special Forms of Renal Infection Chapter 8 Reflux and Obstructive Nephropathy James M Gloor and Vicente E Torres Anatomy of Vericoureteric Reflux Pathogenesis of Vesicoureteric Reflux and Reflux Nephropathy Diagnosis of Vesicoureteric Reflux and Reflux Nephropathy Clinical Course of Vesicoureteric Reflux Treatment of Vesicoureteric Reflux Complications of Reflux Nephropathy Pathogenesis of Obstructive Nephropathy Clinical Manifestations of Obstructive Nephropathy Diagnosis of Obstructive Nephropathy Posterior Urethral Valves Ureterovesical Junction Obstruction Retroperitoneal Fibrosis Chapter 9 Cystic diseases of The Kidney Yves Pirson and Dominique Chauveau General Features Nongenetic Disorders Genetic Disorders Chapter 10 Toxic Nephropathies Jean-Louis Vanherweghem Exposure to Nephrotoxins Exposure to Metals Exposure to Analgesics Exposure to Cyclosporine Exposure to Aminosalicylic Acid Exposure to Ochratoxins Exposure to Chinese Herbs Chapter 11 Metabolic Causes of Fubulointerstitial Disease Steven J Scheinman Chapter 12 Renal Tubular Disorders Lisa M Guay-Woodford Overview of Renal Tubular Disorders Renal Glucosuria Aminoacidurias Renal Hypophosphatemic Rickets Fanconi's Syndrome Renal Tubular Acidoses Bartter-like Syndromes Pseudogypoparathyroidism Disorders of Aldosterone-Regulated Transport Nephrogenic Diabetes Insipidus UrolithiasesIndex,1999,
"Lassification of Signals Using Wavelets and Principal Components Reduction , with Application to Auditory Brain Activity","The paper deals with a generalized linear model with functional data using a wavelet representation of the signals. A reduction of dimension is first obtained through a principal component analysis. The discriminative function is then given by a loglikelihood maximization, with a LASSO penalization, in order to ensure the sparsity of the wavelet representation. In order to have a data-driven procedure, we explore different cross-validation schemes. A simulation study is presented, showing our estimator that is competitive with those described in Reiss and Ogden (2013). We apply this model to a classification of functional EEG data, to study the capacity of discrimination of nearby sounds.",2013,
Fighting in Three Uniforms: Soviet POWs in World War Two,"The fate of Soviet POWs represents a complex challenge for the historian: few studies devote space and time to discuss their treatment. Soviet military doctrine ordered soldiers to fight to the death, and the USSR did not recognize the Geneva Convention. Indeed, the Soviet government regarded POWs as traitors, and punished their relatives at home by reducing their food rations. Consequently, Soviet historians largely ignored the terrible ordeal of POWs in German captivity. Soviet post-war narratives concentrated on a few individuals who managed to escape and join the partisans. Textbooks heaped particular scorn on POWs who fought on the German side in the antiSoviet Vlassov movement. There was another reason to ignore the fate of POWs. After 1945, the glorious victory in the â€˜Great Patriotic Warâ€™ replaced the October Revolution as the new founding myth of the USSR, with the â€˜unity of party and peopleâ€™ emerging as the focal point. The mere existence of POWs and their service in enemy uniform challenged this narrative.",2013,
Iterative navigation of multipole diagnostic catheters to locate repeatingâ€pattern atrial fibrillation drivers,"INTRODUCTION
Targeting repeating-pattern atrial fibrillation (AF) sources (reentry or focal drivers) can help in patient-specific ablation therapy for AF; however, the development of reliable and accurate tools for locating such sources remains a major challenge. We describe iterative catheter navigation (ICAN) algorithm to locate AF drivers using a conventional circular Lasso catheter.


METHODS AND RESULTS
At each step, the algorithm analyzes 10 bipolar electrograms recoded at a given catheter location and the history of previous catheter movements to determine if the source is inside the catheter loop. If not, it calculates new coordinates and selects a new position for the catheter. The process continues until a source is located. The algorithm was evaluated in a computer model of atrial tissue with various degrees of fibrosis under a broad range of arrhythmia scenarios. The latter included slow and fast reentry, macroreentry, figure-of-eight reentry, and fibrillatory conduction. Depending on the initial distance of the catheter from the source and scenario, it took about 3 to 16 steps to localize an AF source. In 94% of cases, the identified location was within 4â€‰mm from the source, independently of the initial position of the catheter. The algorithm worked equally well in the presence of patchy fibrosis, low-voltage areas, fragmented electrograms, and dominant-frequency gradients.


CONCLUSIONS
AF repeating-pattern sources can be localized using circular catheters without the need to map the entire tissue. The proposed algorithm has the potential to become a useful tool for patient-specific ablation of AF sources located outside the pulmonary veins.",2019,Journal of Cardiovascular Electrophysiology
Regularized Laplacian Estimation and Fast Eigenvector Approximation,"Recently, Mahoney and Orecchia demonstrated that popular diffusion-based procedures to compute a quick approximation to the first nontrivial eigenvector of a data graph Laplacian exactly solve certain regularized Semi-Definite Programs (SDPs). In this paper, we extend that result by providing a statistical interpretation of their approximation procedure. Our interpretation will be analogous to the manner in which l2-regularized or l1-regularized l2-regression (often called Ridge regression and Lasso regression, respectively) can be interpreted in terms of a Gaussian prior or a Laplace prior, respectively, on the coefficient vector of the regression problem. Our framework will imply that the solutions to the Mahoney-Orecchia regularized SDP can be interpreted as regularized estimates of the pseudoinverse of the graph Laplacian. Conversely, it will imply that the solution to this regularized estimation problem can be computed very quickly by running, e.g., the fast diffusion-based PageRank procedure for computing an approximation to the first nontrivial eigenvector of the graph Laplacian. Empirical results are also provided to illustrate the manner in which approximate eigenvector computation implicitly performs statistical regularization, relative to running the corresponding exact algorithm.",2011,
"Schooling, Family, and the Ethnic Working Class before World War II","Since the 1970s, â€œrevisionistâ€ scholars have challenged many long-held assumptions about schooling in American history in ways that students and teachers can find fruitful for understanding the educational system within which they work. They contest the idea that public schools throughout the nationâ€™s history equally benefited students from different race, class, and gender backgrounds. As they engage questions of culture and difference, they also show that parents and students often held different views of schooling than did American teachers and professional reformers.1 For example, until the implementation of effective compulsory school attendance and child labor laws in the late 1930s, large numbers of working-class children quit formal schooling to work in the labor force. Low-income families depended on the earnings of their children to contribute to the familyâ€™s material subsistence. This was particularly true among immigrants to America, disproportionately poor and culturally predisposed to look skeptically upon American schools. They feared these institutions would influence their children in ways that conflicted with their own transplanted, old world cultures. The historical impact of public schooling on white working-class families is addressed skillfully by Stephen Lassonde in Learning to Forget: Schooling and Family Life in New Havenâ€™s Working Class, 1870-1940. Although he does not explicitly identify himself as a revisionist, Lassonde works with many of the assumptions of these historians in this study of effects of American education on parent-child relations among immigrants before World War II. His ambitious book engages several subfields of scholarship: child and educational history, family history, immigrant Italian American history, and working-class history. Lassonde wants to â€œcontemplate the effects of school attendance on working-class childrenâ€™s changing economic and emotional worthâ€ (3). He focuses on the relationship between families and schools rather than on schooling as an institution, choosing as a case study New Haven, Connecticut, beginning in the late nineteenth century, when the Irish were the largest immigrant group in the city. In this period, what has been termed the â€œfamily economyâ€ dominated working-class values about work and school. Collective family concerns were paramount. For the children, obligations often conflicted with school attendance. Studies of other immigrant groups in different cities report similar results.2 Learning to Forget: Schooling and Family Life in New Havenâ€™s Working Class, 1870-1940.",2010,Transformation
Incorporating group correlations in genome-wide association studies using smoothed group Lasso.,"In genome-wide association studies, penalization is an important approach for identifying genetic markers associated with disease. Motivated by the fact that there exists natural grouping structure in single nucleotide polymorphisms and, more importantly, such groups are correlated, we propose a new penalization method for group variable selection which can properly accommodate the correlation between adjacent groups. This method is based on a combination of the group Lasso penalty and a quadratic penalty on the difference of regression coefficients of adjacent groups. The new method is referred to as smoothed group Lasso (SGL). It encourages group sparsity and smoothes regression coefficients for adjacent groups. Canonical correlations are applied to the weights between groups in the quadratic difference penalty. We first derive a GCD algorithm for computing the solution path with linear regression model. The SGL method is further extended to logistic regression for binary response. With the assistance of the majorize-minimization algorithm, the SGL penalized logistic regression turns out to be an iteratively penalized least-square problem. We also suggest conducting principal component analysis to reduce the dimensionality within groups. Simulation studies are used to evaluate the finite sample performance. Comparison with group Lasso shows that SGL is more effective in selecting true positives. Two datasets are analyzed using the SGL method.",2013,Biostatistics
Adoption d'une nouvelle mÃ©thode de lutte sanitaire en milieu paysan au Burkina Faso : le pÃ©diluve acaricide/insecticide,"Le pediluve acaricide-insecticide est une nouvelle methode de lutte integree contre les vecteurs en zone subhumide Ouest-Africaine : son efficacite a ete validee par de nombreuses etudes en situations experimentales et reelles. Cette invention sanitaire d'origine exogene proposee par la recherche, a ete co-construite avec des groupes d'eleveurs il y a dix ans et a ensuite diffuse. Vingt-deux pediluves et soixante douze eleveurs ont ete etudies. A partir de 97 variables concernant les modalites de mise en oeuvre, la sociologie, les aspects organisationnels, le systeme d'elevage, l'appreciation de l'outil et les connaissances des eleveurs, 32 variables explicatives ont ete reparties en deux lots ("" pratiques et perceptions zootechniques "" et "" connaissances du systeme epidemiologique "") suite aux analyses preliminaires et sept variables ont ete choisies comme indicateurs d'adoption. Les lots de variables ont ete soumis a des analyses multivariees permettant de caracteriser trois groupes d'eleveurs, dont l'adoption a ete evaluee. Le premier groupe est constitue par les eleveurs modernes de Ouagadougou qui ont bien adopte la methode. Les eleveurs plus traditionnels de Bobo-Dioulasso sont separes en deux groupes dont un n'a pas du tout adopte le pediluve contrairement au second. Les dix variables discriminant principalement ces groupes sont analysees. Elles ont trait au systeme d'elevage, aux modalites de mise en oeuvre de la methode et a l'appreciation de l'outil. La discussion porte sur l'influence relative des connaissances des eleveurs et des pratiques d'elevage sur l'adoption. L'importance des modalites de mise en place ainsi que des caracteristiques du systeme de production est presentee. Enfin, l'appreciation du risque par les eleveurs est discutee a la lumiere des criteres d'adoptabilite de Mendras et Forse qui revelent les variations de perceptions individuelles des benefices et risques et le role essentiel du reseau sociotechnique. (Resume d'auteur)",2010,
Regularization and the small-ball method I: sparse recovery,"We obtain bounds on estimation error rates for regularization procedures of the form \begin{equation*} 
\hat f \in {\rm argmin}_{f\in 
F}\left(\frac{1}{N}\sum_{i=1}^N\left(Y_i-f(X_i)\right)^2+\lambda \Psi(f)\right) \end{equation*} when $\Psi$ is a norm and $F$ is convex. 
Our approach gives a common framework that may be used in the analysis of learning problems and regularization problems alike. In particular, it sheds some light on the role various notions of sparsity have in regularization and on their connection with the size of subdifferentials of $\Psi$ in a neighbourhood of the true minimizer. 
As `proof of concept' we extend the known estimates for the LASSO, SLOPE and trace norm regularization.",2016,arXiv: Statistics Theory
Novel Immune-Related Gene Signature for Risk Stratification and Prognosis of Survival in Lower-Grade Glioma,"Objective Despite several clinicopathological factors being integrated as prognostic biomarkers, the individual variants and risk stratification have not been fully elucidated in lower grade glioma (LGG). With the prevalence of gene expression profiling in LGG, and based on the critical role of the immune microenvironment, the aim of our study was to develop an immune-related signature for risk stratification and prognosis prediction in LGG. Methods RNA-sequencing data from The Cancer Genome Atlas (TCGA), Genome Tissue Expression (GTEx), and Chinese Glioma Genome Atlas (CGGA) were used. Immune-related genes were obtained from the Immunology Database and Analysis Portal (ImmPort). Univariate, multivariate cox regression, and Lasso regression were employed to identify differentially expressed immune-related genes (DEGs) and establish the signature. A nomogram was constructed, and its performance was evaluated by Harrellâ€™s concordance index (C-index), receiver operating characteristic (ROC), and calibration curves. Relationships between the risk score and tumor-infiltrating immune cell abundances were evaluated using CIBERSORTx and TIMER. Results Noted, 277 immune-related DEGs were identified. Consecutively, 6 immune genes (CANX, HSPA1B, KLRC2, PSMC6, RFXAP, and TAP1) were identified as risk signature and Kaplanâ€“Meier curve, ROC curve, and risk plot verified its performance in TCGA and CGGA datasets. Univariate and multivariate Cox regression indicated that the risk group was an independent predictor in primary LGG. The prognostic signature showed fair accuracy for 3- and 5-year overall survival in both internal (TCGA) and external (CGGA) validation cohorts. However, predictive performance was poor in the recurrent LGG cohort. The CIBERSORTx algorithm revealed that naÃ¯ve CD4+ T cells were significant higher in low-risk group. Conversely, the infiltration levels of M1-type macrophages, M2-type macrophages, and CD8+T cells were significant higher in high-risk group in both TCGA and CGGA cohorts. Conclusion The present study constructed a robust six immune-related gene signature and established a prognostic nomogram effective in risk stratification and prediction of overall survival in primary LGG.",2020,Frontiers in Genetics
A contribution to the conceptualisation of quality in impact assessment,"Quality is much sought after in, and a basic foundation for, good impact assessment (IA). However, the term is rarely defined, has an uncertain relationship with IA effectiveness, and it means different things to different stakeholders, which can lead to debates over the legitimacy associated with an IA process. Thus, IA quality needs conceptualising to position research and practice within broader understandings. This paper contributes to this conceptualisation by identifying nine dimensions of quality through a process of literature review drawing on three fields of study in which quality and quality management have already been debated and conceptualised: education; health care; and business. This approach sidesteps the plural views on quality existing within the field of IA itself which might otherwise bias the identification of quality dimensions. We therefore propose that the dimensions of IA quality are: Efficiency; Optimacy; Conformance; Legitimacy; Equity; Capacity Maintenance; Transformative Capacity; and Quality Management. A literature review of IA research and practice confirms the relevance of the identified quality dimensions to IA. We identify, to an extent, the relationship between quality and effectiveness. Quality aligns with procedural and transactive effectiveness, partly aligns with normative effectiveness and is distinct from, but helps to deliver, substantive effectiveness. 1. Why conceptualise? Impact Assessment (IA) is an umbrella term for a process (including, amongst others, Environmental Impact Assessment (EIA), Strategic Environmental Assessment (SEA), Health Impact Assessment (HIA), Social Impact Assessment (SIA) and Sustainability Assessment (SA)) that is applied at all levels of decision making and across many sectors (Morrison-Saunders et al., 2014b). IA has been defined as both a technical tool for analysing the consequences of a planned intervention and a legal and institutional procedure linked to the decision-making process of a planned intervention (IAIA, 2010). The process and the outcomes of IA are thus concerned with scientific observation and analysis, with principles of design, with the application of regulations and law, and with the interpretation of local and contextual rights and understandings. IA thus requires a broad range of activities that cuts across sectors and involves multiple stakeholders, each of which has different notions of what good â€˜qualityâ€™ means. We seek to conceptualise these notions of quality in IA. We start by introducing the concept of plurality. Leuschner (2012) analysed the role that pluralism and objectivity each has in scientific research and stated that in â€œsocially, morally, economically or ecologically relevant sciences that have to deal with complex research objects, deliberative instances including a plurality of perspectives are helpful for both moral and epistemic reasonsâ€ (p.197). The act of deliberation allows competing perspectives to be assessed and a consensus to be reached. Leuschner (2012) summarised the Kellert et al. (2006) notion of pluralism as involving one or more of a plurality of views over the appropriate theoretical approach to a problem; over the method(s) to apply to examining a problem; there can also be a plurality of people with different perspectives on a problem; and a plurality of people with different value concepts which, in turn, can cause different theoretical or methodological approaches. This analysis can be applied to IA (see http://dx.doi.org/10.1016/j.eiar.2017.10.006 Received 13 July 2017; Received in revised form 5 September 2017; Accepted 4 October 2017 âŽ Corresponding author at: Ben Cave Associates, United Kingdom. E-mail addresses: alan.bond@uea.ac.uk (A. Bond), francois.retief@nwu.ac.za (F. Retief), ben.cave@bcahealth.co.uk (B. Cave), mofun@statoil.com (M. Fundingsland), peter.duinker@dal.ca (P.N. Duinker), rverheem@eia.nl (R. Verheem), lex.brown@griffith.edu.au (A.L. Brown). Environmental Impact Assessment Review 68 (2018) 49â€“58 0195-9255/ Â© 2017 Elsevier Inc. All rights reserved. MARK Section 2) in the way that IA involves the application of science to political decision-making and is thus relevant, â€˜socially, morally, economically or ecologicallyâ€™; in the way that IA deals with complex research objects, namely the potential effects of a policy, plan, programme or project; and to the way that there is a plurality of views about what IA is expected to deliver to different stakeholders (Glasson et al., 1997; Morrison-Saunders et al., 2001; Bond and MorrisonSaunders, 2011). Fuller (1999) highlighted the different expectations of proponents, the public and decision-makers in relation to the EIA process. This analysis can also be applied to the way that quality is understood in IA as whatever the desired decision outcome for a particular stakeholder, the IA is seen as being one of the determinants of that decision and therefore the quality expectations underpin what the various parties see as being a legitimate decision (Owens et al., 2004). While there is a plurality of views concerning quality in IA the role that IA plays in underpinning policy decisions, not to mention commercial pressures, means there is a need to manage, and to control, quality in IA and to define and to measure it. Thus, understandings of quality matter as they dictate practice and the changes made to improve practice. This underpins the need for a conceptualisation of quality in IA, so that it is clear how quality can be interpreted, and which dimensions of quality are actually tested and the subject of quality improvement interventions, and which are not. We recognise that taking an approach to conceptualise quality in IA by drawing solely on IA literature has the potential to reproduce any existing biases (i.e. focussing on some understandings of quality at the expense of others), which would be an inappropriate way to frame quality. In this paper, we will therefore examine how quality is understood in other fields and explore the applicability of these dimensions to IA. Our first aim is therefore to contribute to a conceptualisation of quality in IA that transcends any potential narrowness in the impact assessment field. We are sensitive to the tendency for the terms quality and effectiveness both to be used interchangeably in the IA field. Whilst some authors conflate the terms, many authors have dealt with quality and effectiveness as distinct and exclusive concepts, an understanding which has also provided the basis for criteria and empirical research (for example, Retief, 2007; Lyhne et al., 2015). Further weight is added to the view that quality and effectiveness are distinct concepts by various calls for research on the correlation between the two concepts (Sadler, 1996; Thissen, 2000; Owens et al., 2004; Retief, 2010). Our second aim is therefore to clarify the relationship between quality and effectiveness in IA. We consider the plural nature of quality in Section 2 and present evidence for differing perspectives of quality in IA. In Section 3 we introduce the methodology through which we contribute both to conceptualising IA quality, and to examining the overlap with IA effectiveness. We unpick the meaning of quality in Section 4, whereby a series of dimensions of quality drawn from fields outside IA are identified (Section 4.1). A synthesis of these dimensions is undertaken to produce a single framing of quality based on three fields of research (Section 4.2). Section 4.3 examines the relationship between these dimensions of quality and some recognised understandings of effectiveness in IA. In Section 5 we examine the extent to which the dimensions are already considered in IA practice and reflected in IA literature. This examination identifies the extent to which the dimensions are already considered in IA practice. Finally, we conclude in Section 6 on what this contribution to a conceptualisation of quality in IA might mean for future research and practice and how it can be used to clarify the boundaries for research. 2. Quality and plurality in IA In terms of relevant theory, pluralism is reflected in the diversity of interpretations of quality that exist in the IA literature, and it is acknowledged that the â€œtheoretical indeterminacy is likely to remain a key feature of IA for the foreseeable futureâ€ (Cashmore and Kornov, 2013, p.28). A number of authors have made significant contributions to IA theory (for example, Lawrence, 1997; Bartlett and Kurian, 1999; Cashmore, 2004; Richardson, 2005; Fischer, 2007; Weston, 2010; Lobos and Partidario, 2014) which together reflect the plurality of theories that exist in relation to forms of IA. We take, as an example, two models drawn from Bartlett and Kurian (1999), namely the information processing model and the institutionalist model. The information processing model reflects positivist theory, or rationalism, whereby better information leads to better decision-making. Positivist theory is regarded as underpinning the derivation of the world's first EIA legislation â€“ the US National Environmental Policy Act in 1969, albeit the limitations of that theory are increasingly recognised (Weston, 2000). The institutionalist model aims at explaining the difference between the formal process and its practical implementation within institutions (Larsen et al., 2012). In fields like HIA where legal mandates are rare, institutionalisation has been of particular interest as a means of facilitating practice (see, for example, Wismar et al., 2006; Morgan, 2008; Harris and Haigh, 2015). Nykvist and Nilsson (2009) argued that institutional strengthening was more important than process improvement if IA was to deliver the sustainable outcomes sought. The fact that pluralism can be observed in the variety of methods to apply is reflected within theories. For example, in the context of positivist theory, the quality of the information underpinning and presented in the environment",2018,
Performance analysis of flexible intelligent hand prosthesis,"The study of flexible intelligent hand prosthesis has important practical significance for handicapped people. Aiming at the grasping force control of flexible hand prosthesis, this paper draws lessons from the anatomical structure design of human hand, and proposes a fingertip grasping force control method based on linear tension feedback. The control strategy can realize the stable control of fingertip grasping force. The static mechanical model of finger is established, and the mathematical relationship of fingertip contact force calculation in static state is obtained. Then a friction compensation method is proposed. The experimental results show that the fitting value of the friction moment of the lasso matches well with the test value, and the error after friction compensation is obviously reduced.",2019,
Size matters: network inference tackles the genome scale,"The growing importance of microarray data challenges biologists, and especially the systems biology community, to come up with genome-scale analysis methods that can convert the large quantity of available high-throughput data into high-quality systems-level insights. One area of systems-level analysis that has received considerable attention in recent years is that of inferring molecular-level regulation, with frequent focus on transcriptional regulatory networks (Kholodenko et al, 1997; Tavazoie et al, 1999; Gardner et al, 2003; Segal et al, 2003; Beer and Tavazoie, 2004; Yu et al, 2004; di Bernardo et al, 2005; Gardner and Faith, 2005; Woolf et al, 2005; Margolin et al, 2006; Faith et al, 2007). As microarrays provide a tool for measuring transcript levels of the whole genome, recent interest has shifted to inferring networks on a genome scale. The less-studied organisms are a natural starting point for such mapping, as it is for these organisms that the rapid, genome-scale identification of regulatory structure is most needed. 
 
In a recent study, Bonneau et al (2006) apply the Inferelator, their elegant new algorithm, for inferring gene networks, to precisely such a little-studied but important organism. Specifically, the authors focus on Halobacterium NRC-I, a model archaeon (DasSarma et al, 2006), to show that, at least for a small genome, it is possible to determine a sizeable portion of the transcriptional regulatory network from microarrays without much prior knowledge. This choice of an organism has two practical advantages. First, the salt-loving NRC-I is one of a handful of Halobacteria for which transformation techniques have been well studied, allowing in vivo validation of network predictions. Second, NRC-I's genome is relatively small and thus, its regulation ought to be comparatively easy to reconstruct. Small genome or not, putting high-throughput profiling technologies to work on the genome scale requires a confluence of robust algorithms, biologically plausible simplifying assumptions, and a robust verification strategy. The work of Bonneau et al (2006) is a good example, using multiple tools in the bioinformatics toolbox to build a credible blueprint of a transcriptional-regulatory network involving thousands of genes and more than 100 transcription factors. 
 
In order to appreciate the need for a well-structured approach to regulatory mapping, consider the mathematical and biological scope of this cross-disciplinary problem. The tiny archaeon Halobacterium NRC-I contains about 2400 genes. For each one of these, the goal is to understand the transcriptional regulatory apparatusâ€”that is about 2400 question marks, each with thousands of possible answers in the form of a set of transcriptional regulators. Put that against a typical compendium size of several hundred chips for a given organism, and you get what is known as a â€˜small n, large p' problem, where the number of possible parameters (regulators), p, dwarfs the number of data points (microarrays), n, available to define them. This problem gets considerably worse for complex organisms, where a larger number of available microarrays are more than offset by the vast complexity of large genomes, alternate splice variants, and multiple layers of regulation. For network inference algorithms, â€˜small n, large p' means dearth of data and very high computational demands. 
 
As if this computational complexity were not bad enough, there is the inherent high dimensionality in the biological realm. Regulation happens in the domains of mRNA, proteins, metabolites, kinases, acetylases, and so on, and through a variety of pleiotropic perturbations and influences, such as salinity, temperature, and cell-wall permeability. As the best high-throughput data capture only mRNA, one must make simplifying assumptions and skip many important parameters. Bonneau and colleagues' best simplifying assumption is to focus on predicting the targets of transcription factors in the network, along with some key environmental influences. When only transcription factors are allowed to regulate other genes, the â€˜p' in the â€˜small n, large p' problem is no longer so big. In fact, at 120, it is smaller than the number of chips (268) used in this study. 
 
To further constrain the network learning problem, the Inferelator performs a pre-processing step of bi-clusteringâ€”organizing experimental data by both genes and conditions. This algorithm, the cMonkey (Reiss et al, 2006), allows further reduction of dimensionality by collapsing genes into conditionally coexpressed modules. cMonkey identified 300 such bi-clusters, and 159 individual genes that could not be grouped, a nearly six-fold reduction in dimensionality. Crucially, as the composition of the culture medium used for the microarray-profiled experiments is known, each bi-cluster's grouping of genes by experimental condition suggests plausible metabolic or environmental effectors of regulation. The authors exploit this benefit of their approach in one of their verifying experiments. Bi-clustering, therefore, serves two ends: it limits the number of genes, and thus variables to reconstruct, to fewer than 500 (including only 80 TFs and metabolites), and places each predicted regulatory interaction into an experiment-specific context. 
 
The problem now becomes mathematically well-posed, and the authors solve it using LASSO regression, a sparse regression method designed just for such computationally difficult problems (Tibshirani, 1996). LASSO works by selecting a small set of the most likely regulators of a given gene, and simultaneously determines a quantitative influence function relating regulator expression to target expression (Figure 1). In addition, the authors extend the LASSO algorithm beyond its typical linear domain by including piecewise and nonlinear terms in the regression to model saturation effects and pairwise combinatorial regulation. With this approach, the authors construct a model of transcription regulation in Halobacterium that matches 80 transcription factors to 500 predicted gene targets and captures the putative metabolic controllers of these pathways. This is an impressive result, both in size and regulatory complexity, particularly in light of the relatively modest size of the experimental data set (i.e., 268 microarrays). Moreover, this represents a dramatic leap in our understanding of this little-studied organism. 
 
 
 
Figure 1 
 
(A) Schematic diagram of a hypothetical bacterial operon, represented by a single gene Y, which is regulated by a protein X1 and a protein complex X2X3. (B) Within its dynamic range, the level of the transcript y may be modeled as a function of transcripts ... 
 
 
 
Having obtained the first-pass transcriptional blueprint, Bonneau and colleagues ask the obligatory next question: how much do we trust this network? In network inference, three broad types of verification are possible: computational verification through cross-validation, in vivo verification, and literature-driven curation. To be effective, the last approach should leverage a large data set documenting connectivity known in the literature, such as TransFac (Matys et al, 2003) or RegulonDB (Salgado et al, 2006). This type of verification not being available for Halobacterium, the authors vigorously pursue the former two, including knockout experimentation and ChIP-chip analysis, demonstrating that their network can serve as a reliable and useful blueprint of Halobacterium NRC-I's transcriptional regulation. 
 
Bonneau et al (2006) show the feasibility of mapping a genome-scale regulatory network from a modestly sized compendium of microarrays, an important success for the systems biology community. As microarray technology continues to improve and costs drop, growing databases of microarrays present an opportunity to infer ever more complex regulatory networks in both microbes and higher organisms. Abundance of data fuels the need for a network inference case study that would clearly map the boundaries of what is possible with today's network mapping algorithms. To this end, we believe that the once and future model organisms like Escherichia coli and Saccharomyces cerevisiae, buoyed by extensive bodies of literature and large databases such as RegulonDB, SGD (Christie et al, 2004), and TransFac, may represent attractive short-term targets for network inference studies. In addition to the use of curated data sets, it may be possible to seed organisms with small synthetic in vivo networks, the connectivity of which is known by design, and to measure the success of network reconstruction on the whole by success or failure to reconstruct the seed. We are aware of at least one lab doing such work (Cantone et al, 2006). Biological yardsticks in general will gain in importance, as they supplement in silico testing and usher in algorithms' transition from design to practical use, and from simple organisms to higher eukaryotes. 
 
Challenges remain, but we see the immediate future of network inference as promising and bright. Molecular biologists have long been looking for ways to generate more oomph from their microarrays. Systems biology may have some answers, and we laud Bonneau and colleagues for providing an illuminating step in that direction.",2007,Molecular Systems Biology
Recurso de protecciÃ³n: reivindicaciÃ³n histÃ³rica constitucional,"Destacados tratadista y constitucionalistas iberoamericanos entre los que podemos citar, entre otros, a Hector Fix-Zamudio, Luis Lopez Guerra, Luis Aguiar de Luque, Manuel Herrera y Lasso, Jose Luis Lazzarini, Francisco Fernandez Segado, por senalar algunos, cometen un gravisimo error historico-juridico al sostener que el Recurso de Proteccion, denominado en otros paises ""amparo"", fue creado en Mexico por Manuel Crescencio Rejon, Mariano Otero y los constituyentes de 1857 y que de alli fue a integrarse en sistemas constitucionales, como el espanol y de varios otros paises iberoamericanos.",2015,Revista de Derecho PÃºblico
êµ­ë‚´ ë“œë¼ë§ˆ ì‹œì²­ë¥  ì˜ˆì¸¡ ë° ì˜í–¥ìš”ì¸ ë¶„ì„,"ìµœê·¼ ìƒì—…ë°©ì†¡ì˜ ë„ìž…ê³¼ ì±„ë„ì˜ ë‹¤ì–‘í™”ë¡œ êµ­ë‚´ ë“œë¼ë§ˆ ì‹œìž¥ì˜ ì‹œì²­ë¥  ê²½ìŸì´ ì‹¬í™”ë˜ì—ˆë‹¤. ì´ì— ì‹œì²­ë¥ ì— ëŒ€í•œ ì‹¤ì¦ì ì¸ ì—°êµ¬ì˜ í•„ìš”ì„±ì´ ëŒ€ë‘ë˜ê³  ìžˆë‹¤. ë³¸ ì—°êµ¬ì˜ ëª©ì ì€ ë‹¤ì–‘í•œ ë°ì´í„°ë§ˆì´ë‹ ê¸°ë²•ì„ ì´ìš©í•˜ì—¬ ìµœê·¼ ë°©ì†¡ì‹œìž¥ì˜ ë³€í™”ë¥¼ ê³ ë ¤í•œ êµ­ë‚´ ë“œë¼ë§ˆ ì‹œì²­ë¥  ì˜ˆì¸¡ ëª¨í˜•ì„ ì œì‹œí•˜ê³  ì‹œì²­ë¥ ì— ìœ ì˜í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë³€ìˆ˜ë“¤ì„ ë„ì¶œí•˜ëŠ” ë° ìžˆë‹¤. ëª¨í˜• ì í•© ì‹œ ì„ í˜•íšŒê·€ëª¨í˜•, LASSO íšŒê·€ëª¨í˜•, ëžœë¤ í¬ë ˆìŠ¤íŠ¸, ê·¸ëž˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ë“±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ë¶„ì„ ë°©ë²•ì„ ê³ ë ¤í•˜ì˜€ë‹¤. ì´ ë•Œ ë“œë¼ë§ˆ ë°©ì˜ ì „ ì•Œ ìˆ˜ ìžˆëŠ” ê¸°ë³¸ ì •ë³´ë“¤ë§Œì„ ê³ ë ¤í•˜ì—¬ ë“œë¼ë§ˆì˜ ì´ˆë°˜ ì‹œì²­ë¥ ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨í˜•ì„ ì í•©í•œ í›„ ë°©ì˜ ì´ˆê¸°ì˜ ì—¬ë¡ ì„ ê³ ë ¤í•œ í‰ê·  ì‹œì²­ë¥  ì˜ˆì¸¡ ëª¨í˜•ì„ ì í•©í•˜ì˜€ë‹¤. ê·¸ ê²°ê³¼ ë“œë¼ë§ˆ ì´ˆë°˜ ì‹œì²­ë¥ ì€ ë°©ì†¡ì‚¬, ë°©ì†¡ì‹œê°„, ë“œë¼ë§ˆ ë°©ì˜ ì´ì „ ë“œë¼ë§ˆ ê´€ë ¨ ê²€ìƒ‰ëŸ‰ ë“± ë“œë¼ë§ˆì˜ êµ¬ì¡°ì  ìš”ì¸ê³¼ ìž„ì†Œë¬¸ íš¨ê³¼ì˜ ì˜í–¥ì„ í¬ê²Œ ë°›ìœ¼ë©°, í‰ê· ì‹œì²­ë¥ ì€ ë“œë¼ë§ˆ ì´ˆë°˜ ì‹œì²­ë¥ ê³¼ ë“œë¼ë§ˆ ë°©ì˜ ì´í›„ ë“œë¼ë§ˆ ê´€ë ¨ ê²€ìƒ‰ëŸ‰ ë“± ë°©ì˜ ì´ˆê¸°ì˜ ì—¬ë¡ ì— í° ì˜í–¥ì„ ë°›ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤.",2015,
Das Edikt des Sex. Sotidius Strabo Libuscidianus und die Fasten der Statthalter Galatiens in augusteischer und tiberischer Zeit,"Sex. Sotidius Strabo is attested as legatus Ti. Caesaris Augusti pro pr(aetore) in an edict to the provincials, which has been transmitted in a bilingual inscription from Sagalassos (AE 1976, no. 653). Despite its reference to the current emperor and his predecessor, the edict does not imply that Strabo had first been appointed by Augustus and then maintained by Tiberius. This observation leads up to a thorough revision of the fasti of early Galatia. Most importantly, T. Helvius Basila is re-established as the last appointee of Augustus.",2009,
