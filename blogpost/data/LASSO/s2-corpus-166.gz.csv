title,abstract,year,journal
Wavelet Reconstruction of Nonuniformly Sampled Signals,"For the reconstruction of a nonuniformly sampled signal based on its noisy observations, we propose a level dependent l1 penalized wavelet reconstruction method. The LARS/Lasso algorithm is applied to solve the Lasso problem. The data adaptive choice of the regularization parameters is based on the AIC and the degrees of freedom is estimated by the number of nonzero elements in the Lasso solution. Simulation results conducted on some commonly used 1_D test signals illustrate that the proposed method possesses good empirical properties.",2009,IEEE Signal Processing Letters
å¤šä»»åŠ¡Sparse Group Lassoç‰¹å¾æå–ä¸Žæ”¯æŒå‘é‡æœºå›žå½’åœ¨æ’æ˜Ÿå¤§æ°”ç‰©ç†å‚é‡ä¼°è®¡ä¸­çš„åº”ç”¨,"The multi-task learning puts the multiple tasks together to analyse and calculate for discovering the correlation between them, which can improve the accuracy of analysis results. This kind of methods have been widely studied in machine learning, pattern recognition, computer vision, and other related fields. This paper investigates the application of multi-task learning in estimating the effective temperature ( T eff ), surface gravity (lg g ), and chemical abundance ([Fe/H]). Firstly, the spectral characteristics of the three atmospheric physical parameters are extracted by using the multi-task Sparse Group Lasso algorithm, and then the support vector machine is used to estimate the atmospheric physical parameters. The proposed scheme is evaluated on both Sloan stellar spectra and theoretical spectra computed from Kurucz's New Opacity Distribution Function (NEWODF) model. The mean absolute errors (MAEs) on the Sloan spectra are:0.0064 for lg ( T eff /K), 0.1622 for lg( g /(cmÂ·s -2 )), and 0.1221 dex for[Fe/H]; The MAEs on synthetic spectra are 0.0006 for lg ( T eff /K), 0.0098 for lg( g /(cmÂ·s -2 )), and 0.0082 dex for[Fe/H]. Experimental results show that the proposed scheme is excellent for atmospheric parameter estimation.",2016,
Alaskan flatfishes on the German market: part 1: identification by DNA and protein analytical methods,"North Pacific flatfishes are gaining increased popularity on the German market. Isoelectric focusing of sarcoplasmic proteins and PCR-based DNA analysis were applied to identify fillets of nine Alaskan Flatfish species: Artheresthes stomias (Arrow-tooth flounder), Limanda aspera (Yellowfin sole), Isopsetta isolepis (Butter sole), Lepidopsetta bilineata (Southern rock sole), Lepidopsetta polyxystra (Northern rock sole), Hippoglossus stenolepis (Pacific halibut), Hippoglossoides elassodon (Flathead sole), Platichthys stellatus (Starry flounder), and Glyptocephalus zachirus (Rex sole). Characteristic protein patterns were obtained for raw fillets of several species. Reactivity of flatfish DNA against five pairs of primers was tested, amplifying segments of the mitochondrial cytochrome b, cytochrome oxidase subunit I, 16S rRNA gene, as well as the nuclear parvalbumin gene. Amplicons of the cytochrome b gene were sequenced and used for single-strand conformation polymorphism analysis. The survey of deep-frozen commercial yellowfin sole fillets resulted in the detection of 17% of the fillets being mislabelled; Northern rock sole, butter sole and flathead sole had been used as substitutes.",2011,European Food Research and Technology
Effective Screening and Joint Modeling for High-Throughput Genomic Data Analysis.,"RHYNE, JACOB DAVIS. Effective Screening and Joint Modeling for High-Throughput Genomic Data Analysis. (Under the direction of Dr. X. Jessie Jeng). When analyzing genetic data, many current modeling methods are computationally infeasible, due to the size of the data. This dissertation explores two possible solutions to this problem: screening to reduce the number of predictors or making modeling methods more computationally efficient. The first chapter introduces key background information and gives an overview of key developments in relevant statistical methodology. The second chapter presents a screening methodâ€“where SNP ranking and screening is based on the Higher Criticism (HC) statisticâ€“to be performed prior to joint modeling of the expression of genes and SNPs. It is shown that the HC-based SNP screening can greatly reduce the computational burden of joint modeling and improve the power for eQTL mapping. The third chapter considers a well-known joint modeling method, LORS, which is computationally infeasible for large data. An alternative method is proposed to solve the LORS optimization problem with less computational time required. The proposed method and LORS are applied to data from the International HapMap Project to illustrate the performance of each. The fourth chapter presents a new joint modeling procedure which extends the debiased lasso (DLasso) to a multivariate response. This method addresses a weakness of LORS in that statistical inference can be performed after joint modeling. It is shown that the proposed procedure can effectively control false discoveries and identify a large proportion of true signals. Â© Copyright 2019 by Jacob Davis Rhyne",2019,
Liquid electrolyte informatics using an exhaustive search with linear regression.,"Exploring new liquid electrolyte materials is a fundamental target for developing new high-performance lithium-ion batteries. In contrast to solid materials, disordered liquid solution properties have been less studied by data-driven information techniques. Here, we examined the estimation accuracy and efficiency of three information techniques, multiple linear regression (MLR), least absolute shrinkage and selection operator (LASSO), and exhaustive search with linear regression (ES-LiR), by using coordination energy and melting point as test liquid properties. We then confirmed that ES-LiR gives the most accurate estimation among the techniques. We also found that ES-LiR can provide the relationship between the ""prediction accuracy"" and ""calculation cost"" of the properties via a weight diagram of descriptors. This technique makes it possible to choose the balance of the ""accuracy"" and ""cost"" when the search of a huge amount of new materials was carried out.",2018,Physical chemistry chemical physics : PCCP
Reconstruction of the Facial Nerve in Pigs with Facial Nerve Allografts Wrapped in a Fibrin Scaffold Containing Fibroblasts Transduced with Adenovirus Encoding VEGF 156,"*Corresponding author: JosÃ© M Lasso, Plastic Surgery, Hospital General Universitario Gregorio MaraÃ±Ã³n, Ãrea 3400, C/ Dr Esquerdo 46, 28007 Madrid, Spain, E-mail: josemaria.lasso@salud.madrid.org Citation: Lasso JM (2015) Reconstruction of the Facial Nerve in Pigs with Facial Nerve Allografts Wrapped in A Fibrin Scaffold Containing Fibroblasts Transduced with Adenovirus Encoding VEGF 156. Enliven: Surg Transplant 1(1): 009. Copyright: @ 2015 Dr. Jose M Lasso. This is an Open Access article published and distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution and reproduction in any medium, provided the original author and source are credited. Received Date: 9th June 2015 Accepted Date: 22nd June 2015 Published Date: 27th June 2015 Research Article Enliven: Surgery and Transplantation ISSN: 2379-5719",2015,
Synthesis for Polynomial Lasso Programs,"We present a method for the synthesis of polynomial lasso programs. These programs consist of a program stem, a set of transitions, and an exit condition, all in the form of algebraic assertions conjunctions of polynomial equalities. Central to this approach is the discovery of non-linear algebraic loop invariants. We extend Sankaranarayanan, Sipma, and Manna's template-based approach and prove a completeness criterion. We perform program synthesis by generating a constraint whose solution is a synthesized program together with a loop invariant that proves the program's correctness. This constraint is non-linear and is passed to an SMT solver. Moreover, we can enforce the termination of the synthesized program with the support of test cases.",2014,
Variability in the trophic role of coral reef fish larvae in the oceanic plankton,"The transport of larval coral reef fishes to juvenile habitat inherently requires that they survive the planktonic journey; however, the processes governing survival â€” particularly those related to feeding â€” are not well known. Monthly sampling across the Straits of Florida allowed for analyses of the diets and diet variability of several co-occurring taxa of coral reef fish larvae from the families Serranidae, Lutjanidae, Mullidae, Pomacentridae, Labridae, Scaridae and Acanthuridae. The proportions of larvae with food present in the gut were high (0.94 to 1.0) for all taxa except scarids (0.04), and diets were generally narrow and predator-specific. Serranus spp. (Serranidae) diets changed little with growth and were composed almost entirely of calanoid copepods, while the labrids Thalassoma bifasciatum and Xyrichtys spp. consumed harpacticoid and cyclopoid (Farranula and Oncaea) copepods almost exclusively throughout ontogeny. Lutjanine and acanthurid larvae relied increasingly upon appendicularians with growth, and mullids exhibited an ontogenetic shift from nauplii to calanoid copepodites and appendicularians. Cluster analysis examining diet similar- ity among taxa yielded clear groupings: small acanthurids, labrids, appendicularian-feeders, and a fourth group consisting of subgroups of larvae with calanoid and mixed diets. Within larval taxa, canonical correspondence analysis indicated how diet varied with several environmental and larva- specific variables. The trophic niche breadth of 4 taxa decreased significantly with growth, while other taxa exhibited no significant change. These results highlight distinct differences between high- and low-latitude regions, most notably the taxon-specific trophic roles and the apparent niche parti- tioning of larval fishes within the diverse planktonic food webs of lower latitudes.",2009,Marine Ecology Progress Series
L'experience lasso,"L'experience lasso: laser synchronisation from stationary orbit est une procedure de transfert de temps entre des horloges au sol utilisant un lien laser avec un oscillateur ultra-stable embarque a bord d'un satellite geostationnaire. L'objet de cette these est de faire un bilan complet de cette experience, de sa proposition aux experiences futures qui en decoulent, en passant par l'analyse detaillee des observations. Cette experience a pour but de montrer la faisabilite d'un transfert de temps intercontinental a mieux que la nanoseconde (10#-#9s). Un tel transfert de temps a pu etre realise grace a l'introduction de nouveaux concepts: le suivi de l'horloge du satellite de facon independante a partir de chaque station, et l'utilisation de toute l'information disponible dans les donnees. Durant 1992 et 1993, deux stations ont participe a cette experience: le mlrs (texas) et le cerga (grasse). Le traitement et l'analyse de ces donnees ont montre que lasso permet d'etudier le comportement d'une horloge embarquee sur un satellite avec une precision meilleure que 100 ps (10#-#1#0s), et que la precision du transfert de temps via lasso est meilleure que 100 picosecondes. Il y a donc un gain d'un facteur 5 a 10 par rapport aux techniques de transfert de temps actuelles (gps, two-way). L'exactitude, actuellement de l'ordre de 1. 5 ns, pourra etre amelioree par un meilleur etalonnage des stations. Pour l'avenir, une experience de type lasso est envisageable avec une precision d'une dizaine de picosecondes, ce qui presente un grand interet dans le domaine de la metrologie du temps pour l'etude d'horloges ultra-stables en orbite, l'etalonnage de techniques de transfert de temps. Cela ouvre egalement la voie a des experiences de physique fondamentale dans le systeme solaire",1994,
The REMEDIA-Life project and the cultivation of macroalgae as bioremediators: exploitation of their biomass for biotechnological purposes,"1Istituto di Ricerca sulle Acqueâ€“ S.S. Talassografico di Taranto â€“ CNR, Via Roma, 374123 Taranto (Italy) 2 DiSTeBA, UniversitÃ  del Salento, Via Prov.le Lecce-Monteroni â€“ 73100 Lecce (Italy) 3Istituto di Scienze delle Produzioni Alimentari, U.O.S. di Lecce, via Prov.le Lecce-Monteroni, Lecce, Italy;",2019,
High-dimensional regression and classification under a class of convex loss functions,"The weighted L1 penalty was used to revise the traditional Lasso in the linear regression model under quadratic loss. We make use of this penalty to investigate the highdimensional regression and classification under a wide class of convex loss functions. We show that for the dimension growing nearly exponentially with the sample size, the penalized estimator possesses the oracle property for suitable weights, and its induced classifier is shown to be consistent to the optimal Bayes rule. Moreover, we propose two methods, called componentwise regression (CR) and penalized componentwise regression (PCR), for estimating weights. Both theories and simulation studies provide supporting evidence for the advantage of PCR over CR in high-dimensional regression and classification. The effectiveness of the proposed method is illustrated using real data sets.",2013,Statistics and Its Interface
A note on adaptive Lp regularization,"In this paper, the adaptive Lp regularization is proposed for parameter estimation and variable selection. In particular, we focus on the (0 <; p <; 1) case when the adaptive Lp regularizer has a nonconvex penalty. Besides some traditional properties for penalized linear regression model, such as unbiasedness and sparsity, we have shown that the adaptive Lp regularization also enjoy the oracle property. A modified iterative algorithm is utilized to solve the adaptive Lp. By comparing with ordinary least square, adaptive lasso and Lp, the numerical results show that the adaptive Lp is more accurate and sparse.",2012,The 2012 International Joint Conference on Neural Networks (IJCNN)
Competitive interactions and the availability of sleeping sites for a diurnal coral reef fish,"A field study was made to test whether the population size of a diurnal reef fish, the wrasse Thalassoma bifasciatum (Bloch), was limited by inter- or intraspecific competition for sleeping shelter. T. bifasciatum is often attacked at dusk by two small territorial damselfishes, Eupomacentrus dorsopunicans (Poey) and E. planifrons (Cuvier). Although these three species sleep in the same general habitats, there are qualitative differences in the types of holes they use and how they use them. Wrasse holes are usually in these damselfishes' territories, but damselfish attacks do not prevent wrasses entering holes. Wrasses infrequently defend their holes intraspecifically. They regularly change their holes, with little intra- or interspecific aggressive interaction. When its hole is removed, a wrasse is late in retiring but finds a hole near its old one with little aggressive interaction, and does not have a higher mortality rate. Empty wrasse holes are rarely refilled, and then only by conspecifics. Wrasses added to reefs find unoccupied holes and do not usurp other fishes' holes. Damselfish defend their eggs and food against the wrasse, but not their sleeping shelter, nor living space per se. Sleeping sites are not limiting the wrasse, but are present in a surplus. Intraspecific hole defense by a wrasse prevents a delay in its retiring that would increase the risk of crepuscular predation on it.",1979,Journal of Experimental Marine Biology and Ecology
Use of Reclaimed Mine Land by Disturbance-oriented Avian Species: Implications for Conservation and Management 1,"Human disturbed landscapes such as those in early stages of mine reclamation provide habitat for disturbance-oriented species. Disturbance- oriented birds that are uncommon or absent from the surrounding region may be concentrated at large-scale human disturbed sites such as surface mines. Implications for conservation and management of such species are important considerations, given the possibility one or more of those species may be federally protected. Recent expansion of the breeding range of Interior Least Terns (Sterna antillarum athalassos), a federally endangered species, in Texas has many implications for management on private lands. Interior Least Terns first nested on reclaimed mine spoil at Big Brown Mine in East-Central Texas in 1997. Management objectives for reclamation planning were subsequently established to provide suitable nesting and foraging habitat for terns while seeking to reduce the risk of interference with mining activities at Big Brown Mine. Since 1997, an average of 29 nests per year have occurred on artificial sites created for tern nesting, with average annual nest success 49%, hatching success 47%, and fledging success 46%. Average annual reproductive success (fledglings per female) is 0.40. We discuss colonization of reclaimed mine land by disturbance- oriented avian species and present research on the nesting and foraging ecology of Interior Least Terns in Texas as a case study. Implications for conservation and management of disturbance-oriented birds in reclamation are discussed.",2002,Journal of the American Society of Mining and Reclamation
Evaluating the HER-2 status of breast cancer using mammography radiomics features.,"PURPOSE
The aim of our study was to evaluate the HER-2 status in breast cancer patients using mammography (MG) radiomics features.


METHODS
A total of 306 Chinese female patients with invasive ductal carcinoma of no special type (IDC-NST) enrolled from January 2013 to July 2018 were divided into a training set (nâ€¯=â€¯244) and a testing set (nâ€¯=â€¯62). One hundred and eighty-six radiomics features were extracted from digital MG images based on the training set. The least absolute shrinkage and selection operator (LASSO) method was used to select the optimal predictive features for HER-2 status from the training set. Both support vector machine (SVM) and logistic regression models were employed based on the selected features. The area under the receiver operating characteristic (ROC) curves (AUCs) of the training set and testing set were used to evaluate the predictive performance of the models.


RESULTS
Compared with the SVM model, the performance of the logistic regression model using a combination of cranial caudal (CC) and mediolateral oblique (MLO) MG views was optimal. In the training set, the sensitivity, specificity, accuracy and area under the curve (AUC) values of the logistic regression model for evaluating HER-2 status based on quantitative radiomics features were 87.29%, 58.73%, 80.00% and 0.846 (95% confidence interval (CI), 0.800-0.887), respectively, and in the testing set, the values were 73.91%, 68.75%, 77.00% and 0.787 (95% CI, 0.673-0.885), respectively.


CONCLUSIONS
Radiomics features could be an efficient tool for the preoperative evaluation of HER-2 status in patients with breast cancer.",2019,European journal of radiology
"[Machine learning for predictive analyses in health: an example of an application to predict death in the elderly in SÃ£o Paulo, Brazil].","This study aims to present the stages related to the use of machine learning algorithms for predictive analyses in health. An application was performed in a database of elderly residents in the city of SÃ£o Paulo, Brazil, who participated in the Health, Well-Being, and Aging Study (SABE) (n = 2,808). The outcome variable was the occurrence of death within five years of the elder's entry into the study (n = 423), and the predictors were 37 variables related to the elder's demographic, socioeconomic, and health profile. The application was organized according to the following stages: division of data in training (70%) and testing (30%), pre-processing of the predictors, learning, and assessment of the models. The learning stage used 5 algorithms to adjust the models: logistic regression with and without penalization, neural networks, gradient boosted trees, and random forest. The algorithms' hyperparameters were optimized by 10-fold cross-validation to select those corresponding to the best models. For each algorithm, the best model was assessed in test data via area under the ROC curve (AUC) and related measures. All the models presented AUC ROC greater than 0.70. For the three models with the highest AUC ROC (neural networks and logistic regression with LASSO penalization and without penalization, respectively), quality measures of the predicted probability were also assessed. The expectation is that with the increased availability of data and trained human capital, it will be possible to develop predictive machine learning models with the potential to help health professionals make the best decisions.",2019,Cadernos de saude publica
Variance Reduced Three Operator Splitting,"Despite the rise to fame of incremental variance-reduced methods in recent years, their use in nonsmooth optimization is still limited to few simple cases. This is due to the fact that existing methods require to evaluate the proximity operator for the nonsmooth terms, which can be a costly operation for complex penalties. In this work we introduce two variance-reduced incremental methods based on SAGA and SVRG that can efficiently take into account complex penalties which can be expressed as a sum of proximal terms. This includes penalties such as total variation, group lasso with overlap and trend filtering, to name a few. Furthermore, we also develop sparse variants of the proposed algorithms which can take advantage of sparsity in the input data. Like other incremental methods, it only requires to evaluate the gradient of a single sample per iteration, and so is ideally suited for large scale applications. We provide a convergence rate analysis for the proposed methods and show that they converge with a fixed step-size, achieving in some cases the same asymptotic rate as their full gradient variants. Empirical benchmarks on 3 different datasets illustrate the practical advantages of the proposed methods.",2018,
Editorial Board,"ASSOCIATE EDITORS Gerd Bayer, University of Erlangen, Germany Sarah Lawson Welsh, University of York St. John, UK Lucienne Loh, University of Liverpool, UK Mark Mathuray, Royal Holloway, University of London Cristina Sandru, The University of Northampton, UK Alex Tickell, The Open University, UK Fiona Tolan, Liverpool John Moores University, UK MANAGING EDITORS Melanie Murray, The University of Northampton, UK Anastasia Valassopoulos, University of Manchester, UK (Special Issues)",2014,Journal of Postcolonial Writing
"Carbon substrate utilization, antibiotic sensitivity, and numerical taxonomy of bacterial isolates from the Great Salt Plains of Oklahoma","The current work extends the phenotypic characterization of a bacterial culture collection from the Great Salt Plains of Oklahoma. This barren expanse of mud flats is typically crusted with thalassohaline salt evaporites. The initial account of the aerobic heterotrophic bacteria from the Great Salt Plains described 105 halotolerant isolates that represented 47 phylotypes. Extensive phenotypic analyses were performed on 76 isolates representing 37 unique phylotypes. The current report extends these observations for 60 of the isolates by measuring a wider set of phenotypic characteristics. Utilization patterns for 45 carbon substrates were used to assign the isolates into seven coherent phenons, along with several singletons and a group of isolates that did not grow on single carbon substrates. Most of the isolates were able to utilize nearly all of the nitrogen sources tested, with nitrate being the least utilized. Little antibiotic resistance was seen in the collection as a whole; however, certain phenons were enriched for antibiotic-resistant organisms. A total of 81 phenotypic characteristics were used to generate dendrograms. The numerical taxonomy trees essentially agreed with those generated using 16S rRNA gene sequences. The pattern of carbon substrate utilization showed substantial changes at different salinities that may have relevance to the variable salinities microbes experience at the Salt Plains over time.",2006,Archives of Microbiology
Variable Selection and Outlier Detection in Regularized Survival Models: Application to Melanoma Gene Expression Data,"The importance of gene expression data analysis for oncological diagnosis and treatment has become widely accepted in recent years. One of the main associated challenges is the development of mathematical and statistical methods for data analysis to improve prognosis and guide treatment decisions. One of the difficulties that researchers face when dealing with gene expression datasets concerns their high-dimensionality. In this context, the goal of this work is to reduce the dimensionality of gene expression data using regularization techniques such as Lasso and Elastic net, complemented with DegreeCox, a network-based regularization method for survival analysis recently proposed. Also identification of long or short-term survivors (outliers) may lead to the detection of new prognostic factors, and the Rank Product test is used to identify those observations. An example based on the The Cancer Genome Atlas (TCGA) Melanoma dataset is presented, where the covariates are patientsâ€™ gene expression. The application of data reduction techniques to the Melanoma dataset enabled the selection of relevant genes over a range of parameters evaluated, with 5 in common between elastic net regularization and DegreeCox for one of the two models further evaluated. Moreover, a long term survivor was detected as outlier by the Rank Product test, being systematically highly ranked for the martingale residuals of the models evaluated.",2018,
State-space model estimation of EEG time series for classifying active brain sources,"Electroencephalography (EEG) signals are known to be generated from the current source signals occurring inside human brains and these sources may or may not be active concurrently at a certain time. This paper aims to classify active and inactive sources from the information that can be inferred from parameters of a dynamical model that captures characteristics of EEG time series. We propose a state-space model for explaining coupled dynamics of the source and EEG signals where EEG is a linear combination of sources according to the characteristics of volume conduction. Our model has a structure that the sparsity pattern of the model output matrix can indicate the position of active and inactive sources. With this assumption, the proposed estimation method consists of two steps. Firstly, a subspace identification method is performed to estimate the dynamic matrix of the model and the mapping matrix from the state variable to EEG output. Secondly, the estimation of the output matrix in the state-space model from the mapping matrix is solved by a group lasso problem to promote a sparsity pattern. As a result, nonzero rows of the output matrix represent active source that corresponding to EEG data. We verify the performance of our method on randomly generated data sets that represent realistic human brain activities in a fair setting. An acceptable accuracy of 95 â€“ 98% is obtained with a suitable selection of a problem parameter and a thresholding process to discard small magnitudes of the output matrix.",2018,2018 11th Biomedical Engineering International Conference (BMEiCON)
BehÃ¤lter zur aufnahme eines fluids und sauggerÃ¤t mit einem derartigen behÃ¤lter,"Die Erfindung betrifft einen Behalter (10) zur Aufnahme von mittels Unterdruck in diesen eingesaugtem, insbesondere feststoffhaltigem Fluid, mit einer Einlass- und einer Auslassoffnung (17, 18) fur das Fluid und mit einer Absaugoffnung (23) zum Absaugen des Behalters (10) und einer Beluftungsoffnung (25) zum Beluften des Behalters (10), wobei der Auslassoffnung (18) eine Auslassventileinheit (20) und der Beluftungsoffnung (25) eine von einem Schwimmer (28) betatigbare Beluftungsventileinheit (26) zugeordnet ist und die beiden Ventileinheiten (20, 26) in Abhangigkeit vom Fullstand des Behalters (10) selbsttatig offnenbar und schliesbar sind. Um den Behalter derart weiterzubilden, dass er praktisch vollstandig entleert und die mechanische Belastung der Auslass- und der Beluftungsventileinheit (20, 26) reduziert werden kann, wird erfindungsgemas vorgeschlagen, dass der Schwimmer (28) in Abhangigkeit vom Fullstand des Behalters mit einer der Auftriebskraft des Schwimmers (28) entgegenwirkenden Ruckhaltekraft beaufschlagbar ist.",2006,
EEG signal analysis using sparse approximations,"Electroencephalogram (EEG) is physiological signal generated in the brain. Electroencephalography is a method to record the electrical activity of the brain in order to detect the abnormalities of the brain. However, EEG also detects the signals which are not originated from the brain called artifacts. This paper deals with the analysis and extraction of EEG signals in sparse representation using sparse algorithms Orthogonal Matching Pursuit (OMP) and LASSO. OMP is an iterative greedy algorithm which replaces optimization problem in each step of Matching Pursuit(MP), an earlier algorithm for solving sparse approximation problems by least squares minimization. LASSO is an optimization technique which involves regression analysis concepts. Sparse approximations are used in practical applications like feature extraction, Denoising, Inpainting etc.",2017,"2017 Third International Conference on Biosignals, Images and Instrumentation (ICBSII)"
A Space-Time Trellis Code Design Method for OFDM Systems,"We introduce a new design method for space-time trelliscodes (STTC's) in orthogonal frequency-division multiplexing(OFDM) systems with frequency-selective fading. First, byanalyzing the pairwise error probability (PEP), we conclude thatlarge effective length and random interleaving are twocritical principles in designing robust space-time codes (STC's)for OFDM systems. Then, based on the analogy between the proposedSTC design principles for multiple-antenna OFDM systems and thetrellis-coded modulation (TCM) code design criteria forsingle-antenna flat-fading channels, we develop a new STTC designmethod. At each trellis stage, this method converts the singleoutput code symbol of a traditional TCM code into several STTCcode symbols, which are to be simultaneously transmitted frommultiple transmitter-antennas, and hence results in a new class ofSTTC's. In this way, the effective lengths that have beenoptimized for traditional TCM codes are preserved in the resultingSTTC's; together with a random interleaver, the proposed new classof STTC's can robustly and efficiently exploit both the spatialand the frequency-selective fading diversity resources inmultiple-antenna OFDM systems. Finally, the excellent performanceof the proposed STTC's are demonstrated through computersimulations.",2003,Wireless Personal Communications
Riorganizzazioni d'impresa tra benefici immediati e differiti: il caso della Banca di Credito Cooperativo dei Comuni Cilentani,"Riorganizzazioni dâ€™impresa tra benefici immediati e differiti: il caso della Banca di Credito Cooperativo dei Comuni Cilentani (by Antonio Botti, Salvatore Angione) - ABSTRACT: Un processo di riorganizzazione sovente nasconde una serie di criticita derivanti dal verificarsi di situazioni difformi da quelle ipotizzate. Nella valutazione ex-ante del progetto spesso ci si sofferma piu sui vantaggi dellâ€™operazione, che sui rischi derivanti dalla medesima. E questo il punto di partenza del presente lavoro, che studia un caso di fusione tra quattro Casse Rurali per riflettere sulle problematiche derivanti da un processo di riorganizzazione aziendale e verificare se i vantaggi prefigurati dal piano industriale si sono realizzati ed in che lasso di tempo cio e accaduto. Il contributo parte dallâ€™individuazione delle motivazioni che hanno spinto i partecipanti alla fusione, analizzando le condizioni competitive ed enucleando gli obiettivi dellâ€™operazione. Tali obiettivi sono confrontati con le finalita che la dottrina associa a questa operazione per inquadrare la stessa da un punto di vista teorico. Il caso analizzato puo essere inquadrato in un processo di turnaround, inteso in senso ampio, infatti i partecipanti cercano di fronteggiare il declino delle performance intervenendo sulle strategie, sullâ€™organizzazione, sui processi e sulla cultura. Nel lavoro sono, quindi, discussi i vantaggi collegati alla generazione di sinergie ed alla disponibilita di specifiche risorse e si evidenzia come tali vantaggi possono realizzarsi solo al raggiungimento di una certa dimensione minima di massa critica, la quale assume pero una duplice dimensione. Infatti, la massa critica presenta una dimensione quantitativa, rappresentata dalla semÂ¬plice sommatoria di fattori patrimoniali, ed una qualitativa, che si manifesta nelle problematiche derivanti dallâ€™integrazione di risorse diverse. Nel caso analizzato il diverso estrinsecarsi della massa critica e chiaramente testimoniato dal tempo entro il quale i benefici attesi si sono realizzati e dalla loro dimensione. Infatti, i benefici connessi a dimensioni strutturali della massa critica si sono realizzati in un tempo relativamente breve, come evidenziano alcuni indicatori gestionali. I benefici non correlati alla dimensione strutturale si sono concretizzati in un tempo piu lungo, in quanto hanno richiesto ulteriori azioni funzionali allâ€™integrazione delle diverse riÂ¬sorse. Lâ€™analisi evidenzia come in un processo di integrazione non ci si puo soffermare solamente alla valutazione dellâ€™aspetto dimensionale, ma altre variabili, come lâ€™organizzazione, la cultura, la comunicazione, assumono unâ€™elevata criticita nel determinare le probabilita di successo dellâ€™operazione.",2007,
Estimasi Rapat Spektral Daya Berbasiskan Compressive Sampling,"This paper focus on spectrum sensing based on power spectral density (PSD) reconstruction from sub-Nyquistrate samples. In the existing works on PSD reconstruction from sub-Nyquist-rate samples, the resulting system of linear equations (SLE) is generally overdetermined, which allows the PSD reconstruction using least-squares (LS). Note that there is a lower bound for the achievable sampling rate ensuring that the resulting SLE is overdetermined. This paper aims for a further sampling rate reduction, which results in an underdetermined SLE. However, when the resulting SLE is underdetermined, the LS method cannot be used to reconstruct PSD and additional constraints are required. Under this circumstance, a sparsity assumption (which is applicable for some applications) can be applied on the PSD. The use of the orthogonal matching pursuit (OMP) and the least absolute shrinkage and selection operator (LASSO) algorithms to reconstruct the PSD for the case of underdetermined SLE is examined. The simulation study shows that if an appropriate regularization parameter is used, the quality of the PSD reconstructed using LASSO is only slightly below the one produced using Nyquist-rate sampling. From the detection point of view, the PSD reconstructed using LASSO can accurately locate the occupied frequency band when the user signal power is sufficiently high compared to the noise power. Meanwhile, OMP can be used only in the noiseless scenario. These results indicate that the sampling rate alleviation up to a very low rate is possible while maintaining the quality of the spectrum sensing results at the acceptable level.",2018,
Development and validation of a brain maturation index using longitudinal neuroanatomical scans,"BACKGROUND
Major psychiatric disorders are increasingly being conceptualized as 'neurodevelopmental', because they are associated with aberrant brain maturation. Several studies have hypothesized that a brain maturation index integrating patterns of neuroanatomical measurements may reliably identify individual subjects deviating from a normative neurodevelopmental trajectory. However, while recent studies have shown great promise in developing accurate brain maturation indices using neuroimaging data and multivariate machine learning techniques, this approach has not been validated using a large sample of longitudinal data from children and adolescents.


METHODS
T1-weighted scans from 303 healthy subjects aged 4.88 to 18.35years were acquired from the National Institute of Health (NIH) pediatric repository (http://www.pediatricmri.nih.gov). Out of the 303 subjects, 115 subjects were re-scanned after 2years. The least absolute shrinkage and selection operator algorithm (LASSO) was 'trained' to integrate neuroanatomical changes across chronological age and predict each individual's brain maturity. The resulting brain maturation index was developed using first-visit scans only, and was validated using second-visit scans.


RESULTS
We report a high correlation between the first-visit chronological age and brain maturation index (r=0.82, mean absolute error or MAE=1.69years), and a high correlation between the second-visit chronological age and brain maturation index (r=0.83, MAE=1.71years). The brain maturation index captured neuroanatomical volume changes between the first and second visits with an MAE of 0.27years.


CONCLUSIONS
The brain maturation index developed in this study accurately predicted individual subjects' brain maturation longitudinally. Due to its strong clinical potentials in identifying individuals with an abnormal brain maturation trajectory, the brain maturation index may allow timely clinical interventions for individuals at risk for psychiatric disorders.",2015,NeuroImage
Chapter 4 Feature Selection in Feature Network Models : Finding Predictive Subsets of Features with the Positive Lasso 1,"A set of features is the basis for the network representation of proximity data achieved by Feature Network Models (FNM). Features are binary variables that characterize the objects in an experiment, with some measure of proximity as response variable. Sometimes features are provided by theory and play an important role in the construction of the experimental conditions. In some research settings, the features are not known a priori. This paper shows how to generate features in this situation and how to select an adequate subset of features that takes into account a good compromise between model fit and model complexity, using a new version of Least Angle Regression that restricts coefficients to be nonnegative, called the Positive Lasso. It will be shown that features can be generated efficiently with Gray codes that are naturally linked to the FNM. The model selection strategy makes use of the fact that FNM can be considered as a univariate multiple regression model. A simulation study shows that the proposed strategy leads to satisfactory results if the number of objects ! 22. If the number of objects is larger than 22, the number of features selected by our method exceeds the true number of features in some conditions.",2006,
Fast Sparse Group Lasso,"Sparse Group Lasso is a method of linear regression analysis that finds sparse parameters in terms of both feature groups and individual features. Block Coordinate Descent is a standard approach to obtain the parameters of Sparse Group Lasso, and iteratively updates the parameters for each parameter group. However, as an update of only one parameter group depends on all the parameter groups or data points, the computation cost is high when the number of the parameters or data points is large. This paper proposes a fast Block Coordinate Descent for Sparse Group Lasso. It efficiently skips the updates of the groups whose parameters must be zeros by using the parameters in one group. In addition, it preferentially updates parameters in a candidate group set, which contains groups whose parameters must not be zeros. Theoretically, our approach guarantees the same results as the original Block Coordinate Descent. Experiments show that our algorithm enhances the efficiency of the original algorithm without any loss of accuracy.",2019,
Identification of a six-gene signature predicting overall survival for hepatocellular carcinoma,"BackgroundHepatocellular carcinoma (HCC) remains a major challenge for public health worldwide. Considering the great heterogeneity of HCC, more accurate prognostic models are urgently needed. To identify a robust prognostic gene signature, we conduct this study.Materials and methodsLevel 3 mRNA expression profiles and clinicopathological data were obtained in The Cancer Genome Atlas Liver Hepatocellular Carcinoma (TCGA-LIHC). GSE14520 dataset from the gene expression omnibus (GEO) database was downloaded to further validate the results in TCGA. Differentially expressed mRNAs between HCC and normal tissue were investigated. Univariate Cox regression analysis and lasso Cox regression model were performed to identify and construct the prognostic gene signature. Time-dependent receiver operating characteristic (ROC), Kaplanâ€“Meier curve, multivariate Cox regression analysis, nomogram, and decision curve analysis (DCA) were used to assess the prognostic capacity of the six-gene signature. The prognostic value of the gene signature was further validated in independent GSE14520 cohort. Gene Set Enrichment Analyses (GSEA) was performed to further understand the underlying molecular mechanisms. The performance of the prognostic signature in differentiating between normal liver tissues and HCC were also investigated.ResultsA novel six-gene signature (including CSE1L, CSTB, MTHFR, DAGLA, MMP10, and GYS2) was established for HCC prognosis prediction. The ROC curve showed good performance in survival prediction in both the TCGA HCC cohort and the GSE14520 validation cohort. The six-gene signature could stratify patients into a high- and low-risk group which had significantly different survival. Cox regression analysis showed that the six-gene signature could independently predict OS. Nomogram including the six-gene signature was established and shown some clinical net benefit. Furthermore, GSEA revealed several significantly enriched oncological signatures and various metabolic process, which might help explain the underlying molecular mechanisms. Besides, the prognostic signature showed a strong ability for differentiating HCC from normal tissues.ConclusionsOur study established a novel six-gene signature and nomogram to predict overall survival of HCC, which may help in clinical decision making for individual treatment.",2019,Cancer Cell International
lAGrIME DI SAn pIEtrO DE OrlAnDO DI lASSO: uMA AnÃ¡l ISE SObrE SuA EXECuÃ§Ã£ O,"This work is part of a broader study of the work Lagrime di San Pietro by Orlando di Lasso and brings the proposal for a viable execution of the piece with mixed choir a cappella. Will be treated most relevant aspects of the work such as his compositional characteristics, vocal types that was intended and performing group, approaching the practice of that era and drawing a parallel with the existing resources in our day. After discussing these aspects, this study suggests a performance consistent with the ideal of the composer and adapted to current parameters.",2011,
"Knowledge and attitude of young people regarding HIV prevention and unwanted pregnancy in Bobo-Dioulasso, Burkina Faso","Introduction: Despite health education efforts, young people are still faced with major health problems. The objective of this study was to assess the knowledge and attitude regarding HIV prevention and unwanted pregnancy among young people in Bobo-Dioulasso, Burkina Faso.
Methods: Based on two-level sampling, representing 94,947 households in the Bobo-Dioulasso municipality, 573 young people between the ages of 15 and 24 years were interviewed. This data collection was conducted from September 2014 to January 2015 in the three districts of the municipality. A questionnaire was used to assess the knowledge and attitudes of young people.
Results: The interviewees had a poor knowledge about HIV transmission and prevention and contraception Very few young people (9%) had complete knowledge about the modes of transmission and 5% had no knowledge. Persistent misperceptions about the effectiveness of condoms (25%) and contraception (32%) did not prevent some young people from using them (79% used condoms and 46% used contraceptives). Knowledge and attitudes of young people regarding HIV and contraception varied according to age, sex, education level and type of parental supervision.
Conclusion: A significant proportion of young people still has incomplete knowledge about HIV/AIDS and contraception. Actions designed to reinforce the knowledge of young people are of paramount importance. The capacities of parents and healthcare providers also need to be reinforced to improve the quality of relationship with young people.",2016,Sante publique
Characterization of an Î±-agarase from Thalassomonas sp. LD5 and its hydrolysate,"It has been a long time since the first Î±-agarase was discovered. However, only two Î±-agarases have been cloned and partially characterized so far and the study of Î±-agarases has lagged far behind that of Î²-agarases. Here, we report an Î±-agarase, AgaD, cloned from marine bacterium Thalassomonas sp. LD5. Its cDNA consists of 4401Â bp, encoding a protein of 1466 amino acids. Based on amino acid similarity, AgaD is classified into glycoside hydrolase (GH) family GH96. The recombinant enzyme gave a molecular weight of about 180Â kDa on SDS-PAGE and 360Â kDa on Native-PAGE indicating it acted as a dimer. However, the recombinant enzyme is labile and easy to be fractured into series of small active fragments, of which the smallest one is about 70Â kDa, matching the size of catalytic module. The enzyme has maximal activity at 35Â Â°C and pH 7.4, and shows a strong dependence on the presence of calcium ions. AgaD degrades agarose to yield agarotetraose as the predominate end product. However, the hydrolysates are rapidly degraded to odd-numbered oligosaccharides under strong alkaline condition. The spectra of ESI-MS and 1H-NMR proved that the main hydrolysate agarotetraose is degraded into neoagarotriose, bearing the sequence of G-A-G (G, d-galactose; A, 3,6-anhydro-Î±-l-galactose). Unlike the alkaline condition, the hydrolysates are further hydrolyzed into smaller degree polymerization (DP) of agaro-oligosaccharides (AOS) in dilute strong acid. Therefore, this study provides more insights into the properties for both the Î±-agarases and the AOS.",2018,Applied Microbiology and Biotechnology
Sensitivity of $\ell_{1}$ minimization to parameter choice,"The use of generalized LASSO is a common technique for recovery of structured high-dimensional signals. Each generalized LASSO program has a governing parameter whose optimal value depends on properties of the data. At this optimal value, compressed sensing theory explains why LASSO programs recover structured high-dimensional signals with minimax order-optimal error. Unfortunately in practice, the optimal choice is generally unknown and must be estimated. Thus, we investigate stability of each LASSO program with respect to its governing parameter. Our goal is to aid the practitioner in answering the following question: given real data, which LASSO program should be used? We take a step towards answering this by analyzing the case where the measurement matrix is identity (the so-called proximal denoising setup) and we use $\ell_{1}$ regularization. For each LASSO program, we specify settings in which that program is provably unstable with respect to its governing parameter. We support our analysis with detailed numerical simulations. For example, there are settings where a 0.1% underestimate of a LASSO parameter can increase the error significantly; and a 50% underestimate can cause the error to increase by a factor of $10^{9}$.",2018,arXiv: Information Theory
Characterization of a new endo-type polysaccharide lyase (PL) family 6 alginate lyase with cold-adapted and metal ions-resisted property.,"Alginate lyase played an important role in brown algae degradation, and its enzymatic degradation products showed various biological activities. Although many alginate lyases have been characterized, the enzymes with special characterizations are still rather rare. In this study, a new alginate lyase gene, tsaly6A, has been cloned from marine bacterium Thalassomonas sp. LD5, and expressed in Escherichia coli. The deduced alginate lyase, TsAly6A, belonged to the polysaccharide lyase (PL) family 6 and showed the highest amino acid identity (63%) with an exo-type oligoalginate lyase AlyGC. However, this study showed that TsAly6A was an endo-type enzyme yielding alginate trisaccharides (64.5%) as the main products. Compared with other alginate lyases, TsAly6A showed high trisaccharide-yielding levels. Meanwhile, TsAly6A showed the specific activity of 15,960â€¯U/Î¼mol at its optimal pH (pHâ€¯8.0) and temperature (35â€¯Â°C). In addition, TsAly6A was a cold-adapted, salt-activated and metal ions-resisted alginate lyase, which will enable it to perform high activity in the solution containing various ions. Its cold-adaptation, metal ions-tolerance and high trisaccharides yields make TsAly6A an excellent candidate for industrial applications.",2018,International journal of biological macromolecules
"24-Month adherence, tolerance and efficacy of once-a-day antiretroviral therapy with didanosine, lamivudine, and efavirenz in African HIV-1 infected children: ANRS 12103/12167.","BACKGROUND
There is no data on long-term benefit of once-a-day antiretroviral therapy (ART) with combination of DDI, 3TC and EFV to allow its use in future therapeutic strategies.


OBJECTIVES
To assess 24-month immuno-virological, adherence, tolerance, and effectiveness of a once-a-day ART with DDI, 3TC and EFV.


METHODS
A phase 2 open trial including 51 children aged from 30 months to 15 years, monitored a once-a-day regimen for 24 months from 2006 to 2008 in the Departement de Pediatrie du CHUSS, at Bobo-Dioulasso in Burkina Faso. We tested immunological and virological response, adherence, tolerance and resistance of the treatment.


RESULTS
Children with CD4 >25% at 24 months were 67.4% (33/49) CI 95% [54%, 80%]. The proportion of children with viral plasma RNA <300 cp / ml at 24 months of treatment was 81.6 % (40/49) CI [68.0% 91.2%]. Good adherence was obtained with more than 88% adherence > 95% over the 24 months. Drugs were well tolerated.


CONCLUSIONS
Given the limited number of antiretroviral drugs available in Africa and the inadequacy of laboratory monitoring in support program, once-a-day treatment and especially the DDI-based combination strategies could be an attractive operational option.",2013,African health sciences
Tejedorxs y subversivxs,"Desde que Rozsika Parker publicase en 1984 el libro The Subversive Stitch: Embroidery and the Making of the Feminine, han pasado ya treinta y cuatro anos. Parker ponia el foco en las practicas artisticas relacionadas con el tejido y con el bordado, que habian sido categorizadas y relegadas al terreno de la artesania, de lo decorativo y de lo domestico. Se analizaba el recorrido en el que el sistema del arte habia desechado este tipo de creaciones unicamente por la tecnica utilizada y los materiales usados, atendiendo tambien la carga simbolica de haberse definido como â€œmodos de hacer femeninosâ€. En los anos setenta habia surgido un interes especial en la recuperacion de procesos que encontrandose casi desaparecidos por la irrupcion de la industria textil, rescataban del olvido, no solamente conocimientos tecnicos, sino espacios de encuentro y colaboracion que permitian repensar los modos de organizacion social. A finales de los ochenta es cuando comenzara un interes ascendente por reencontrar nuevos modos de accion, en los que hay una mirada critica hacia aspectos vinculados al entorno domestico, y donde se expone la necesidad de releer, transmutar y significar los roles, espacios y estereotipos del sistema patriarcal. Hay un analisis de esa deriva hacia los anos noventa, donde habra una puesta en practica de muchas revisiones de la historia del arte. Cuando entramos en el s. XXI la expansion de la red de internet permitira un nuevo movimiento de artistas que replantearan nuevos modos de hacer y pensar de manera global. Betsy Greer acunara en 2003 el termino â€œcraftivism (craft+activism)â€ para dar nombre a aquellas manifestaciones que venian trabajando en la busqueda de lugares comunes y de encuentro entre arte y activismo desde la reivindicacion del â€œlow artâ€ como forma de reconstruccion y cambio de las sociedades desde espacios alternativos. El dossier Tejedorxs y subversivxs se presenta como un lugar de visibilizacion y estudio de practicas relacionadas con el arte de accion, el arte textil y el craftivismo, que han venido sucediendo en estos anos, en una nueva red globalizada que se expande tejiendo nuevas tramas y urdimbres y siendo la propia accion de tejer, bordar o coser la que prevalece a veces por encima del objeto tejido, que es nexo tambien de nuevas relaciones y experiencias desde las que podemos comprender, habitar y transformar el mundo. El analisis academico sobre el textil no ha tenido hasta ahora un espacio propio, queda mucho trabajo por realizar en cuanto a nuevos modos de investigar desde el arte y desde la practica. Jessica Hemmings lanzaba la pregunta en 2010, sobre si es necesaria una teoria sobre el arte textil, proponiendo formatos como la ficcion o publicaciones no academicas como fuentes para la construccion de un espacio de critica y como herramientas para poder delimitar nuevos territorios de investigacion. De modo similar en el ambito de las artes escenicas y el arte de accion se estan desarrollando practicas de investigacion que cada vez cobran mas autonomia. En este dossier se muestran textos de investigacion, asi como presentaciones de proyectos y obras artisticas que producen un marco comun. Elisabetta Balasso propone un lenguaje revelador, el TxT (textil- textual- contextual). Bordar, tejer y coser â€œaquello que no puede explicarseâ€ mostrando acciones recientes de craftivismo en Venezuela. A su vez, Geraldine Guerrero y Benjamin Castro se acercan a lo performativo con la accion Velo Negro realizada en Mexico, compartiendo tambien esa vinculacion del tejido con los cuerpos desaparecidos. Ese recordatorio que nos hace volver al origen del rito y del acto de tejer como elemento de conexion con lo ancestral y para hacer volver a la vida a lxs que ya no estan con nosotrxs. Gabriela Bernal, en una accion poetica, transforma esa dualidad entre la vida y la muerte en contacto directo con la naturaleza. Ella es la tejedora, la que se mimetiza con el tejido y la que a traves del canto une tambien esa parte de la tradicion oral extinguida, en un intento de rescate simbolico que marca fuertemente con los hilos y los nudos. En el texto sobre la obra de Marcela Cernadas, Aurora Villalobos traduce ese lugar de revision de la figura de Penelope y como la simbologia del tejido se reconfigura en actualizaciones de los mitos. Marina Fernandez nos desplaza desde el espacio de lo domestico a la esfera publica en proyectos que llevan el color hacia el lugar comun uniendo generaciones y Silvio de Gracia tambien investiga sobre acciones y obras basadas en el cuerpo, que han cuestionado los espacios de lo domestico en relacion al tejido, haciendo patente esa fragilidad entre lo publico y lo privado. La parte mas ambigua de la relacion con el textil y lo domestico es revisada por Laurita Siles, que viaja en el tiempo para rescatar un sistema de trabajo realizado por mujeres en el entorno rural que producian desde su hogar para la industria, el llamado putting out system . El tejido envuelve el cuerpo y tambien es cuerpo. ?Que tiene la practica de tejer que traspasa transversalmente la historia? La transmision de este tipo de arte se ha realizado siempre a traves de la ensenanza â€œcuerpo a cuerpoâ€. En la era del post-internet, una nueva generacion que entiende la presencialidad de los cuerpos de una forma renovada ha posibilitado que sigamos conociendo los tejidos. Al igual que otras artes como la danza o la musica, el arte textil se ha conservado en su gran mayoria gracias a esa memoria corporal, muchas veces preservada por la tradicion familiar y/o cultural. Tambien, parte esa memoria se ha desvanecido para siempre porque ya no quedan personas que sepan activar esos objetos o que recuerden cosas de ellos, queda lo inerte y solo podemos tratar de imaginar fragmentos de ese enigma que muchos tejidos conservan. La textura y el rastro de lo humano queda impreso en las fibras, siendo testimonio de una vida en movimiento y en constante transformacion. Artistas como Celia Pym - entrevistada por Carolina Martinez-, exploran esa parte del tejido, y devuelven a las prendas de ropa esa vida que les falta. Los gestos singulares de cada persona no permanecen, sin embargo, podemos imaginarlos y conocer su historia a traves de lo que han llevado como una segunda piel. Las polillas, insectos y el tiempo haran que ese tejido poco a poco desaparezca, pero quedara siempre la huella. ?Quien ha usado esa ropa? ?Quien la hizo? ?Como se movia? De modo similar, Esther Belvis en su obra I do not remember: an embroidered autobiography, utiliza el bordado como instrumento para hacer aflorar la memoria de lo vivido, al igual que se observa en la obra de Leonilson, en ese transito de la memoria y la autobiografia del cuerpo analizado por Yuji Kawasima. Hay una necesidad primaria de â€œhacer con las manosâ€ y de retorno al plano de lo fisico, que se ha visto ampliada justo cuando pensabamos que lo virtual nos podia hacer perder ese instinto, pero las extremidades son nuestro contacto con el mundo, exploramos a traves de ellas. En la oscuridad, desprovistos de la mirada, son siempre las manos las que buscan para reconocer, para situarnos y para comprender. El tejido ha estado valorado dentro de la historia del arte como una artesania, no elevable a la categoria de arte. Como indicaban Griselda Pollock y Rozsika Parker, en Old Mistresses.Women,art and ideology, se deberia plantear una revision global que no solamente recupere las figuras de las artistas que no han tenido visibilidad ni reconocimiento en la historia del arte, sino que argumente cuales han sido las bases para seleccionar y para sesgar aquellas formas que se separaron en base a determinadas estructuras que consolidaban el patriarcado del sistema artistico. Leyla Dunia conversa tambien en este dossier con Maria Gimeno, que ha llevado a la practica artistica todas estas cuestiones a traves de la performance y del arte visual/objetual y Pamela Pazmino plantea un desglose de parte de ese camino que se recorre desde los anos sesenta hasta la actualidad.",2018,
Causality network retrieval from short time series,"We investigate how efficiently a known underlying causality structure of a simulated multivariate process can be retrieved from the analysis of time-series. Causality is quantified from conditional transfer entropy and the network is constructed by retaining only the statistically validated contributions. We compare results from three methodologies: two commonly used regularization methods, Glasso and ridge, and a newly introduced technique, LoGo, based on the combination of information filtering network and graphical modelling. For these three methodologies we explore the regions of time series lengths and model-parameters where a significant fraction of true causality links is retrieved. We conclude that, when time-series are short, with length of the time series shorter than the number of variables, sparse models are better suited to uncover true causality links with LoGo retrieving the true causality network more accurately than Glasso and ridge.",2017,arXiv: Methodology
Opportunities and issues in the health tourism industry: deep sea water development in Taiwan.,"The deep sea water (DSW) industry has a great commercial potential for the global health tourism market. This study aims to investigate the successful relationships between stakeholders with a focus on the role of the government. Two surveys were conducted on the east coast of Taiwan to discover if the local governments were willing to give any assistance of the development of the DSW industry. The results of the study revealed that the first priority was the installation of a thalasso spa in Hualien, eastern Taiwan. Taiwan Government must consider that the opening of three similar facilities close together will need careful planning and study of the market size. The study suggests establishing a government-owned DSW Research & Development Park and thalasso spa near the three private sectors to balance the fierce competition among the three private companies.",2015,Tourism Analysis
Hinging Hyperplanes for Time-Series Segmentation,"Division of a time series into segments is a common technique for time-series processing, and is known as segmentation. Segmentation is traditionally done by linear interpolation in order to guarantee the continuity of the reconstructed time series. The interpolation-based segmentation methods may perform poorly for data with a level of noise because interpolation is noise sensitive. To handle the problem, this paper establishes an explicit expression for segmentation from a compact representation for piecewise linear functions using hinging hyperplanes. This expression enables the use of regression to obtain a continuous reconstructed signal and, as a consequence, application of advanced techniques in segmentation. In this paper, a least squares support vector machine with lasso using a hinging feature map is given and analyzed, based on which a segmentation algorithm and its online version are established. Numerical experiments conducted on synthetic and real-world datasets demonstrate the advantages of our methods compared to existing segmentation algorithms.",2013,IEEE Transactions on Neural Networks and Learning Systems
The flare package for high dimensional linear regression and precision matrix estimation in R,"This paper describes an R package named flare, which implements a family of new high dimensional regression methods (LAD Lasso, SQRT Lasso, lq Lasso, and Dantzig selector) and their extensions to s...",2015,Journal of Machine Learning Research
Tropical fishes in a temperate sea: evolution of the wrasse Thalassoma pavo and the parrotfish Sparisoma cretense in the Mediterranean and the adjacent Macaronesian and Cape Verde Archipelagos,"The northeastern Atlantic and the Mediterranean Sea share geological histories and display great faunal affinities. The majority of the Mediterranean species have Atlantic origins, with a few species with tropical affinities. These include the parrotfish Sparisoma cretense and the wrasse Thalassoma pavo that are restricted to the subtropical northeastern Atlantic, the Macaronesian archipelagos (Azores, Madeira, and Canaries) and the southern Mediterranean. The Pleistocene glaciations have been described as having different effects on the fauna of the two regions. During glacial peaks, Mediterranean waters remained warmer than those of the adjacent Atlantic. Within the eastern Atlantic, the effects of Pleistocene glaciations were differentiated. Here, we perform a comparative analysis focusing on T. pavo and S. cretense populations from the northeastern Atlantic and the Mediterranean to assess the effects of Pleistocene glaciations in these two species. Sequences from the mitochondrial control region were obtained and analyzed combining phylogeographic and demographic approaches. Gene flow between Atlantic and Mediterranean populations was shown to be very high. The Mediterranean populations of T. pavo and S. cretense showed high levels of genetic diversity, even in the eastern basin, pointing to an ancient colonization event. This suggests that both species must have been able to persist in the Mediterranean during the cold Pleistocene periods. Historical migration estimates revealed a Mediterranean towards Atlantic trend in the case of T. pavo, which may reflect the re-colonization of areas in the Atlantic by fish that survived the cold phases in relatively warmer Mediterranean refugia. Our data also showed that within the Macaronesian Archipelagos, migrations occurred from Madeira towards the Azores, for both T. pavo and S. cretense, thus supporting a post-glacial colonization of the Azores by fish that persisted in the warmer region of Madeira. Similar geographic distributions, thermal affinities, and means of dispersion for T. pavo and S. cretense resulted in a similar response to the effects of Pleistocene glaciations, as evidenced by identical phylogeographic patterns.",2008,Marine Biology
A new application of variable selection in longitudinal data,"In this paper, the Elastic Net method is applied to longitudinal data model which appears in network marketing. It not only makes us better understand the impact of big data on a variety of marketing activities, but also allows companies to better play its effectiveness. The Elastic Net estimation of longitudinal data model is established and proved that this model has the nature of group effect. The data simulation verifies that the Elastic Net method can select all the strongly correlated variables into the model while the Lasso method can not. A network marketing example are given to show the Elastic Net method used in longitudinal data model is feasible. The model in fitting effect and prediction ability are better than the traditional longitudinal data model. It also realizes the application of the Elastic Net method in network marketing.",2017,2017 IEEE 2nd International Conference on Big Data Analysis (ICBDA)(
EEG Emotion Recognition Based on Granger Causality and CapsNet Neural Network,"Emotion recognition is a very challenging task in the brain-computer interface field, and it is of great significance in medical, education, military, and other fields. The classification problem is the key to the field of emotion recognition research. In this paper, a classification model based on CapsNet neural network is proposed. By extracting the granger causality feature of original EEG signals, sparse group lasso algorithm is used for feature screening, and the obtained high-relevance feature subset is taken as the input of the network to achieve the final emotional classification. The experimental results show that by adjusting the model parameters and network structure, the constructed CapsNet neural network performs emotional classification on EEG signals, and obtains 88.09% and 87.37% average classification accuracy under valence and arousal emotion dimensions, compared with SVM and CNN. The classification system can obtain better results and significantly improve the performance of EEG emotional classification. This is the first time that CapsNet is applied to EEG emotional classification.",2018,2018 5th IEEE International Conference on Cloud Computing and Intelligence Systems (CCIS)
RLS-Based Detection for Massive Spatial Modulation MIMO,"Most detection algorithms in spatial modulation (SM) are formulated as linear regression via the regularized least-squares (RLS) method. In this method, the transmit signal is estimated by minimizing the residual sum of squares penalized with some regularization. This paper studies the asymptotic performance of a generic RLS-based detection algorithm employed for recovery of SM signals. We derive analytically the asymptotic average mean squared error and the error rate for the class of bi-unitarily invariant channel matrices.The analytic results are employed to study the performance of SM detection via the box-LASSO. The analysis demonstrates that the performance characterization for i.i.d. Gaussian channel matrices is valid for matrices with non-Gaussian entries, as well. This justifies the partially approved conjecture given in [1]. The derivations further extend the former studies to scenarios with non-i.i.d. channel matrices. Numerical investigations validate the analysis, even for practical system dimensions.",2019,2019 IEEE International Symposium on Information Theory (ISIT)
Vitamin D Is A Prognostic Factor Of Amyotrophic Lateral Sclerosis And Confers Protection To Motoneurons In Vitro (P4.084),"OBJECTIVE: 
To study prognosis of amyotrophic lateral sclerosis (ALS) patients according to plasma vitamin D (VD) levels and to determine the effect of VD on motoneurons (MNs) in vitro for both survival and neuroprotective effects.
 BACKGROUND: 
ALS is a rapidly evolving and incurable MN disorder with a highly variable prognosis, ranging from 3 months to more than 20 years. There is to date no consensus biomarker linked to ALS prognosis. The detrimental consequences of VD deficiency have been documented in several neurological diseases, such as multiple sclerosis, Alzheimerâ€™s disease, stroke or Parkinsonâ€™s disease.
 DESIGN/METHODS: 
74 ALS patients had plasma VD level measurement and were followed quarterly. Prognosis was studied according 2 parameters: 1) survival; 2) rate of decline, defined by the number of ALSFRS-R points lost each month. Purified MNs from mice embryos were cultured for 48hrs and 1,25(OH)2D3 (the biologically active hormone) was added at progressive concentrations to evaluate MN survival and MN protection against Fas-ligand induced apoptosis.
 RESULTS: 
ALS patients with a severe VD deficiency (SVD, < 25nmol/L) had a 4 times higher rate of decline compared to patients with normal VD levels (NVD, 1.42 vs 0.36, respectively, p=0.00013). In the NVD group, median survival was 52.8 vs 29.5 months for SVD patients (log rank, p=0.002). After adjustment for age at onset, risk of death was increased in SVD patients compared to those with NVD (Cox proportional hazard, HR 5.9, 95% CI 1.4 to 24.3; p=0.01). In vitro, VD significantly potentiated the effect of neurotrophic factors (+ 40 % survival at 100 nM, p<0.001) and completely prevented MNs from Fas-induced death (p<0.001).
 CONCLUSIONS: 
Our findings suggest that vitamin D as a reliable prognostic factor of ALS and support a neuroprotective function of vitamin D on MNs in vitro.
 Study Supported by: Disclosure: Dr. William has received personal compensation for activities with Novartis, Merck & Co. Inc., Sanofi-Aventis Pharmaceuticals Inc., Biogen Idec, and Actelion. Dr. Tremblier has nothing to disclose. Dr. Plassot has nothing to disclose. Dr. Alphandery has nothing to disclose. Dr. Salsac has nothing to disclose. Dr. Pageot has nothing to disclose. Dr. Juntas-Morales has nothing to disclose. Dr. Scamps has nothing to disclose. Dr. Daures has nothing to disclose. Dr. Raoul has nothing to disclose.",2014,Neurology
Comparative behaviour of the Anatidae and its evolutionary implications,"An attempt has been made to summarize, in broad outline, the variations encountered in the behaviour of the Anatidae, and to relate these variations to their probable evolutionary significance. In particular, variations in manner of pair formation and pair bond length, in geographic distribution and ecology, and the related conditions of allopatry or sympatry with other species are discussed and their probable effects on behaviour are suggested. Instances are mentioned where a knowledge of behaviour would be helpful in judging evolutionary relationships that have thus far eluded taxonomists (e.g., Stictonetta, Heteronetta, Thalassornus), and likewise examples are pointed out where behavioural evidence suggests different relationships from those which are currently accepted (e.g., Lophonetta, Anas, leucophrys, and the eiders).",1960,
ALDH1A3 induces mesenchymal differentiation and serves as a predictor for survival in glioblastoma,"As aldehyde dehydrogenase (ALDH) is a novel stem cell marker, increasing studies have confirmed that high ALDH activity promotes tumorigenesis and progression in cancers. Some preliminary studies have found that ALDH1A3 may play an important role in glioma malignant progression, but so far there was no conclusive conclusion. The purpose of our study was to elucidate the mechanisms by which ALDH1A3 regulated in glioma and to provide practical tools for clinical application. Aldefluor, flow cytometry sorting and qRT-PCR were performed to verify the role of ALDH1A3 in ALDH activity maintenance. Transwell, immunofluorescence, glycolytic assays, and orthotopic xenograft models were used to explore ALDH1A3 bio-functions in GBM. LASSO-COX, COX survival analysis and Kaplanâ€“Meier analysis were used to establish the prognostic evaluation system and predict postoperative chemotherapy sensitivity of GBMs. Our integrated study found that (1) ALDH1A3 associates with mesenchymal differentiation of GBM in Eastern and Western world patients. (2) ALDH1A3 plays a critical role in ALDH activity maintenance. (3) ALDH1A3 is an activator of mesenchymal transformation in GBM. (4) ALDH1A3-derived PMT markersâ€™ molecular signature can predict 1-, 2-, and 3-year survival rates of GBMs precisely. In conclusion, ALDH1A3 was a major contributor to ALDH activity and a key driver in triggering mesenchymal transformation in GBM. ALDH1A3-based molecular classification scheme can help to improve guidance for prognosis forecasting and individualized treatment decision making for GBM patients.",2018,Cell Death & Disease
1643) Proposal to conserve the fossil pollen morphogeneric name Classopollis against Corollina and Circulina,"The generic names Classopollis Pflug 1953, Corollina Malyavk. 1949, and Circulina Malyavk. 1949 are fossil pollen morphogeneric names for one of the important late Mesozoic fossil pollen forms, which in its numerous species ranges from Mid-Triassic to early Cenozoic in age. The plants producing the pollen are various fossil conifers, as shown by in situ pollen in fossil male cones. This form and other morphogeneric units of similar morphology comprise the Circumpolles group of fossil pollen (cf. Traverse, Paleopalynology: 224-227. 1988). The intertwining and complex nomenclatural history of the generic names involved causes confusion to the present. Malyavkina (l.c.) described and illustrated what in my opinion is clearly recognizable as this form of fossil pollen from the early Jurassic of south-central parts of the then Soviet Union in the Kazakhstan/Urals areas. (She did not give more specific locality information.) She provided two generic names for variants of the basic form: Corollina and Circulina. Malyavkina illustrated species referred to Corollina and Circulina with simple line drawings. Many palynologists find these drawings inadequate, though I have never doubted that they are sufficient to demonstrate that she was describing forms of fossil circumpolloid pollen now generally referred to either Corollina or, more often, Classopollis. The fact that Malyavkina presented her descriptions partly in the form of keys, so that one must assemble the total desc iption of Corollina and Circulina from phrases on different pages, is not a legitimate objection to the validity of her publication. Malyavkina included only one species, C. compacta, in her treatment of Corollina and hence it provides the type. However, she included two species in Circulina, C. funifera and C. simplex, without indicating either as type. The earliest acceptable lectotype selection is that of Potoni6 (l.c. 1966) who selected C. funifera. Potonie's choice must be followed under Art. 10.5 of the ICBN. Klaus (Jahrb. Geol. Bundesanst., Sonderb. 5, 165, P1. 36, Fig. 58, 1960) designated C. meyeriana Klaus as ""neotype"" for a redefined Circulina, but this is not acceptable under Art. 10.2 of ICBN, and that usage of the name Circulina need not be considered here. Pflug (1953), who presumably did not know of Malyavkina's work, because Soviet scientific publications were not widely circulated in the West at the time of his research, published the generic name, Classopollis, for this same form of pollen from the Early Jurassic of Germany, using good photographic illustration and understandable description. The fact that Pflug thought that the form was angiospermid and tricolpate, and that he did not designate or preserve type specimens, does not affect the validity of his publication. The problem is one of priority. Corollina and Circulina were published four years before Classopollis. A clear majority of paleopalynologists, however, have accepted Classopollis as the correct generic name for this sort of fossil pollen. If one accepts Circulina and Corollina as validly published by Malyavkina in 1949, as one must, one or the other name is a potential threat to the use of Classopollis, and therefore both are proposed here for rejection. There are prominent paleopalynologists who use Corollina Malyavkina for the whole CorollinaCirculina-Classopollis complex, and will probably continue to do so perfectly correctly unless Classopollis is conserved against it. I know that I would continue to use it. This confuses the literature. It appears to me, a strong advocate in the past for the legitimacy and adoption of Malyavkina's names, that the best way to secure nomenclatural stability in this situation is to conserve Classopollis against Corollina, and also against",2004,Taxon
Postpartum Family Planning in Burkina Faso. STEP UP Research Report.,"Objective: This is a formative study aiming to identify the main barriers to the provision and uptake of quality
postpartum family planning (PPFP) services at the supply, access, demand and policy levels in Burkina Faso.
Design & Methods: A combination of three methods was used: a review of relevant literature, policy and clinical
guidelines; observations of client-provider interactions in government-run primary health care centres in and
around the city of Bobo-Dioulasso; and semi-structured interviews with stakeholders and key informants,
including service providers and users.
Results: At the supply level, this study reveals that there are substantial shortfalls in the availability of quality
postpartum family planning (PPFP). Individual counselling and the quality of information provided are often
inadequate and occasions to advise women on family planning are wasted, resulting in low uptake of
contraception during routine postnatal care. Providers appear to have an ambivalent and largely resigned
attitude towards the possibility of enabling women to make informed choices, and towards the potential
involvement of men. Services offer a limited range of methods due to a variety of factors including the lack of
competent staff, stock issues, and provider biases. Furthermore, legal barriers are in place which prevent the
majority of maternity staff from providing long-acting reversible contraception (LARC). The accessibility of
services is limited by geographical and cost barriers. Cultural traditions and practices and high desired family
size place limits on the demand for modern contraception, which is not well understood or acceptable to many
people. Notable policy gaps exist in relation to user fees and to authorising maternity staff to provide LARC, and
some national clinical guidelines are in need of improvement. However, most of the difficulties observed in the
provision of PPFP services are in fact due to the failure to translate largely sound policies and guidelines into
practice.
Conclusions: This study contributes to identifying priority areas and makes recommendations for improvement
in order to respond to unmet need for family planning in the postpartum. Furthermore, it suggests that there may
be a margin for the expansion of demand, and that improving quality of care could play a role in this.",2014,
Neural Granger Causality for Nonlinear Time Series,"While most classical approaches to Granger causality detection assume linear dynamics, many interactions in applied domains, like neuroscience and genomics, are inherently nonlinear. In these cases, using linear models may lead to inconsistent estimation of Granger causal interactions. We propose a class of nonlinear methods by applying structured multilayer perceptrons (MLPs) or recurrent neural networks (RNNs) combined with sparsity-inducing penalties on the weights. By encouraging specific sets of weights to be zero---in particular through the use of convex group-lasso penalties---we can extract the Granger causal structure. To further contrast with traditional approaches, our framework naturally enables us to efficiently capture long-range dependencies between series either via our RNNs or through an automatic lag selection in the MLP. We show that our neural Granger causality methods outperform state-of-the-art nonlinear Granger causality methods on the DREAM3 challenge data. This data consists of nonlinear gene expression and regulation time courses with only a limited number of time points. The successes we show in this challenging dataset provide a powerful example of how deep learning can be useful in cases that go beyond prediction on large datasets. We likewise demonstrate our methods in detecting nonlinear interactions in a human motion capture dataset.",2018,arXiv: Machine Learning
4 A new algorithm for finding the lasso solution,"Adaptive ridge is a special form of ridge regression, balancing the quadratic penalization on each parameter of the model. This paper shows the equivalence between adaptive ridge and lasso (least absolute shrinkage and selection operator). This equivalence states that both procedures produce the same estimate. Least absolute shrinkage can thus be viewed as a particular quadratic penalization. From this observation, we derive an EM algorithm to compute the lasso solution. We finally present a series of applications of this type of algorithm in regression problems: kernel regression, additive modeling and neural net training.",1998,
Ageratina adenophora (Asteraceae) new species to the Italian alien flora and observations on its environmental threats.,"Discovery of new aliens and evaluation of their naturalization status are crucial for their correct management. For Italy, a comprehensive work was recently published by Celesti-Grapow et al. (2010). In spite of this, the number of exotic species is in steady increase (e.g. Alberti 2012, Galasso 2012, Stinca et al. 2012, Villa et al. 2012) and in some cases they are recognized as invasive (e.g. Iamonico 2011; Iberite et al. 2011). During the botanical investigations on the flora of Southern Italy, two separate populations referred the genus Ageratina Spach were found in Campania region. The genus is rarely recognized in Italian floras, being included in Eupatorium L. (e.g. Pignatti 1982). However, several Ageratina species are considered aliens out of their native area (Americas) (Nesom 2006) and some are invasive in several countries (e. g. Wang & Wang 2006). With the aim to correctly identify the Ageratina populations found, a morphological study is carAbstract Ageratina adenophora is recorded for the first time in Italy (Campania region). Its naturalization status and ecology are discussed, also providing a morphological comparison with the related taxa (both occurring in Italy) A. ligustrina and Eupatorium cannabinum. Some remarks on potential threats for habitat and native flora are provided as well.",2013,Hacquetia
Food resource partitioning between two sympatric temperate wrasses,"The present study analysed two sympatric wrasses, Thalassoma pavo and Coris julis, with similar sizes and morphologies, that are widespread in the reef habitats of the Mediterranean and the eastern Atlantic coast. Ocean warming has induced the northward movement of T. pavo, whereas C. julis has been moving to deeper habitats. In addition, under conditions of high slope of the sea bottom, T. pavo occupies shallow habitats and C. julis is in greater abundance in deeper habitats. By investigating stomach contents and prey availability in the benthos, we assessed whether the two wrasses exploit food resources by choosing different prey within the same habitat both under co-existence and segregation conditions. The results showed that T. pavo mainly feeds on gammarids and sipunculids, whereas C. julis mainly feeds on Alvania spp. and Paguroidea. The two wrasses also showed an intrinsic partitioning of food resources, independently of the condition of co-existence or segregation and benthic prey availability in the environment. The two wrasses fall in the â€˜over dispersion of resource useâ€™ model, in which species share numerous niche dimensions in a variable manner. Our findings may contribute to exclude a greater trophic competition between these labrid species in a projected warming scenario.",2017,Marine and Freshwater Research
A Note on Choosing the Threshold for Large Covariance Estimations in Factor Models,"This note shows that for i.i.d. data, estimating large covariance matrices in factor models can be casted using a simple plug-in method to choose the threshold: $$ \mu_{jl}=\frac{c_0}{\sqrt{n}}\Phi^{-1}(1-\frac{\alpha}{2p^2})\sqrt{\frac{1}{n}\sum_{i=1}^n\hat u_{ji}^2\hat u_{li}^2}.$$ This is motivated by the tuning parameter suggested by Belloni et al. (2012) in the lasso literature. It also leads to the minimax rate of convergence of the large covariance matrix estimator. Previously, the minimaxity is achievable only when $n=o(p\log p)$ by Fan et al. (2013), and now this condition is weakened to $n=o(p^2\log p)$. Here $n$ denotes the sample size and $p$ denotes the dimension.",2016,arXiv: Methodology
"Rare conifers from the type area of the Maastrichtian (Upper Cretaceous, southeast Netherlands)","Two conifer twigs from the type area of the Maastrichtian are described as Brachyphyllum sp. 1 and Brachyphyllum sp. 2. They might belong to the Cheirolepidiaceae, Podocarpaceae or Taxodiaceae. Brachyphyllum sp. 1 occurs with the conifers Brachyphyllum patens (?Cheirolepidiaceae) and Elatidopsis cryptomerioides (Taxodiaceae), the seagrass Thalassocharis bosqueti and the ammonite Baculites vertebralis in the upper part of the Kunrade Chalk in the Kunrade area, while Brachyphyllum sp. 2 probably originates from the lower part of this deposit.",2003,Scripta Geologica
A new approach to Pairs Trading : Using fundamental data to find optimal portfolios,"Since itsâ€™ invention at Morgan Stanley in 1987 pairs trading has grown to be one of the most common and most researched strategies for market neutral returns.The strategy identifies stocks, or other financial securities, that historically has co-moved and forms a trading pair. If the price relation is broken a short position is entered in the overperforming stock and a long in the underperforming. The positions are closed when the spread returns to the long-term relation. A pairs trading portfolio is formed by combining a number of pairs.To detect adequate pairs different types of data analysis has been used. The most common way has been to study historical price data with different statistical models such as the distance method. Gatev et al (2006) used this method and provided the most extensive research on the subject and this study will follow the standards set by that article and add new interesting factors. This is done through an investigation on how the analysis can be improved by using the stocks fundamental data, e.g. P/E, P/B, leverage, industry classification. This data is used to set up restrictions and Lasso models (type of regression) to optimize the trading portfolio and achieve higher returns. All models have been back-tested using S&P 500 stocks between 2001-04-01 and 2015-04-01 with portfolios changed every six months.The most important finding of the study is that restricting stocks to have close P/E-ratios combined with traditional price series analysis increases returns. The most conservative measure gives annual returns of 3.99% to 4.98% depending on the trading rules for this portfolio. The returns are significantly (5%-level) higher than those obtained by the traditional distance method.Considerable variations in return levels is shown to be created when capital commitments are changed and trading rules, transaction costs and restrictions on unique portfolio stocks are implemented.Further research regarding how analysis of P/E-ratios can improve pairs trading is suggested.The thesis has been written independently without an external client and studied an area that the author found interesting.",2015,
"POSTHARVEST DECAY ON STONE FRUIT-WHAT, WHEN and HOW TO REDUCE Part 2: Pre- and postharvest control measures to reduce decay development","Introduction An integrated approach to disease management, encompassing preand postharvest activities, including effective use of postharvest technologies, is required to restrict fruit deterioration between harvest and end use (Wills, McGlasson, Graham, & Joyce, 2007). All decay management programmes must start with good pre-harvest practices. Practices to reduce the impact of environments favourable for the development of pathogens and to minimize the inoculum potential, should be followed meticulously, after which postharvest decay control should be applied. Postharvest decay control practices do not only entail chemical application. This communication focuses on control measures across pathogens, based on the premise that the infection process of the potential causal organisms, the physiology of the fruit and effect of environmental conditions are understood, as elaborated previously in Part 1 of the series.",2013,
Low-Rank and Sparse Modeling of High-dimensional Vector Autoregressions,"Network modeling of high-dimensional time series in presence of unobserved latent variables is an important problem in macroeconomics and finance. In macroeconomic policy making and forecasting, it is often impossible to observe and incorporate all the relevant series in the analysis. Failure to include these variables often results in spurious connectivity among the observed time series in structural analyses, which may have serious policy implications. In order to accurately estimate a network of Granger causal interactions after accounting for latent effects, we introduce a novel approach of low-rank and sparse vector autoregression (VAR). We argue that in presence of a few latent pervasive factors, the transition matrix of a misspecified VAR model among the observed series can be approximated as the sum of a low-rank and a sparse component. Exploiting this connection, we consider estimating low-rank plus sparse VAR models using a combination of nuclear norm and lasso penalties. We establish non-asymptotic upper bounds on the estimation error rates of the low-rank and the sparse components and demonstrate the advantage of the proposed methodology over ordinary and sparse VAR estimates via numerical experiments.",2015,
De-Biasing Covariance-Regularized Discriminant Analysis Conference,"Fisherâ€™s Linear Discriminant Analysis (FLD) is a well-known technique for linear classification, feature extraction and dimension reduction. The empirical FLD relies on two key estimations from the data â€“ the mean vector for each class and the (inverse) covariance matrix. To improve the accuracy of FLD under the High Dimension Low Sample Size (HDLSS) settings, Covariance-Regularized FLD (CRLD) has been proposed to use shrunken covariance estimators, such as Graphical Lasso, to strike a balance between biases and variances. Though CRLD could obtain better classification accuracy, it usually incurs bias and converges to the optimal result with a slower asymptotic rate. Inspired by the recent progress in de-biased Lasso, we propose a novel FLD classifier, DBLD, which improves classification accuracy of CRLD through de-biasing. Theoretical analysis shows that DBLD possesses better asymptotic properties than CRLD. We conduct experiments on both synthetic datasets and real application datasets to confirm the correctness of our theoretical analysis and demonstrate the superiority of DBLD over classical FLD, CRLD and other downstream competitors under HDLSS settings.",2018,
Lasso-Kalman smoother for tracking sparse signals,"Fixed-interval smoothing of time-varying vector processes is an estimation approach with well-documented merits for tracking applications. The optimal performance in the linear Gauss-Markov model is achieved by the Kalman smoother (KS), which also admits an efficient recursive implementation. The present paper deals with vector processes for which it is known a priori that many of their entries equal to zero. In this context, the process to be tracked is sparse, and the performance of sparsity-agnostic KS schemes degrades considerably. On the other hand, it is shown here that a sparsity-aware KS exhibits complexity which grows exponentially in the vector dimension. To obtain a tractable alternative, the KS cost is regularized with the sparsity-promoting â„“1 norm of the vector process - a relaxation also used in linear regression problems to obtain the least-absolute shrinkage and selection operator (Lasso). The Lasso (L)KS derived in this work is not only capable of tracking sparse time-varying vector processes, but can also afford an efficient recursive implementation based on the alternating direction method of multipliers (ADMoM). Finally, a weighted (W)-LKS is also introduced to cope with the bias of the LKS, and simulations are provided to validate the performance of the novel algorithms.",2009,"2009 Conference Record of the Forty-Third Asilomar Conference on Signals, Systems and Computers"
CapacitÃ  Sismica Di Edifici Monumentali in Muratura,"Il tema trattato nella tesi e il comportamento sismico di edifici monumentali; la tesi e divisa in due parti principali di cui la prima riguardante gli edifici monumentali ecclesiastici a pianta basilicale, la seconda tratta invece l'analisi sismica di edifici multipiano.
Con riferimento agli edifici a pianta basilicale sono state analizzate le criticita insite nell'impiego dell'analisi modale con spettri di risposta per la valutazione delle azioni sismiche su modelli FEM globali degli edifici; da tali approfondimenti e emersa, confermando pienamente quanto prescritto dalle LL.GG. 2010 per la salvaguardia degli edifici monumentali, la necessita di un'analisi di dettaglio dei singoli macroelementi per valutare la sicurezza rispetto a fenomeni di collasso locale.
E'stata riscontrata, sempre nell'ambito degli edifici a pianta basilicale, una variabilita della capacita sismica strettamente connessa alla geometria, e quindi alla classe dei macroelementi; attraverso tali osservazioni traspare la possibilita di giungere a sviluppare in futuro procedure speditive di analisi della vulnerabilita.
Nella seconda parte della tesi, dedicata invece agli edifici multipiano, e stato analizzato un campione costituito da 2 edifici napoletani e 2 edifici aquilani che rappresentano, in termini di rapporti geometrici, una vasta popolazione di edifici presenti nell'Italia Centro-Meridionale.
Per tali strutture e stata valutata la capacita per carichi orizzontali applicando diversi strumenti di calcolo piu o meno avanzati (Softwares: Abaqus, 3DMacro, 3Muri; Analisi Limite) riscontrando un sostanziale accordo tra i risultati ottenuti e pervenendo ad interessanti indicazioni sulla scelta degli interventi di consolidamento.
E' stato infine valutato il contributo che le catene, tradizionalmente adottate come accorgimento per evitare meccanismi di ribaltamento (del I tipo), sono in grado di offrire nell'incrementare la capacita di pareti sollecitate nel piano (meccanismi di II tipo).",2013,
A sparse and decomposed particle swarm optimization for inferring gene regulatory networks based on fuzzy cognitive maps,"Inferring gene regulatory networks (GRNs) is vital to understand the complex cellular processes and reveal the regulatory mechanisms among genes. Although various methods have been developed, more accurate algorithms which can control the sparseness of GRNs still need to be developed. In this work, we model GRNs by fuzzy cognitive maps (FCMs), and a node in an FCM means a gene. Then, a new sparse and decomposed particle swarm optimization, termed as SDPSOFCM-GRN, is proposed to train FCMs, which employs the least absolute shrinkage and selection operator (Lasso) to control the network sparseness with a decomposed strategy. In the experiments, the performance of SDPSOFCM-GRN is validated on synthetic data and the well-known benchmark DREAM3 and DREAM4. The results show that SDPSOFCM-GRN can well control the sparseness of GRNs, and infer directed GRNs with high accuracy and efficiency.",2019,Journal of bioinformatics and computational biology
Aspergillus penicillioidesâ€”a true halophile existing in hypersaline and polyhaline econiches,"Aspergillus penicillioides is a true halophile, present in diverse econiches from the hypersaline athalassohaline Dead Sea and the thalassohaline solar salterns, to the polyhaline estuaries and mangroves of Goa-India. Thirty-nine isolates from these environments were seen to be moderate halophiles, stenohaline or euryhaline in nature, with comparable salt tolerance indices. They had an obligate need for a low water activity and were unable to grow on a regular defined medium such as Czapek Dox Agar, or on various nutrient rich agar media such as Malt Extract, Potato Dextrose and Sabouraud Agar; however, growth was obtained on all these media when amended with 10Â % solar salt. In the absence of added salt, the conidia either did not germinate, or when germinated, distortions and lysis were seen in the short mycelial forms; on media with salt, the mycelia and vesicles appeared normal.",2013,Annals of Microbiology
Variable selection in linear models,"Variable selection in linear models is essential for improved inference and interpretation, an activity which has become even more critical for high dimensional data. In this article, we provide a selective review of some classical methods including Akaike information criterion, Bayesian information criterion, Mallow's Cp and risk inflation criterion, as well as regularization methods including Lasso, bridge regression, smoothly clipped absolute deviation, minimax concave penalty, adaptive Lasso, elastic-net, and group Lasso. We discuss how to select the penalty parameters. We also provide a review for some screening procedures for ultra high dimensions. WIREs Comput Stat 2014, 6:1â€“9. doi: 10.1002/wics.1284 
 
Conflict of interest: The authors have declared no conflicts of interest for this article. 
 
For further resources related to this article, please visit the WIREs website.",2014,Wiley Interdisciplinary Reviews: Computational Statistics
Estimating structured signals in sparse noise: A precise noise sensitivity analysis,"We consider the problem of estimating a structured signal xo from linear, underdetermined and noisy measurements y = Ax<sub>0</sub> + z, in the presence of sparse noise z. A natural approach to recovering x<sub>0</sub>, that takes advantage of both the structure of xo and the sparsity of z is solving: x = arg min<sub>x</sub> ||y - Ax||<sub>1</sub> subject to f(x) â‰¤ f(x<sub>0</sub>) (constrained LAD estimator). Here, f is a convex function aiming to promote the structure of x<sub>0</sub>, say â„“<sub>1</sub>-norm to promote sparsity or nuclear norm to promote low-rankness. We assume that the entries of A and the non-zero entries of z are i.i.d normal with variances 1 and Ïƒ<sup>2</sup>, respectively. Our analysis precisely characterizes the asymptotic noise sensitivity ||x - x<sub>0</sub>||<sup>2</sup><sub>2</sub>/Ïƒ<sup>2</sup> in the limit Ïƒ<sup>2</sup> â†’ 0. We show analytically that the LAD method outperforms the more popular LASSO method when the noise is sparse. At the same time its performance is no more than Ï€/2 times worse in the presence of non-sparse noise. Our simulation results verify the validity of our theoretical predictions.",2014,"2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton)"
Concave 1-norm group selection.,"Grouping structures arise naturally in many high-dimensional problems. Incorporation of such information can improve model fitting and variable selection. Existing group selection methods, such as the group Lasso, require correct membership. However, in practice it can be difficult to correctly specify group membership of all variables. Thus, it is important to develop group selection methods that are robust against group mis-specification. Also, it is desirable to select groups as well as individual variables in many applications. We propose a class of concave [Formula: see text]-norm group penalties that is robust to grouping structure and can perform bi-level selection. A coordinate descent algorithm is developed to calculate solutions of the proposed group selection method. Theoretical convergence of the algorithm is proved under certain regularity conditions. Comparison with other methods suggests the proposed method is the most robust approach under membership mis-specification. Simulation studies and real data application indicate that the [Formula: see text]-norm concave group selection approach achieves better control of false discovery rates. An R package grppenalty implementing the proposed method is available at CRAN.",2015,Biostatistics
"ThalassothÃ©rapie, thermalisme et bien-Ãªtre : Du profil sÃ©mantique du mot bien-Ãªtre aux portraits discursifs des publics","Cette etude tente de degager un profil semantique du mot â€˜bien-etreâ€™ dans une sphere dâ€™activite particuliere : la thalassotherapie et le thermalisme non medicalise. Un premier corpus construit a partir des mots-cles Â« thalassotherapie + bien-etre Â» entres sur des sites generalistes (google.fr) et specialises (scholar.google.fr, doctissimo.fr) a permis de degager les cotextes syntaxico-semantiques du mot â€˜bien-etreâ€™ puis dâ€™elargir ces cotextes aux mots associes renvoyant aux acteurs, aux objets, aux actions qui participent aux representations de ce Â« bien-etre Â», et a leurs Â« places syntaxiques Â» dans cette sphere dâ€™activite. Un deuxieme corpus constitue de brochures imprimees ou en ligne de centres specialises dans Â« les cures bien-etre Â» permet dâ€™elargir le corpus aux representations semiotiques (photos, affiches, couleurs, mise en pagesâ€¦) des objets, des acteurs et des actions, et de dresser des portraits discursifs des destinataires vises par ce qui est devenu un Â« marche Â» du bien-etreâ€¦ ou Â« du malaise Â».",2016,
Les facteurs clÃ©s de succÃ¨s des projets d'aide au dÃ©veloppement,"Cette these examine les facteurs cles de succes, les interactions entre eux, et leur relation avec les dimensions du succes des projets d'aide au developpement. Elle s'articule autour de trois articles de recherche, l'un conceptuel sur l'experience des agences d'aide en matiere d'identification des facteurs cles de succes (FCS) de leurs projets et les deux autres, empiriques, qui epousent deux perspectives : celle des superviseurs de projet des agences d'aide multilaterale au developpement notamment la Banque mondiale et celle des coordonnateurs de projet sur le terrain, en l'occurrence en Afrique. Sur le plan methodologique, ces travaux adoptent une approche contingente de l'etude des projets et de leur succes; et les donnees ont ete collectees par questionnaire. D'abord, la these fait le point sur l'experience des agences d'aide dans l'identification des criteres et des FCS des projets de developpement. C'est l'objet du premier article qui s'intitule : Â« Identification des criteres et des facteurs cles de succes des projets dans la documentation des agences d'aide au developpement Â». (Une toute premiere version de ce papier a deja fait l'objet de publication dans la Revue Management & Avenir sous le titre : Â« Les agences d'aide au developpement font-elles assez en matiere de formulation des facteurs cles de succes des projets? Â»). L'objectif specifique de ce premier article est de mettre en evidence les criteres et les FCS que les agences d'aide au developpement utilisent, d'analyser l'evolution des criteres et des FCS a travers les decennies de developpement et de faire un rapprochement entre la gestion de projet et la gestion des projets de developpement international. Dans ce premier article, nous presentons les agences d'aide dans leur diversite et dans leur contribution au developpement et nous envisageons les projets comme des vecteurs du developpement. Ensuite, nous tentons de definir les concepts de resultats de developpement, de succes, de criteres de succes et de facteurs de succes des projets de developpement avant de presenter les criteres de succes et les FCS des agences d'aide. Puis nous analysons l'evolution des criteres et des FCS a travers les decennies de developpement. Enfin, nous faisons un rapprochement entre la gestion de projet et la gestion des projets de developpement international sur les criteres et les FCS ainsi que sur leur evolution dans le temps. Les resultats montrent que si les agences ont bien defini et harmonise les criteres de succes, il reste beaucoup a faire pour les criteres impact et durabilite, et les FCS. Ils suggerent qu'un rapprochement entre la gestion de projet et la gestion des projets de developpement international est possible et qu'en matiere de succes des projets, la gestion des projets de developpement international peut tirer des enseignements de la litterature de la gestion de projet pour mieux comprendre les criteres et les FCS des projets de developpement. Partant de ces enseignements, le deuxieme article, qui s'appuie sur le premier, analyse les interrelations entre quatre FCS bien connus tant en gestion de projet qu'en gestion des projets de developpement international mais captant Â« l'exercice global de supervision des projets de la Banque mondiale Â» (la conception, le suivi, la coordination, et la formation) et leurs influences respectives sur deux dimensions du succes des projets tout autant bien connues (le succes de la gestion et le succes du livrable). Cet article s'intitule : Â« World Bank projects' critical success factors and their interactions : an empirical investigation Â». Ce deuxieme article, utilisant plutot les modeles d'equations structurelles comme methode d'analyse statistique des donnees, a ete accepte pour publication au PMI Research Conference 2010. (Une premiere version de cet article, utilisant plutot la regression multiple comme methode d'analyse statistique des donnees, a fait l'objet de publication dans les actes du 9eme congres de l'IRNOP (International Research Network on Organising by Projects) en 2009 sous le titre : Â« The most critical success factors for World Bank projects : the Task Team Leaders' perspective Â». Ces deux versions different dans la mesure ou la seconde fait des analyses confirmatoires et teste ainsi la validite des instruments de mesure et du modele lui-meme). Dans ce deuxieme article, nous mettons d'abord en evidence la specificite des projets de developpement international, les problemes qu'ils posent, et les notions de succes, de critere et de facteur de succes tant dans la litterature de la gestion de projet que dans celle plus specifique de la gestion des projets de developpement international. Ensuite, nous posons des hypotheses sur les relations entre les FCS et les dimensions du succes des projets. Apres nous procedons a une analyse factorielle en composantes principales des criteres et des FCS avec le logiciel SPSS et nous analysons les interrelations entre FCS a l'aide des modeles d'equations structurel1es (estimees notamment avec le logiciel AMOS). Les resultats de ce deuxieme article confirment l'existence empirique d'un facteur de second-ordre que nous avons baptise Â« FCS relies a la gestion de projet Â» mais captant l'exercice global de supervision des projets. Les resultats empiriques montrent en outre que les FCS affectent de facon significativement differente les deux dimensions du succes des projets et que la premiere (le succes de la gestion) n'affecte pas significativement la deuxieme (le succes du livrable). Ils confirment aussi l'existence empirique de FCS non relies a la gestion de projet mais plutot relies au projet lui-meme comme le budget et l'experience du superviseur de projet et indiquent que ces derniers ne semblent pas avoir un effet sur les FCS relies a la gestion de projet (conception, suivi, coordination, et formation) mais captant l'exercice global de supervision des projets. Enfin ils suggerent que dans la perception des TTL, la hierarchie des FCS est la suivante : la conception, le suivi, la coordination et la formation dans cet ordre. Enfin, tres peu a ete ecrit sur la gestion de projet a l'intention des gestionnaires de projet du Tiers-Monde, notamment a l'intention des coordonnateurs africains des projets de developpement et la litterature est muette sur la facon d'adopter les outils et les techniques de gestion de projet importes. Quels sont les concepts, outils et techniques de gestion de projet que les gestionnaires africains des projets de developpement peuvent deployer? Quel est leur degre d'application actuelle? Sachant que la planification de projet reste un FCS, quelle est la force de la relation entre l'effort de planification et le succes des projets de developpement? Ce sont les questions qui sont abordees dans le dernier article : Â« Project management in the international development industry : the project coordinator's perspective Â». Il a ete publie dans la revue International Journal of Managing Projects in Business. Il met en evidence la perception des coordonnateurs de projets de developpement, en fait les gestionnaires de projet dans un secteur specifique et non-traditionnel de la gestion de projet, le developpement international, et analyse la relation empirique entre l'effort de gestion de projet dans la phase d'execution (le degre d'utilisation des outils de gestion de projet), le succes et les criteres de succes des projets. Dans ce dernier article, nous abordons l'importance des outils tant en gestion de projet en general qu'en gestion des projets de developpement en particulier. Nous proposons egalement un tableau synoptique des outils utilises dans la gestion des projets de developpement international que nous classons en trois grandes categories : les outils d'identification et de planification; les outils de realisation et de suivi; et les outils de mesure de performance, d'evaluation et de gouvernance. Nous donnons ensuite un bref apercu des travaux sur le succes et les criteres de succes avant de presenter et de discuter les resultats de l'analyse factorielle en composantes principales des outils de gestion de projet, et de l'analyse de correlation et de regression entre l'effort de gestion de projet et le succes. En somme, ce dernier article suggere que le succes des projets est insensible a l'effort de planification mais supporte de facon significative l'idee que le recours au suivi et a l'evaluation peut ameliorer les resultats des projets. 
______________________________________________________________________________ 
MOTS-CLES DE Lâ€™AUTEUR : aide au developpement, gestion de projet, criteres de succes, facteurs cles de succes, planification de projet, outils et techniques de gestion de projet, Banque mondiale, Afrique, Task Managers, coordonnateurs nationaux de projet, modele d'equations structurelles.",2011,
Un nuevo modelo predictivo basado en variables clÃ­nicas y en polimorfismos en genes de citocinas permite predecir la incidencia de EICR grave post-trasplante hematopoyÃ©tico alogÃ©nico,"El trasplante alogenico de progenitores hematopoyeticos (alo-TPH) es el tratamiento de eleccion para la curacion de enfermedades como las leucemias agudas y otras neoplasias hematologicas, inmunodeficiencias severas o errores congenitos del metabolismo y la enfermedad de injerto contra receptor (EICR), reaccion aloinmune de las celulas del donante contra celulas sanas de distintos tejidos del receptor, es una de las complicaciones mas relevantes post-TPH y la principal causa de morbilidad y mortalidad del mismo. Entre un 30 y un 50% de los pacientes que reciben un trasplante alogenico desarrollan la EICR pero el anticipar dicha complicacion sigue siendo un tema aun no resuelto. Hasta ahora se hace principalmente usando variables clinicas. Sin embargo, en los ultimos anos, se esta viendo tambien la importancia de las variables geneticas y, aunque la seleccion de donantes adecuados para el TPH se basa fundamentalmente en la compatibilidad del sistema HLA entre donante (D) y receptor (R), se esta estudiando la influencia de otros genes ya que aun en trasplantes HLA identicos se observan complicaciones como la EICR o el rechazo del injerto. La fisiopatologia de la EICR, se basa en una ?tormenta de citocinas? principalmente proinflamatorias originada en el R por efecto de los regimenes de acondicionamiento a la que se le anade la alorreactividad de los linfocitos T del D, que infiltran directamente diferentes organos produciendo el dano tisular.Las citocinas son moduladores proteicos de la respuesta inmune y, por tanto, influyen en la alorreactividad D/R tras el al-TPH y pueden determinar el exito del mismo.El objetivo del trabajo era analizar los polimorfismos geneticos que pueden tener impacto real en la incidencia de la EICR para establecer un modelo predictivo genetico y clinico para el desarrollo de la EICR post-TPH alogenico de D HLA identico familiar.La asociacion entre variables clinicas y geneticas en D y R con el desarrollo de la EICR aguda y la EICR cronica se estudio usando el analisis multivariante por regression penalizada de tipo LASSO y observamos que estos modelos eran muy utiles para anticipar la EICRa y la EICRc graves. Segun LASSO el mejor modelo clinico para anticipar la EICRa grados III-IV incluyo tres variables: el acondicionamiento, la irradiacion corporal total y el tipo de patologia y obtiene una tasa de clasificaciones correctas para los pacientes que van a desarrollar la EICR (TCC1) de un 50% y un VPN de 91,8%. Por otro lado el modelo clinico-genetico incluyo las mismas variables clinicas que el modelo clinico mas 11 citocinas (IL-1A, IL-1B, IL-2, IL-6, IL-7R, IL-10, IL-17A, IL-23R, INF?, TGFs y TNF?). Este modelo obtuvo una TCC1 del 100% y un VPN del 98,6%.El mejor modelo clinico para predecir la EICRc extensa incluyo la edad del R en el momento del trasplante, el sexo del R, la fuente de progenitores hematopoyeticos y el haber presentado antes del dia 100 la EICRa. Con este modelo se conseguia una TCC del 66.7% y un VPN del 82,9%. Cuando al modelo se le incluyeron las variables geneticas, las variables clinicas se mantuvieron y se le anadieron al modelo 8 citocinas (IL-1B, IL-2, IL-7R, IL-10, IL-17A, IL-23R, INF? y la TGFs) mejorando asi los resultados de la TCC1 con un 80% y un VPN del 85,1%.Basandonos en los resultados del coeficiente de regresion s de LASSO calculamos las ecuaciones de riesgo y con el valor de riesgo clasificamos a los pacientes en alto riesgo (mayor del punto de corte, Y=1) o bajo riesgo (menor al punto de corte). Los dos modelos clasifican bien pero clasifica mejor el modelo clinico-genetico con una significacion estadistica p < 0.001. En conclusion, los modelos predictivos con variables clinicas y geneticas estratifican mejor a los pacientes que los modelos exclusivamente clinicos y podrian permitir el manejo optimizado de las estrategias de inmunomodulacion post-TPH dirigidas a potenciar el efecto de injerto contra leucemia con el fin de minimizar el riesgo de recidiva.",2018,
L1 methods for shrinkage and correlation,"This dissertation explored the idea of L1 norm in solving two statistical problems including multiple linear regression and diagnostic checking in time series. In recent years L1 shrinkage methods have become popular in linear regression as they can achieve simultaneous variable selection and parameter estimation. Their objective functions containing a least squares term and an L1 penalty term which can produce sparse solutions (Fan and Li, 2001). Least absolute shrinkage and selection operator (Lasso) was the first L1 penalized method proposed and has been widely used in practice. But the Lasso estimator has noticeable bias and is inconsistent for variable selection. Zou (2006) proposed adaptive Lasso and proved its oracle properties under some regularity conditions. We investigate the performance of adaptive Lasso by applying it to the problem of multiple undocumented change-point detection in climate. Artificial factors such as relocation of weather stations, recalibration of measurement instruments and city growth can cause abrupt mean shifts in historical temperature data. These changes do not reflect the true atmospheric evolution and unfortunately are often undocumented due to various reasons. It is imperative to locate the occurrence of these abrupt mean shifts so that raw data can be adjusted to only display the true atmosphere evolution. We have built a special linear model which accounts for long-term temperature change (global warming) by linear trend and is featured by p = n (the number of variables equals the number of observations). We apply adaptive Lasso to estimate the underlying sparse model and allow the trend parameter to be unpenalized in the objective function. Bayesian Information Criterion (BIC) and the CM criterion (Caussinus and Mestre, 2004) are used to select the finalized model. Multivariate t simultaneous confidence intervals can post-select the change-points detected by adaptive Lasso to attenuate overestimation. Considering that the oracle properties of adaptive Lasso are obtained under the condition of linear independence between predictor variables, adaptive Lasso should be used with caution since",2013,
All-arthroscopic suprapectoral long head of biceps tendon tenodesis with interference screw-like tendon fixation after modified lasso-loop stitch tendon securing.,"Arthroscopic suprapectoral techniques for tenodesis of the long head of the biceps tendon (LHB) are appropriate for the treatment of proximal biceps lesions. Several types of techniques and fixation devices have been described and evaluated in biomechanical studies regarding primary stability. In this technical note, we describe an all-arthroscopic suprapectoral technique using the 6.25-mm Bio-SwiveLock device (Arthrex, Naples, FL) for an interference screw-like bony fixation after having armed the tendon with a lasso-loop stitch. Both the interference screw fixation and securing of the lasso-loop tendon have been well described and approved in biomechanical tests concerning the primary stability. One advantage of this technique performed from the glenohumeral space, in addition to the strong and secure fixation with ingrowth of the tendon in a bony canal, is the avoidance of touching the soft tissue above the bicipital groove, which results in a smooth fitting of the tendon into its natural canal and therefore avoids mechanical irritation of the stump at the rotator interval. In conclusion, the all-arthroscopic suprapectoral LHB tenodesis performed from the glenohumeral space with the modified lasso-loop stitch for securing of the tendon and the 6.25-mm Bio-SwiveLock suture anchor for interference screw-like bony tendon fixation is an appropriate technique for the treatment of LHB-associated lesions.",2012,Arthroscopy techniques
Graph Neural Lasso for Dynamic Network Regression,"In this paper, we will study the dynamic network regression problem, which focuses on inferring both individual entities' changing attribute values and the dynamic relationships among the entities in the network data simultaneously. To resolve the problem, a novel graph neural network, namely graph neural lasso (GNL), will be proposed in this paper. To model the real-time changes of nodes in the network, GNL extends gated diffusive unit (GDU) to the regression scenario and uses it as the basic neuron unit. GNL can effectively model the dynamic relationships among the nodes based on an attention mechanism.",2019,ArXiv
Linking 2D Harris matrix with 3D stratigraphic visualisations : an integrated approach to archaeological documentation,"This paper will present the first results of a new approach to recording and visualising archaeological excavations using integrated 3D and Harris Matrix data entry, query and visualisations tools. Accurate records of stratigraphie sequences in an archaeological excavation are crucial for post-excavation analysis. Traditional recording techniques capture 2D or 2.5D surface plans ofstratigraphic units. Relationships between units are recorded and the sequence is visualised as a 2D abstract model, the Harris Matrix. Several software tools have been developed to assist in this task, replacing earlier time-consuming and error-prone paper-based methods. Recent progress in photogramtnetry and other 3D recording techniques has also made it po.ssible to visualise excavated layers in a 3D space. Computer technology has thus developed to incorporate photogrammetric models, enabling archaeologists to view and analyse excavations within the 3D world in which they work. A review of existing tools has shown that whilst each approach to visualising excavated layers has particular strengths, individually they do not provide a level ofunder.itanding that is required for a 'complete picture \ A computer generated Harris Matrix diagram is essential for understanding stratigraphie relationships, whilst a 3D model is extremely effective for the visual comparison of the form and structural relationships of these layers. We conclude that 2D abstract models and 3D views provide different, but complementaiy, benefits in the analysis of an archaeological excavation. For archaeologists to significantly benefit from both of these tools, we believe that linked 2D and 3D views should be available This paper describes a first attempt to provide such linking. Two tools providing suitable visualisations are the jnet graph tool and the Stratigraphie Visualisation Tool (STRAT). Jnet is a 2D Harris Matrix tool that allows the user to analyse stratigraphie relationships between layers and manipulate data. The STRA T tool is a 3D world in which archaeologists can navigate and explore in detail the layers of an excavation. The integration tool uses XML to communicate between jnet and STRAT providing a standard description method to facilitate the data exchange. XML is the native data format for jnet, so it provides seamless software mapping between the two tools. Import aitd export software incorporated within both STRAT and jnet transforms and stores this data in a structure suitable for exchange between the 2D (jnet) and 3D (STRAT) applications. The result of this software solution is a flexible composite software tool allowing t^vo different views of a site, which archaeologists can use to model, view and analyse their excavations more effectively A test excavation was carried out in Sagalassos (Turkey) in the summer of 2004. After documenting and registering the .stratigraphie data on site, it was entered into the new tool. Sections of a Harris Matrix, such as a particular trench, can be viewed to establish relationships between strata. Navigation in 3D within a trench permits viewing from all angles and replaying through the stratigraphie sequence. The results, presented in this paper show the high potential of this approach for future archaeological research.",2005,
Avalon: towards QoS awareness and improved utilization through multi-resource management in datacenters,"Existing techniques for improving datacenter utilization while guaranteeing the QoS are based on the assumption that queries have similar behaviors. However, user queries in emerging compute demanding services demonstrate significantly diverse behavior and require adaptive parallelism. Our study shows that the end-to-end latency of the compute demanding query is determined together by the system-wide load, its workload, its parallelism, contention on shared cache, and memory bandwidth. When hosting such new services, the current cross-query resource allocation results in either severe QoS violation or significant resource under-utilization. To maximize hardware utilization while guaranteeing the QoS, we present Avalon, a runtime system that independently allocates shared resources for each query. Avalon first provides an automatic feature identification tool based on Lasso regression, to identify features that are relevant to a query's performance. Then, it establishes models that can precisely predict a query's duration under various resource configurations. Based on the accurate prediction model, Avalon proactively allocates ""just-enough"" cores and shared cache spaces to each query, so that the remaining resource can be assigned to execute best-effort applications. During runtime, Avalon monitors the progress of each query and mitigates any possible QoS violation due to memory bandwidth contention, occasional I/O contention, or unpredictable system interference. Our results show that Avalon improves utilization by 28.9% on average compared with state-of-the-art techniques while achieving 99%-ile latency target.",2019,Proceedings of the ACM International Conference on Supercomputing
Insuffisance aortique syphilitique: Ã  propos dâ€™un cas,"La syphilis tertiaire et ses complications cardiovasculaires sont devenues rares dans les pays developpes mais restent encore preoccupante dans nos pays. Les atteintes cardiovasculaires portent frequemment sur la racine et lâ€™arche aortique. Nous rapportons ici un cas dâ€™insuffisance aortique syphilitique chez un patient de 70 ans admis dans le service de cardiologie du centre hospitalier universitaire de Bobo-Dioulasso. Lâ€™examen clinique retrouvait une insuffisance cardiaque globale stade III, un fremissement et un souffle diastolique dâ€™insuffisance aortique importante confirme a lâ€™echocardiographie Doppler, associes a des douleurs precordiales angineuses. Lâ€™examen cutane montrait des lesions a type de gommes syphilitiques a localisations multiples. Lâ€™electrocardiogramme objectivait une hypertrophie ventriculaire gauche avec un indice de Sokolov a 49 millimetre et le telecoeur une cardiomegalie avec un index cardio-thoracique a 0,70. La serologie etait positive pour le RPR a 1/8 et le TPHA a 1/640. Lâ€™evolution clinique sous la penicillino-therapie surveillee et le traitement specifique de lâ€™insuffisance cardiaque a ete favorable. La decouverte dâ€™une insuffisance aortique chez les sujets de plus de 60 ans dans nos pays devrait faire rechercher une syphilis tertiaire par une serologie pour une prise en charge adequate.",2012,The Pan African Medical Journal
Pileup Correction Algorithm using an Iterated Sparse Reconstruction Method,"Every radioactive source can be characterized by an histogram obtained after collecting the energies of photons emitted from the source, also called energy spectrum. However, when the activity of this source is high, a physical phenomenon known as the pile-up effect distorts direct measurements, resulting in a significant distortion of the energy spectrum. We suggest in this letter an iterative algorithm to attenuate the pile-up effect and enhance the resulting energy spectra. It is based on iterations of a post-processed, non-negative, version of the Least Absolute Shrinkage and Selection Operator (LASSO). Results on simulations and real data illustrate the improvement obtained by the proposed method.",2015,IEEE Signal Processing Letters
Development and Validation of a Nomogram for Preoperative Prediction of Perineural Invasion in Colorectal Cancer,"BACKGROUND In colorectal cancer (CRC), perineural invasion (PNI) is usually identified histologically in biopsy or resection specimens and is considered a high-risk feature for recurrence of CRC and is an indicator for adjuvant therapy. Preoperative identification of PNI could help determine the need for adjuvant therapy and the approach to surgical resection. This study aimed to develop and validate a nomogram for the preoperative prediction of PNI in patients with CRC. MATERIAL AND METHODS A total of 664 patients with CRC from a single center were classified into a training dataset (n=468) and a validation dataset (n=196). The least absolute shrinkage and selection operator (LASSO) regression model was used to select potentially relevant features. Multivariate logistic regression analysis was used to develop the nomogram. The performance of the nomogram was assessed based on its calibration, discrimination, and clinical utility. RESULTS The nomogram consisted of five clinical features and provided good calibration and discrimination in the training dataset, with an area under the curve (AUC) of 0.704 (95% CI, 0.657-0.751). Application of the nomogram in the validation cohort showed acceptable discrimination, with the AUC of 0.692 (95% CI, 0.617-0.766) and good calibration. Decision curve analysis (DCA) showed that the nomogram was clinically useful. CONCLUSIONS The nomogram developed in this study might allow clinicians to predict the risk of PNI in patients with CRC preoperatively. The nomogram showed favorable discrimination and calibration values, which may help optimize preoperative treatment decision-making for patients with CRC.",2019,Medical Science Monitor : International Medical Journal of Experimental and Clinical Research
Encefalocolassoterapia chirurgica nelle epilessie,"RiassuntoL'esplorazione radiografica degli spazi sottodurali con il metodo diPenfield s'Ã¨ rilevata negli epilettici particolarmente benefica, specie negli affetti da â€žstatus epiletticusâ€œ; poco efficace, invece, in quelli â€žda piccolo maleâ€œ.Il metodo consiste nel praticare un foro di trapanazione frontale con apertura della dura senza ledere l'aracnoide e nel procedere ad una puntura lombare; si ha allora rapido svuotamento degli spazi sottoaracnoidei e dei ventricoli con collasso del cervello.L'A. pratica questo metodo da 13 anni con ottimi risultati e data la sua innocuitÃ  la suggerisce in attesa del metodo elettivo. Il suo meccanismo d'azione Ã¨ dovuto ai fenomeni secondarii (edema e congestione) cui darebbe luogo, meccanismo del resto anologo agli altri interventi antiepilettici.ZusammenfassungDie radiographische Erforschung des Subduralraumes nachPenfields Methode hat sich bei Epileptikern als besonders erfolgreich erwiesen, hauptsÃ¤chlich beim â€žstatus epilepticusâ€œ; dagegen ist sie beim â€žpetit malâ€œ wenig aufschluÃŸreich. Die Methode besteht darin, ein frontales Bohrloch mit ErÃ¶ffnung der Dura zu machen, ohne die Arachnoidea zu verletzen und eine Lumbaipunktion vorzunehmen; auf diese Weise erzielt man eine rasche Entleerung des Subarachnoidalraumes und der Ventrikel mit einem Gehirnkollaps.Der Verfasser verwendet diese Methode seit 13 Jahren mit glÃ¤nzendem Erfolg und empfiehlt sie wegen ihrer UnschÃ¤dlichkeit.SummaryThe radiographic exploration of the subdural space withPenfield's method has proved to be especially beneficent by epileptics, particularly in the â€žstatus epilepticusâ€œ; it is less efficacious, however, in â€žpetit malâ€œ. The method consists in making a frontal drill hole and opening the dura without injuring the arachnoid and in making a lumbar puncture; in this way we obtain a rapid emptying of the subarachnoid space and of the ventricles with a brain collapse. The author uses this method since 13 years with excellent results and owing to its harmlessness, he suggests it while looking forward to another elective method.RÃ©sumÃ©L'exploration radiographique de l'espace sous-dural par la mÃ©thode dePenfield s'est montrÃ©e particuliÃ¨rement utile chez les Ã©pileptiques et sourtout dans les Ã©tats Ã©pileptiques. Un trou de trÃ©panation pratiquÃ© dans la rÃ©gion frontale et la dure-mÃ¨re ouverte de faÃ§on que l'arachnoÃ¯de reste intacte, une ponction lombaire procurera un collapse du cerveau rapide en vertu de l'Ã©vacuation de l'espace sous-arachnoÃ¯dal et des ventricules cÃ©rÃ©braux.A la base de son expÃ©rience de 13 ans, l'auteur recommande vivement la mÃ©thode en question qui se distingue par son caractÃ¨re inoffensif et les rÃ©sultats brillants.ResumenEl estudio radiografico de los espacios subdurales, siguiendo el mÃ©todo dePenfield, se ha mostrado beneficioso en los epilÃ©pticos. Sobre todo en el â€žstatus epilepticusâ€œ, obteniÃ©ndose en cambio menos datos en el â€žpetit malâ€œ. El mÃ©todo consiste en practicar un trÃ©pano frontal con abertura de la dura y sin lesionar la aracnoides, al mismo tiempo que se practica una puncion lumbar. De este modo se consigue un rÃ¡pido vaciamiento de los espacios subaracnoideos y de los ventriculos y el colapso cerebral consiguiente.El autor emplea este mÃ©todo hace 13 aÃ±os con resultados excelentes y lo recomienda por su inocuidad.",2005,Acta Neurochirurgica
Structures de dÃ©pendance complexes pour modÃ¨les Ã  composantes supervisÃ©es,"Une forte redondance des variables explicatives cause de gros problemes d'identifiabilite et d'instabilite des coefficients dans les modeles de regression. Meme lorsque l'estimation est possible, l'interpretation des resultats est donc extremement delicate. Il est alors indispensable de combiner a leur vraisemblance un critere supplementaire qui regularise l'estimateur. Dans le sillage de la regression PLS, la strategie de regularisation que nous considerons dans cette these est fondee sur l'extraction de composantes supervisees. Contraintes a l'orthogonalite entre elles, ces composantes doivent non seulement capturer l'information structurelle des variables explicatives, mais aussi predire autant que possible les variables reponses, qui peuvent etre de types divers (continues ou discretes, quantitatives, ordinales ou nominales). La regression sur composantes supervisees a ete developpee pour les GLMs multivaries, mais n'a jusqu'alors concerne que des modeles a observations independantes.
Or dans de nombreuses situations, les observations sont groupees. Nous proposons une extension de la methode aux GLMMs multivaries, pour lesquels les correlations intra-groupes sont modelisees au moyen d'effets aleatoires. A chaque etape de l'algorithme de Schall permettant l'estimation du GLMM, nous procedons a la regularisation du modele par l'extraction de composantes maximisant un compromis entre qualite d'ajustement et pertinence structurelle. Compare a la regularisation par penalisation de type ridge ou LASSO, nous montrons sur donnees simulees que notre methode non seulement permet de reveler les dimensions explicatives les plus importantes pour l'ensemble des reponses, mais fournit souvent une meilleure prediction. La methode est aussi evaluee sur donnees reelles.
Nous developpons enfin des methodes de regularisation dans le contexte specifique des donnees de panel (impliquant des mesures repetees sur differents individus aux memes dates). Deux effets aleatoires sont introduits : le premier modelise la dependance des mesures relatives a un meme individu, tandis que le second modelise un effet propre au temps (possedant donc une certaine inertie) partage par tous les individus. Pour des reponses Gaussiennes, nous proposons d'abord un algorithme EM pour maximiser la vraisemblance du modele penalisee par la norme L2 des coefficients de regression. Puis nous proposons une alternative consistant a donner une prime aux directions les plus ""fortes"" de l'ensemble des predicteurs. Une extension de ces approches est egalement proposee pour des donnees non-Gaussiennes, et des tests comparatifs sont effectues sur donnees Poissonniennes.",2019,
Hyperalgesic acetabular fracture treated by transversus abdominis plane block in the ED.,"Chest 2008;133(Suppl):454S-545S. [16] TorbickiA, PerrierA,Konstantinides S, et al. Guidelines on the diagnosis and management of acute pulmonary embolism: the Task Force for the Diagnosis and Management of Acute Pulmonary Embolism of the European Society of Cardiology (ESC). Eur Heart J 2008;29:2276-315. [17] Erkens PMG, Prins MH. Fixed dose subcutaneous low molecular weight heparins versus adjusted dose unfractionated heparin for venous thromboembolism. Cochrane Database Syst Rev 2010(9): CD001100. [18] AttinÃ  D, Valentino M, GaliÃ¨ N, Modolon C, Buia F, de Luca F, et al. Application of a new pulmonary artery obstruction score in the prognostic evaluation of acute pulmonary embolism: comparison with clinical and haemodynamic parameters. Radiol Med 2011;116:230-45. [19] JimÃ©nez D, Aujesky D, DÃ­az G, et al. RIETE Investigators. Prognostic significance of deep vein thrombosis in patients presenting with acute symptomatic pulmonary embolism. Am J Respir Crit Care Med 2010; 181:983-91. [20] Ahlehoff O, Gislasson GH, Torp-Pedersen C, et al. Risk assessment for recurrent venous thrombosis. Lancet 2011;377(9771):1073. [21] Kyrle PA, Rosendaal FR, Eichinger S. Risk assessment for recurrent venous thrombosis. Lancet 2010;376(9757):2032-9. [22] KaczyÅ„ska A, Kostrubiec M, Pacho R, et al. Elevated D-dimer concentration identifies patients with incomplete recanalization of pulmonary artery thromboemboli despite 6 months anticoagulation after the first episode of acute pulmonary embolism. Thromb Res 2008;122:21-5. [23] Romera A, Cairols MA, Vila-Coll R, et al. A randomised open-label trial comparing long-term sub-cutaneous low-molecular-weight heparin compared with oral-anticoagulant therapy in the treatment of deep venous thrombosis. Eur J Vasc Endovasc Surg 2009;37:349-56. [24] Hull RD, Liang J, Townshend G. Long-term low-molecular-weight heparin and the post-thrombotic syndrome: a systematic review. Am J Med 2011;124:756-65. [25] Iorio A, Guercini F, Pini M. Low-molecular-weight heparin for the long-term treatment of symptomatic venous thromboembolism: metaanalysis of the randomized comparisons with oral anticoagulants. J Thromb Haemost 2003;1:1906-13. [26] Castro DJ, DÃ­az G, MartÃ­ D, et al. Monotherapy with enoxaparin for the prevention of recurrent venous thromboembolism. Blood Coagul Fibrinolysis 2007;18:173-7. [27] Van der Heijden JF, Hutten BA, Bueller HR, et al. Vitamin K antagonists or low-molecular-weight heparin for the long-term treatment of symptomatic venous thromboembolism (Cochrane Review). The Cochrane Library, Issue 4. Chichester: John Wiley & Sons, Ltd; 2004.",2012,The American journal of emergency medicine
Toxicogenomic prediction with group sparse regularization based on transcription factor network information,"Regression analysis such as linear regression and logistic regression has often been employed to construct toxicogenomic predictive models, which forecast toxicological effects of chemical compounds in human or animals based on gene expression data. While in general these techniques can generate an accurate and sparse model when a regularization term is added to a loss function, they ignore structural relationships behind genes which form vast regulatory networks and interact with each other. Recently, several reports proposed structured sparsity-inducing norms to incorporate prior structural information and make a model reflecting relationships between variables. In this study, assuming that genes regulated by the same transcription factor should be selected together, we applied the latent group Lasso technique on toxicogenomic data with transcription factor networks as prior knowledge. We compared generated classifiers for liver weight gain in rats between the latent group Lasso and Lasso. The latent group Lasso was comparable or superior to the Lasso in terms of predictive performances (balanced accuracy: 74% vs. 72%, sensitivity: 62% vs. 62%, specificity: 86% vs. 83%). Besides, groups selected by the latent group Lasso suggested involvement of Wnt/Î²-catenin signaling pathway. Such mechanism-related analysis could not have been possible with the Lasso and is one of the advantages of the latent group Lasso.",2015,Fundamental Toxicological Sciences
Thesis for the Degree of Doctor of Philosophy Parameter Estimation and Filtering Using Sparse Modeling,"Sparsity-based estimation techniques deal with the problem of retrieving a data vector from an undercomplete set of linear observations, when the data vector is known to have few nonzero elements with unknown positions. It is also known as the atomic decomposition problem, and has been carefully studied in the field of compressed sensing. Recent findings have led to a method called basis pursuit, also known as Least Absolute Shrinkage and Selection Operator (LASSO), as a numerically reliable sparsity-based approach. Although the atomic decomposition problem is generally NPhard, it has been shown that basis pursuit may provide exact solutions under certain assumptions. This has led to an extensive study of signals with sparse representation in different domains, providing a new general insight into signal processing. This thesis further investigates the role of sparsity-based techniques, especially basis pursuit, for solving parameter estimation problems. The relation between atomic decomposition and parameter estimation problems under a so-called separable model has also led to the application of basis pursuit to these problems. Although simulation results suggest a desirable trend in the behavior of parameter estimation by basis pursuit, a satisfactory analysis is still missing. The analysis of basis pursuit has been found difficult for several reasons, also related to its implementation. The role of the regularization parameter and discretization are common issues. Moreover, the analysis of estimates with a variable order, in this case, is not reducible to multiple fixed-order analysis. In addition to implementation and analysis, the Bayesian aspects of basis pursuit and combining prior information have not been thoroughly discussed in the context of parameter estimation. In the research presented in this thesis, we provide methods to overcome the above difficulties in implementing basis pursuit for parameter estimation. In particular, the regularization parameter selection problem and the so-called off-grid effect is addressed. We develop numerically stable algorithms to avoid discretization and study homotopy-based solutions for complex-valued problems. We use our continuous estimation algorithm, as a framework to analyze the basis pursuit. Moreover, we introduce finite set based mathematical tools to perform the analysis. Finally, we study the Bayesian aspects of basis pursuit. In particular, we introduce and study a recursive Bayesian filter for tracking the sparsity pattern in a variable",2015,
"Vereine, Anstalten, Unternehmungen","konnto. Ich ersucho darum Fround Btocki dringend, mir das (7. Pseudoaristatum aus Schur 's tterbaro zu senden, dann werde ich die Frago gem beleuchten und eiues der zwei yon mir genannten Galien mit dem S ehur'schen verbinden, wenn die botanischen Gesetze dieses verlangen sollton. Uebrigens kann man die S ebur'sche Art nicht so leicht mit einer anderen vereinigen, denn die Arten Schur 's sind nieht immer klar beschrieben und sehr oft widerspricht die Originalpfianzo tier Beschreibung Schur's. Quercus pallida H euff. und Q~u. pall. PanS. sind nieht gut gewahlte Namen. Letztere ist eino Q~. hungarica Hub. mit langor gestielton und blasson Bliittern und Qu. pallida Heuff. ~ Qu. pubescens ear. #labrata Houff. , aber Qu. glabrata kann sic nieht heissen, denn dieser Name wurde viel eher yon Gussono, spiiter auch yon Schur andoron Q~uercus-Formen gegobon, deswegen benannte ich sie in Term. tud. K6zl. 1886. Aug. p. 353 Qu. tridactyla m., dean die drei oborsten Lappen der Blatter sind fingerfSrmig verlangert, v. B o r b ~ s.",2005,Ã–sterreichische botanische Zeitschrift
Headlight of a motor vehicle,"Headlamp (1, 1 ') of a motor vehicle, comprising a housing (2), comprising a ventilation system with a housing (2) provided for the air inlet (4) and a provided on the housing air outlet (5) and with a hose (7) as an air supply line (6) to the air inlet (4) 'is arranged, as a filter (9, 9 which in the course of the air supply line (6) and / or at the end of which a filter (9, 9)') is a substantially radially symmetrical about a longitudinal axis (14) constructed cyclone filter (9, 9 ') is provided, wherein the cyclone filter (9, 9') has an inflow portion (11) having a centrally located on the longitudinal axis (14) of the filter (9, 9 ') arranged inlet opening (12) a blade (16) comprising swirler (15), adapted to generate a circular flow of air passing through the inflow section (11) the supplied air in the outer region of the filter (9, 9 ') in a discharge section (21) and the outflow (21) arranged with one on the longitudinal axis (14) Au slassoffnung (27) for filtered air and at least one outside of the filter (9, 9 ') arranged ...",2008,
Study of Wine Evaluation Based on Lasso Regression,"Appraisal of quality is a crucial link in wine industry. At present, appraisal of wine quality mainly relies on sensory evaluation method, which may derive subjective biases. It shows particular importance for an establishment of objective and reasonable wine evaluation system to regulate the wine market. In this paper, after identifying the existence of multicollinearity of the physicochemical indicators of grape and liquor, Lasso regression is employed to build an evaluation model. Corresponding to the physicochemical indicators, this model is set up from four aspects: appearance, taste, aroma and overall balance. Lasso regression is used in each aspect. Weighted sum of the four aspects, overall assessment of the wine is obtained. As a conclusion, the new wine evaluation system is more objective and credible, thus it can substitute for sensory evaluation methods.",2013,
A Selection Operator for Summary Association Statistics Reveals Allelic Heterogeneity of Complex Traits,"In recent years, as a secondary analysis in genome-wide association studies (GWASs), conditional and joint multiple-SNP analysis (GCTA-COJO) has been successful in allowing the discovery of additional association signals within detected loci. This suggests that many loci mapped in GWASs harbor more than a single causal variant. In order to interpret the underlying mechanism regulating a complex trait of interest in each discovered locus, researchers must assess the magnitude of allelic heterogeneity within the locus. We developed a penalized selection operator for jointly analyzing multiple variants (SOJO) within each mapped locus on the basis of LASSO (least absolute shrinkage and selection operator) regression derived from summary association statistics. We found that, compared to stepwise conditional multiple-SNP analysis, SOJO provided better sensitivity and specificity in predicting the number of alleles associated with complex traits in each locus. SOJO suggested causal variants potentially missed by GCTA-COJO. Compared to using top variants from genome-wide significant loci in GWAS, using SOJO increased the proportion of variance prediction for height by 65% without additional discovery samples or additional loci in the genome. Our empirical results indicate that human height is not only a highly polygenic trait, but also has high allelic heterogeneity within its established hundreds of loci.",2017,American Journal of Human Genetics
"Lasso's Music for Shakespeare's ""Samingo""","N i570 the publishing house of Le Roy and Ballard offered in Paris a collection entitled Mellange d'Orlande de Lassus, conk .vAdtenant plusieurs chansons . . . containing, in fact, some of Lasso's most popular songs. A number of these had been published earlier, but it was the Mellange of i570 (and the subsequent editions of I576 and i586, by the same publisher) that enjoyed a singularly wide distribution both in continental Europe and England. In the collection we meet such perennial favorites as ""Susanne un jour"", ""Mon coeur se recommande a vous"", ""Bon jour, mon coeur"", and, of primary importance to this article, ""Un jour vis un foulon"", which found its way into Shakespeare's 2 Henry IV under the title ""Samingo"", a contraction of ""Sir Mingo"" or ""Mounsier Mingo"". In accordance with the custom of the time the work was published in partbooks, of which a handsome set, bound in five volumes, survives in the British Museum. The Museum holds, in addition, parts of the second and third editions. I. In tracing the course of Silence's song we meet, first of all, its treble part in the Mellange of i570, f. 4v. This treble part forms the basis of the music example at the end of this article; the text runs as follows:",1958,Shakespeare Quarterly
HIV-associated follicular bronchiolitis.,"A 38-year-old African American, HIV-positive man (CD4 count, 347 cells/ml; viral load, 633,000 copies/ml), having never received highly active antiretroviral therapy, presented with several months of nonproductive cough. He had no other past medical history. Computed tomography of the chest (Figure 1) demonstrated innumerable miliary nodules. Bronchoalveolar lavage (BAL) was performed and contained 71% neutrophils, 13% lymphocytes, and 12% alveolar macrophages. Flow cytometry was not performed. Bacterial, acid-fast bacilli, and fungal smears were negative, and no organisms grew on culture. Pneumocystis carinii pneumonia direct fluorescence antibody and respiratory virus polymerase chain reaction were also negative. An open-lung biopsy specimen stained with hematoxylin and eosin (Figure 2; Figure E1 in the online supplement) showed hyperplastic peribronchovascular lymphoid follicles, follicular bronchiolitis. Bacterial, acid-fast bacilli, and fungal cultures of the biopsy specimen were without growth. Follicular bronchiolitis, like lymphoid interstitial pneumonia, is a rare HIV-associated lung disease characterized by bronchialassociated lymphoid tissue hyperplasia (1), thought due to repetitive antigen stimulation and polyclonal lymphoid expansion (2). When associated with follicular bronchiolitis, this histopathological pattern is limited to the peribronchiole area, whereas in lymphoid interstitial pneumonia it extends into the interstitium. It has been described in both HIV-positive children and adults (3, 4). Computed tomography invariably shows small (,3 mm) centrilobular nodules and often demonstrates peribronchial nodules (5). The differential diagnosis includes miliary tuberculosis, disseminated fungal disease, viral pneumonia, and less likely metastases from cancer. Prognosis varies; however, it can resolve with highly active antiretroviral therapy (3). In our patientâ€™s case, atazanavir, ritonavir, and tenofovir/emtricitabine were begun prior to discharge. At a 6-month follow-up, our patientâ€™s viral load had become undetectable, his CD4 count had improved, and his cough had resolved. The pulmonary nodules found in cases of follicular bronchiolitis can resolve after HIV treatment is commenced; however, the timeliness of this resolution is unknown (4). Repeat imaging in this patientâ€™s case was not performed. Figure 1. Computed tomography of the chest revealing innumerable 2to 3-mm miliary nodules.",2013,American journal of respiratory and critical care medicine
The identification of an active fault by a multidisciplinary study at the archaeological site of Sagalassos (SW Turkey),"Abstract The archaeological site of Sagalassos (SW Turkey) is located in a region characterized by the absence of any significant recent seismic activity, contrary to adjacent regions. However, the assessment of earthquake-related damage at the site suggests that the earthquakes that have been demonstrated to have struck this Pisidian city in ca. AD 500 and in the middle or second half of the 7th century AD are characterized by an MSK intensity of at least VIII and occurred on a fault very close to the city. Different investigation techniques (archaeoseismology, remote sensing and geomorphology, surface geology and structural data, 2D resistivity imaging and palaeoseismological trenching) have been applied at the archaeological site and its direct surroundings in search for the causative fault of these earthquakes. This multidisciplinary approach shows that each of the different approaches independently provides only partial, non-conclusive information with respect to the fault identification. Integration is imperative to give a conclusive answer in the search for the causative fault. This study has, indeed, revealed the existence of a to date unknown active normal fault system passing underneath ancient Sagalassos, i.e. the Sagalassos fault. A historical coseismic surface rupture event on this fault could be identified. This event possibly corresponds to the devastating Sagalassos earthquakes of ca. AD 500 and the middle or second half of the 7th century AD. Finally, this study demonstrates that in the particular geodynamic setting of SW Turkey archaeological sites with extensive earthquake-related damage form an important tool in any attempt to asses the seismic hazard.",2006,Tectonophysics
Bayesian Penalized Regression,"We consider ordinary least squares, lasso, bridge, and ridge regression methods under a unified framework. The particular method is determined by the form of the penalty term, which is typically chosen by cross validation. We introduce a fully Bayesian approach which allows selection of the penalty through posterior inference if desired. We also show how to use a type of model averaging approach to eliminate the nuisance penalty parameters and perform inference through the marginal posterior distribution of the regression coefficients. We develop a component-wise Markov chain Monte Carlo algorithm for sampling and establish conditional and marginal posterior consistency for the Bayesian model. Numerical results show that the method tends to select the optimal penalty and performs well in both variable selection and prediction. Both simulated and real data examples are provided.",2017,
Waarom diffuus licht werkt en wat we niet weten,"Diffuus maken van licht zorgt voor meer opbrengst. Dat is al in diverse onderzoeken bewezen en diffuse glassoorten en coatings rukken op in de tuinbouw. Het begrip ijlt na. Er zijn duidelijke plantkundige redenen aan te wijzen waarom de productie hoger ligt, maar er zitten ook gaten in de inzichten.",2013,
Sparse Algorithms Are Not Stable,"We consider two desired properties of learning algorithms: sparsity and algorithmic stability. Both properties are believed to lead to good generalization ability. We show that these two properties are fundamentally at odds with each other: A sparse algorithm cannot be stable and vice versa. Thus, one has to trade off sparsity and stability in designing a learning algorithm. In particular, our general result implies that '1-regularized regression (Lasso) cannot be stable, while '2-regularized regression is known to have strong stability properties and is therefore not sparse. Index Termsâ€”Stability, sparsity, Lasso, regularization.",2012,
Genomic Selection for Drought Tolerance Using Genome-Wide SNPs in Maize,"Traditional breeding strategies for selecting superior genotypes depending on phenotypic traits have proven to be of limited success, as this direct selection is hindered by low heritability, genetic interactions such as epistasis, environmental-genotype interactions, and polygenic effects. With the advent of new genomic tools, breeders have paved a way for selecting superior breeds. Genomic selection (GS) has emerged as one of the most important approaches for predicting genotype performance. Here, we tested the breeding values of 240 maize subtropical lines phenotyped for drought at different environments using 29,619 cured SNPs. Prediction accuracies of seven genomic selection models (ridge regression, LASSO, elastic net, random forest, reproducing kernel Hilbert space, Bayes A and Bayes B) were tested for their agronomic traits. Though prediction accuracies of Bayes B, Bayes A and RKHS were comparable, Bayes B outperformed the other models by predicting highest Pearson correlation coefficient in all three environments. From Bayes B, a set of the top 1053 significant SNPs with higher marker effects was selected across all datasets to validate the genes and QTLs. Out of these 1053 SNPs, 77 SNPs associated with 10 drought-responsive transcription factors. These transcription factors were associated with different physiological and molecular functions (stomatal closure, root development, hormonal signaling and photosynthesis). Of several models, Bayes B has been shown to have the highest level of prediction accuracy for our data sets. Our experiments also highlighted several SNPs based on their performance and relative importance to drought tolerance. The result of our experiments is important for the selection of superior genotypes and candidate genes for breeding drought-tolerant maize hybrids.",2017,Frontiers in Plant Science
Verlasso Salmon Will Be At The International Boston Seafood Show | Verlasso,"After you swing by booth #1433 to meet our Verlasso Premium Farmed Salmon Team, here are some fun things to do while youâ€™re in Boston for IBSS.",2013,
Alternative Penalty Functions for Penalized Likelihood Principal Components,"ABSTRACT The penalized likelihood principal component method of Park (2005) offers flexibility in the choice of the penalty function. This flexibility allows the method to be tailored to enhance interpretation in special cases. Of particular interest is a penalty function in the style of the Lasso that can be used to produce exactly zero loadings. Also of interest is a penalty function for cases in which interpretability is best represented by alignment with orthogonal subspaces, rather than with axis directions. In each case, a data example is presented.",2007,Journal of Applied Statistics
Positron probing of the micellar template interior in MCM-41,"AbstractThepropertiesofpositroniumannihilatinginthemicellartemplateinMCM-41materialswereinvestigated.Foralkyltrimethylammoniumbromidesurfactants(C n Â¼ 14;16;18)thetemplateinteriorisliquid-like;thebubblemodelofpositronium,elaboratedforbulkliquids,canbeapplied.Theequivalentsurfacetensionislinearlydependentontemperature,likeinclassicliquids.Averylong-livedcomponentino-Pslifetimespectrum( 20ns)canbeascribedtoo-Psincracksintheelongatedtemplatestructure. 2003ElsevierScienceB.V.Allrightsreserved. 1. IntroductionSurfactantmoleculescanclustertogetherasmicelles,whichareformedabovethecriticalcon-centrationandabovecertaintemperature(Kraï¬€ttemperature).Inconcentratedsolutions,themi-cellesformedfromsurfactantmoleculesmayas-sume the shape of long cylinders. Nuclearmagneticresonanceshowsthatthehydrocarbontails inside the micelles are mobile (mobilityslightlymorerestrictedthaninthebulk)andthemicelleinteriorbehaveslikealiquidmedium[1].Since1992anewclassoforderedmesoporoussilicamaterialswassynthetized:micelletemplatedsilicas(MTSs).ThemostpopularrepresentativeofthesesorbentsisMCM-41,synthetizedfromthemicellesofasurfactantwhichonadditionofaninorganicreactant,reorganizethemselvesintoamesomorphichexagonalstructure;thecylindricalmicellesinthesolutionbecomecoveredwithsilicalayerabout1-nmthick.Themicellarcore(tem-plate)canberemovedbycalcinationathightemperature,creatinginthiswayaporoushon-eycomb-likestructure;theporesizeisadjustablebychangingthealkylchainlengthandcomposi-tionofthesurfactant.Themicellesformedinthesolutionarethusencapsulatedinsilica.Afterdryingtheproducttheyremainasaï¬llerofthesilicaskeleton.Wefounditinterestingtostudyhowfartheanalogybetweenthemicelleinteriorandbulkyliquidphaseispreservedinsuchadry system.Asaprobe,easilypenetratingthestructure,weusedpositrons,morepreciselyâ€“theelectronâ€“positronboundstatecalledpositronium.Therearesomepapersaboutpositronsinmicellarsystems[2â€“6],",2003,Chemical Physics Letters
Autism and depression are connected: A report of two complimentary network studies,"Autism and depression often co-occur. Through network analysis, we seek to gain a better understanding of this co-occurrence by investigating whether (1) autism and depression share overlapping groups of symptoms and/or (2) are connected through a bridge of mastery or worry symptoms. This is addressed in two complimentary studies: (1) Study 1 focusing on depressed (Nâ€‰=â€‰258) and non-depressed adults (Nâ€‰=â€‰117), aged 60-90 years; (2) Study 2 focusing on autistic (Nâ€‰=â€‰173) and non-autistic adults (Nâ€‰=â€‰70), aged 31-89â€‰years. Self-report questionnaire data were collected on autistic traits (AQ-28), depression symptoms (Study 1: Inventory of Depressive Symptomatology Self Report; Study 2: Symptom Checklist 90-Revised depression subscale), worry (Worry Scale-R) and mastery (the Pearlin Mastery Scale). For both studies, data were analysed by creating glasso networks and subsequent centrality analyses to identify the most influential variables in the respective networks. Both depressed and autistic adults are highly similar in the perceived amount of worries and lack of control. While caution is needed when interpreting the pattern of findings given the bootstrapping results, findings from both studies indicate that overlapping symptoms do not fully explain the co-occurrence of autism and depression and the perception of having control over your life, that is, mastery seems a relevant factor in connecting autism and depression.",2019,Autism
Chapter 7 â€“ Regression,"In this chapter, we introduce the notion of using data to make predictions. We start with linear regression, using subthreshold excitatory potentials to predict spiking behavior of neurons in auditory cortex. We introduce the notions of fitting a line to points and determining slope and intercept as beta weights. We then extend the concept of regression to the increasingly important method of logistic regression, where we predict binary or categorical outcomes using data from color perception, which we also use as an opportunity to introduce string parsing. We conclude the chapter by discussing modern machine learning methods like lasso and ridge regression.",2017,
The comparison of topologies related to various concepts of generalized covering spaces,"Abstract The most common construction of a generalized covering space is that of a topologized (appropriate version of a) path space X Ëœ . There have been three suggested topologies on it, each with its advantages and disadvantages. They are called the Whisker topology, the Lasso topology and the quotient of the compact open topology. In this paper we study the relationship between these topologies. The main result consists of an example demonstrating that the Lasso topology is not finer that the compact open topology. Our results also apply to the topology of the fundamental group which appears naturally as a subspace of X Ëœ .",2014,Topology and its Applications
Simulation der Nanostrukturbildung in Alkali-dotierten Fullerenschichten,"This work presentstheoreticalbackgroundfor the investigationof nanostructureformation in alkali-metaldopedfullerenelayers.A numberof computationalmethodsareusedto describestructuraltransformationin the fullerenelayer. They includetight-bindingmolecular dynamics,empiricalmoleculardynamics,Monte-Carlocalculationsaswell asother methods. Thediscoveryof superconducti vity in alkali-metal-dopedfullerenesin 1991haspromptedmuchresearchactivities concerningthis classof chemicalcompounds. Thedopedfullerenelayersshow thehighestsuperconductingcritical temperatureT0 amongorganicsuper conductors,whereT0 scaleswith thelatticeconstantfor a largeclassof A3C60 phases. The symbolA denotesanalkali metalor acombinationof alkali metals.T0 variesin awiderange of temperaturesfrom 19.3K for K3C60 to 31.3K for Rb2CsC60. New methodsof preparationof thesuperconducti ve materialson thebaseof alkali fulleride compoundsis a subjectof challenge.A new electrochemical methodof synthesisof potassiumand rubidium fullerides hasbeenrecentlydevelopedby Prof. Dunschand coworkers in the departmentof electrochemistryandconducti ve polymersat IFW Dresden. Elaboratecharacterizationof sampleshasshown that thenatureof theelectrochemical processis complicated.Theprocessof electrochemical dopingis accompaniedby severalside effects,andoneof themis nanostructureformationat thesurfaceof thefullerenelayer. In the presentwork an explanationis given for the nanostructureformation observed recentlyby scanningtunnelmicroscopy. Thecorrespondingmodelis basedon theconcept of spontaneousphaseseparationthat hasbeenrealizedby kinetic Monte Carlo calculations.Thesecalculationspredict instability of initially homogeneousalkali-dopedfullerene layers.Dueto thesignificantgapin theMadelungenergy betweenAC60 andA3C60 phases formationof analkali-poorandanalkali-reachphaseis expected. The resultsof the Monte Carlo simulationspoint out that the particlesizeof the correspondingphasesremainsin thenanometerange.Thedependenc y of theparticlesizeon adjustableparameters, likethesizeof theelementaryboxandthesamplingmethod,havebeenstudied.Thesizeanddensityof thenanostructures canbeprobablycontrolledin acertain degreethroughthealkali metalcontent.MonteCarlodataexhibit differencesin thekinetics of the processin potassiumandrubidium systemsandbring a new interpretationfor 13C NMR data. Interpretationof experimentaldatafor metaldepositiononfullerenesubstratescanbeeasily givenin theframework of thephaseseparationconceptaswell. Metalclustersof thesize order50 to 100nm emerge in courseof electrochemical copperdepositionon alkali-doped fullerenelayers.Particlesof thealkali-reachphasearemetallicandcanform, in contactwith eachother, electricallyconducti ve paths.The electricallyconducti ve pathsthroughthe insulatingfullerenelayer areprobablyresponsiblefor the inhomogeneouscopperdeposition underelectrochemical conditions. Therearea numberof experimentalindicationsthat besidepenetrationof alkali metal ions into the fullerenelayer alsointensi ve chemicalinteractionbetweenfullereneparticles andwaterfrom theelectrolytetakesplace.Electronicbandstructurecalculationsbymeansof extendedHÃ¼ckel theoryhelpto elucidatetheroleof thechemicalinteractions.Thereacti vity of theC 60 ions increasesnoticeablewith theelectricalcharge.This resultsin formationof a numberof KxC60Hy compounds. Thehydrogentake-upslows down thegrowth of AxC60 particlesdue to the low electricconducti vity of the correspondingphases.Therefore,this effect canhaveanimpacton thestructureof thelayersurface. In additionto the processesthat develop insideof the C60 layer effectson the surface have beenstudiedby meansof tight-bindingmoleculardynamics.Theelectrode-electrolyte interfaceaswell asmodelsfor thesystemconsistingof dopedfullerenelayersandelectrolyte solution,areconsidered. Thetheoreticalmethodsandtheir applicability to thesesystems have beentestedanda numberof structuralandenergeticparameters, for instancetheelectrostaticpotentialneartheinterface,havebeencalculated.Onepossiblefurtherdevelopment of themethodthrougha combinationwith inverseMonteCarlosimulationshave beendiscussed. A novel computerprogramhasbeendevelopedin courseof thiswork, which is designed asa distributedapplication.Thesoftwarecomponentsaresuitablefor a heterogeneous network andrun underWindows2000aswell asCompaqTRU64UNIX operationsystems.It canbeusedfor diverseconventionalandkineticMonteCarlocalculations.",2003,
Aua ã«å‚åŠ ã—ã¦ 14 å¹´ã§å¤‰ã‚ã£ãŸã“ã¨,2008 å¹´5 æœˆ17 æ—¥ã€œ 22 æ—¥ã«ãƒ•ãƒ­ãƒªãƒ€å·žã‚ªãƒ¼ãƒ©ãƒ³ãƒ‰ã§é–‹å‚¬ã•ã‚ŒãŸAUAï¼ˆAmerican UrologicalAssociationï¼‰ã®å­¦è¡“é›†ä¼šã«å‚åŠ ã—ã¾ã—ãŸï¼Žç§ã«ã¨ã£ã¦ä¹…ã—ã¶ã‚Šã®AUA å­¦è¡“é›†ä¼šã§ã®ç™ºè¡¨ã§ã—ãŸï¼Ž,2008,
Abstract 2693: Relapse in BCP-ALL predicted by activated signaling in pro-B cell subsets,"B-cell precursor acute lymphoblastic leukemia (BCP-ALL) is the most common type of childhood cancer and is characterized by the malignant expansion of B-lymphocyte progenitors in the bone marrow (BM). Current therapy improves the relapse-free survival in children to over 80%. However, the âˆ¼20% of patients who relapse have a poor prognosis and there are no reliable tests that predict relapse using diagnostic samples. We reasoned that aligning BCP-ALL cells according to a formalized context of normal B-lymphocyte development would reveal hidden cell states associated with relapse, and potentially expose targets to augment therapy for patients at risk. Until recently, our ability to pinpoint the identities of B-cell progenitors had been hindered by the vast cellular diversity within the BM and by the scarcity of the primary BM samples. We applied a single-cell proteomics platform termed mass cytometry by time-of-flight (CyTOF). In CyTOF, elemental mass reporter tagged antibodies probe proteins defining cellular identity and signaling within those cells. CyTOF simultaneously quantifies > 40 proteins per cell in millions of individual cells. We defined a cell-state signature for 15 developmental populations of B lymphocytes within the normal human BM. Using this signature we assigned each leukemia cell from 52 primary diagnostic samples to its closest match in B lymphopoiesis using a classifier based on Mahalanobis distance. When applied to BM samples from 4 healthy donors our classifier correctly assigned cells to the true developmental population (accuracy = 0.92, F-measure = 0.92). Using this classifier it was determined that each BCP-ALL sample contains a mix of developmental populations - with 97% of samples enriched in populations that span the pre-pro-B to pre-B transition. We identified 20 predictors (using a machine learning approach) in diagnostic samples that perfectly separate patients who will relapse from those who will not (lasso; predictive AUC = 0.83). This is superior to the NCI risk that is currently employed at clinical diagnosis. These predictors are informative and suggest that high basal activation of IL-7 signaling nodes (pSTAT5, pAKT) in pre-pro-B to pro-BII cells and poor response following pre-B-cell receptor engagement in pre-BI cells portend relapse. As such, these pathways might eventually be targeted via drug repurposing to improve outcomes and to guide therapy in the high-risk childhood BCP-ALL patients identified with our predictor signature. Such an approach to cancer cell developmental classification could be generally applicable across various investigations on understanding and preventing relapse. Citation Format: Zinaida Good, Jolanda Sarno, Astraea Jager, Nikolay Samusik, Wendy Fantl, Nima Aghaeepour, Robert Tibshirani, Sean C. Bendall, Giuseppe Gaipa, Andrea Biondi, Garry P. Nolan, Kara L. Davis. Relapse in BCP-ALL predicted by activated signaling in pro-B cell subsets. [abstract]. In: Proceedings of the 107th Annual Meeting of the American Association for Cancer Research; 2016 Apr 16-20; New Orleans, LA. Philadelphia (PA): AACR; Cancer Res 2016;76(14 Suppl):Abstract nr 2693.",2016,Cancer Research
Measuring the return to online advertising: Estimation and inference of endogenous treatment effects,"In this paper we aim to conduct inference on the â€œliftâ€ effect generated by an online advertisement display: specifically we want to analyze if the presence of the brand ad among the advertisements on the page increases the overall number of consumer clicks on that page. A distinctive feature of online advertising is that the ad displays are highly targeted- the advertising platform evaluates the (unconditional) probability of each consumer clicking on a given ad which leads to a higher probability of displaying the ads that have a higher a priori estimated probability of click. As a result, inferring the causal effect of the ad display on the page clicks by a given consumer from typical observational data is difficult. To address this we use the large scale of our dataset and propose a multi-step estimator that focuses on the tails of the consumer distribution to estimate the true causal effect of an ad display. This â€œidentification at infinityâ€ (Chamberlain (1986)) approach alleviates the need for independent experimental randomization but results in nonstandard asymptotics. To validate our estimates, we use a set of large scale randomized controlled experiments that Microsoft has run on its advertising platform. Our dataset has a large number of observations and a large number of variables and we employ LASSO to perform variable selection. Our non-experimental estimates turn out to be quite close to the results of the randomized controlled trials.",2018,
Characterization of Sviceucin from Streptomyces Provides Insight into Enzyme Exchangeability and Disulfide Bond Formation in Lasso Peptides.,"Lasso peptides are bacterial ribosomally synthesized and post-translationally modified peptides. They have sparked increasing interest in peptide-based drug development because of their compact, interlocked structure, which offers superior stability and protein-binding capacity. Disulfide bond-containing lasso peptides are rare and exhibit highly sought-after activities. In an effort to expand the repertoire of such molecules, we heterologously expressed, in Streptomyces coelicolor, the gene cluster encoding sviceucin, a type I lasso peptide with two disulfide bridges originating from Streptomyces sviceus, which allowed it to be fully characterized. Sviceucin and its reduced forms were characterized by mass spectrometry and peptidase digestion. The three-dimensional structure of sviceucin was determined using NMR. Sviceucin displayed antimicrobial activity selectively against Gram-positive bacteria and inhibition of fsr quorum sensing in Enterococcus faecalis. This study adds sviceucin to the type I lasso peptide family as a new representative. Moreover, new clusters encoding disulfide-bond containing lasso peptides from Actinobacteria were identified by genome mining. Genetic and functional analyses revealed that the formation of disulfide bonds in sviceucin does not require a pathway-encoded thiol-disulfide oxidoreductase. Most importantly, we demonstrated the functional exchangeability of the sviceucin and microcin J25 (a non-disulfide-bridged lasso peptide) macrolactam synthetases in vitro, highlighting the potential of hybrid lasso synthetases in lasso peptide engineering.",2015,ACS chemical biology
Abstract 884: Circulating microRNAs as non-invasive biomarkers for early detection of lung cancer,"Lung cancer is the leading cause of cancer deaths worldwide. In 2008, 1.61 million new cases, and 1.38 million deaths due to lung cancer were recorded. This high mortality rate is mainly due to the late stage at which lung cancer is diagnosed. While early diagnosis has been successfully implemented through tomography-based population screenings in high-risk individuals, there is a need for simpler, non-invasive and more accessible methodologies for effective early cancer detection programs. Circulating microRNA (miRNA) profiles have been suggested as promising diagnostic and prognostic biomarkers for cancer, including lung cancer. However, the results have so far been inconsistent between studies. The objective of this study was to explore the potential of circulating miRNAs in plasma for early detection of lung cancer using global profiling approach. Plasma samples were collected from 100 early stage (I to IIIA) non-small-cell lung cancer patients (35 lung adenocarcinoma and 65 squamous cell carcinoma patients) and 100 age- and gender-matched healthy controls. 754 circulating miRNAs were analyzed via quantitative RT-PCR using TaqMan Low Density Arrays. Data were quantile normalized and limma analysis with adjustment for multiple testing to control for false discovery rate (FDR, Benjamini-Hochberg method) was performed to identify differentially regulated miRNA between cases and controls. Penalized Lasso logistic regression model (with penalty parameter tuning conducted by 10-fold cross-validation) was used to compute the least redundant panel of miRNAs for discriminating between cases and controls. The area under the receiver operating characteristic curve (AUC) was calculated to assess the discriminatory power of the model. Internal validation was conducted by calculating the bootstrap optimism-corrected AUC for the selected model. Sixty one plasma miRNAs were found to be significantly differentially expressed between lung cancer cases and controls including 33 upregulated and 28 downregulated miRNAs (p-value Citation Format: Magdalena B. Wozniak, Ghislaine Scelo, David Muller, Anush Moukeria, David Zaridze, Paul Brennan. Circulating microRNAs as non-invasive biomarkers for early detection of lung cancer. [abstract]. In: Proceedings of the 105th Annual Meeting of the American Association for Cancer Research; 2014 Apr 5-9; San Diego, CA. Philadelphia (PA): AACR; Cancer Res 2014;74(19 Suppl):Abstract nr 884. doi:10.1158/1538-7445.AM2014-884",2014,Cancer Research
Vollmantelzentrifuge mit einem wehr und diesem zugeordneter stationÃ¤rer ablenkscheibe,"Eine Vollmantelzentrifuge mit einer um eine horizontale Drehachse drehbaren Schleudertrommel (1), die ein Wehr zur Ableitung einer Flussigkeit aus der Schleudertrommel (1) aufweist, das einen Durchlass mit wenigstens einer oder mehreren Durchlassoffnungen (5) in einem axialen Endbereich oder Trommeldeckel (3) sowie vorzugsweise eine auserhalb der Schleudertrommel (1) vor den Durchlassoffnungen (5) angeordnete Drosselscheibe aufweist, deren Abstand zu der wenigstens einen Durchlassoffnung (5) veranderlich ist, so dass zwischen dem Durchlass (4) und der Drosselscheibe (6) oder einem sonstigen Bauelement ein veranderlicher Ringspalt (8) ausgebildet ist, zeichnet sich dadurch aus, dass der Ringspalt (8) von einer sich z.B. kegelig aufweitenden Ablenkscheibe (12) umgeben ist.",2005,
Variational Bayes logistic regression as regularized fusion for NIST SRE 2010,"Fusion of the base classifiers is seen as a way to achieve high performance in state-of-the-art speaker verification systems. Typically, we are looking for base classifiers that would be complementary. We might also be interested in reinforcing good base classifiers by including others that are similar to them. In any case, the final ensemble size is typically small and has to be formed based on some rules of thumb. We are interested to find out a subset of classifiers that has a good generalization performance. We approach the problem from sparse learning point of view. We assume that the true, but unknown, fusion weights are sparse. As a practical solution, we regularize weighted logistic regression loss function by elastic-net and LASSO constraints. However, all regularization methods have an additional parameter that controls the amount of regularization employed. This needs to be separately tuned. In this work, we use variational Bayes approach to automatically obtain sparse solutions without additional cross-validation. Variational Bayes method improves the baseline method in 3 out of 4 sub-conditions. Index Terms: logistic regression, regularization, compressed sensing, linear fusion, speaker verification",2012,
Colorimetrische Bestimmung von Mangan in GlÃ¤sern,"ZusammenfassungEs wurde eine colorimetrische (richtiger spektralphotometrische) Methode ausgearbeitet, durch die die quantitative Bestimmung sehr kleiner Manganmengen in den gebrÃ¤uchlichsten Glassorten ermÃ¶glicht wird. Sie beruht auf der Farbreaktion (OrangerotfÃ¤rbung) zwischen Mangan(II)-Ion und Formaldoxim. Letzteres Reagens erwies sich als etwa 10mal empfindlicher als das schon frÃ¼her fÃ¼r eine spektralphotometrische Manganbestimmung benÃ¼tzte Reagens Kaliumperjodat. Auch sind mit Formaldoxim die Schwankungen der Analysenwerte in dem durch die Problemstellung geforderten Konzentrationsbereich geringer als mit Kaliumperjodat. Der EinfluÃŸ zahlreicher Fremdelemente wurde erforscht bzw. eliminiert.SummaryA spectrophotometric method was worked out, through which it is possible to make a quantitative determination of very small amounts of manganese in the most commonly used varieties of glass. It is based on the color reaction (orange-red coloration) between manganese (II) and formaldoxime. This reagent proved 10 times more sensitive than potassium periodate, used previously for a spectrophotometric determination of manganese. Moreover, with formaldoxime, the variations in the analysis values are less than with potassium periodate in the concentration range set by the present problem. The influence of many foreign elements was studied and eliminated.RÃ©sumÃ©On Ã©labore une mÃ©thode spectrophotomÃ©trique qui rend possible le dosage quantitatif de trÃ¨s petites quantitÃ©s de manganÃ¨se dans les verres ordinaires. Cette mÃ©thode repose sur la rÃ©action colorÃ©e (orangÃ©) entre l'ion Mn2+ et la formaldoxime. Ce dernier rÃ©actif paraÃ®t dix fois plus sensible que le periodate de potassium dÃ©jÃ  utilisÃ© prÃ©cÃ©demment pour le dosage spectrophotomÃ©trique du manganÃ¨se. Avec la formaldoxime, les variations des chiffres d'analyse paraissent plus faible qu'avec ce periodate, dans le domaine de concentration envisagÃ© pour la rÃ©solution du problÃ¨me. On Ã©tudie et Ã©limine l'influence de nombreux Ã©lÃ©ments Ã©trangers.",1950,Mikrochemie vereinigt mit Mikrochimica acta
22q11.2 deletion syndrome as a natural model for COMT haploinsufficiency-related dopaminergic dysfunction in ADHD.,"In the current issue of IJNP Gothelf and co-workers report an important study which sheds light on the association between chromosome 22q11.2 deletion syndrome (22q11.2 DS; velocardiofacial syndrome, VCFS), dopaminergic transmission, and psychiatric disorders. 22q11.2 DS occurs in at least 1/5000 live births and thus is the most common chromosomal deletion syndrome in humans (Botto et al., 2003). The deletion in the long arm of chromosome 22, usually comprises up to 3 Mb, and is transmitted dominantly, although most patients suffer from de-novo mutations. The clinical phenotype ranges from immune deficiency with thymal aplasia, congenital heart abnormalities, velopharyngeal insufficiency with hypernasal speech, slight dysmorphy with characteristic facies, to severe syndromal developmental abnormalities with mental retardation (Shprintzen, 2000). Most interestingly for the field of neuropsychiatry, 22q11.2 DS is associated with an increased rate of variety of psychiatric disorders. In childhood and adolescence, 22q11.2 DS is associated with attention deficit hyperactivity disorder (ADHD; Antshel et al., 2005; Niklasson et al., 2002), affecting up to 55% of the patients (Gothelf et al., 2004). Another, less frequent comorbidity in adolescence seems to be obsessiveâ€“compulsive disorder (OCD; Gothelf et al., 2006). Finally, there is an increased prevalence for comorbidity with schizophrenic and bipolar affective psychoses in adulthood (Murphy, 2005).",2007,The international journal of neuropsychopharmacology
Os Spas No Turismo De Bem-estar,"RESENHA DE: 
VIEGAS FERNANDES, Joao; VIEGAS FERNANDES, Filomena Mauricio. SPAs, Centros Talasso e Termas â€“ Turismo de saude e bem-estar. Lisboa, Portugal: Pergaminho AS; Gestao Plus Edicoes, 2008.",2016,
BÃ¤uerin und Ã–konomie,"Traditionelles bauerliches Wirtschaften ist gekennzeichnet durch die â€žEinheit von Produktion, Konsum und generativer Reproduktion in Haushalt und Familie des Bauernâ€œ64. Ob wir diese nun im Anschlus an A.W. Tschajanow als â€žFamilienwirtschaftâ€œ65 oder im Gefolge von O. Brunner als â€žHauswirtschaftâ€œ66, mit M. Sahlins als â€žSteinzeitokonomieâ€œ67 oder C. Meillassoux als â€žhausliche Produktionsweiseâ€œ68 bezeichnen, ihre Charakteristika bleiben im wesentlichen die gleichen69. Das Wirtschaften orientiert sich hier eher am Motiv der Familienversorgung, der Sicherstellung von â€žNahrungâ€œ und an den Bruttoertragen aus der Familienarbeit, als an einem Kosten-Nutzen-Kalkul, an Profitmaximierung oder am Nettoeinkommen:,,Vor Erwirtschaftung eines â€šSurplusâ€˜ ... ist sie (die Familienwirtschaft, erg.) bestrebt, die Befriedigung der tradierten, sozial-kulturell normierten Bedurfnisse familiarer Subsistenz sicherzustellen.â€œ70 Die Produktion erfolgt subsistenzund gebrauchswertorientiert. Zwischen familiarem Konsumverhalten und der Ausbeutung der Arbeitskraft wird in spezifischer Weise ausbalanciert (â€žArbeit-Konsum-Balanceâ€œ): Unbefriedigte Bedurfnisse fordern zur Mehrarbeit auf, die Muhsal der Arbeit setzt der Bedurfnisbefriedigung eine Schranke, insbesondere im Grenzfall, wenn ein gesteigerter Arbeitsaufwand keine nennenswert hoheren Ertrage mehr bringt. Das Niveau, auf dem die Faktoren ausbalanciert werden, entspringt dabei nicht den subjektiven Wunschen einzelner Familienmitglieder, sondern dem Gesamtkomplex des â€žGanzen Hausesâ€œ. Es handelt sich also insgesamt um eine Okonomie der begrenzten Ziele.",1983,
Impact of Ozone on the Growth and Yield of Trees : A Review,"Data f rom 25 exper iments on seed l ings o f 43 tree s p e c i e s a n d h y b r i d s show that ozone (0,) can reduce growth and photosynthesis at concentrations common in many areas of the USA. Seedlings have been primarily employed for such studies for logislic reasons, and will likely provide the greatest breadth of information for some time IO come. However, a number of impediments limit application of seedling response s tud ies IO a s s e s s m e n t o f i m p a c t s o n r e g i o n a l t i m b e r p r o d u c tion. Large trees differ from seedlings in a number of ways, including C allocation and canopy structure, and methods must be developed IO acrount for these differences if information from seedling studies is to prove useful IO forest impact assessmenl. Understanding how comp e t i t i o n m e d i a t e s i n d i v i d u a l tree r e s p o n s e s w i l l r e q u i r e i n v e s t i g a t i o n o f whether systematic differences of microclimate leaf morphology that exist across canopies affects foliage sensitivity IO 0,. and whether the maximum growth rates of genolypes are correlated with susceptibility IO 0,. Definitive information on these factors is necessary IO assess imparts of 0, on stand development and diameter distributions in both mulliand single species stands. Of critical economic importance is whether 0, preferentially damages taller, more valuable individuals within stands and more valuable, faster growing stand types. Of the several air pollutants common in various regions of the USA, ozone (0,) is the only one likely to impact Pest Impact Assessment Technology Research Work Unit, USDA Forest Service, Southeastern Forest Exp. Stn., Research Triangle Park, NC 27709. Contribution of the Pest Impact Assessment Technol Res. Work Unit, USDA Forest Service, Southeastern Forest Exp. Stn. Received 13 July 1987. *Corresponding author. Published in J. Environ. Qua). 17:347-360 (1988). large areas for which sufficient response information is available to assess exposure-response relationships. Controlled exposures of trees to SO, or NO, have been limited to concentrations of 0.05 pL/L and above, concentrations that are rare in most forested areas of the country (Altshuller, 1983; National Research Council, 1986). Additionally NO, and SO, are subject to relatively large spatial and temporal variability (Seinfeld, 1986; Roberts, 1984), complicating estimation of exposure for rural areas with Little monitoring. Assessment of acid deposition is complicated by negative and positive impacts (Bell, 1986), unresolved mechanisms of action (Society of American Foresters, 1984), and the probable importance of indirect effects (Ulrich, 1983). Several excellent 0, reviews are available (Guderian, 1985; Heath, 1980; Heck et al., 1986; Mudd, 1984; Runeckles, 1986), but they have not focused on responses of tree species. Several have addressed impacts on trees but they are either theoretical syntheses or qualitative discussions of response (Winner and Atkinson, 1986; Harkov and Brennan, 1979; Taylor and Norby, 1984; Kozlowski and Constantinidou, 1986a, b). Here 1 review data from controlled exposures and discuss how such data might be incorporated in large-scale economic assessments. This review consists of three parts: (i) a critique of available experimental approaches, (ii) a review of tree response data from controlled fumigations, and (iii) a discussion of difficulties extrapolating these results to regional economic damage assessments. This analysis is J. Environ. Qual., Vol. 17, no. 3, 1988 3 4 7 restricted to estimation of timber market impact, ignoring other benefits that forests provide. EXPERIMENTAL APPROACHES Fisher (1981) cites two methods for determining damage functions for polluation impact assessment: statistical field studies (e.g., Miller, 1983; Kercher and Exelrod, 1981), and controlled exposure-response experiments (as in Heck et al., 1986). Statistical field studies exploiting spatial or tempera1 contrasts in 0, have been made difficult by low spatial resolution and few years of comparable O1 concentration data (Pinkerton and Lefohn, 1986; USEPA, 1986). A third approach providing the most rapic input to policy makers is expert opinion, possibly structured around interdisciplinary workshops (e.g., Helling and Chambers, 1973; Bonnickson and Becker, 1983). The most prominent model of the experimental approach to regional air pollution impact assessment is The National Crop Loss Assessment Network (NCLAN) (Heck et al., 1986), in which yield reductions were estimated from a series of exposure-response fumigation studies. However, long rotations and the large sizes of trees prevent rotation-long fumigation as employed by NCLAN, complicating estimation of stand-level yield impacts. Greater heterogeneity of soils, topography and species, and poorly characterized intraspecific variability each present additional problems for stand and regional extrapolation. Fumigation Chamber Designs Indoor growth chambers, greenhouses, and continuously stirred tank reactors (CSTRâ€™s) are the most common fumigation environments for tree studies. In these indoor environments, plants differ morphologically and physiologically from those grown outdoors, and they react differently to 0, (Lewis and Brennan, 1977). Outdoor exposures usually employ open-top chambers (OTC) or, rarely, chamberless designs (Reich and Amundson, 1984). Chamberless designs produce the fewest microclimatic artifacts, particularly in winter (Olszyk et al., 1986), but control of fumigation levels under differing winds has proved difficult (Guderain et al., 1985). Open-top chambers after temperature, humidity, and air flow, extending leaf retention and increasing height growth over chamberless controls (Duchelle et al., 1982; Wang et al., 1986). Chamberless designs may benefit from improvements in airflow control, but OTCâ€™s currently provide the most realistic data on yield response. Ideally, exposure-response studies should include treatments representing four or more concentrations of 0, that span the range of control scenarios under policy consideration, allowing nonlinear regression analysis of impacts. While unusual in tree response studies published thus far, use of this design is becoming more common. Relevant Dosing Regimes The relevance of experimental dosing regimes depends on patterns of exposure common in forests. The most commonly cited exposure statistic is the daily 7-hr mean, averaged over the growing season. The regional patterns of 0, characterized by this measure obscure smaller temporal and spatial patterns. Daily 0, concentrations tend to peak around 1400 h near urban areas, but diurnal swings are dampened and often displaced later in the day in more remote areas (Lefohn and Jones, 1986; USEPA, 1986; Miller et al., 1982; Berry, 1964). Mean 0, concentrations in urban and rural areas are often fairly similar, about 0.040 to 0.055 pL/L in the southeast (Pinkerton and Lefohn, 1986). However, peak events are more extreme in cities (USEPA, 1986). In the southeast, hourly means greater than 0.120 FL/L, occurred at only 2 of 28 rural sites, but they occurred at least once in nearly every city (Pinkerton and Lefohn, 1986). While controlled exposure studies usually manipulate exposure means, other exposure parameters are known to affect plant response (Male; 1982). These include the variance of 0, concentrationâ€˜and the timing of episodes and respites (Jensen, 1979; Musselman et al., 1983; Hogsett et al., 1985b). Indoor fumigations usually employ square-wave dosing regimes, with constant daytime 0, concentrations. Outdoor fumigations use treatments based on fixed 0, additions or complete removals of 0, from ambient air, resulting in realistic diurnal and seasonal variations, but with constant variance across treatments. Most fumigations include exposure to ambient 0, at night across ail treatments. The impact of this nighttime exposure is unknown. Although stomates are typically closed at night, Reich and Lassoie (1985) found that longterm 0, fumigation alters normal diurnal patterns of stomata1 conductance, raising the possibility of significant nighttime uptake of 0,. Extending 0, fumigation from 8 to 24 h did result in greater damage in one study (Ashmore et al., 1987, poster presented at the 19th Annual Air Pollution Workshop, Helena, MT). Note that published multiyear fumigations have also not controlled 0, exposures during the winter months (Wang et al., 1986; Duchelle et al., 1982; Chevone et al., 1983). There are two schools of thought on appropriate control 0, concentrations: zero and natural. Most researchers use charcoal-filtered air for their no-O> treatment, which brings 0, concentrations to an unspecified level near zero. This practice clarifies the mechanisms of 0, impact and highlights impacts at low 0, concentrations. Other researchers (e.g., Reich and Lassoie, 1985) contend that such low concentrations of 0, do not constitute realistic controls because pristine levels of 0, are closer to 0.025 pL/L (USEAP, 1986). These researchers use control concentrations of 0.025 to 0.030 pL/L. Types of Response Measures Experiments have identified biochemical and physiological effects of 0,. At the biochemical level, 0, oxidizes sulfhydryl and fatty acid double bonds, increases membrane permeability, and disrupts membrane-bound photosynthetic systems (Guderian et al., 1985; Mudd, 1984). Foliar sugar and polysaccharide levels are lowered as well (Miller et al., 1969). At the physiological level, 348 J. Environ. Qual., Vol. 17, no. 3, 1988 net photosynthesis is reduced, dark respiration is increased (Barnes, 1972), and C transport to roots is lowered (McLaughlin and McConathy, 1983). Other physiological impacts include coincident and long-term reductions in stomata1 conductance (Hill and Littlefield, 1969; Reich and Amundson, 1985; Coyne and Bingham, 1982), accelerated leaf senescence (Reich, 1983; Jensen, 1982; Noble and Jensen,",2004,
Functional logistic regression with fused lasso penalty,"ABSTRACT This study considers the binary classification of functional data collected in the form of curves. In particular, we assume a situation in which the curves are highly mixed over the entire domain, so that the global discriminant analysis based on the entire domain is not effective. This study proposes an interval-based classification method for functional data: the informative intervals for classification are selected and used for separating the curves into two classes. The proposed method, called functional logistic regression with fused lasso penalty, combines the functional logistic regression as a classifier and the fused lasso for selecting discriminant segments. The proposed method automatically selects the most informative segments of functional data for classification by employing the fused lasso penalty and simultaneously classifies the data based on the selected segments using the functional logistic regression. The effectiveness of the proposed method is demonstrated with simulated and real data examples.",2018,Journal of Statistical Computation and Simulation
Efficient Implementations of the Generalized Lasso Dual Path Algorithm,"We consider efficient implementations of the generalized lasso dual path algorithm given by Tibshirani and Taylor in 2011. We first describe a generic approach that covers any penalty matrix D and any (full column rank) matrix X of predictor variables. We then describe fast implementations for the special cases of trend filtering problems, fused lasso problems, and sparse fused lasso problems, both with X = I and a general matrix X. These specialized implementations offer a considerable improvement over the generic implementation, both in terms of numerical stability and efficiency of the solution path computation. These algorithms are all available for use in the genlasso R package, which can be found in the CRAN repository.",2014,ArXiv
And you thought you knew classic movies! : a quiz book,"*What movie paired Fred Astaire with Rita Hayworth?*What Western found Jimmy Stewart lassoed and dragged through a campfire?*In what classic does one woman's cigarette set another woman's hat on fire? You may think you know classic movies, but John DiLeo's memory-bending quiz book is about to make you think again. The 200 quizzes in"" And You Thought You Knew Classic Movies ""will test your recall of every aspect of Hollywood's Golden Age (1930-70). None of these tests is easy, but their match-'em format makes them as irresistible as crossword puzzles--and the toughest ones will make even lifelong buffs quiver. Are you crazy for ""Gun Crazy""? Can't help loving ""The Girl Can't Help It""? Or is ""Breakfast at Tiffany's"" more your cup of tea? Whatever your taste, ""And You Thought You Knew Classic Movies"" will send you reeling to the video store in ecstasy.",1999,
Key Considerations and Methods in the Study of Gene-Environment Interactions.,"With increased involvement of genetic data in most epidemiological investigations, gene-environment (G Ã— E) interactions now stand as a topic, which must be meticulously assessed and thoroughly understood. The level, mode, and outcomes of interactions between environmental factors and genetic traits have the capacity to modulate disease risk. These must, therefore, be carefully evaluated as they have the potential to offer novel insights on the ""missing heritability problem"", reaching beyond our current limitations. First, we review a definition of G Ã— E interactions. We then explore how concepts such as the early manifestation of the genetic components of a disease, the heterogeneity of complex traits, the clear definition of epidemiological strata, and the effect of varying physiological conditions can affect our capacity to detect (or miss) G Ã— E interactions. Lastly, we discuss the shortfalls of regression models to study G Ã— E interactions and how other methods such as the ReliefF algorithm, pattern recognition methods, or the LASSO (Least Absolute Shrinkage and Selection Operator) method can enable us to more adequately model G Ã— E interactions. Overall, we present the elements to consider and a path to follow when studying genetic determinants of disease in order to uncover potential G Ã— E interactions.",2016,American journal of hypertension
The Epidemiological Characteristics and Prognostic Factors of Low-Grade Brainstem Glioma: A Real-World Study of Pediatric and Adult Patients,"Purpose: Our current understanding of low-grade brainstem glioma (LGBSG) is still limited. This study aimed to conduct a large-scale population-based real-world study to understand the epidemiological characteristics of LGBSG and determine the predictive factors of cancer-specific survival (CSS) and overall survival (OS) of LGBSG patients. Patients and Methods: We used Surveillance Epidemiology and End Results database to conduct this study of patients with histologically confirmed LGBSG. Patient demographics, tumor characteristics, and treatment options were compared between pediatric and adult patients. Univariate and multivariate analyses were employed to determine prognostic factors of CSS and OS. Kaplanâ€“Meier curve and decision tree were used to confirm the prognostic factors. All variables were further identified by L1-penalized (Lasso) regression and then a nomogram was established to predict the 5- and 8-year CSS and OS rate. The precision of the nomogram was evaluated by calibration plots, Harrell's concordance index, and time-dependent receiver operating characteristic curve. The clinical use of nomogram was estimated by decision curve analysis. Results: A cohort of 305 patients with LGBSG, including 165 pediatric and 140 adult patients, was analyzed. Adult and pediatric patients showed different patterns concerning tumor size, tumor extension, adjuvant therapy, and survival rate. Univariate analysis revealed that pediatric group, gross total resection (GTR), World Health Organization grade II, radiotherapy, extension to ventricular system, and diffuse astrocytic and oligodendroglial tumor (DAOT) were significantly associated with CSS. Multivariate analysis showed that pediatric group, metastasis, ventricular system involvement, and DAOT were independently associated with CSS. The prognostic factors were further confirmed by Kaplanâ€“Meier curve and decision tree. Kaplanâ€“Meier curve also showed that adjuvant therapy added no benefits in patients with GTR and non-GTR. In addition, the nomogram was developed and the C-index of internal validation for CSS was 0.87 (95% CI, 0.78â€“0.96). Conclusion: This study shows that pediatric and adult patients have different tumor characteristics, treatment options, and survival rate. Pediatric group, DAOT, ventricular system involvement, and metastasis were identified as independent prognostic factors for CSS by multivariate analysis. Adjuvant therapy showed no benefits on CSS in patients with GTR and non-GTR. The nomogram was discriminative and clinically useful.",2020,Frontiers in Oncology
Using Textual Transcripts of Parliamentary Interventions for Profiling Portuguese Politicians,"This work presents an experimental study on the subject of profiling political actors through textual transcriptions of their parliamentary interventions. Supervised learning techniques were used to learn models, which attempt to classify Portuguese politicians according to their gender, their age group, or their political affiliation and orientation. Experiments were made using different types of classification models, using state-of-the-art feature weighting schemes, using stylometric features from state-of-theart approaches for author profiling, and using features derived from distributional word clustering or from concise semantic analysis. Experiments with the group Lasso regularization technique for logistic regression models were also performed. The experiments showed that language usage is indeed indicative of a personâ€™s characteristics and ideology.",2016,
AndriÌ‡ake LiÌ‡manindan Ele GeÃ§en Dsc Grubu-pergamon -Ã§andarli SiÌ‡giÌ‡llatalari,"Lykia Bolgesiâ€™nin onemli limanlarindan biri olan Andriake kentinde, 2009 senesinde baslatilan kazilarda, I.S. 5.-6. yuzyila ait bir sinagog yapisi ortaya cikarilmistir. Kazilar sirasinda, yapinin apsis bolumunun zemin altindaki, ana kaya alani arasindaki bosluklarin, kentin seramik coplugunden getirilen, malzeme ile dolgu yapildigi gozlemlenmistir. Atik alanindan getirilen malzemeler, Hellenistik Donemâ€™den Bizans Donemiâ€™ne kadar tarihlenmektedir. Ozellikle Hellenistik ve Roma seramikleri soz konusu bu alanda yogun olarak karsimiza cikmistir. Bu seramikler icerisindeki en yogun grup terra sigillatalardir. Ele gecen, 193 parca icerisinde, Dogu Sigillatalardan A, B, C, D grubu, yerel uretimler, Sagalassos Kirmizi Astarlilari, Italya Sigillatalari, Gec Roma seramikleri vardir. Dogu Sigillata gruplarindan, DSA ve DSD (Kibris) seramikleri, iki ayri calismada tarafimdan degerlendirilmistir.Â  Bu calismada ise, Dogu Sigillatalarindan, Bati Anadolu uretimi DSC grubu degerlendirilecektir. Seramikler; hamur-astar yapilari ile formlarina gore gruplandirilmistir. Bu gruplarin kap dagilimlari ile sayisal yogunluklari degerlendirilmistir. Andriake liman kentindeki sigillatalarin incelenmesiyle, limanin farkli donemlerde, hangi kentlerle ticari iliskileri oldugu ortaya cikarilmaya calisilmistir.",2017,
Radiomics Signatures of Computed Tomography Imaging for Predicting Risk Categorization and Clinical Stage of Thymomas,"Purpose
The aim of this study is to develop and compare performance of radiomics signatures using texture features extracted from noncontrast enhanced CT (NECT) and contrast enhanced CT (CECT) images for preoperative predicting risk categorization and clinical stage of thymomas.


Materials and Methods
Between January 2010 and October 2018, 199 patients with surgical resection and histopathologically confirmed thymoma were enrolled in this retrospective study. We extracted 841 radiomics features separately from volume of interest (VOI) in NECT and CECT images. The features with poor reproducibility and highly redundancy were removed. Then a least absolute shrinkage and selection operator method (LASSO) logistic regression model with 10-fold cross validation was used for further feature selection and radiomics signatures build. The predictive performances of radiomics signatures were assessed by receiver operating characteristic (ROC) analysis. The areas under the receiver operating characteristic curve (AUC) between radiomics signatures were compared by using Delong test.


Result
In differentiating high risk thymomas from low risk thymomas, the AUC, sensitivity, and specificity were 0.801(95% CI 0.740-0.863), 0.752 and 0.767 for radiomics signature based on NECT images, and 0.827 (95% CI 0.771 -0.884), 0.798, and 0.722 for radiomics signature based on CECT images. But there was no significant difference (p=0.365) between them. In differentiating advanced stage thymomas from early stage thymomas, the AUC, sensitivity, and specificity were 0.829 (95%CI 0.757-0.900), 0.712, and 0.806 for radiomics signature based on NECT images and 0.860 (95%CI 0.803-0.917), 0.699, and 0.889 for radiomics signature based on CECT images. There was no significant difference (p=0.069) between them. The accuracy was 0.819 for radiomics signature based on NECT images, 0.869 for radiomics signature based on CECT images, and 0.779 for radiologists. Both radiomics signatures had a better performance than radiologists. But there was significant difference (p = 0.025) only between CECT radiomics signature and radiologists.


Conclusion
Radiomics signatures based on texture analysis from NECT and CECT images could be utilized as noninvasive biomarkers for differentiating high risk thymomas from low risk thymomas and advanced stage thymomas from early stage thymoma. As a quantitative method, radiomics signature can provide complementary diagnostic information and help to plan personalized treatment for patients with thymomas.",2019,BioMed Research International
Propofol â€“ AbhÃ¤ngigkeitspotenzial und forensische Relevanz,"ZusammenfassungPropofol ist ein weltweit sehr hÃ¤ufig eingesetztes Hypnotikum, das neben seiner Eignung fÃ¼r den medizinischen Einsatz auch ein AbhÃ¤ngigkeitspotenzial aufweist. SpÃ¤testens seit dem propofolassoziierten Tod des SÃ¤ngers Michael Jackson ist die Substanz auch der breiten Ã–ffentlichkeit bekannt. Besonders hÃ¤ufig ist der Missbrauch bei Medizinern und medizinischem Fachpersonal. Aufgrund des engen Fensters zwischen den gewÃ¼nschten Effekten und einer potenziell lebensbedrohlichen Intoxikation ist der missbrÃ¤uchliche Konsum von Propofol jedoch auch fÃ¼r Mediziner Ã¤uÃŸerst riskant. Die hohe LetalitÃ¤tsrate, die innerhalb des ersten Jahres nach Beginn der AbhÃ¤ngigkeit beobachtet wird, verdeutlicht das Risiko, das mit dieser Suchterkrankung einhergeht. Entsprechend ist es umso wichtiger, dass ein solcher Missbrauch frÃ¼hzeitig erkannt wird. Der Nachweis eines chronischen Propofolmissbrauchs kann mithilfe einer validen Haaranalytik erfolgen.AbstractPropofol is aÂ rapidly acting hypnotic agent that is widely used for induction and maintenance of general anesthesia but also for endoscopic and pediatric sedation. Besides its medical application in aÂ clinical setting, propofol is also misused, particularly by healthcare professionals. At least since the propofol-associated death of the performer Michael Jackson, the substance is also known to the general public; however, propofol has aÂ narrow therapeutic range between the desired effects and potentially fatal toxicity, making abuse of the drug extremely dangerous even for experienced physicians. The high mortality rate documented in the first year of substance misuse underlines the risk associated with this addictive disorder. Consequently, early recognition of potential propofol misuse is critical. To confirm such aÂ chronic propofol misuse, aÂ valid hair analysis can be carried out.",2018,Rechtsmedizin
M ar 2 01 0 POST-l 1-PENALIZED ESTIMATORS IN HIGH-DIMENSIONAL LINEAR REGRESSION MODELS,"In this paper we study post-penalized estimators which apply ordinary, unpenalized linear regression to the model selected by first-step penalized estimators, typically LASSO. It is well known that LASSO can estimate the regression function at nearly the oracle rate, and is thus hard to improve upon. We show that post-LASSO performs at least as well as LASSO in terms of the rate of convergence, and has the advantage of a smaller bias. Remarkably, this performance occurs even if the LASSO-based model selection â€œfailsâ€ in the sense of missing some components of the â€œtrueâ€ regression model. By the â€œtrueâ€ model we mean here the best s-dimensional approximation to the regression function chosen by the oracle. Furthermore, post-LASSO can perform strictly better than LASSO, in the sense of a strictly faster rate of convergence, if the LASSO-based model selection correctly includes all components of the â€œtrueâ€ model as a subset and also achieves a sufficient sparsity. In the extreme case, when LASSO perfectly selects the â€œtrueâ€ model, the post-LASSO estimator becomes the oracle estimator. An important ingredient in our analysis is a new sparsity bound on the dimension of the model selected by LASSO which guarantees that this dimension is at most of the same order as the dimension of the â€œtrueâ€ model. Our rate results are non-asymptotic and hold in both parametric and nonparametric models. Moreover, our analysis is not limited to the LASSO estimator in the first step, but also applies to other estimators, for example, the trimmed LASSO, Dantzig selector, or any other estimator with good rates and good sparsity. Our analysis covers both traditional trimming and a new practical, completely data-driven trimming scheme that induces maximal sparsity subject to maintaining a certain goodness-of-fit. The latter scheme has theoretical guarantees similar to those of LASSO or post-LASSO, but it dominates these procedures as well as traditional trimming in a wide variety of experiments. First arXiv version: December 2009.",2010,
RÃ©flexions mÃ©thodologiques sur une enquÃªte Ã  passages rÃ©pÃ©tÃ©s : l'EMIS de Bobo-Dioulasso.,"Ouaidou Nassour y van df Wai i f Ettenne â€” Reflexiones metodologicas sobre una encuesta de visitas multiples : la encuesta EMIS en Bobo-Dioulasso. La salida de observacion Ñ€Ð¾Ð³ causas ignoradas constituye uno de los problemas mas dificiles en el analisis de las encuestas por visitas repetidas La encuesta EMIS para determtnar la mortahdad infantil, efectuada en Bobo-Dioulasso entre 1981 y 1984, permite identificar bien las fuentes de error Primero, en el momento del nacimiento â€¢ lugar del parto, principalmente en el caso de mujeres que vienen de regiones lejanas, caractensticas del parto, pnncipalmente en el caso de operaciones cesareas, tratamiento descuidado de las fichas correspondantes a ni nos nacidos muertos En el curso de las visitas repetidas numerosas mujeres se pierden de la observacion, especialmente las que pertenesen a categonas vulnerables En el caso de esta encuesta el cuestionano no estaba destmado a precisar el tipo de migracion ni a detectar las migraciones temporales ahora bien si se reclasifican los datos segun la presencia o ausencia de la mujer en el curso de una visita determinada, se ponen en evidencia claras diferencias de mortahdad.",1987,Population
Abstract B41: Methylation profiling of ovarian cancer to study etiologic and prognostic heterogeneity and to develop a molecular classifier.,"Background: Ovarian cancer is a heterogeneous disease that is divisible into multiple subtypes with variable pathogenesis, etiology and biological behavior. We analyzed DNA methylation profiling data to identify biologic subgroups of ovarian cancer and study their relationship with histologic subtypes and prognosis. Additionally, we developed a molecular classifier in relation to standard histologic subtype for classification of ovarian tumors in epidemiologic studies. Methods: A total of 180 paraffin embedded ovarian epithelial tumor tissues, including the four major epithelial ovarian tumor subtypes (serous, endometrioid, mucinous and clear cell) and tumors of low malignant potential (LMP) were selected from two different sources: The Polish Ovarian Cancer study, an incident population-based case-control study conducted from 2001-2004, and the Surveillance, Epidemiology, and End Results Residual Tissue Repository (SEER RTR), which included ovarian tumors blocks collected between 1994 and 2004 from the Iowa and Hawaii SEER registries. The distributions of tumor histologic subtypes and grades from the studies were similar. All analyses were restricted to Caucasian women. Methylation profiling was conducted using the Illumina 450K methylation array. Analyses were restricted to the 22 autosomal chromosomes and non-SNP probes. Fourteen samples did not pass quality control and were excluded from the analysis. Of the 166 evaluable samples, 29 cases (17.5%) had their histologic subtype recoded after expert review. In order to compute and validate our histological signatures, the samples were divided into a training set (N=110) and a validation set (N=56). In addition, 10 high grade serous cases with 450K methylation data from the ovarian TCGA effort were included for replication. Signatures were computed using a LASSO logistic regression. Results: Among 166 samples, 32 (19%) were from the Polish study and 134 (81%) were from the SEER RTR. Unsupervised hierarchical clustering of the 5,000 most variable CpG sites showed 4 major clusters: Cluster 1 with 79% invasive serous and 14% endometrioid carcinomas, including the majority of high grade carcinomas; cluster 2 with 77% either endometrioid or clear cell carcinomas; cluster 3 with 71% serous LMP; and cluster 4 with 73% mucinous carcinomas. We observed significant survival differences across these clusters (long-rank test P= 4.64Ã—10-6), similar to differences observed for histologic subtypes. We used the training set to determine a parsimonious classifier based on methylation markers for histologic subtypes. We applied these signatures to an independent validation set from the Polish Study, SEER RTR, and the ovarian TCGA and found that 77% of the samples were correctly classified. Among the cases for which the histology was recoded after expert review, the methylation signatures correctly classified the histology subtype in 76% of the cases. Conclusions: Unsupervised analysis of DNA methylation profiling identified 4 distinct clusters of ovarian carcinomas, consistent with data indicating that ovarian cancer is heterogeneous with respect to cells of origin, carcinogenic pathways and histology. High grade serous carcinomas were grouped with high grade endometrioid cancers, while the remaining endometrioid carcinomas clustered with clear cell carcinomas, consistent with a common origin for a subset of these tumors from orthotopic or ectopic endometrial tissue. Our results suggest that methylation signatures provide a classification of ovarian tumors that overlaps with histologic subtypes and probable mechanisms of origin. Ongoing analyses will compare performance of the methylation classifier with histologic subtype in relation to risk factors and prognosis. Citation Format: Clara Bodelon, Keith Killian, Joshua Sampson, Holly Stevenson, William Anderson, Rayna Matsuno, Louise Brinton, Jolanta Lissowska, Mark Sherman, Nicolas Wentzensen. Methylation profiling of ovarian cancer to study etiologic and prognostic heterogeneity and to develop a molecular classifier. [abstract]. In: Proceedings of the AACR Special Conference on Advances in Ovarian Cancer Research: Exploiting Vulnerabilities; Oct 17-20, 2015; Orlando, FL. Philadelphia (PA): AACR; Clin Cancer Res 2016;22(2 Suppl):Abstract nr B41.",2016,Clinical Cancer Research
Gli edifici ad alte prestazioni energetiche in Piemonte,"Premessa. 
Il superamento dei sistemi a bassa efficienza. La crisi letta come il blocco di un sistema a bassa efficienza incapace di rinnovarsi ed evolvere verso nuovi modelli socio-economici 
Il tema della ""crisi"" ricorre ormai da anni, senza che vi sia una chiarezza rispetto a cosa effettivamente sia e senza che vengano indicate soluzioni concrete per uscire dal periodo di stallo. 
Cio delinea da un lato l'incapacita del sistema di fare autocritica, dall'altro, una non volonta di superare schemi di comportamento ed abitudini consolidate caratterizzate da un basso livello di efficienza e ispirate a modelli ormai obsoleti. 
Non e un caso che paesi tradizionalmente piu efficienti siano meno in crisi di paesi tradizionalmente orientati in senso opposto. Lo stesso dicasi per i settori dell'industria e dell'economia all'interno dei singoli paesi: quelli piu orientati all'innovazione sono in crescita, mentre, quelli legati a dinamiche obsolete, che non hanno avuto la capacita di innovare, sono in drastica contrazione. 
Il ripetersi continuo di situazioni sempre uguali, avendo la sensazione che nulla cambi, puo essere visto come il sintomo di un attaccamento a valori non sostanziali da cui inconsciamente la societa cerca di liberarsi per far posto a modelli organizzativi piu direttamente espressione delle reali esigenze. Analogamente, la sofferenza della societa puo essere letta come espressione di una resistenza a profondi cambiamenti in atto, che sfociano talvolta in conflitti generazionali, essendo le nuove generazioni tendenzialmente piu predisposte a recepire i nuovi modelli. 
La globalizzazione e senza dubbio tra i cambiamenti che maggiormente hanno influenzato il corso degli eventi negli ultimi decenni. Senza voler alimentare la sterile diatriba tra chi e pro o contro, e indubbio che essa abbia accentuato gli squilibri tra e all'interno dei singoli paesi, forzando un riadattamento dellâ€™economia e della societa nella direzione di una maggiore efficienza e di un maggiore sviluppo tecnologico. La cosiddetta competitivita economica, il conseguimento della quale risulta necessario per garantire la sopravvivenza in un mondo globalizzato, puo anche essere vista come uno strumento ""positivo"" in grado di innescare i cambiamenti suddetti, come un pungolo atto ad evidenziare i difetti della societa, al fine di poterli correggere nell'ottica di una societa armonica e progredita. 
L'eccessiva concentrazione di risorse, corollario del processo determinatosi, e conseguenza di una lettura esclusivamente sul piano economico del processo, risulta essere una distorsione che andra gradualmente e necessariamente corretta nel corso dei prossimi anni. 
La competitivita non deve infatti essere utilizzata ideologicamente come strumento fine a se stesso, con la conseguenza di ""eliminare"" parti di societa non piu adeguate alle attuali esigenze, ma come uno strumento in grado di dare la spinta iniziale, spesso dolorosa, necessaria a staccarsi da vecchi schemi per creare dei nuovi modelli socio-economici equilibrati. 
La globalizzazione non e pero l'unica spinta esistente verso la creazione di una societa efficiente. L'alto tasso di antropizzazione del pianeta ed il conseguente impatto dell'attivita umana sul delicato ecosistema terrestre pongono un altro limite invalicabile all'inefficienza dei sistemi economico-produttivi. L'attuale pressione ambientale e tale da richiedere un ridimensionamento deN'economia se non si vogliono alterare in modo definitivo ed irrimediabile gli. L'unico modo per continuare ad espandersi vi sempre maggiori, e operare con sistemi ad altire le poche rie e con il minor spreco possibile. In tal mmite, puo diventare opportunita. 
Volgendo la riceemi aile superare i limiti di sviluppo attuali, co necessita umane, dovuto ad un naturale processocitaggiungimento di un elevato tasso di innovazun circolo virtuoso che mettera l'uomo nella condizia che cio comprometta gli equilibri ambientali, ma ancLo sviluppo tecnologico non dovra portare ara ali. In tal senso l'high-tech ed il low-tech potranno e dovranno fondersi, in accordo con il principio filosofico dell'unita degli opposti: soltanto ricercando una sintesi tra qualita contrastanti infatti sara possibile raggiungere una condizione di equilibrio: ecologia e tecnologia non si escludono, ma si completano a vicenda. 
- La ricerca dell'efficienza nel sistema edificio-impianto 
 
La ricerca dell'efficienza nel sistema economico e sociale ha delle ricadute anche nell'ambito della progettazione e costruzione degli edifici, dove negli ultimi anni si assiste ad un incremento dell'attenzione rivolta agli aspetti energetici ed ambientali. 
Il punto di partenza e il concetto di sviluppo sostenibile, che, come definito dalla Commissione Bruntland nel 1987, Â« ... e uno sviluppo che soddisfa i bisogni del presente senza compromettere la possibilita delle generazioni future di soddisfare i propriÂ» (WCED,1987). Da allora l'efficienza energetica si e diffusa sempre di piu nella cultura e nei codici dei paesi industrializzati: in Italia, dal 1991 (anno di emanazione della L. 10/91) e poi dal 2005 (anno di emanazione del D.Lgs. 192/2005) la normativa energetica in ambito edilizio ha subito importanti modifiche, e risulta allo stato attuale in continuo aggiornamento, con prospettive fino al 2020 (anno in cui, secondo la revisione della Direttiva europea EPBD sull'efficienza energetica degli edifici, tutti gli edifici di nuova costruzione dovranno essere a energia quasi zero). Quando tale percorso sara portato a termine, si potra dire che in quindici anni si e passati da un concetto di edificio a basse prestazioni energetiche, dove l'impianto sopperiva in maniera significativa alle dispersioni dell'involucro, con conseguenti costi elevati per il riscaldamento (edifici progettati in accordo alla L.10/91), ad un concetto di edificio ad altissime prestazioni, con un consumo di energia virtualmente nullo (nearly zero energy building). Questo comporta una vera e propria rivoluzione nel modo di progettare e costruire, in un lasso di tempo relativamente breve, e pone alcune questioni al contorno: 
- La prima questione e nella definizione dell'oggetto, vale a dire come si definisce un edificio a energia quasi zero? 
- La seconda considerazione riguarda la sfera tecnologica, ovvero come si progetta un edificio a energia quasi zero? Quali sono le tecnologie da impiegare al fine di realizzare un tale edificio? Quale il rapporto con i vari contesti climatici? 
- Il terzo punto riguarda le ricadute sul piano architettonico-compositivo, vale a dire quali sono i limiti che un tale standard impone a livello compositivo nella progettazione di un edificio? Il rischio potrebbe essere che per garantire eccellenti prestazioni energetiche si debba rinunciare a qualcosa sul piano della composizione, realizzando edifici estremamente rigidi come le prime passivhaus progettate in Germania negli anni'80. 
(4) L'ultima considerazione e di carattere economico: elevare costantemente le prestazioni dell'edificio (comportamento energetico, acustico, strutturale in risposta agli adeguamenti della normativa sismica) puo portare ad un incremento dei costi di costruzione insostenibile e non commisurato alle reali possibilita del mercato. Possiamo giungere quindi al paradosso di realizzare l'edificio perfetto, supertecnologico, che resiste ai terremoti ed uragani, che non consuma energia, ma che poi nessuno e in grado di permettersi, o che determina costi ambientali maggiori di quelli che sono i benefici apportati. Come ovviare dunque all'incremento dei costi? Qual e il modello da seguire? Meglio un edificio molto performante ma costoso, o meglio rinunciare ad un po' di comfort e seguire modelli piu ecologici e piu semplici da realizzare? 
Il presente lavoro parte da tali considerazioni per approfondire il concetto di edificio ad alte prestazioni energetiche nel contesto piemontese, al fine di valutare come il modello di passivhaus nato in Nord Europa, e diffusosi a partire prevalentemente dalla Germplicato, e in che modo, nella nostra regione. 
Il presente lavoro di tesi e strutturato in quattro parti: la prima, affronta il concetto di edificio a energia quasi zero da un punto di vista teorico, illustrando lo stato attuale del dibattito a partire dall'analisi di documenti presenti in letteratura; la seconda, descrive le caratteristiche tecnologiche degli edifici ad alta efficienza energetica partendo dagli esempi di passivhaus realizzati in Europa, e giungendo ad un concetto di passivhaus allargato anche ai contesti mediterranei; la terza parte descrive due ricerche in ambito europeo relativamente all'analisi degli edifici passivi (il progetto Cepheus ed il progetto Passive-On) al fine di valutare la fattibilita tecnico/economica del modello di casa passiva ed estendere poi tale concetto ai climi mediterranei; 
 
la quarta ed ultima parte invece, si propone di tradurre, attraverso l'analisi di un caso studio realizzato sul territorio piemontese, tale concetto in un modello effettivamente applicabile al Piemonte, da un punto di vista prestazionale, economico ed architettonico.",2014,
End-stage liver disease in alcohol-dependent patients,"SummaryThis case report is about aÂ 44-year-old woman with alcohol-related end-stage liver disease. Initial contact with the patient was made in the alcohol-outpatient clinic of the Department of Psychiatry and Psychotherapy, Clinical Division of Social Psychiatry, Medical University of Vienna. Due to aÂ particularly poor general condition, Child Pugh ScoreÂ C/MELD ScoreÂ 20, the patient was admitted to ward 4A, with the clinical and scientific focus of treating patients with alcohol use disorder. The withdrawal process was complicated by aÂ multitude of factors associated with end-stage liver disease. By explaining the theoretical background of possible somatic as well as psychiatric complications of end-stage liver disease and elaborating on treatment options aÂ comprehensive overview of the psychiatric and somatic management of this patient population is given.ZusammenfassungIm vorliegenden Beitrag wird der Fall einer 44-jÃ¤hrigen Frau mit alkoholassoziierter Lebererkrankung im Endstadium beschrieben. Die Erstvorstellung der Patientin erfolgte in der Ambulanz fÃ¼r AlkoholismusgefÃ¤hrdete der Klinischen Abteilung fÃ¼r Sozialpsychiatrie, UniversitÃ¤tsklinik fÃ¼r Psychiatrie und Psychotherapie, Medizinische UniversitÃ¤t Wien. Aufgrund eines ausgesprochen schlechten Allgemeinzustands mit Child-Pugh-ScoreÂ C und MELD-ScoreÂ 20 wurde die Patientin auf der StationÂ 4A, mit klinischem und wissenschaftlichem Schwerpunkt der Behandlung von Patienten mit AlkoholabhÃ¤ngigkeit, aufgenommen. Der medikamentÃ¶s-gestÃ¼tzte Entzug war durch eine Vielzahl an Faktoren, die mit einer Lebererkrankung im Endstadium zusammenhingen, erschwert. Im Beitrag wird der theoretische Hintergrund mÃ¶glicher somatischer wie auch psychiatrischer Komplikationen der Lebererkrankung im Endstadium erlÃ¤utert, zudem werden die Behandlungsoptionen ausfÃ¼hrlich beschrieben. Es wird ein umfassender Ãœberblick des psychiatrischen und somatischen Managements dieser Patientengruppe geboten.",2019,Neuropsychiatrie
Penalized differential pathway analysis of integrative oncogenomics studies,"Through integration of genomic data from multiple sources, we may obtain a more accurate and complete picture of the molecular mechanisms underlying tumorigenesis. We discuss the integration of DNA copy number and mRNA gene expression data from an observational integrative genomics study involving cancer patients. The two molecular levels involved are linked through the central dogma of molecular biology. DNA copy number aberrations abound in the cancer cell. Here we investigate how these aberrations affect gene expression levels within a pathway using observational integrative genomics data of cancer patients. In particular, we aim to identify differential edges between regulatory networks of two groups involving these molecular levels. Motivated by the rate equations, the regulatory mechanism between DNA copy number aberrations and gene expression levels within a pathway is modeled by a simultaneous-equations model, for the one- and two-group case. The latter facilitates the identification of differential interactions between the two groups. Model parameters are estimated by penalized least squares using the lasso (L1) penalty to obtain a sparse pathway topology. Simulations show that the inclusion of DNA copy number data benefits the discovery of gene-gene interactions. In addition, the simulations reveal that cis-effects tend to be over-estimated in a univariate (single gene) analysis. In the application to real data from integrative oncogenomic studies we show that inclusion of prior information on the regulatory network architecture benefits the reproducibility of all edges. Furthermore, analyses of the TP53 and TGFb signaling pathways between ER+ and ER- samples from an integrative genomics breast cancer study identify reproducible differential regulatory patterns that corroborate with existing literature.",2014,Statistical Applications in Genetics and Molecular Biology
