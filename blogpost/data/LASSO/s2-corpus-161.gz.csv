title,abstract,year,journal
Species limits in Vachellia (Acacia) karroo (Mimosoideae: Leguminoseae): Evidence from automated ISSR DNA â€œfingerprintingâ€,"Vachellia karroo (Hayne) Banfi & Galasso, previously known as Acacia karroo Hayne, is a very common woody species in South Africa, and displays a large amount of morphological and architectural variation. Previous morphological studies have provided evidence to support the recognition of a number of segregate species, but this has not been supported by early protein electrophoresis studies. Genetic variability of the species throughout South Africa was examined by means of the Inter-Simple Sequence Repeat (ISSR) DNA â€œfingerprintingâ€ to determine whether there is any genetic structure that correlates to the morphological diversity. Based upon 33 samples from across the South African distribution of this species, we found no evidence for any genetic structuring, suggesting the species is one panmictic entity. The existence of morphologically discrete varieties in light of this genetic finding is difficult to explain, and perhaps the species ought to be considered as an ochlospecies. A scenario whereby the various morphotypes evolved in refugia during previous climates followed by subsequent expansion and introgression during the current interglacial may explain this conundrum. Alternatively, the evolution of the morphotypes has been recent and rapid, and the genetic variation observed here represents the ancestral gene pool that has not yet undergone lineage sorting as a consequence of isolation.",2012,South African Journal of Botany
Adaptive multi-view clustering via cross trace lasso,"We propose a novel multi-view clustering method by learning auto-regression problems under structural constraints and treating the regression coefficients as new feature representations for the cluster partition. In particular, we take the data intrinsic correlation structure into account. Correlated data under one view tend to be also related under another view and are likely to fall into the same group. Therefore we pair the data matrix from one view and the regression coefficient from a different view together to meet a trace Lasso constraint, which adaptively adjusts the sparsity of regression coefficients in order to promote consistent data correlations across views. Then a joint low-rank constraint is further imposed to encourage similar regression coefficients for the same samples under distinct views. Finally, we develop an effective algorithm to optimize the objective function. And experimental results demonstrate that our method is useful and fairly competitive compared with other state-of-the-art multi-view clustering methods.",2015,2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)
Detection of Green Turtle Herpesviral Sequence in Saddleback Wrasse Thalassoma duperrey: A Possible Mode of Transmission of Green Turtle Fibropapilloma.,"Samples of DNA were prepared from various tissues and organs (including snout, gill, eye, brain, heart, liver, gut content, intestine, swim bladder, spleen, gallbladder, spinal cord, gonad, and muscle) of six healthy appearing reef cleaner fish, saddleback wrasses Thalassoma duperrey, captured from a cleaning station in North Kaneohe Bay, Oahu, Hawaii. The DNA samples were tested for evidence of green turtle herpesvirus infection by nested polymerase chain reaction (PCR). Green turtle herpesviral sequences were detected in snout (3/6), gill (2/6), and liver (1/6). All other tissues were negative. Except for a single nucleotide substitution (from A to G at position 48, resulting in a single amino acid change from isoleucine to methionine at position 16), the DNA sequences detected in the fish were identical to that of a newly reported green turtle herpesvirus. Although preliminary, these data represent the first evidence for an association of a herpesvirus with saddleback wrasse, suggesting that cleaner fish may serve as vectors or carriers for the transmission of the agent causing green turtle fibropapilloma.",2000,Journal of aquatic animal health
Microfluidic system and manufacturing process for a microfluidic system,"Die Erfindung betrifft ein mikrofluidisches System (1) mit einem Mikrofluidikchip (2) und einer Kapillare (9, 9', 9'', 9'''), wobei ein Endstuck (8, 8', 8'', 8''') der Kapillare (9, 9', 9'', 9''') in eine Ein/Auslassoffnung (4, 4', 4'', 4''') des Mikrofluidikchips (2) eingefuhrt ist und die Kapillare (9, 9', 9'', 9''') mit dem Mikrofluidikchip (2) stoffschlussig verbunden ist, wobei das in die Ein/Auslassoffnung (4, 4', 4'', 4''') eingefuhrte Endstuck (8, 8', 8'', 8''') der Kapillare (9, 9', 9'', 9''') mit einer Innenwand (11, 11', 11'', 11''') der Ein/Auslassoffnung (4, 4', 4'', 4'''), welche durch Teilbereiche eines mindestens eine Substratschicht (3, 3', 3'', 3''') umfassenden Substrats des Mikrofluidikchips (2) gegeben ist, durch Erwarmen stoffschlussig verbunden ist. Die Erfindung betrifft ferner ein Herstellungsverfahren fur ein derartiges mikrofluidisches System (1).",2010,
Sparsity considerations for dependent variables,"The aim of this paper is to provide a comprehensive introduc- tion for the study of `1-penalized estimators in the context of dependent observations. We define a general `1-penalized estimator for solving prob- lems of stochastic optimization. This estimator turns out to be the LASSO (Tib96) in the regression estimation setting. Powerful theoretical guaran- tees on the statistical performances of the LASSO were provided in recent papers, however, they usually only deal with the iid case. Here, we study this estimator under various dependence assumptions.",2011,Electronic Journal of Statistics
Genome-wide Association Study for Beta-glucan Concentration in Elite North American Oat,"Genome-wide association studies (GWAS) can be a useful approach to detect quantitative trait loci (QTL) controlling complex traits in crop plants. oat (Avena sativa L.) b-glucan is a soluble dietary fiber and has been shown to have positive health benefits. We report a GWAS involving 446 elite oat breeding lines from North America genotyped with 1005 diversity arrays technology (DArT) markers and with phenotypic data from both historical and balanced 2-yr data. Association analyses accounting for pairwise relationships and population structure were conducted using single-marker tests and least absolute shrinkage and selection operator (LASSo). Single-marker tests yielded six and 15 significant markers for the historical and balanced data sets, respectively. The LASSo method selected 24 and 37 markers as the most important in explaining b-glucan concentration for the historical and balanced data sets, respectively. Comparisons of genetic location showed that 15 of the markers in our study were found on the same linkage groups as QTL identified in previous studies. Four of the markers colocalized to within 4 cM of three previously detected QTL, suggesting concordance between QTL detected in our study and previous studies. Two of the significant markers were also adjacent to a b-glucan candidate gene in the rice (Oryza sativa L.) genome. our findings suggest that GWAS can be used for QTL detection for the purpose of gene discovery and for marker-assisted selection to improve b-glucan concentration in elite oat. F.G. Asoro, M.A. Newell, and W.D. Beavis, Dep. of Agronomy, Iowa State Univ., Ames, IA 50011; M.P. Scott, USDA-ARS, Corn Insects and Crop Genetics Research Unit, Dep. of Agronomy, Ames, IA 50011; J.-L. Jannink, USDA-ARS, R.W. Holley Center for Agriculture and Health, Dep. of Plant Breeding and Genetics, Cornell Univ., Ithaca, NY 14853. Received 20 Jan. 2012. *Corresponding author (jeanluc.jannink@ars.usda.gov). Abbreviations: AIC, Akaike Information Criterion; BLAST, basic local alignment search tool; BLUP, best linear unbiased prediction; CesA2, cellulose synthase A catalytic subunit 2; Csl, cellulose synthaseâ€“like; DArT, diversity arrays technology; FDR, false discovery rate; GWAS, genome-wide association studies; LASSO, least absolute shrinkage and selection operator; LD, linkage disequilibrium; OPN, oat performance nurseries; PC, principal component; PCA, principal component analysis; PK, population structure + kinship model; QTL, quantitative trait loci. Published in Crop Sci. 53:542â€“553 (2013). doi: 10.2135/cropsci2012.01.0039 Â© Crop Science Society of America | 5585 Guilford Rd., Madison, WI 53711 USA All rights reserved. No part of this periodical may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any information storage and retrieval system, without permission in writing from the publisher. Permission for printing and for reprinting the material contained herein has been obtained by the publisher. Published February 6, 2013",2013,Crop Science
EffektivitÃ¤t und Sicherheit der elektrophysiologisch gefÃ¼hrten Pulmonalvenenablation bei Patienten mit medikamentÃ¶s therapierefraktÃ¤rem symptomatischem paroxysmalem und persistierendem Vorhofflimmern,"Hintergrund: Vorhofflimmern ist die haufigste atriale Rhythmusstorung mit einer aufgrund demographischer Faktoren zunehmenden Inzidenz. Nach einer Pionierarbeit von Haissaguerre ist mit der sich daraus entwickelnden Pulmonalvenenablation erstmals ein kuratives interventionelles Therapieverfahren eingefuhrt worden. Ziel der Studie: In der vorliegenden Arbeit verglichen wir das bis dato etablierte Ablationsverfahren unter Einsatz des Lasso-Katheters und eines 4 mm Ablationskatheters mit einem alternativen Verfahren, bei dem mit dem neuartigen zirkularen Helix-Katheter nur ein Katheter fur Mapping und Ablation simultan eingesetzt wurde, hinsichtlich Effektivitat und Sicherheit bei Patienten mit paroxysmalem und persistierendem Vorhofflimmern. Material und Methode: In eine prospektive, nicht randomisierte Beobachtungsstudie schlossen wir konsekutiv 38 Patienten mit symptomatischem, medikamentos therapierefraktarem Vorhofflimmern ein. 29 Patienten litten unter paroxysmalem, 9 Patienten unter persistierendem Vorhofflimmern. Die Pulmonalvenenablation nach elektrophysiologisch orientiertem Ansatz wurde bei 24 Patienten mit dem Lasso-Katheter und bei 14 Patienten mit dem Helix-Katheter vorgenommen. Die Nachbeobachtung hinsichtlich der Effektivitat wurde mittels Tele-EKG, Langzeit-EKG und Patientenbefragung vorgenommen, Komplikationen wurden mit Hilfe der TEE und der CT beurteilt. Ergebnisse: Nach 5 Â± 5 Monaten unterschieden sich die Erfolgsraten in der Lasso-Gruppe mit 52% (Sinusrhythmus 39%, Reduktion der Vorhofflimmerlast 13%) und in der Helix-Gruppe mit 50% (Sinusrhythmus 43%, Reduktion der Vorhofflimmerlast 7%) nicht voneinander. Hingegen lag die Erfolgsrate bei Patienten mit paroxysmalem Vorhofflimmern mit 64% (Sinusrhythmus 54%, Reduktion der Vorhofflimmerlast 11%) deutlich hoher als die Erfolgsrate bei Patienten mit persistierendem Vorhofflimmern (Sinusrhythmus 0%, Reduktion der Vorhofflimmerlast 11%) (p=0,005). Die hohere Komplikationsrate in der Lasso-Gruppe (Pulmonalvenenstenose 8,3% versus 0% in der Helix-Gruppe; Perikardtamponade n=1 versus n=0; jeweils eine TIA in beiden Gruppen) durfte zum Teil durch die verwendete Technik bedingt und zum anderen auf die Lernkurve zuruckzufuhren sein, da die initialen Ablationen mit dem Lasso-Katheter durchgefuhrt wurden. Fazit: Die Pulmonalvenenablation nach elektrophysiologisch orientiertem Ansatz ist ein mit beiden in unserem Kollektiv verwendeten Kathetersystemen gut durchfuhrbares Verfahren, wobei sich die Erfolgsrate nach Erstintervention und die Komplikationsrate mit den Angaben in der Literatur decken. Die Erfolgsraten liegen bei Patienten mit paroxysmalem Vorhofflimmern deutlich hoher als bei Patienten mit persistierendem Vorhofflimmern. Die Limitationen unserer Studie liegen in der fehlenden Randomisierung und in einem relativ kurzen Follow-up Zeitraum. In der Zukunft wird sich die Methode zum einen technisch weiterentwickeln, zum anderen werden Langzeit- und Multicenterstudien mit einheitlichem Studiendesign sowie der Aufbau von umfassenden nationalen und internationalen Registern erforderlich sein, um den Wert der verschiedenen Methoden hinsichtlich Effektivitat und Sicherheit exakter beurteilen und damit Indikationen und Leitlinien differenzierter aufstellen zu konnen.",2010,
Stagewise Estimating Equations,"Stagewise estimation is a slow-brewing approach for model building that has recently experienced a revival due to its computational efficiency, its flexibility in handling complex data structures, and its intrinsic connections with penalized estimation. Synthesizing generalized estimating equations to handle correlated non-Gaussian data with stagewise techniques, this thesis proposes general stagewise estimation approaches that perform model selection in the presence of complex covariate structures. First, the setting where there is a prior covariate grouping structure or hierarchy is considered. As the grouping structure in practice is often not ideal as even important groups may contain unimportant variables, the key is to simultaneously conduct group selection and within-group variable selection, or in other words, bi-level selection. This thesis presents two approaches to address the challenge. The first is the bi-level stagewise estimating equations (BiSEE) approach, which is shown to correspond to the sparse group lasso penalized regression. The second is the hierarchical stagewise estimating equations (HiSEE) approach that can handle a more general hierarchical grouping structure, in which each stagewise estimation step itself is executed as a hierarchical selection process based on the grouping structure. The second setting explored is regression with interaction terms. As it is often required that main effect terms be included when an interaction term is part of a model, the goal is to perform variable selection that maintains the variable hierarchy. Two approaches are proposed by this thesis. The first is a hierarchical lasso stagewise estimating equations approach, which is shown to directly correspond to the hierarchical lasso penalized regression. The second is a stagewise active set approach, which enforces the variable hierarchy by conforming the selection to a properly growing active set in each stagewise estimation step. Simulation studies are presented to show the efficacy and superior computational efficiency of the proposed approaches. The approaches are also used to study the association between the suicide-related hospitalization rates among 15â€“19 year olds in Connecticut and the characteristics of the school districts in which they reside. Stagewise Estimating Equations Gregory Phillip Lucas Vaughan B.S., Mathematics, Trinity College, CT, USA, 2012 B.S., Computer Science, Trinity College, CT, USA, 2012 A Dissertation Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy at the University of Connecticut 2017",2017,
Development and validation of a gene profile predicting benefit of postmastectomy radiotherapy in patients with high-risk breast cancer: a study of gene expression in the DBCG82bc cohort.,"PURPOSE
To identify genes predicting benefit of radiotherapy in patients with high-risk breast cancer treated with systemic therapy and randomized to receive or not receive postmastectomy radiotherapy (PMRT).


EXPERIMENTAL DESIGN
The study was based on the Danish Breast Cancer Cooperative Group (DBCG82bc) cohort. Gene-expression analysis was performed in a training set of frozen tumor tissue from 191 patients. Genes were identified through the Lasso method with the endpoint being locoregional recurrence (LRR). A weighted gene-expression index (DBCG-RT profile) was calculated and transferred to quantitative real-time PCR (qRT-PCR) in corresponding formalin-fixed, paraffin-embedded (FFPE) samples, before validation in FFPE from 112 additional patients.


RESULTS
Seven genes were identified, and the derived DBCG-RT profile divided the 191 patients into ""high LRR risk"" and ""low LRR risk"" groups. PMRT significantly reduced risk of LRR in ""high LRR risk"" patients, whereas ""low LRR risk"" patients showed no additional reduction in LRR rate. Technical transfer of the DBCG-RT profile to FFPE/qRT-PCR was successful, and the predictive impact was successfully validated in another 112 patients.


CONCLUSIONS
A DBCG-RT gene profile was identified and validated, identifying patients with very low risk of LRR and no benefit from PMRT. The profile may provide a method to individualize treatment with PMRT.",2014,Clinical cancer research : an official journal of the American Association for Cancer Research
Prioritizing predicted cis-regulatory elements for co-expressed gene sets based on Lasso regression models,Computational prediction of cis-regulatory elements for a set of co-expressed genes based on sequence analysis provides an overwhelming volume of potential transcription factor binding sites. It presents a challenge to prioritize transcription factors for regulatory functional studies. A novel approach based on the use of Lasso regression models is proposed to address this problem. We examine the ability of the Lasso model using time-course microarray data obtained from a comprehensive study of gene expression profiles in skin and mucosal wounds in mouse over all stages of wound healing.,2011,2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society
A Theoretical Analysis of Sparse Recovery Stability of Dantzig Selector and LASSO,"Dantzig selector (DS) and LASSO problems have attracted plenty of attention in statistical learning, sparse data recovery and mathematical optimization. In this paper, we provide a theoretical analysis of the sparse recovery stability of these optimization problems in more general settings and from a new perspective. We establish recovery error bounds for these optimization problems under a mild assumption called weak range space property of a transposed design matrix. This assumption is less restrictive than the well known sparse recovery conditions such as restricted isometry property (RIP), null space property (NSP) or mutual coherence. In fact, our analysis indicates that this assumption is tight and cannot be relaxed for the standard DS problems in order to maintain their sparse recovery stability. As a result, a series of new stability results for DS and LASSO have been established under various matrix properties, including the RIP with constant $\delta_{2k}< 1/\sqrt{2}$ and the (constant-free) standard NSP of order $k.$ We prove that these matrix properties can yield an identical recovery error bound for DS and LASSO with stability coefficients being measured by the so-called Robinson's constant, instead of the conventional RIP or NSP constant. To our knowledge, this is the first time that the stability results with such a unified feature are established for DS and LASSO problems. Different from the standard analysis in this area of research, our analysis is carried out deterministically, and the key analytic tools used in our analysis include the error bound of linear systems due to Hoffman and Robinson and polytope approximation of symmetric convex bodies due to Barvinok.",2017,arXiv: Statistics Theory
Observations sur le Primaire de la region de Bobo-Dioulasso (Haute-Volta),"A 400 meter-deep borehole through the Paleozoic section at Bobo-Dioulasso in the upper Volta region, western Africa, shows that the Bobo sandstones are thicker than heretofore mapped and that there is a schistose formation at least 70 meters thick in the upper part of the Sotuba sandstones, to which the schist belt northeast and southeast of Dedougou, originally mapped as the Toun schists, belongs. Other details of the stratigraphy are reported.",1960,Bulletin De La Societe Geologique De France
Enhanced Production of Îº-Carrageenase and Îº-Carrageenan Oligosaccharides through Immobilization of Thalassospira sp. Fjfst-332 with Magnetic Fe3O4-Chitosan Microspheres.,"In this study, immobilized bacteria (IMB) microsphere was prepared by embedding Îº-carrageenase-producing Thalassospira sp. Fjfst-332 (TF332) onto a magnetic Fe3O4-chitosan carrier. The performance of Fe3O4-chitosan carrier was optimized by comparing its bacteria immobilization capacity at different Fe3O4:chitosan ratios and temperatures, while the functions of IMB microspheres were characterized by examining their Îº-carrageenase production at different temperatures, pH's, and reuse cycles. At the 1:1 (w:w) Fe3O4:chitosan ratio, the Fe3O4-chitosan carriers possessed sufficient anchoring capacity for bacterial immobilization without significant compromise of their magnetism for magnetic separation of IMB from culture media. The spectroscopic analysis of IMB microspheres indicated that the immobilization of TF332 might affect the amide groups in chitosan. Compared to free bacteria, IMB can produce Îº-carrageenase at higher temperature, wider pH range, and faster rate. More importantly, the Îº-carrageenase-producing activity was sustained for at least seven reuse cycles. The major Îº-carrageenan degradation products of IMB-derived Îº-carrageenase were the oligosaccharides containing two to six monosaccharide units. Overall, this Fe3O4-chitosan-TF-332 microsphere has the potential to become a stable and reusable platform for large-scale production of Îº-carrageenan oligosaccharides.",2017,Journal of agricultural and food chemistry
"Crenobalneotherapy in fibromyalgia, a systematic review","The purpose of the study is to find and summarize the best evidence for crenobalneotherapy in fibromyalgia syndrome. 
Method 
Bibliographic analysis. Performed by 3 reviewers (FBF, AD, ND), on multiple databases with keywords: â€œFibromyalgiaâ€ AND â€œspaâ€ OR â€œbalneotherapyâ€ OR â€œhydrotherapyâ€ OR â€œmudâ€ OR â€œpeloidâ€ OR â€œbathâ€ OR â€œpoolâ€ OR â€œthalassotherapyâ€ OR â€œmineral waterâ€ OR â€œhot bathâ€ OR â€œaquaticâ€ OR â€œthermal waterâ€. 
Inclusion criteria were: comparative studies evaluating interventions of 1 to 6 weeks, diagnostic of fibromyalgia with 1990 ACR classification criteria, trials performed after 1990, No restriction in length of follow up, studies in English, French, and Turkish. 
Methodological analysis. Internal validity is estimated by CLEAR NTP (10 items): evaluating selection bias, performance bias, detection bias & attrition bias. 
External validity & Statistical validity is estimated by personal checklists. We also performed an empirical analysis of publication bias by the graphical test proposed by Sutton (Sutton BMJ 2012).",2018,
Multiscale analysis and nonlinear dynamics : from genes to the brain,"Introduction - Multiscale Analysis: Modeling, Data, Networks, and Dynamics I. MULTIRESOLUTION ANALYSIS Mathieu Desbrun, Roger D. Donaldson, Houman Owhadi: Discrete Geometric Structures in Homogenization and Inverse Homogenization Isaac Z. Pesenson: Multiresolution Analysis on Compact Riemannian Manifolds II. NONLINEAR DYNAMICS of TRANSCRIPTION NETWORKS and SYNTHETIC BIOCHEMICAL CIRCUITS Elisa Franco, Jongmin Kim, Friedrich Simmel: Dynamics of synthetic transcription networks Raphael Plasson, Yannick Rondelez: Synthetic biochemical dynamic circuits III. NONLINEAR DYNAMICS: THE BRAIN AND THE HEART Paul L. Nunez, Ramesh Srinivasan, Lester Ingber: Theoretical and experimental electrophysiology in human neocortex: multiscale dynamic correlates of conscious experience Danielle S. Bassett, Felix Siebenhuhner: Multiscale network organization in the human brain Michel Le Van Quyen, Vicente Botella-Soler, Mario Valderrama: Neuronal oscillations scale up and scale down the brain dynamics Michael X. Cohen, Bradley Voytek: Linking nonlinear neural dynamics to single-trial human behavior Etienne Hugues, Juan R. Vidal, Jean-Philippe Lachaux, Gustavo Deco: Brain dynamics at rest: how structure shapes dynamics Misha Z. Pesenson: Adaptive multiscale encoding - a computational function of neuronal synchronization Zhilin Qu, Michael Nivala: Multi-scale nonlinear dynamics in cardiac electrophysiology: from sparks to sudden death Connor Houghton, Thomas Kreuz: Measures of spike train synchrony: from single neurons to populations",2013,
A modified multinomial baseline logit model with logit functions having different covariates,"The multinomial logistic regression is a useful tool in the health and life sciences. In this paper, we propose a modified multinomial baseline logit model for nominal polychotomous data. The modified model is suitable for use in the situation where separate logistic models may be functions of different covariates. An estimation procedure is presented. The modified model is an alternative to the multinomial baseline logit model and the multivariate sparse group lasso. Simulation shows that this modified model outperforms the multinomial baseline logit model and the multinomial sparse group lasso. A real data set about an adolescent placement study is analyzed to demonstrate flexibility and efficiency of the modified model.",2019,Communications in Statistics - Simulation and Computation
[Complications of the biopsy of prostate transrectal ecoguide: about a case].,"Oh RC, Hustead TR. Causes and evaluation of mildly elevated liver transaminase levels. Am Fam Physician. 2011;84:1003--8. Davidson DF, Watson DJM. Macroenzyme detection by polyethyleneglycol precipitation. Ann Clin Biochem. 2003;40:514--20. Lee M, Vajro P, Keeffe EB. Isolated aspartate aminotransferase elevation: think macro-AST. Dig Dis Sci. 2011;56:311--3. Galasso PJ, Litin SC, Oâ€™Brien JF. The macroenzymes: a clinical review. Mayo Clin Proc. 1993;68:349--54. Turecky L. Macroenzymes and their clinical significance. Bratisl Lek Listy. 2004;105:260--3. Diego Martinez-Urbistondo âˆ— y Bruno Sangro",2013,Gastroenterologia y hepatologia
Efficient method for solving one norm equality constrained problem,"The paper proposes an efficient method for solving a one norm equality constrained optimization problem. In fact, this kind of optimization problems is nonconvex. First, the problem is formulated as the least absolute shrinkage and selection operator (LASSO) optimization problem. Then, it is solved by iterative shrinkage algorithms such as the fast iterative shrinkage thresholding algorithm (FISTA). Next, the solution of the LASSO optimization problem is employed for formulating the constraint of the corresponding least squares constrained optimization problem. The solution of the least squares constrained optimization problem is taken as a near globally optimal solution of the one norm equality constrained optimization problem. Computer numerical simulation results show that our proposed method outperforms existing methods in terms of the accuracy of the obtained solution satisfying the one norm equality constraint.",2014,"2014 9th International Symposium on Communication Systems, Networks & Digital Sign (CSNDSP)"
Interactive visual exploration of halos in large-scale cosmology simulation,"Halo is one of the most important basic elements in cosmology simulation, which merges from small clumps to ever larger objects. The processes of halosâ€™ birth and merging play a fundamental role in studying theÂ evolution of large-scale cosmological structure. In this paper, a visual analysis system is developed to interactively identify and explore the evolution histories of thousands of halos. In this system, an intelligent structure-aware selection method in What You See Is What You Get manner is designed to efficiently define userâ€™s interesting region in 3D space with 2D hand-drawn lasso input. Then the exact information of halos within this 3D region is identified by data mining in the merger tree files. To avoid visual clutter, all the halos are projected in 2D space with MDS method. Through the linked view of 3D view and 2D graph, users can interactively explore these halos, including the tracing path and theÂ evolution history tree.Graphical abstract",2014,Journal of Visualization
Block-sparse Solutions using Kernel Block RIP and its Application to Group Lasso,"We propose kernel block restricted isometry property (KB-RIP) as a generalization of the well-studied RIP and prove a variety of results. First, we present a â€œsumof-normsâ€-minimization based formulation of the sparse recovery problem and prove that under suitable conditions on KB-RIP, it recovers the optimal sparse solution exactly. The Group Lasso formulation, widely used as a good heuristic, arises naturally from the Lagrangian relaxation of our formulation. We present an efficient combinatorial algorithm for provable sparse recovery under similar assumptions on KB-RIP. This result improves the previously known assumptions on RIP under which a combinatorial algorithm was known. Finally, we provide numerical evidence to illustrate that not only are our sumof-norms-minimization formulation and combinatorial algorithm significantly faster than Lasso, they also outperforms Lasso in terms of recovery.",2011,
"Conservation genetics and ecology of the endangered heathland shrub, Allocasuarina emuina","The subtropical coastal heathlands of south-east Queensland have undergone considerable habitat loss in recent years due to high levels of urbanisation. This study used morphological and microsatellite markers to investigate the reproductive ecology and population genetic structure of the endangered wind-pollinated shrub, Allocasuarina emuina, and its risk of genetic assimilation by a common congener, A. littoralis. Differences in breeding system were found between the dioecious population of A. emuina on Mt. Emu and the monoecious, wet heath populations of the coastal plain. Highly significant differences (p A. littoralis appear to be maintaining species boundaries. An examination of the genetic relationships between A. littoralis, A. emuina and three other restricted, â€˜dioeciousâ€™ species from the region, A. thalassoscopica (E), A. rigida ssp. exsul (V), and A. filidens (R), found genotypes of the four threatened taxa to each be composed of a limited subset of A. littoralis alleles, with varying proportions of identical multilocus profiles, indicating both facultative apomixis and sexual reproduction. Chromosome determinations confirmed A. littoralis as an autopolyploid (2n = 22, 33, 44), whereas the four threatened species were found to be either diploid (A. rigida ssp. exsul, 2n = 22), triploid (A. filidens, 2n = 33), or tetraploid (A. emuina and A. thalassoscopica, 2n = 44). Negligible differentiation was detected among species at either the matK or the JLA chloroplast regions, implying that diversification from the putative progenitor, A. littoralis, has been relatively recent. Minimal morphological, cytological, or genetic differentiation was found between the single population of A. thalassoscopica and A. emuina, which suggests that the status of A. thalassoscopica as a separate taxon should be reviewed.; ; Submitted in the fulfilment of the requirements of the degree of Doctor of Philosophy, University of the Sunshine Coast, 2010.",2010,
Deep convolutional neural network for mammographic density segmentation,"Breast density is one of the most significant factors for cancer risk. In this study, we proposed a supervised deep learning approach for automated estimation of percentage density (PD) on digital mammography (DM). The deep convolutional neural network (DCNN) was trained to estimate a probability map of breast density (PMD). PD was calculated as the ratio of the dense area to the breast area based on the probability of each pixel belonging to dense region or fatty region at a decision threshold of 0.5. The DCNN estimate was compared to a feature-based statistical learning approach, in which gray level, texture and morphological features were extracted from each ROI and the least absolute shrinkage and selection operator (LASSO) was used to select and combine the useful features to generate the PMD. The reference PD of each image was provided by two experienced MQSA radiologists. With IRB approval, we retrospectively collected 347 DMs from patient files at our institution. The 10-fold cross-validation results showed a strong correlation r=0.96 between the DCNN estimation and interactive segmentation by radiologists while that of the feature-based statistical learning approach vs radiologistsâ€™ segmentation had a correlation r=0.78. The difference between the segmentation by DCNN and by radiologists was significantly smaller than that between the feature-based learning approach and radiologists (p < 0.0001) by two-tailed paired t-test. This study demonstrated that the DCNN approach has the potential to replace radiologistsâ€™ interactive thresholding in PD estimation on DMs.",2018,
Prediction models for solitary pulmonary nodules based on curvelet textural features and clinical parameters.,"Lung cancer, one of the leading causes of cancer-related deaths, usually appears as solitary pulmonary nodules (SPNs) which are hard to diagnose using the naked eye. In this paper, curvelet-based textural features and clinical parameters are used with three prediction models [a multilevel model, a least absolute shrinkage and selection operator (LASSO) regression method, and a support vector machine (SVM)] to improve the diagnosis of benign and malignant SPNs. Dimensionality reduction of the original curvelet-based textural features was achieved using principal component analysis. In addition, non-conditional logistical regression was used to find clinical predictors among demographic parameters and morphological features. The results showed that, combined with 11 clinical predictors, the accuracy rates using 12 principal components were higher than those using the original curvelet-based textural features. To evaluate the models, 10-fold cross validation and back substitution were applied. The results obtained, respectively, were 0.8549 and 0.9221 for the LASSO method, 0.9443 and 0.9831 for SVM, and 0.8722 and 0.9722 for the multilevel model. All in all, it was found that using curvelet-based textural features after dimensionality reduction and using clinical predictors, the highest accuracy rate was achieved with SVM. The method may be used as an auxiliary tool to differentiate between benign and malignant SPNs in CT images.",2013,Asian Pacific journal of cancer prevention : APJCP
Transcriptome analysis of expressed sequence tags from the venom glands of the fish Thalassophryne nattereri.,"Thalassophryne nattereri (niquim) is a venomous fish found on the northern and northeastern coasts of Brazil. Every year, hundreds of humans are affected by the poison, which causes excruciating local pain, edema, and necrosis, and can lead to permanent disabilities. In experimental models, T. nattereri venom induces edema and nociception, which are correlated to human symptoms and dependent on venom kininogenase activity; myotoxicity; impairment of blood flow; platelet lysis and cytotoxicity on endothelial cells. These effects were observed with minute amounts of venom. To characterize the primary structure of T. nattereri venom toxins, a list of transcripts within the venom gland was made using the expressed sequence tag (EST) strategy. Here we report the analysis of 775 ESTs that were obtained from a directional cDNA library of T. nattereri venom gland. Of these ESTs, 527 (68%) were related to sequences previously described. These were categorized into 10 groups according to their biological functions. Sequences involved in gene and protein expression accounted for 14.3% of the ESTs, reflecting the important role of protein synthesis in this gland. Other groups included proteins engaged in the assembly of disulfide bonds (0.5%), chaperones involved in the folding of nascent proteins (1.4%), and sequences related to clusterin (1.5%), as well as transcripts related to calcium binding proteins (1.0%). We detected a large cluster (1.3%) related to cocaine- and amphetamine-regulated transcript (CART), a peptide involved in the regulation of food intake. Surprisingly, several retrotransposon-like sequences (1.0%) were found in the library. It may be that their presence accounts for some of the variation in venom toxins. The toxin category (18.8%) included natterins (18%), which are a new group of kininogenases recently described by our group, and a group of C-type lectins (0.8%). In addition, a considerable number of sequences (32%) was not related to sequences in the databases, which indicates that a great number of new toxins and proteins are still to be discovered from this fish venom gland.",2006,Biochimie
The Economic Impact of Large Petroleum Investments on Local Regions in Norway: A Synthetic Control Analysis Using Machine Learning Techniques,"Large investments in connection with extraction of natural resources can cause changes in the local economy of the associated municipalities. In this thesis, the effects of several large petroleum investments on the local economy of three Norwegian municipalities post year 1993 were examined using econometric techniques. Specifically, the effects on size, activity and composition of local â€˜cornerstoneâ€™ industries and the general population were investigated. Synthetic Control (SC) analysis was utilized to measure the unknown counterfactual of the selected municipalities. Biases related to variable selection were mitigated using the Least Absolute Shrinkage and Selection Operator (LASSO) methodology on datasets consisting of up to 6400 various economic and demographic indicators. The findings show that the size and activity of the local economy most likely increased despite that the investments presumably crowded out existing cornerstone industries. As for demographics, results strongly indicate an investment-induced increase in number of citizens within both extremes of the educational attainment spectrum, with multifaceted effects on individual pre-tax income. Furthermore, there was credible evidence of an investment-specific decrease in joband income-security along with increased frequency in municipal relocation. However, this might have been rooted in labour market liberalizations seen in the period after year 1993. In summary, the petroleum investments seem to have largely benefitted the local economy for two of the municipalities examined. Whereas the third did not seem to experience similar effects. Abstract (Norwegian version)Norwegian version) Store investeringer i forbindelse med utvinning av naturressurser kan i visse sammenhenger fÃ¸re til endringer i lokalÃ¸konomien hos tilknyttede kommuner. I denne oppgaven ble effekten av flere store petroleumsinvesteringer pÃ¥ lokalÃ¸konomien i tre norske kommuner etter Ã¥r 1993 undersÃ¸kt ved hjelp av Ã¸konometriske teknikker. Spesielt ble effekten pÃ¥ stÃ¸rrelse, aktivitet og sammensetning av lokale ""hjÃ¸rnesteinsindustrier"" og befolkningen i befolkningen undersÃ¸kt. Syntetiske kontroller ble brukt til Ã¥ mÃ¥le den ukjente kontrafaktiske versjonen av kommunen, mens biaser relatert til variabelseleksjon ble redusert ved hjelp av Least Absolute Shrinkage and Selection Operator (LASSO) metodikk pÃ¥ datasett som bestÃ¥r av opptil 6400 ulike Ã¸konomiske og demografiske indikatorer. Resultatene viser at stÃ¸rrelsen og aktiviteten til den lokale Ã¸konomien mest sannsynlig Ã¸kte til tross for at investeringene trolig medfÃ¸rte et press pÃ¥ sysselsettingen innen eksisterende hjÃ¸rnesteinsnÃ¦ringer. NÃ¥r det gjelder demografi ble det funnet sterke indikasjoner pÃ¥ at investeringene medfÃ¸rte en Ã¸kning i antall borgere innenfor begge ekstremer av utdanningsspekteret, med flere kommuneog/eller investeringsspesifikke effekter pÃ¥ indviduell inntekt fÃ¸r skatt. Dataene indikerte ogsÃ¥ en investeringsspesifikk nedgang i arbeidsog inntektssikkerhet sammen med en Ã¸kt flyttefrekvens, men dette har muligens hatt sin rot i liberaliseringer av arbeidsmarkedet etter 1993. Samlet sett ser det ut til at effektene av petroleumsinvesteringene har vÃ¦rt positive for to av kommunene. Det var ikke mulig Ã¥ finne en tilsvarende effekt pÃ¥ den tredje kommunen.",2019,
Collateralismo e disimpegno. Chiesa e cattolici in Austria tra autoritarismo e democrazia (1932-1952),"La proclamazione della Prima repubblica austriaca nel novembre del â€˜18, col conseguente collasso della monarchia asburgica, secolare punto di riferimento politico della Chiesa nel panorama mitteleuropeo, privo la gerarchia ecclesiastica della sua funzione di mediazione tra il potere politico e la societa civile. Se lâ€™affermazione dello Stato autoritario-corporativo (Standestaat) di Dollfuss consenti alla Chiesa di recuperare un ruolo preminente nella societa, cio porto allâ€™estremizzazione del cattolicesimo politico, contribuendo a rendere la religione cattolica un elemento di divisione fra le classi e minando alle fondamenta la democrazia. Il disimpegno politico voluto dai vescovi austriaci nel 1934 e lâ€™occupazione nazista del paese (1938-45) costituiranno le premesse per quella rimodulazione dei rapporti fra Stato e Chiesa che, con lâ€™abbandono del collateralismo politico in favore di una linea piu attenta alle mutate esigenze pastorali del paese, culmineranno col â€œManifesto di Mariazellâ€ e il Katholikent...",2013,Revue d'Histoire EcclÃ©siastique
"Interpretive and Supportive Psycho- therapies: Matching Therapy and Patient Personality. William E. Piper,","William E. Piper,Anthony S. Joyce, Mary McCallum, HassanF. Azim, and John S. Ogrodniczuk. (2001).Washington, DC: American PsychologicalAssociation. 352 pages, $39.95, ISBN: 1-55798-831-5.This text presents the theoretical back-ground and empirical findings from animportant study of the process and out-come of supportive and interpretivepsychotherapies. In particular, the studydocuments the clinical usefulness ofmatching interpretive and supportivetreatments to particular patient charac-teristics. Although some of the results ofthe project are already available in pub-lished articles (Ogrodniczuk & Piper,1999; Ogrodniczuk, Piper, Joyce, M Piper & Duncan, 1999;Piper, Joyce, McCallum, & Azim, 1998;Piper, McCallum, Joyce, Azim, & Ogrod-niczuk, 1999; Piper, Ogrodniczuk, et al.,1999), the book provides greater detailsabout the background, methods, andresults of the study. Moreover, copiesof the treatment manuals and adherencescales are also included as appendices.Overall, the book is exceptionally wellwritten, understandable to researcherand clinician alike, and informative.The book begins with a historicalreview of short-term interpretively ori-ented (psychodynamic) psychotherapies,followed by a review of dynamicallyoriented supportive psychotherapies. InChapter 3, the authors present their viewof the essential and defining features ofinterpretive and supportive therapies.The defining features of interpretivetherapy include, among others, the cre-ation of a state of tolerable deprivation andanxiety in the session, provision of inter-pretations, a focus on the patientâ€“thera-pist relationship, a focus on unconsciousprocesses, exploration and interpretationof mature and immature defenses, and afocus on internalization of responsibilityfor difficulties. In contrast, the comparabledefining features of supportive therapy in-clude the creation of a state of gratifica-tion in the session, provision of reflections,questions, and clarifications rather thaninterpretations, a focus on relationshipsexternal to therapy, a focus on consciousprocesses, facilitation of mature defensesand discouraging of immature defenses,and a focus on externalization of respon-sibility for difficulties. Although the pri-mary objective of interpretive therapy isto enhance the patientâ€™s insight about re-petitive conflicts and trauma that under-lie presenting problems, the objective ofsupportive therapy is to improve thepatientâ€™s adaptation to his or her life situ-ation. Piper et al. make clear that mostsessions, and indeed many therapy ap-proaches, involve substantial mixtures ofinterpretive and supportive features. Forthe purposes of their research study,however, the authors created treatmentmanuals that represent primarily inter-pretive and primarily supportive thera-pies, respectively.Chapter 4 reviews the available lit-erature on matching patient characteris-tics to type of treatment to maximizebenefits. Chapter 5 then presents thebackground of the two patient variablesthat were chosen for the current study:psychological mindedness and quality ofobject relations. They define quality ofobject relations as a continuum rangingfrom primitive to mature that describesthe typical types of relationships formedDownloaded by [University of Pennsylvania] at 12:01 08 February 2013",2003,
Effective Liveness Verification Using a Transformation-Based Framework,"Liveness properties such as ""will every request eventually get a grant?"" are crucial to the verification of a variety of design types. Liveness properties may only be falsified by infinite-length counterexamples, represented using lasso-shaped traces with a prefix (e.g., showing a particular request) followed by a repeating suffix loop (e.g., showing no grant). A variety of techniques have been developed to solve liveness properties, including BDD-based model checkers, various bounded liveness checking methods, and liveness-to-safety conversion. Nonetheless, the verification of such properties is computationally very challenging, no single algorithm works best, and many industrialsized liveness problems remain practically unsolvable. In this paper, we detail three approaches to solve liveness properties in our verification toolset SixthSense. The first is in the context of dynamic verification, enhancing a simulation engine to support native liveness checking. The second approach is formal, using abstraction-guided liveness-to-safety conversion for greater scalability. The third approach leverages complementary transformation algorithms to enhance the scalability of liveness checking algorithms. We additionally address automated verification of liveness properties on designs with memories, which has not received significant prior research. Experiments are provided to confirm the effectiveness of our techniques.",2014,2014 27th International Conference on VLSI Design and 2014 13th International Conference on Embedded Systems
Comparison of anti-predatory defenses of Red Sea and Caribbean sponges. II. Physical defense,"In addition to the commonly used chemical defense mechanism against predation, ses- sile organisms such as terrestrial plants, soft corals and seaweeds are known to have a physical defense mechanism comprising structural elements made of lignin, CaCO3, silica, etc. Most sponges have siliceous spicules that play a key role as skeletal elements. To date, there has been no evidence to show that these spicules also play a role in defense against predation. It is known that low nutri- tional value of a prey may make it less susceptible to predation. The siliceous spicules found in sponges are indigestible to predators and so sponges that produce large amounts of these spicules may be less susceptible to predation due to their low nutritional value. In the present study, we tested the physical defenses of 6 Red Sea sponge species and 6 Caribbean sponge species against the gen- eralist Red Sea wrasse Thalassoma klunzingeri. Physical defense of the 6 species collected in the Red Sea was also tested using the Caribbean wrasse T. bifasciatum. The spicules of 4 out of the 6 Red Sea sponges deterred predation by T. klunzingeri. Two out of the 6 Caribbean sponges were found to deter predation by T. klunzingeri. In assays conducted in the Bahamas on the Caribbean wrasse T. bifasciatum, only 1 Red Sea sponge species, Suberites clavatus, was found to be physically defended by its spicules. A positive correlation was found between the size of the spicules and their ability to deter predation by T. klunzingeri. Only spicules larger than ~250 Âµm deterred predation. On the other hand, T. bifasciatum seemed to be deterred based on reduced nutritional quality resulting from high concentration of spicules in a sponge, irrespective of their size. The combination of Crella cyatophora spicules and crude chemical extract deterred predation to a greater extent than that observed for each defense mechanism separately. This finding most probably indicates an additive mechanism of defense used by this sponge species.",2003,Marine Ecology Progress Series
Workhardening adaptation of rigid-plastic structures,"SommarioSi considera una struttura discreta rigido-plastica, la quale Ã¨ sottoposta all'azione di carichi variabili quasi-staticamente entro limiti assegnati, e si studiano le condizioni di adattamento per incrudimento, ossia le condizioni affinchÃ© la struttura, dopo una fase iniziale rigido-plastica, manifesti un comportamento perfettamente rigido. Si definisce il coefficiente di sicurezza nei riguardi dell'adattamento (per incrudimento) attraverso due problemi di ottimizzazione duali. Si rilevano talune proprietÃ  caratterisliche della superficie di snervamento all'atto del collasso, anche facendo uso di una appropriata descrizione geometrica. Si dimostrano quindi alcuni teoremi statici e cinematici, analoghi a quelli della teoria dello shakedown. Una semplice applicazione conclude il lavoro.SummaryThe paper considers discrete rigid-plastic structures which are subjected to the action of loads varying quasi-statically within given limits. It studies the conditions for workhoardening adaptation, that is the conditions to ensure that the structure, after an initial rigid-plastic phase, shows a purely rigid behavior. The safety factor against the workhardening inadaptation is defined by two dual optimization problems. Some characteristic features of the yielding surface at failure are pointed out, using also a proper geometric description. Static and kinematic theorems, which are similar to those of shakedown theory, are given. A simple application concludes the paper.",1975,Meccanica
Genome mining for ribosomally synthesized natural products.,"In recent years, the number of known peptide natural products that are synthesized via the ribosomal pathway has rapidly grown. Taking advantage of sequence homology among genes encoding precursor peptides or biosynthetic proteins, in silico mining of genomes combined with molecular biology approaches has guided the discovery of a large number of new ribosomal natural products, including lantipeptides, cyanobactins, linear thiazole/oxazole-containing peptides, microviridins, lasso peptides, amatoxins, cyclotides, and conopeptides. In this review, we describe the strategies used for the identification of these ribosomally synthesized and posttranslationally modified peptides (RiPPs) and the structures of newly identified compounds. The increasing number of chemical entities and their remarkable structural and functional diversity may lead to novel pharmaceutical applications.",2011,Current opinion in chemical biology
The Golden Constant: The English and American Experience 1560-2007,"Contents: About the New Edition by Jill Leyland Preface Previously Written by Roy Jastram Foreword to the New Edition by Pierre Lassonde Introduction Part I: The English Experience 1. The Price of Gold 2. Historical Fluctuations in the Price of Gold 3. Commodity Prices and the Construction of Index Numbers 4. The Purchasing Power of Gold 5. The Purchasing Power of Gold in Inflation and Deflation Part II: The American Experience 6. The Evolution of the Gold Standard and Historical Fluctuations in Gold Prices 7. The Purchasing Power of Gold 8. Reflections on the Golden Constant Part III: After the Gold Price was Freed, 1971 to 2007 9. The Gold Market and the Purchasing Power of Gold 1971 to 2007 10. Further Explorations into the Gold Price and its Purchasing Power Appendices Index",2009,
KÃ¼hlanordnung fÃ¼r eine Spannungsversorgung eines Generatormotors zum Betreiben eines Fahrzeugs,"Kuhlanordnung
fur eine
Spannungsversorgung eines Generatormotors zum Betreiben eines Fahrzeugs, wobei
die Spannungsversorgung ein Gehause
(70) aufweist, in dem ein Batteriegehause (20), das Batterien (5) enthalt, ein
Wechselrichter (7) und ein DC/DC-Wandler (8) angeordnet sind, wobei
das Gehause
(70) mit einem Einlasskanal (10), der eine Lufteinlassoffnung (11)
aufweist, und einem Auslasskanal (40), der eine Luftausslassoffnung (41)
aufweist, stromungstechnisch
verbunden ist, und wobei mittels eines Ventilators (60) eine Luftstromung durch
die Kanale
(10, 40) und das Gehause
(70) erzeugt wird, wobei im Einlasskanal (10) ein Ventil (13)
angeordnet ist, das durch die Luftstromung betatigt wird, so dass wahrend des
Betriebs des Ventilators (60) Luft in dem Einlasskanal (10) stromt, wobei
das Ventil (13) aus einem elastischen Material besteht oder um eine
Drehachse drehbar angeordnet ist, und wobei die Luft dem Gehause (70)
von oben zugefuhrt
wird, das Batteriegehause
(20) von oben nach unten durchstromt, um die Batterien...",2002,
A Penalized Regression Approach for Integrative Analysis in Gen ome-Wide Association Studies,"Over one thousand genome-wide association studies (GWAS) have been conducted in the past decade. Increasing biological evidence suggests the polygenic genetic architecture of complex traits: a complex trait is affected by many risk variants with small or moderate effects jointly. Meanwhile, recent progress in GWAS suggests that complex human traits may share common genetic bases, which is known as â€œpleiotropyâ€. To further improve statistical power of detecting risk genetic variants in GWAS, we propose a penalized regression method to analyze the GWAS dataset of primary interest by incorporating information from other related GWAS. The proposed method does not require the individual-level of genotype and phenotype data from other related GWAS, making it useful when only summary statistics are available. The key idea of the proposed approach is that related traits may share common genetic basis. Specifically, we propose a linear model for integrative analysis of multiple GWAS, in which risk genetic variants can be detected via identification of nonzero coefficients. Due to the pleiotropy effect, there exist genetic variants affecting multiple traits, which correspond to a consistent nonzero pattern of coefficients across multiple GWAS. To achieve this, we use a group Lasso penalty to identify this nonzero pattern in our model, and then develop an efficient algorithm based on the proximal gradient method. Simulation studies showed that the proposed approach had satisfactory performance. We applied the proposed method to analyze a body mass index (BMI) GWAS dataset from a European American (EA) population and achieved improvement over single GWAS analysis.",2015,Journal of biometrics & biostatistics
Le gisement ZaccarI prÃ¨s de Bou-SaÃ¢da (AlgÃ©rie),Res. d'A. Le gisement ZaccarI est localise au sommet d'un remblaiement sableux le long de l'oued Bou-Saada el-Hamel en amont de l'agglomeration. L'industrie lithique presente deux caracteristiques: abondance de grosses pieces (surtout de grattoirs)| fort pourcentage de microburins et de pieces de tres petites dimensions (moins de 1cm). Les deux caracteristiques nous ont permis de definir cet ensemble comme une industrie keremienne elassolithique.,1977,
"Exploring the associations of serum concentrations of PCBs, PCDDs, and PCDFs with walking speed in the U.S. general population: Beyond standard linear models.","Studies have shown that persistent organic pollutants (POPs) can have various health effects. However, little is known about the effects of multiple chemicals with possible common sources of exposure on walking speed, a proxy index reflecting lower limb neuromuscular function and physical function. We simultaneously applied multiple linear and nonlinear statistical models to explore the complex exposure-response relationship between a mixture of 22 selected POPs and walking speed. A total of 14 polychlorinated biphenyls (PCBs), 3 polychlorinated dibenzo-p-dioxins (PCDDs), and 5 polychlorinated dibenzofurans (PCDFs) were measured in the serum of participants in the National Health and Nutrition Examination Survey (NHANES) from 1999 to 2002. Walking speed was measured during a physical examination. Linear regression (LR), least absolute shrinkage and selection operator (LASSO), and group LASSO were used to evaluate the linearity of mixtures, while restricted cubic spline (RCS) regression, random forest (RF), and Bayesian kernel machine regression (BKMR) models were used to evaluate the nonlinearity of mixtures. Potential confounders were adjusted in the above models. A total of 436 subjects were included in our final analysis. The results of the LR model did not identify any POP exposure that was significantly associated with walking speed. The LASSO results revealed an inverse association of one PCDD congener and two PCDF congeners with walking speed, while the group LASSO analysis identified PCDFs at the exposure level and at the group level. In the RCS analysis, two PCB congeners presented significant overall associations with walking speed. The PCB congener PCB194 showed statistically significant effects on the outcome (Pâ€¯=â€¯0.01) when a permutation-based RF was used. The BKMR analysis suggested that PCBs and PCDFs (probabilitiesâ€¯=â€¯0.887 and 0.909, respectively) are potentially associated with walking speed. Complex statistical models, such as RCS regression, RF and BKMR models, can detect the nonlinear and nonadditive relationships between PCBs and walking speed, while LASSO and group LASSO can identify only the linear relationships between PCDFs and walking speed. Fully considering the influence of collinearity in each method during modelling can increase the comprehensiveness and reliability of conclusions in studies of multiple chemicals.",2019,Environmental research
[Governance of HIV/AIDS organizations in Bobo-Dioulasso (Burkina Faso)].,"INTRODUCTION
Although HIV/AIDS organizations continue to play a major role in the fight against pandemic HIV infections, they are still faced with enormous governance challenges that impair their operations / interventions and their sustainability. The objective of this study was to develop an inventory of the quality of governance within HIV/AIDS organizations in Bobo-Dioulasso.


METHODS
This qualitative research was conducted in 40 organizations from Bobo-Dioulasso. Qualitative data were collected over a 45-day period using an interview guide. Thematic analysis of the data was performed and the results were reported.


RESULTS
Although all 40 organizations had established good governance mechanisms, only fifteen complied with the major rules of democratic functioning and the roles of the various bodies. The majority of these organizations (29/40) ignored many democratic rules. The number of members required for the Executive Board was not met in 29/40 organizations resulting in monopolization of decision-making by a handful of people. Technical and financial reports were not published, resulting in limited access to information on the organization's activities. Gender equality also constituted a weakness.


DISCUSSION
Application of good governance principles was limited in these organizations. Organization members, leaders and technical and financial partners must reinforce good governance efforts in order to improve good governance in these organizations.",2014,Sante publique
Trattamento di angiomi vertebrali sintomatici con vertebroplastica,"Gli angiomi vertebrali sintomatici, compressivi o aggressivi, sono rari. Il gold standard del loro trattamento Ã¨ costituito dalla decompressione chirurgica con rimozione del tessuto angiomatoso, ma Ã¨ gravato dal rischio di cospicua emorragia intraoperatoria, o da ematoma epidurale e collasso vertebrale postoperatori. Generalmente lâ€™intervento Ã¨ preceduto da angiografia con embolizzazione. La radioterapia ha unâ€™efficacia incostante e comporta il rischio di una mielopatia postattinica. Negli ultimi anni la vertebroplastica si Ã¨ dimostrata una modalitÃ  di trattamento estremamente efficace in questa patologia che puÃ² essere effettuata sia in combinazione con lâ€™intervento chirurgico che come terapia definitiva a se stante. Descriviamo la nostra esperienza nellâ€™applicazione di questa metodica in 7 angiomi sintomatici, di cui 5 dorsali e 2 lombari.",2003,The Neuroradiology Journal
FUTUR -E: Quale futuro per la centrale Marzocco a Livorno?,"Lo scenario energetico italiano ha conosciuto, in questi ultimi anni, un cambiamento repentino sulle linee delle norme nazionali e sovranazionali in merito a questioni climatiche e ambientali. Il rapido sviluppo di nuove tecnologie ha assestato un duro colpo al vecchio sistema elettrico centralizzato che ha lasciato ormai lo schema â€œone-to-manyâ€ per passare ad uno piÃ¹ integrato. Cosa fare quindi con le vecchie infrastrutture elettriche? Possono essere considerate parte del patrimonio industriale e culturale italiano? A che stregua? Questo paper analizza innanzitutto il progetto promosso da Enel S.p.A. dal nome Futur-E, alludendo al futuro dellâ€™energia. Il caso preso in considerazione Ã¨ quello della Centrale Marzocco, sita a Livorno e scelta per la sua rilevanza architettonica, situazione urbana ambigua e interesse ambientale. Lâ€™impianto Ã¨ infatti collocato vicino al centro cittadino allâ€™interno dellâ€™area industrial portuale, che costituisce un terzo dellâ€™agglomerato urbano. Il paper ha come obiettivo lâ€™analisi del sito e della cittÃ  di Livorno, e lo studio di uno scenario di sviluppo per lâ€™area che non neghi il suo passato produttivo ma che ne rafforzi lâ€™identitÃ  industriale, mettendo in luce la qualitÃ  architettonica e paesaggistica di unâ€™area al momento conclusa. Lo scenario prevede lâ€™inserimento di funzioni che abbiano come tema centrale il ciclo e il ri-ciclo dellâ€™acqua, promuovendo da una parte la valorizzazione dellâ€™asset industriale e dallâ€™altra la cultura dellâ€™acqua in una cittÃ  nata e scolpita da questa risorsa naturale. Parole chiave: energy; urban design; waterfronts and harbors. Brief history of electricity in Italy The introduction of electricity represented one of the major technological revolution in recent history, touching every sphere of human behaviour: from the production one, to the social life and home comfort. It had the force to modify dominant cultural models, reshape territories and social conditions while promoting technological development. In Italy, the introduction of electricity is related to the beginning of industrialization processes in a country mainly devoted to agriculture: the new technology fuelled the myth of positive development leading to hope to finally fill the gap with other European countries. The history of the Italian electrical development can be divided in three main periods: the first, that includes the beginning of the electrical era, the second between 1930s and 1950s characterized by its expansion, and the last, from 1962 up to today, that regards the electric redefinition (Castronovo, 1994). The first phase started in 1880 when the first applications of electronic devices were made mostly in northern Italy, and in 1883 the first thermoelectric plant in Italy was realized in Via Santa Radegonda in Milan (Mori, 1992). The progressive electrification of the city, led to the need of finding a more powerful alternative with respect to small thermoelectric plants: Italy chose to exploit the wide water reserves in the Alps and to start the hydroelectrical production, made possible by the technological development in terms of transmission of energy. During that period, the electrical production was managed at a municipal level in an independent way. At the end of 1890s big cities like Milano, Torino, Roma, Genova, Palermo, Napoli, Firenze and smaller ones as Livorno, Messina, Avellino, Udine and Cuneo had their own electrical plant (Labbate, 2013). 1900 opened as a century of economic expansion, with the increase of energy requirements: once again the exploitation of water led to the construction of several new plants in rural and mountain areas with the need to coordinate and manage in integrated way the transportation facilities from remote areas. In this period, Italy was the worldâ€™s sixth country for installed power: the electrified municipalities passed from 401 to 4600 and before the I World War the national industry covered 60% of national requirements. During the War, the difficulties in procuring petroleum led to an even greater development of electricity, acting as a booster for the industry. The hydroelectrical power was chosen to be employed even after WWI and Italy reached the 82% of installed power with the construction of some of the biggest plants. This trend has been fostered also under the fascist regime, with its autarkic plans to get to an energetic independence. In this period, the major electric groups emerged also with the help of governmental grants and foreign capitals: SIP, Sade, La Centrale, Edison, SME, Bastogi (Galasso, 1993). The 1929 economic crisis led to the exploitation of hydrological resources but the total absence of an energetic plan had a big impact on the delay in the infrastructure construction and the permanence of big imbalances. The WWII had merciless implications for the electric production; the most damaged areas were in central Italy, mostly located next to industrial and port areas (Castronovo, 1994). The international grants devoted to reconstruction had been seminal to regain competitiveness, and already in 1948, the installed power was superior with respect to the pre-war condition, along with the development of telephone and radio lines. The electric consumption increased in the following decades, in relation to the economic boom, availability of resources, availability of devices, and new pattern of consumption. Considering the production pattern, this period is a time of diversification: up until 1940 the major role was played by hydroelectric plants, while in the following decades a series of measures were put in place to foster the production through thermoelectric ones. The international energy market had been changing a lot during WWII and the routes of petroleum commerce had radically changed: the discovery of the Middle East deposits allowed Italy to experience a wide reduction of oil prices, leading to a favourable condition for the development of imported fossil fuels exploitation. In this scenario, the biggest part of the current thermoelectric park has been built to cover the ever-increasing demand. Meanwhile the hydrological resources registered a dramatic decrease that led to the final choice of thermoelectric as a base for the electric production. The realization of these new plants had a strong impact on the territory, contributing to the change of city skylines and port areas together with country sides and mountainous areas crossed by the electrical networks. The natural landscape became more and more artificial with an irreparable modification of natural territorial assets. In this period, a new form of energy begun to be highly discussed and researched: the nuclear one. From 1960s the first investments in the field had been made in technologies and machinery that worked only by the following decade in three sites. 1960s marked the process of nationalization, or rather the gradual absorption of all companies producing transforming and distributing electrical energy by one public state company, namely Enel. After almost one year long discussion, Enel was born the 12 December 1962. It gradually began the process of absorption while trying to complete the process of electrification and consequently new big plants and transport infrastructures such as the spine between Firenze and Roma and the interconnection with France and Switzerland (Zanetti, 1994). The complete electrification of the country was finally reached in 1971: 97% of the total territory was covered. The 1970s have been mainly the years of oil crisis that hardly hit not only the production sphere but every aspect of the human life. The huge Italian dependency on fossil fuels has been a particularly harsh condition that led Italian government to move investments on nuclear sector and international cooperation projects, such as policies for the containment of energy consumption. The next decade opened with a strong concern over environmental issues and energy saving measures: for the first time in Italy, the third Piano Energetico Nazionale (PEN) in 1981(Labbate, 2013) mentioned the use of renewable resources and promoted the containment of consumptions. The governmental plan acted as a booster for research on these matters, while implementing the nuclear application in short-time period, by creating the appropriate legislation. Nonetheless, on 26th April 1986 the disaster of Chernobyl changed completely the minds of the Italian population over the use of nuclear energy, renouncing to the nuclear program within the PEN and closing the three existing plants on the territory. The needed energy was then imported by nearby countries such as France and Switzerland. In 1992, last year of existence of Enel as a public body, the electric production in Italy is assessed at 226 billion kWh, divided in 49 billion renewable resources and 177 billion traditional thermoelectric mostly on fuel oil (Labbate, 2013). Between 1998 and 1999, following an EU regulation of 1966, Enel organized the spin-off of its previously integrated businesses (production, transmission, distribution) and restructured its organization to become a private holding. The liberalization process has been ruled by Decreto Bersani and Enel sold 15100 MW of installed power in a decade process that ended in 2003 when the production set of Enel has been set on 49,2% of national total diminishing up to 27,8% in 2010 (Paoloni, 2014). Whatâ€™s next The energetic scenario is now undergoing another moment of radical change worldwide. Two factors have lately influenced the global demand of energy: the world crisis of 2008/2009 and the emergence in the global scenario of new economical actors which are affecting the global market and its balance. The energy demand is expected to rapidly grow worldwide reaching +35% by 2035 but while the situation in Europe, and in general in the industrialized countries is characterized by a status quo situation, the developing ones will push the demand up to",2017,
Reed Muller Sensing Matrices and the LASSO,"We construct two families of deterministic sensing matrices where the columns are obtained by exponentiating codewords in the quaternary Delsarte-Goethals code $DG(m,r)$. This method of construction results in sensing matrices with low coherence and spectral norm. The first family, which we call Delsarte-Goethals frames, are $2^m$ - dimensional tight frames with redundancy $2^{rm}$. The second family, which we call Delsarte-Goethals sieves, are obtained by subsampling the column vectors in a Delsarte-Goethals frame. Different rows of a Delsarte-Goethals sieve may not be orthogonal, and we present an effective algorithm for identifying all pairs of non-orthogonal rows. The pairs turn out to be duplicate measurements and eliminating them leads to a tight frame. Experimental results suggest that all $DG(m,r)$ sieves with $m\leq 15$ and $r\geq2$ are tight-frames; there are no duplicate rows. For both families of sensing matrices, we measure accuracy of reconstruction (statistical 0-1 loss) and complexity (average reconstruction time) as a function of the sparsity level $k$. Our results show that DG frames and sieves outperform random Gaussian matrices in terms of noiseless and noisy signal recovery using the LASSO.",2010,ArXiv
"Heinen's Hosting Cookbook Signings, Chef Demos | Verlasso","For those in the Cleveland area, check out the details below for where to sample Verlasso, pick up a cookbook and meet the authors.",2015,
Best Predictive Generalized Linear Mixed Model with Predictive Lasso for High-Speed Network Data Analysis,"Optimizing network usage is important to maximize the network performance. When the network usage grows rapidly, it is important to build an accurate predictive model. We present a new predictive algorithm which can analyze the network performance in various network conditions and traffic patterns. Our approach is based on the best predictive generalized linear mixed model (GLMM). The parameters of the best predictive GLMM are estimated by minimizing the mean squared prediction error (MSPE). To expedite the parameter learning with the big data collected through the network, our algorithm introduced Â regularization, LASSO, and an innovative bootstrap. The merits of our new approach validated through data and simulation are that (1) the highest prediction accuracy even under a model misspecification; and (2) the least computation time compared to the Estimation-oriented GLMM with Lasso and Stepwise Selection GLMM. A major computational advantage of our method is that, unlike some of the current approaches, our method does not require the EM (Expectation-Maximization algorithm) procedure.",2015,International Journal of Statistics and Probability
Oracle Inequalities for High-dimensional Prediction,"The abundance of high-dimensional data in the modern sciences has generated tremendous interest in penalized estimators such as the lasso, scaled lasso, square-root lasso, elastic net, and many others. In this paper, we establish a general oracle inequality for prediction in high-dimensional linear regression with such methods. Since the proof relies only on convexity and continuity arguments, the result holds irrespective of the design matrix and applies to a wide range of penalized estimators. Overall, the bound demonstrates that generic estimators can provide consistent prediction with any design matrix. From a practical point of view, the bound can help to identify the potential of specific estimators, and they can help to get a sense of the prediction accuracy in a given application.",2016,arXiv: Statistics Theory
HisCoM-mimi: software for hierarchical structural component analysis for miRNA-mRNA integration model for binary phenotypes,"To identify miRNA-mRNA interaction pairs associated with binary phenotypes, we propose a hierarchical structural component model for miRNA-mRNA integration (HisCoM-mimi). Information on known mRNA targets provided by TargetScan is used to perform HisCoM-mimi. However, multiple databases can be used to find miRNA-mRNA signatures with known biological information through different algorithms. To take these additional databases into account, we present our advanced application software for HisCoM-mimi for binary phenotypes. The proposed HisCoM-mimi supports both TargetScan and miRTarBase, which provides manually-verified information initially gathered by text-mining the literature. By integrating information from miRTarBase into HisCoM-mimi, a broad range of target information derived from the research literature can be analyzed. Another improvement of the new HisCoM-mimi approach is the inclusion of updated algorithms to provide the lasso and elastic-net penalties for users who want to fit a model with a smaller number of selected miRNAs and mRNAs. We expect that our HisCoM-mimi software will make advanced methods accessible to researchers who want to identify miRNA-mRNA interaction pairs related with binary phenotypes.",2019,Genomics & Informatics
"Functional space, preferably with thermo-acoustic, insulating enclosure and with this cooperative air flap assembly","The present invention relates to a functional space (18), in particular for a motor vehicle (10), which is bounded by an enclosure, wherein more than half, preferably more than 75%, more preferably more than 85% of the enclosing surface thermo-acoustic insulating panel material (20, 21) and / or of thermo-acoustic insulating covering material (20, 21) is formed, in which co-operates the enclosure at a Einlassort (24) having an inlet-air valve system (26) having an inlet air passage opening (30) and at least one intake-air flap (28), preferably a plurality of intake-air damper (28), said at least one inlet-air damper is adjustable between a flow position, in which a through-flow of air cross-section of the intake-air passage opening (30) is larger, so that air through the intake air passage opening (30) into the working space (18) can be introduced, and a Locking position in which the through-flow of air cross-section of the intake-air passage opening (30) is smaller, preferably zero, so that per unit of time in the working space (18) through the intake-air passage opening (30) therethrough einleitbare air amount is smaller than in the passage position, preferably is zero.",2014,
Radial Level Planarity: A Propositional Logic Approach,"Drawing graphs is a discipline in graph theory,dealing with the optimal representation of graphs. Animportant class of graphs are the planar graphs,which can be drawn without any intersecting edges.Such graphs are superior in terms of humanreadability. Radial level graphs are a specific classof graphs that only have edges between vertices ofdifferent levels, which are arranged in concentriccircles. The knowledge about the planarity of a graphenables the use of more efficient algorithms todisplay good representations. In this book, severalapproaches are discussed to describe the problem ofradial level planarity in a propositional logicframework. A model is introduced that describes theproblem as a SAT problem and for some types of graphseven as a 2-SAT problem, which is solvable in lineartime. The truth assignment of the variables describesthe non-intersecting embedding. Additionally, themodel is capable of introducing vertices-grouping,enabling the modelling of semantic rules. This bookis aiming for scientists that do research in thefields of graph drawing and/or propositional networksand theoretical informatics as well as for interestedstudents.",2008,
Etat de la rÃ©gÃ©nÃ©ration naturelle et domestication des espÃ¨ces ligneuses utilisÃ©es dans l'artisanat d'art dans l'ouest et le sud-ouest du Burkina faso,"Les travaux realises s'inscrivent dans le cadre d'un projet de recherche sur les especes ligneuses utilisees dans l'artisanat. Ce projet a pour but de trouver un moyen de pallier la rarefaction des especes ligneuses importantes pour l'artisanat du Burkina Faso en utilisant des techniques de multiplication vegetative a faible cout. Les travaux ont ete realises dans la foret de Dinderesso a l'ouest du Burkina Faso et dans le parc forestier de l'Universite de Bobo-Dioulasso. Les differentes techniques de multiplication par voie vegetative ont ete le marcottage aerien avec usage de sphaigne comme substrat, le bouturage classique de branche et l'induction de drageons. 3 principales especes utilisees dans l'artisanat ont ete retenues pour l'etude: Isoberlinia doka, Burkea africana et Pterocarpus erinaceus. L'induction de drageons chez Burkea a ete un succes dans la moitie des essais. Elle est nulle pour Isoberlinia. Le succes du marcottage chez Burkea et Pterocarpus est moindre: 6% des essais ont abouti a la production de racines. Le bouturage dans nos conditions d'essais s'est revele moins favorable (31,4%). (Resume d'auteur)",2008,
Performance of CT-based radiomics in diagnosis of superior mesenteric vein resection margin in patients with pancreatic head cancer,"To accurately identify the relationship between a portal radiomics score (rad-score) and pathologic superior mesenteric vein (SMV) resection margin and to evaluate the diagnostic performance in patients with pancreatic head cancer. A total of 181 patients with postoperatively and pathologically confirmed pancreatic head cancer who underwent multislice computed tomography within one month of resection between January 2016 and December 2018 were retrospectively investigated. For each patient, 1029 radiomics features of the portal phase were extracted, which were reduced using the least absolute shrinkage and selection operator (LASSO) logistic regression algorithm. Multivariate logistic regression models were used to analyze the association between the portal rad-score and SMV resection margin. Patients with negative (R0) and positive (R1) margins accounted for 70.17% (127) and 29.83% (54) of the cohort, respectively. The rad-score was significantly associated with the SMV resection margin status (pâ€‰<â€‰0.05). Multivariate analyses confirmed a significant and independent association between the portal rad-score and SMV resection margin (OR 4.62; 95% CI 2.19â€“9.76; pâ€‰<â€‰0.0001). The portal rad-score had high accuracy (area under the curveâ€‰=â€‰0.750). The best cut point based on maximizing the sum of sensitivity and specificity was âˆ’ 0.741 (sensitivityâ€‰=â€‰64.8%; specificityâ€‰=â€‰74.0%; accuracyâ€‰=â€‰71.3%). Decision curve analysis indicated the clinical usefulness of radiomics score. The portal rad-score is significantly associated with the pathologic SMV resection margin, and it can accurately and noninvasively predict the SMV resection margin in patients with pancreatic cancer.",2020,Abdominal Radiology
[Training at the African Institute of Tropical Ophthalmology in Bamako].,"The African Institute of Tropical Ophthalmology (AITO) is an OCCCMED institute, founded in Bamako in 1953. The OCCCMED itself is based at Bobo Dioulasso (Burkina Faso). AITO is a WHO collaborating center for the prevention of blindness. Training is one of the main activities of the institute, along with eye care, research and assessment. The prevalence of blindness in sub-Saharan countries is about 1.2%, with blindness mostly caused by cataracts, trachoma, glaucoma and onchocercosis. The demand for eye care is high but there are currently too few trained personnel to satisfy that demand. Therefore, AITO's role in training eye-care professionals is particularly important. The institute trains ophthalmologists, specialist nurses, eye surgeons (who remove cataracts) and spectacle manufacturers. Training is carried out within the framework of the community and apprenticeship in the workplace. The student must attain specific targets, listed in a ""competency passport"" issued at the start of training. Clinical and surgical ophthalmology and general eye care are taught. Training costs and grants are mostly paid by the Lions Club International Sight First Program or by the French Overseas Development Ministry. Since 1991, AITO has trained to graduation: 18 ophthalmologists; 24 eye surgeons; 83 specialist nurses; 16 spectacle manufacturers.",1998,Sante
Single-Locus and Multi-Locus Genome-Wide Association Studies for Intramuscular Fat in Duroc Pigs,"Intramuscular fat (IMF) is an important quantitative trait of meat, which affects the associated sensory properties and nutritional value of pork. To gain a better understanding of the genetic determinants of IMF, we used a composite strategy, including single-locus and multi-locus association analyses to perform genome-wide association studies (GWAS) for IMF in 1,490 Duroc boars. We estimated the genomic heritability of IMF to be 0.23 Â± 0.04. A total of 30 single nucleotide polymorphisms (SNPs) were found to be significantly associated with IMF. The single-locus mixed linear model (MLM) and multiple-locus methods multi-locus random-SNP-effect mixed linear model (mrMLM), fast multi-locus random-SNP-effect efficient mixed model association (FASTmrEMMA), and integrative sure independence screening expectation maximization Bayesian least absolute shrinkage and selection operator model (ISIS EM-BLASSO) analyses identified 5, 9, 8, and 21 significant SNPs, respectively. Interestingly, a novel quantitative trait locus (QTL) on SSC 7 was found to affect IMF. In addition, 10 candidate genes (BDKRB2, GTF2IRD1, UTRN, TMEM138, DPYD, CASQ2, ZNF518B, S1PR1, GPC6, and GLI1) were found to be associated with IMF based on their potential functional roles in IMF. GO analysis showed that most of the genes were involved in muscle and organ development. A significantly enriched KEGG pathway, the sphingolipid signaling pathway, was reported to be associated with fat deposition and obesity. Identification of novel variants and functional genes will advance our understanding of the genetic mechanisms of IMF and provide specific opportunities for marker-assisted or genomic selection in pigs. In general, such a composite single-locus and multi-locus strategy for GWAS may be useful for understanding the genetic architecture of economic traits in livestock.",2019,Frontiers in Genetics
Adaptive Shifts of Life-history Allocations,"Optimal-life-history theory is based on the relative benefit of immediate versus future reproduction. We apply this theory to the life-history tactics of female Thalassoma bifasciatum, a sex-changing coral-reef fish. Local social structure varies in this species and influences a female's chances of achieving high future reproductive success as a territorial terminal-phase male. We predicted that female life-history allocations would be flexible and responsive to variation in future reproductive prospects. We altered population size structure on four reefs, removing large fish and adding small fish. These alterations enhanced the residual reproductive value of the remaining larger female residents. The predicted response to the manipulation was a reduction in reproductive activity and an increase in growth. Our results do not support this hypothesis. Possible interpre- tations are that: 1) the theory, or our application of the theory, is flawed; 2) female Thalassoma are unresponsive to changes in future reproductive prospects; or 3) the design of our study was ineffectual at detecting a response. We report here an approach to the study of adaptive life-history strategies that deserves implementation in other systems.",1989,
On the Trade-Off between Multi-level Security Classification Accuracy and Training Time,"Automatic security classification is a new research area about to emerge. It utilizes machine learning to assist humans in their manual classification. In this paper, we investigate the importance of the training time of the machine learner. To the best of our knowledge, this has not been analyzed in previous works. We compare various machine learning methods, including SVM, LASSO and the ensemble methods Adaboosting and Adabagging, with respect to their performance. The paper demonstrates that the computational cost of a method is an important part of its performance metric.",2015,"2015 3rd International Conference on Artificial Intelligence, Modelling and Simulation (AIMS)"
Biosurfactant evaluation heterocyclic hydrocarbon degrading marine bacteria,"Biosurfactants have several advantages as compared with chemically synthetic surfactants 
such as biodegradability, lower toxicity, environmental-friendly and have selective and 
specific activity under extreme temperature, pH and salinity. Eventually, biosurfactants 
became the 1 st choice in the food, pharmaceutical and cosmetic industrial. Apart from that, 
biosurfactants are also being used to enhance biodegradation activity in the polluted area. 
The main goal of this project is to identify strains of bacteria that are capable to degrade 
heterocyclic hydrocarbon while producing biosurfactant. Apart from that, the effect of 
additional surfactant on the biodegradation of carbazole by Thalassospira Profundimaris, 
strain M02 was also studied. The biodegradation rate of carbazole was measured by using 
spectrometer. Isolated marine bacterias and soil bacterias were cultured using heterocyclic 
hydrocarbon as sole carbon source. Marine bacteria which were capable to degrade 
heterocyclic hydrocarbon were further tested for biosurfactant production ability. In the 
biosurfactant evaluation, a simple and rapid, drop-collapse test was utilized. From the 
result, no biosurfactant was confmned from cell suspension. The addition of Tween 20 at 
different concentration, 0.03% and 0.06% showed enhanced biodegradation rate of 
carbazole by strain M02 by 140% and 233.6% respectively.",2013,
"Binary Classification, Logistic and Nominal Regression: Application to Bank Customer Loyalty Data","Customers are the foundation of any businessâ€™s success, and a business can never be too grateful for loyal customers. Customer insight is therefore an important key to help sustain loyal and active customers. In this thesis we are going to detect significant differences between different customer types, as well as indicating future inactive customers. Doing so, we will get useful insight about the inactive customers, and perhaps understand why they choose to go from being active to being inactive. The analyses are done on a bank customer database, provided by the bank itself. The bank customers are divided into six groups, or categories, based on customer activity and the number products used. The categories are denoted by Aâ€“F, where A contains the most active customers and F contains the least active customers with no products used. We perform nominal regression in order to detect differences between these groups. We experienced that customers that have applied for loan/credit card are more likely to be customers from the categories A and B. Furthermore, we experienced that probability for being in category F is strongly decreased if the customer is a member or a nonmember with member benefits. Also, the probability for being in category A is significantly increased if the customers have activated electronical billing. Let the categories Aâ€“D relate to the active customers, and the categories Eâ€“F relate to the inactive customers. To indicate customers that are going to be inactive in the future, we create an indicator model. We perform statistical modelling and learning methods, such as binary logistic regression, random forests and XGBoost, in order to create this model. We use model selection methods, such as the Akaike Information Criterion (AIC), lasso regularization and variable importance. The performance of a model is evaluated on the AUC value on test data. The model that performed best was the XGBoost model with all the variables included. Thus, this will be used as the indicator for detecting bank customers that are going to be inactive within the next year. We experienced that balance of the customer was clearly the most significant variable, when it comes to being active or inactive in the future. The binary logistic regression coefficient for this variable is negative. Hence, the higher the balance on the deposit account of a customer, the lower is the probability for being inactive in the future. The number of transactions of the customer and if the customer has a loan, are both also very important factors when it comes to being active/inactive in the future.",2019,
A LSE and Sparse Message Passing-Based Channel Estimation for mmWave MIMO Systems,"In this paper, we propose a novel channel estimation algorithm based on the Least Square Estimation (LSE) and Sparse Message Passing algorithm (SMP), which is of special interest for Millimeter Wave (mmWave) systems, since this algorithm can leverage the inherent sparseness of the mmWave channel. Our proposed algorithm will iteratively detect exact the location and the value of non-zero entries of sparse channel vector without its prior knowledge of distribution. The SMP is used to detect exact the location of non- zero entries of the channel vector, while the LSE is used for estimating its value at each iteration. Then, the analysis of the Cramer-Rao Lower Bound (CRLB) of our proposed algorithm is given. Numerical experiments show that our proposed algorithm has much better performance than the existing sparse estimators (e.g. LASSO), especially when mmWave systems have massive antennas at both the transmitters and receivers. In addition, we also find that our proposed algorithm converges to the CRLB of the genie-aided estimation of sparse channels in just a few turbo iterations.",2016,2016 IEEE Globecom Workshops (GC Wkshps)
P450scc-like immunoreactivity throughout gonadal restructuring in the protogynous hermaphrodite Thalassoma duperrey.,"The source of steroid hormones, which potentially regulate gonadal restructuring throughout protogynous sex change in teleosts, remains largely unknown. To address this issue, immunocytochemical methods were employed to detect gonadal sites of steroidogenesis in the protogynous hermaphrodite wrasse Thalassoma duperrey at different stages in the sex change process. Steroidogenic cells were classified based on the presence of P450 cholesterol-side-chain-cleavage-like immunoreactivity (P450scc-ir). P450scc-ir cells were predominantly in the thecal layer of normal females. As females underwent sex change, P450scc-ir localization shifted from the thecal layer to the interstitium. P450scc-ir cells appeared to increase in number midway through sex change. In sex-changed males, P450scc-ir cells were found in small clusters interspersed among spermatogenic lobules. These results demonstrate for the first time the ability of the gonad to produce potential steroidal mediators of gonadal restructuring throughout the sex change process.",1998,The International journal of developmental biology
PROFIL MORFOLOGI CACING Haemonchus sp. DAN Mecistocirrus digitatus DENGAN PEWARNAAN CARMINE DAN SCANNING ELECTRON MICROSCOPE (SEM),"Several morphological similarities, nature of hematophagus and habitat (that is abomasum) similarities between Haemonchus sp. and M. digitatus as worm spacies living in a cow, in the same manner as lacking information of them may cause a misidentification_ 
 
Forty cow abomasums from PO race and thirty six cow abomasums from madura race was dissected and observed to find out worms which were suspected to be Haemonchus sp. and M. digitatus. The amount of the infecting worms was counted to reveal its influencelassociation toward cow race. On the result, there was no revealed influence between the amounts of infecting worms to the cow race. M. digitatus was much more found (8657 worms) than Haemonchus sp. (29 worms). The identification was enabled by carmine coloring and electron microscope scanning. The ultrastructure of M. digitatus 's synlophe appeared to be circularly multiple, the H. similis of its cuticle constructed ""synlophe"" in blunt ridge (it looked like momordica/bitter melon), while its H. contortus constructed synlophe in incisive ridge. 
 
By measuring worm's length, a distance of vulva from top posterior and spicula's length in assistance of SEM result, it was concluded that kind of worms infecting cow's abomasums was dominated by M. digitatus and the species of infecting Haemonchus was H. similis. The worm's length of M. digitatus are 28,2 â€“ 31,2 mm for female, 20,3 â€“ 22,1 mm for male. The distance of vulva from top posterior of M. digitatus are 0,34 â€“ 0, 81 mm , and spicula's length are 3,71 â€“ 5,97 mm. While its H. similis 13,1 mm â€“ 16,3 mm are female worm's, 9,7 â€“ 11,7 mm for male, distance of vulva from top posterior are 2,36 â€“ 2,82 mm, length of spicula's are 0,26 â€“ 0,44 mm and the distance tip of spicula's are 0,058 - 0,072 mm.",2001,
Network-Clustered Multi-Modal Bug Localization,"Developers often spend much effort and resources to debug a program. To help the developers debug, numerous information retrieval (IR)-based and spectrum-based bug localization techniques have been devised. IR-based techniques process textual information in bug reports, while spectrum-based techniques process program spectra (i.e., a record of which program elements are executed for each test case). While both techniques ultimately generate a ranked list of program elements that likely contain a bug, they only consider one source of informationâ€”either bug reports or program spectraâ€”which is not optimal. In light of this deficiency, this paper presents a new approach dubbed Network-clustered Multi-modal Bug Localization (NetML), which utilizes multi-modal information from both bug reports and program spectra to localize bugs. NetML facilitates an effective bug localization by carrying out a joint optimization of bug localization error and clustering of both bug reports and program elements (i.e., methods). The clustering is achieved through the incorporation of network Lasso regularization, which incentivizes the model parameters of similar bug reports and similar program elements to be close together. To estimate the model parameters of both bug reports and methods, NetML employs an adaptive learning procedure based on Newton method that updates the parameters on a per-feature basis. Extensive experiments on 355 real bugs from seven software systems have been conducted to benchmark NetML against various state-of-the-art localization methods. The results show that NetML surpasses the best-performing baseline by 31.82, 22.35, 19.72, and 19.24 percent, in terms of the number of bugs successfully localized when a developer inspects the top 1, 5, and 10 methods and Mean Average Precision (MAP), respectively.",2019,IEEE Transactions on Software Engineering
HW 2 : Regression,"i |y âˆ’ Î¸x| + Î»||Î¸||q In our situation, each y is the rating of a review (one of {1, 2, 4, 5}) and x is a bag-of-words of the review. When p = q = 2, we recover ridge regression, and when p = 2 and q = 1 we recover the â€œlasso,â€ which can obtain sparse solutions. While exact solutions are possible for most of some of these conditions, we instead focus on gradient-based optimizations. Specifically, we consider two algorithms. First, we consider the widely-used quasi-Newton method LBFGS (?), and the OWL-QN variant for `1 regularization (?). Second, we consider the Adaptive Gradient (AdaGrad) variant of Stochastic Gradient Descent, using forward `2 and `1 regularization. (?). This latter algorithm is much like gradient descent, except that step sizes are determined on a per-component basis, where the step size at time t for component i is defined to be:",2012,
Binarized Support Vector Machines,"The widely used support vector machine (SVM) method has shown to yield very good results in supervised classification problems. Other methods such as classification trees have become more popular among practitioners than SVM thanks to their interpretability, which is an important issue in data mining. 
 
In this work, we propose an SVM-based method that automatically detects the most important predictor variables and the role they play in the classifier. In particular, the proposed method is able to detect those values and intervals that are critical for the classification. The method involves the optimization of a linear programming problem in the spirit of the Lasso method with a large number of decision variables. The numerical experience reported shows that a rather direct use of the standard column generation strategy leads to a classification method that, in terms of classification ability, is competitive against the standard linear SVM and classification trees. Moreover, the proposed method is robust; i.e., it is stable in the presence of outliers and invariant to change of scale or measurement units of the predictor variables. 
 
When the complexity of the classifier is an important issue, a wrapper feature selection method is applied, yielding simpler but still competitive classifiers.",2010,INFORMS J. Comput.
"Thalassobacter stenotrophicus gen. nov., sp. nov., a novel marine alpha-proteobacterium isolated from Mediterranean sea water.","A Gram-negative, slightly halophilic, strictly aerobic, chemo-organotrophic bacterium was isolated from Mediterranean sea water near Valencia (Spain). 16S rRNA gene sequence comparisons showed that the isolate represented a separate branch within the alpha-3 subclass of the Proteobacteria, now included within the order 'Rhodobacterales'. Jannaschia helgolandensis was the closest relative, but their low sequence similarity and other features indicated that they were not related at the genus level. Isolate 5SM22T produced bacteriochlorophyll a and grew on solid media as regular salmon-pink colonies. Cells are motile rods, with polar flagella. The DNA G+C content is 59.1 mol%. Morphological, physiological and genotypic differences from related, thus far known genera support the description of Thalassobacter stenotrophicus gen. nov., sp. nov. with strain 5SM22T (=CECT 5294T=DSM 16310T) as the type strain.",2005,International journal of systematic and evolutionary microbiology
SFP-P058 â€“ Cardiologie â€“ Traitement transcutanÃ© de lâ€™atrÃ©sie pulmonaire Ã  septum ventriculaire intact : une premiÃ¨re au Liban,"Objectif Decrire la technique dâ€™une alternative percutanee au traitement chirurgical classique de lâ€™atresie pulmonaire a septum ventriculaire intact (APSI), consistant a ouvrir la voie pulmonaire avec la creation dâ€™un shunt aorto-pulmonaire. Presentation du cas Le diagnostic echographique dâ€™APSI est fait a la naissance dâ€™un garcon a terme 3 kg devant une cyanose isolee. Lâ€™anatomie etant favorable a une reparation bi-ventriculaire (Ventricule droit tripartites; Anneau tricuspide 13 mm; Anneau pulmonaire 7,5 mm; Pas de sinusoide), la perfusion de prostaglandine est initiee et lâ€™enfant est transfere a J4 en salle de catheterisme. Un catheter JR 4 French est place par voie veineuse en face du plancher valvulaire pulmonaire. Le bout rigide dâ€™un guide 0,014 Â» est introduit dans le catheter puis enfonce a travers le plancher valvulaire. Une sonde a lasso est introduite par voie arterielle a la rencontre du guide. Apres lâ€™accrochagedu guidea lâ€™aidedu lasso, ce circuit arterio-veineux nous a permis dâ€™avancer le catheter veineux a travers le plancher valvulaire et parla suite dâ€™effectuer une valvuloplastie au ballon. Lâ€™ouverture de la voie pulmonaire, bien que large (ballon 10 mm), nâ€™a pas permis le sevrage de prostaglandine. Cette aggravation de la cyanose est classiquement due dans ce type de malformation a la non recuperation rapide de la fonction diastolique du ventricule droit et a lâ€™augmentation consequente du shunt auriculaire inverse. A J10 de vie, lâ€™enfant est repris en salle de catheterisme et un stent (diametre = 3,5 mm ; Longueur = 16 mm) est place par voie veineuse dans le canal arteriel. Lâ€™enfant rentre a domicile a J14 de vie sous Aspirine avec une SaO2 a 90 %. A 3 mois de vie, ce nourrisson a une bonne croissance avec un canal permeable et une SaO2 a 94 %. Conclusion Dans les formes dâ€™APSI favorables a la reparation biâ€“ventriculaire, le traitement transcutane en periode neonatale est une alternative delicate et elegante a la chirurgie a cÅ“ur ouvert.",2008,Archives De Pediatrie
Cleavage of RNA by Imidazole,"Development of RNA cleaving agents, artificial RNases, has attracted considerable attention in the last years, because they can find important applications in biotechnology, for manipulating RNA, and in drug design. A direct approach to design of artificial RNases consists in imitation of the active centers of natural enzymes by simple organic structures possessing minimal sets of the most important characteristics that are essential for catalysis (for reviews see Vlassov et al. 1998; Komiyama and Sumaoka 1998). Usually, these primitive mimics are less efficient and less specific as compared to the natural enzymes. However, these synthetic constructs are more stable than proteins and can function in a broader range of conditions. Artificial RNases are much smaller than the natural enzymes and in contrast to the natural enzymes, their activity is not modulated by different effector molecules. This simplicity appears to be an advantage when artificial RNases are used in design of therapeutics for controlling gene expression or as components of synthetic conjugates. These conjugates are targeted to specific RNA molecules by oligonucleotides, and unwanted interactions of their components have to be minimized.",2004,
SeafoodSource: Verlasso inks deal for Texas distribution | Verlasso,SeafoodSource shares the announcement of Verlasso's new partnership with Louisiana Seafoods.,2012,
Imbalanced Binary Classification On Hospital Readmission Data With Missing Values,"Hospital readmission is a costly, undesirable, and often preventable patient outcome of inpatient care. Early readmission prediction can effectively prevent life-threatening events and reduce healthcare costs. However, imbalanced class distribution and high missing value rates are usually associated with readmission data and need to be handled carefully before building classification models. In this paper, we investigate the prediction of hospital readmission on a dataset with high percentage of missing values and class imbalance problem. Different methods are applied to impute missing values in the categorical variables and numerical variables. In addition, SMOTE (Synthetic Minority Over-sampling Technique) and cost-sensitive learning are combined with different classification methods (LASSO logistic regression, random forest, and gradient boosting) to explore which one will yield the best classification performance on the readmission data. Total misclassification cost and area under ROC curve are used as evaluation metrics for model comparison. Our results show that the SMOTE method causes overfitting on our readmission data and cost-sensitive learning outperforms SMOTE in terms of total misclassification cost.",2018,
Il by-pass bilio-intestinale nel trattamento della sindrome metabolica nel paziente obeso,"Introduzione. Lâ€™obesita (O) e una condizione patologica cronica, evolutiva e recidivante, ad eziopatogenesi multifattoriale, consistente in unâ€™alterazione della composizione del corpo caratterizzata da eccesso assoluto e relativo di grasso, che peggiora la qualita della vita e provoca complicanze che possono condurre a morte. 
Pazienti e metodi. Lâ€™esperienza si riferisce a 45 pazienti obesi diabetici, tutti sottoposti ad intervento di by-pass bilio-intestinale nel periodo gennaio 2006-dicembre 2007. I pazienti trattati sono stati preliminarmente sottoposti ad un rigoroso esame clinico e di laboratorio. 
Un preciso ritmo di controlli di laboratorio, sovrapponibili a quelli eseguiti nella fase pre-operatoria dellâ€™intervento, e stato richiesto ad ogni paziente: il primo allo scadere del 1Â° mese dallâ€™intervento, il 2Â°a 6 mesi ed il terzo a 12 mesi. 
Risultati. Il calo ponderale medio e stato di circa 40 Kg e, ancor piu importante, da questi dati appare chiaro che il BMI si riduce, fino a stabilizzarsi, a 12 mesi dallâ€™intervento chirurgico, su valori di 34-31 Kg/m2, ottenendo, in tal modo, un miglioramento dei valori implicati nello sviluppo della sindrome metabolica e, soprattutto, della frequenza cardiaca e della ripolarizzazione ventricolare. 
Conclusioni. I dati ottenuti dal nostro studio suffragano lâ€™ipotesi di proporre gli interventi di chirurgia bariatrica malassorbitiva, in particolare il By-Pass Bilio-Intestinale, come metodiche profilattiche per patologie dismetaboliche, con riduzione del rischio cardiovascolare nel paziente obeso.",2010,
Development and Validation of an IDH1-Associated Immune Prognostic Signature for Diffuse Lower-Grade Glioma,"A mutation in the isocitrate dehydrogenase 1 (IDH1) gene is the most common mutation in diffuse lower-grade gliomas (LGGs), and it is significantly related to the prognosis of LGGs. We aimed to explore the influence of the IDH1 mutation on the immune microenvironment and develop an IDH1-associated immune prognostic signature (IPS) for predicting prognosis in LGGs. IDH1 mutation status and RNA expression were investigated in two different public cohorts. To develop an IPS, LASSO Cox analysis was conducted for immune-related genes that were differentially expressed between IDH1wt and IDH1mut LGG patients. Then, we systematically analyzed the influence of the IPS on the immune microenvironment. A total of 41 immune prognostic genes were identified based on the IDH1 mutation status. A four-gene IPS was established and LGG patients were effectively stratified into low- and high-risk groups in both the training and validation sets. Stratification analysis and multivariate Cox analysis revealed that the IPS was an independent prognostic factor. We also found that high-risk LGG patients had higher levels of infiltrating B cells, CD4+ T cells, CD8+ T cells, neutrophils, macrophages and dendritic cells, and expressed higher levels of CTLA-4, PD-1 and TIM-3. Moreover, a novel nomogram model was established to estimate the overall survival in LGG patients. The current study provides novel insights into the LGG immune microenvironment and potential immunotherapies. The proposed IPS is a clinically promising biomarker that can be used to classify LGG patients into subgroups with distinct outcomes and immunophenotypes, with the potential to facilitate individualized management and improve prognosis.",2019,Frontiers in Oncology
Labeling the Features Not the Samples: Efficient Video Classification with Minimal Supervision,"Feature selection is essential for effective visual recognition. We propose an efficient joint classifier learning and feature selection method that discovers sparse, compact representations of input features from a vast sea of candidates, with an almost unsupervised formulation. Our method requires only the following knowledge, which we call the \emph{feature sign}---whether or not a particular feature has on average stronger values over positive samples than over negatives. We show how this can be estimated using as few as a single labeled training sample per class. Then, using these feature signs, we extend an initial supervised learning problem into an (almost) unsupervised clustering formulation that can incorporate new data without requiring ground truth labels. Our method works both as a feature selection mechanism and as a fully competitive classifier. It has important properties, low computational cost and excellent accuracy, especially in difficult cases of very limited training data. We experiment on large-scale recognition in video and show superior speed and performance to established feature selection approaches such as AdaBoost, Lasso, greedy forward-backward selection, and powerful classifiers such as SVM.",2016,
Sound source separation using image signal processing based on sparsity of sound field,"Microphone arrays have been used to separate sound sources to improve speech recognition in a noisy environment. We propose a method using image signal processing to achieve highly accurate sound source separation. The microphone array is 1-m long and consists of eight microphones. Temporal sequences of the sound pressures obtained from the eight microphones are converted into sequences of luminance. These are arranged in parallel in an image, which is referred to as a spatio-temporal sound pressure distribution image. Sparse modeling using L1 regularization (Lasso) is applied to the image for restoring a high-resolution image. The spatial spectrum of the restored image is obtained using a two-dimensional fast Fourier transform (FFT) algorithm. In this spectrum, the angle of a line through the center denotes the arrival direction of sound, and the distance from the center indicates its frequency. By extracting a line from the spectrum, the sound source can be separated. A computational experiment revealed...",2016,Journal of the Acoustical Society of America
Dedicating music manuscripts : On function and form of paratexts in fifteenth- and sixteenth-century sources,"because of 'the applause and the approval that the other songs that I have edited far and wide have brought' .41 It is the expression of a composer's self-awareness and consciousness that could probably hardly have been imagined earlier in the century, leaving out of consideration Lasso's mature career. Just one year earlier, in 1595, Philippe Rogier claimed to be true to the age-old tradition of publishing with the intention of reaching immortality of one's name. According to the composer, dedicating the edition to Alberto Acquaviva, Duke of Atri and possibly son of Giovanni Girolamoenhanced this purpose.42 It is my conviction that composers were attentive to the new possibilities of music printing and that they became ever more conscious of the power of this medium. Reading the dedications, one doesn't only come across extra bits and pieces of biographical and historical information. When reading between the lines, the liminary texts on the whole allow insight in the functioning of the dedicatory act, its aims and effect. While taking care not to over-interpret the words, one shouldn't be hesitant to interpret them either, for we can be certain that in the sixteenth century, just as now, one could read the lines but also read between the lines.",2008,
A tutorial on the Lasso approach to sparse modeling,"abstract Article history:Received 13 December 2011Received in revised form 3 October 2012Accepted 5 October 2012Available online 13 October 2012Keywords:SparsityL 1 norm(Bi)convex optimizationLasso In applied research data are often collected from sources w ith a high dimensional multi variate output. Analysis ofsuchdataiscomposedofe.g.extractionandcharacterizationof underlyingpatterns,andoftenwiththeaim of ï¬nd-ingasmall subsetofsigni ï¬cant variablesorfeatures.Variable andfeatureselectioniswell-established inthe area ofregression,whereasforothertypesofmodelsthisseemsmoredifï¬cult. Penalization of the L 1 norm provides an in-teresting avenue for such a problem, as it produces a spar se solution and hence embeds variable selection. In thispaper a brief introduction to the mathematical properties of using the L 1 norm as a penalty is given. Examples ofmodelsextendedwith L 1 normpenalties/constraintsarepresented.TheexamplesincludePCAmodelingwithsparseloadings which enhance interpretability of single componen ts. Sparse inverse covariance matrix estimation is usedtounravelwhichvariablesareaffectingeachother,andamodi ï¬edPCAtomodeldatawith(piecewise)constantre-sponses in e.g. process monitoring is shown. All example s are demonstrated on real or synthetic data. The resultsindicate that sparse solutions, when approp riate, can enhance model interpretability.Â© 2012 Elsevier B.V. All rights reserved.",2012,Chemometrics and Intelligent Laboratory Systems
ManÃ­as: un trastorno mÃ¡s comÃºn de lo que se piensa,"El objetivo del presente trabajo eshacer una revision bibliografica de laliteratura publicada sobre las manias.Para ello, se procedio a analizar diversaspublicaciones y se resumieron losaspectos mas relevantes de este tema.Las manias son mucho mas comunes y,generalmente, uno se percata de ellassolo cuando las padecen personas delentorno familiar, social o laboral. Entre lasmas frecuentes se puede mencionar lasrelacionadas con la limpieza, la salud, elorden, la seguridad fisica o psicologica, yla acumulacion de objetos. Las personasque sufren este trastorno no sonconscientes de que estan enfermas, porlo que no buscan ni aceptan tratamiento.",2016,
Geographic distribution and conservation status of sawfish Pristis spp (Pristiformes: Pristidae) in the southern Caribbean Sea,"Formato ISO 690-2 (Articulos de revistas electronicas) Gomez-Rodriguez, Santiago, Caldas, Juan P., Acero-P., Arturo, Martinez-Silva, Maria A., Saenz-Okuyama, Paola, Carlos A., Lasso, Lasso-Alcala, Oscar M., Geographic distribution and conservation status of sawfish Pristis spp (Pristiformes: Pristidae) in the southern Caribbean SeaBiota Colombiana [en linea] 2014, 15 ( ) : [Fecha de consulta: 6 de diciembre de 2017] Disponible en: ISSN 0124-5376",2014,
"Mississippianâ€“Early Permian brachiopods from western Argentina: Tools for middle- to high-latitude correlation, paleobiogeographic and paleoclimatic reconstruction","Abstract Brachiopod faunas from western Argentina are reviewed to improve the current understanding of their biostratigraphic and paleobiogeographic value for intercontinental correlation and paleoclimatic reconstruction, especially for middle to high paleolatitudes. The oldest faunal assemblage, the late Tournaisianâ€“early Visean Malimanian fauna, indicates an incipient biogeographic segregation of southwestern South America from contemporaneous peri-Gondwana and northern hemisphere regions, likely due to the enhanced thermal gradient that predated the pronounced latest Visean global cooling and the major latitudinal biotic differentiation on a global scale. Paleogeographical distribution of key brachiopod taxa provides evidence of faunal interchange along western Gondwana during late Early Carboniferous. The paleoclimate of the region by this time has been interpreted as temperate preglacial conditions, in a higher paleolatitudinal setting. Global cooling and strong differentiation between marine biota of circum-polar and paleoequatorial regions occurred after late Visean. The Barrealian fauna ( Rugosochonetes-Bulahdelia and Levipustula assemblages), represents the oldest faunal record in western Argentina of this major latitude-related biotic segregation linked with the onset of the mid-Carboniferous glaciation. The Barrealian fauna appeared during a major late Viseanâ€“Serpukhovian glacial episode with short-lived glacial and interglacial stages. Climatic fluctuations were probably related to local faunal changes and marine biotic exchange between higher and middle paleolatitudes of southwestern and eastern Gondwana. Widespread postglacial deposits bearing Bashkirian faunas demonstrate the beginning of a progressive climatic amelioration trend until early Permian times, barely affected by short-lived colder paleoclimatic fluctuations. The incoming of the late Bashkirianâ€“early Moscovian Marginovatia-Maemia fauna was linked to a climatic change in the region following the disappearance of glacial conditions in westernmost Argentina. Ocean currents from the north, that reached the region bringing boreal brachiopods, were warm enough since Bashkirian times to build a thermal barrier for the biotic interchange with peri-Gondwana regions under subpolar settings and a faunal disconnection was established. In addition, asymmetrical climatic record between western Argentina and regions still under strong glacial influence, such as Patagonia and eastern Australia, reflect the clockwise rotation of Gondwana and consequent migration of western Argentina to lower latitudes. After a preceding mainly regressive depositional interval, the marine incursion bearing the Tivertonia - Streptorhynchus fauna accompanied the most extensive transgression that covered western Argentina. It was probably linked with the beginning of a thalassocratic regime by the global major sea level rise of late Asselianâ€“Sakmarian times. The Tivertonia-Streptorhynchus assemblage represents a middle paleolatitude temperate and mixed fauna, which migrated toward southern Gondwana regions, indicating a marine faunal connection during a climatic amelioration trend. The last marine incursion in western Argentina brought the Costatumulus fauna, linked to a brief interruption of the mostly temperate paleoclimatic conditions established since the Pennsylvanian. A short-lived minor glacial pulse associated with the Costatumulus fauna reflected local mitigated climatic fluctuations, by the paleolatitudinal gradient to circumpolar areas where a major glacial pulse occurred during Sakmarianâ€“Artinskian times.",2010,"Palaeogeography, Palaeoclimatology, Palaeoecology"
Multiscale Biharmonic Kernels,"This paper introduces a general principle for constructing multiscale kernels on surface meshes, and presents a construction of the multiscale pre-biharmonic and multiscale biharmonic kernels. Our construction is based on an optimization problem that seeks to minimize a smoothness criterion, the Laplacian energy, subject to a sparsity inducing constraint. Namely, we use the lasso constraint, which sets an upper bound on the l1 -norm of the solution, to obtain a family of solutions parametrized by this upper-bound parameter. The interplay between sparsity and smoothness results in smooth kernels that vanish away from the diagonal. We prove that the resulting kernels have gradually changing supports, consistent behavior over partial and complete meshes, and interesting limiting behaviors (e.g. in the limit of large scales, the multiscale biharmonic kernel converges to the Green's function of the biharmonic equation); in addition, these kernels are based on intrinsic quantities and so are insensitive to isometric deformations. We show empirically that our kernels are shape-aware, are robust to noise, tessellation, and partial object, and are fast to compute. Finally, we demonstrate that the new kernels can be useful for function interpolation and shape correspondence.",2011,Comput. Graph. Forum
1-30-2012 A significance test for the lasso,"In the sparse linear regression setting, we consider testing the significance of the predictor variable that enters the current lasso model, in the sequence of models visited along the lasso solution path. We propose a simple test statistic based on lasso fitted values, called the covariance test statistic, and show that when the true model is linear, this statistic has an Exp(1) asymptotic distribution under the null hypothesis (the null being that all truly active variables are contained in the current lasso model). Our proof of this result assumes some (reasonable) regularity conditions on the predictor matrix X, and covers the important high-dimensional case p > n. Of course, for testing the significance of an additional variable between two nested linear models, one may use the usual chi-squared test, comparing the drop in residual sum of squares (RSS) to a Ï‡21 distribution. But when this additional variable is not fixed, but has been chosen adaptively or greedily, this test is no longer appropriate: adaptivity makes the drop in RSS stochastically much larger than Ï‡21 under the null hypothesis. Our analysis explicitly accounts for adaptivity, as it must, since the lasso builds an adaptive sequence of linear models as the tuning parameter Î» decreases. In this analysis, shrinkage plays a key role: though additional variables are chosen adaptively, the coefficients of lasso active variables are shrunken due to the l1 penalty. Therefore the test statistic (which is based on lasso fitted values) is in a sense balanced by these two opposing propertiesâ€”adaptivity and shrinkageâ€”and its null distribution is tractable and asymptotically Exp(1).",2015,
[Metabolic syndrome and cardiovascular risk patients under antiretrovirals in a day hospital at Bobo-Dioulasso (Burkina Faso)].,"Highly active antiretroviral therapy (HAART) has reduced morbidity and mortality of HIV but has led to an increasing metabolic cardiovascular risk. A cross-sectional study was conducted from May to September 2011 in Day Care Hospital for HIV-Patients of Bobo-Dioulasso. We included in this study 400 patients infected by HIVon antiretroviral therapy â‰¥ 6 months selected by a random draw. Metabolic syndrome was assessed according to the definitions of the IDF and ATP-III. The high risk of cardiovascular disease in 10 years was defined by a Framingham score â‰¥ 20%. The average age of our patients was 41.4 years [20-76]. 17% received an IP. The average duration of PI exposure was 35.5 months and 50.1 months for NNRTI. The prevalence of diabetes was 1.3% (95% CI: 0.5-3) and that of hypertension of 12.0 % (95% CI: 9.3-16). The prevalence of metabolic syndrome according to IDF was 10% (95% CI: 7.3-13.5) and the metabolic syndrome according to ATP-III 12.3% (95% CI: 9.3-16). The body mass index was higher (BMI 25.2 vs. 22.5 kg/m(2), p <10(-3) with ATPIII and BMI 26.6 vs. 22.4 kg/m(2), p <10(-3) with IDF), and duration exposure to ARVs longer in patients with metabolic syndrome regardless of the definition used (58.6 months vs 27.9 months). High cardiovascular risk was present in 1.8% (95% CI: 0.8 to 3.7) of our patients, all male more than half (n=4/7) of them were smoking. The choice of antiretroviral therapy must take into account its potential long-term toxicity. It should also strengthen supervision.",2014,Bulletin de la Societe de pathologie exotique
An Adaptive SSVEP-Based Brain-Computer Interface to Compensate Fatigue-Induced Decline of Performance in Practical Application,"Brain-computer interfaces based on steady-state visual evoked potentials are promising communication systems for people with speech and motor disabilities. However, reliable SSVEP response requires userâ€™s attention, which degrades over time due to significant eye-fatigue when low-frequency visual stimuli (5â€“15 Hz) are used. Previous studies have shown that eye-fatigue can be reduced using high-frequency flickering stimuli (>25 Hz). Here, it is quantitatively demonstrated that the performance of a high-frequency SSVEP BCI decreases over time, but this amount of decrease can be compensated effectively by using two proposed adaptive algorithms. This leaded to a robust alternative communication system for practical applications. The asynchronous spelling system implemented in this study uses a threshold-based version of LASSO algorithm for frequency recognition. In long online experiments, when participants typed a sentence with the BCI system for 16 times, accuracy of the system was close to its maximum along the experiment. However, regression analysis on typing speed of each sentence demonstrated a significant decrease in all 7 subjects ( ${p} < {0.05}$ ) when thresholds obtained from a calibration test were kept fixed over the experiment. In comparison, no significant change in typing speed was observed when the proposed adaptive algorithms were used. The analysis of variances revealed that the average typing speed of the last four sentences when using adaptive relational algorithm (8.7 char/min) was significantly higher than the tolerance-based algorithm (8.1 char/min) and significantly above 6 char/min when the fixed thresholds were used. Therefore, the relational algorithm proposed in this paper could successfully compensate for the effect of fatigue on performance of the SSVEP BCI system.",2018,IEEE Transactions on Neural Systems and Rehabilitation Engineering
Broadleaf Weed Control in Sprinkler Irrigated Bragg Soybeans,"Twelve herbicides were evaluated for control of broadleaf weeds and safety to the soybeans in cooperation with Barkley Company of Arizona near somerton, Arizona. The soil type was a silt clay loam. Plot size was 15 feet wide by 30 feet long. Lasso, Cobex, Vernam, Prowl, Tolban and R -40244 were aplied pre -plant on July 7, 1978 and double incorporated with a disc to the approximate depth of 3 inches. Six rows of soybeans, 30 inches apart, were sown through each plot with flex -type planters on July 13. Dacthal, Sencor (Lexone) and Surflan were applied pre -emergence to the soybeans on July 14. The area was then sprinkle irrigated as needed until September 10, at which time they were flood irrigated for the remainder of the season. Post -emergence applications of Basagran and Tenoran were made to the soybean and weed foliage on August 2. Wright groundcherry was in the 4 to 8 leaf stage with 6 leaves being predominate. Common purslane plants were 2 to 6 inches in diameter, with most 3 inches. Soybean plants were mostly in the first trifoliate leaf stage when the postemergence applications were made. All herbicides were applied with a knapsack compressed air sprayer in 20 gallons of water per acre. Population of Wright groundcherry and common purslane in check plots were dense enough to provide a complete canopy on September 28. Soybeans were almost completely crowded out. Weed control and percent stand evaluations were made on September 28. Sencor and Basagran treatments resulted in excellent control of Wright groundcherry. Prowl and Vernam gave good Wright groundcherry control. All herbicides tested gave good to excellent control of common purslane, except Tenoran. Cobex and R -40244 reduced soybean stands to unacceptable levels at the rates tested. Basagran controlled weeds, but some stand loss was apparent. Untreated check stand loss was due to extreme weed competition.",1979,
Forecasting completed cost of highway construction projects using LASSO regularized regression,"Finishing highway projects within budget is critical for state highway agencies (SHAs) because budget overruns can result in severe damage to their reputation and credibility. Cost overruns in highway projects have plagued public agencies globally. Hence, this research aims to develop a parametric cost estimation model for SHAs to forecast the completed project cost prior to project execution to take necessary measures to prevent cost escalation. Ordinary least square (OLS) regression has been a commonly used parametric estimation method in the literature. However, OLS regression has certain limitations. It, for instance, requires strict statistical assumptions. This paper proposes an alternative approachâ€” least absolute shrinkage and selection operator (LASSO)â€”that has proved in other fields of research to be significantly better than the OLS method in many respects, including automatic feature selection, the ability to handle highly correlated data, ease of interpretability, and numerical stability of the model predictions. Another contribution to the body of knowledge is that this study simultaneously explores project-related variables with some economic factors that have not been used in previous research, but economic conditions are widely considered to be influential on highway construction costs. The data were separated into two groups: one for training the model and the other for validation purposes. Using the same dataset, both LASSO and OLS were used to build models, and then their performance was evaluated based on the mean absolute error, mean absolute percentage error, and root mean square error. The results showed that the LASSO regression model outperformed the OLS regression model based on the criteria.",2017,
Security-Constrained Multi-Objective Optimal Power Flow for a Hybrid AC/VSC-MTDC System With Lasso-Based Contingency Filtering,"In order to coordinate the economy and voltage quality of a meshed AC/VSC-MTDC system, a new corrective security-constrained multi-objective optimal power flow (SC-MOPF) method is presented in this paper. A parallel SC-MOPF model with <inline-formula> <tex-math notation=""LaTeX"">$N$ </tex-math></inline-formula>-1 security constraints is proposed for corrective control actions of the meshed AC/DC system, in which the minimization of the generation cost and voltage deviation are used as objective functions. To solve this model, a novel parallel bi-criterion evolution indicator based evolutionary algorithm (BCE-IBEA) algorithm is developed to seek multiple well-spread Pareto-optimal solutions through the introduction of parallel computation. In this process, a least absolute shrinkage and selection operator (Lasso)-based <inline-formula> <tex-math notation=""LaTeX"">$N$ </tex-math></inline-formula>-1 contingency filtering scheme with a composite security index is developed to efficiently screen out the most severe cases from all contingencies. And thereby, the best compromise solutions reflecting the preferences of different decision makers are automatically determined via an integrated decision making technique. Case studies in the modified IEEE 14- and 300-bus systems demonstrate that the presented approach manages to address this SC-MOPF problem with significantly improved computational efficiency.",2020,IEEE Access
Performance Analysis Of Regularized Linear Regression Models For Oxazolines And Oxazoles Derivitive Descriptor Dataset,"Regularized regression techniques for linear regression have been created the last few ten years to reduce the flaws of ordinary least squares regression with regard to prediction accuracy. In this paper, new methods for using regularized regression in model choice are introduced, and we distinguish the conditions in which regularized regression develops our ability to discriminate models. We applied all the five methods that use penalty-based (regularization) shrinkage to handle Oxazolines and Oxazoles derivatives descriptor dataset with far more predictors than observations. The lasso, ridge, elasticnet, lars and relaxed lasso further possess the desirable property that they simultaneously select relevant predictive descriptors and optimally estimate their effects. Here, we comparatively evaluate the performance of five regularized linear regression methods The assessment of the performance of each model by means of benchmark experiments is an established exercise. Cross-validation and resampling methods are generally used to arrive point evaluates the efficiencies which are compared to recognize methods with acceptable features. Predictive accuracy was evaluated using the root mean squared error (RMSE) and Square of usual correlation between predictors and observed mean inhibitory concentration of antitubercular activity (R square). We found that all five regularized regression models were able to produce feasible models and efficient capturing the linearity in the data. The elastic net and lars had similar accuracies as well as lasso and relaxed lasso had similar accuracies but outperformed ridge regression in terms of the RMSE and R square metrics.",2013,ArXiv
Unlocking GOES: A Statistical Framework for Quantifying the Evolution of Convective Structure in Tropical Cyclones.,"Tropical cyclones (TCs) rank among the most costly natural disasters in the United States, and accurate forecasts of track and intensity are critical for emergency response. Intensity guidance has improved steadily but slowly, as processes which drive intensity change are not fully understood. Because most TCs develop far from land-based observing networks, geostationary (Geo) satellite imagery is critical to monitoring these storms. Modern high-resolution Geo observations provide an unprecedented scientific opportunity. These complex data are however challenging to analyze by forecasters in real time, whereas off-the-shelf machine learning algorithms have limited applicability due to their ""black box"" structure. This study presents analytic tools that quantify convective structure patterns in infrared Geo imagery for over-ocean TCs, yielding lower-dimensional but rich representations that support analysis and visualization of how these patterns evolve during a rapid intensity change. The proposed ORB feature suite targets the global Organization, Radial structure, and Bulk morphology of TCs. Combined with a functional basis, the resulting representation of convective structure patterns on multiple scales serves as input to powerful but sometimes hard-to-interpret machine learning methods. This study uses the logistic lasso, a penalized generalized linear model, to relate predictors to rapid intensity change. Using ORB alone, binary classifiers identifying the presence (versus absence) of such events achieve accuracy comparable to classifiers using environmental predictors alone, while a combined predictor set further reduces nowcasting errors. More complex nonlinear machine learning methods did not improve accuracy over our linear logistic lasso model.",2019,arXiv: Applications
Hazardous and radioactive waste treatment technologies handbook,"Overview of U.S. Federal Laws and Regulations Affecting Mixed Waste Treatment, M. Knecht Waste Characterization & Classification Sample Collection Design, J. Maney Analytical Technology, S. Goheen Statistical Inference, E. Chai Other Characterization and Classification, R. Montgomery Separation Techniques In-situ Remediation of Contaminated Soils by Electrokinetic Processes, S. Pamukcu and C. Huang Mercury Separation, T. Klasson Separation of Radionuclides from Aqueous Mixed-Waste Solutions Using Liquid-Liquid Extraction Processes, T. Todd, J. Law, and R. Herbst Thermal Treatment Technologies Incineration, J. McFee, C. Pfrommer, Jr., and M. Aident Vitrification, I. Pegg and I. Joseph Application of Steam-Reforming to Various Types of Radwaste, T. Galloway, M. Cage, and T. Snyder Wet Air Oxidation, R. Shah and R. Mahalingam Supercritical Water Oxidation, P. Savage and C. Oh Thermal Desorption, G. Stegemeier, H. Vinegar, P. Sadler Molten Salt Oxidation, P. Hsu and M. Adamson Fluidized-Bed Calcination, J. Christian Non-thermal Treatment Technologies Supercritical Fluid Extraction for Nuclear Waste Treatment, C. Wai Electrochemical or Direct Chemical Oxidation, B. Balazs, Z. Chiba, M. Adamson, R. Pierce, N. Nelson, J. Cooper, P. Hsu, and P. Lewis Electrohydraulic Cavitation and Sonolysis, M. A. Beckett, J. Schramm, G. Zhang, and I. Hua Gas Phase Destruction, B. Penetrante and L. Rosocha Radiation Induced Oxidation, W. Cooper, M. Nickelsen, T. Tobien, and B. Mincher Phytoremediation, G. Lanza and P. Flathman Stabilization and Solidification Technologies Generals of Mixed Waste Solidification and Stabilization Methods, V. Maio Chemical Fixation and Stabilization, C. Langton Chemically Bonded Phosphate Ceramics for Mixed Waste Stabilization and Solidification, A. Wagh, D. Singh, and S. Jeong Polyester Resin Microencapsulation, R. Biyani , P. Agamuthu, and R. Mahalingam Polyethylene Encapsulation, P. Kalb Sulfur Polymer Encapsulation, P. Kalb In-situ Buried Waste Stabilization Using Jet Grouting, G. Loomis, R. Farnsworth, and J. Jessmore Offgas Control for Mixed Waste Thermal Treatment Systems, N. Soelberg Introduction Design and Performance Objectives for Offgas Control Systems Input Offgas Flowrates and Compositions Examples of Existing Offgas Systems for Mixed Waste Treatment APCS Designs for Complying with New Regulations Mercury Emissions Control Technologies for Mixed Waste Treatment Offgas System Design and Capital Cost Estimates Conclusions and Recommendations Decontamination, J. Tripp, R. Demmer, and R. Meservey Decontamination Techniques Mechanical Surface Removal Methods Chemical Decontamination Biological Decontamination Bulk Decontamination Defining Terms References System Integration and Deployment Integration of Mixed Waste Treatment into an Environmental and Quality Management System, J. Meagher Risk Analysis and Toxicology, R. Vanhorn Planned Life-Cycle Cost Estimates, W. Schwinkendorf",2001,
Elastic Net Hypergraph Learning for Image Clustering and Semi-Supervised Classification.,"Graph model is emerging as a very effective tool for learning the complex structures and relationships hidden in data. In general, the critical purpose of graph-oriented learning algorithms is to construct an informative graph for image clustering and classification tasks. In addition to the classical K-nearest-neighbor and r-neighborhood methods for graph construction, l1-graph and its variants are emerging methods for finding the neighboring samples of a center datum, where the corresponding ingoing edge weights are simultaneously derived by the sparse reconstruction coefficients of the remaining samples. However, the pairwise links of l1-graph are not capable of capturing the high-order relationships between the center datum and its prominent data in sparse reconstruction. Meanwhile, from the perspective of variable selection, the l1 norm sparse constraint, regarded as a LASSO model, tends to select only one datum from a group of data that are highly correlated and ignore the others. To simultaneously cope with these drawbacks, we propose a new elastic net hypergraph learning model, which consists of two steps. In the first step, the robust matrix elastic net model is constructed to find the canonically related samples in a somewhat greedy way, achieving the grouping effect by adding the l2 penalty to the l1 constraint. In the second step, hypergraph is used to represent the high order relationships between each datum and its prominent samples by regarding them as a hyperedge. Subsequently, hypergraph Laplacian matrix is constructed for further analysis. New hypergraph learning algorithms, including unsupervised clustering and multi-class semi-supervised classification, are then derived. Extensive experiments on face and handwriting databases demonstrate the effectiveness of the proposed method.",2017,IEEE transactions on image processing : a publication of the IEEE Signal Processing Society
RLS-weighted Lasso for adaptive estimation of sparse signals,"The batch least-absolute shrinkage and selection operator (Lasso) has well-documented merits for estimating sparse signals of interest emerging in various applications, where observations adhere to parsimonious linear regression models. To cope with linearly growing complexity and memory requirements that batch Lasso estimators face when processing observations sequentially, the present paper develops a recursive Lasso algorithm that can also track slowly-varying sparse signals of interest. Performance analysis reveals that recursive Lasso can either estimate consistently the sparse signal's support or its nonzero entries, but not both. This motivates the development of a weighted version of the recursive Lasso scheme with weights obtained from the recursive least-squares (RLS) algorithm. The resultant RLS-weighted Lasso algorithm provably estimates sparse signals consistently. Simulated tests compare competing alternatives and corroborate the performance of the novel algorithms in estimating time-invariant and tracking slow-varying signals under sparsity constraints.",2009,"2009 IEEE International Conference on Acoustics, Speech and Signal Processing"
Agriculture as a success factor for municipalities.,"Prospective changes in agricultural policies will set more emphasis on targets and customer concerns. The analysis of a unique data base stemming from 18,000 citizensâ€™ responses in 60 communes shows interference between the performance of farming and the cognition of quality of life. Agriculture is â€“ among other factors â€“ one of the most significant predictors of quality of life in a municipality. INTRODUCTION AND MOTIVATION Austrian agricultural policy has been striving for years to reward services performed by a multifunctional agriculture. Currently, with the reform of agricultural and regional policy of the EU the targets are discussed anew. In this situation, arguments and evidence in the multi-functionality are important. To what extent does agriculture promote common goods and achieve objectives, perceived and recognised by the population? The analysis of a record on population surveys in citizen participation processes helps to answer this question. The research project â€œErfolgsVisionâ€ (engl. â€œVision of Successâ€) analyzed the results from population surveys in a cross-comparable way. The research project aimed at giving better support to citizen participation processes. The general idea was that an eagleâ€™s eye view of the recent citizen participation processes may yield new information, valuable for regional development consultants as well as municipality management and policies. Three partners joined for that project: SPES Academy, the data owner and regional developer; STUDIA-Schlierbach, an applied social researcher, so far responsible for municipal survey evaluations; and the Department of Statistics and Probability Theory at the Vienna University of Technology. PARTICIPATION PROCESSES AS A DATA SOURCE Over the past few years, the SPES Academy supervised and controlled numerous citizen participation processes in Austrian and German municipalities, mostly within the framework of Local Agenda 21, LEADER or communal business development programmes. These processes established innovative ideas, alliances and problem solutions in the municiW.E. Baaske is head of STUDIA-Schlierbach, Studienzentrum fur inter-nationale Analysen (baaske@studia-schlierbach.com) P. Filzmoser teaches at the Vienna University of Technology, Dep. of Statistics and Probability Theory (filzmoser@statistik.tuwien.ac.at) W. Mader works at SPES Academy, Panoramaweg 1, AT-4553 Schlierbach (mader@spes.co.at). R. Wieser works at the Vienna University of Technology, Dep. of Statistics and Probability Theory (wieser@statistik.tuwien.ac.at) palities. For many of them it was the first time that broad levels of the population were actively involved in local development. Interviews were conducted in order to understand citizensâ€™ demands, preferences and dispositions. They covered major issues concerning the habitation environment, infrastructure and services. They also assessed social capital in communities and positions on strategic fields of action. The results of the surveys have been used to provide a basis for local decision making. They have been reflected and discussed in communal committees and â€“ most often â€“ presented in public events or published in the local news. Each municipality received its own evaluation, consisting of tables, texts and graphics. This data gathered from local polls resulted in a unique record when summarised over the regions and years,. The SPES â€œGemeindepanoramaâ€ (engl. â€œpanorama of the municipalityâ€) is a screening of the local mind-set. Between 2000 and 2006, 60 communities participated, 45 of them from Austria (Upper and Lower Austria, Tyrol and Vorarlberg) and 15 from Germany: Baden-Wurttemberg and Bavaria. In total, 18,748 questionnaires have been collected, on average 312 per municipality. The survey has been subject to individual adaptations towards the municipal needs. It usually comprised about 250 questions, most of them multiple choice. 134 questions have been posed identically in 30 or more municipalities and yield comparable results. Some 25 questions concerned the local agriculture. In the course of the research project, those data have been merged with statistics on demography and economy. 40 mayors gave feed-backs on recent performance of their commune. ANALYZING SUCCESS FACTORS Hypotheses. Starting the research project, SPES developed a list of 27 hypotheses to be tested and questions to be answered, e.g. â€“ What makes communities successful? â€“ What makes quality of life (satisfaction)? What success factors are conditions for a sustained positive trend in quality of life? â€“ What factors encourage optimism? E.g. a strong mayor, successful projects, citizens interior binding and commitment, youth on board, good climate in coexistence and cooperation, high social capital, good communal information and public relations. â€“ Sector thinking in the communities disturbs the development of a positive quality of life. The closer to the habitat, the more important networked, holistic thinking becomes. If merchants win against farmers, then all lose in the final analysis. Data preparation included indicator building, handling of missing values, selection of variables and communes: Variables with less than 20% missing observations and observations with less than 50% missing variables were erased. Missing values were replaced by a nearest neighbour estimate. From the questions and hypotheses, we derived target variables. Sets of explanatory variables were not derived from the hypotheses, but with an automatic search procedure (Lasso regression). An allsubset regression has been carried out to find the essential set of variables explaining the target variable. Robust regression procedures have been applied to attain results that are not susceptible to singularities. ANALYSIS RESULTS FOR QUALITY OF LIFE Quality of Life (QoL) is â€“ on the one hand â€“ a subjective and personal measure of oneâ€™s own satisfaction with life. On the other hand the term is used to characterise regions or cities, reflecting the objective opportunities the location provides to the individual. QoL models reflect key areas as e.g. Being, Belonging and Becoming (Tichbon, Newton 2002) and include access to public services, nutrition and health, knowledge and the physical environment. QoL is represented graphically in order to test it on normal distribution, see Fig. 1. Lasso regression then identified the most influential 26 variables. The all-subset regression further selects variables for a regression model, see Tab. 1. The significant factors for a communeâ€™s quality of life are thus linked to supply structures, merchantsâ€™ activity and inventiveness, to social climate factors like â€œyouth-friendlinessâ€. It is important to mention, that model variables have been selected by the methods described above. Other model calculations show an influence of health servicesâ€™ supply and education and vocational training opportunities. Figure 1. Distribution and quantiles plot of â€œQuality of Lifeâ€. The variable reflects results of the question â€œPlease assess the current state of quality of life in your municipality, on a scale of 1 to 5 (1 ... very good, 5 ... very bad).â€ (n = 56) Table 1. Regression model for â€œQuality of Lifeâ€. Explaining variables: A ... state of the agriculture (question posed similar to Quality of Life, see above), Y ... state of municipalityâ€™s youth friendliness, V ... state of the municipalityâ€™s view, MC ... merchants activate the municipalityâ€™s centre, MI ... merchants are active and come up with ideas. QoL = 8.73 + 0.28 A + 0.21 Y + 0.14 V + 0.20 MC + 0.20 MI (5.9) (4.0) (3.6) (3.8) (3.2) adj. R2 = 0.93, dF = 27 Figure 2. Scatterplot of agricultural density (farms per population), x-axis, versus state of agriculture (SPES pollâ€™s result), y-axis; Loess-regression line; objects=municipalities The most important influential predictors have been displayed in scatterplots. They depict not only strength of interference, but also non-linear behaviour and the position of individual municipalities. The state of agriculture is important, but not sufficient itself to explain quality of life. The state of agriculture does not relate in a negative manner to the state of jobs in the region. The state of agriculture corresponds in part to the share of the agricultural population, especially when this density is low. At higher agricultural densities interference becomes zero, see Fig. 2.",2009,
Listado de autores de la SÃ­ntesis De La PolÃ­tica Nacional De Salud Y Lineamientos EstratÃ©gicos 201 6-2025. Synthesis of National Health Policy and Strategic Guidelines 201 6-2025.,"Listado de Autores - Ministerio de Salud Direccion de Planificacion de Salud â€“ Dra. Reina Roa, Directora de Planificacion â€“ Dra. I ritzel Santamaria, Subdirectora de Planificacion Departamento de Analisis de Situacion y Tendencias de Salud â€“ Dra. Norma Astudillo â€“ Dra. Yelkis Gill â€“ Dra. Cristina Gomez â€“ Dra. Jamileth Cortes â€“ Lic. Bernardino Lozano â€“ Lic. Indira Credidio Departamento de Planificacion de Salud Ambiental â€“ Dra. Melva Cruz â€“ Dra. Fulvia Bajura Departamento de Planificacion de Salud Poblacional â€“ Dra. Fania de Roach â€“ Dra. Daira Ibanez Departamento de Formulacion y Evaluacion de Presupuesto y Proyectos de Inversion â€“ Dra. Luzmery Lasso â€“ Dr. Oscar Gonzalez Departamento de Registros Medicos y Estadisticas de Salud â€“ Lic. Fanny Castaneda â€“ Lic. Lesbia Mojica â€“ Lic. Guillermina Mc Cleary â€“ Lic. Eduardo Navalo Correspondencia a: Dra. Reina Roa. Correo: reinaro@cwpanama.net",2016,
Two agencies explain conflict-of-interest rules,"Representatives of the National Institutes of Health (NIH) and the National Science Foundation (NSF) are trying to make sure researchers understand all the implications of new rules on conflicts of interest that went into effect Oct. 1. The rules are designed to ensure that research funded by the agencies is objective and will not be called into question because of investigator financial holdings. Biomedical research, particularly clinical studies, likely will be most affected by the rules, but they apply to ""everyoneâ€”domestic or foreign, public or private, profit or nonprofit. They apply to all investigatorsâ€”not only principal investigator and coinvestigator, but everybody who is involved in the research who is in a decision-making role. That is, anyone who is responsible for some outcome of the research,"" according to George J. Galasso, associate director of the office of extramural research at NIH. Galasso spoke at an American Association for the Advancement of Science Professional Society Ethics ...",1995,Chemical & Engineering News
Invited commentary to: â€œResection of hepatic metastases from colorectal cancerâ€œ,"References (1) Hugues K: Resection of the liver for eolorectal carcinoma metastases: a maltiinstitutional study of indication for resection. Surgery 1988;103:278-88. (2) Hugues K, Scheele J, Sugarbaker P-H: Surgery for colorectal cancer metastatic to the liver optimizing the results of treatment. Surg Clin North Am 1989;69:339-59. (3) Launois B: Hepatectomy: The posterior intrahepatic approach. Br J Surg 1997;84: 291-292. (4) Nordlinger B, Jaeck D, Balladur P, Vaillant J-C, Paris F: REsection chirurgicale des m6tastases h6patiques. Commentaires sur les r6sultats de l'enquete de lAssociation Frann~aise de Chirurgie. In: Norlinger B, Jaeck D (eds): Traitement des m6tastases hfpatiques des cancers colorectaux. Springer, Paris 1992; 141:55-59. (5) Scheele J: Hepatectomy for liver metastases. Br J Surg 1993;80:274-278. (6) Scheele J: Segment orientated resection of the liver: rationale and technique. In: Ligydakis N.J., Tytgat GNS.eds Hepato biliary and panceatic malignancies. Diagnosis medical and surgical management. Thieme, Stuttgart 1989;219:41-47. (7) Stephenson K-R, Steinberg S-M, Hughes K-S, Vetto J-T, Sugarbaker P-M., Chang A-L: Perioperative blood transfusions are associated with decreased time to recurrence and decreased survival after resection of colorectal liver metastases. Ann. Surg 1988;208:679-687. (8) Wagner S, Adson M-A, van Heerden J-A, llstrup D-M: The natural history of hepatic metastases from colorectal cancer. A comparison with resective treatment. Ann Surg 1984;199:502-508. (9) Tschmelitsch J, Eberwein M. Prommegger R, Oberwalder M, Unger A, Klingler A, Glaser K: Resection of Hepatic Metastases from Colorectal Cancer. Acta Chir Austriaca 1998;30:242-249.",2007,Acta Chirurgica Austriaca
What role for EUPHA,"G Damiani*, R Galasso, L Sommella, L Pinnarelli, SC Colosimo, R Almiento, L Sicuro, W Ricciardi Department of Public Health-Universita Cattolica S.Cuore-Rome, Italy Referral Oncological Center of Basilicata Rionero in Vulture (PZ), Italy â€˜San Filippo Neriâ€™ Hospital Trust-Rome, Italy *Contact details: gdamiani@rm.unicatt.it Background Reducing undesirable practice variations in care has long been promoted for its potential to improve the quality of health care. Besides, Computerized Clinical Decision Support Systems, designed to help physicians in clinical decision making and based on patient-specific recommendations, are widely spreading. Due to these two issues, computerized guideline (CG) implementation strategies have been considered as useful means of improving health outcomes, optimizing resource utilization and patient care quality. This study carried out a systematic review of scientific articles to evaluate the effectiveness of CG on cliniciansâ€™ behaviour, patients and organization outcomes. Methods Our literature search was carried out through electronic databases, using keywords, hand searching and analysis of further references from the bibliographic citations for each article meeting selected criteria. Analytical and experimental studies published in five languages, in adult population without time restriction. All studies were scored for methodological quality (MQ) on a previously validated scale. Proportions of studies reporting an improvement on physician, patient, and organization outcomes and their 95% confidence intervals (CI) were calculated. A logistic regression model, adjusted for study MQ, was used to investigate association between the outcomes of interest and study-specific covariates (i.e. degree of automation, user training, type of electronic suggestion). Results Out of 3672 articles found according to chosen keywords, 39 matched our criteria. Thirty were set in the USA, 6 in Europe, 2 in Asia and 1 in Australia. CG improved physician performance in 23 (67%), 95% CI 1â„4 51.9â€“83.4, of the 34 studies assessing this outcome. Out of 17 articles assessing patient and organization outcomes 8 trials (47%), 95% CI 1â„4 23.3â€“70.8, reported improvements for both issues. Studied covariates showed no association with outcomes. Conclusions Our initial results suggest that CG improve physician performance. The effects on patient and organization outcomes remain understudied and, when studied, inconsistent, so that further researches are needed.",2006,European Journal of Public Health
"Lâ€™approvvigionamento di Valencia (1650-1763). Consumi, mercato e istituzioni","Abastecimiento Alimentacion Mercado Valencia, Ss. XVII-XVIII El presente articulo tiene por objetivo realizar un analisis del abastecimiento de vituallas en Valencia entre 1650 y 1763, a traves del estudio de los autos de buen gobierno promulgados en este periodo por las autoridades municipales. Principalmente, pretendemos romper los planteamientos clasicas, centrados casi exclusivamente en el abasto de trigo, reivindicando la presencia de otro tipo de alimentos, tales como frutas, verduras, carne, pescado o queso entre otros, dentro de la dieta de antiguo regimen. Las fuentes utilizadas para nuestro estudio son de naturaleza juridica, los autos de buen gobierno promulgados en este periodo por las autoridades municipales. A traves de esta documentacion, planteamos una metodologia que complemente los estudios clasicos, excesivamente cuantitativos, con la informacion cualitativa y el analisis de variables sociales, institucionales y juridicas. A la luz de esta documentacion hemos podido comprobar la existencia de una menor dependencia frumentaria de la ciudad de Valencia, asi como una dieta mas variada de lo que plantean los estudios clasicos, el incremento de las dificultades de aprovisionamiento en Valencia durante la primera mitad del XVIII. Destacan el papel que los revendedores jugaron en esta inestabilidad, asi como la incapacidad de las autoridades y de los sistemas de abasto para hacer frente a la nueva realidad de Valencia en esta centuria. Por lo tanto, y en conclusion, senalamos la necesidad de incidir en los estudios sobre abastecimiento desde un punto de partida mas complejo, metodologica y documentalmente, que permita obtener un analisis mas complejo y acertado sobre este tema de investigacion. Alimentazione Mercato Valencia, secc. XVII-XVIII Il lavoro si propone di analizzare lâ€™approvvigionamento alimentare di Valencia fra il 1650 e il 1763, attraverso lo studio degli Â«autos de buen gobiernoÂ» emanati dalle autorita municipali in quel lasso di tempo. In tal modo si vuole abbandonare lâ€™approccio tradizionale incentrato quasi esclusivamente sullâ€™annona frumentaria, per affermare lâ€™importanza durante lâ€™ancien regime anche di altri consumi alimentari, per esempio di frutta, verdura, carne, pesce e formaggio. La documentazione utilizzata e di natura giuridica, gli autos de buen gobierno promulgati dalle autorita municipali, in virtu dei quali e possibile affrancarsi dallâ€™impostazione eccessivamente quantitativa degli studi tradizionali a favore di un approccio piu attento agli aspetti qualitativi e allâ€™analisi delle componenti sociali, istituzionali e giuridiche. Alla luce di tale documentazione e comprovata la minor dipendenza dal frumento dei consumi valenciani e la sussistenza di una dieta piu variegata rispetto a quanto contemplato dagli studi tradizionali, ma anche lâ€™aggravarsi dei problemi annonari della citta nella prima meta del secolo XVIII. Si palesa cosi la responsabilita del commercio speculativo in tale squilibrio, cosi come lâ€™incapacita delle autorita e del sistema annonario di far fronte ai nuovi bisogni della citta nel â€™700. In tema di approvvigionamento alimentare e necessario quindi perseguire una prospettiva di analisi piu complessa, sul piano metodologico ed euristico, per ottenere risultati piu solidi e veritieri.",2012,
Are affective temperaments determinants of quality of life in euthymic patients with bipolar disorder?,"BACKGROUND
Bipolar disorder (BD) is a disabling illness that is associated with low quality of life (QoL). This low QoL goes further than mood episodes, which suggests that stable traits, such as affective temperaments, can cause functional impairment.


OBJECTIVE
Our study analyses the impact of affective temperaments on the Physical Component Summary (PCS) and Mental Component Summary (MCS) of QoL in euthymic BD patients.


METHODS
A multicentre study was conducted in 180 euthymic BD patients and 95 healthy controls. Firstly, statistical analyses were performed to compare QoL and affective temperaments between the two groups. Secondly, Adaptive Lasso Analysis was carried out to identify the potential confounding variables and select the affective temperaments as potential predictors on the PCS and MCS of QoL in BD patients, as well as the control group.


RESULTS
QoL scores in terms of PCS and MCS in BD patients were significantly lower than in healthy individuals. Whereas anxious temperament, anxiety disorder comorbidity, and age were the best predictors of PCS impairment in BD patients, anxious temperament, subclinical depressive symptoms, and age were the best predictors of MCS impairment.


LIMITATIONS
Further longitudinal studies with unaffected high-risk relatives are needed to examine the potential interaction between affective temperament and psychopathology.


CONCLUSIONS
Anxious temperament has an impact on QoL in BD in terms of both the physical component and the mental component. Systematic screening of temperament in BD would give clinicians better knowledge of QoL predictors. Further research should allow more individualized treatment of BD patients based on temperamental factors.",2018,Journal of affective disorders
Metering device for powdered treating agent for a washing machine and a washing machine,"Die Erfindung betrifft eine Dosiereinrichtung (18) fur pulverformiges Behandlungsmittel fur eine Waschmaschine (1), mit mindestens einem Vorratsbehalter (20) fur Behandlungsmittel wie Waschmittel oder Wasch- oder Spulzusatze mit einem uber eine vertikale Drehachse (38) drehbaren Ruhrwerk (24) mit umlaufenden Messern (37), welches mit einem Elektroantrieb (25a) gekoppelt ist und von diesem antreibbar ist, und einer Fordereinrichtung (17), mit der das Behandlungsmittel (WP) uber einen Verbindungsschlauch (16) zur Waschmaschine (1) gefordert werden kann, und einem Dosiermittel zur Ausgabe von Behandlungsmittel (WP) aus dem Vorratsbehalter (20) in die Fordereinrichtung (17). Um eine genaue Dosierung bereitzustellen, umfasst das Dosiermittel eine zylinderformige Kammer (27) mit einem darin enthaltenen Zellenrad (28) mit mehreren durch Stege (29) getrennten Zellen (30), das uber eine vertikale Drehachse (31) drehbar unterhalb des Bodens (32) des Vorratsbehalters (20) angeordnet ist, wobei die Kammer (27) im Boden (32) des Vorratsbehalters (20) eine Einlassoffnung (33) zum Befullen der Zellen (30) und auf der Unterseite eine Auslassoffnung (34) zur Fordereinrichtung (17) besitzt, wobei das Zellenrad (28) mit der Drehachse (38) des Ruhrwerks (24) gekoppelt ist. Die Erfindung betrifft ferner eine Waschmaschine (1), umfassend einen Laugenbehalter (2) zur Aufnahme von Waschflussigkeit und eine Steuereinrichtung (7), mit einer Dosiereinrichtung (18), wie oben genannt, die ...",2007,
A Brief History of the Gathering of Fresh-water Pearls in the United States,"The gathering of pearls from the fresh-water shells of North America, although a matter of comparatively recent date among the present inhabitants, really goes back very far into the unrecorded past, and early attracted notice among the first European explorers. In the prehistoric period the mound-builders of the Mississippi Valley gathered immense quantities of these pearls, as is amply shown by the stores of them found on the"" hearths"" of a number of mounds, especially in Ohio, by the recent explorations of Prof. F. W. Putnam and Mr. W. K. Moorehead. By age, burial, and in some cases funeral or sacrificial fires, these pearls have lost their luster and beauty; but they were evidently highly prized by these ancient people and gathered by the hundred thousand. The finding of two bushels in a single series of mounds is an evidence of their abundance. . The first explorers who traveled among the Indian tribes speak frequently of the number and beauty of the pearls in possession of the natives. Especially marked are these accounts in connection with the great expedition of De Soto, from Florida through the present Gulf States to Mississippi, in 1540-41. Garcilasso de 181 Vega and other narrators give minute accounts of pearls as worn by the Indians; and from the accounts given by them to De Soto at various times,andas taken by the Spaniards from burial-places of native chieftains, it is quite evident that perhaps all of these referred to were not marine, but fresh-water pearls. De Soto's narratives, which undoubtedly referred to the latter, seem exaggerated, but the recent finds substantiate them. The process is described, moreover, of gathering the shells and opening them by heat, which was shown to De Soto, at his request, ]jy a friendly chief. In the same way several early English travelers, from New England to Florida, refer to the Indians as having pearls, undoubtedly from the fresh-water Uuionidre, No particular attention, however, was given to the subject until about forty years ago. The natives had been dispossessed, and the white race, occupied with other interests and necessities, took little note of the hosts of fresh-water shells inhabiting the streams and lakes, and did not suspect their power of producing pearls. In the rivers of Saxony and Bohemia, indeed, and those of Scotland and Ireland and the lakes of Finland, such pearls have long been known and valued, although Unio life is far less abundant there than in our great river systems of America; but not until the middle of the present century was a search begun Or any important discovery made.",2009,
Histologic Factors Associated With Need for Surgery in Patients With Pedunculated T1 Colorectal Carcinomas.,"BACKGROUND & AIMS
Most patients with pedunculated T1 colorectal tumors referred for surgery are not found to have lymph node metastases, and were therefore unnecessarily placed at risk for surgery-associated complications. We aimedÂ to identify histologic factors associated with need for surgery in patients with pedunculated T1 colorectal tumors.


METHODS
We performed a cohort-nested matched case-control study of 708 patients diagnosed with pedunculated T1 colorectal tumors at 13 hospitals in The Netherlands, from January 1, 2000 through December 31, 2014, followed for a median of 44 months (interquartile range, 20-80 months). We identified 37 patients (5.2%) who required surgery (due to lymph node, intramural, or distant metastases). These patients were matched with patients with pedunculated T1 colorectal tumors without a need for surgery (no metastases, controls, nÂ = 111). Blinded pathologists analyzed specimens from eachÂ tumor, stained with H&E. We evaluated associations between histologic factors and patient need for surgery using univariable conditional logistic regression analysis. We used multivariable least absolute shrinkage and selection operator (LASSO; an online version of the LASSO model is available at:Â http://t1crc.com/calculator/) regression to develop models for identification of patients with tumors requiring surgery, and tested the accuracy of our model by projecting our case-control data toward the entire cohort (708 patients). We compared our model with previously developed strategies to identify high-risk tumors: conventional model 1 (based onÂ poor differentiation, lymphovascular invasion, or Haggitt level 4) and conventional model 2 (based on poor differentiation, lymphovascular invasion, Haggitt level 4, or tumor budding).


RESULTS
We identified 5 histologic factors that differentiated cases from controls: lymphovascular invasion, Haggitt level 4 invasion, muscularis mucosae type B (incompletely or completely disrupted), poorly differentiated clusters and tumor budding, which identified patients who required surgery with an area under the curve (AUC) value of 0.83 (95% confidence interval, 0.76-0.90). When we used a clinically plausible predicted probability threshold of â‰¥4.0%, 67.5% (478 of 708) of patients were predicted to not need surgery. This threshold identified patients who required surgery with 83.8% sensitivity (95% confidence interval, 68.0%-93.8%) and 70.3% specificity (95% confidence interval, 60.9%-78.6%). Conventional models 1 and 2 identified patients who required surgery with lower AUC values (AUC, 0.67; 95% CI, 0.60-0.74; PÂ = .002 and AUC, 0.64; 95% CI, 0.58-0.70; P < .001, respectively) than our LASSO model. When we applied our LASSO model with a predicted probability threshold of â‰¥4.0%, the percentage of missed cases (tumors mistakenly assigned as low risk) was comparable (6Â of 478 [1.3%]) to that of conventional model 1 (4 of 307 [1.3%]) and conventional model 2 (3 of 244 [1.2%]). However, the percentage of patients referred for surgery based on our LASSO model was much lower (32.5%, nÂ = 230) than that for conventional model 1 (56.6%, nÂ = 401) or conventional modelÂ 2 (65.5%, nÂ = 464).


CONCLUSIONS
In a cohort-nested matched case-control study of 708 patients with pedunculated T1 colorectal carcinomas, we developed a modelÂ based on histologic features of tumors that identifies patients who require surgery (due to high risk of metastasis) withÂ greater accuracy than previous models. Our model might be used to identify patients most likely to benefit from adjuvant surgery.",2018,Gastroenterology
Estudos sobre a aplicaÃ§Ã£o de autoencoder para construÃ§Ã£o de inferÃªncias na indÃºstria quÃ­mica,"In the modern industry, processes are constantly being optimized to seeki safer, cleaner and more energy-efficient production. To this end, advanced monitoring and control systems have been gaining prominence in chemical factories and refineries. However, industrial processes face problems in the measurement of some variables, such as product quality and component concentration. The use of in-line analyzers or laboratory measurements does not allow direct control, due to the sampling time and uncertainty of the analyzer measurements. To circumvent this problem and finally generate frequent and reliable information, this work studies the autoencoder, a tool based on neural networks not yet applied on the development and maintenance of inferences. Some techniques of machine learning will be presented and used, as pretreatment of data following the training of a neural network of unsupervised learning through the compression and decompression of the input information, called autoencoder, produces a latent space with lower dimension concentrating the information winthin the data and therefore being capable of developing soft-sensors. The proposed methodology for the development of the sofsensors is to use the reduced space by the autoencoder to predict the desired variables o the system. The latent space of the autoencoder can be seen as a generalization of the principal components of the PCA methodology. Then, a comparison of the results obtained with PCA, the current standard and the autoencoder is made to evaluate the object of this work. The first step is the pre-processing of the data. Subsequently the data are separated into calibration and test sets using the k-rank methodology. Then the models are constructed through linear regression with methods (Ridge and Lasso-Lars) that perform the selection of variables, discarding unnecessary variables to the models, which will be validated using several evaluation metrics. This methodology is tested with two case studies. One with artificial data generated with known relation between its variables. And one with data from an Aspen simulation of a propene/propane separation unit. This unit has the objective of producing propene with purity of 99.6%, from a load of GLP. It is composed of three columns of distillation. In the first column, the heavy compounds are withdrawn from the bottom and the top stream goes to the second column which has the purpose of removing the ethane from the stream. Thus, the bottom stream of this column goes to a third column, which separates the propene from the propane. The useful information to help control the unit are: concentration of heavy at the top of the first column so that the amount of this impurity can be reduced; in the second column it is important to reduce propene that escapes along with ethane at the top of the column to increase the final production of the plant; and in the third column it is important to maintain the top current within the specification, whereby it is necessary to estimate the impurity of propane at the top of the column. The results show that at this point there is no clear superiority in the quality of the predictions when comparing to the ones of the PCA method for the case-studies and the proposed methodology.",2019,
Genomic selection for grain yield and quality traits in durum wheat,"The prediction accuracies of genomic selection depend on several factors, including the genetic architecture of target traits, the number of traits considered at a given time, and the statistical models. Here, we assessed the potential of single-trait (ST) and multi-trait (MT) genomic prediction models for durum wheat on yield and quality traits using a breeding panel (BP) of 170 varieties and advanced breeding lines, and a doubled-haploid (DH) population of 154 lines. The two populations were genotyped with the Infinium iSelect 90K SNP assay and phenotyped for various traits. Six ST-GS models (RR-BLUP, G-BLUP, BayesA, BayesB, Bayesian LASSO, and RKHS) and three MT prediction approaches (MT-BayesA, MT-Matrix, and MT-SI approaches which use economic selection index as a trait value) were applied for predicting yield, protein content, gluten index, and alveograph measures. The ST prediction accuracies ranged from 0.5 to 0.8 for the various traits and models and revealed comparable prediction accuracies for most of the traits in both populations, except BayesA and BayesB, which better predicted gluten index, tenacity, and strength in the DH population. The MT-GS models were more accurate than the ST-GS models only for grain yield in the BP. Using BP as a training set to predict the DH population resulted in poor predictions. Overall, all the six ST-GS models appear to be applicable for GS of yield and gluten strength traits in durum wheat, but we recommend the simple computational models RR-BLUP or G-BLUP for predicating single trait and MT-SI for predicting yield and protein simultaneously.",2018,Molecular Breeding
On Regression Methods for Virtual Metrology in Semiconductor Manufacturing,"Virtual metrology (VM) aims to predict metrology values using sensor data from production equipment and physical metrology values of preceding samples. VM is a promising technology for the semiconductor manufacturing industry as it can reduce the frequency of in-line metrology operations and provide supportive information for other operations such as fault detection, predictive maintenance and run-to-run control. The prediction models for VM can be from a large variety of linear and nonlinear regression methods and the selection of a proper regression method for a specific VM problem is not straightforward, especially when the candidate predictor set is of high dimension, correlated and noisy. Using process data from a benchmark semiconductor manufacturing process, this paper evaluates the performance of four typical regression methods for VM: multiple linear regression (MLR), least absolute shrinkage and selection operator (LASSO), neural networks (NN) and Gaussian process regression (GPR). It is observed that GPR performs the best among the four methods and that, remarkably, the performance of linear regression approaches that of GPR as the subset of selected input variables is increased. The observed competitiveness of high-dimensional linear regression models, which does not hold true in general, is explained in the context of extreme learning machines and functional link neural networks.",2014,
Removal of retained Foley catheter in bladder with novel use of ureteral catheter: lasso technique.,"Numerous and varied foreign bodies have been described in the lower urinary tract. Techniques previously used to remove these objects have included open and endoscopic removal. We present a novel endoscopic technique using a ureteral catheter as a lasso to remove a retained foreign body, in this case a retained Foley catheter.",2008,Urology
Bayesian Lasso Tobit regression,"In the present research, we have proposed a new approach for model selection in Tobit regression. The new technique uses Bayesian Lasso in Tobit regression (BLTR). It has many features that give optimum estimation and variable selection property. Specifically, we introduced a new hierarchal model. Then, a new Gibbs sampler is introduced. We also extend the new approach by adding the ridge parameter inside the variance covariance matrix to avoid the singularity in the case of multicollinearity or in case the number of predictors greater than the number of observations. A comparison was made with other previous techniques applying the simulation examples and real data. It is worth mentioning, that the obtained results were promising and encouraging, giving better results compared to the previous methods.",2019,
"Chantal Meyer-Plantureux, AntisÃ©mitisme et homophobie. ClichÃ©s en scÃ¨ne et Ã  lâ€™Ã©cran, xix-xx siÃ¨cles","Nella Francia della Terza Repubblica (e non solo), lâ€™Ebreo e lâ€™Omosessuale sono figure turpi, spregevoli, condannate e ripudiate, i capri espiatori di una societa scalfita da una profonda crisi dellâ€™identita maschile, fattasi estrema dopo la sconfitta del 1870 â€“ dramma nazionale, prova della debolezza di un paese e del collasso della razza. Da questa ferita, lâ€™omofobia erompe come lo strumento sovrano per ristabilire lâ€™ordine e le regole: maschio e femmina, francese e straniero, normale e ano...",2019,
Genetic biomarkers associated with response to palliative radiotherapy in patients with painful bone metastases.,"BACKGROUND
Palliative radiotherapy (RT) is effective in patients with painful bone metastases. Genetic factors may identify subgroup of patients who responded to RT. To identify DNA biomarkers associated with response to palliative RT.


METHODS
Patients who received a single 8 Gy dose of RT for painful bone metastases were categorised into responders (n=36), non-responders (NR) (n=71). Saliva samples were sequenced to identify single-nucleotide variants (SNVs) in genes with known disease-causing variants from inflammation, radiation response, and DNA damage pathways. In univariate analysis, Cochran-Armitage trend tests were used to identify SNVs that associated with pain response (P<0.005), and the Penalized LASSO method with minimum Bayesian Information Criterion was used to identify multi-SNVs that jointly predict pain response to RT. The corresponding estimated effect of the multi-SNVs were used to drive the prognostic score for each patient. Based on it, patients were divided into 3 equal size risk groups.


RESULTS
Forty-one significant variants were identified in univariate analysis. Multivariable analysis selected 14 variants to generate prognostic scores, adjusting for gender and primary cancer site. Eighty-nine percent of patients in the high prognostic group responded to palliative radiation therapy (P=0.0001). Estimated effect sizes of the variants ranged from 0.108-2.551. The most statistically significant variant was a deletion at position 111992032 in the ataxin gene ATXN2 (P=0.0001). Five variants were non-synonymous, including AOAH rs7986 (P=0.0017), ZAN rs539445 (P=0.00078) and rs542137 (P=0.00078), RAG1 rs3740955 (P=0.0014), and GBGT1 rs75765336 (P=0.0026).


CONCLUSIONS
SNVs involved in mechanisms including DNA repair, inflammation, cellular adhesion, and cell signalling have significant associations with radiation response. SNVs with predictive power may stratify patient populations according to likelihood of responding to treatment, therefore enabling more efficient identification of beneficial strategies for pain management and improved resource utilisation.",2017,Annals of palliative medicine
Integrated water resources management for vulnerable groups in Burkina Faso : three case studies,"This paper describes the situation of two valleys of Burkina Faso dominated by agriculture activities, with regards to sharing of natural resources (land and water) for rural set up. It further analyses the process to support the creation of water committees and to prepare scenarios for a more productive and equitable use of scarce resources, leading to poverty alleviation, and risk avoidance. Conflict prevention objectives, through negotiations between stakeholder groups on water and land use rights are also considered. Case studies: Vallee du Kou (Province du HOUET). Surface basin: 1.823 sq. km; Major city: Bobo-Dioulasso (450.000 inhabitants.) In the basin of the ""Vallee du Kou,"" a variety of water uses range from urban drinking water to industrial water use and irrigation. Both groundwater and river water resources are heavily exploited. Extraction is poorly regulated as is pollution control. Conflicts are rising between several agricultural water user groups, tapping into the River Kou and main irrigation channels, without consideration for downstream users. Vallee des lacs de Tamasogo, Dem et Sian (Province de SANMATENGA). Surface basin: approx. 3.000 sq. km; Major city: Kaya - 45.000 inhabitants. This site is located in the sahelian part of the country, rural income and food security very much depends on the good management of soil and water resources. Important water and soil conservation measures at field level have yielded a clear success in improving and stabilizing yields in rainfed agriculture. It has also been shown that widespread anti-erosion measures help to regenerate forest cover and raise groundwater tables. Growing demand for drinking water from a nearby city (Kaya) will further increase pressure on these surface water resources, especially in the dry season. The results are discussed considering capacity building improvement on: - Operational water management institutions at the sub-basin level. - Negotiation between stakeholder groups on water and land use rights, including for vulnerable groups. - Soil and fertility management integrated in the water management plans. (Resume d'auteur)",2004,
QuestionÃ¡rio De PercepÃ§Ã£o Dos Pais - Q.P.P.,"RESUMO - Com base na literatura psicologica e sociologica pertinente, foi construido um instrumento de 43 itens (QPP) para avaliar a percepcao que os filhos possuem de seus pais. A validacao fatorial foi efetuada com uma amostra de 574 estudantes de 2? grau e superior. Quatro fatores apareceram na figura do pai: companheiro amigo, disciplina punitiva, disciplina lassa, centralizacao no filho; quatro fatores surgiram tambem na figura da mae: intimidade amiga, superprotecao, controle lasso, punicao. Esses quatro fatores em ambas as figuras parentais se agrupam em dois fatores de segunda ordem: amore disciplina. Todos eles possuem indices satisfatorios de precisao. Sao apresentados igualmente o instrumento e o seu modo de utilizacao.",2012,Psicologia: Teoria E Pesquisa
Stability Robustness Bounds of Stochastic Linear Systems with Delayed Perturbations,"This note considers stability robustness bounds on a classof stochastic linear systems with delayed perturbations.Using the stochastic Lyapunov stability theory,severalsufficient conditions for delay-independent stochasticasymptotic stability are obtained.It is shown that if theperturbation terms satisfy some conditions,then the sto-chastic systems have the robustness.",1998,
Prediction of Disease-free Survival in Hepatocellular Carcinoma by Gene Expression Profiling,"BackgroundProgression of hepatocellular carcinoma (HCC) often leads to vascular invasion and intrahepatic metastasis, which correlate with recurrence after surgical treatment and poor prognosis. The molecular prognostic model that could be applied to the HCC patient population in general is needed for effectively predicting disease-free survival (DFS).MethodsA cohort of 286 HCC patients from South Korea and a second cohort of 83 patients from Hong Kong, China, were used as training and validation sets, respectively. RNA extracted from both tumor and adjacent nontumor liver tissues was subjected to microarray gene expression profiling. DFS was the primary clinical end point. Gradient lasso algorithm was used to build prognostic signatures.ResultsHigh-quality gene expression profiles were obtained from 240 tumors and 193 adjacent nontumor liver tissues from the training set. Sets of 30 and 23 gene-based DFS signatures were developed from gene expression profiles of tumor and adjacent nontumor liver, respectively. DFS gene signature of tumor was significantly associated with DFS in an independent validation set of 83 tumors (PÂ =Â 0.002). DFS gene signature of nontumor liver was not significantly associated with DFS in the validation set (PÂ =Â 0.827). Multivariate analysis in the validation set showed that DFS gene signature of tumor was an independent predictor of shorter DFS (PÂ =Â 0.018).ConclusionsWe developed and validated survival gene signatures of tumor to successfully predict the length of DFS in HCC patients after surgical resection.",2013,Annals of Surgical Oncology
Genomic evaluation using machine learning algorithms in the Spanish Holstein population,"The aim of this study was to validate the recorded data and genome-assisted evaluation models for the Spanish Holstein population as an initial step towards the first official national genomic evaluation. Preliminary national genomic evaluation for production and type traits in Holstein Friesian bulls in Spain were tested using both the Spanish reference population (ESP), composed by 2,115 progeny tested bulls, and the Eurogenomics population (EG), composed by 22,247 progeny tested bulls. Four different traits currently included in the Spanish genetic evaluation were used: milk yield (MY), fat yield (FY), protein yield (PY), and udder depth (UD). Two different genomic evaluation methodologies, Bayesian-Lasso (B-Lasso) and a machine learning algorithm: Random-Boosting (R-Boost) were compared to traditional pedigree index (PI). The predictive ability was measured in terms of correlations, mean square error (MSE) and regression coefficients between progeny proofs and direct genomic values (DGV) in the validation set. Genomic evaluations were more accurate than the traditional pedigree index. The increment in Pearson correlation between observed and predicted response depended on the trait, but the EG population provided greater accuracy than ESP at predicting future progeny performance, as expected. The methodologies implemented showed similar results. B-Lasso showed higher Pearson correlations for MY (0.590 vs 0.572), FY (0.655vs 0.649) and PY (0.583vs 0.545), whereas R-Boost showed larger values for UD (0.584 vs 0.562). Genomic predictions from R-Boost resulted in 4.03% lower predictive mean square errors than B-Lasso. R-Boost showed smaller MSE for MY, PY and UD, whereas B-Lasso was preferred for FY in terms of MSE. R-Boost showed regression coefficients more close to 1 than B-Lasso. The response to different methodologies of genomic evaluation was within the range of values expected for a population of a similar size. The methods that presented higher Pearson correlation also showed larger MSE. This should be considered in model comparison study deciding the method with better predictive ability.",2012,Interbull Bulletin
"Lasso, fractional norm and structured sparse estimation using a Hadamard product parametrization","Using a multiplicative reparametrization, it is shown that a subclass of Lq penalties with q less than or equal to one can be expressed as sums of L2 penalties. It follows that the lasso and other norm-penalized regression estimates may be obtained using a very simple and intuitive alternating ridge regression algorithm. As compared to a similarly intuitive EM algorithm for Lq optimization, the proposed algorithm avoids some numerical instability issues and is also competitive in terms of speed. Furthermore, the proposed algorithm can be extended to accommodate sparse high-dimensional scenarios, generalized linear models, and can be used to create structured sparsity via penalties derived from covariance models for the parameters. Such model-based penalties may be useful for sparse estimation of spatially or temporally structured parameters.",2017,Comput. Stat. Data Anal.
Contact Investigations of Granular Mechanical Media in a Tumbling Sorting Machine,"Chapter 1 briefly introduced some contact problems in granular media with some computational procedures used in sequential and parallel computations. 
 
In Chapter 2, a general description of the molecular dynamic problems and clarification of the basics of the granular media are presented. Some of the frequently-used algorithms and models, e.g. Discrete Element Method (DEM) and penalty method of the spring-dashpot model are involved in this chapter.Some basic techniques for speeding up simulations of particulate systems by using some proper sorting algorithms and neighbor list computations, e.g. the Verlet approach and the linked linear list method, are used and compared. Different integration approaches was also discussed. It was found that Verlet integrators are efficient, accurate and appropriate to solve the equations of motion of the granular systems. 
 
In Chapter 3, the spatial decomposition method is basically used in building the parallel programing codes. This method allows scalability and good results especially when load balancing is done. Needless to say that the important factor which affects the success of the numerical procedure is how much one has access to a computer system which is powerful enough to handle the problem of interest. In this chapter, existing sequential algorithms are extended and modified in such a way that modern high performance computers can be utilized for their parallel evaluation. The library functions of the Parallel Virtual Machine (PVM) are used to handle communication between processors in a distributed memory environment. This chapter also underlined the relation between the speedup, which is the usually used measure of the program scalability, and the size of the system. It was found that the performance improves with increasing the number of particles. The reason is due to the communication and data flow which become more efficient between the different tasks as the number of particles increases and therefore, the communication cost will directly decrease and accordingly, the computational speedup will increase. In some cases, a superlinear behavior is recorded when using different computers with many processors due to the individual cache memory effect of each of the machines used in the network. 
 
As a practical industrial application of granular studies, particle screening, which is considered as an essential technology of particle separation in many industrial fields, is selected to be investigated in Chapter 4. This chapter presents a numerical model for studying the particle screening process using the discrete element method that considers the motion of each particle individually. Dynamical quantities like particle positions, velocities and orientations are tracked at each time step of the simulation. The particular problem of interest is the separation of round shaped particles of different sizes using a rotating tumbling vertical cylinder while the particulate material is continuously fed into its interior. This rotating cylinder can be designed as a uniform or stepped multi level oblique vertical vessel and is considered as a big reservoir for the mixture of particulate material. The finer particles usually fall through the sieve openings while the oversized particles are rebounded and ejected through outlets located around the machine body. Particle-particle and particle-boundary collisions will appear under the tumbling motion of the rotating structure. Herein, the penalty method, which employs spring-damper models, is applied to calculate the normal and frictional forces. 
 
For specific geometrical and contact parameters particle transportation, sifting rates and machine efficiency are recorded. Particles are simulated in uniform and stepped models of tumbling cylinders. For both continuous screening and batch sieving, it was found that the segregation process is very sensitive to the rotational speed of the machine. Furthermore, the particle feeding rates, inclination angles and shaft eccentricity have a great influence on the machine efficiency. Small angles between 0.5 degree to 1 degree and eccentricities between 25 to 50mm are recommended. The sieve roughness has also an influence on the number of particles that stay or leave the machine. An optimal value of relatively medium friction coefficient is recommended. Moreover, the barrel oscillation has a significant influence on the sorting process. Oscillatory motion of the barrel shows better performance relative to the non-rotating or even continuous-rotating motion. 
 
Finally, the thesis ends in Chapter 5 with a general summary of the presented work and a short overview of the proposed work in the future. 
Kapitel 1 gibt eine kurze Einfuhrung in die in granularen Medien auftretenden Kontaktprobleme zusammen mit Erlauterungen zu einigen numerischen Algorithmen die in der sequentiellen und parallelen Simulation Verwendung finden. 
 
In Kapitel 2 wird eine allgemeine Beschreibung der Probleme der Molekulardynamik gegeben und es werden die Grundeigenschaften granularer Medien erlautert. Einige der am haufigsten verwendeten Algorithmen und Modelle, z.B. die Diskrete Element Methode (DEM) und die Penalty-Methode mit Feder-Dampfersystemen, werden in diesem Kapitel einfuhrt. Einige Ansatze zur Beschleunigung der Simulation von Partikelsystemen durch die Sortierung mit geeigneten Sortierverfahren und die Nachbarschaftssuche mit Listen, z.B. der Verlet-Ansatz und verkettete lineare Listen werden verwendet und verglichen. Verschiedene Integrationsverfahren werden ebenfalls erlautert. Es wird beobachtet, dass Verlet-Integratoren effizient und genau sind und damit geeignet sind zur Integration der Bewegungsgleichungen granularer Systeme. 
 
In Kapitel 3 wird die raumliche Gebietsunterteilung zur Erzeugung des parallelen Codes verwendet. Diese Methode gewahrleistet Skalierbarkeit und gute Resultate besonders in Verbindung mit Lastverteilung. Eine Voraussetzung fur den Erfolg numerischer Berechnungen ist der Zugang zu Computersystemen, die machtig genug sind, um das zu untersuchende Problem zu berechnen. In diesem Kapitel werden bestehende sequentielle Algorithmen erweitert und verandert, um sie an moderne Hochleistungsrechner anzupassen. Die Bibliotheksfunktionen der Parallel Virtual Machine (PVM) werden fur die Kommunikation zwischen Prozessoren in einem System mit verteiltem Speicher verwendet. Dieses Kapitel verdeutlicht auch den Zusammenhang zwischen dem Speedup, dem haufig verwendeten Messwert fur Programmskalierbarkeit und der grose des Systems. Es wird beobachtet, dass die Leistung der Simulation sich mit steigender Partikelzahl verbessert. Der Grund liegt im Kommunikations- und Datenfluss, der bei steigender Partikelzahl effizienter wird. In einigen Fallen wurde superlineares Speedupverhalten beobachtet, was auf Cache-Effekte der einzelnen Prozessoren zuruckzufuhren sein konnte. 
 
Als praktische, industrielle Anwendung granularer Untersuchungen wurde das Partikelsieben in Kapitel 4 betrachtet, welches eine essentielle Technologie zur Partikeltrennung in vielen industriellen Bereichen ist. Dieses Kapitel stellt ein numerisches Modell zur Untersuchung des Siebprozesses unter Verwendung der Diskrete Element Method vor, bei dem die Bewegung der einzelnen Partikel getrennt simuliert werden. Dynamische Parameter wie Partikelpositionen, Geschwindigkeiten und Orientierungen werden in jedem Simulationszeitschritt verfolgt. Das betrachtete Problem liegt in der Trennung runder Partikel verschiedener Grosen mit Hilfe eines taumelnden vertikalen Zylinders, in den das Siebmaterial stetig zugefuhrt wird. Dieser Zylinder kann als glatter oder abgesetzter, mehrstufiger vertikaler Behalter beschaffen sein und wird als groses Reservoir fur das Siebmaterial betrachtet. Die kleineren Partikel fallen normalerweise durch die Sieboffnungen, wohingegen die groseren Partikel zuruckprallen und an konzentrischen Auslassoffnungen an der Zylinderwand austreten. Wahrend des Siebvorgangs treten sowohl Partikel-Partikel-Wechselwirkungen als auch Partikel-Wand-Wechselwirkungen auf. Hierbei wird ein Feder-Dampfer Penalty-Ansatz zur Berechnung der normalen Wechselwirkungskrafte und der Reibkrafte verwendet. 
 
Fur bestimmte Geometriekonstellationen und Kontaktparameter wird der Partikelfluss, die Siebgute und die Maschineneffizienz aufgezeichnet. Es werden Siebvorgange in glatten und gestuften Taumelzylindern untersucht. Sowohl fur kontinuierliches Sieben als auch fur das Sieben fester Chargengrosen ergibt sich eine ausgepragte Abhangigkeit des Siebvorgangs von der Rotationsgeschwindigkeit der Trommel. Daruberhinaus haben die Zufuhrrate, der Neigungswinkel und die Exzentrizitat einen grosen Einflus auf die Effizienz der Maschine. Kleine Winkel zwischen 0.5 Grad und 1 Grad und Exzentrizitaten zwischen 25 und 50 mm sind zu empfehlen. Die Siebrauheit hat ebenfalls einen Einfluss auf die Anzahl der Partikel, die in der Siebtrommel verbleiben oder diese verlassen. Als optimaler Wert wird ein relativ geringer Reibwert vorgeschlagen. Desweiteren haben die Schwingungen der Trommel einen signifikanten Einfluss auf den Siebprozess. Schwingende Bewegungen der Siebtrommel fuhren zu besseren Ergebnissen als rotationsfreie Bewegungen oder Bewegungen mit kontinuierlicher Rotation. 
 
Die Arbeit endet in Kapitel 5 mit einer Zusammenfassung der vorgestellten Betrachtungen und einem kurzen Uberblick uber zukunftige Erweiterungen.",2007,
The network structure of paranoia in the general population,"PurposeBebbington and colleaguesâ€™ influential study on â€˜the structure of paranoia in the general populationâ€™ used data from the British National Psychiatric Morbidity Survey and latent variable analysis methods. Network analysis is a relatively new approach in psychopathology research that considers mental disorders to be emergent phenomena from causal interactions among symptoms. This study re-analysed the British National Psychiatric Morbidity Survey data using network analysis to examine the network structure of paranoia in the general population.MethodsWe used a Graphical Least Absolute Shrinkage and Selection Operator (glasso) method that estimated an optimal network structure based on the Extended Bayesian Information Criterion. Network sub-communities were identified by spinglass and EGA algorithms and centrality metrics were calculated per item and per sub-community.ResultsWe replicated Bebbingtonâ€™s four component structure of paranoia, identifying â€˜interpersonal sensitivitiesâ€™, â€˜mistrustâ€™, â€˜ideas of referenceâ€™ and â€˜ideas of persecutionâ€™ as sub-communities in the network. In line with previous experimental findings, worry was the most central item in the network. However, â€˜mistrustâ€™ and â€˜ideas of referenceâ€™ were the most central sub-communities.ConclusionsRather than a strict hierarchy, we argue that the structure of paranoia is best thought of as a heterarchy, where the activation of high-centrality nodes and communities is most likely to lead to steady state paranoia. We also highlight the novel methodological approach used by this study: namely, using network analysis to re-examine a population structure of psychopathology previously identified by latent variable approaches.",2018,Social Psychiatry and Psychiatric Epidemiology
Editorial,"In the past 10 years, the development of statistical methods has been greatly shaped by the demand of analyzing high-dimensional data generated in the fields of biological and medical sciences. Variable selection is a fundamental task in analyzing modern high-dimensional data. Many papers have been devoted to this important topic. Methods such as LASSO and SCAD are now household names in the literature. This special issue comprises five invited contributions from some leading experts in this area, with emphasis on solving interesting application problems. BÃ¼hlmann, RÃ¼timann and Kalisch provided a very nice review article on two widely applicable variable selection techniques: stability selection and aggregated multiple p-values. Both techniques are based on sub-sampling and aim to control false positive selections in observational data analysis. Lu, Zhang and Zeng presented a new variable selection method that is designed to identify important variables involved in optimal treatment decision-making. Their method is based on a penalized regression framework and can be easily implemented by existing software packages. The new method is illustrated with an application to an AIDS clinical trial. Jiang, Huang and Zhang studied a new cross-validated area under the ROC curve (CV-AUC) criterion for tuning parameter selection for sparely penalized logistic regression. The CV-AUC criterion is specifically designed for optimizing the classification performance for binary outcome data. It is shown that CV-AUC outperforms other popular competitors such as AIC, BIC or E-BIC. CV-AUC is used to select genes related to cancer based on microarray data. The survey paper by Zhang and Lin focuses on six important properties for high-dimension-lowsample-size classification problems: predictability, consistency, generality, stochastic stability, robustness and interpretability/sparsity. The authors reviewed several popular classifiers and compared their performance on simulated and real data. Li and Tibshirani proposed a new method for the identification of features that are associated with an outcome variable in RNA-Seq data. Their method is non-parametric and hence more robust than those parametric competitors that are based on Poisson or negative-binomial models. The new method is general enough to be applied to data with quantitative, survival, two-class or multipleclass outcomes. We hope that the readers find this special issue interesting and inspiring. Finally, we want to thank all authors and referees for their enthusiastic support.",2013,Statistical Methods in Medical Research
Loihi: A Neuromorphic Manycore Processor with On-Chip Learning,"Loihi is a 60-mm2 chip fabricated in Intels 14-nm process that advances the state-of-the-art modeling of spiking neural networks in silicon. It integrates a wide range of novel features for the field, such as hierarchical connectivity, dendritic compartments, synaptic delays, and, most importantly, programmable synaptic learning rules. Running a spiking convolutional form of the Locally Competitive Algorithm, Loihi can solve LASSO optimization problems with over three orders of magnitude superior energy-delay-product compared to conventional solvers running on a CPU iso-process/voltage/area. This provides an unambiguous example of spike-based computation, outperforming all known conventional solutions.",2018,IEEE Micro
Penalized Weighted Least Squares for Outlier Detection and Robust Regression,"To conduct regression analysis for data contaminated with outliers, many approaches have been proposed for simultaneous outlier detection and robust regression, so is the approach proposed in this manuscript. This new approach is called ""penalized weighted least squares"" (PWLS). By assigning each observation an individual weight and incorporating a lasso-type penalty on the log-transformation of the weight vector, the PWLS is able to perform outlier detection and robust regression simultaneously. A Bayesian point-of-view of the PWLS is provided, and it is showed that the PWLS can be seen as an example of M-estimation. Two methods are developed for selecting the tuning parameter in the PWLS. The performance of the PWLS is demonstrated via simulations and real applications.",2016,arXiv: Methodology
1460-P: Predicting Atherosclerotic Cardiovascular Disease (ASCVD) Risk in Veterans with Diabetes,"Estimating ASCVD risk in patients with diabetes could guide intensity of risk factor treatment, but existing risk calculators (2013 ACC/AHA ASCVD pooled cohort equations [PCE] and RECODe risk equations [RECODe]) have not been evaluated in a contemporary American population with diabetes. Using validated phenotyping algorithms, we evaluated prediction models for the development of a composite â€œhardâ€ ASCVD outcome (non-fatal myocardial infarction, non-fatal stroke, cardiovascular death) over 5 years in 184,823 diabetic U.S. Veterans without baseline ASCVD receiving primary care in the VA 2002-2007 (2.4% women, 19.5% black, mean age 61 years, 9851 ASCVD events). We compared discrimination using the C-statistic and calibration using the Greenwood-Nam-Dâ€™Agostino test (GND) of the PCE variables (sex, age, race, cholesterol, blood pressure [BP], smoking status, BP medications, statin treatment, and aspirin), RECODe, and a series of models using PCE variables with VA sample-specific coefficients. Models with PCE variables and VA-specific coefficients had better discrimination (C=0.642) than the PCE (C=0.582) or RECODe (C=0.633). Successive addition of hemoglobin A1c, estimated glomerular filtration rate, diabetes medications, and statin therapy improved the model (full model, C=0.669), with only minimal enhancement by semisupervised variable selection using LASSO (C=0.672). The C-statistic of the full model was similar in those Conclusion: Health system-specific tailoring of prediction equations provides improved discrimination and calibration compared to existing models. This risk predictor could be embedded in the electronic health record and used to guide intensification of treatment aimed to improve ASCVD outcomes. Disclosure S. Raghavan: None. Y. Ho: None. D. Posner: None. J.L. Vassy: None. D.R. Gagnon: None. L.S. Phillips: Advisory Panel; Self; Janssen Pharmaceuticals, Inc. Research Support; Self; AbbVie Inc., GlaxoSmithKline plc., Kowa Pharmaceutical Europe Co. Ltd., Novartis Pharmaceuticals Corporation, Novo Nordisk Inc., Pfizer Inc. Stock/Shareholder; Self; Diasyst Inc. Other Relationship; Self; Diasyst Inc., Janssen Pharmaceuticals, Inc. P.W. Wilson: None. Funding U.S. Department of Veterans Affairs; American Heart Association",2019,Diabetes
Ancient Greek Ethnicities: towards a Reassessment,"This paper offers a response to Kostas Vlassopoulosâ€™ â€˜Ethnicity and Greek History: Re-examiningour Assumptionsâ€™, especially his comments about the unit of analysis that we should adopt in studying ancient ethnicity, the relationship between ethnicity and nationalism, and the limitations of testing evidence against definitional models. It also considers the role that religious ritual played in professions of ethnicity as well as the heuristic utility in distinguishing between â€˜aggregativeâ€™ and â€˜oppositionalâ€™ identities or between â€˜ethnicâ€™ or â€˜culturalâ€™ definitions of Hellenic identity. Finally, it questions prevailing opinions about the relationship between ethnicity and the ethnic group",2015,Bulletin of The Institute of Classical Studies
A resilient domain decomposition polynomial chaos solver for uncertain elliptic PDEs,"Abstract A resilient method is developed for the solution of uncertain elliptic PDEs on extreme scale platforms. The method is based on a hybrid domain decomposition, polynomial chaos (PC) framework that is designed to address soft faults. Specifically, parallel and independent solves of multiple deterministic local problems are used to define PC representations of local Dirichlet boundary-to-boundary maps that are used to reconstruct the global solution. A LAD-lasso type regression is developed for this purpose. The performance of the resulting algorithm is tested on an elliptic equation with an uncertain diffusivity field. Different test cases are considered in order to analyze the impacts of correlation structure of the uncertain diffusivity field, the stochastic resolution, as well as the probability of soft faults. In particular, the computations demonstrate that, provided sufficiently many samples are generated, the method effectively overcomes the occurrence of soft faults.",2017,Comput. Phys. Commun.
Ecojustice in science education: leaving the classroom,"Eduardo Dopico and Eva Garcia-VÃ¡zquezâ€™s article enriched the ecojustice literature with an interesting metaphor of leaving the classroom, which I argue for here. Glasson and Boggs help to highlight the challenges and fortitude of working ecojustice perspectives in science education and the ways that a dialogical conversation addresses the world at large rather than focusing narrowly and exclusively on science education. Considering the metaphor of â€˜leaving the classroomâ€™ I want to explore the tensions that can be experienced by science educators who do research focused on ecosocial justice. While it is not a new idea to suggest that there are gatekeepers in science education who try to maintain what counts in terms of impact in the classroom and what counts or not for the purposes of doing good work in science education, I anticipate highlighting the tensions that ecojustice educators may experience and why they can and should persevere with the incisive work that they are doing to conserve the prospects of future generations. Ecojustice no longer belongs constrained under the confines of environmental sciences or environmental education in science education. It is a separate and distinct field of study that should be generally accepted for the ways it brings clarity and conversation to ideas, curriculum studies, and thick descriptions of how people engage in eco-justice and ethics.",2011,Cultural Studies of Science Education
PrÃ©fÃ©rence face au risque et difficultÃ©s financiÃ¨res des mÃ©nages les plus pauvres,"[fre] Une meilleure comprehension des facteurs influencant les difficultes de paiement eprouvees par les menages est une question economique importante en raison de la prevalence et de lâ€™impact de ces difficultes. Lâ€™objectif de lâ€™article est de determiner si les preferences des individus face au risque modifient leurs probabilites de faire face a des difficultes de paiement. Nous analysons, dans un premier temps, les mecanismes par lesquels la transmission entre lâ€™attitude face au risque et les difficultes financieres sâ€™operent. Nous partons du constat que la richesse future dâ€™un menage est aleatoire et effectuons le lien entre la dispersion de sa distribution et la probabilite de defaut de paiement. Nous montrons alors comment des decisions (assurance, prevention, gestion de portefeuille et epargne) influencees par lâ€™attitude face au risque peuvent reduire cette probabilite. Dans un second temps, nous verifions empiriquement lâ€™influence de lâ€™attitude face au risque sur les difficultes de paiements. Les difficultes financieres etant plus frequentes chez les individus les plus defavorises economiquement, notre travail se concentre sur les menages qui vivent en dessous du seuil de pauvrete (defini comme 60 % du niveau de vie median de la population). A partir de lâ€™enquete Patrimoine 2010 et sur base des choix de loteries proposes par Barsky et al. (1997), nous classons les menages selon leurs preferences face au risque. A lâ€™aide dâ€™un modele probit, nous montrons lâ€™effet significatif de lâ€™attitude vis-a-vis du risque, de lâ€™Ã¢ge, de lâ€™education, de la situation familiale et des anticipations de variabilite future du revenu sur la probabilite quâ€™un menage pauvre connaisse ou ait connu des difficultes financieres. Ainsi nous mettons en evidence le fait que les menages qui ont une aversion relative au risque plus prononcee sont . moins susceptibles de faire face a ces difficultes.",2014,Economie Et Statistique
