title,abstract,year,journal
The LocaLisa system as the key to shortening the procedure duration and fluoroscopy time during ablation of atrial fibrillation.,"BACKGROUND
Ablation of atrial fibrillation (AF) can be difficult and time-consuming. Systems facilitating catheter navigation may be helpful.


AIM
To compare the efficacy of the LocaLisa system with the conventional mapping/ablation approach to radiofrequency (RF) ablation of AF.


METHODS
Group 1, consisting of 64 patients (48 male; aged 51.5+/-10.6 years), underwent segmental isolation of the pulmonary veins with the Lasso catheter and the LocaLisa system. Group 2, consisting of 64 patients (44 male, aged 51.4+/-11.0 years), had RF ablation guided by means of a conventional fluoroscopy-based approach. Clinical and procedural data were analysed.


RESULTS
Nine patients from group 1 and three patients from group 2 had persistent AF. In group 1 the mean number of isolated veins was 3.98+/-0.96, while in group 2 - 4.0+/-0.95 (NS). In group 1 cavotricuspid isthmus lines were created in four patients and lines in the roof of the left atrium in two patients. One patient needed slow pathway ablation. In group 2 six patients had ablation of the cavotricuspid isthmus and a line was created at the roof of the left atrium in one patient. Two patients had ectopic activity ablated in the crista terminalis. Procedure times were 131.6+/-40.3 and 170.0+/-56.5 min (p <0.0001) and fluoroscopy times were 16.93+/-9.7 and 35.66+/-12.7 min (p <0.0001) for groups 1 and 2, respectively. Long-term efficacy of RF ablation was similar in both groups (for example, complete success was achieved in 59% of patients using LocaLisa and 50% without using this system, NS).


CONCLUSIONS
The LocaLisa navigation system makes it possible to shorten both the duration of the procedure and the total fluoroscopy time during ablation of AF.",2008,Kardiologia polska
Estimation of an oblique structure via penalized likelihood factor analysis,"The problem of sparse estimation via a lasso-type penalized likelihood procedure in a factor analysis model is considered. Typically, model estimation assumes that the common factors are orthogonal (i.e., uncorrelated). However, if the common factors are correlated, the lasso-type penalization method based on the orthogonal model frequently estimates an erroneous model. To overcome this problem, factor correlations are incorporated into the model. Together with parameters in the orthogonal model, these correlations are estimated by a maximum penalized likelihood procedure. Entire solutions are computed by the EM algorithm with a coordinate descent, enabling the application of a wide variety of convex and nonconvex penalties. The proposed method is applicable even when the number of variables exceeds that of observations. The effectiveness of the proposed strategy is evaluated by Monte Carlo simulations, and its utility is demonstrated through real data analysis.",2014,Comput. Stat. Data Anal.
The attractors for 2nd-order stochastic delay lattice systems,This paper deals with the long-time dynamical behavior of a classof 2nd-order stochastic delay lattice systems. It is shown under thedissipative and sublinear growth conditions that such a systempossesses a compact global random attractor within the set oftempered random bounded sets. A numerical example is given toillustrate the obtained theoretical result.,2016,Discrete and Continuous Dynamical Systems
Artificial intelligence models to stratify cardiovascular risk in incident hemodialysis patients,"End stage renal disease condition increases the risk of cardiovascular disease. The mortality rates among hemodialysis patients are 20% higher than the general population, thus in recent years the preservation of the cardiovascular system has become a major point of focus for nephrology care in patients. Cardiovascular events jeopardize the life of a dialysis patient and must therefore be prevented. The aim of this study is to develop forecast models that can predict the cardiovascular outcome of incident hemodialysis (HD) patients. Data relating to the treatment methods and the physiological condition of patients was collected during the first 18months of renal replacement therapy and then used to predict the insurgence of cardiovascular events within a 6-month time window. Information regarding 4246 incident hemodialysis patients was collected. A Lasso logistic regression model and a random forest model were developed and used for predictive comparison. Every forecast model was tested on 20% of the data and a 5-fold cross validation approach was used to validate the random forest model. Random forest showed higher performance with AUC of the ROC curve and sensitivity higher than 70% in both the temporal windows models, proving that random forests are able to exploit non-linear patterns retrieved in the feature space. Out of bag estimates of variable importance and regression coefficients were used to gain insight into the models implemented. We found out that malnutrition and an inflammatory condition strongly influence cardiovascular outcome in incident HD patients. Indeed the most important variables in the model were blood test variables such as the total protein content, percentage value of albumin, total protein content, creatinine and C reactive protein. Age of patients and weight loss in the first six months of renal replacement therapy were also highly involved in the prediction. A greater understanding of the mechanisms involved in the insurgence of cardiovascular events in dialysis patients can ensure physicians to intervene in the appropriate manner when a high-risk cardiovascular condition is identified.",2013,Expert Syst. Appl.
"Acute Urinary Retention among Adult Men at Bobo-Dioulasso University Teaching Hospital: Epidemiology, Aetiologies and Initial Management","We conducted a cross-sectional study 
between February 1st, 2012 and September 30, 2012 at Bobo-Dioulasso University 
Teaching hospital. The target population was all patients seen at the 
emergency services for acute urinary retention. Among the 155 patients 
admitted for urological emergencies, 104 (67.1%) had acute urinary retention. 
The average age of patients was 65 years, ranging from 23 to 89 years and the 
majority was more than 60 years old (77.8%) and lived in rural areas (64.4%). 
Prostate tumor pathology and urethral stricture were the most frequent 
diagnosis, and the renal function was impaired in 33.7% of cases. 
Urethrovesical drainage, cystocatheterism, and suprapubic cystostomy were the 
treatment approach in 56.0%, 28.0% and 15.2% of the cases. Acute urinary 
retention is the most common urological emergency and many complications are 
associated with urethrovesical sounding. These complications should therefore 
be prevented by improving acute urinary care.",2015,Open Journal of Urology
Estimating net efficiency of a survey trawl for flatfishes,"Net efficiency, or the proportion of fish within the path of a trawl net that are captured, of the 83-112 Eastern bottom trawl was estimated for four flatfish and one roundfish species encountered on the stock assessment surveys of the eastern Bering Sea. Net efficiency data was collected by repeatedly towing with an experimental trawl consisting of the usual trawl net with an auxiliary net attached underneath which is designed to capture all fish escaping under the trawl footrope. Efficiency was estimated by the ratio of the catch from the trawl net to the combined catch from both nets. Estimates of net efficiency as a function of fish length were obtained by sequentially fitting a nested hierarchy of statistical models to the efficiency and length data for each species and choosing the best model using likelihood ratio tests. For flathead sole, Hippoglossoides elassodon; northern rock sole, Lepidopsetta sp. cf. bilineata; Pacific halibut, Hippoglossus stenolepis and Pacific cod, Gadus macrocephalus, net efficiency did not vary with body length and was always >0.94. For yellowfin sole, Limanda aspera, net efficiency increased with body length and reached an asymptotic maximum of 0.77.",2002,Fisheries Research
A signature of 33 immuneâ€related gene pairs predicts clinical outcome in hepatocellular carcinoma,"OBJECTIVE
Hepatocellular carcinoma (HCC) has become the second most common tumor type that contributes to cancer-related death worldwide. The study aimed to establishÂ a robust immune-related gene pair (IRGP) signature for predicting the prognosis of HCC patients.


METHODS
Two RNA-seq datasets (The Cancer Genome Atlas Program and International Cancer Genome Consortium) and one microarray dataset (GSE14520) were included in this study. We used a series of immune-related genes from the ImmPort database to construct gene pairs. Lasso penalized Cox proportional hazards regression was employed to develop the best prognostic signature. We assigned patients into two groups with low immune risk and high immune risk. Then, the prognostic ability of the signature was evaluated by a log-rank test and a Cox proportional hazards regression model.


RESULTS
After 1000 iterations, the 33-immune gene pair model obtained the highest frequency. As a result, we chose the 33 immune gene pairs to establish the immune-related prognostic signature. As we expected, the immune-related signature accurately predicted the prognosis of HCC patients, and high-risk groups showed poor prognosis in the training datasets and testing datasets as well as in the validation datasets. Furthermore, the immune-related gene pair (IRGP) signature also showed higher predictive accuracy than three existing prognostic signatures.


CONCLUSION
Our prognostic signature, which reflects the link between the immune microenvironment and HCC patient outcome, is promising for prognosis prediction in HCC.",2020,Cancer Medicine
Sharp oracle inequalities for low-complexity priors,"In this paper, we consider a high-dimensional statistical estimation problem in which the number of parameters is comparable or larger than the sample size. We present a unified analysis of the performance guarantees of exponential weighted aggregation and penalized estimators with a general class of data losses and priors which encourage objects which conform to some notion of simplicity/complexity. More precisely, we show that these two estimators satisfy sharp oracle inequalities for prediction ensuring their good theoretical performances. We also highlight the differences between them. When the noise is random, we provide oracle inequalities in probability using concentration inequalities. These results are then applied to several instances including the Lasso, the group Lasso, their analysis-type counterparts, the $$\ell _\infty $$â„“âˆž and the nuclear norm penalties. All our estimators can be efficiently implemented using proximal splitting algorithms.",2017,Annals of the Institute of Statistical Mathematics
[Retroperitoneal laparoscopic nephron-sparing surgery for renal tumors].,"OBJECTIVE
To evaluate the feasibility and clinical efficacy of employing a homemade lasso to control the renal blood flow in retroperitoneal laparoscopic nephron-sparing surgery for the treatment of renal tumors.


METHODS
Eight patients with benign renal tumors and 14 with malignant renal tumors underwent enucleation and wedge resection of renal tumors through retroperitoneal laparoscopy. Of these 22 patients, 15 were males and 7 females with a mean age of 45 years old. The mean tumor diameter was 3.2 cm.


RESULTS
All the procedures were technically successful without conversion to open surgery in all 22 patients. The mean operative time was 150 min and mean blood loss 80 ml. The mean postoperative hospital stay was 8 days. No intraoperative or postoperative complication occurred. All 14 cases of malignant renal tumors had a negative surgical margin. With a follow-up of 5-29 months, no recurrence occurred.


CONCLUSION
Retroperitoneal laparoscopic partial nephrectomy is feasible and safe for selective patients with renal tumors. Using a homemade lasso to control the renal blood flow in retroperitoneal laparoscopic partial nephrectomy is simple and less interferential.",2009,Zhonghua yi xue za zhi
"Speculation, philosophy and the end of religion: Save the name 'God' and the folly of this name as the queen of the sciences or the jester of academia","In this article, Meillassoux and Laruelle were brought into conversation with Derrida concerning contingency, temporality, non-philosophy and God. The conversation between Derrida and Meillassoux focused on their respective views on trace and radical contingency, which opened towards reflections on God as either divinology (Meillassoux) or the endless desertification of language (Derrida), thus saving the name â€˜Godâ€™ and keeping the name safe. One cannot think this desertification of language, â€˜Godâ€™, without a reflection on khÅra. This opened a conversational space with Laruelleâ€™s non-philosophy. One of the major criticisms against Laruelle is that his non-philosophy has no worth in terms of the extra-philosophical (ethical, political or juridical) and the same could be said with regards to khÅra and, specifically, Derridaâ€™s interpretation of khÅra. Therefore Derridaâ€™s interpretation of khÅra with its â€˜unilateralâ€™ relation to logos, the giving and receiving of khÅra without giving and receiving anything and thus remaining indifferent, were brought into conversation with Laruelleâ€™s unilateral duality. This unilateral duality, although indifferent to philosophy, makes all the difference to logos and thus to philosophy. The question is: what place is given to khÅra and/or non-philosophy within academia? Derridaâ€™s God can be interpreted as a kind of autodeconstructive divine violence or holy folly. What place is given to divine violence or holy folly within academia? What is the relation of non-philosophy to philosophy? Is it the non-foundational foundation that remains totally indifferent to philosophy as it does not engage in a dialectical relationship with philosophy and yet it is the theory or science of philosophy? Can academia afford to â€˜give placeâ€™ to this holy folly, this non-philosophy, this khÅratic theo-logic, but on the other hand, can it afford not to â€˜give placeâ€™ to the queen and/or jester of academia?",2014,Verbum Et Ecclesia
A novel prognostic nomogram based on 5 long non-coding RNAs in clear cell renal cell carcinoma,"Clear cell renal cell carcinoma (ccRCC) is the most common and invasive histological subtype of all kidney malignancies, with high levels of incidence and mortality. In the present study, long non-coding (lnc)RNA expression profiles of patients with ccRCC from The Cancer Genome Atlas database were comprehensively analyzed to identify differentially expressed lncRNAs (DElncRNAs). The patients with ccRCC were then divided into training and validation cohorts. Univariate and LASSO regression analyses were performed to select the most significant survival-associated candidate DElncRNAs in the training cohort. Multivariate Cox regression analysis was then performed to develop a risk score formula and a prognostic nomogram for predicting 3- and 5-year overall survival (OS). The accuracies of the nomogram predictions were evaluated by determining the area under the receiver operating characteristic curve (AUC) and a calibration plot. Finally, functional enrichment analysis and protein-protein interaction network prediction were implemented to predict the functions and molecular mechanisms of the candidate DElncRNAs in ccRCC. A total of 1,553 DElncRNAs were identified, and 5 candidate DElncRNAs (AC026992.2, AC245041.2, LINC00524, LINC01956 and LINC02080) were included in the nomogram. The AUC values for 3- and 5-year overall survival in the training cohort were 0.768 and 0.814, respectively, which were increased compared with that based on the clinical index (0.760 and 0.694, respectively). Gene Ontology and Kyoto Encyclopedia of Genes and Genomes analyses revealed that the 521 mRNAs highly associated with 5 DElncRNAs were primarily involved in 17 terms and 25 pathways, respectively. Based on the 5 DElncRNAs, a novel and convenient prognostic nomogram for predicting 3- and 5-year OS for patients with ccRCC was developed. The results of the present study may be conducive to the development of a precise predictive tool for the prognosis of ccRCC and may provide information regarding the molecular mechanisms of ccRCC. However, additional experimental in vitro and in vivo studies investigating lncRNAs may be required.",2019,Oncology Letters
Pixel prediction by context based regression,"We propose a pixel prediction algorithm, which learns a regression function corresponding to each context. A context refers to a group of pixels, that have similar correlations with its neighboring pixels. We propose to form a pixel's feature vector by its neighboring pixels' ratios, so that they better capture the pixel properties described by the regression weights. Then we use K-means clustering to classify the feature vectors of all pixels into several contexts. Clustering reduces pixel randomness within each context, thus reducing prediction error. We apply three regression algorithms, the least square, quantile and lasso regression, which assume different loss function and regularization. Experimental results demonstrate that all context based regression methods have outperformed conventional pixel predictors. Among them, quantile regression, which assumes l1-norm loss function has the best result. It has 3.1% less bits per pixel (bpp) than least square prediction with 12 neighboring pixels.",2012,"2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Seared Verlasso Salmon with a Citrus Chive Vinaigrette | Verlasso,The Verlasso team was recently on site at ShopRite for a cooking demo and sampling where Chef Davis shared his seared Verlasso salmon recipe.,2013,
Growth-related changes in diet and foraging behavior of the yellow wrasseThalassoma lutescens at Kuchierabu Island,"Ontogenetic changes in diet and foraging behavior ofThalassoma lutescens were examined in shallow reef habitats around Kuchierabu Island, southern Japan. This species mainly took small benthic invertebrates, including gammarids, polychaetes, sipunculids, chitons, crabs, gastropods, pelecypods and urchins from algal mats. Larger fish consumed correspondingly larger prey, although most of the latter were armored with hard exoskeletons, shells or body plates (e.g., crabs, gastropods, pelecypods and urchins). Such hard parts were crushed with the molar-like, pharyngeal teeth which develop with fish growth, allowing exploitation of such larger, hard-bodied prey. Because the densities of larger prey species were relatively low in the initial habitats foraged, larger fish shifted their foraging attention to rock and coral crevices, where the prey species dwelt in greater numbers, as well as foraging over larger areas. Such behavioral changes maintained high foraging efficiency in larger fish.",1991,Japanese Journal of Ichthyology
Nomogram to predict postoperative PR in patients undergoing CT-guided transthoracic lung biopsy.,"Background
Pleural reaction (PR) frequently occurs following computed tomography-guided transthoracic needle biopsy (CT-TNB). The purpose of this study was to establish a predictive model for PR following CT-TNB.


Methods
In this study, a total of 436 patients who underwent CT-TNB between June 2016 and December 2017 at a tertiary hospital were consecutively included. Patient demographics, lesion features, laboratory tests, and biopsy parameters were collected. The least absolute shrinkage and selection operator (LASSO) regression and multivariate logistic regression analyses were performed to establish a prediction model for post-CT-TNB PR, presented by a nomogram. Discrimination and calibration were assessed. For internal validation, a bootstrap resampling method was applied, and decision curve analysis (DCA) was used to evaluate its clinical utility.


Results
PR occurred in 7.8% (34/436) of patients. Four non-zero coefficient variables (gender, age, lesion location, and puncture position) were filtered by LASSO regression analysis and were used to establish a predictive model. The area under the curve in the derivation and validation was 0.840 (95% CI, 0.767-0.913) and 0.841 (95% CI, 0.769-0.912), respectively. The model was well-calibrated (P>0.05), and DCA indicated clinical efficacy.


Conclusions
In this study, we established a nomogram, including as parameters gender, age, lesion location, and puncture position, which may have great significance for individualized prediction of post-CT-TNB PR.",2019,Journal of thoracic disease
Marine regressions and the evolution of groundwater dwelling amphipods (Crustacea),"The origin of marine lineages of amphipods in continental and insular ground waters is treated, and the im- portance in it of relative sea-level lowering is weighed. Pat- terns of distribution and relationships of Hadzioidea, Salentinellidae, Bogidielloidea and Niphargidae are re- viewed, with emphasis on the evidence for their direct marine origin, and on their dispersal abilities. The process of troglobitization, linked with subterranean evolution, in amphipods is discussed. A two-step model of the evolution of thalassoid lineages is discerned. During the first phase, marine populations colonize crevicular or interstitial habitats. These habitats are physiographically connected with the inland stygohabi- tats, and are characterized by severe ecological conditions. During the second phase, certain lineages overcome the salinity boundary and colonize inland ground waters through active migration or passive isolation, or through a combination of both. Marine regressions seem of little significance in the first evolutionary phase, where they primarily explain the isola- tion in coastal ground waters of marine littoral populations, already adapted to subterranean conditions. Vicariance by marine regressions is considered of relatively great evolu- tionary significance in thalassoid groups of low vagility and dispersal ability. This type of vicariance is followed by peripatric speciation, and a largely polychotomous pattern of descent is predicted.",1991,Journal of Biogeography
Enhancing the Demand for Labour survey by including skills from online job advertisements using model-assisted calibration,"In the article we describe an enhancement to the Demand for Labour (DL) survey conducted by Statistics Poland, which involves the inclusion of skills obtained from online job advertisements. The main goal is to provide estimates of the demand for skills (competences), which is missing in the DL survey. To achieve this, we apply a data integration approach combining traditional calibration with the LASSO-assisted approach to correct representation error in the online data. Faced with the lack of access to unit-level data from the DL survey, we use estimated population totals and propose a~bootstrap approach that accounts for the uncertainty of totals reported by Statistics Poland. We show that the calibration estimator assisted with LASSO outperforms traditional calibration in terms of standard errors and reduces representation bias in skills observed in online job ads. Our empirical results show that online data significantly overestimate interpersonal, managerial and self-organization skills while underestimating technical and physical skills. This is mainly due to the under-representation of occupations categorised as Craft and Related Trades Workers and Plant and Machine Operators and Assemblers.",2019,arXiv: General Economics
"Introduction au machine learning et au deep learning, mise en oeuvre en Python","Lâ€™apprentissage machine (machine learning) est une discipline scientifique qui s'intÃ©resse Ã  la conception et au dÃ©veloppement d'algorithmes permettant aux ordinateurs d'apprendre Ã  prendre des dÃ©cisions Ã  partir de donnÃ©es. L'ensemble des donnÃ©es possibles qui alimentent une tÃ¢che d'apprentissage peut Ãªtre trÃ¨s vaste et variÃ©, ce qui rend la modÃ©lisation et les hypothÃ¨ses prÃ©alables critiques pour la conception d'algorithmes pertinents. Ce stage se concentre sur la mÃ©thodologie sous-jacente Ã  l'apprentissage supervisÃ© avec un accent particulier sur la formulation mathÃ©matique des algorithmes et la faÃ§on dont ils peuvent Ãªtre mis en Å“uvre et utilisÃ©s dans la pratique. Introduction Ã  lâ€™apprentissage supervisÃ© : rÃ©gression et classification binaire, mÃ©triques dâ€™Ã©valuation classiques et quelques Â« recettes de cuisine Â» (cross-validation, overfitting) MÃ©thodes linÃ©aires : LDA, modÃ¨les linÃ©aires gÃ©nÃ©ralisÃ©s, rÃ©gression logistique. SVM linÃ©aire : hinge loss, mÃ©thodes de rÃ©gularisation ridge, lasso, problÃ¨mes en grande dimension MÃ©thodes non-linÃ©aires : arbres de dÃ©cision, CART, boosting, XGBoost, LightGBM, random forests, mÃ©thodes Ã  noyaux MÃ©thodes dâ€™optimisation pour le machine learning : coordinate gradient descent, descente de gradient stochastique et amÃ©liorations Deep learning : feed-forward neural networks, convolutional neural networks, back-propagation, algorithmes stochastiques pour lâ€™entrainement, early stopping, mÃ©thodes dâ€™initialisation, rÃ©gularisation dropout, mise en oeuvre avec Tensorflow et Keras",2019,
Alcohol as an Environmental Mortality Hazard.,"Alcohol is a major environmental hazard, with negative effects on many organs, including the brain, liver, pancreas, and heart.1 It is a leading cause of mortality in industrialized countries.2 Whether the mortality effects of alcohol are due to genetic or environmental effects or a combination of both is poorly understood. For example, cardiovascular and nearly all of the other alcohol-associated somatic disorders carry their own genetic vulnerability, and there is evidence that genetic variants associated with decreased alcohol intake may also be associated with decreased cardiovascular risk, irrespective of the degree of alcohol consumption.3 Persons with alcohol use disorders (AUDs) may also die because of consequences of comorbid tobacco and illicit drug use, which again carry their own genetic risk factors. Indeed, in patients with AUDs, tobaccorelated mortality accounts for up to half of the deaths observed over a 12-year period following alcohol detoxification.4 Road traffic crashes and suicides represent a significant cause of mortality in AUD.5 In addition, about half of all murders in the United States and Germany are committed under the influence of current alcohol intake,5 and elevated rates of alcohol-associated aggression are found in individuals with higher alcohol intake and hence also in those with AUDs, particularly if violent acts have been experienced during previous states of alcohol intoxication.5 Finally, socioeconomic status has been shown to moderate the risk for alcohol-related mortality across European countries; especially in younger adults of low socioeconomic status, alcohol-related deaths account for a large portion of excess mortality.6 These examples paint a complex picture of interrelated causality governed by both genetic and environmental risk factors for alcohol-related mortality rates. The study by Kendler and coauthors7 in this issue of JAMA Psychiatry disentangles the environmental and genetic risk factors that contribute to increased mortality among individuals with AUDs. The authors studied all individuals born in Sweden from 1940 to 1965 and controlled for mortality rates in halfsiblings, full-siblings, and monozygotic twins. They observed that familial factors significantly contributed to the rather strong increase in the mortality hazard ratio associated with AUDs in early to middle adulthood. In contrast, both increasing age and increasing duration of alcohol use contributed to high alcohol-associated mortality rates in late adulthood. In fact, Kendler and coauthors7 observed that AUD was associated with a 6-fold increase in mortality rate (5.8-5.9) for all ages and was highest in the age group of 30 to 39 years, showing an inverted U-shape and hence being lower in the age groups of 15 years and older and 65 years and older. Because all-cause mortality increases with age, most persons with AUDs will die with increasing duration of alcohol use. But when compared with the general population, mortality differences are most dramatic in early to middle adulthood. In light of such observations, it is important to disentangle genetic and environmental risk factors both in middle adulthood (when AUDs cause the strongest increase in mortality rates) and in elderly individuals (when overall mortality is highest). Accordingly, the main goal of the current study was the question: do increased mortality rates in individuals with AUD arise from familial risk factors or from general effects of excessive alcohol intake? Familial contributions to high mortality rates do not necessarily imply genetic risk factors. However, the authors carefully weighed the evidence for the genetic contribution in early to middle adulthood and emphasized that the comparison of mortality rates associated with AUDs in half-siblings reared together vs apart support the hypothesis that increased mortality during early to middle adulthood mainly reflects the influence of genetic factors. The authors suggested that impulsivity and novelty seeking could be among such factors, as such personality traits are partly heritable and may contribute to the use of other illicit drugs and to increased risk-taking behavior and individual vulnerability to experience violence. This is of particular interest because several adoption studies and 1 twin study showed that there was no genetic contribution to violent behavior except in combination with AUDs.5 Therefore, further studies on specific causes of mortality associated with AUDs in early to middle adulthood and their association with risk taking and violent experiences are highly warranted. There is a multitude of other, partially heritable risk factors associated with alcohol use, which can contribute to increased mortality in early to middle adulthood. Of specific importance is nicotine consumption, which is all too often associated with excessive alcohol intake and AUDs. Indeed, as indicated here, tobacco consumption accounts for up to 50% of elevated mortality rates following alcohol detoxification treatment in a community sample,4 thus pointing to nicotine dependence as another partially heritable risk factor, which can help to explain how genetic factors contribute to alcoholassociated mortality.4 The study by Kendler and coauthors7 highlights several key points for further study. Exploration of International Classification of Diseases codes for causes of death may stimulate research in the widely understudied area of alcohol-related aggression, the role of comorbid drug consumption (eg, tobacco), and other environmental and social risk factors. Sex differences in AUDs are an understudied research area, and Related article page 575 Opinion",2016,JAMA psychiatry
The treatment of recurrent atrial tachycardia originated from left atrium after the circumferential pulmonary veins isolation in patients with atrial fibrillation,"Objective To evaluate the radiofrequency(RF) ablation for the recurrent atrial tachycardia(AT) originated from left atrium(LA) after the circumferential pulmonary veins isolation(CPVI) in patients with atrial fibrillation(AF).Methods A repeat procedure was performed in 18 patients with recurrent AT after CPVI.In this procedure,PV conduction was confirmed by Lasso catheter.Activation mapping and entrainment technique were performed with 3-D Carto system to identify the earliest activation area and reentrant circuit.The gaps on the original continuous circular lesions(CCLs) around the ipsilateral pulmonary veins(PVs) were confirmed by the Lasso catheter and mapping catheter.Block the gap and the earliest activation area to terminate focal AT;Block the gap and the reentrant circuit to terminate reentrant AT.Results Recovered PV activation in 13 of 18 patients(72.7%) were demonstrated.Focal AT in 6 patients and reentrant AT in other 12 patients were confirmed.All conduction gaps were successfully closed with segmental ablation and all AT were terminated by the relevant ablation.One special reentrant tachycardia between PV and LA was indentified and was terminated by blocking the exit on the original CCLs.Conclusions Recovered PV spikes were confirmed in almost all patient with recurrent AT after CPVI and the gaps related to AT.",2007,The Chinese Journal of Cardiac Pacing and Electrophysiology
"Probenaufarbeitungschip, Reaktionskammer und Verwendung des Probenaufarbeitungschips","Reaktionskammer
(20) mit einem Volumen im Î¼l-Bereich
fur mikrofluidische
Anwendungen, in der Mikropartikel (5) mit Abmessungen im Î¼m-Bereich,
insbesondere Mikrokugelchen,
gefangen sind, mit Bodenwand (21 ), Deckwand (22) und Seitenwanden (23,
24, 23', 23'', 24', 24'') sowie mit eine Einlassoffnung (25)
und eine Auslassoffnung
(26) begrenzenden Wehren (30, 40, 130, 140), die eine Wehrkrone
(31, 41, 131, 141) und beidseitig der Wehrkrone (31) Wehrflachen (32,
33, 42, 43, 132, 133, 142, 143) aufweisen, wobei die Einlassoffnung (25)
und die Auslassoffnung
(26) schlitzartig ausgebildet sind, gegenuberliegend angeordnet sind
und sich uber
die Breite der Reaktionskammer (20) erstrecken, dadurch gekennzeichnet, dass
mindestens die steilste Tangente (T 1 , T 2 ) der in der Reaktionskammer (20) liegenden
Wehrflachen
(32, 42, 132, 142) mit der Bodenwand (21) der Reaktionskammer (20)
einen Winkel Î± mit Î± â‰¤ 45Â° bildet.",2005,
Heat-Related Health Impacts under Scenarios of Climate and Population Change,"Recent assessments have found that a warming climate, with associated increases in extreme heat events, could profoundly affect human health. This paper describes a new modeling and analysis framework, built around the Benefits Mapping and Analysis Program-Community Edition (BenMAP), for estimating heat-related mortality as a function of changes in key factors that determine the health impacts of extreme heat. This new framework has the flexibility to integrate these factors within health risk assessments, and to sample across the uncertainties in them, to provide a more comprehensive picture of total health risk from climate-driven increases in extreme heat. We illustrate the framework's potential with an updated set of projected heat-related mortality estimates for the United States. These projections combine downscaled Coupled Modeling Intercomparison Project 5 (CMIP5) climate model simulations for Representative Concentration Pathway (RCP)4.5 and RCP8.5, using the new Locating and Selecting Scenarios Online (LASSO) tool to select the most relevant downscaled climate realizations for the study, with new population projections from EPA's Integrated Climate and Land Use Scenarios (ICLUS) project. Results suggest that future changes in climate could cause approximately from 3000 to more than 16,000 heat-related deaths nationally on an annual basis. This work demonstrates that uncertainties associated with both future population and future climate strongly influence projected heat-related mortality. This framework can be used to systematically evaluate the sensitivity of projected future heat-related mortality to the key driving factors and major sources of methodological uncertainty inherent in such calculations, improving the scientific foundations of risk-based assessments of climate change and human health.",2018,International Journal of Environmental Research and Public Health
Spatio-temporal Modeling of Yellow Taxi Demands in New York City Using Generalized STAR Models,"A highly dynamic urban space in a metropolis such as New York City, the spatio-temporal variation in demand for transportation, particularly taxis, is impacted by various factors such as commuting, weather, road work and closures, disruption in transit services, etc. To understand the user demand for taxis through space and time, a generalized spatio-temporal autoregressive (STAR) model is proposed in this study. In order to deal with the high dimensionality of the model, LASSO-type penalized methods are proposed to tackle the parameter estimation. The forecasting performance of the proposed models is measured using the out-of-sample mean squared prediction error (MSPE), and it is found that the proposed models outperform other alternative models such as vector autoregressive (VAR) models. The proposed modeling framework has an easily interpretable parameter structure and practical to be applied by taxi operators. Efficiency of the proposed model also helps in model estimation in real-time applications.",2017,arXiv: Applications
Chef Massimo Fabbri Talks Verlasso | Verlasso,"Chef Massimo Fabbri of Ristorante Posto in Washington, D.C. has added Verlasso to his menu.",2014,
Probabilistic tractography using Lasso bootstrap,"&NA; Diffusion magnetic resonance imaging (dMRI) can be used for noninvasive imaging of white matter tracts. Using fiber tracking, which propagates fiber streamlines according to fiber orientations (FOs) computed from dMRI, white matter tracts can be reconstructed for investigation of brain diseases and the brain connectome. Because of image noise, probabilistic tractography has been proposed to characterize uncertainties in FO estimation. Bootstrap provides a nonparametric approach to the estimation of FO uncertainties and residual bootstrap has been used for developing probabilistic tractography. However, recently developed models have incorporated sparsity regularization to reduce the required number of gradient directions to resolve crossing FOs, and the residual bootstrap used in previous methods is not applicable to these models. In this work, we propose a probabilistic tractography algorithm named Lasso bootstrap tractography (LBT) for the models that incorporate sparsity. Using a fixed tensor basis and a sparsity assumption, diffusion signals are modeled using a Lasso formulation. With the residuals from the Lasso model, a distribution of diffusion signals is obtained according to a modified Lasso bootstrap strategy. FOs are then estimated from the synthesized diffusion signals by an algorithm that improves FO estimation by enforcing spatial consistency of FOs. Finally, streamlining fiber tracking is performed with the computed FOs. The LBT algorithm was evaluated on simulated and real dMRI data both qualitatively and quantitatively. Results demonstrate that LBT outperforms stateâ€ofâ€theâ€art algorithms. HighlightsWe propose a probabilistic tractography method named Lasso bootstrap tractography.The distribution of diffusion signals is estimated using modified Lasso bootstrap.We compute fiber orientations (FOs) using an algorithm incorporating FO smoothness.Qualitative and quantitative evaluation was performed on simulated and real data. Graphical abstract Figure. No caption available.",2017,Medical Image Analysis
A clinical predictive score for postoperative myasthenic crisis,"OBJECTIVE
Myasthenia gravis (MG) is an autoimmune disease mostly caused by autoantibodies against acetylcholine receptor associated with thymus abnormalities. Thymectomy has been proven to be an efficacious treatment for patients with MG, but postoperative myasthenic crisis often occurs and is a major complication. We aimed to develop and validate a simple scoring system based on clinical characteristics in the preoperative status to predict the risk of postoperative myasthenic crisis.


METHODS
We studied 393 patients with MG who underwent thymectomy at 6 tertiary centers in Japan (275 patients for derivation and 118 for validation). Clinical characteristics, such as gender, age at onset and operation, body mass index, disease duration, MG subtype, severity, symptoms, preoperative therapy, operative data, and laboratory data, were reviewed retrospectively. A multivariate logistic regression with LASSO penalties was used to determine the factors associated with postoperative myasthenic crisis, and a score was assigned. Finally, the predictive score was evaluated using bootstrapping technique in the derivation and validation groups.


RESULTS
Multivariate logistic regression identified 3 clinical factors for predicting postoperative myasthenic crisis risk: (1) vital capacityâ€‰<â€‰80%, (2) disease durationâ€‰<â€‰3 months, and (3) bulbar symptoms immediately before thymectomy. The postoperative myasthenic crisis predictive score, ranging from 0 to 6 points, had areas under the curve of 0.84 (0.66-0.96) in the derivation group and 0.80 (0.62-0.95) in the validation group.


INTERPRETATION
A simple scoring system based on 3 preoperative clinical characteristics can predict the possibility of postoperative myasthenic crisis. Ann Neurol 2017;82:841-849.",2017,Annals of Neurology
Regulatory T cells: Pursuing a germinal centre career,"centres, where, helped by follicular helper T (TFH) cells, they develop into high-affinity plasma and memory B cells. This process is under stringent control to avoid uncontrolled B cell proliferation and production of autoantibodies. Now, two studies published in Nature Medicine report that germinal centre reactions are controlled by regulatory T (TReg) cells with a TFH cell-like phenotype. The two studies identified forkhead box P3 (FOXP3)+ TReg cells expressing the TFH cell-associated factors CXC-chemokine receptor 5 (CXCR5) and B cell lymphoma 6 (BCL-6) in the germinal centres of immunized mice. These follicular TReg cells expressed both TFH cellassociated and TReg cell-associated genes and were suppressive in vitro. So, do follicular TReg cells develop from TFH or TReg cells? Adoptive transfer experiments indicated that follicular TReg cells originate from TReg cells. Moreover, Linterman et al. showed that thymus-derived but not induced TReg cells are the follicular TReg cell progenitors. In addition, they observed that, similarly to TFH cells, follicular TReg cells require signalling through CD28 and SLAM-associated protein (SAP) for their generation, and both studies demonstrated that BCL-6 expression is essential for their differentiation. Thus, BCL-6 expression and SAP-mediated signalling lead to the development of follicular TReg cells from natural TReg cells. But what is the function of follicular TReg cells? To address this, Linterman et al. generated chimeric mice that contained SAP-deficient T cells (which cannot differentiate into TFH or follicular TReg cells), as well as T cells expressing the diphtheria toxin receptor under the control of the Foxp3 promoter. Selective depletion of follicular TReg cells with diphtheria toxin resulted in increased numbers of TFH cells and germinal centre B cells in response to immunization. Intriguingly, the numbers of non-antigen-specific B cells were increased, whereas the percentages of antigen-specific plasma cells and memory B cells were reduced in chimeric mice lacking follicular TReg cells, compared with the numbers in control chimaeras. Thus, the authors suggest that follicular TReg cells limit TFH cell numbers, and possibly select against those that are self-reactive, thereby providing a competitive advantage to high-affinity antigen-specific B cells. By contrast, Chung et al. observed no increase in TFH cell numbers in response to immunization when they transferred naive CD4+ T cells together with BCL-6or CXCR5-deficient TReg cells (which cannot differentiate into follicular TReg cells) into T cell-deficient recipients. In their model, the absence of follicular TReg cells resulted in increased numbers of germinal centre B cells but also in elevated levels of antigen-specific B cells and high-affinity immunoglobulins. Taken together, the two studies describe the BCL-6-dependent differentiation of natural TReg cells into follicular TReg cells, which negatively regulate germinal centre B cell numbers. The seemingly opposing conclusions on the effect of follicular TReg cells on antigen-specific B cell responses may rely on the experimental approaches used, and further research will clarify the contribution of follicular TReg cells to the regulation of germinal centre reactions. Maria Papatriantafyllou",2011,Nature Reviews Immunology
Are National Training Organisations an Effective Means of Developing the UK Skill Base in the Context of the Global Economy,"This paper was published as Working Paper 34 by the Centre for Labour Market Studies, University of Leicester. It is available from http://www.clms.le.ac.uk/research/wpapers.lasso",2002,
"Insular endemism in the Mediterranean vascular flora: the case of the Aeolian Islands (Sicily, Italy)","The present paper briefly provides the state of the art of the knowledge on vascular plant endemism in the oceanic (â€œthalassogenousâ€) Aeolian Archipelago (Sicily). Preliminary analysis of distribution areas and review of recent literature on biosystematics of endemic species revealed that: (a) Aeolian strictly endemic taxa are just 6, i.e. about the 0.7 % of the local vascular flora; among them, just 4 can be considered (with doubt) derived from in situ evolution. (b) The other 18 endemics are taxa occurring in wider areas, so they can not be generally considered â€œlocally evolvedâ€ but relicts. This preliminary analysis con firms that not only continental (â€œchersogenousâ€) but all Mediterranean islands are primarily conservative rather than evolutionary active systems. speciation; evolutionary refugia; dispersal; island biota.",2012,
"Late Jurassicâ€“Early Cretaceous palynostratigraphy of the onshore Mandawa Basin, southeastern Tanzania","Abstract New palynostratigraphic data are presented for Upper Jurassic and Lower Cretaceous formations of the Mandawa Basin, southeastern Tanzania. A Late Jurassic (Kimmeridgianâ€‘Tithonian) age is confirmed for the Kipatimu Formation, from which the terrestrial sporomorphs allow a rough correlation to the mid Oxfordianâ€‘Tithonian Classopollisâ€‘Araucariacitesâ€‘Shanbeipollenits Assemblage Zone. A dinoflagellate cyst assemblage recorded in the Mitole Formation correlates to the Dingodinium jurassicumâ€“Kilwacysta assemblage as described from the Tithonian Trigonia smeei Bed of the Tendaguru Hill, southeast Tanzania. Dinoflagellate cyst assemblages in the upper Nalwehe Formation contain species typical of the Hauterivianâ€‘Barremian, while the Kihuluhulu Formation contains marine microfloras of Aptian to Albian ages. The palynological records confirm the presence of sediments related to profound marine transgressions and subsequent sea-level high-stands in the Late Jurassic (Kimmeridgianâ€‘Tihonian) and in the late Early Cretaceous (Aptianâ€‘Albian).",2018,Review of Palaeobotany and Palynology
Three differentially expressed miRNAs as potential biomarkers for lung adenocarcinoma prognosis.,"OBJECTIVE
The aim of this study is to screen MicroRNA (miRNA) related to the prognosis of lung adenocarcinoma (LUAD) and to explore the possible molecular mechanism.


METHODS
A total of 535 LUAD data were downloaded from The Cancer Genome Atlas (TCGA) database. The miRNAs for LUAD prognosis were screened by Cox risk proportional regression model and Last Absolute Shrinkage and Selection Operator (LASSO) regression model. The performance of the model was verified by time-dependent Receiver Operating Characteristic (ROC) curve. The possible biological process of miRNAs' target genes was analyzed by Gene Ontology (GO), Kyoto gene and genome encyclopedia (KEGG).


RESULTS
127 differentially expressed miRNAs were screened with 111 up-regulated and 16 down-regulated miRNAs. Three key miRNAs, hsa-miR-1293, hsa-miR-490 and hsa-miR-5571, were screened from survival analysis, which are significantly enriched in systemic lupus erythematosus pathways.


CONCLUSION
Hsa-miR-1293, hsa-miR-490 and hsa-miR-5571 can be used as novel biomarkers for the prediction of prognosis of LUAD.",2020,Combinatorial chemistry & high throughput screening
Nouvelle mÃ©thode de linÃ©arisation harmonique pour systÃ¨mes non linÃ©aires Ã  paramÃ¨tre rÃ©parti decrits par leurs noyaux de Green-Laplace â€ ,"Abstract On considero uno classo de systemes non lineaires a parametre reparti qui presentent une structure analogue a cello doa systemes usuels a parametre localise. Leur representation est prise sous forme d' equations operationnelles integrates avec noyaux de Green-Laplace. On developpe pour ces systemes une methode du premier harmonique utilisant les functions propres de cos noyaux. Dans ce contexte on enonce : une condition d'existence et do stabilite des oscillations limites symetriques, un critere de Stabilite a l'urigino, deux critares de stabilite global entree-sortie. Enauite on montre comment ameliorer la precision ainsi obtenue on tenant compte d'un plus grand nombro d'harmoniques. Quelques exemples sont donnees A class of non-linear distributed parameter systems which exhibit a structure similar to that of standard lumped parameter non-linear systems is considered. They are represented by means of integral operational equations with Greenâ€”Laplace kernels. For these systems, a describing funct...",1973,International Journal of Electronics
La (perduta) memoria del terremoto: un confronto tra i danni prodotti dal sisma del 1987 e del 2012 su alcune chiese dellâ€™Emilia,"Gli effetti traumatici che si susseguono dopo ogni evento sismico fanno emergere con assoluta chiarezza quanto sia vulnerabile il nostro costruito esistente. Alle costruzioni storiche, piu o meno antiche, realizzate senza il rispetto di criteri che tengono conto della pericolosita sismica del sito â€“ criteri imposti oggi dalla Normativa o governati dalle regole dellâ€™arte nel passato â€“ si aggiunge la continua constatazione dellâ€™inadeguatezza degli strumenti che utilizziamo per cautelarci dal rischio sismico. Lâ€™evoluzione dellâ€™ingegneria sismica e dâ€™altronde basata, in maniera quasi duale, sugli eventi piu o meno importanti che si sono verificati nel mondo industrializzato, alimentando la ricerca della comunita scientifica. Ogni evento, infatti, rappresenta un test che permette di valutare la bonta dei modelli di calcolo, delle soluzioni tecniche, permettendo di proporne di nuovi quando i risultati non sono stati congruenti a quanto teoricamente preventivato. Fa parte ovviamente del consueto sviluppo della ricerca che ha lâ€™obbligo di stare sulla frontiera della conoscenza, modificare i metodi di verifica, aggiornare i parametri che entrano in gioco. Piu complessa e pero lâ€™applicazione sulle costruzioni, monumentali e non. Gli interventi che progettiamo sono episodi che condizionano il comportamento strutturale (la risposta sismica) per un lasso temporale molto lungo, che male si coniuga con gli aggiornamenti normativi che la ricerca accademica puo determinare. Le motivazioni sono abbastanza ovvie: da un lato la difficolta a traghettare sul mondo professionale i risultati della ricerca rende lento questo aggiornamento continuo, dallâ€™altro le disponibilita economiche limitate, completamente assorbite per gestire lâ€™emergenza del momento non consentono di pianificare in termini preventivi una riduzione del rischio sismico. In questo panorama lâ€™evento dellâ€™Emilia rappresenta una situazione emblematica. Lâ€™azione sismica che si e verificata sia in termini di accelerazione massima sia come contenuto in frequenza evidenzia un evento con una probabilita di eccedenza minore di quella presa normalmente come riferimento per lo stato limite di salvaguardia della vita. La ridotta profondita dellâ€™evento sismico ha determinato accelerazioni verticali comparabili a quelle orizzontali. Valori cosi elevati della componente sussultoria, sottolineano la necessita di una diversa interpretazione del loro effetto in termini di spettro di risposta, rispetto a quanto ad oggi normato. Si fa ad esempio riferimento allâ€™invariabilita degli spettri verticali previsti dalle Norme Tecniche per le Costruzioni (D.M. 14 gennaio 2008) per le diverse classi del sottosuolo. Da questo punto di vista la possibilita di cautelarsi preventivamente puo sembrare quasi inutile, consci delle conoscenze in nostro possesso. In questo lavoro, invece, si e provato a dimostrare tramite lo studio di alcuni manufatti storici, come sia possibile operare in unâ€™ottica preventiva, cercando di capire come anche la â€œlimitata conoscenzaâ€ attuale sul fenomeno terremoto avrebbe potuto salvaguardare molte costruzioni, oggi irrimediabilmente compromesse. Lo stato di danneggiamento oggi rilevabile sulle costruzioni monumentali emiliane non puo unicamente essere imputato ad una non esaustiva conoscenza della pericolosita sismica di quelle zone: la totale mancanza di agire in un ottica culturale di prevenzione e, ancora una volta, la prima causa della perdita nostro patrimonio culturale.",2013,
The Lasso under Poisson-like Heteroscedasticity,"The performance of the Lasso is well understood under the assumptions of the standard sparse linear model with homoscedastic noise. However, in several ap- plications, the standard model does not describe the important features of the data. This paper examines how the Lasso performs on a non-standard model that is mo- tivated by medical imaging applications. In these applications, the variance of the noise scales linearly with the expectation of the observation. Like all heteroscedas- tic models, the noise terms in this Poisson-like model are not independent of the design matrix. Under a sparse Poisson-like model for the high-dimension regime that allows the number of predictors (p) â‰« sample size (n), we give necessary and sufficient conditions for the sign consistency of the Lasso estimate. Simulations re- veal that the Lasso performs equally well in terms of model selection performance on both Poisson-like data and homoscedastic data (with properly scaled noise vari- ance), across a range of parameterizations.",2013,Statistica Sinica
UspjeÅ¡an seminar Hrvatske zajednice laringektomiranih u Thalassotherapiji u Crikvenici,"Od 13. do 19.lipnja 2010. godine odrÅ¾an je vec tradicionalni, peti, seminar nadomjesnog govora, plivanja, psihoonkoloske potpore i po prvi puta tecaj zaÂ  laringektomirane volontere, koji posjecuju novooperirane na klinikama u svrhu motivacije u rehabilitaciji. Sudjelovalo je 62 clana iz cijele Hrvatske, gdje sada HZL ima 10 klubova. Seminar su vrhunski, na volonterskoj osnovi, izvodile profesorice logopedi M. Sucic, B. Imris, T. Å½ivkovic-Ivanovic i Lj. Siric, kao iÂ  mr.sc. Vrcic-Kiseljak, prof. defektolog. Tecaj za volontere odrÅ¾ali su prof. M.Sucic i Z. Celikovic, a korisno predavanje odrÅ¾ao je fra Z. Senjak, u smislu duhovne potpore, te inÅ¾enjer V. Klindic o pomagalima za govor i njegu stome. Uz svakojutarnju gimnastiku na plaÅ¾i, te prijateljsko druÅ¾enje seminar je svima ostao u dobrom sjecanju sa Å¾eljom da se ponovi. Ponovno druÅ¾enje HZL planira na Sv.BlaÅ¾aÂ  2011., kada su pozvani, osim gostiju iz Slovenije i prijatelji iz Njemacke, kao i drugi. Domacini iz Thalassotherapije, osobito dr. Matesa-Anic, koja je sve pregledala i odredila potrebnu Inhalacijsku terapiju, trudili su se da svima boravak bude ugodan i koristan.",2010,
Specification and Designof Establishedreliabilitypowerrelays,"Thispapercoversworkon established reliability forpowerrelaysby the NationalAssociation of RelayManufacturers andanAirForceappointed committeeworkingcooperatively withSAESubcommittee A-2R. A practicalmeansof specifying established reliability forpowerrelays usingMIL-R-6106 as a basicspecification isproposed.Lifecyclesfromqualification,acceptanceandrequalification tests arecombinedto establisha reliability of 1%per10,000cycles. Theauthorsalsocoverprinciples and proceduresforthedesignandmanufacture of established reliability powerrelays.",1965,
Howmanygeneral practitioners for1433 patients,"1990.15 Joint Formulary Conunittee. British national formulary. No 23. London:British MedicalAssociation, Royal Pharmaceutical Society ofGreatBritain,1992:3.1,3.2,3.3.16 Bogle SM,Harris CM.Measuring prescribing: the shortcomings ofthe item.BMJ1994;308:637-40.17 Roberts SJ, Harris CM. Age, sex, and temporary resident originated units(ASTRO-PUs): new weightings for analysing prescribing of general prac-ticesin",1995,
Geographical and Anthropological Aspects of the Identity of Southern Italy,"1. Locations and space If it ever really existed, the notion of the South of Italy as a cultural landscape indistinct and primitive in its atavistic and dense backwardness was an imaginary vision of distant lands on the outskirts of Europe. A â€œparadise populated by devilsâ€ where the aforementioned backwardness consisted of violence, individualism, familism, fatalism and so on. Or even worse, a space where atavistic customs and modes of behavior are practiced and pursued with modern instruments. The question would for the most part be one of â€œpassive modernizationâ€ (Cafagna, 1994), which with the homologation of consumption has merely recast ancestral modes of behavior which are still present and largely still active. Even so, the entire â€œSouthern questionâ€ in the last fifty years has centered on a primitive space (the South) with locations and territories defined in terms of economic as well as social expansion. Places and territories are differentiated, giving citizenship to â€œmany Southsâ€ as opposed to just one. Therefore, today more than ever, as Giuseppe Galasso reminds us, citing Max Sorre, â€œthe empirical knowledge of the habitat ties together all of the economic, social and religious notions of the inhabitants....â€. He adds that it is â€œinside each single habitat that one can see the concrete development of the social life, the formation and development of mentality and behavior, the accumulation of experience, the conservation and the innovation of customs, and the birth and decline of traditions.â€ It is furthermore a question of a range of studies and investigations which, â€œboth taken up and neglected by sociologists and geographers, anthropologists and students of city planning, ecologists and economists, has concluded with the formation of a no manâ€™s land rather than a territory of frontiers, and a superimposition, if not a confusion, of notions and techniques, rather than the drawing up of conceptions and scientific methodsâ€ (Galasso, 1997, p. 21). If the unity of the South as a homogenous cultural landscape, supposing that it did exist in the first place, was shattered, and therefore its cultural space is a sum of diverse and different locations, the question is how and why, even if only synthetically, such differences were created, or rather, accentuated. Obviously, one cannot and one must not exclude that which remains of the common ever more tenuous identity traits, which in the past fifty years have undergone a real evolution. From the end of the second world war to today the per capita revenue of the South in real terms has quadrupled. This is much greater, to give one example, than the fifteen new countries which are about to enter Europe and not too far removed from other Mediterranean Basin states such as Spain, Greece and Portugal. An economic growth, both in terms of duration and size, without precedent in the history of the ancient kingdom. This has allowed two regions (Abruzzo and Molise) to leave the â€œhistorical Southâ€ and another two (Puglia and Basilicata) to draw closer to its threshold. It has also caused not only economic but in certain places social development, breaking down the old stereotypes of the South and its citizens. One example is Matera and part of its province, which is typical of the most extreme â€œrural societyâ€ and the most primitive urban conditions. In his introduction to an investigation by Censis from midway through the 80s, the sociologist Giuseppe De Rita notes how forty years previously, â€œthe native of Matera imposed his ancient culture: his sense of time without apparent scansion, his capacity for prolonged silence, his necessary patience, his slow rumination, the primacy of his sparse language, the importance of seeing with the eyes, the primordial appendages of the family, the local neighborhood, the churchâ€. If to this description of a cultural landscape immersed in an agrarian landscape, product of baronial and rustic estates, one can add that of the infernal Dantesque landscape, of Levian memory, of the",2006,
Gradnja napovednih modelov s pomoÄjo strukturiranih in nestrukturiranih podatkovnih virov,"Teoreticna izhodisca: Sladkorna bolezen tipa 2 (SB2) je najpogostejsa oblika sladkorne bolezni, predvsem v razvitih drÅ¾avah sveta. Za SB2 zboleva vedno vec ljudi, in to zaradi neprimernega Å¾ivljenjskega stila, predvsem premalo fizicne dejavnosti in nepravilnega prehranjevanja. Ceprav vecina ljudi SB2 vidi kot samoumevno bolezen, ki se lahko pojavi v poznih letih, se mnogi ne zavedajo njene resnosti. SB2 predstavlja glavni vzrok za moÅ¾gansko kap in bolezni srca. Poleg tega lahko privede do slepote, bolezni ledvic oziroma, v skrajnem primeru, tudi do smrti. S starostjo se tveganje za SB2 razumljivo povecuje, vendar pa lahko v veliki meri na povecanje tveganja vplivamo predvsem sami. Smrtnemu izidu so najbolj podvrÅ¾eni bolniki s SB2, ki so bili hospitalizirani na enoti intenzivnega oddelka. Glavni namen magistrskega dela je bil preveriti vpliv najpogosteje ponavljajocih se korenov besed iz zapisov o zdravljenju bolnika na tocnost napovednega modela za napoved preÅ¾ivetja bolnikov s SB2. 
Metodologija raziskovanja: Analize smo opravili na filtrirani podatkovni zbirki MIMIC-III, ki hrani skupno 4236 zapisov o bolnikih s SB2. Analize so bile izvedene s programskim jezikom R s pomocjo naslednjih klasifikatorjev: Random Forest, Single C5.0 Ruleset, Glmnet (Lasso regresija), XGBoost ter GBM. Rezultate smo evalvirali z Bootstrap metodo, ponovljeno 100-krat. 
Rezultati: Vsi napovedni modeli, zgrajeni na podatkih moskega vzorca, so bili v primerjavi z modeli, zgrajenimi na podatkih Å¾enskega vzorca, statisticno signifikantno uspesnejsi pri napovedovanju umrljivosti bolnikov s SB2 (Î”AUC = +0,049, p 0,001). Ne glede na spol se rezultati pri napovedovanju z vkljucenim kriterijem SAPS izboljsajo v primerjavi z napovedovanjem, ce kriterij SAPS ni prisoten (Î”AUCÅ½enske = +0,0756, Î”AUCMoski = +0,082). 
Sklep: Napovedni model XGBoost je najprimernejsi model za napovedovanje umrljivosti bolnikov s SB2. Prisotnost besed, ki se navezujejo na stimulacijo oziroma spodbujanje, starost, gibanje, neodzivnost in diagnozo intracerebralne krvavitve, ima najvecji vpliv na uspesno napovedovanje umrljivosti bolnikov s SB2. Z vkljucitvijo bigramov se uspesnost napovednih modelov ne izboljsa signifikantno. Uporaba pogosto uporabljenega kriterija SAPS, ki temelji na fizioloskih podatkih, ostaja primarno vodilo pri napovedovanju umrljivosti bolnikov s SB2.",2017,
Hemodynamic parameters and vessel tortuosity: an investigation with a mesenterial vascular network,"Purpose: The effect of hemodynamic parameters on vessel tortuosity remains un- clear. Here we investigate the correlation of tortuosity with a set of hemodynamic parameters in a mesenterial vascular network. Methods: A mesenterial vascular network of 389 vessels (131 arteries, 132 veins, and 126 capillaries) was imaged. Eleven hemodynamic parameters were measured (pressure, wall shear stress, diameter, blood velocity and flow, viscosity, haematocrit, partial oxygen saturation, oxygen saturation, wall thickness, and local vessel density). Tortuosity was assessed quantitatively with a validated algorithm and correlation computed with subsets of hemodynamic parameters selected by a lasso regressor. Results: Results suggest that tortuosity is related to pressure, wall shear stress, diameter, blood velocity, viscosity, partial but not full oxygen saturation, and wall thickness for the arteries; diameter, blood flow, hematocrit, and density for the veins; and viscosity (but not hematocrit), partial and full oxygen saturation, and density for the capillaries. The combination of hemodynamic parameters correlating best with tortuosity is the set of all parameters except density (r = 0.64, p < 0.01), using as tortuosity definition the set of tortuosity features (geometric measures) correlating best with a single hemodynamic factor for the arteries. Conclusion: Â This pilot suggests two general conclusions. First, the quantitative definition of tortuosity (i.e., the set of geometric features adopted) should be tuned to the specific data and problem considered. Second, tortuosity is caused by a combination of hemodynamic factors, not a single one.",2017,
Fluid pressure control device for an automatic,"A switching valve 60 is provided such that it selectively a communication between a discharge orifice oil passage 33 which is connected to a discharge port 42b of a linear solenoid valve SLC1, and a clutch oil passage 34 which is connected to a clutch hydraulic pressure chamber 80, and a communication between a Auslassoffnungsolkanal 36 is connected to an outlet 52b of an electromagnetic pump 50, and turns the clutch oil passage 34th An accumulator 70, which acts as a damper is connected to the output port oil passage 33rd Consequently, the pressure accumulator 70 is not connected to a path leading from the outlet port 52b of the electromagnetic pump 50 to the clutch hydraulic pressure chamber 80 (the Auslassoffnungsolkanal 36, the switching valve 60 and the clutch oil passage 34). Thus, a leakage of working oil during the driving of the electromagnetic pump can be prevented. As a result, the size of the electromagnetic pump 50 can be reduced by the electromagnetic pump 50 is designed so that it provides a necessary and sufficient pump performance.",2012,
Autoregressive model for individual consumption data - Sparsity recovery and significance test,"Understanding consumer flexibility and behavior patterns is becoming increasingly vital to the design of robust and efficient energy saving programs. Accurate prediction of consumption is a key part to this understanding. Existing prediction methods usually have high relative errors that can be larger than 30%. In this paper, we explore sparsity in users' past data and relationship between different users to increase prediction accuracy. We show that using LASSO and Granger Causality techniques, prediction accuracy can be significantly improved in comparison to existing algorithms. We use mean absolute percentage error (MAPE) as the criteria.",2016,2016 IEEE Power and Energy Society General Meeting (PESGM)
3 â€“ Experimental investigations and fundamental restrictions,"This chapter presents a brief review of some previous experiments of fluorescent cooling of solid-state specimens and discusses how anti-Stokes cooling of materials is the subject of active experimental investigations and study. One of such experiments is the Los-Alamos experiment. The chapter examines this experiment and explores how it is restricted in the experiment of fluorescent cooling of solid-state specimens. It further discusses the initial work on the development of a solid-state laser refrigerator, known as Los Alamos Solid-State Optical Refrigerator (LASSOR). One of the important characteristics of solid-state optical refrigerators is the absolute efficiency of the cooling process-ratio of cooling power to the total supplied radiation power- and the volume density of the cooling power, which can be achieved in the working substance. The chapter examines these characteristics. The experimental values of the photo thermal deflection of the probing laser beam, normalized with respect to both the pumping intensity and the linear absorption coefficient, are presented in the chapter. These results were obtained at the pumping intensity lower than the saturation intensity.",2009,
Sharon Palmer Writes About Her Verlasso Trip | Verlasso,Verlasso hosted four dietitians on a visit to Patagonia to learn more about how we raise our salmon. Sharon Palmer was among those in attendance.,2015,
An Exploratory Study of Patient Falls,"Banks are extremely highly levered due to the nature of their business model and bank capital serves as a source of stability and protection of the society from abuse of the government support (aka safety net). As a result, bank capital is heavily regulated. However, there are economic reasons that prompt banks to hold capital beyond the regulatory requirements. Understanding those reasons is very important for the efficiency in banking regulation, for the risk management of the banks, and for investorsâ€™ and customersâ€™ assessment of the bankâ€™s soundness. We study the determinants of bank capital structure using several variable selection methods. We show how every method is appropriate for the right purpose. However, it is essential to ensure that assumptions of the methods are satisfied. We use lasso variable selection and estimation method that is not robust to outliers. To overcome the limitations of this powerful technique, we study samples of banks with only outliers and samples without outliers separately. We find substantial differences in the drivers of capital decisions of bank-outliers. The findings uncover moral hazard effect among Systematically Important Financial Institutions.",2016,Nursing focus
Efficiency for Regularization Parameter Selection in Penalized Likelihood Estimation of Misspecified Models,"It has been shown that Akaike information criterion (AIC)-type criteria are asymptotically efficient selectors of the tuning parameter in nonconcave penalized regression methods under the assumption that the population variance is known or that a consistent estimator is available. We relax this assumption to prove that AIC itself is asymptotically efficient and we study its performance in finite samples. In classical regression, it is known that AIC tends to select overly complex models when the dimension of the maximum candidate model is large relative to the sample size. Simulation studies suggest that AIC suffers from the same shortcomings when used in penalized regression. We therefore propose the use of the classical corrected AIC (AIC c ) as an alternative and prove that it maintains the desired asymptotic properties. To broaden our results, we further prove the efficiency of AIC for penalized likelihood methods in the context of generalized linear models with no dispersion parameter. Similar results exist in the literature but only for a restricted set of candidate models. By employing results from the classical literature on maximum-likelihood estimation in misspecified models, we are able to establish this result for a general set of candidate models. We use simulations to assess the performance of AIC and AIC c , as well as that of other selectors, in finite samples for both smoothly clipped absolute deviation (SCAD)-penalized and Lasso regressions and a real data example is considered. Supplementary materials for this article are available online.",2013,Journal of the American Statistical Association
The group lasso for logistic regression,"The group lasso is an extension of the lasso to do variable selection on (predefined) groups of variables in linear regression models. The estimates have the attractive property of being invariant under groupwise orthogonal reparameterizations. We extend the group lasso to logistic regression models and present an efficient algorithm, that is especially suitable for high dimensional problems, which can also be applied to generalized linear models to solve the corresponding convex optimization problem. The group lasso estimator for logistic regression is shown to be statistically consistent even if the number of predictors is much larger than sample size but with sparse true underlying structure. We further use a two-stage procedure which aims for sparser models than the group lasso, leading to improved prediction performance for some cases. Moreover, owing to the two-stage nature, the estimates can be constructed to be hierarchical. The methods are used on simulated and real data sets about splice site detection in DNA sequences. Copyright 2008 Royal Statistical Society.",2008,Journal of The Royal Statistical Society Series B-statistical Methodology
IT or not to be: The impact of Moodle in the education of developing countries,"E-learning environments, such as Moodle, provide a technology that fosters the improvement of the educational system in developed countries, where education is traditionally performed with relatively high standards of quality. A large number of case studies and research have been conducted to demonstrate how e-learning technologies can be applied to improve both training and learning processes. However, these technologies have not been proved efficient when applied to developing countries. The challenges that must be addressed in developing countries, both technological and societal, are much more complex and the possible solution margins are more constrained than those existing in the context where these technologies have been created. In this paper we show how Moodle can be used to improve the quality of education in developing countries and, even more important, how can be used to turn the educational system more sustainable and effective in the long-term. We describe our experience in implementing a programming course in Moodle for the Higher School of Informatics at the Universite Polytechnique de Bobo-Dioulasso, in Burkina Faso (West Africa), joining efforts with local professors in designing and implementing the 
learning system. The case example has been designed having in mind a number of contextual problems: lack of lecturers, excessive teaching hours per lecturer, massive classes, and curricula organization and stability, among others. We finally discuss how the teaching effort is reduced, the studentsâ€™ knowledge and capacity improves, and the institutional academic model can be guaranteed with the proposal. For this reason, we claim that information technologies in developing countries are a cost-effective way to guarantee the objectives originally defined in the academic curricula and, therefore, deal with the problem of the education.",2012,
Color Correction Method for Digital Camera Based on Variable-Exponent Polynomial Regression,"Subject to the response uniformity of photoelectric sensors, the captured raw images always have serious chroma distortions. How to determine the mapping matrix between RGB and XYZ color spaces is important for the color distortion correction. However, the commonly used algorithms cannot give consideration to the precision and the adaptability. A more reasonable mapping algorithm based on variable-exponent polynomial regression is proposed to evaluate the mapping matrix coefficients. Variable-exponent regularization with the LÏ-norm (1 < Ï < 2) combines the features of lasso regression and ridge regression methods, owning both the sparsity and smoothing properties. The optimal solution for the variable-exponent regularization is given using lagged fix-point iteration method. Data from the standard color correction experiments are used to test the variable-exponent, lasso, ridge, and least-squares regression algorithms with different polynomial regression models. The results demonstrate that the proposed algorithm has the best performance.",2018,
Nekoreliuotos realybÄ—s problema Quentino Meillassoux ir Grahamo Harmano spekuliatyviajame realizme,"The current article discusses the positions of two representatives of the speculative realism movement. This is a relatively new movement of the 21st century. Meillassoux and Harman disagree with the postulates of Immanuel Kant and post-Kantian philosophy, which are referred to as correlationism. Both authors commit their attention to one or another type of the conception of reality. Comparing the positions of both authors, the aim of the research is to show how the authors of speculative realism rethink the turn to reality in the context of contemporary philosophy. It is maintained that the positions of the two representatives of the speculative realism movement are different. Harman stays within the frame of the tradition of continental philosophy. He maintains minimal creed of continental philosophy, namely, irreducibility of both theory and practice to one of the extremes â€“ empirical material data or thought. Meanwhile, Meillassouxâ€™s speculative attempt is more radical. He tries to separate radically reality and thought. Primary mathematizable qualities of objects refer to uncorrelated reality, whereas secondary qualities of an object â€“ to correlationists. Keywords: speculative realism, Meillassoux, Harman, correlationism, groundlessness. DOI:Â  http://dx.doi.org/10.15823/zz.2016.20",2017,Å½mogus ir Å½odis
Intorno a un non Comune Teratoma Ascellare Spontaneo in Mus Musculus Albinus (1),"Le rieerche bibliograflche sull'argomento e la maneanza quasi assoluta di notizie reperibili mi hanno indotto ad illustrare brevemente un partieolare caso di teratoma spontaneo osservato nel nostro Istituto, Si tratta di una topina impubere (7 gr. di peso circa) che era stata usata per una reazione di ASCHHEIM-ZONDEK. L'animale sacrificato con asflssia, veniva autopsiato per il eontrollo della reazione in corso. La incisione B 10 scollamento dei tegumenti delle regioni ascellari ed inguinali da noi sistematieamente eseguito, portava a reperire alIa regione ascellare destra dell'animale, nella sede di elezione delle linfoghiandole, una intumescenza del volume quasi di un cece, di consistenza piuttosto melle che fece pensare ad una linfoghiandola circondata da nn connettivo molto lasso ed imbibito (penilinfoadenite'l, iniezioni di urina con ingresso dell'ago alIa regione sacrale e scarico del Iiquido alIa regione alta del dorso, tra nuea e regions interscapolare). Apparentemente non si notarono particolari rapporti coi tessuti circostanti. Grande fu la sorpresa all'esame microscopieo delle sezioni del pezzo incluso, poiehe r isulto trattarsi di un teratoma costituito in prevalenza da un tessuto a struttura tipicamente nervosa, e contenente inglobata una linfoghiandola ed altre formazioni di cui diremo piu dettagliatamente in seguito (microfotografla 1). Gift CARMINATI (1) aveva avuto occasions di riscontrare un analogo reperto in un ratto, e per quel che mi eonsta non ho trovato altre indicazioni ad eccezione di quanto riferiseono SPERLING H STROCH (2) circa il reperto, riseontrato in vari casi, di rudimenti sottoeutanei di vari apparati a eostituzione pin 0 meno normale (tessuto cerebrale con eirconvoluzioni, cavita ventricolari e plessi eorioidei). Un piu attento esame del tessuto a struttura tipieamente nervosa motte in evidenza che, malgrado la sua alta differenziazione, esso offre quadri richiamanti la citoarehitetturadel normale tessuto nervoso centrale solo in due sedi. In una la struttura ricorda quella delle eirconvoluzioni cerebellari per la presenza di elementi che offrono grande analogia con Ie cellule del PURKINJE, a loro volta confinanti con uno strato di cellule piecole, rotondeggianti, a nucleo rotondo ed intensamente cromofilo, a searso citoplasma che richiama 10 strato dei granuU.",1947,Tumori Journal
Accounting and smart cities: New evidence for governmentality and politics,"The purpose of this study is to explore the ways in which the smart cities agenda has forced the electricity company to reorient its accounting tools. It answers the research question: how smart electricity costs and pricing policies imposed by political decision-makers govern a smart city performance. The question, what is smart city governance, and the purposes for which cities become smart, such as a smart economy, smart mobility, smart environment and smart living, have attracted the attention of a multitude of researchers in recent years (Broccardo, Culasso, & Mauro, 2019; Hollands, 2015). Factors that explain the success and failure of smart cities goals and projects, such as performance measurement (Argento, Grossi, JÃ¤Ã¤skelÃ¤inen, Servalli, & Suomala, 2019; BrorstrÃ¶m, Argento, Grossi, Thomasson, & Almqvist, 2018), public governance (Cowley, Joss, & Dayot, 2018), public accountability (Mizrahi & Minchuk, 2019) and sustainability (Niemann & Hoppe, 2018), are publicly known. Critical case study researches have provided different analytical ways of thinking and acting Abstract",2020,Corporate Ownership and Control
"13.9. Consiglio di Stato, sez. VI, 9 aprile 2009, n. 2197","I Giudici di Palazzo Spada, con la pronuncia in rassegna, forniscono alcune preziose indicazioni al fine di individuare i limiti temporali entro i quali e possibile costituire il deposito cauzionale definitivo. Secondo il disposto dellâ€™art. 113, d.lgs. 163/06 e s.m.i., l'impresa rimasta aggiudicataria di una pubblica gara, comâ€™e noto, deve prestare â€œcauzione definitivaâ€ a favore della Stazione Appaltante, a garanzia di tutti gli obblighi assunti con la firma del contratto dâ€™appalto, per un importo pari al 10% dellâ€™importo dei lavori, servizi o forniture al netto del ribasso dâ€™asta eventualmente offerto. Sennonche, lâ€™art. 113 cit. non indica un preciso termine entro il quale lâ€™affidatario deve prestare la garanzia in parola a favore della Stazione Appaltante, limitandosi, viceversa, a statuire che â€œ Lâ€™esecutore del contratto e obbligato a costituire una garanzia fideiussoria â€¦ â€. Nella fattispecie de qua , la societa aggiudicataria della locazione di un immobile si era vista dichiarare decaduta dallâ€™aggiudicazione, giacche, nonostante fosse stata invitata piu volte dallâ€™Amministrazione a produrre la documentazione necessaria per addivenire alla stipula del contratto di locazione, non aveva fornito alcun riscontro. Successivamente, stante il mancato deposito della quietanza relativa alla prescritta cauzione definitiva, lâ€™Ente Appaltante, dopo aver preso atto delle controdeduzioni dellâ€™aggiudicatario, confermava il provvedimento di decadenza gia adottato. La Societa adiva il Tribunale Amministrativo Regionale per la Campania domandando lâ€™annullamento di tale ultima determinazione, ma il Giudice di prime cure respingeva il ricorso. Avverso la pronuncia di rigetto, veniva proposto formale ricorso in appello innanzi al Supremo Consesso Amministrativo. Orbene, nella sentenza n. 2197 del 2009, i Giudici della Sesta Sezione del Consiglio di Stato rilevano che il notevole lasso di tempo trascorso dalla conclusione della gara e lâ€™assenza di una fattiva collaborazione dellâ€™impresa alla conclusione del contratto giustificano i presupposti per la conferma del provvedimento di decadenza, nonche lâ€™interesse di rilievo pubblico allâ€™annullamento dellâ€™esito della gara. Ed infatti, con precipuo riferimento al caso di specie, sussiste lâ€™imprescindibile esigenza di prevenire ogni danno patrimoniale per il mancato versamento dei canoni di affitto, tutelando lâ€™interesse pubblico di utilizzo del bene di proprieta dellâ€™Ente secondo criteri di economicita e in condizioni vantaggiose per lâ€™Erario. Piu in particolare, il Collegio non manca lâ€™occasione per affermare il principio secondo il quale lâ€™assenza di un termine entro il quale un determinato adempimento deve essere posto in essere non vale a giustificare il ritardo, concretando, invece, lâ€™immediato inadempimento, secondo il noto brocardo latino quod sine die debetur statim debetur . Dal che, la legittimita del provvedimento con il quale la Stazione Appaltante dichiara la decadenza dallâ€™aggiudicazione del concorrente che non abbia tempestivamente provveduto a costituire la cauzione definitiva, con conseguente rigetto del proposto appello. Da ultimo, il Consiglio di Stato, non manca di precisare che proprio la sussistenza di un obbligo immediato, fa si che lâ€™operatore economico aggiudicatario in via definitiva di una pubblica gara debba costituire la garanzia di cui allâ€™art. 113, d.lgs. 163 cit. senza ritardo e, segnatamente, â€œ fin dal momento della ricezione della richiesta formulata con raccomandata,e cio indipendentemente da ogni ulteriore atto di diffida dellâ€™Amministrazione â€.",2009,
A Fixed-point Proximity Approach to Solving the Support Vector Regression with the Group Lasso Regularization,"We introduce an optimization model of the support vector regression with the group lasso regularization and develop a class of efficient two-step fixed-point proximity algorithms to solve it numerically. To overcome the difficulty brought by the non-differentiability of the group lasso regularization term and the loss function in the proposed model, we characterize its solutions as fixed-points of a nonlinear map defined in terms of the proximity operators of the functions appearing in the objective function of the model. We then propose a class of two-step fixedpoint algorithms to solve numerically the optimization problem based on the fixed-point equation. We establish convergence results of the proposed algorithms. Numerical experiments with both synthetic data and real-world benchmark data are presented to demonstrate the advantages of the proposed model and algorithms.",2017,
Congenital long QT syndrome aggravated by salt-wasting nephropathy.,"Abstract Long QT syndrome (LQTS) is characterized by episodes of fainting or by sudden death as a resultof torsades de pointes (TdP). In both the congenital and acquired forms of the syndrome, symptomsoften become manifest upon exposure to additional clinical stressors of repolarization, such as drugsor hypokalemia.We report here the case of a patient with congenital LQTS in a 6-year-old boy who manifestedsymptoms only in the presence of electrolyte abnormalities associated with the inherited salt-wastingrenal disorder Gitelman syndrome. In this case, a second distinct congenital disorder modified theclinical presentation of LQTS. Keywords Congenital long QT syndrome; Gitelman syndrome; Repolarization; Failure Case report The proband is a 6-year-old boy who first presented in March 2002 with a syncopal episodeafter a flu-like illness. At age 3 years, the patient had presented with a viral illness and wasfound to have severe hypokalemia (1.6 mEq/L). Additional clinical evaluation revealed ahistory of lethargy, growth failure, normal blood pressure, hypomagnesemia (0.70 mEq/L),hypocalciuria (12.8 mEq/day), and urinary potassium wasting (94.4 mEq/L). A presumptivediagnosis of Gitelman syndrome, an inherited salt-wasting nephropathy, was made. Thepatientâ€™s growth improved dramatically after potassium and magnesium supplementation wasstarted. However, at age 4 years, the patient began to experience syncopal episodes oftenassociated with intercurrent illnesses and hypokalemia. The short-lived syncopal episodesusually occurred during vigorous play. The patientâ€™s mother (a nurse) described a singleâ€œgaspingâ€ breath followed by apnea, cyanosis, and ashen appearance associated with a â€œveryrapid and irregular pulse.â€ However, an ECG tracing was never successfully recorded duringa syncopal episode. Evaluation at age 6 years after one such episode revealed serum potassium3.2 mEq/L, magnesium 1.9 mEq/L, and prolonged corrected QT interval (QTc) 500 ms (Figure1). Failure of QTc to shorten despite potassium repletion (serum potassium 4.5 mEq/Lassociated with QTc 490 ms) prompted referral of the patient to a cardiologist. The patient had",2005,Heart rhythm
Fast Algorithms and Theory for High-Dimensional Bayesian Varying Coefficient Models,"Nonparametric varying coefficient (NVC) models are widely used for modeling time-varying effects on responses that are measured repeatedly. In this paper, we introduce the nonparametric varying coefficient spike-and-slab lasso (NVC-SSL) for Bayesian estimation and variable selection in NVC models. The NVC-SSL simultaneously estimates the functionals of the significant time-varying covariates while thresholding out insignificant ones. Our model can be implemented using a highly efficient expectation-maximization (EM) algorithm, thus avoiding the computational burden of Markov chain Monte Carlo (MCMC) in high dimensions. In contrast to frequentist NVC models, hardly anything is known about the large-sample properties for Bayesian NVC models. In this paper, we take a step towards addressing this longstanding gap between methodology and theory by deriving posterior contraction rates under the NVC-SSL model when the number of covariates grows at nearly exponential rate with sample size. Finally, we illustrate our methodology through simulation studies and data analysis.",2019,arXiv: Methodology
Evaluating the Risk Factors of Post Inflammatory Hyperpigmentation Complications with Nd-YAG Laser Toning Using LASSO-Based Algorithm,"The neodymium-doped yttrium aluminum garnet (Nd-YAG) laser is used for removal of pigmented skin patches and rejuvenation of skin. However, complications such as hyperpigmentation, hypopigmentation, and petechiae can occur after frequent treatments. Therefore, identifying the risk factors for such complications is important. The development of a multivariable logistic regression model with least absolute shrinkage and selection operator (LASSO) is needed to provide valid predictions about the incidence of post inflammatory hyperpigmentation complication probability (PIHCP) among patients treated with Nd-YAG laser toning. A total of 125 female patients undergoing laser toning therapy between January 2014 and January 2016 were examined for post-inflammatory hyperpigmentation (PIH) complications. Factor analysis was performed using 15 potential predictive risk factors of PIH determined by a physician. The LASSO algorithm with cross-validation was used to select the optimal number of predictive risk factors from the potential factors for a multivariate logistic regression PIH complication model. The optimal number of predictive risk factors for the model was five: immediate endpoints of laser (IEL), Î±-hydroxy acid (AHA) peels, Fitzpatrick skin phototype (FSPT), acne, and melasma. The area under the receiver operating characteristic curve (AUC) was 0.79 (95% CI, 0.70â€“0.88) in the optimal model. The overall performance of the LASSO-based PIHCP model was satisfactory based on the AUC, Omnibus, Nagelkerke R2, and Hosmerâ€“Lemeshow tests. This predictive risk factor model is useful to further optimize laser toning treatment related to PIH. The LASSO-based PIHCP model could be useful for decision-making.",2020,Applied Sciences
Android Malware Detection using Deep Belief Network,"Over the last few years, the Android smartphone had faced attacks from malware and malware variants, as there is no effective commercial Android security framework in the market. Thus, using machine learning algorithms to detect Android malware applications that can fit with the smartphone resources limitations became popular. This paper used state of the art Deep Belief Network in Android malware detection. The Lasso is one of the best interpretable l1-regularisation techniques which proved to be an efficient feature selection embedded in learning algorithm. The selected features subset of Restricted Boltzmann Machines tuned by Harmony Search feature reduction with Deep Belief Network classifier was used, achieving 85.22% Android malware detection accuracy.",2018,
La Computacion En La Educacion Infantil Y Juvenil,"EL DOCTOR MARCO ANTONIO MURRAY LASSO, PRESIDENTE DE LA SOCIEDAD MEXICANA DE COMPUTACION EN LA UNAM QUE ORGANIZA EL IV SIMPOSIO SOBRE ""LA COMPUTACION EN LA EDUCACION INFANTIL Y JUVENIL"" EN CUAL SE TRATARAN TEMAS COMO LA APLICACION DE LA COMPUTACION EN LA EDUCACION PRIMARIA Y MEDIA, LA ENSENANZA DE LA CIENCIA, ENTRE OTROS; DIJO EN CONFERENCIA DE PRENSA, QUE ESTA EPOCA ES LA ERA DE LA INFORMAATICA, PUES EL MUNDO SE ESTA REVOLUCIONANDO CON AL APLICACION DE LA COMPUTADORA EN ACTIVIDADES INTELECTUALES, GUBERNAMENTALES, COMERCIALES Y DE SERVICIOS, DE TAL FORMA, EL SIMPOSION TIENE COMO OBJETIVO PROMOVER EL SERVICIO DE LA MISMA EN LA EDUCACION TEMPRANA, MEDIA Y PROFESIONAL.",1988,
[Prediction of 6-year incidence risk of chronic kidney disease in the elderly aged 65 years and older in 8 longevity areas in China].,"Objective: To establish a prediction model for 6-year incidence risk of chronic kidney disease (CKD) in the elderly aged 65 years and older in China. Methods: In this prospective cohort study, we used the data of 3 742 participants collected during 2008/2009-2014 and during 2012-2017/2018 from Healthy Aging and Biomarkers Cohort Study, a sub-cohort of the Chinese Longitudinal Healthy Longevity Survey. Two follow up surveys for renal function were successfully conducted for 1 055 participants without CKD in baseline survey. Lasso method was used for the selection of risk factors. The risk prediction model of CKD was established by using Cox proportional hazards regression models and visualized through nomogram tool. Bootstrap method (1 000 resample) was used for internal validation, and the performance of the model was assessed by C-index and calibration curve. Results: The mean age of participants was (80.8Â±11.4) years. In 4 797 person years of follow up, CKD was found in 262 participants (24.8%). Age, BMI, sex, education level, marital status, having retirement pension or insurance, hypertension prevalence, blood uric acid, blood urea nitrogen and total cholesterol levels and estimated glomerular filtration rate in baseline survey were used in the model to predict the 6-year incidence risk of CKD in the elderly. The corrected C-index was 0.766, the calibration curve showed good consistence between predicted probability and observed probability in high risk group, but relatively poor consistence in low risk group. Conclusion: The incidence risk prediction model of CKD established in this study has a good performance, and the nomogram can be used as visualization tool to predict the 6-year risk of CKD in the elderly aged 65 years and older in China.",2020,Zhonghua liu xing bing xue za zhi = Zhonghua liuxingbingxue zazhi
Group Lasso-Based Band Selection for Hyperspectral Image Classification,"Band selection plays an important role in reducing the dimensionality of spectral response of hyperspectral images (HSIs) to avoid dimension disaster for land-cover classification. Compared with traditional dimension reduction methods, such as principal component analysis, independent component analysis, or linear discriminant analysis, band selection can help provide interpretability to later constructed models by preserving the physical meaning of selected features. In this letter, a group lasso-based band selection (GLBS) method is proposed for multilabel HSI classification. Using the group lasso algorithm, the two objectives of band selection and classification are implemented simultaneously. The performance of GLBS is fully investigated and compared with benchmark methods, and the experimental results demonstrate the superiority of GLBS.",2017,IEEE Geoscience and Remote Sensing Letters
[Epidemiological and clinical profile of cerebral palsy at the Bobo-dioulasso university hospital (Burkina Faso)].,"INTRODUCTION
Cerebral palsy is the leading cause of motor disability in children.


OBJECTIVE
To describe the epidemiological and clinical profiles of cerebral palsy in children seen at the of Bobo-Dioulasso University Hospital.


POPULATION AND METHODS
This is a descriptive cross-sectional study prospectively conducted at the Department of Physical Medicine at the University Hospital of Bobo-Dioulasso over a period of one year from 1 July 2012 to 30 June 2013. Our study population consisted of all children aged between 0 and 15 years received during the study period displaying cerebral palsy symptoms.


RESULTS
We studied 174 patients including 106 boys and 68 girls. The average age was 32.79 months. Etiological factors were dominated by prematurity (34.5%) and cerebral anoxia (25.86%). The main clinical presentations were diplegia (50%), quadriplegia (19.54%), hemiplegia (14.37%), monoplegia (10.34%) and triplegia (5.75%). The most common associated symptoms were epilepsy (15%), eye disorders (12.6%), and hearing problems (10%).


CONCLUSION
Due to its frequency and disabling potential, cerebral palsy is a major public health problem in Burkina Faso. Its support in the African environment is heavily complicated by self-medication and traditional therapy.",2015,Le Mali medical
Process monitoring research based on sparse principal component analysis,"Principal Component Analysis(PCA)is a multivariate statistical technique, with a range of applications in data processing and dimensionality reduction. Over the past two decades, PCA method has also been widely applied to various kinds of industrial processes for process monitoring and fault diagnosis with some successes. Due to the increasing volumes of data, process monitoring methods which are based on PCA approaches suffer many limitations, such as great calculation loads and poor real-time performance. In this paper, a new method called Sparse Principal Component Analysis(SPCA)is developed in process monitoring, using the lasso(least absolute shrinkage and selection operator)to produce modified principal components with sparse loadings. And the SPCA can be formulated as a regression-type optimization function to achieve the main elements of choice. Furthermore, the fault detection is then performed by a detection index using model parameters, and the sparse principal component analysis is used in the Tennessee Eastman process(TE processes)monitoring for simulations. Compared with the traditional principal component analysis method, this SPCA approach builds a model based on the sparse modeling data. Therefore it can reduce the amount of calculations and improve the real time performance. As the SPCA model is applied to simulate with real data, the results show that it has better effectiveness in TE processes.",2014,Computer Engineering and Applications
"Curved geometries in a transfer zone, Quebrada dei Toro, Salta Province, NW Argentina","Introduction The Quebrada deI Toro, or Toro Canyon, is a first-order geomorphic feature in the Central Andes of northwestern Argentina (Fig. 1). The canyon initia tes at the eastern border of the Puna, near the Santa Rosa de 'l'asti 1Batholith, and descends with a WNW -ESE, then NNW -SSE, orientation, traversing the western half of the Cordillera Oriental up to where it debouches into the structural depression forming the Lerma Valley. The Toro Canyon, to a large extent, follow s the trace of the Toro Lineament, one of the most widely cited geological features in northwestern Argentina, postulated almost simultaneously by Salfity et al. (1975), Baldis et al. (1976), and Mon (1976), and christened by Mon (1976) . The Toro Lineament marks the southern limit for Paleozoic exposures in northwestem Argentina; farther south Mesozoic and Cenozoic strata rest unconformably on metamorphic basement. The Toro Lineament has been compromised in numerous geological hypotheses for northwestern Argentina, such as: (a) that it marks internal boundaries in the Puna and Cordillera Oriental geological provinces (Alonso et al. 1984; Ramos 1999). (b) that it reflects PaJeozoic or older structural features , (c) that it exerted a strong control on Cenozoic magmatism (Petrinovic et al. , 1999,2001; Hongn et al. 2002), (d) that it presently is an active intraplate fault zone, judging from recent seismic events along its trace. There exist, as well, divergent opinions regarding the intensity and timing of tectonic activity of the Toro Lineament: significant activity in the Miocene cornpensating structural shortening of the Andes (Seggiaro y Hongn, 1999), minor activity in the Miocene and a sinistral strike-slip offset of 20 km in the Quaternary (Marrett, 1990; Marrett y Strecker, 2000), and also that its strike-slip behaviour is due to north-south differential shortening of the Andes in the Cenozoic (Riller and Oncken , 2002). The present summary suggests that curved structures associated to the Toro Lineament reflect its activity as a transfer zone. This interpretation is based on a comparison between the mapped structural geometries and simil ar geometries obtained in analogie modelling (Calassou et al., 1993; Baby et al. , 1994).",2005,
Combining clustering of variables and feature selection using random forests: the CoV/VSURF procedure,"High-dimensional data classification is a challenging problem. A standard approach to tackle this problem is to perform variables selection, e.g. using step-wise or LASSO procedures. Another standard way is to perform dimension reduction, e.g. by Â Principal Component Analysis or Partial Least Square procedures. The approach proposed in this paper combines both dimension reduction and variables selection. First, a procedure of clustering of variables is used to built groups of correlated variables in order to reduce the redundancy of information. This dimension reduction step relies on the R package ClustOfVar which can deal with both numerical and categorical variables. Secondly, the most relevant synthetic variables (which are numerical variables summarizing the groups obtained in the first step) are selected with a procedure of variable selection using random forests, implemented in the R package VSURF. Numerical performances of the proposed methodology called CoV/VSURF are compared with direct applications of VSURF or random forests on the original $p$ variables. Improvements obtained with Â the CoV/VSURF Â procedure are illustrated on two simulated mixed datasets (cases $n > p$ and $n < p$) and on a real proteomic dataset.",2016,arXiv: Statistics Theory
Large coronary artery fistula and patent ductus arteriosus: transcatheter closure with three PDA nitinol wire mesh occluders,"Coronary artery fistulas (CAF) are the most common congenital anomaly of this vessel. We present the case of a 26-year-old man with two coexisting congenital cardiac defects: patent ductus arteriosus (PDA) and CAF. The patient 3 months earlier had the transcatheter PDA closed (type A, diameter 4 mm) with a 10/8 mm PDA nitinol wire mesh occluder. After the procedure he continued to have symptoms of fatigue and continuous murmur in the precordial region persisted. In angio-CT a large coronary fistula from the circumflex coronary artery with suspicion of multiple orifices to the right atrium was found. An arteriovenous wire loop was created (guidewire introduced from the aorta through the CAF was snared using a lasso catheter in the superior vena cava and exteriorized through the right femoral vein). Retrogradely an 8 F long sheath and delivery system was introduced to the end of the fistula and a 12/10 mm Cardio-O-Fix PDA occluder (Starway Comp, China, Beijing) was implanted, closing one orifice of the CAF. Another leak (orifice of CAF - 3.5 mm diameter) was closed using a similar technique with a 10/8 mm PDA Cardio-O-Fix device. Complete closure of the coronary artery fistula and disappearance of the heart murmur were observed after the procedure. The patient was discharged home 4 days later on acetylsalicylic acid 150 mg/day. During 6 months of follow-up he was doing well without any complaints or pathological symptoms. In control angio-CT performed 3 months after the procedure complete closure of the CAF was confirmed.",2013,PostÄ™py w Kardiologii Interwencyjnej = Advances in Interventional Cardiology
Choosing Clinical Variables for Risk Stratification Post-Acute Coronary Syndrome,"Most risk stratification methods use expert opinion to identify a fixed number of clinical variables that have prognostic significance. In this study our goal was to develop improved metrics that utilize a variable number of input parameters. We first used Bootstrap Lasso Regression (BLR) â€“ a Machine Learning method for selecting important variables â€“ to identify a prognostic set of features that identify patients at high risk of death 6-months after presenting with an Acute Coronary Syndrome. Using data derived from the Global Registry of Acute Coronary Events (GRACE) we trained a logistic regression model using these features and evaluated its performance on a development set (Nâ€‰=â€‰43,063) containing patients who have values for all features, and a separate dataset (Nâ€‰=â€‰6,363) that contains patients who have missing feature values. The final model, Ridge Logistic Regression with Variable Inputs (RLRVI), uses imputation to estimate values for missing features. BLR identified 19 features, 8 of which appear in the GRACE score. RLRVI had modest, yet statistically significant, improvement over the standard GRACE score on both datasets. Moreover, for patients who are relatively low-risk (GRACEâ‰¤87), RLRVI had an AUC and Hazard Ratio of 0.754 and 6.27, respectively, vs. 0.688 and 2.46 for GRACE, (pâ€‰<â€‰0.007). RLRVI has improved discriminatory performance on patients who have values for the 8 GRACE features plus any subset of the 11 non-GRACE features. Our results demonstrate that BLR and data imputation can be used to obtain improved risk stratification metrics, particularly for patients who are classified as low risk using traditional methods.",2019,Scientific Reports
Experience with the IEEE Reliability Test System,"within the range used in this investigation. This is referred [4] H. Leon Harter, Albert H. Moore, ""Use of order statistics in to as the Guaranteed Minimum Relative Efficiency. For iterative maximum likelihood estimation of the parameters of Gamma and Weibull populations"", Technometrics, vol 7, 1965, pp sample size 8 the procedure using MLE-KURT as an initial 639-643. estimator tends to give the best estimates in terms of [5] L. F. Knusel, ""Uber minimum-distance-schatzunger"". Published relative s-efficiency for the location and shape parameters. PhD Thesis, Swiss Federal Institute of Technology, 1969. For relatively large sample sizes, the table suggests that the [61 William C. Parr, William R. Schucany, ""Minimum distance and kurtosis discriminant is of no benefit, however, the robust estimation"", J. American StatilsticalAssoc., vol 75, 1980, pp distance estimates for location and shape are useful. 616-624. [7] William J. Rey. Robust Statistical Methods. Springer-Verlag. Table III summarizes the data still further. This table [8] M. A. Stephens, ""EDF statistics for goodness of fit and some comportrays the maximum Guaranteed Minimum Relative Efparisons"". J. American Statistical Assoc., vol 69, 1974, pp 730-737. ficiency obtained for each sample size over the range of [91 J. Wolfowitz, ""The minimum distance method"", Annals shape parameters and identifies the procedure that gave Mathematical Statistics, vol 28, 1957, pp 75-88. that maxi m v e. t[10] J. Wolfowitz, ""Estimation by the minimum distance method"", Anthat maximum value. It iS evident from this table that the kurtosis as a discriminant and the Anderson-Darling nals Inst. Statistical Mathematics, vol 5, 1953, pp 9-23.",1984,IEEE Transactions on Reliability
Dissecting the maturation steps of the lasso peptide microcin J25 in vitro.,"Microcin J25 is the archetype of a growing class of bacterial ribosomal peptides possessing a knotted topology (lasso peptides). It consists of an eight-residue macrolactam ring through which the C-terminal tail is threaded. It is biosynthesized as a precursor that is processed by two maturation enzymes (McjB/McjC). Insights into the mechanism of microcin J25 biosynthesis have been provided previously by mutagenesis of the precursor peptide in vivo. In this study we have demonstrated distinct functions of McjB and McjC in vitro for the first time, based on the detection of reaction intermediates. McjB was characterized as a new ATP-dependent cysteine protease, whereas McjC was confirmed to be a lactam synthetase. The two enzymes were functionally interdependent, likely forming a structural complex. Their substrate preference was directly investigated with the aid of mutated precursor peptides. Depending on the substitutions, microcin J25 variants with either a lasso or branched-cyclic topology could be generated in vitro.",2012,Chembiochem : a European journal of chemical biology
Food Provisioning in Relation to Reproductive Strategy in Altricial Birds: a Comparison of Two Hypotheses,"1988. The evolution of large body size in females: a critique of Darwin's ""fecundity advantage"" model. American Naturalist 131:124-131. --. 1989. Ecological causes for the evolution of sexual dimorphism: a review ofthe evidence. Quarterly Review of Biology 64:419-464. --. 1990. Proximate determinants of sexual differences in adult body size. American Naturalist 135:278-283. --. 1991. Intersexual dietary divergence and the evolution of sexual dimorphism in snakes. American Naturalist 138:103-122. Stille, B., T. Madsen, and M. Niklasson. 1986. Mul-",1994,Evolution
Deciphering N6-Methyladenosine-Related Genes Signature to Predict Survival in Lung Adenocarcinoma,"Lung cancer is the most commonly diagnosed cancer and the leading cause of cancer-related death. Among these, lung adenocarcinoma (LUAD) accounts for most cases. Due to the improvement of precision medicine based on molecular characterization, the treatment of LUAD underwent significant changes. With these changes, the prognosis of LUAD becomes diverse. N6-methyladenosine (m6A) is the most predominant modification in mRNAs, which has been a research hotspot in the field of oncology. Nevertheless, little has been studied to reveal the correlations between the m6A-related genes and prognosis in LUAD. Thus, we conducted a comprehensive analysis of m6A-related gene expressions in LUAD patients based on The Cancer Genome Atlas (TCGA) database by revealing their relationship with prognosis. Different expressions of the m6A-related genes in tumor tissues and non-tumor tissues were confirmed. Furthermore, their relationship with prognosis was studied via Consensus Clustering Analysis, Principal Components Analysis (PCA), and Least Absolute Shrinkage and Selection Operator (LASSO) Regression. Based on the above analyses, a m6A-based signature to predict the overall survival (OS) in LUAD was successfully established. Among the 479 cases, we found that most of the m6A-related genes were differentially expressed between tumor and non-tumor tissues. Six genes, HNRNPC, METTL3, YTHDC2, KIAA1429, ALKBH5, and YTHDF1 were screened to build a risk scoring signature, which is strongly related to the clinical features pathological stages (p < 0.05), M stages (p < 0.05), T stages (pâ€‰<â€‰0.05), gender (p = 0.04), and survival outcome (p = 0.02). Multivariate Cox analysis indicated that risk value could be used as an independent prognostic factor, revealing that the m6A-related genes signature has great predictive value. Its efficacy was also validated by data from the Gene Expression Omnibus (GEO) database.",2020,BioMed Research International
Analisi di vulnerabilitÃ  sismica della chiesa di San Giovanni in Avigliana = Seismic vulnerability analysis of the church San Giovanni in Avigliana,"Analisi della chiesa di San Giovanni in Avigliana, valutazione delle caratteristiche della muratura, dei moltiplicatori di collasso ed analisi globale agli elementi finiti",2018,
High density microelectrode recording predicts span of therapeutic tissue activation volumes in subthalamic deep brain stimulation for Parkinson disease,"BACKGROUND
Subthalamic deep brain stimulation alleviates motor symptoms of Parkinson disease by activating precise volumes of neural tissue. While electrophysiological and anatomical correlates of clinically effective electrode sites have been described, therapeutic stimulation likely acts through multiple distinct neural populations, necessitating characterization of the full span of tissue activation. Microelectrode recordings have yet to be mapped to therapeutic tissue activation volumes and surveyed for predictive markers.


OBJECTIVE
Combine high-density, broadband microelectrode recordings with detailed computational models of tissue activation to describe and to predict regions of therapeutic tissue activation.


METHODS
Electrophysiological features were extracted from microelectrode recordings along 23 subthalamic deep brain stimulation implants in 16 Parkinson disease patients. These features were mapped in space against tissue activation volumes of therapeutic stimulation, modeled using clinically-determined stimulation programming parameters and fully individualized, atlas-independent anisotropic tissue properties derived from 3T diffusion tensor magnetic resonance images. Logistic LASSO was applied to a training set of 17 implants out of the 23 implants to identify predictors of therapeutic stimulation sites in the microelectrode recording. A support vector machine using these predictors was used to predict therapeutic activation. Performance was validated with a test set of six implants.


RESULTS
Analysis revealed wide variations in the distribution of therapeutic tissue activation across the microelectrode recording-defined subthalamic nucleus. Logistic LASSO applied to the training set identified six oscillatory predictors of therapeutic tissue activation: theta, alpha, beta, high gamma, high frequency oscillations (HFO, 200-400Â Hz), and high frequency band (HFB, 500-2000Â Hz), in addition to interaction terms: theta x HFB, alpha x beta, beta x HFB, and high gamma x HFO. A support vector classifier using these features predicted therapeutic sites of activation with 64% sensitivity and 82% specificity in the test set, outperforming a beta-only classifier. A probabilistic predictor achieved 0.87 area under the receiver-operator curve with test data.


CONCLUSIONS
Together, these results demonstrate the importance of personalized targeting and validate a set of microelectrode recording signatures to predict therapeutic activation volumes. These features may be used to improve the efficiency of deep brain stimulation programming and highlight specific neural oscillations of physiological importance.",2019,Brain stimulation
Sparse exponential discriminant analysis,"Exponential discriminant analysis (EDA), which solves the singularity problem of the conventional linear discriminant analysis (LDA) using diffusion mapping, has been wildly used in dealing with supervised classification and dimensionality reduction problems for its simplicity and robustness. However, the discriminant rules of the EDA algorithm involve a linear combination of all features, thus may result in poor model interpretability and inaccurate classification performance. In this paper, a sparse exponential discriminant analysis (SEDA) algorithm is proposed for addressing those issues. The SEDA algorithm is developed by introducing the lasso penalty into the EDA algorithm, so that it can select the key features to improve the discriminant performance and discard the features with little significance to simplify the discriminant model. To solve the non-convex SEDA model, it is recast as an iterative convex optimization problem using the monorization-maximization (MM) algorithm, and the optimization problem is finally solved using tools from convex optimization. The SEDA algorithm is tested with two famous classification datasets, and the experimental results illustrate the model interpretability and discriminant performance of the proposed SEDA algorithm.",2017,2017 36th Chinese Control Conference (CCC)
In-process complex machining condition monitoring based on deep forest and process information fusion,"Abnormal machining condition causes losses of quality for finished part. A machining condition monitoring system is considerably vital in the intelligent manufacturing process. Existing machining condition monitoring methods usually detect only one single abnormal condition under the same machining process, which is unrealistic and impractical for real complicated machining process. In this paper, a novel hybrid condition monitoring approach for multiple abnormal conditionsâ€™ detection of complicated machining process by using deep forest and multi-process information fusion is proposed. First, various process data are obtained from a triaxial accelerometer and a sound sensor mounted on the spindle of CNC. Then, the time domain, frequency domain, and time-frequency domain features extracted from the multiple sensory signals are simultaneously optimized to select a subset with key features by the lasso technique. Furthermore, deep forest is utilized as a condition classifier by using the selected features. Finally, cutting experiments are designed and conducted, and the results show that the proposed method can effectively detect the multiple abnormal conditions under the different machining parameters.",2019,The International Journal of Advanced Manufacturing Technology
Estimating time-varying brain connectivity networks from functional MRI time series,"At the forefront of neuroimaging is the understanding of the functional architecture of the human brain. In most applications functional networks are assumed to be stationary, resulting in a single network estimated for the entire time course. However recent results suggest that the connectivity between brain regions is highly non-stationary even at rest. As a result, there is a need for new brain imaging methodologies that comprehensively account for the dynamic nature of functional networks. In this work we propose the Smooth Incremental Graphical Lasso Estimation (SINGLE) algorithm which estimates dynamic brain networks from fMRI data. We apply the proposed algorithm to functional MRI data from 24 healthy patients performing a Choice Reaction Task to demonstrate the dynamic changes in network structure that accompany a simple but attentionally demanding cognitive task. Using graph theoretic measures we show that the properties of the Right Inferior Frontal Gyrus and the Right Inferior Parietal lobe dynamically change with the task. These regions are frequently reported as playing an important role in cognitive control. Our results suggest that both these regions play a key role in the attention and executive function during cognitively demanding tasks and may be fundamental in regulating the balance between other brain regions.",2014,NeuroImage
Simultaneous support recovery in high dimensions : Benefits and perils of block l 1 / l âˆž-regularization,"Given a collection of r â‰¥ 2 linear regression problems in p dimensions, suppose that the regression coefficients share partially common supports of size at most s. This set-up suggests the use of l1/lâˆž-regularized regression for joint estimation of the p Ã— r matrix of regression coefficients. We analyze the high-dimensional scaling ofl1/lâˆž-regularized quadratic programming, considering both consistency rates in lâˆž-norm, and how the minimal sample size n required for consistent variable selection scales with model dimension, sparsity, and overlap between the supports. We first establish bounds on thelâˆž-error as well sufficient conditions for exact variable selection for fixed design matrices, as well as for designs drawn randomly from general Gaussian distributions. Specializing to the caser = 2 linear regression problems with standard Gaussian designs whose supports overlap in a fraction Î± âˆˆ [0, 1] of their entries, we prove that l1/lâˆž-regularized method undergoes a phase transition characterized by the rescaled sample size Î¸1,âˆž(n, p, s, Î±) = n/{(4 âˆ’ 3Î±)s log(p âˆ’ (2 âˆ’ Î±) s)}. An implication is that the use ofl1/lâˆž-regularization yields improved statistical efficiency if the overlap parameter is large enough ( Î± > 2/3), but has worse statistical efficiency than a naive Lasso-based approach for moderate to small overlap (Î± < 2/3). Empirical simulations illustrate the close agreement between theory and actual behavior in practice. These results show that caution must be exercised in applyingl1/lâˆž block regularization: if the data does not match its structure very closely, it can impair statistical performance relative to computationally less expensive schemes.",2009,
Improving survival prediction using a novel feature selection and feature reduction framework based on the integration of clinical and molecular data.,"The accurate prediction of a cancer patient's risk of progression or death can guide clinicians in the selection of treatment and help patients in planning personal affairs. Predictive models based on patient-level data represent a tool for determining risk. Ideally, predictive models will use multiple sources of data (e.g., clinical, demographic, molecular, etc.). However, there are many challenges associated with data integration, such as overfitting and redundant features. In this paper we aim to address those challenges through the development of a novel feature selection and feature reduction framework that can handle correlated data. Our method begins by computing a survival distance score for gene expression, which in combination with a score for clinical independence, results in the selection of highly predictive genes that are non-redundant with clinical features. The survival distance score is a measure of variation of gene expression over time, weighted by the variance of the gene expression over all patients. Selected genes, in combination with clinical data, are used to build a predictive model for survival. We benchmark our approach against commonly used methods, namely lasso- as well as ridge-penalized Cox proportional hazards models, using three publicly available cancer data sets: kidney cancer (521 samples), lung cancer (454 samples) and bladder cancer (335 samples). Across all data sets, our approach built on the training set outperformed the clinical data alone in the test set in terms of predictive power with a c.Index of 0.773 vs 0.755 for kidney cancer, 0.695 vs 0.664 for lung cancer and 0.648 vs 0.636 for bladder cancer. Further, we were able to show increased predictive performance of our method compared to lasso-penalized models fit to both gene expression and clinical data, which had a c.Index of 0.767, 0.677, and 0.645, as well as increased or comparable predictive power compared to ridge models, which had a c.Index of 0.773, 0.668 and 0.650 for the kidney, lung, and bladder cancer data sets, respectively. Therefore, our score for clinical independence improves prognostic performance as compared to modeling approaches that do not consider combining non-redundant data. Future work will concentrate on optimizing the survival distance score in order to achieve improved results for all types of cancer.",2020,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
A Communication-Efficient Parallel Method for Group-Lasso,"Group-Lasso (gLasso) identifies important explanatory factors in predicting the response variable by considering the grouping structure over input variables. However, most existing algorithms for gLasso are not scalable to deal with large-scale datasets, which are becoming a norm in many applications. In this paper, we present a divide-and-conquer based parallel algorithm (DC-gLasso) to scale up gLasso in the tasks of regression with grouping structures. DC-gLasso only needs two iterations to collect and aggregate the local estimates on subsets of the data, and is provably correct to recover the true model under certain conditions. We further extend it to deal with overlappings between groups. Empirical results on a wide range of synthetic and real-world datasets show that DC-gLasso can significantly improve the time efficiency without sacrificing regression accuracy.",2016,ArXiv
A Unified Variable Selection Approach for Varying Coefficient Models,"In varying coefficient models, three types of variable selection problems are of practical interests: separation of varying and constant effects, selection of variables with nonzero varying effects, and selection of variables with nonzero con- stant effects. Existing variable selection methods in the literature often focus on only one of the three types. In this paper, we develop a unified variable selection approach for both least squares regression and quantile regression models with pos- sibly varying coefficients. The developed method is carried out by using a two-step iterative procedure based on basis expansion and a double adaptive-LASSO-type penalty. Under some regularity conditions, we show that the proposed procedure is consistent in both variable selection and the separation of varying and constant coefficients. In addition, the estimated varying coefficients possess the optimal con- vergence rate under the same smoothness assumption, and the estimated constant coefficients have the same asymptotic distribution as their counterparts obtained when the true model is known. Finally, we investigate the finite sample perfor- mance of the proposed method through a simulation study and the analysis of the Childhood Malnutrition Data in India.",2012,Statistica Sinica
Prevalence of Group B Streptococcus among Pregnant Women in Bobo-Dioulasso (Burkina Faso),"Background: Group B Streptococcus (GBS) or Streptococcus agalactiae, which asymptomatically colonizes the female genital tract, is one of the leading causes of septicemia, meningitis and pneumonia in neonates. This study was conducted in Bobo Dioulasso, Burkina Faso to determine the prevalence of GBS colonization among pregnant women. Methods: Six hundred and eleven (611) pregnant women were screened for GBS colonization between July and December 2016. Vaginal swab samples were aseptically collected from the subjects after oral informed consent. Standard microbiological methods were used to isolate and identify GBS isolates. The antibiotic susceptibility profile of GBS isolates was assessed using the Kirby-Bauer disk diffusion method. Results: Colonization prevalence was 6.05%. No risk factors associated with the carriage rate was statistically identified. All isolates were susceptible to Amoxicillin, Ampicillin, Cefotaxime, Levofloxacin, Vancomycin and Nitrofurantoin. Resistance to antibiotics was found for erythromycin (35.14%), lincomycin (16.22%) and penicillin G (10.81%). Conclusion: Although a low carriage (6.05%) rate and isolates were susceptible to many antibiotics found in this study, a policy of systematic screening of pregnant women at least in the third trimester must be promoted.",2019,Open Journal of Medical Microbiology
Heterogeneous structural breaks in panel data models,"This paper develops a new model and a new estimation procedure for panel data that allow us to identify heterogeneous structural breaks. In many applications, there are good reasons to suspect that structural breaks occur at different time points across individual units and the sizes of the breaks differ too. We model individual heterogeneity using a grouped pattern such that individuals within a given group share the same regression coefficients. For each group, we allow common structural breaks in the coefficients, while the number of breaks, the break points, and the size of breaks can differ across groups. To estimate the model, we develop a hybrid procedure of the grouped fixed effects approach and adaptive group fused Lasso (least absolute shrinkage and selection operator). We show that our method can consistently identify the latent group structure, detect structural breaks, and estimate the regression parameters. Monte Carlo results demonstrate a good performance of the proposed method in finite samples. We apply our method to two cross-country empirical studies and illustrate the importance of taking heterogeneous structural breaks into account.",2018,arXiv: Econometrics
Ã‰laboration et caractÃ©risations physicochimiques d'une nouvelle membrane de dialyse par adsorption de nanocouches de polyÃ©lectrolytes inverses,"Resume Ce travail participe a l'amelioration de la selectivite et de l'adaptabilite au milieu d'etude d'une membrane de dialyse en poly(acrylonitrile-co-methallyl sulfonate), plus communement appelee AN69. Nous avons procede a des modifications de la surface de cette membrane par adsorption d'un polyelectrolyte cationique, le chlorure de poly(diallyldimethylammonium), note PDADMA. Les modifications physicochimiques de la membrane AN69 sont suivies par differents outils. La determination des nombres de transport de Li+ est realisee a partir de mesures de potentiels de membrane, la selectivite vis-a-vis des sels (LiCl, NaCl, KCl, CaCl2 et MgCl2) par des mesures directes de flux de diffusion. Les changements de permeabilite hydraulique sont evalues par des mesures de flux de solvant, a differentes pressions transmembranaires. Enfin, les modifications de charge de surface sont evaluees par des mesures de potentiel d'ecoulement effectuees grÃ¢ce a une nouvelle cellule de mesure, presentee dans cet article pour la premiere fois. Nos travaux montrent que l'adsorption du polyelectrolyte sur la surface de la membrane est essentiellement due a des interactions electrostatiques et ne peut etre decrochee que dans une solution concentree de chlorure de sodium (>Â 2Â mol/L). Par ailleurs, nous avons mis au point un protocole qui permet d'eliminer facilement un film adsorbe de PDADMA ayant vieilli et ouvert la possibilite de son renouvellement par un film frais, sans changement du support constitue par l'AN69. Cette nouvelle approche de la modification Â«Â non permanenteÂ Â» des surfaces de membranes de dialyse ouvre de grandes possibilites pour la realisation d'une meilleure adaptabilite des materiaux de filtration au milieu d'etude. De plus, la membrane ainsi modifiee voit sa selectivite changer. Ainsi, pour la membrane AN69 initiale, l'ordre de passage des ions etudies estÂ : Ca 2+ > Mg 2+ > Na + > K + > Li + , alors qu'apres impregnation pendant 18Â h dans le PDADMA, cet ordre devientÂ : K + > Ca 2+ > Na + > Li + > Mg 2+ . Ce changement de selectivite si marque permet d'envisager la possibilite de preparer, par simple dialyse, a partir de la ressource eau de mer, des solutions salines de composition variables, pouvant interesser les centres de thalassotherapies et la sante humaine. Pour citer cet articleÂ : M. Pontie et al., C. R. Chimie 08 (2005).",2005,Comptes Rendus Chimie
pre: An R Package for Fitting Prediction Rule Ensembles,"Prediction rule ensembles (PREs) are sparse collections of rules, offering highly interpretable regression and classification models. This paper presents the R package pre, which derives PREs through the methodology of Friedman and Popescu (2008). The implementation and functionality of package pre is described and illustrated through application on a dataset on the prediction of depression. Furthermore, accuracy and sparsity of PREs is compared with that of single trees, random forest and lasso regression in four benchmark datasets. Results indicate that pre derives ensembles with predictive accuracy comparable to that of random forests, while using a smaller number of variables for prediction.",2017,
Graphical Lasso for High-dimensional Complex Gaussian Graphical Model Selection,"We consider the problem of infemng the conditional independence graph (CIG) of both proper and improper, complex-valued, high- dimensional multivariate Gaussian vectors. A $p$-variate complex Gaussian graphical model (CGGM) associated with an undirected graph with $p$ vemces is defined as the family of complex Gaussian distributions that obey the conditional independence restrictions im- plied by the edge set of the graph. For real random vectors, consider- able body of work exists, whereas that on proper complex Gaussian graphical models (PCGGMs) is sparse, while that on ICGGMs is non-existent. In this paper, we present a graphical lasso based penal- ized log-likelihood approach for both PCGGMs and ICGGMs. An alternating minimization algorithm is used to optimize the objective functions. Numerical examples illustrate the proposed algorithms.",2019,"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Protocoled procedure in fMRI studies in epilepsy patients in clinical practice,"Poster: ""ECR 2017 / C-1292 / Protocoled procedure in fMRI studies in epilepsy patients in clinical practice Â "" by: ""V. Sanchez Sanchez, C. GARRIDO, A. Martin Lenero, G. LASSO, S. PINEDA, M. Soto Garcia, S. SOTES, M. FABREGAT, N. Bargallo Alabart; Barcelona/ES""",2016,
On Model Selection Consistency of the Elastic Net When p >> n,"We study the model selection property of the Elastic Net. In the classical settings when p (the number of predictors) and q (the number of predictors with non-zero coefficients in the true linear model) are fixed, Yuan and Lin (2007) give a necessary and sufficient condition for the Elastic Net to consistently select the true model. They showed that it consistently selects the true model if and only if there exist suitable sequences â€š1(n) and â€š2(n) that satisfy EIC (which is defined later in the paper). Here we study the general case when p;q, and n all go to infinity. For general scalings of p;q, and n, when gaussian noise is assumed, sufficient conditions are given such that EIC guarantees the Elastic Net's model selection consistency. We show that to make these conditions hold, n should grow at a rate faster than q log(p âˆ’q). We compare the variable selection performance of the Elastic Net with that of the Lasso. Through theoretical results and simulation studies, we provide insights into when the Elastic Net can consistently select the true model even when the Lasso cannot. We also point out through examples that when the Lasso cannot select the true model, it is very likely that the Elastic Net cannot select the true model either.",2008,
Development and Validation of Machine Learning Algorithms for Predicting Adverse Events Following Surgery for Lumbar Degenerative Spondylolisthesis.,"INTRODUCTION
Preoperative prognostication of adverse events (AEs) for patients undergoing surgery for lumbar degenerative spondylolisthesis (LDS) can improve risk stratification and help guide the surgical decision-making process. The aim of this study was to develop and validate a set of predictive variables for 30-day AEs following surgery for LDS.


METHODS
The American College of Surgeons National Surgical Quality Improvement Program (NSQIP) was used for this study (2005-2016). Logistic regression (enter, stepwise and forward) and least absolute shrinkage and selection operator (LASSO) methods were performed to identify and select variables for analyses, which resulted in 26 potential models. The final model was selected based upon clinical criteria and numerical results.


RESULTS
The overall 30-day rate of AEs for 80,610 patients who underwent surgery for LDS in this database was 4.9% (n=3,965). The median age of the cohort was 58.0 years (range, 18-89 years). The model with the following 10-predictive factors: age, gender, American Society of Anesthesiologists grade, autogenous iliac bone graft, instrumented fusion, levels of surgery, surgical approach, functional status, preoperative serum albumin (g/dl) and serum alkaline phosphatase (IU/L) performed well on the discrimination, calibration, Brier score and decision analyses to develop machine learning algorithms. Logistic regression showed higher AUCs than LASSO methods across the different models. The predictive probability derived from the best model is uploaded on an open access web application which can be found at: https://spine.massgeneral.org/drupal/Lumbar-Degenerative-AdverseEvents CONCLUSION: It is feasible to develop machine learning algorithms from large datasets to provide useful tools for patient-counseling and surgical risk assessment.",2020,World neurosurgery
Subgroup identification in clinical trials via the predicted individual treatment effect,"Identifying subgroups of treatment responders through the different phases of clinical trials has the potential to increase success in drug development. Recent developments in subgroup analysis consider subgroups that are defined in terms of the predicted individual treatment effect, i.e. the difference between the predicted outcome under treatment and the predicted outcome under control for each individual, which in turn may depend on multiple biomarkers. In this work, we study the properties of different modelling strategies to estimate the predicted individual treatment effect. We explore linear models and compare different estimation methods, such as maximum likelihood and the Lasso with and without randomized response. For the latter, we implement confidence intervals based on the selective inference framework to account for the model selection stage. We illustrate the methods in a dataset of a treatment for Alzheimer disease (normal response) and in a dataset of a treatment for prostate cancer (survival outcome). We also evaluate via simulations the performance of using the predicted individual treatment effect to identify subgroups where a novel treatment leads to better outcomes compared to a control treatment.",2018,PLoS ONE
Performance of a blockwise approach in variable selection using linkage disequilibrium information,"BackgroundGenome-wide association studies (GWAS) aim at finding genetic markers that are significantly associated with a phenotype of interest. Single nucleotide polymorphism (SNP) data from the entire genome are collected for many thousands of SNP markers, leading to high-dimensional regression problems where the number of predictors greatly exceeds the number of observations. Moreover, these predictors are statistically dependent, in particular due to linkage disequilibrium (LD).We propose a three-step approach that explicitly takes advantage of the grouping structure induced by LD in order to identify common variants which may have been missed by single marker analyses (SMA). In the first step, we perform a hierarchical clustering of SNPs with an adjacency constraint using LD as a similarity measure. In the second step, we apply a model selection approach to the obtained hierarchy in order to define LD blocks. Finally, we perform Group Lasso regression on the inferred LD blocks. We investigate the efficiency of this approach compared to state-of-the art regression methods: haplotype association tests, SMA, and Lasso and Elastic-Net regressions.ResultsOur results on simulated data show that the proposed method performs better than state-of-the-art approaches as soon as the number of causal SNPs within an LD block exceeds 2. Our results on semi-simulated data and a previously published HIV data set illustrate the relevance of the proposed method and its robustness to a real LD structure. The method is implemented in the R package BALD (Blockwise Approach using Linkage Disequilibrium), available from http://www.math-evry.cnrs.fr/publications/logiciels.ConclusionsOur results show that the proposed method is efficient not only at the level of LD blocks by inferring well the underlying block structure but also at the level of individual SNPs. Thus, this study demonstrates the importance of tailored integration of biological knowledge in high-dimensional genomic studies such as GWAS.",2015,BMC Bioinformatics
NASA Awards Laboratory Support Services and Operations Contract,"NASA has awarded the Laboratory Support Services and Operations (LASSO) contract at the agencyâ€™s Kennedy Space Center in Florida to URS Federal Services Inc., an AECOM company, of Germantown, Maryland.",2017,
The Potential of Radiomics Nomogram in Non-invasively Prediction of Epidermal Growth Factor Receptor Mutation Status and Subtypes in Lung Adenocarcinoma,"Purpose: Up to 50% of Asian patients with NSCLC have EGFR gene mutations, indicating that selecting eligible patients for EGFR-TKIs treatments is clinically important. The aim of the study is to develop and validate radiomics-based nomograms, integrating radiomics, CT features and clinical characteristics, to non-invasively predict EGFR mutation status and subtypes. Materials and Methods: We included 637 patients with lung adenocarcinomas, who performed the EGFR mutations analysis in the current study. The whole dataset was randomly split into a training dataset (n = 322) and validation dataset (n = 315). A sub-dataset of EGFR-mutant lesions (EGFR mutation in exon 19 and in exon 21) was used to explore the capability of radiomic features for predicting EGFR mutation subtypes. Four hundred seventy-five radiomic features were extracted and a radiomics sore (R-score) was constructed by using the least absolute shrinkage and selection operator (LASSO) regression in the training dataset. A radiomics-based nomogram, incorporating clinical characteristics, CT features and R-score was developed in the training dataset and evaluated in the validation dataset. Results: The constructed R-scores achieved promising performance on predicting EGFR mutation status and subtypes, with AUCs of 0.694 and 0.708 in two validation datasets, respectively. Moreover, the constructed radiomics-based nomograms excelled the R-scores, clinical, CT features alone in terms of predicting EGFR mutation status and subtypes, with AUCs of 0.734 and 0.757 in two validation datasets, respectively. Conclusions: Radiomics-based nomogram, incorporating clinical characteristics, CT features and radiomic features, can non-invasively and efficiently predict the EGFR mutation status and thus potentially fulfill the ultimate purpose of precision medicine. The methodology is a possible promising strategy to predict EGFR mutation subtypes, providing the support of clinical treatment scenario.",2019,Frontiers in Oncology
Hierarchical patch dynamics and animal movement pattern,"In hierarchical patch systems, small-scale patches of high density are nested within large-scale patches of low density. The organization of multiple-scale hierarchical systems makes non-random strategies for dispersal and movement particularly important. Here, we apply a new method based on first-passage time on the pathway of a foraging seabird, the Antarctic petrel (Thalassoica antarctica), to quantify its foraging pattern and the spatial dynamics of its foraging areas. Our results suggest that Antarctic petrels used a nested search strategy to track a highly dynamic hierarchical patch system where small-scale patches were congregated within patches at larger scales. The birds searched for large-scale patches by traveling fast and over long distances. Once within a large-scale patch, the birds concentrated their search to find smaller scale patches. By comparing the pathway of different birds we were able to quantify the spatial scale and turnover of their foraging areas. On the largest scale we found foraging areas with a characteristic scale of about 400Â km. Nested within these areas we found foraging areas with a characteristic scale of about 100Â km. The large-scale areas disappeared or moved within a time frame of weeks while the nested small-scale areas disappeared or moved within days. Antarctic krill (Euphausia superba) is the dominant food item of Antarctic petrels and we suggest that our findings reflect the spatial dynamics of krill in the area.",2006,Oecologia
Detecting associations of rare variants with common diseases: collapsing or haplotyping?,"In recent years, a myriad of new statistical methods have been proposed for detecting associations of rare single-nucleotide variants (SNVs) with common diseases. These methods can be generally classified as 'collapsing' or 'haplotyping' based. The former is the predominant class, composed of most of the rare variant association methods proposed to date. However, recent works have suggested that haplotyping-based methods may offer advantages and can even be more powerful than collapsing methods in certain situations. In this article, we review and compare collapsing- versus haplotyping-based methods/software in terms of both power and type I error. For collapsing methods, we consider three approaches: Combined Multivariate and Collapsing, Sequence Kernel Association Test and Family-Based Association Test (FBAT): the first two are population based and are among the most popular; the last test is family based, a modification from the popular FBAT to accommodate rare SNVs. For haplotyping-based methods, we include Logistic Bayesian Lasso (LBL) for population data and family-based LBL (famLBL) for family (trio) data. These two methods are selected, as they can be used to test association for specific rare and common haplotypes. Our results show that haplotype methods can be more powerful than collapsing methods if there are interacting SNVs leading to larger haplotype effects. Even if only common SNVs are genotyped, haplotype methods can still detect specific rare haplotypes that tag rare causal SNVs. As expected, family-based methods are robust, whereas population-based methods are susceptible, to population substructure. However, the population-based haplotype approach appears to have smaller inflation of type I error than its collapsing counterparts.",2015,Briefings in bioinformatics
Correction model for the temperature of numerical weather prediction by SVM,"In order to improve the accuracy of numerical weather prediction(NWP) temperature, a support vector machine (SVM) model based on LASSO feature analysis is proposed to revise the predicted temperature for the next 12 hours. In this paper, high-resolution mode prediction data that include 2m temperature and related meteorological factors forecasted by the European Center of Medium range Weather Forecast ( ECMWF) , and the temperature data of the automatic stations in East China and coastal areas provided by the Shanghai Meteorological Bureau are used to build the proposed model. , In this paper, The results show that the root mean square error, absolute error and accuracy are greatly improved by the proposed prediction model. The comprehensive performance of the proposed method is better than that of the traditional linear regression technology.",2020,
Analisi Della Sicurezza Statica E Sismica Di Dighe in Muratura E Ipotesi Di Interventi Di Miglioramento,"Lâ€™universo dighe rappresenta oggi una tematica abbastanza delicata per quanto riguarda la loro sicurezza. Garantire la sicurezza vuol dire prevedere e poter controllare il comportamento di tali opere, nei confronti delle azioni alle quali sono esposte. Il rischio associato ad una diga e molto elevato date le drammatiche conseguenze prodotte da un ipotetico collasso della struttura. La maggior parte degli sbarramenti nazionali e stata costruita nella prima meta del secolo scorso; le conoscenze in ambito sismico in quel tempo erano abbastanza limitate e nellâ€™immaginario collettivo non era ancora consolidata lâ€™idea che un sisma potesse compromettere tali strutture cosi imponenti. Ancora oggi il campo della sicurezza sismica delle dighe e una tematica abbastanza giovane e riveste particolare importanza dati i continui sviluppi tecnici e normativi, in seguito a gli eventi sismici che colpiscono il territorio nazionale. In Italia oggi e presente un preciso quadro normativo che indirizza chiaramente nella progettazione, costruzione e valutazione nei diversi fronti della sicurezza di tali opere. Con il D.M. 26 giugno 2014 â€œNorme tecniche per la progettazione e la costruzione degli sbarramenti di ritenuta (dighe e traverse)â€ , il D.M. 17 Gennaio 2018 â€œAggiornamento delle Norme tecniche per le costruzioniâ€ e le linee guida emanate nel Luglio 2018 dal Ministero delle Infrastrutture e dei Trasporti â€œIstruzioni per lâ€™applicazione della normativa tecnica di cui al D.M. 26.06.2014 (NTD14) e al D.M. 17.01.2018 (NTC18)â€ si e in possesso di tutti gli strumenti normativi necessari nellâ€™approccio allâ€™arduo compito della valutazione della sicurezza delle opere di sbarramento nazionali. Questo lavoro nasce dalla collaborazione con Gruppo Ingegneria Torino (GIT), societa di ingegneria che offre servizi specialistici di progettazione e consulenza, presso la quale e stato svolto un tirocinio curriculare che mi ha visto fin da subito impegnato nella risoluzione di diverse ipotesi di intervento riguardanti la diga della Lavagnina. Per tale lavoro di tesi magistrale si e dunque tratto spunto da una commessa di GIT, ipotizzandone possibili reali sviluppi futuri applicabili allo sbarramento in oggetto. La diga della Lavagnina, situata nel territorio del comune di Casaleggio Boiro (AL), e uno degli sbarramenti che interessa il torrente Gorzente, le cui acque sono utilizzate a scopo idroelettrico dallâ€™omonima centrale costruita piu a valle. Per la realizzazione di tale lavoro e stato necessario affrontare una prima fase conoscitiva, basata sullo studio della particolare tipologia costruttiva della diga in oggetto. Un corpo diga in muratura di pietrame e malta e soggetto ad una serie di diverse tipologie di degrado, associate al naturale deperimento del materiale nel tempo e allâ€™azione dei fattori climatici che interagiscono con la struttura. In una seconda fase, dopo la raccolta di tutte le informazioni disponibile sulla caratterizzazione geometrica e fisico-meccanica dello sbarramento, si e approcciato lo studio per la valutazione sismica dello stesso, seguendo lâ€™iter metodologico richiesto dalla normativa. Le verifiche di sicurezza richieste per uno sbarramento di ritenuta sono molteplici e richiedono una serie di dati che non e sempre possibile ottenere. In questo lavoro si sono eseguite le verifiche piu importanti e rappresentative per ottenere un quadro conoscitivo preliminare sul comportamento in fase statica e dinamica della diga di Lavagnina.",2019,
Responses of coral reef wrasse assemblages to disturbance and marine reserve protection on the Great Barrier Reef,"Coral reefs are periodically impacted by disturbance events that reduce live coral cover and habitat complexity, with concomitant effects on fish assemblage structure. While the density of some fish species may increase following coral loss, most species decline. Determining which species are â€˜winnersâ€™ and â€˜losersâ€™ following disturbances is fundamental to inform projections of future reef community structure, biodiversity, and productivity. Here, we analyse a long-term (2006â€“2018), spatially extensive (â‰ˆâ€‰700Â km) â€˜natural experimentâ€™ in which the responses of 11 wrasse taxa to acute disturbance events and no-take marine reserve (NTMR) protection were quantified on fringing coral reefs in the Palm (18Â°34â€²Â S, 146Â°29â€²Â E), Whitsunday (20Â°08â€²Â S, 148Â°56â€²Â E), and Keppel Island (23Â°10â€²Â S, 150Â°57â€²Â E) groups, Great Barrier Reef, Australia. The responses of wrasse densities to benthic habitat change were taxa specific and temporally consistent. Disturbance-mediated reductions in live hard coral cover and/or habitat complexity resulted in density declines for Hemigymnus melapterus, Hemigymnus fasciatus, Cheilinus fasciatus, Labroides spp., Oxycheilinus digramma, and Thalassoma spp. Conversely, Halichoeres spp. densities correlated positively with increased relative cover of sand and rubble, while Stethojulis spp., Anampses spp., Epibulus insidiator, and Bodianus spp. displayed variable responses to habitat changes. No wrasses exhibited an NTMR effect and predator density, irrespective of NTMR status, only influenced five taxa across all island groups. The lack of NTMR effects and variable top-down predator effects suggest that taxa-specific benthic habitat associations were the predominant drivers of wrasse densities on inshore GBR reefs.",2019,Marine Biology
Trabajo de CÃ¡tedra: uso de la placa Discovery para el cÃ¡lculo e implementaciÃ³n de filtros FIR e IIR,"1 Estudiante, CÃ¡tedra de TeorÃ­a de Circuitos II â€“ Universidad TecnolÃ³gica Nacional â€“ Facultad Regional BahÃ­a Blanca, Correo Postal 8000, Buenos Aires, Argentina pazmartin35@gmail.com http://www.frbb.utn.edu.ar/frbb/index.php 2 Profesor, CÃ¡tedra de TeorÃ­a de Circuitos II â€“ Universidad TecnolÃ³gica Nacional Facultad Regional BahÃ­a Blanca, Correo Postal 8000, Buenos Aires, Argentina arodrig@frbb.utn.edu.ar 3 Ayudante, CÃ¡tedra de TeorÃ­a de Circuitos II â€“ Universidad TecnolÃ³gica Nacional Facultad Regional BahÃ­a Blanca, Correo Postal 8000, Buenos Aires, Argentina christian_galasso81@yahoo.com.ar",2016,
PrÃ©diction phÃ©notypique et sÃ©lection de variables en grande dimension dans les modÃ¨les linÃ©aires et linÃ©aires mixtes,"Les nouvelles technologies permettent l'acquisition de donnees genomiques et post-genomiques de grande dimension, c'est-a-dire des donnees pour lesquelles il y a toujours un plus grand nombre de variables mesurees que d'individus sur lesquels on les mesure. Ces donnees necessitent generalement des hypotheses supplementaires afin de pouvoir etre analysees, comme une hypothese de parcimonie pour laquelle peu de variables sont supposees influentes. C'est dans ce contexte de grande dimension que nous avons travaille sur des donnees reelles issues de lâ€™espece porcine et de la technologie haut-debit, plus particulierement le metabolome obtenu a partir de la spectrometrie RMN et des phenotypes mesures post-mortem pour la plupart. L'objectif est double : d'une part la prediction de phenotypes dâ€™interet pour la production porcine et d'autre part l'explicitation de relations biologiques entre ces phenotypes et le metabolome. On montre, grÃ¢ce a une analyse dans le modele lineaire effectuee avec la methode Lasso, que le metabolome a un pouvoir predictif non negligeable pour certains phenotypes importants pour la production porcine comme le taux de muscle et la consommation moyenne journaliere. Le deuxieme objectif est traite grÃ¢ce au domaine statistique de la selection de variables. Les methodes classiques telles que la methode Lasso et la procedure FDR sont investiguees et de nouvelles methodes plus performantes sont developpees : nous proposons une methode de selection de variables en modele lineaire basee sur des tests d'hypotheses multiples. Cette methode possede des resultats non asymptotiques de puissance sous certaines conditions sur le signal. De part les donnees annexes disponibles sur les animaux telles que les lots dans lesquels ils ont evolues ou les relations de parentes qu'ils possedent, les modeles mixtes sont consideres. Un nouvel algorithme de selection d'effets fixes est developpe et il s'avere beaucoup plus rapide que les algorithmes existants qui ont le meme objectif. GrÃ¢ce a sa decomposition en etapes distinctes, lâ€™algorithme peut etre combine a toutes les methodes de selection de variables developpees pour le modele lineaire classique. Toutefois, les resultats de convergence dependent de la methode utilisee. On montre que la combinaison de cet algorithme avec la methode de tests multiples donne de tres bons resultats empiriques. Toutes ces methodes sont appliquees au jeu de donnees reelles et des relations biologiques sont mises en evidence",2012,
Target Tracking inSensor Networks: Criteria forSensor Selection,"Thispaperdiscusses theperformance ofasensorperformance oftheoptimal state estimation filter, theCram6r- selection scheme based onfourexpected performance criteria in RaoLowerBound(CRLB),hasanupperbounddetermined atarget tracking scenario, namely best expected heading, range, bythesolution oftheMRE fortheclassofsystems with Doppler andbearing accuracy. Thesensor selection algorithm . isbasedon theModified Riccati Equation, whichiscapablerobablt ofdetection Pd< 1.Besdes, usngtheMRELelds ofhandling sensorswithprobability ofdetection Pd<_1.The Particle Filtering technique havebeenusedfortarget trackingIn(6)azimuth andheading accuracy areusedtocontrol withanadaptation formissed detections inthecaseofPd< 1. a multi-function radar, wherethegoal istoattain a certain Results arecompared using multiple runswithsimulated datafor '",2007,
Corrigendum: Evaluation of the lasso and the elastic net in genome-wide association studies,"Translational research program is intended to provide scientists with an incentive to examine research findings from the perspective of concrete applications or other uses, and to give outstanding researchers an opportunity to develop these findings into specific applications and/or economic, societal or social benefits. This program is jointly funded by the Austrian Science Fund (FWF) and the Austrian Ministry for Transport, Innovation and Technology (BMVIT). Therefore, the acknowledgments section of the paper â€œEvaluation of the lasso and the elastic net in genome-wide association studiesâ€ should state: 
 
â€œThe financial support of the Austrian Ministry for Transport, Innovation and Technology (BMVIT) and the Austrian Science Fund (FWF) via the project TRP46-B19 is greatly acknowledged.â€",2014,Frontiers in Genetics
Conservation ofallelic richness inwildcroprelatives isaidedby assessment ofgenetic markers,"ABSTRACT Wildcrop relatives are animportantsourceof genetic variationfor improving domesticatedspecies. Givenlimitedresources,methodsformaximizingthegeneticdiversityof collections of wild relatives are needed to help spreadprotection over a larger numberofpopulations and species.Simulationswereconductedtoinvestigate theoptimalstrategyofsamplingmaterials frompopulationsofwild relatives, withthe objective of maximizing the number of alleles (allelic richness) in collections of fixed size. Twomethods, based onassessing populations for variation at marker loci (e.g., allo-zymes, restriction fragment length polymorphisms), werede-veloped and compared with several methods that are not dependent on markers. Marker-assisted methods yielded higheroverall allelic richness inthesimulated collections, and they were particularly effective in conserving geographically localized alleles, theclassof alleles thatis mostsubjecttoloss. Decisions in conservation biology maybe based on demo-graphic or genetic criteria",1993,
Indirizzi per un contenimento della pressione fiscale sulla casa,"Mancando una rotta, si e andati avanti navigando a vista. Ne e seguita, fin qui, una produzione legislativa frammentaria, disorganica e non di rado contraddittoria. L'analisi della legislazione fiscale piu recente dimostra che l'unico obiettivo perseguito dal legislatore e stata la massimizzazione del gettito. I1 recente provvedimento sulle ristrutturazioni si fa apprezzare, piu che altro, come espressione di una ritrovata consapevolezza del ruolo che l'edilizia puo svolgere nella prospettiva del rilancio delle iniziative e dell'occupazione, e come segnale di una inversione di tendenza e di un diverso modo di porsi della politica rispetto alle problematiche specifiche. La pressione fiscale nel settore ha subito, in questi ultimi anni, una accelerazione insostenibile. I1 gettito e passato dagli 8.400 miliardi del 1980 ai 51.000 miliardi del 1993 segnando un incremento di circa 15.000 miliardi nel solo biennio 1991-1993, in correlazione con l'applicazione dei nuovi estimi e dell'entrata in vigore dell'IC1. Attualmente il gettito proveniente dal settore ha superato abbondantemente i 60 mila miliardi. Ad una ""politica"" ispirata al modello quantitativo, di incentivazione indiscriminata della produzione e, quindi, di indiscriminata erosione della base imponibile, si e contrapposta, negli anni piu recenti, una sequela di prowedimenti, che si sono abbattuti sul settore con effetti paralizzanti. Le conseguenze di questa politica sono sotto gli occhi di tutti: un mercato depresso; la produzione in forte calo; centinaia di migliaia di addetti senza lavoro; l'indotto sull'orlo del collasso. E , infatti, venuta a mancare, quasi completamente, quella parte della domanda che investiva non tanto in vista del reddito ritraibile dall'affitto, (che, oltre a essere risibile, viene letteralmente falcidiato dal fisco) quanto, piuttosto, in vista della possibilita di realizzare guadagni in conto capitale. segno organico di politica tributaria per la casa.",2009,Aestimum
"Hepatocellular carcinoma associated microRNA expression signature: integrated bioinformatics analysis, experimental validation and clinical significance","microRNA (miRNA) expression profiles varied greatly among current studies due to different technological platforms and small sample size. Systematic and integrative analysis of published datesets that compared the miRNA expression profiles between hepatocellular carcinoma (HCC) tissue and paired adjacent noncancerous liver tissue was performed to determine candidate HCC associated miRNAs. Moreover, we further validated the confirmed miRNAs in a clinical setting using qRT-PCR and Tumor Cancer Genome Atlas (TCGA) dataset. A miRNA integrated-signature of 5 upregulated and 8 downregulated miRNAs was identified from 26 published datesets in HCC using robust rank aggregation method. qRT-PCR demonstrated that miR-93-5p, miR-224-5p, miR-221-3p and miR-21-5p was increased, whereas the expression of miR-214-3p, miR-199a-3p, miR-195-5p, miR-150-5p and miR-145-5p was decreased in the HCC tissues, which was also validated on TCGA dataset. A miRNA based score using LASSO regression model provided a high accuracy for identifying HCC tissue (AUC = 0.982): HCC risk score = 0.180E_miR-221 + 0.0262E_miR-21 - 0.007E_miR-223 - 0.185E_miR-130a. E_miR-n = Log 2 (expression of microRNA n). Furthermore, expression of 5 miRNAs (miR-222, miR-221, miR-21 miR-214 and miR-130a) correlated with pathological tumor grade. Cox regression analysis showed that miR-21 was related with 3-year survival (hazard ratio [HR]: 1.509, 95%CI: 1.079-2.112, P = 0.016) and 5-year survival (HR: 1.416, 95%CI: 1.057-1.897, P = 0.020). However, none of the deregulated miRNAs was related with microscopic vascular invasion. This study provides a basis for further clinical application of miRNAs in HCC.",2015,Oncotarget
Occupational Mobility in the Year 2000: Projections for American Men and Women,"We construct intergenerational occupational mobility tablesfor men and women aged 25-64 in the year 2000. The procedure for creating such tables involves three steps: (1) deriving origin distributions in the absence of actual survey data on occupational background; (2) constructing destination distributions using occupational forecasts prepared by the Bureau of Labor Statistics; (3) calculating cell counts by adjusting the most recent mobility tables available to the derived origin and destination distributions using the Deming-Stephan technique. The empirical accuracy of some aspects of our projection method is also assessed. We calculate several descriptive statistics on the basis of our predicted mobility matrix and examine mobility trends by comparing these statistics to those based on tables from earlier periods. Our results show an increasing tendency toward immobility and downward mobility, especially for men. Postwar American society has been characterized by extensive upward social mobility. The driving force behind this mobility has been change in the occupational structure: ""despite the many social changes in the United States in the last two decades, it is a more favorable occupational structure, and only that, which has sustained or improved the mobility opportunities of American men"" (Hauser et al. 1975b:597). Some prognosticators thought that this extensive upgrading of the occupational structure would continue indefinitely (Porter 1968). However, it is a phenomenon of the past unlikely to recur in the near future. Recently, the Bureau of Labor Statistics (BLS) of the Department of Labor published projec* The authors contributed equally to this article. We thank the anonymous reviewers from Social Forces, as well as Henryk Domanski, John Lukasiewicz, Bogdan Mach, Zbigniew Sawihski, and Kazimierz Slomczyhski for comments on earlier drafts of this article. Financial supportfrom the Department of Sociology at the University of Vermont is gratefully acknowledged. An earlier version of this article was presented at a meeting of the Research Committee on Social Stratification of the International SociologicalAssociation, held in August of 1989 at Stanford University. Direct all correspondence to Daniel H. Krymkowski, Department of Sociology, University of Vernont, 31 S. Prospect St., Burlington, VT 05405 (BrINET: D_Krymkowski@Uvmvax). i) The University of North Carolina Press Social Forces, September 1992, 71(1):145-157 This content downloaded from 157.55.39.30 on Fri, 27 May 2016 05:50:27 UTC All use subject to http://about.jstor.org/terms 146 / Social Forces 71:1, September 1992 tions of the occupational structure for the year 2000 (Silvestri & Lukasiewicz 1987). The BLS forecasts a considerably slower rate of occupational growth during 1986-2000 han was the case between 1972-86. Silvestri and Lukasiewicz (1987) point out that the ""19 percent increase [projected to occur between 1986 and 2000] is only half the average annual rate of increase that occurred over the previous 14-year period"" (46). Moreover, the slowdown applies most significantly to higher-status occupational groups. For example, the executive, administrative, and managerial category increased by 73.7% between 1972 and 1986, but is projected to increase by only 28.7% between 1986 and 2000 (Silvestri & Lukasiewicz 1987). The slowdown in the lower-status category of service workers, however, will be much less extensive: service workers increased by 45.9% between 1972-86 and are predicted to increase by 32.7% between 1986-2000. Given the connection between changes in the occupational structure and social mobility, it is important to examine the implications of the BLS labor-force projections for mobility. Will the projected changes in the occupational structure significantly alter the mobility chances of Americans? In this article, we predict the social mobility pattern for the year 2000 and assess recent mobility trends. We next describe the approach used to assess the effect of slower occupational growth on mobility. Deriving an Origin Distribution In a very influential paper, Duncan (1966) discusses the problem of constructing the origin distribution of an intergenerational occupational mobility table in the absence of actual survey data on social background. Among other things, he demonstrates that the origin distribution of such a table does not refer to an occupational distribution at a particular point in time. Although the problem is not as straightforward as some had thought, it is nonetheless solvable. In this section we show how the origin distribution of any national-level intergenerational occupational mobility table1 can be derived using standard demographic concepts, some of which Duncan explicitly mentioned. These concepts include the age distribution of the labor force in the destination year, and age-specific and occupation-specific statistics on fertility, child mortality, and career mobility. The construction of the origin distribution is presented by considering three time points: t, t+T, and T, where t is ffie birth year of persons in the labor force in year T, t+T iS the year of reference for occupational origins (in that year persons born in year t are T years old), and T is the year for which the destination distribution is constructed. T and T are constants, t is a variable, and t+T ? T. We consider the age j of persons in the labor force in year T to be in the range V.i, jiJ, and the following relations between the birth years and ages of the oldest and youngest persons apply. This content downloaded from 157.55.39.30 on Fri, 27 May 2016 05:50:27 UTC All use subject to http://about.jstor.org/terms Occupational Mobility in the Year 2000 / 147",1992,Social Forces
