title,abstract,year,journal
Private Empirical Risk Minimization Beyond the Worst Case: The Effect of the Constraint Set Geometry,"Empirical Risk Minimization (ERM) is a standard technique in machine learning, where a model is selected by minimizing a loss function over constraint set. When the training dataset consists of private information, it is natural to use a differentially private ERM algorithm, and this problem has been the subject of a long line of work started with Chaudhuri and Monteleoni 2008. A private ERM algorithm outputs an approximate minimizer of the loss function and its error can be measured as the difference from the optimal value of the loss function. When the constraint set is arbitrary, the required error bounds are fairly well understood~\cite{BassilyST14}. In this work, we show that the geometric properties of the constraint set can be used to derive significantly better results. Specifically, we show that a differentially private version of Mirror Descent leads to error bounds of the form $\tilde{O}(G_{\mathcal{C}}/n)$ for a lipschitz loss function, improving on the $\tilde{O}(\sqrt{p}/n)$ bounds in Bassily, Smith and Thakurta 2014. Here $p$ is the dimensionality of the problem, $n$ is the number of data points in the training set, and $G_{\mathcal{C}}$ denotes the Gaussian width of the constraint set that we optimize over. We show similar improvements for strongly convex functions, and for smooth functions. In addition, we show that when the loss function is Lipschitz with respect to the $\ell_1$ norm and $\mathcal{C}$ is $\ell_1$-bounded, a differentially private version of the Frank-Wolfe algorithm gives error bounds of the form $\tilde{O}(n^{-2/3})$. This captures the important and common case of sparse linear regression (LASSO), when the data $x_i$ satisfies $|x_i|_{\infty} \leq 1$ and we optimize over the $\ell_1$ ball. We show new lower bounds for this setting, that together with known bounds, imply that all our upper bounds are tight.",2014,ArXiv
Predictive analysis of heat transfer characteristics of nanofluids in helically coiled tube heat exchanger using regression approach,"Nanofluids are the combination of base fluid and nanoparticles which offer 
 higher thermal conductivity resulting higher heat transfer. In this research 
 article, soft computing tool is used to find the accurate Nusselt number of 
 coiled tube heat exchanger handling Al2O3/H2O nanofluids at three different 
 volume concentrations and at different mass flow rate in terms of Dean 
 number (De). The input predictor variables used in this model are convective 
 heat transfer coefficient, thermal conductivity of nanofluids and Dean 
 number and the output response variable is Nusselt number. Linear 
 Regression (LM), Generalized Linear Regression (GLM) and Lasso and 
 Elastic-Net Regularized Generalized Linear Models (GLM_NET) methodologies 
 are taken to predict the Nusselt number. It is observed that the linear 
 regression method shows an accurate agreement with experimental data with 
 Root Mean Square Error (RMSE) value of 0.05614 and regression coefficient 
 value (R2) is 0.99. It is studied that the experimental data holds good 
 accordance with the predicted data given by the trained network. The average 
 relative errors in the prediction of Nusselt number and heat transfer 
 coefficients are found to be 0.3% and 0.2%, respectively.",2020,Thermal Science
Partial least squares regression for high dimensional and correlated data,"This thesis focuses on the investigation of partial least squares (PLS) method- ology to deal with high-dimensional correlated data. Current develop- ments in technology have enabled experiments to produce data that are characterised by, first, the number of variables that far exceeds the number of observations and, second, variables that are substantially correlated be- tween them. These types of data are common to be found in, first, chemo- metrics where absorbance levels of chemical samples are recorded across hundreds of wavelengths in a calibration of near-infrared (NIR) spectrom- eter. Second, they are also common to be found in genomics where copy number alterations (CNA) are recorded across thousands of genomic re- gions from cancer patients. PLS is a well-known method to employ in the analysis of high-dimensional data as a regression method in chemo- metric data or as a classification method in genomic data. It deals with those characteristics of the data by constructing latent variables, called components, to represent the original variables. However, there are some challenges in the application of PLS for such analysis and, in this research, there are several areas of investigation that we have performed to deal with them. The first one is that there are three main PLS algorithms with po- tentially different interpretation of relevant quantities. We deal with this problem by consolidating those three algorithms and identify the case in which those three algorithms would give the same estimates. The second one is the unusual negative shrinkage factors (or â€œfilter factorsâ€) that PLS experiences in the model fitting. One of the main reasons PLS can deal with high-dimensional data is that the estimates experience a shrinkage. Unlike ridge regression or principal component regression that experience shrinkage factors between zero and one, PLS can experience shrinkage factors more than one or even negative (hence, more appropriate to be called â€œfilter factorsâ€ than â€œshrinkage factorsâ€). To our knowledge, there has been no previous meaningful investigation on the negative filter fac- tors (NFF) in PLS. In this research we present a novel result whereby we identify the condition for NFF to happen and investigate characteristics of the data that are associated with NFF to get an insight. Lastly, the main challenge of the application of PLS is in the interpretation of weights as- sociated with the predictors. With hundreds and thousands of predictors, each and every predictor variable has non-zero weight. However, we ex- pect that only some predictor variables are contributing to the association with the outcome variable. We therefore resort to the sparse estimation of predictor weights where some weights are zero estimated and the other weights are non-zero. A (standard) lasso estimation has a weakness in dealing with correlated variables as it picks up one variable within a corre- lation â€œblockâ€ without knowing the reason. A novel approach is needed to take into account the dependencies between predictor variables in estimat- ing the weights. We propose a new method where a new penalty function is introduced in the likelihood function associated with the estimation of weights. The penalty function is a combination of a lasso penalty that im- poses sparsity and a penalty based on Cauchy distribution with a smoother matrix to take into account dependencies between genomic regions. The results show that the estimates of the weights are sparse: many weights are zero estimated, and those non-zero estimates are grouped and exhibit smoothness within them. The interpretation on genomic regions becomes easy and identification of important regions for each component can be done simultaneously with prediction in a single modelling framework. We investigate the relation between PLS and graphical modelling using the in- formation in the weights to construct the graph with unsuccessful results.",2019,
WE-E-BRE-05: Ensemble of Graphical Models for Predicting Radiation Pneumontis Risk.,"PURPOSE
We propose a prior knowledge-based approach to construct an interaction graph of biological and dosimetric radiation pneumontis (RP) covariates for the purpose of developing a RP risk classifier.


METHODS
We recruited 59 NSCLC patients who received curative radiotherapy with minimum 6 month follow-up. 16 RP events was observed (CTCAE grade â‰¥2). Blood serum was collected from every patient before (pre-RT) and during RT (mid-RT). From each sample the concentration of the following five candidate biomarkers were taken as covariates: alpha-2-macroglobulin (Î±2M), angiotensin converting enzyme (ACE), transforming growth factor Î² (TGF-Î²), interleukin-6 (IL-6), and osteopontin (OPN). Dose-volumetric parameters were also included as covariates. The number of biological and dosimetric covariates was reduced by a variable selection scheme implemented by L1-regularized logistic regression (LASSO). Posterior probability distribution of interaction graphs between the selected variables was estimated from the data under the literature-based prior knowledge to weight more heavily the graphs that contain the expected associations. A graph ensemble was formed by averaging the most probable graphs weighted by their posterior, creating a Bayesian Network (BN)-based RP risk classifier.


RESULTS
The LASSO selected the following 7 RP covariates: (1) pre-RT concentration level of Î±2M, (2) Î±2M level mid- RT/pre-RT, (3) pre-RT IL6 level, (4) IL6 level mid-RT/pre-RT, (5) ACE mid-RT/pre-RT, (6) PTV volume, and (7) mean lung dose (MLD). The ensemble BN model achieved the maximum sensitivity/specificity of 81%/84% and outperformed univariate dosimetric predictors as shown by larger AUC values (0.78âˆ¼0.81) compared with MLD (0.61), V20 (0.65) and V30 (0.70). The ensembles obtained by incorporating the prior knowledge improved classification performance for the ensemble size 5âˆ¼50.


CONCLUSION
We demonstrated a probabilistic ensemble method to detect robust associations between RP covariates and its potential to improve RP prediction accuracy. Our Bayesian approach to incorporate prior knowledge can enhance efficiency in searching of such associations from data. The authors acknowledge partial support by: 1) CREATE Medical Physics Research Training Network grant of the Natural Sciences and Engineering Research Council (Grant number: 432290) and 2) The Terry Fox Foundation Strategic Training Initiative for Excellence in Radiation Research for the 21st Century (EIRR21).",2014,Medical physics
Kajian Metode Least Absolute Selection and Shrinkage Operator (LASSO) pada Data yang Mengandung Heteroskedastisitas,"MEIRA MAWATI. Study of Least Absolute Selection and Shrinkage Operator (LASSO) Method Under Heteroscedasticity. Under the supervision of KUSMAN SADIK and BAGUS SARTONO. Least Absolute Selection and Shrinkage Operator (LASSO) has been acknowledged to analyse high dimention data to select variables and to estimate parameters. LASSO estimators obtained by minimizing the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Jia et al. (2010), in his research, conducted an analysis on a medical imaging application data using LASSO when error variance of the data suffered heteroscedasticity problem, which is Poisson-like distributed. This research aimed to study the similar problem. LASSO is evaluated by using heteroscedastic regression data. By conducting simulation approach, the result showed that LASSO encountered difficulties. In regression data that has too many zerocoefficients estimator, LASSO is not selective. Compared to OLS (Ordinary Least Square) and Best Subset, LASSO doesnâ€™t offer better solution.",2015,
Predicting Mass Incidents from Weibo,"The outbreak of mass incidents severely affects the stability of society. If we can predict mass incidents in advance, we may find the solution to avoid the confliction in time. Some of the existing approaches rely on emotional modeling. Much research has been conducted on microblog incident detection using statistical models, like LASSO regression method, Dynamic Query Expansion DQE and so on. In this paper, we propose to combine sentiment analysis and statistical methods, and uses LASSO regression method for mass incidents prediction. Experiments on Qingdao demonstrated that our proposed approach achieves a good performance.",2016,
Estimation Consistency of Group Lasso with Special Diagonal Matrix,"Group Lasso is an efficient regularized leastsquare regression algorithm, and is now being used as a computationally feasible method to select grouped variables. In this paper, we address the issue of estimation consistency of the group Lasso with special diagonal matrix. We derive sufficient condition for the consistency of group Lasso under practical assumptions, such as model misspecification. This sufficient condition, which depends mainly on the covariance of the predictor variables, states that group Lasso selects the true model consistently if the predictors that are in and not in the true model have low correlation. Specifically, the consistency condition adopts the regularization with special kernel matrix. Experiments are carried out to provide insights and understanding of this result.",2009,2009 Second International Conference on Intelligent Networks and Intelligent Systems
A six-microRNA signature can better predict overall survival of patients with esophagus adenocarcinoma,"Background
The microRNAs (miRNAs) have been validated as prognostic markers in many cancers. Here, we aimed at developing a miRNA-based signature for predicting the prognosis of esophagus adenocarcinoma (EAC).


Methods
The RNA-sequencing data set of EAC was downloaded from The Cancer Genome Atlas (TCGA). Eighty-four patients with EAC were classified into a training set and a test set randomly. Using univariate Cox regression analysis and the least absolute shrinkage and selection operator (LASSO), we identified prognostic factors and constructed a prognostic miRNA signature. The accuracy of the signature was evaluated by the receiver operating characteristic (ROC) curve.


Result
In general, in the training set, six miRNAs (hsa-mir-425, hsa-let-7b, hsa-mir-23a, hsa-mir-3074, hsa-mir-424 and hsa-mir-505) displayed good prognostic power as markers of overall survival for EAC patients. Relative to patients in the low-risk group, those assigned to the high-risk group according to their risk scores of the designed miRNA model displayed reduced overall survival. This 6-miRNA model was validated in test and entire set. The area under curve (AUC) for ROC at 3 years was 0.959, 0.840, and 0.868 in training, test, and entire set, respectively. Molecular functional analysis and pathway enrichment analysis indicated that the target messenger RNAs associated with 6-miRNA signature were closely related to several pathways involved in carcinogenesis, especially cell cycle.


Conclusion
In summary, a novel 6-miRNA expression-based prognostic signature derived from the EAC data of TCGA was constructed and validated for predicting the prognosis of EAC.",2019,PeerJ
Histopathology-based immunoscore predicts recurrence for intrahepatic cholangiocarcinoma after hepatectomy,"Intrahepatic cholangiocarcinoma (ICC) is a rare malignancy with poor prognosis. The evaluation of recurrence risk after liver resection is of great importance for ICCs. We aimed to assess the prognostic value of intra- and peritumoral immune infiltrations and to establish a novel histopathology-related immunoscore (HRI) associated with ICC recurrence. A total of 280 ICC patients who received curative resection between February 2005 and July 2011 were enrolled in our study. Patients were randomly assigned to the derivation cohort (nâ€‰=â€‰176) or the validation cohort (nâ€‰=â€‰104). Sixteen immune biomarkers in both intra- and peritumoral tissues were examined by immunohistochemistry. The least absolute shrinkage and selection operator (LASSO) Cox model was used to establish the HRI score. Cox regression analysis was used for multivariate analysis. Nine recurrence-related immune features were identified and integrated into the HRI score. The HRI score was used to categorize patients into low-risk and high-risk groups using the X-tile software. Kaplanâ€“Meier analysis presented that the HRI score showed good stratification between low-risk and high-risk groups in both the derivation cohort (Pâ€‰<â€‰0.001) and the validation cohort (Pâ€‰=â€‰0.014), respectively. Multivariate analysis demonstrated that serum Î³-glutamyl transpeptidase, carbohydrate antigen 19-9, lymphoid metastasis, tumor numbers, and the HRI score were independent risk factors associated with recurrence-free survival (RFS). The combination of Shenâ€™s model and HRI score provided better performance in recurrence prediction compared with traditional staging systems. The HRI score might serve as a promising RFS predictor for ICC with prognostic values.",2019,"Cancer Immunology, Immunotherapy"
"Sparse Group Lasso: Optimal Sample Complexity, Convergence Rate, and Statistical Inference","In this paper, we study sparse group Lasso for high-dimensional double sparse linear regression, where the parameter of interest is simultaneously element-wise and group-wise sparse. This problem is an important instance of the simultaneously structured model -- an actively studied topic in statistics and machine learning. In the noiseless case, we provide matching upper and lower bounds on sample complexity for the exact recovery of sparse vectors and for stable estimation of approximately sparse vectors, respectively. In the noisy case, we develop upper and matching minimax lower bounds for estimation error. We also consider the debiased sparse group Lasso and investigate its asymptotic property for the purpose of statistical inference. Finally, numerical studies are provided to support the theoretical results.",2019,ArXiv
Lasso Regressions and Forecasting Models in Applied Stress Testing,"Model selection and forecasting in stress tests can be facilitated using machine learning techniques. These techniques have proved robust in other fields for dealing with the curse of dimensionality, a situation often encountered in applied stress testing. Lasso regressions, in particular, are well suited for building forecasting models when the number of potential covariates is large, and the number of observations is small or roughly equal to the number of covariates. This paper presents a conceptual overview of lasso regressions, explains how they fit in applied stress tests, describes its advantages over other model selection methods, and illustrates their application by constructing forecasting models of sectoral probabilities of default in an advanced emerging market economy.",2015,
Batch Effect Confounding Leads to Strong Bias in Performance Estimates Obtained by Cross-Validation,"BACKGROUND
With the large amount of biological data that is currently publicly available, many investigators combine multiple data sets to increase the sample size and potentially also the power of their analyses. However, technical differences (""batch effects"") as well as differences in sample composition between the data sets may significantly affect the ability to draw generalizable conclusions from such studies.


FOCUS
The current study focuses on the construction of classifiers, and the use of cross-validation to estimate their performance. In particular, we investigate the impact of batch effects and differences in sample composition between batches on the accuracy of the classification performance estimate obtained via cross-validation. The focus on estimation bias is a main difference compared to previous studies, which have mostly focused on the predictive performance and how it relates to the presence of batch effects.


DATA
We work on simulated data sets. To have realistic intensity distributions, we use real gene expression data as the basis for our simulation. Random samples from this expression matrix are selected and assigned to group 1 (e.g., 'control') or group 2 (e.g., 'treated'). We introduce batch effects and select some features to be differentially expressed between the two groups. We consider several scenarios for our study, most importantly different levels of confounding between groups and batch effects.


METHODS
We focus on well-known classifiers: logistic regression, Support Vector Machines (SVM), k-nearest neighbors (kNN) and Random Forests (RF). Feature selection is performed with the Wilcoxon test or the lasso. Parameter tuning and feature selection, as well as the estimation of the prediction performance of each classifier, is performed within a nested cross-validation scheme. The estimated classification performance is then compared to what is obtained when applying the classifier to independent data.",2014,PLoS ONE
lassopack: Model selection and prediction with regularized regression in Stata,"This article introduces lassopack, a suite of programs for regularized regression in Stata. lassopack implements lasso, square-root lasso, elastic net, ridge regression, adaptive lasso and post-estimation OLS. The methods are suitable for the high-dimensional setting where the number of predictors $p$ may be large and possibly greater than the number of observations, $n$. We offer three different approaches for selecting the penalization (`tuning') parameters: information criteria (implemented in lasso2), $K$-fold cross-validation and $h$-step ahead rolling cross-validation for cross-section, panel and time-series data (cvlasso), and theory-driven (`rigorous') penalization for the lasso and square-root lasso for cross-section and panel data (rlasso). We discuss the theoretical framework and practical considerations for each approach. We also present Monte Carlo results to compare the performance of the penalization approaches.",2019,arXiv: Econometrics
Application of Bayesian least absolute shrinkage and selection operator (LASSO) and BayesCÏ€ methods for genomic selection in French Holstein and MontbÃ©liarde breeds.,"Recently, the amount of available single nucleotide polymorphism (SNP) marker data has considerably increased in dairy cattle breeds, both for research purposes and for application in commercial breeding and selection programs. Bayesian methods are currently used in the genomic evaluation of dairy cattle to handle very large sets of explanatory variables with a limited number of observations. In this study, we applied 2 bayesian methods, BayesCÏ€ and bayesian least absolute shrinkage and selection operator (LASSO), to 2 genotyped and phenotyped reference populations consisting of 3,940 Holstein bulls and 1,172 MontbÃ©liarde bulls with approximately 40,000 polymorphic SNP. We compared the accuracy of the bayesian methods for the prediction of 3 traits (milk yield, fat content, and conception rate) with pedigree-based BLUP, genomic BLUP, partial least squares (PLS) regression, and sparse PLS regression, a variable selection PLS variant. The results showed that the correlations between observed and predicted phenotypes were similar in BayesCÏ€ (including or not pedigree information) and bayesian LASSO for most of the traits and whatever the breed. In the Holstein breed, bayesian methods led to higher correlations than other approaches for fat content and were similar to genomic BLUP for milk yield and to genomic BLUP and PLS regression for the conception rate. In the MontbÃ©liarde breed, no method dominated the others, except BayesCÏ€ for fat content. The better performances of the bayesian methods for fat content in Holstein and MontbÃ©liarde breeds are probably due to the effect of the DGAT1 gene. The SNP identified by the BayesCÏ€, bayesian LASSO, and sparse PLS regression methods, based on their effect on the different traits of interest, were located at almost the same position on the genome. As the bayesian methods resulted in regressions of direct genomic values on daughter trait deviations closer to 1 than for the other methods tested in this study, bayesian methods are suggested for genomic evaluations of French dairy cattle.",2013,Journal of dairy science
Statistical Seasonal Prediction Based on Regularized Regression,"AbstractThis paper proposes a regularized regression procedure for finding a predictive relation between one variable and a field of other variables. The procedure estimates a linear prediction model under the constraint that the regression coefficients have smooth spatial structure. The smoothness constraint is imposed using a novel approach based on the eigenvectors of the Laplace operator over the domain, which results in a constrained optimization problem equivalent to either ridge regression or least absolute shrinkage and selection operator (LASSO) regression, which can be solved by standard numerical software. In addition, this paper explores an unconventional procedure whereby regression models are estimated from dynamical model output and then verified against observationsâ€”the reverse of the traditional order. The methodology is illustrated by constructing statistical prediction models of summer Texas-area temperature based on concurrent Pacific sea surface temperature (SST). None of the regulari...",2017,Journal of Climate
"Sound quality prediction based on systematic metric selection and shrinkage: Comparison of stepwise, lasso, and elastic-net algorithms and clustering preprocessing","Abstract Sound quality is the impression of quality that is transmitted by the sound of a device. Its importance in sound and acoustical design of consumer products no longer needs to be demonstrated. One of the challenges is the creation of a prediction model that is able to predict the results of a listening test while using metrics derived from the sound stimuli. Often, these models are either derived using linear regression on a limited set of experimenter-selected metrics, or using more complex algorithms such as neural networks. In the former case, the user-selected metrics can bias the model and reflect the engineer pre-conceived idea of sound quality while missing potential features. In the latter case, although prediction might be efficient, the model is often in the form of a black-box which is difficult to use as a sound design guideline for engineers. In this paper, preprocessing by participants clustering and three different algorithms are compared in order to construct a sound quality prediction model that does not suffer from these limitations. The lasso, elastic-net and stepwise algorithms are tested for listening tests of consumer product for which 91 metrics areÂ used as potential predictors. Based on the reported results, it is shown that the most promising algorithm is the lasso which is able to (1) efficiently limit the number of metrics, (2) most accurately predict the results of listening tests, and (3) provide a meaningful model that can be used as understandable design guidelines.",2017,Journal of Sound and Vibration
Value of radiomics in differential diagnosis of chromophobe renal cell carcinoma and renal oncocytoma,"To explore the value of CT-enhanced quantitative features combined with machine learning for differential diagnosis of renal chromophobe cell carcinoma (chRCC) and renal oncocytoma (RO). Sixty-one cases of renal tumors (chRCCâ€‰=â€‰44; ROâ€‰=â€‰17) that were pathologically confirmed at our hospital between 2008 and 2018 were retrospectively analyzed. All patients had undergone preoperative enhanced CT scans including the corticomedullary (CMP), nephrographic (NP), and excretory phases (EP) of contrast enhancement. Volumes of interest (VOIs), including lesions on the images, were manually delineated using the RadCloud platform. A LASSO regression algorithm was used to screen the image features extracted from all VOIs. Five machine learning classifications were trained to distinguish chRCC from RO by using a fivefold cross-validation strategy. The performance of the classifier was mainly evaluated by areas under the receiver operating characteristic (ROC) curve and accuracy. In total, 1029 features were extracted from CMP, NP, and EP. The LASSO regression algorithm was used to screen out the four, four, and six best features, respectively, and eight features were selected when CMP and NP were combined. All five classifiers had good diagnostic performance, with area under the curve (AUC) values greater than 0.850, and support vector machine (SVM) classifier showed a diagnostic accuracy of 0.945 (AUC 0.964â€‰Â±â€‰0.054; sensitivity 0.999; specificity 0.800), showing the best performance. Accurate preoperative differential diagnosis of chRCC and RO can be facilitated by a combination of CT-enhanced quantitative features and machine learning.",2019,Abdominal Radiology
Short-term traffic flow forecasting: Multi-metric KNN with related station discovery,"Nonparametric regression is a classic method for short-term traffic flow forecasting in Intelligent Transportation Systems (ITS). Feature space construction and distance metric selection are two important parts in nonparametric regression. Few of previous works have taken both these two aspects into account together. In addition, how to use information of related stations in network scale is a key to improve the performance of ITS. In this paper, we propose a novel three-stage framework based on KNN to handle the issues above for short-term traffic flow forecasting. In the first stage, the related origin stations and destination stations of target task are discovered from the whole traffic network. Then for each target task, a particular distance metric is learned in the second stage. Finally, an extended multi-metric k-nearest neighbor regression model is built in the third stage. Experimental results on real-world traffic dataset show that our multi-metric KNN model with Lasso outperforms the traditional KNN model and the feature construction method is effective.",2015,2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)
HOMINID: a framework for identifying associations between host genetic variation and microbiome composition,"Recent studies have uncovered a strong effect of host genetic variation on the composition of host-associated microbiota. Here, we present HOMINID, a computational approach based on Lasso linear regression, that given host genetic variation and microbiome taxonomic composition data, identifies host single nucleotide polymorphisms (SNPs) that are correlated with microbial taxa abundances. Using simulated data, we show that HOMINID has accuracy in identifying associated SNPs and performs better compared with existing methods. We also show that HOMINID can accurately identify the microbial taxa that are correlated with associated SNPs. Lastly, by using HOMINID on real data of human genetic variation and microbiome composition, we identified 13 human SNPs in which genetic variation is correlated with microbiome taxonomic composition across body sites. In conclusion, HOMINID is a powerful method to detect host genetic variants linked to microbiome composition and can facilitate discovery of mechanisms controlling host-microbiome interactions.",2017,GigaScience
High-dimensional immunomonitoring models of HIV-1-specific CD8 T-cell responses accurately identify subjects achieving spontaneous viral control.,"UNLABELLED
The development of immunomonitoring models to determine HIV-1 vaccine efficacy is a major challenge. Studies suggest that HIV-1â€“specific CD8 T cells play a critical role in subjects achieving spontaneous viral control (HIV-1 controllers) and that they will be important in immune interventions. However, no single CD8 T-cell function is uniquely associated with controller status and the heterogeneity of responses targeting different epitopes further complicates the discovery of determinants of protective immunity. In the present study, we describe immunomonitoring models integrating multiple functions of epitope-specific CD8 T cells that distinguish controllers from subjects with treated or untreated progressive infection. Models integrating higher numbers of variables and trained with the least absolute shrinkage and selection operator (LASSO) variant of logistic regression and 10-fold cross-validation produce â€œdiagnostic testsâ€ that display an excellent capacity to delineate subject categories. The test accuracy reaches 75% area under the receiving operating characteristic curve in cohorts matched for prevalence of protective alleles. Linear mixed-effects model analyses show that the proliferative capacity, cytokine production, and kinetics of cytokine secretion are associated with HIV-1 control. Although proliferative capacity is the strongest single discriminant, integrated modeling of different dimensions of data leverages individual associations. This strategy may have important applications in predictive model development and immune monitoring of HIV-1 vaccine trials.


KEY POINTS
Immune monitoring models integrating multiple functions of HIV-1-specific CD8 T cells distinguish controllers from subjects with progressive HIV-1 infection. This strategy may have important applications in predictive model development and immune monitoring of HIV-1 vaccine trials.",2013,Blood
Eight key long non-coding RNAs predict hepatitis virus positive hepatocellular carcinoma as prognostic targets,"BACKGROUND
Hepatitis B virus, together with hepatitis C virus, has been recognized as the leading causes of hepatocellular carcinoma (HCC). Long non-coding RNAs (lncRNAs) have been suggested in increasing studies to be the potential prognostic factors for HCC. However, the role of combined application of lncRNAs in estimating overall survival (OS) for hepatitis virus positive HCC (VHCC) is uncertain.


AIM
To construct an lncRNA signature related to the OS of VHCC patients to enhance the accuracy of prognosis prediction.


METHODS
The expression patterns of lncRNAs, as well as related clinical data were collected from 149 VHCC patients from The Cancer Genome Atlas database. The R package was adopted to obtain the differentially expressed lncRNAs (DElncRNAs). LncRNAs significantly associated with OS were screened by means of univariate Cox regression analysis, so as to construct a least absolute shrinkage and selection operator (LASSO) model. Subsequently, the constructed lncRNA signature was developed and validated. Afterwards, the prognostic nomogram was established, which combined the as-established lncRNA signature as well as the clinical features. Meanwhile, subgroup analysis stratified by the virus type was also performed. Finally, the above-mentioned lncRNAs were enriched to corresponding pathways according to the markedly co-expressed genes.


RESULTS
A total of 1420 DElncRNAs were identified, among which 406 were significant in univariate Cox regression analysis. LASSO regression confirmed 8 out of the 406 lncRNAs, including AC005722.2, AC107959.3, AL353803.1, AL589182.1, AP000844.2, AP002478.1, FLJ36000, and NPSR1-AS1. Then, the prognostic risk score was calculated. Our results displayed a significant association between the risk model and the OS of VHCC [hazard ratio = 1.94, 95% confidence interval (CI): 1.61-2.34, log-rank P = 2e-10]. The inference tree suggested that the established lncRNA signature was useful in the risk stratification of VHCC. Furthermore, a nomogram was plotted, and the concordance index of internal validation was 0.763 (95%CI: 0.700-0.826). Moreover, the subgroup analysis regarding etiology confirmed this risk model. In addition, the Wnt signaling pathway, angiogenesis, the p53 pathway, and the PI3 kinase pathway were the remarkably enriched pathways.


CONCLUSION
An eight-lncRNA signature has been established to predict the prognosis for VHCC, which contributes to providing a novel foundation for the targeted therapy of VHCC.",2019,World Journal of Gastrointestinal Oncology
Variable Selection in Composite Quantile Regression Models with Adaptive Group Lasso,"Variable selection plays an important role in the model building process. In this paper, we extend the oracle properties of adaptive group lasso penalty to the context of composite quantile regression model, simultaneously estimate regression coefficient and implement variable selection in linear regression model. By combing the information of multiple quantile regression models, we obtain the more efficient estimator of the regression coefficient compared to the standard least square estimator. In addition, we show theoretically that our proposed method is able to identify the true model consistently, and the resulting estimator can be as efficient as oracle. A real data analysis confirmed that the optimal model selected by the adaptive group lasso based on composite quantile regression procure consistently demonstrate the smallest average model size, regardless of which selection method is used.",2013,International journal of applied mathematics and statistics
"Supporting Information for: Forecasting dengue and influenza incidences using a sparse representation of Google trends, electronic health records, and time series data","The Autoregressive Likelihood Ratio algorithm is an example of a stepwise regression method where we start with a trivial autoregressive model and then build up a sparse model by adding only the most statistically significant variables and removing the least significant variables using a statistically principled approach. The algorithm is described below. In the subsequent section, a novel technique that enables a computationally efficient implementation of the algorithm is described. Next, Autoregressive Likelihood Ratio method is compared with the lasso method. The time complexity of the two methods are compared in the final section.",2019,
Moving Beyond Sub-Gaussianity in High-Dimensional Statistics: Applications in Covariance Estimation and Linear Regression,"Concentration inequalities form an essential toolkit in the study of high-dimensional statistical methods. Most of the relevant statistics literature is based on the assumptions of sub-Gaussian/sub-exponential random vectors. In this paper, we bring together various probability inequalities for sums of independent random variables under much weaker exponential type (sub-Weibull) tail assumptions. These results extract a part sub-Gaussian tail behavior in finite samples, matching the asymptotics governed by the central limit theorem, and are compactly represented in terms of a new Orlicz quasi-norm - the Generalized Bernstein-Orlicz norm - that typifies such tail behaviors. 
We illustrate the usefulness of these inequalities through the analysis of four fundamental problems in high-dimensional statistics. In the first two problems, we study the rate of convergence of the sample covariance matrix in terms of the maximum elementwise norm and the maximum k-sub-matrix operator norm which are key quantities of interest in bootstrap procedures and high-dimensional structured covariance matrix estimation. The third example concerns the restricted eigenvalue condition, required in high dimensional linear regression, which we verify for all sub-Weibull random vectors under only marginal (not joint) tail assumptions on the covariates. To our knowledge, this is the first unified result obtained in such generality. In the final example, we consider the Lasso estimator for linear regression and establish its rate of convergence under much weaker tail assumptions (on the errors as well as the covariates) than those in the existing literature. The common feature in all our results is that the convergence rates under most exponential tails match the usual ones under sub-Gaussian assumptions. Finally, we also establish a high-dimensional CLT and tail bounds for empirical processes for sub-Weibulls.",2018,arXiv: Statistics Theory
Use of machine learning approaches to compare the contribution of different types of data for predicting an individual's risk of ill health: an observational study,"Abstract Background Public health science has made considerable effort to understand the determinants of health. Although substantial gains have been made in understanding the determinants of population health, our ability to translate discoveries at the population level towards discriminating between cases and non-cases of disease at the individual level has been limited despite increasing availability of data. This study draws from the recent advances in machine learning approaches to explore whether such methods can revolutionise how we build predictive models of health using social survey data. Methods Data from the Understanding Society survey (wave 2 [2010â€“12], 6830 individuals who took part in all aspects of data collection and for whom all data were included) were used to measure five types of data: personal (eg, age, sex), social (eg, occupation, education), health (eg, body weight, grip strength), biomarker (eg, cholesterol, hormones), and genetic. Outcome variables were presence of a limiting long-term illness, and type of illness or disability (eg, hypertension) 1 and 5 years from baseline (both overall status and predicting only new cases). Variable reduction was applied on the explanatory measures (âˆ¼200) within data type using LASSO regression. Deep learning via neural networks (using k-fold cross validation) was used to build predictive models on training data (75% of total sample). Model evaluation was performed on test data (25%) and compared several model fit statistics (eg, accuracy, sensitivity, specificity). Model fit was compared with simpler logistic regression models. Findings Health data had the strongest prediction of future health status (test data accuracy 71%), with personal data (61%) the poorest performing data type. Within the health data, physical activity and presence of some health conditions were strong individual predictors. Models only allowed for shallow learning of data, with more complex models adding little or reducing performance. However, the models only offered marginal improvements (âˆ¼1â€“2% accuracy improvements) compared with logistic regression models. Interpretation The project makes two main contributions to public health science: the evaluation of different data types and their relative contributions as predictors of health status; and exploring the potential of machine learning to improve predictive models of ill health. Funding Understanding Society Biomedical Data Fellowship Programme. The funder had no role in the research.",2018,The Lancet
"Comparative study of computational algorithms for the Lasso with high-dimensional, highly correlated data","Variable selection is important in high-dimensional data analysis. The Lasso regression is useful since it possesses sparsity, soft-decision rule, and computational efficiency. However, since the Lasso penalized likelihood contains a nondifferentiable term, standard optimization tools cannot be applied. Many computation algorithms to optimize this Lasso penalized likelihood function in high-dimensional settings have been proposed. To name a few, coordinate descent (CD) algorithm, majorization-minimization using local quadratic approximation, fast iterative shrinkage thresholding algorithm (FISTA) and alternating direction method of multipliers (ADMM). In this paper, we undertake a comparative study that analyzes relative merits of these algorithms. We are especially concerned with numerical sensitivity to the correlation between the covariates. We conduct a simulation study considering factors that affect the condition number of covariance matrix of the covariates, as well as the level of penalization. We apply the algorithms to cancer biomarker discovery, and compare convergence speed and stability.",2016,Applied Intelligence
Prognostic value of immune-related genes in clear cell renal cell carcinoma,"Clear cell renal cell carcinoma (ccRCC) is the most common pathological subtype of renal cell carcinoma, and immune-related genes (IRGs) are key contributors to its development. In this study, the gene expression profiles and clinical data of ccRCC patients were downloaded from The Cancer Genome Atlas database and the cBioPortal database, respectively. IRGs were obtained from the ImmPort database. We analyzed the expression of IRGs in ccRCC, and discovered 681 that were differentially expressed between ccRCC and normal kidney tissues. Univariate Cox regression analysis was used to identify prognostic differentially expressed IRGs (PDEIRGs). Using Lasso regression and multivariate Cox regression analyses, we detected seven optimal PDEIRGs (PLAU, ISG15, IRF9, ARG2, RNASE2, SEMA3G and UCN) and used them to construct a risk model to predict the prognosis of ccRCC patients. This model accurately stratified patients with different survival outcomes and precisely identified patients with different mutation burdens. Our findings suggest the seven PDEIRGs identified in this study are valuable prognostic predictors in ccRCC patients. These genes could be used to investigate the developmental mechanisms of ccRCC and to design individualized treatments for ccRCC patients.",2019,Aging (Albany NY)
Development and verification of a nomogram for prediction of recurrenceâ€free survival in clear cell renal cell carcinoma,"Nowadays, gene expression profiling has been widely used in screening out prognostic biomarkers in numerous kinds of carcinoma. Our studies attempt to construct a clinical nomogram which combines risk gene signature and clinical features for individual recurrent risk assessment and offer personalized managements for clear cell renal cell carcinoma. A total of 580 differentially expressed genes (DEGs) were identified via microarray. Functional analysis revealed that DEGs are of fundamental importance in ccRCC progression and metastasis. In our study, 338 ccRCC patients were retrospectively analysed and a risk gene signature which composed of 5 genes was obtained from a LASSO Cox regression model. Further analysis revealed that identified risk gene signature could usefully distinguish the patients with poor prognosis in training cohort (hazard ratio [HR]Â =Â 3.554, 95% confidence interval [CI] 2.261-7.472, PÂ <Â .0001, nÂ =Â 107). Moreover, the prognostic value of this gene-signature was independent of clinical features (PÂ =Â .002). The efficacy of risk gene signature was verified in both internal and external cohorts. The area under receiver operating characteristic curve of this signature was 0.770, 0.765 and 0.774 in the training, testing and external validation cohorts, respectively. Finally, a nomogram was developed for clinicians and did well in the calibration plots. This nomogram based on risk gene signature and clinical features might provide a practical way for recurrence prediction and facilitating personalized managements of ccRCC patients after surgery.",2019,Journal of Cellular and Molecular Medicine
Short-Term Covid-19 Forecast for Latecomers,"The number of Covid-19 cases is increasing dramatically worldwide. Therefore, the availability of reliable forecasts for the number of cases in the coming days is of fundamental importance. We propose a simple statistical method for short-term real-time forecasting of the number of Covid-19 cases and fatalities in countries that are latecomers â€“ i.e., countries where cases of the disease started to appear some time after others. In particular, we propose a penalized (LASSO) regression with an error correction mechanism to construct a model of a latecomer in terms of the other countries that were at a similar stage of the pandemic some days before. By tracking the number of cases and deaths in those countries, we forecast through an adaptive rolling-window scheme the number of cases and deaths in the latecomer. We apply this methodology to Brazil, and show that (so far) it has been performing very well. These forecasts aim to foster a better short-run management of the health system capacity.",2020,
Penalization method for sparse time series model,"Vector autoregressive (VAR) model has been widely used in many field, e.g., genetics, science, economics and finance. Especially, in genetics, VAR model with high dimensional setting is studied extensively. In order to find a suitable VAR model and improve the forecasting accuracy, capability of true model selection is important matter in several areas. In recent years, numerous studies on penalization method have been going on for true model selection of VAR model. Haufe et al. (2008) proposed several sparse approaches (e.g. ridge regression and multiple test, granger causality test, lasso, group lasso). Ren and Zhang (2010) proposed the subset selection methods for VAR model using a adaptive lasso in order to overcome lassoâ€™s problem by different amount of penalty to each coefficient. Shimamura et al. (2009) proposed a recursive regularization for VAR model for n â‰¤ p case using an elastic net which has a combination penalty term the ridge and the lasso. However, existing penalization methods can not reflect properties of time series model with lagged variables. In order to improve the forecasting accuracy of univariate time series model, Park and Sakaori (2011) proposed a lag weighted lasso which reflects deceasing variable effect as the lag increase. The lag weighted lasso assigns different penalties depend on not only coefficient size but also lag effect. The superiority of the lag weighted lasso is identified in forecasting accuracy and true model selection for univariate time series model. In this study, we extend the lag weighted lasso from univariate to multivariate time series model. We also propose a lag weighted penalization methods for VAR model namely a lag weighted ridge regression and a lag weighted elastic net. And we show that superiority of the lag weighted penalization methods in forecasting accuracy and true model selection for VAR model.",2011,
Testing-Based Forward Model Selection,"This paper introduces and analyzes a procedure called Testing-based forward model selection (TBFMS) in linear regression problems. This procedure inductively selects covariates that add predictive power into a working statistical model before estimating a final regression. The criterion for deciding which covariate to include next and when to stop including covariates is derived from a profile of traditional statistical hypothesis tests. This paper proves probabilistic bounds for prediction error and the number of selected covariates, which depend on the quality of the tests. The bounds are then specialized to a case with heteroskedastic data with tests derived from Huber-Eicker-White standard errors. TBFMS performance is compared to Lasso and Post-Lasso in simulation studies. TBFMS is then analyzed as a component into larger post-model selection estimation problems for structural economic parameters. Finally, TBFMS is used to illustrate an empirical application to estimating determinants of economic growth.",2015,arXiv: Statistics Theory
Shrinking symbolic regression over medical and physiological signals,"Medical embedded systems of the present and future are recording vast sets of data related to medical conditions and physiology. Linear modeling techniques are proposed as a means to help explain relationships between two or more medical or physiological signal measurements from the same human subject. In this paper a statistical regression algorithm is explored for use in medical monitoring, telehealth, and medical research applications. An essential element in applying linear modeling to physiological data is determining functional forms for the predictor signals. In this paper we demonstrate an efficient method for symbolic regression and model selection among possible transformation functions for the predictor variables. The three-stage method uses LASSO shrinkage regression to select a brief functional form and performs an polynomial lag regression with this form. This method is applied to medical and physiological time series data exploring the link between respiration and blood oxygen saturation percentage in sleep apnea patients. We found that our method for selecting a functional transformation of the predictor variable dramatically improved the goodness of fit of the model according to standard analysis of variance measures. In the dataset examined, the model achieved a multiple R2 of 0.3373, while a plain time-lagged model without transformation or polynomial lags had a R2 of only 0.016. All of the variables in the model produced by the algorithm had high scores in t tests for validity.",2010,2010 2nd International Conference on Signal Processing Systems
A new comorbidity index: the health-related quality of life comorbidity index.,"OBJECTIVE
To derive and validate the health-related quality of life comorbidity index (HRQL-CI).


STUDY DESIGN AND SETTING
Of 261 clinical classification codes (CCCs) in the 2003 Medical Expenditure Panel Survey (MEPS), 44 were identified as adult, gender-neutral, chronic conditions. The least absolute shrinkage and selection operator (LASSO) procedure identified CCCs significantly associated with the Short Form-12 physical component summary (PCS) and mental component summary (MCS) scores. Regression models were fitted with the selected CCCs, resulting in two subsets corresponding to PCS and MCS, collectively called the HRQL-CI. Internal validation was assessed using 10-fold cross-validation, whereas external validation in terms of prediction accuracy was assessed in the 2005 MEPS database. Prediction errors and model RÂ² were compared between HRQL-CI models and models using the Charlson-CI.


RESULTS
LASSO identified 20 CCCs significantly associated with PCS and 15 with MCS. The RÂ² for the models, including the HRQL-CI (0.28 for PCS and 0.16 for MCS) were greater than those using the Charlson-CI (0.13 for PCS and 0.01 for MCS). The same pattern of higher RÂ² for models using the HRQL-CI was observed in the validation tests.


CONCLUSION
The HRQL-CI is a valid risk adjustment index, outperforming the Charlson-CI. Further work is needed to test its performance in other patient populations and measures of HRQL.",2011,Journal of clinical epidemiology
Extending classical statistical methods to study customer satisfaction. An application to a private indoor climbing centre in France,"book 86 Extending classical statistical methods to study customer satisfaction. An application to a private indoor climbing centre in France Authors: StÃ©phane Champely & Ã‰ric Boutroy Institution: Centre for Research and Innovation in Sport (CRIS), Lyon 1 University, France. E-mail: champely@univ-lyon1.fr Abstract keywords Customer satisfaction study, Statistics, Importanceperformance analysis, Tetraclasse model, Lasso.keywords Customer satisfaction study, Statistics, Importanceperformance analysis, Tetraclasse model, Lasso. Background For managers, it is crucial to identify the key drivers that determine customer satisfaction. Importance-Performance Analysis (IPA) is a simple albeit effective tool to allocate scarce resources. The three-factor theory of customer satisfaction nevertheless suggests that the study of the relationship between attributes performance and overall satisfaction is more informative (Kano, 1984). Aims The paper will review and extend some classical statistical tools for studying customer satisfaction: IPA and the tetraclasse model (TM; Bodet, 2006). An innovative data learning technique, the lasso, will also be presented. Research design A customer satisfaction survey was carried out in November 2011 in the biggest French private indoor climbing centre. A census method was used during one week long (n=921). The questionnaire comprises in particular 25 attribute importance measurements and 25 corresponding performance measurements, each defined on a 4-point Likert scale. These variables describe primary and secondary services, service quality and atmosphere. In addition, overall satisfaction was evaluated. Initially rated as a 10-level Likert scale, it was later recoded as a 4-category ordinal variable. Methodology and data analysis IPA studies quality attributes on two dimensions: their performance level (satisfaction) and their importance to the customer. The resulting scatterplot helps to set high and low priorities, and possible overkill. Yet, this EPA display heavily depends on the survey sample size and the variability of both importance and performance measurements. It seems thus interesting to add some confidence intervals to study the robustness of this analysis (Farnum & Hall, 2007). Moreover, some market segmentation by sporting expertise or occupation can be also tested and depicted using the IPA plot. To study the relationship between an overall satisfaction measurement and attributes performances, the Llosaâ€™s TM employs a correspondence analysis. It is here proved that a similar plot can be obtained using basic percentage computations. Moreover, the resulting scales are easier to interpret and introduce light and shade into manager decisions. Supplementary confidence intervals can again be drawn. When overall satisfaction is measured on an ordinal response scale, the proportional odds model is a suitable regression tool. To select the most significant attributes performances, automatic selection algorithms are commonly used. However, when the number of explanatory variables is high, selection procedures exhibit a high variability. A different and innovative technique is presented: the lasso (Archer, 2011). By penalizing the coefficients size, more robust estimations are obtained. Plotting the coefficients against the penalizing parameter gives an idea of the results stability. Information criteria help to select the best-fitting model. Standardized coefficient (beta) could then be printed, plotted and interpreted. Furthermore, to detect the asymmetric impact of attributes performances on overall satisfaction, dummy variables can be introduced to identify excitement, performance and basic factors (Matzler et al, 2004). Results IPA indicates that satisfaction and importance are usually high for core services (good and varied routes, route renewal). On the contrary, price, cleanliness and waiting time are considered as important but not so well satisfied. These three attributes and the fitness room (not important in IPA) are classified as â€œplusâ€ by the TM. The core services and also conviviality and reception quality are considered as â€œbasicâ€. Advices, supervision and equipment renting seem to be key factors (for beginners). The lasso shows that overall satisfaction is a function of price, core services, reception quality, conviviality and cleanliness. Discussion and implications/conclusions The private indoor climbing centre must clearly concentrate its resources on its core services and does not try to become a general leisure centre. Human resources, mostly recruited for their sporting diploma (climbing), must be trained to customer relationship. A particular attention must be given to beginners. The IPA, the TM, the lasso analysis impact of each attributeâ€™s performance on overall satisfaction and the asymmetric impact analysis will be compared, emphasizing their respective strengths and weaknesses and the different kind of results that can be obtained. It seems nevertheless difficult to give a definitive answer to the question of the best approach. Depending on the manager goals, the measurement scales, the sample size, the prior knowledge about the attributes dimension and the mathematical sophistication of the user, advice may vary. In our mind, the four analyses are more complementary than rival to yield prescriptions for customer satisfaction management.",2012,
Statistical downscaling modeling with quantile regression using lasso to estimate extreme rainfall,"Rainfall is one of the climatic elements with high diversity and has many negative impacts especially extreme rainfall. Therefore, there are several methods that required to minimize the damage that may occur. So far, Global circulation models (GCM) are the best method to forecast global climate changes include extreme rainfall. Statistical downscaling (SD) is a technique to develop the relationship between GCM output as a global-scale independent variables and rainfall as a local- scale response variable. Using GCM method will have many difficulties when assessed against observations because GCM has high dimension and multicollinearity between the variables. The common method that used to handle this problem is principal components analysis (PCA) and partial least squares regression. The new method that can be used is lasso. Lasso has advantages in simultaneuosly controlling the variance of the fitted coefficients and performing automatic variable selection. Quantile regression is a method that can be us...",2016,
Stability SCAD: a powerful approach to detect interactions in large-scale genomic study,"BackgroundEvidence suggests that common complex diseases may be partially due to SNP-SNP interactions, but such detection is yet to be fully established in a high-dimensional small-sample (small-n-large-p) study. A number of penalized regression techniques are gaining popularity within the statistical community, and are now being applied to detect interactions. These techniques tend to be over-fitting, and are prone to false positives. The recently developed stability least absolute shrinkage and selection operator (SLASSO) has been used to control family-wise error rate, but often at the expense of power (and thus false negative results).ResultsHere, we propose an alternative stability selection procedure known as stability smoothly clipped absolute deviation (SSCAD). Briefly, this method applies a smoothly clipped absolute deviation (SCAD) algorithm to multiple sub-samples, and then identifies cluster ensemble of interactions across the sub-samples. The proposed method was compared with SLASSO and two kinds of traditional penalized methods by intensive simulation. The simulation revealed higher power and lower false discovery rate (FDR) with SSCAD. An analysis using the new method on the previously published GWAS of lung cancer confirmed all significant interactions identified with SLASSO, and identified two additional interactions not reported with SLASSO analysis.ConclusionsBased on the results obtained in this study, SSCAD presents to be a powerful procedure for the detection of SNP-SNP interactions in large-scale genomic data.",2013,BMC Bioinformatics
Polygenic Risk Scores for Prediction of Breast Cancer and Breast Cancer Subtypes,"Stratification of women according to their risk of breast cancer based on polygenic risk scores (PRSs) could improve screening and prevention strategies. Our aim was to develop PRSs, optimized for prediction of estrogen receptor (ER)-specific disease, from the largest available genome-wide association dataset and to empirically validate the PRSs in prospective studies. The development dataset comprised 94,075 case subjects and 75,017 control subjects of European ancestry from 69 studies, divided into training and validation sets. Samples were genotyped using genome-wide arrays, and single-nucleotide polymorphisms (SNPs) were selected by stepwise regression or lasso penalized regression. The best performing PRSs were validated in an independent test set comprising 11,428 case subjects and 18,323 control subjects from 10 prospective studies and 190,040 women from UK Biobank (3,215 incident breast cancers). For the best PRSs (313 SNPs), the odds ratio for overall disease per 1 standard deviation in ten prospective studies was 1.61 (95%CI: 1.57-1.65) with area under receiver-operator curve (AUC) = 0.630 (95%CI: 0.628-0.651). The lifetime risk of overall breast cancer in the top centile of the PRSs was 32.6%. Compared with women in the middle quintile, those in the highest 1% of risk had 4.37- and 2.78-fold risks, and those in the lowest 1% of risk had 0.16- and 0.27-fold risks, of developing ER-positive and ER-negative disease, respectively. Goodness-of-fit tests indicated that this PRS was well calibrated and predicts disease risk accurately in the tails of the distribution. This PRS is a powerful and reliable predictor of breast cancer risk that may improve breast cancer prevention programs.",2019,American Journal of Human Genetics
Post-Selection Inference for â„“1-Penalized Likelihood Models.,"We present a new method for post-selection inference for â„“1 (lasso)-penalized likelihood models, including generalized regression models. Our approach generalizes the post-selection framework presented in Lee et al. (2013). The method provides p-values and confidence intervals that are asymptotically valid, conditional on the inherent selection done by the lasso. We present applications of this work to (regularized) logistic regression, Cox's proportional hazards model and the graphical lasso. We do not provide rigorous proofs here of the claimed results, but rather conceptual and theoretical sketches.",2018,The Canadian journal of statistics = Revue canadienne de statistique
Enhanced Sparse Imputation Techniques for a Robust Speech Recognition Front-End,"Missing data techniques (MDTs) have been widely employed and shown to improve speech recognition results under noisy conditions. This paper presents a new technique which improves upon previously proposed sparse imputation techniques relying on the least absolute shrinkage and selection operator (LASSO). LASSO is widely employed in compressive sensing problems. However, the problem with LASSO is that it does not satisfy oracle properties in the event of a highly collinear dictionary, which happens with features extracted from most speech corpora. When we say that a variable selection procedure satisfies the oracle properties, we mean that it enjoys the same performance as though the underlying true model is known. Through experiments on the Aurora 2.0 noisy spoken digits database, we demonstrate that the Least Angle Regression implementation of the Elastic Net (LARS-EN) algorithm is able to better exploit the properties of a collinear dictionary, and thus is significantly more robust in terms of basis selection when compared to LASSO on the continuous digit recognition task with estimated mask. In addition, we investigate the effects and benefits of a good measure of sparsity on speech recognition rates. In particular, we demonstrate that a good measure of sparsity greatly improves speech recognition rates, and that the LARS modification of LASSO and LARS-EN can be terminated early to achieve improved recognition results, even though the estimation error is increased.",2011,"IEEE Transactions on Audio, Speech, and Language Processing"
Relationship between the MDS-UPDRS and Quality of Life: A large multicenter study of 3206 patients.,"BACKGROUND
The relationship between Health-Related Quality of Life (HRQoL) and MDS-UPDRS has not been fully studied so far. The aim of this study was to evaluate the relationship between all MDS-UPDRS components and HRQoL in a representative international cohort of PD patients.


METHODS
We collected demographic and disease-related data as well as MDS-UPDRS and PDQ8 scales. Data were analyzed using correlations between PDQ8 and all MDS-UPDRS items, subsequently two hierarchical multiple regressions were performed, first between the scores of the MDS-UPDRS Parts and PDQ8 and second between individual items from those Parts demonstrating significant relationship to PDQ8 scores in the first regression. LASSO regression analyses were performed to evaluate the relationship between PDQ8 and all individual MDS-UPDRS items.


RESULTS
A total of 3206 PD patients were included in the study. In the first regression analysis, PDQ8 was significantly related to MDS-UPDRS parts I and II, but not to III and IV. In the second regression model, significant contributions to PDQ8 were found for Part I items Fatigue, Pain, Depressed mood, Apathy; and Part II items Dressing, Doing hobbies, Freezing, Speech and Tremor. In the LASSO analysis, six Part I, seven Part II, three Part III and one Part IV items contributed to PDQ8 scores. The five items most significantly related to the model were Depressed mood, Dressing, Apathy, Pain and Fatigue.


CONCLUSIONS
This is so far the largest study related to HRQoL issues in PD. Restrictions in activities of daily living and non-motor symptoms significantly contribute to HRQoL in PD.",2018,Parkinsonism & related disorders
Gene expression profiles for a prognostic immunoscore in gastric cancer,"BACKGROUND
Increasing evidence has indicated an association between immune infiltration in gastric cancer and clinical outcome. However, reliable prognostic signatures, based on systematic assessments of the immune landscape inferred from bulk tumour transcriptomes, have not been established. The aim was to develop an immune signature, based on the cellular composition of the immune infiltrate inferred from bulk tumour transcriptomes, to improve the prognostic predictions of gastric cancer.


METHODS
Twenty-two types of immune cell fraction were estimated based on large public gastric cancer cohorts from the Gene Expression Omnibus using CIBERSORT. An immunoscore based on the fraction of immune cell types was then constructed using a least absolute shrinkage and selection operator (LASSO) Cox regression model.


RESULTS
Using the LASSO model, an immunoscore was established consisting of 11 types of immune cell fraction. In the training cohort (490 patients), significant differences were found between high- and low-immunoscore groups in overall survival across and within subpopulations with an identical TNM stage. Multivariable analysis revealed that the immunoscore was an independent prognostic factor (hazard ratio 1Â·92, 95 per cent c.i. 1Â·54 to 2Â·40). The prognostic value of the immunoscore was also confirmed in the validation (210) and entire (700) cohorts.


CONCLUSION
The proposed immunoscore represents a promising signature for estimating overall survival in patients with gastric cancer.",2018,The British Journal of Surgery
Statistical Theory (M16),"This is a course on parametric statistical theory that goes hand in hand with the Lent term course on nonparametric statistical theory. We begin by reviewing some basic principles and models in statistical inference that motivate the development, in the second chapter, of general inferential methods based on the likelihood function. Although these methods are usually perfectly adequate for relatively low-dimensional models, they can fail badly in high-dimensions { in particular, when the dimension of the parameter space (usually denoted p) is larger than the number of observations, n. These â€˜large p, small nâ€™ problems occur in a very wide range of applications, from microarray experiments in biology to portfolio selection in nance, and are at the forefront of modern Statistics. In Chapter 3, we will outline some of the most important recent developments, though this remains a very active research area. Basic principles and models: Likelihood and related quantities, suciency , linear models. Exponential families. [4] First-order theory: Review of basic probability, modes of convergence, Slutskyâ€™s theorem, stochastic order notation, moments and cumulants, Cochranâ€™s theorem. Review of Wald, score, likelihood ratio statistics and signed root versions, distribution theory in no nuisance parameter case. Generalised linear models. [5] High dimensional problems: Shrinkage. Ridge regression. Sparsity and traditional variable selection methods (e.g. AIC). Penalised likelihood, the LASSO and LARS algorithm, other penalty functions (e.g. SCAD). Multiple testing: Bonferroni correction. False discovery rate, Benjamini{Hochberg procedure. [7]",2005,
