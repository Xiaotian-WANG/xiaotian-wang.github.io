title,abstract,year,journal
Forecasting Real House Price of the U.S.: An Analysis Covering 1890 to 2012,"This paper evaluates the ability of Bayesian shrinkage-based dynamic predictive regression models estimated with hierarchical priors (Adaptive Jefferys, Adaptive Student-t, Lasso, Fussed Lasso and Elastic Net priors) and non-hierarchical priors (Gaussian, Lasso-LARS, Lasso-Landweber) in forecasting the U.S. real house price growth. We also compare results with forecasts from bivariate OLS regressions and principal component regression. We use annual dataset on 10 macroeconomic predictors spanning the period 1890 to 2012. Using an out-of-sample period of 1917 to 2012, our results based on MSE and McCracken (2007) MSE-F statistic, indicate that in general, the non-hierarchical Bayesian shrinkage estimators perform better than their hierarchical counterparts as well as the least square estimators. The Bayesian shrinkage estimated with Lasso-Landweber is the best-suited model for forecasting the U.S. real house price. Among the least square models, the individual regression with house price regressed on the fiscal policy variable outperforms the rest. Also results from Lasso-Landweber portray the fiscal policy variable as the best predictor of the U.S. house prices especially in the recent times while the short-term interest rate and real construction cost also did well at the beginning and middle of the sample.",2013,
Pivotal estimation via square-root lasso in nonparametric regression,"We propose a self-tuning v Lasso method that simultaneiously resolves three important practical problems in high-dimensional regression analysis, namely it handles the unknown scale, heteroscedasticity, and (drastic) non-Gaussianity of the noise. In addition, our analysis allows for badly behaved designs, for example perfectly collinear regressors, and generates sharp bounds even in extreme cases, such as the infinite variance case and the noiseless case, in contrast to Lasso. We establish various non-asymptotic bounds for v Lasso including prediction norm rate and sharp sparcity bound. Our analysis is based on new impact factors that are tailored to establish prediction rates. In order to cover heteroscedastic non-Gaussian noise, we rely on moderate deviation theory for self-normalized sums to achieve Gaussian-like results under weak conditions. Moreover, we derive bounds on the performance of ordinary least square (ols) applied to the model selected by v Lasso accounting for possible misspecification of the selected model. Under mild conditions the rate of convergence of ols post v Lasso is no worse than v Lasso even with a misspecified selected model and possibly better otherwise. As an application, we consider the use of v Lasso and post v Lasso as estimators of nuisance parameters in a generic semi-parametric problem (nonlinear instrumental/moment condition or Z-estimation problem).",2013,Annals of Statistics
Selection of classification boundaries using the logistic regression,"We propose the method for selecting classification boundaries for the logistic regression model, by applying the sparse regularization. We can investigate which combination of classification boundaries are truly necessary for the multinomial logistic model by encouraging some of coefficient parameters themselves or their differences toward exactly zeros. The model is estimated by the maximum penalized likelihood method with the fused lasso type penalty. We also introduce some model selection criteria for evaluating models estimated by the penalized likelihood method. Simulation and real data analysis show insights that the proposed method goes well.",2013,
Image quality assessment with lasso regression and pairwise score differences,"The reception of multimedia applications often depends on the quality of processed and displayed visual content. This is the main reason for the development of automatic image quality assessment (IQA) techniques which try to mimic properties of human visual system and produce objective scores for evaluated images. Most of them require a training step in which subjective scores, obtained in tests with human subjects, are used for parameters tuning. In this paper, it is shown that pairwise score differences (PSD) can be successfully used for training a full-reference hybrid IQA measure based on the least absolute shrinkage and selection operator (lasso) regression. The results of extensive experimental evaluation on four largest IQA benchmarks show that the proposed IQA technique is statistically better than its version trained using raw scores, and both approaches are statistically better than state-of-the-art full-reference IQA measures. They are also better than other hybrid approaches. In the paper, the evaluation protocol is extended with tests using PSD.",2016,Multimedia Tools and Applications
BiogÃ©ographie historique des crustacÃ©s malacostracÃ©s stygobies du Maroc,"L'origine et l'histoire evolutive de 11 familles de crustaces malacostraces stygobies dulcaquicoles du maroc sont reconstituees dans le cadre de la biogeographie historique, discipline qui utilise la phylogenie et la distribution des especes et la geologie historique. Les relations phylogenetiques revelees par l'analyse cladistique sont presentees pour les amphipodes metacrangonyctides et pseudoniphargides, et les isopodes cirolanides et microparasellides. Dix des 11 groupes ont une origine marine. Le modele biphase de colonisation et d'evolution permet de comprendre les etapes de leur entree dans les eaux souterraines, ainsi que leur evolution par vicariance lors des regressions marines. A differentes echelles du temps et de l'espace, divers evenements geologiques ont pu determiner la multiplication des lignees et des especes par vicariance: regressions marines mesozoiques et cenozoiques pour les groupes thalassoides, tectonique des plaques separant les ancetres africains et americains (amphipodes hadzioides, syncarides, thermosbaenaces), orogenese atlasique ou rifaine et creusement des vallees qui ont conduit aux especes endemiques actuelles. Les especes aux caracteres plesiomorphes les plus nombreux proviennent des regressions les plus anciennes et vice versa. La congruence entre l'histoire evolutive et biogeographique des metacrangonyctidae et des cirolanidae constitue un test de fiabilite de nos hypotheses. L'evolution est plus rapide dans le milieu interstitiel littoral que dans le milieu interstitiel continental. Pendant une meme periode l'evolution est plus rapide dans certains groupes (bogidiellidae) que dans d'autres (monodellidae). Les malacostraces stygobies dont l'histoire biogeographique est connue peuvent servir aux geologues, comme marqueurs de paleorivages, ou comme temoins permettant de dater l'emission d'une ile ou d'une region continentale",1993,
ModÃ¨les de prÃ©diction pour l'Ã©valuation gÃ©nomique des bovins laitiers franÃ§ais : application aux races Holstein et MontbÃ©liarde,"L'evolution rapide des techniques de sequencage et de genotypage soulevent de nouveaux defis dans le developpement des methodes de selection pour les animaux dâ€™elevage. Par comparaison de sequences, il est a present possible d'identifier des sites polymorphes dans chaque espece afin de baliser le genome par des marqueurs moleculaires appeles SNP (Single Nucleotide Polymorphism). Les methodes de selection des animaux a partir de cette information moleculaire necessitent une representation complete des effets genetiques. Meuwissen et al. (2001) ont introduit le concept de selection genomique en proposant de predire simultanement tous les effets des regions marquees puis de construire un index ""genomique"" en sommant les effets de chaque region. Le challenge dans lâ€™evaluation genomique est de disposer de la meilleure methode de prediction afin dâ€™obtenir des valeurs genetiques precises pour une selection efficace des animaux candidats. Lâ€™objectif general de cette these est d'explorer et dâ€™evaluer de nouvelles approches genomiques capables de predire des dizaines de milliers d'effets genetiques, sur la base des phenotypes de centaines d'individus. Elle sâ€™inscrit dans le cadre du projet ANR AMASGEN dont le but est dâ€™etendre la selection assistee par marqueurs, utilisee jusquâ€™a lors chez les bovins laitiers francais, et de developper une methode de prediction performante. Pour cela, un panel varie de methodes est explore en estimant leurs capacites predictives. Les methodes de regression PLS (Partial Least Squares) et sparse PLS, ainsi que des approches bayesiennes (LASSO bayesien et BayesCÏ€) sont comparees a deux methodes usuelles en amelioration genetique : le BLUP base sur lâ€™information pedigree et le BLUP genomique base sur lâ€™information des SNP. Ces methodologies fournissent des modeles de prediction efficaces meme lorsque le nombre dâ€™observations est tres inferieur au nombre de variables. Elles reposent sur la theorie des modeles lineaires mixtes gaussiens ou les methodes de selection de variables, en resumant lâ€™information massive des SNP par la construction de nouvelles variables. Les donnees etudiees dans le cadre de ce travail proviennent de deux races de bovins laitiers francais (1 172 taureaux de race Montbeliarde et 3 940 taureaux de race Holstein) genotypes sur environ 40 000 marqueurs SNP polymorphes. Toutes les methodes genomiques testees ici produisent des evaluations plus precises que la methode basee sur la seule information pedigree. On observe un leger avantage predictif des methodes bayesiennes sur certains caracteres mais elles sont cependant trop exigeantes en temps de calcul pour etre appliquees en routine dans un schema de selection genomique. Lâ€™avantage des methodes de selection de variables est de pouvoir faire face au nombre toujours plus important de donnees SNP. De plus, elles sont capables de mettre en evidence des ensembles reduits de marqueurs, identifies sur la base de leurs effets estimes, câ€™est-a-dire ayant un impact important sur les caracteres etudies. Il serait donc possible de developper une methode de prediction des valeurs genomiques sur la base de QTL detectes par ces approches.",2012,
Regression Phalanxes,"Tomal et al. (2015) introduced the notion of â€œphalanxesâ€ in the context of rareclass detection in two-class classification problems. A phalanx is a subset of features that work well for classification tasks. In this paper, we propose a different class of phalanxes for application in regression settings. We define a â€œRegression Phalanxâ€ â€“ a subset of features that work well together for prediction. We propose a novel algorithm which automatically chooses Regression Phalanxes from high-dimensional data sets using hierarchical clustering and builds a prediction model for each phalanx for further ensembling. Through extensive simulation studies and several real-life applications in various areas (including drug discovery, chemical analysis of spectra data, microarray analysis and climate projections) we show that an ensemble of Regression Phalanxes improves prediction accuracy when combined with effective prediction methods like Lasso or Random Forests.",2017,
Genomic Selection for Yield and Seed Protein Content in Soybean: A Study of Breeding Program Data and Assessment of Prediction Accuracy,"Soybean [Glycine max (L.) Merr.] is a major crop with high seed protein content. Genomic selection is expected to be a valuable tool in improving the efficiency of breeding programs, especially for complex traits such as yield. This study aimed to evaluate the accuracy of genomic selection for yield and seed protein content in a soybean breeding population. Having a structured population, we compared genomic prediction accuracy obtained using models calibrated across or within two subpopulations: early lines and late lines. Calibrations within subpopulations were more efficient. Using a medium density of markers and genomic best linear unbiased prediction(GBLUP) model, which assumes an additive polygenic architecture, we predicted ~32 and39% of phenotypic variation among late lines for seed protein content and yield, respectively. Prediction accuracy was further improved by including epistasis in the GBLUP model. Further, we assessed accuracies obtained using several Bayesian models that assume different distributions for marker effects: Bayesian ridge regression, Bayesian LASSO, Bayes Cp, and Bayes R. Overall, these approaches did not improve prediction accuracy. In this study, were ported preliminary results relevant to the study of the efficiency of genomic selection use in a breeding program.",2017,Crop Science
Size matters: observations regarding the sonographic double contour sign in different joint sizes in acute gouty arthritis,"ObjectiveIn distinguishing urate arthritis (UA) from non-crystal-related arthritides, joint sonography including the detection of the double contour sign (DCS) and hypervascularization using power Doppler ultrasound (PDUS) is an important step in the diagnostic process. But are these sonographic features equally reliable in every accessible joint under real-life conditions?MethodsWe retrospectively analyzed 362Â patients with acute arthritis and evaluated the DCS and the degree of PDUS hypervascularization in patients with gout and in those with arthritis other than urate arthritis (non-UA). We classified all joints into the groups small, medium, and large. Sensitivities, specificities, positive and negative predictive values (PPV/NPV), and aÂ binary regression model were calculated. We also evaluated the influence of serum uric acid levels (SUA) on the presence of aÂ DCS in each joint category.ResultsSensitivity of the DCS in gout was 72.5% in the entire cohort, 66.0% in large, 78.8% in medium, and 72.3% in small joints. In wrist joints the DCS sensitivity maxed at 83.3%, with aÂ specificity of 81.8%. The lowest rates of DCS sensitivity were found in gout patients with elbow joint involvement (42.9%). In all joints except metatarsophalangeal jointÂ 1 (MTP-1), the incidence of aÂ DCS increased by the increment of SUA levels above 7.5â€¯mg/dl (pâ€¯<â€‰0.001). PDUS signals were most commonly found in medium and small joints and were only scarce in large joints, independent of the underlying diagnosis.ConclusionsIn our study we detected different rates of accuracy regarding DCS and PDUS in patients with acute arthritis. The best results were seen in medium-size joints, especially wrists.ZusammenfassungZielBei der Unterscheidung zwischen Gichtarthritis und nichtkristallassoziierten Arthritiden ist die Arthrosonographie zur Detektion des Doppelkonturzeichens (DCS) und der Hypervaskularisation im Power-Doppler-Ultraschall (PDUS) ein wichtiger Schritt im diagnostischen Prozess. Aber sind diese sonographischen Zeichen unter Alltagsbedingungen gleichsam zuverlÃ¤ssig in allen untersuchbaren Gelenken?MethodenRetrospektiv wurden die Daten von 362 Patienten mit akuter Arthritis und das DCS analysiert sowie die Hypervaskularisation im PDUS bei FÃ¤llen mit Uratarthritis (UA) vs. Nichturatarthritis (non-UA) ausgewertet. Alle Gelenke wurden der GrÃ¶ÃŸe nach in klein, mittel und groÃŸ eingeordnet. Es wurden SensitivitÃ¤ten, SpezifitÃ¤ten, positive und negative prÃ¤diktive Werte und eine binÃ¤re Regression kalkuliert. AuÃŸerdem werteten die Autoren den Einfluss der SerumharnsÃ¤ure auf die Detektierbarkeit eines DCS in jeder Gelenkkategorie aus.ErgebnisseDie SensitivitÃ¤t des DCS bei Gicht in der gesamten Kohorte lag bei 72,5â€¯%, bei groÃŸen Gelenken bei 66,0â€¯%, bei mittleren betrug sie 78,8â€¯% und bei kleinen 72,3â€¯%. Die beste SensitivitÃ¤t war bei Handgelenken mit 83,3â€¯% bei einer SpezifitÃ¤t von 81,8â€¯% zu verzeichnen. Die niedrigste SensitivitÃ¤t fanden die Autoren bei Ellbogenmanifestation (42,9â€¯%). Bei allen Gelenken auÃŸer dem MetatarsophalangealgelenkÂ 1 (MTP-1) war die Inzidenz eines DCS bei SerumharnsÃ¤urewerten >7,5â€¯mg/dl signifikant erhÃ¶ht (pâ€¯<â€‰0,001). PDUS-Signale wurden unabhÃ¤ngig von der Diagnose am hÃ¤ufigsten bei mittleren und kleinen, dagegen kaum bei groÃŸen Gelenken gefunden.SchlussfolgerungenIn der vorliegenden Studie war die Genauigkeit der Vorhersage einer Gichtarthritis durch das DCS sowie das Auftreten von PDUS-HypervaskularitÃ¤t je nach Gelenk unterschiedlich. Die besten Ergebnisse wurden in mittelgroÃŸen Gelenken, insbesondere Handgelenken, erzielt.",2018,Zeitschrift fÃ¼r Rheumatologie
Econometric Game 2013: Forecasting Spanish GDP in a Rich Data Environment,"Recently, there is some evidence that the effectiveness of fiscal policies is not independent of the economic situations. Hence, being able to provide real GDP growth forecasts using all the available information is crucially important for economic authorities. In this paper, using a dataset of 70 different variables for the period 1970-2012 at quarterly frequency, we employ dynamic factors models and LASSO regression techniques to provide different forecasts for the Spanish quarterly GDP growth in 2013. We conclude that these techniques have a better predictive ability than a simple AR(4) model. Nonetheless, we find superiority of combined forecasts over single-model based predictions. With our preferred model, we forecast Spanish 2013 yearly GDP growth to be 0.08%.",2013,
Regularized Skew-Normal Regression,This paper considers the impact of using the regularisation techniques for the analysis of the extended skew-normal distribution. The approach is estimated using a number of techniques and compared to OLS based LASSO and ridge regressions in addition to non- constrained skew-normal regression.,2013,
Comment Prediction in Facebook Pages using Regression Techniques,"Data in Social Networks is increasing day by day. It requires highly managing service to handle the large amount of data towards it. This work is about to study the user activity patterns in Social Networks. So, concentrated on active social Networks which is â€œFacebookâ€ especially in Facebook Page. Here, user comment volume prediction is made based on page category i.e., for a particular category of pageâ€™s post will get certain amount of comments. In order to predict the comment volume for each page and to find which page category getting the highest comment. In preliminary work, it has been concluded with decision tree. So, In Further Study, have analyzed with some more Regression Techniques to make the prediction Effective. In this work, modelled the user comment pattern with respect to Page Likes and Popularity, Page Category and Time. Here Decision Tree, LASSO, K-Nearest Neighbor (KNN), Random Forest, and Leaner Regression Techniques are used. The error is found by Root Mean Square Error (RMSE) Metrics. Then, concluded that K-Nearest Neighbor Algorithm performing well and giving the effective prediction.",2018,
Sparsity identification in ultra-high dimensional quantile regression models with longitudinal data,"AbstractIn this paper, we propose a variable selection method for quantile regression model in ultra-high dimensional longitudinal data called as the weighted adaptive robust lasso (WAR-Lasso) whic...",2019,Communications in Statistics-theory and Methods
Generalizing matrix factorization through flexible regression priors,"Predicting user ""ratings"" on items is a crucial task in recommender systems. Matrix factorization methods that computes a low-rank approximation of the incomplete user-item rating matrix provide state-of-the-art performance, especially for users and items with several past ratings (warm starts). However, it is a challenge to generalize such methods to users and items with few or no past ratings (cold starts). Prior work [4][32] have generalized matrix factorization to include both user and item features for performing better regularization of factors as well as provide a model for smooth transition from cold starts to warm starts. However, the features were incorporated via linear regression on factor estimates. In this paper, we generalize this process to allow for arbitrary regression models like decision trees, boosting, LASSO, etc. The key advantage of our approach is the ease of computing --- any new regression procedure can be incorporated by ""plugging"" in a standard regression routine into a few intermediate steps of our model fitting procedure. With this flexibility, one can leverage a large body of work on regression modeling, variable selection, and model interpretation. We demonstrate the usefulness of this generalization using the MovieLens and Yahoo! Buzz datasets.",2011,
Radiomics study for predicting the expression of PD-L1 in non-small cell lung cancer based on CT images and clinicopathologic features.,"PURPOSE
To predict programmed death-ligand 1 (PD-L1) expression of tumor cells in non-small cell lung cancer (NSCLC) patients by using a radiomics study based on CT images and clinicopathologic features.


MATERIALS AND METHODS
A total of 390 confirmed NSCLC patients who performed chest CT scan and immunohistochemistry (IHC) examination of PD-L1 of lung tumors with clinic data were collected in this retrospective study, which were divided into two cohorts namely, training (nâ€Š=â€Š260) and validation (nâ€Š=â€Š130) cohort. Clinicopathologic features were compared between two cohorts. Lung tumors were segmented by using ITK-snap kit on CT images. Total 200 radiomic features in the segmented images were calculated using in-house texture analysis software, then filtered and minimized by least absolute shrinkage and selection operator (LASSO) regression to select optimal radiomic features based on its relevance of PD-L1 expression status in IHC results and develop radiomics signature. Radiomics signature and clinicopathologic risk factors were incorporated to develop prediction model by using multivariable logistic regression analysis. The receiver operating characteristic (ROC) curves were generated and the areas under the curves (AUC) were reckoned to predict PD-L1 expression in both training and validation cohorts.


RESULTS
In 200 extracted radiomic features, 9 were selected to develop radiomics signature. In univariate analysis, PD-L1 expression of lung tumors was significantly correlated with radiomics signature, histologic type, and histologic grade (pâ€Š< â€Š0.05, respectively). However, PD-L1 expression was not correlated with gender, age, tumor location, CEA level, TNM stage, and smoking (pâ€Š> â€Š0.05). For prediction of PD-L1 expression, the prediction model that combines radiomics signature and clinicopathologic features resulted in AUCs of 0.829 and 0.848 in the training and validation cohort, respectively.


CONCLUSION
The prediction model that incorporates the radiomics signature and clinical risk factors has potential to facilitate the individualized prediction of PD-L1 expression in NSCLC patients and identify patients who can benefit from anti-PD-L1 immunotherapy.",2020,Journal of X-ray science and technology
Habitat complexity modifies the impact of piscivores on a coral reef fish population,"Abstract Patterns in juvenile mortality rates can have a profound affect on the distribution and abundance of adult individuals, and may be the result of a number of interacting factors. Field observations at Lizard Island (Great Barrier Reef, Australia) showed that for a coral reef damselfish, Pomacentrus moluccensis, juvenile mortality (over 1 year) varied between 20 and almost 100% among sites. Correlative data showed that juvenile mortality increased as a function of initial densities (recruitment), predator densities and the availability of preferred coral substrata. A multiple regression showed that these three variables together did not explain significantly more variation in mortality than the single factor showing the strongest relationship. This appeared to be because recruitment, predator densities and preferred coral substrata were all highly correlated, suggesting that one, two or all of these factors may be influencing juvenile mortality rates. One hypothesis was that density-dependent mortality in juveniles was the result of an interaction between predators (which appear to aggregate at high-recruitment sites) and the availability of preferred substrata (predator refuges). We tested this hypothesis by using both laboratory and field experiments to see whether fish predation could significantly alter survivorship of this damselfish, and whether this impact was dependent upon the coral substratum. The laboratory experiment was designed to test the effects of three common predators (Pseudochromis fuscus, Cephalopholis boenak and Thalassoma lunare) and three different coral substrata that varied in their complexity (Pocillopora damicornis, Acropora nasuta and A. nobilis) on the survival of juvenile Pomacentrus moluccensis. There was a significant interaction between predator species and microhabitat in determining survival. Pseudochromis fuscus and C. boenak were both significantly better at capturing juvenile damselfish than T. lunare. Juvenile survivorship was significantly better when they were given the more complex corals, Pocillopora damicornis and A. nasuta, compared with those given the open-structured species A. nobilis. This pattern reflects habitat selection in the field. Predators differed in their strike rates and the proportion of strikes that were successful, but all exhibited greater success at prey capture where A. nobilis was provided as shelter. The interaction between the effect of predator species and microhabitat structure on damselfish survival was tested in the field for a cohort of juvenile Pomacentrus moluccensis. We examined juvenile survival in the presence and absence of two predators that co-occur on natural patch reefs (C. boenak and Pseudochromis fuscus). The experimental patch reefs we used for this purpose were constructed from both high complexity (Pocillopora damicornis) and low complexity (A. nobilis) coral substrata. Both juveniles and predators were translocated to reefs at natural densities. The effects of predation were clearly dependent upon the microhabitat. Reefs of the high-complexity coral with predators supported the same high numbers of Pomacentrus moluccensis as the reefs with no resident predators. However, damselfish abundance was significantly lower on low-complexity reefs with resident predators, relative to the other treatments. Background rates of loss were high, even on preferred coral in the absence of the manipulated predator, suggesting that transient predators may be even more important than the residents. We suggest that adult abundances in this species were strongly influenced by the densities of different predators and the availability of preferred refuges.",1998,Oecologia
A Practical Scheme and Fast Algorithm to Tune the Lasso With Optimality Guarantees,"We introduce a novel scheme for choosing the regularization parameter in high-dimensional linear regression with Lasso. This scheme, inspired by Lepski's method for bandwidth selection in non-parametric regression, is equipped with both optimal finite-sample guarantees and a fast algorithm. In particular, for any design matrix such that the Lasso has low sup-norm error under an ""oracle choice"" of the regularization parameter, we show that our method matches the oracle performance up to a small constant factor, and show that it can be implemented by performing simple tests along a single Lasso path. By applying the Lasso to simulated and real data, we find that our novel scheme can be faster and more accurate than standard schemes such as Cross-Validation.",2016,J. Mach. Learn. Res.
Minimum dietary diversity among women of reproductive age in urban Burkina Faso.,"Micronutrient malnutrition is a challenge for women of reproductive age, who are particularly vulnerable due to greater micronutrient needs. The minimum dietary diversity for women (MDD-W) indicator is a micronutrient adequacy's proxy for those women, but little is known about its relation to other dimensions. We assessed MDD-W and its association with other socioeconomic, food security and purchasing practices in urban Burkina Faso. We conducted multi-stage cluster sampling in two main cities of Burkina Faso, stratified by type of district, and interviewed 12 754 women in the 2009-2011 period. We obtained food consumption data through unquantified 24 hour recalls and computed MDD-W as consuming at least five out of ten predefined food groups. We constructed multivariable regression models with sociodemographic and food security covariates. MDD-W in urban Burkina Faso was 31%, higher in Ouagadougou (33%) than in Bobo-Dioulasso (29%), and lower in unstructured districts. The most frequently consumed food groups were 'all starchy', 'vitamin A rich dark green leafy vegetables' and 'other vegetables'. Household's expenses were associated with higher likelihood of MDD-W, while the association with household food security indicators varied by year and type of district. Purchasing foods in markets and choosing the place of purchase based on large choice rather than proximity showed a positive association with the MDD-W. Only one in three women in urban Burkina Faso reached the minimum dietary diversity, and although socioeconomic and food security variables had the greatest effect on MDD-W, purchasing practices, like going to the market, also showed a positive effect.",2019,Maternal & child nutrition
Distributed Sparse Linear Regression,"The Lasso is a popular technique for joint estimation and continuous variable selection, especially well-suited for sparse and possibly under-determined linear regression problems. This paper develops algorithms to estimate the regression coefficients via Lasso when the training data are distributed across different agents, and their communication to a central processing unit is prohibited for e.g., communication cost or privacy reasons. A motivating application is explored in the context of wireless communications, whereby sensing cognitive radios collaborate to estimate the radio-frequency power spectrum density. Attaining different tradeoffs between complexity and convergence speed, three novel algorithms are obtained after reformulating the Lasso into a separable form, which is iteratively minimized using the alternating-direction method of multipliers so as to gain the desired degree of parallelization. Interestingly, the per agent estimate updates are given by simple soft-thresholding operations, and inter-agent communication overhead remains at affordable level. Without exchanging elements from the different training sets, the local estimates consent to the global Lasso solution, i.e., the fit that would be obtained if the entire data set were centrally available. Numerical experiments with both simulated and real data demonstrate the merits of the proposed distributed schemes, corroborating their convergence and global optimality. The ideas in this paper can be easily extended for the purpose of fitting related models in a distributed fashion, including the adaptive Lasso, elastic net, fused Lasso and nonnegative garrote.",2010,IEEE Transactions on Signal Processing
(18)F-Fluorodeoxyglucose Positron Emission Tomography Can Quantify and Predict Esophageal Injury During Radiation Therapy.,"PURPOSE
We sought to investigate the ability of mid-treatment (18)F-fluorodeoxyglucose positron emission tomography (PET) studies to objectively and spatially quantify esophageal injury inÂ vivo from radiation therapy for non-small cell lung cancer.


METHODS AND MATERIALS
This retrospective study was approved by the local institutional review board, with written informed consent obtained before enrollment. We normalized (18)F-fluorodeoxyglucose PET uptake to each patient's low-irradiated region (<5Â Gy) of the esophagus, as a radiation response measure. Spatially localized metrics of normalized uptake (normalized standard uptake value [nSUV]) were derived for 79 patients undergoing concurrent chemoradiation therapy for non-small cell lung cancer. We used nSUV metrics to classify esophagitis grade at the time of the PET study, as well as maximum severity by treatment completion, according to National Cancer Institute Common Terminology Criteria for Adverse Events, using multivariate least absolute shrinkage and selection operator (LASSO) logistic regression and repeated 3-fold cross validation (training, validation, and test folds). This 3-fold cross-validation LASSO model procedure was used to predict toxicity progression from 43 asymptomatic patients during the PET study. Dose-volume metrics were also tested in both the multivariate classification and the symptom progression prediction analyses. Classification performance was quantified with the area under the curve (AUC) from receiver operating characteristic analysis on the test set from the 3-fold analyses.


RESULTS
Statistical analysis showed increasing nSUV is related to esophagitis severity. Axial-averaged maximum nSUV for 1 esophageal slice and esophageal length with at least 40% of axial-averaged nSUV both had AUCs of 0.85 for classifying grade 2 or higher esophagitis at the time of the PET study and AUCs of 0.91 and 0.92, respectively, for maximum grade 2 or higher by treatment completion. Symptom progression was predicted with an AUC of 0.75. Dose metrics performed poorly at classifying esophagitis (AUC of 0.52, grade 2 or higher mid treatment) or predicting symptom progression (AUC of 0.67).


CONCLUSIONS
Normalized uptake can objectively, locally, and noninvasively quantify esophagitis during radiation therapy and predict eventual symptoms from asymptomatic patients. Normalized uptake may provide patient-specific dose-response information not discernible from dose.",2016,"International journal of radiation oncology, biology, physics"
Lassoing the Determinants of Retirement,"This article uses Danish register data to explain the retirement decision of workers in 1990 and 1998. Many variables might be conjectured to influence this decision such as demographic, socioeconomic, financial, and health related variables as well as all the same factors for the spouse in case the individual is married. In total, we have access to 399 individual specific variables that all could potentially impact the retirement decision. We use variants of the least absolute shrinkage and selection operator (Lasso) and the adaptive Lasso applied to logistic regression in order to uncover determinants of the retirement decision. To the best of our knowledge, this is the first application of these estimators in microeconometrics to a problem of this type and scale. Furthermore, we investigate whether the factors influencing the retirement decision are stable over time, gender, and marital status. It is found that this is the case for core variables such as age, income, wealth, and general health. We also point out the most important differences between these groups and explain why these might be present.",2013,Econometric Reviews
Quantification of toxic metallic elements using machine learning techniques and spark emission spectroscopy,"Abstract. The United States Environmental Protection Agency (US EPA) list of Hazardous Air Pollutants (HAPs) includes metal elements suspected or associated with development of cancer. Traditional techniques for detecting and quantifying toxic metallic elements in the atmosphere are either not real time, hindering identification of sources, or limited by instrument costs. Spark emission spectroscopy is a promising and cost effective technique that can be used for analyzing toxic metallic elements in real time. Here, we have developed a cost-effective spark emission spectroscopy system to quantify the concentration of toxic metallic elements targeted by US EPA. Specifically, Cr, Cu, Ni, and Pb solutions were diluted and deposited on the ground electrode of the spark emission system. Least Absolute Shrinkage and Selection Operator (LASSO) was optimized and employed to detect useful features from the spark-generated plasma emissions. The optimized model was able to detect atomic emission lines along with other features to build a regression model that predicts the concentration of toxic metallic elements from the observed spectra. The limits of detections (LOD) were estimated using the detected features and compared to the traditional single-feature approach. LASSO is capable of detecting highly sensitive features in the input spectrum; however for some elements the single-feature LOD marginally outperforms LASSO LOD. The combination of low cost instruments with advanced machine learning techniques for data analysis could pave the path forward for data driven solutions to costly measurements.",2019,Atmospheric Measurement Techniques Discussions
Constructing large scale surrogate models from big data and artificial intelligence,"Abstract EnergyPlus is the U.S. Department of Energyâ€™s flagship whole-building energy simulation engine and provides extensive simulation capabilities. However, the computational cost of these capabilities has resulted in annual building simulations that typically requires 2â€“3Â min of wall-clock time to complete. While EnergyPlusâ€™s overall speed is improving (EnergyPlus 7.0 is 25â€“40% faster than EnergyPlus 6.0), the overall computational burden still remains and is the top user complaint. In other engineering domains, researchers substitute surrogate or approximate models for the computationally expensive simulations to improve simulation and reduce calibration time. Previous work has successfully demonstrated small-scale EnergyPlus surrogate models that use 10â€“16 input variables to estimate a single output variable. This work leverages feed forward neural networks and Lasso regression to construct robust large-scale EnergyPlus surrogate models based on 3 benchmark datasets that have 7â€“156 inputs. These models were able to predict 15-min values for most of the 80â€“90 simulation outputs deemed most important by domain experts within 5% (whole building energy within 0.07%) and calculate those results within 3Â s, greatly reducing the required simulation runtime for relatively close results. The techniques shown here allow any software to be approximated by machine learning in a way that allows one to quantify the trade-off of accuracy for execution time.",2017,Applied Energy
Enforcing Co-expression in Multimodal Regression Framework,"We consider the problem of multimodal data integration for the study of complex neurological diseases (e.g. schizophrenia). Among the challenges arising in such situation, estimating the link between genetic and neurological variability within a population sample has been a promising direction. A wide variety of statistical models arose from such applications. For example, Lasso regression and its multitask extension are often used to fit a multivariate linear relationship between given phenotype(s) and associated observations. Other approaches, such as canonical correlation analysis (CCA), are widely used to extract relationships between sets of variables from different modalities. In this paper, we propose an exploratory multivariate method combining these two methods. More Specifically, we rely on a 'CCA-type' formulation in order to regularize the classical multimodal Lasso regression problem. The underlying motivation is to extract discriminative variables that display are also co-expressed across modalities. We first evaluate the method on a simulated dataset, and further validate it using Single Nucleotide Polymorphisms (SNP) and functional Magnetic Resonance Imaging (fMRI) data for the study of schizophrenia.",2017,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
Temporal prediction of future state occupation in a multistate model from high-dimensional baseline covariates via pseudo-value regression,"ABSTRACT In many complex diseases such as cancer, a patient undergoes various disease stages before reaching a terminal state (say disease free or death). This fits a multistate model framework where a prognosis may be equivalent to predicting the state occupation at a future time t. With the advent of high-throughput genomic and proteomic assays, a clinician may intent to use such high-dimensional covariates in making better prediction of state occupation. In this article, we offer a practical solution to this problem by combining a useful technique, called pseudo-value (PV) regression, with a latent factor or a penalized regression method such as the partial least squares (PLS) or the least absolute shrinkage and selection operator (LASSO), or their variants. We explore the predictive performances of these combinations in various high-dimensional settings via extensive simulation studies. Overall, this strategy works fairly well provided the models are tuned properly. Overall, the PLS turns out to be slightly better than LASSO in most settings investigated by us, for the purpose of temporal prediction of future state occupation. We illustrate the utility of these PV-based high-dimensional regression methods using a lung cancer data set where we use the patientsâ€™ baseline gene expression values.",2017,Journal of Statistical Computation and Simulation
"Investigation of prediction accuracy and the impact of sample size, ancestry, and tissue in transcriptome-wide association studies.","In transcriptome-wide association studies (TWAS), gene expression values are predicted using genotype data and tested for association with a phenotype. The power of this approach to detect associations relies, at least in part, on the accuracy of the prediction. Here we compare the prediction accuracy of six different methods-LASSO, Ridge regression, Elastic net, Best Linear Unbiased Predictor, Bayesian Sparse Linear Mixed Model, and Random Forests-by performing cross-validation using data from the Geuvadis Project. We also examine prediction accuracy (a) at different sample sizes, (b) when ancestry of the prediction model training and testing populations is different, and (c) when the tissue used to train the model is different from the tissue to be predicted. We find that, for most genes, the expression cannot be accurately predicted, but in general sparse statistical models tend to outperform polygenic models at prediction. Average prediction accuracy is reduced when the model training set size is reduced or when predicting across ancestries and is marginally reduced when predicting across tissues. We conclude that using sparse statistical models and the development of large reference panels across multiple ethnicities and tissues will lead to better prediction of gene expression, and thus may improve TWAS power.",2020,Genetic epidemiology
Robust Bayesian inference under model misspecification,"Bayesian inference is considered one of the best statistical methods available when the model is correctly specified. On the other hand, when this is not the case, and model assumptions do not hold, it can lead to suboptimal results. Equipping the likelihood with a learning rate parameter protects against this. In this thesis the performances of various more robust Bayesian approaches, that differ in the way the learning rate parameter is chosen, are compared to standard Bayes in a variety of situations. Results for various classification problems (with simulated data) and Lasso-type regression problems (with real-world data) indicate that the robust forms of Bayes outperform standard Bayes when the model is incorrect, and donâ€™t perform much worse when the model is correct. Especially the robust Bayesian method with learning rate parameter estimated by k-fold cross-validation achieves good results.",2013,
Structured association analysis leads to insight into Saccharomyces cerevisiae gene regulation by finding multiple contributing eQTL hotspots associated with functional gene modules,"BackgroundAssociation analysis using genome-wide expression quantitative trait locus (eQTL) data investigates the effect that genetic variation has on cellular pathways and leads to the discovery of candidate regulators. Traditional analysis of eQTL data via pairwise statistical significance tests or linear regression does not leverage the availability of the structural information of the transcriptome, such as presence of gene networks that reveal correlation and potentially regulatory relationships among the study genes. We employ a new eQTL mapping algorithm, GFlasso, which we have previously developed for sparse structured regression, to reanalyze a genome-wide yeast dataset. GFlasso fully takes into account the dependencies among expression traits to suppress false positives and to enhance the signal/noise ratio. Thus, GFlasso leverages the gene-interaction network to discover the pleiotropic effects of genetic loci that perturb the expression level of multiple (rather than individual) genes, which enables us to gain more power in detecting previously neglected signals that are marginally weak but pleiotropically significant.ResultsWhile eQTL hotspots in yeast have been reported previously as genomic regions controlling multiple genes, our analysis reveals additional novel eQTL hotspots and, more interestingly, uncovers groups of multiple contributing eQTL hotspots that affect the expression level of functional gene modules. To our knowledge, our study is the first to report this type of gene regulation stemming from multiple eQTL hotspots. Additionally, we report the results from in-depth bioinformatics analysis for three groups of these eQTL hotspots: ribosome biogenesis, telomere silencing, and retrotransposon biology. We suggest candidate regulators for the functional gene modules that map to each group of hotspots. Not only do we find that many of these candidate regulators contain mutations in the promoter and coding regions of the genes, in the case of the Ribi group, we provide experimental evidence suggesting that the identified candidates do regulate the target genes predicted by GFlasso.ConclusionsThus, this structured association analysis of a yeast eQTL dataset via GFlasso, coupled with extensive bioinformatics analysis, discovers a novel regulation pattern between multiple eQTL hotspots and functional gene modules. Furthermore, this analysis demonstrates the potential of GFlasso as a powerful computational tool for eQTL studies that exploit the rich structural information among expression traits due to correlation, regulation, or other forms of biological dependencies.",2012,BMC Genomics
Circulating MicroRNAs as Non-Invasive Biomarkers for Early Detection of Non-Small-Cell Lung Cancer,"BACKGROUND
Detection of lung cancer at an early stage by sensitive screening tests could be an important strategy to improving prognosis. Our objective was to identify a panel of circulating microRNAs in plasma that will contribute to early detection of lung cancer.


MATERIAL AND METHODS
Plasma samples from 100 early stage (I to IIIA) non-small-cell lung cancer (NSCLC) patients and 100 non-cancer controls were screened for 754 circulating microRNAs via qRT-PCR, using TaqMan MicroRNA Arrays. Logistic regression with a lasso penalty was used to select a panel of microRNAs that discriminate between cases and controls. Internal validation of model discrimination was conducted by calculating the bootstrap optimism-corrected AUC for the selected model.


RESULTS
We identified a panel of 24 microRNAs with optimum classification performance. The combination of these 24 microRNAs alone could discriminate lung cancer cases from non-cancer controls with an AUC of 0.92 (95% CI: 0.87-0.95). This classification improved to an AUC of 0.94 (95% CI: 0.90-0.97) following addition of sex, age and smoking status to the model. Internal validation of the model suggests that the discriminatory power of the panel will be high when applied to independent samples with a corrected AUC of 0.78 for the 24-miRNA panel alone.


CONCLUSION
Our 24-microRNA predictor improves lung cancer prediction beyond that of known risk factors.",2015,PLoS ONE
"Combining Optical, Fluorescence, Thermal Satellite, and Environmental Data to Predict County-Level Maize Yield in China Using Machine Learning Approaches","Maize is an extremely important grain crop, and the demand has increased sharply throughout the world. China contributes nearly one-fifth of the total production alone with its decreasing arable land. Timely and accurate prediction of maize yield in China is critical for ensuring global food security. Previous studies primarily used either visible or near-infrared (NIR) based vegetation indices (VIs), or climate data, or both to predict crop yield. However, other satellite data from different spectral bands have been underutilized, which contain unique information on crop growth and yield. In addition, although a joint application of multi-source data significantly improves crop yield prediction, the combinations of input variables that could achieve the best results have not been well investigated. Here we integrated optical, fluorescence, thermal satellite, and environmental data to predict county-level maize yield across four agro-ecological zones (AEZs) in China using a regression-based method (LASSO), two machine learning (ML) methods (RF and XGBoost), and deep learning (DL) network (LSTM). The results showed that combining multi-source data explained more than 75% of yield variation. Satellite data at the silking stage contributed more information than other variables, and solar-induced chlorophyll fluorescence (SIF) had an almost equivalent performance with the enhanced vegetation index (EVI) largely due to the low signal to noise ratio and coarse spatial resolution. The extremely high temperature and vapor pressure deficit during the reproductive period were the most important climate variables affecting maize production in China. Soil properties and management factors contained extra information on crop growth conditions that cannot be fully captured by satellite and climate data. We found that ML and DL approaches definitely outperformed regression-based methods, and ML had more computational efficiency and easier generalizations relative to DL. Our study is an important effort to combine multi-source remote sensed and environmental data for large-scale yield prediction. The proposed methodology provides a paradigm for other crop yield predictions and in other regions.",2020,Remote Sensing
Postprandial metabolite profiles associated with type 2 diabetes clearly stratify individuals with impaired fasting glucose,"IntroductionFasting metabolite profiles have been shown to distinguish type 2 diabetes (T2D) patients from normal glucose tolerance (NGT) individuals.ObjectivesWe investigated whether, besides fasting metabolite profiles, postprandial metabolite profiles associated with T2D can stratify individuals with impaired fasting glucose (IFG) by their similarities to T2D.MethodsThree groups of individuals (age 45â€“65Â years) without any history of IFG or T2D were selected from the Netherlands Epidemiology of Obesity study and stratified by baseline fasting glucose concentrations (NGT (nâ€‰=â€‰176), IFG (nâ€‰=â€‰186), T2D (nâ€‰=â€‰171)). 163 metabolites were measured under fasting and postprandial states (150Â min after a meal challenge). Metabolite profiles specific for a high risk of T2D were identified by LASSO regression for fasting and postprandial states. The selected profiles were utilised to stratify IFG group into high (T2D probabilityâ€‰â‰¥â€‰0.7) and low (T2D probabilityâ€‰â‰¤â€‰0.5) risk subgroups. The stratification performances were compared with clinically relevant metabolic traits.ResultsTwo metabolite profiles specific for T2D (nfastingÂ =Â 12 metabolites, npostprandialÂ =Â 4 metabolites) were identified, with all four postprandial metabolites also being identified in the fasting state. Stratified by the postprandial profile, the high-risk subgroup of IFG individuals (nâ€‰=â€‰72) showed similar glucose concentrations to the low-risk subgroup (nâ€‰=â€‰57), yet a higher BMI (difference: 3.3Â kg/m2 (95% CI 1.7â€“5.0)) and postprandial insulin concentrations (21.5Â mU/L (95% CI 1.8â€“41.2)).ConclusionPostprandial metabolites identified T2D patients as good as fasting metabolites and exhibited enhanced signals for IFG stratification, which offers a proof of concept that metabolomics research should not focus on the fasting state alone.",2017,Metabolomics
Identification of miRNA-Based Signature as a Novel Potential Prognostic Biomarker in Patients with Breast Cancer,"To identify the novel, noninvasive biomarkers to assess the outcome and prognosis of breast cancer (BC), patients with high sensitivity and specificity are greatly desired. Herein, the miRNA expression profile and matched clinical features of BC patients were extracted from The Cancer Genome Atlas (TCGA) database. The preliminary candidates were screened out by the univariate Cox regression test. Then, with the help of LASSO Cox regression analysis, the hsa-let-7b, hsa-mir-101-2, hsa-mir-135a-2, hsa-mir-22, hsa-mir-30a, hsa-mir-31, hsa-mir-3130-1, hsa-mir-320b-1, hsa-mir-3678, hsa-mir-4662a, hsa-mir-4772, hsa-mir-493, hsa-mir-556, hsa-mir-652, hsa-mir-6733, hsa-mir-874, and hsa-mir-9-3 were selected to construct the overall survival (OS) predicting signature, while the hsa-mir-130a, hsa-mir-204, hsa-mir-217, hsa-mir-223, hsa-mir-24-2, hsa-mir-29b-1, hsa-mir-363, hsa-mir-5001, hsa-mir-514a-1, hsa-mir-624, hsa-mir-639, hsa-mir-659, and hsa-mir-6892 were adopted to establish the recurrence-free survival (RFS) predicting signature. Referring to the median risk scores generated by the OS and RFS formulas, respectively, subgroup patients with high risk were strongly related to a poor OS and RFS revealed by Kaplan-Meier (K-M) plots. Meanwhile, receiver operating curve (ROC) analysis validated the accuracy and stability of these two signatures. When stratified by clinical features, such as tumor stage, age, and molecular subtypes, we found that the miRNA-based OS and RFS classifiers were still significant in predicting OS/RFS and showed the best predictive values than any other features. Besides, functional prediction analyses showed that these targeted genes of the enrolled miRNAs were enriched in cancer-associated pathways, such as MAPK/RTK, Ras, and PI3K-Akt signaling pathways. In summary, our observations demonstrate that the novel miRNA-based OS and RFS signatures are independent prognostic indicators for BC patients and worthy to be validated by further prospective studies.",2019,Disease Markers
Variable Selection in Frailty Models using FrailtyHL R Package: Breast Cancer Survival Data,"Abstract Determining relevant variables for a regression model is important in regression analysis. Recently, a variableselection methods using a penalized likelihood with various penalty functions (e.g. LASSO and SCAD) havebeen widely studied in simple statistical models such as linear models and generalized linear models. Theadvantage of these methods is that they select important variables and estimate regression coeï¬ƒcients,simultaneously; therefore, they delete insigniï¬cant variables by estimating their coeï¬ƒcients as zero. Westudy how to select proper variables based on penalized hierarchical likelihood (HL) in semi-parametricfrailty models that allow three penalty functions, LASSO, SCAD and HL. For the variable selection wedevelop a new function in the â€œfrailtyHLâ€ R package. Our methods are illustrated with breast cancersurvival data from the Medical Center at Chonnam National University in Korea. We compare the resultsfrom three variable-selection methods and discuss advantages and disadvantages.Keywords: frailty models, H-likelihood, LASSO, SCAD, Variable selection",2015,
On a Semiparametric Dataâ€Driven Nonlinear Model with Penalized Spatioâ€Temporal Lag Interactions,"To study possibly nonlinear relationship between housing price index (HPI) and consumer price index (CPI) for individual states in the USA, accounting for the temporal lag interactions of the housing price in a given state and spatioâ€temporal lag interactions between states could improve the accuracy of estimation and forecasting. There lacks, however, methodology to objectively identify and estimate such spatioâ€temporal lag interactions. In this article, we propose a semiparametric dataâ€driven nonlinear time series regression method that accounts for lag interactions across space and over time. A penalized procedure utilizing adaptive Lasso is developed for the identification and estimation of important spatioâ€temporal lag interactions. Theoretical properties for our proposed methodology are established under a general near epoch dependence structure and thus the results can be applied to a variety of linear and nonlinear time series processes. For illustration, we analyze the US housing price data and demonstrate substantial improvement in forecasting via the identification of nonlinear relationship between HPI and CPI as well as spatioâ€temporal lag interactions.",2019,Journal of Time Series Analysis
Asymmetric Effect with Quantile Regression for Interval-Valued Variables,"In this paper, we propose a quantile regression with interval valued data using a convex combination method. The model we propose generalizes series of existing models, say typically with the center method. Three estimation techniques consisting EM algorithm, Least squares, Lasso penalty are presented to estimate the unknown parameters of our model. A series of Monte Carlo experiments are conducted to assess the performance of our proposed model. The results support our theoretical properties. Finally, we apply our model to empirical data in order to show the usefulness of the proposed model. The results imply that the EM algorithm provides a best fit estimation for our data set and captures the effect of oil differently across various quantile levels.",2018,
Second order Stein: SURE for SURE and other applications in high-dimensional inference.,"Stein's formula states that a random variable of the form $z^\top f(z) - {\rm{div}} f(z)$ is mean-zero for all functions $f$ with integrable gradient. Here, ${\rm{div}} f$ is the divergence of the function $f$ and $z$ is a standard normal vector. A Second Order Stein formula is proposed to characterize the variance of such random variables. 
In the Gaussian sequence model, a remarkable consequence of Stein's formula is Stein's Unbiased Risk Estimate (SURE) of the mean square risk of almost any given estimator $\hat\mu$ for the unknown mean vector. A first application of the Second Order Stein formula is an Unbiased Risk Estimate of the risk of SURE itself (SURE for SURE): a simple unbiased estimate provides information about the squared distance between SURE and the squared estimation error of $\hat\mu$. SURE for SURE has a simple form and can be computed explicitly for differentiable $\hat\mu$, for example the Lasso and the Elastic Net. 
Other applications of the Second Order Stein formula are provided in high-dimensional regression. This includes novel bounds on the variance of the size of the model selected by the Lasso, and a general semi-parametric scheme to de-bias an almost differentiable initial estimator in order to estimate a low-dimensional projection of the unknown regression coefficient vector.",2018,arXiv: Statistics Theory
A Dirty Model for Multiple Sparse Regression,"The task of sparse linear regression consists of finding an unknown sparse vector from linear measurements. Solving this task even under â€œhigh-dimensionalâ€ settings, where the number of samples is fewer than the number of variables, is now known to be possible via methods such as the LASSO. We consider the multiple sparse linear regression problem, where the task consists of recovering several related sparse vectors at once. A simple approach to this task would involve solving independent sparse linear regression problems, but a natural question is whether one can reduce the overall number of samples required by leveraging partial sharing of the support sets, or nonzero patterns, of the signal vectors. A line of recent research has studied the use of â„“1/â„“q norm block-regularizations with q > 1 for such problems. However, depending on the level of sharing, these could actually perform worse in sample complexity when compared to solving each problem independently. We present a new â€œadaptiveâ€ method for multiple sparse linear regression that can leverage support and parameter overlap when it exists, but not pay a penalty when it does not. We show how to achieve this using a very simple idea: decompose the parameters into two components and regularize these differently. We show, theoretically and empirically, that our method strictly and noticeably outperforms both â„“1 or â„“1/â„“q methods, over the entire range of possible overlaps (except at boundary cases, where we match the best method), even under high-dimensional scaling.",2013,IEEE Transactions on Information Theory
A Unified Robust Regression Model for Lasso-like Algorithms,"We develop a unified robust linear regression model and show that it is equivalent to a general regularization framework to encourage sparse-like structure that contains group Lasso and fused Lasso as specific examples. This provides a robustness interpretation of these widely applied Lasso-like algorithms, and allows us to construct novel generalizations of Lasso-like algorithms by considering different uncertainty sets. Using this robustness interpretation, we present new sparsity results, and establish the statistical consistency of the proposed regularized linear regression. This work extends a classical result from Xu et al. (2010) that relates standard Lasso with robust linear regression to learning problems with more general sparse-like structures, and provides new robustness-based tools to to understand learning problems with sparse-like structures.",2013,
Multiplex quantitation of 270 plasma protein markers to identify a signature for early detection of colorectal cancer.,"Blood-based protein biomarker signatures might be an alternative or supplement to existing methods for early detection of colorectal cancer (CRC) for population-based screening. The objective of this study was to derive a protein biomarker signature for early detection of CRC and its precursor advanced adenoma (AA). In a two-stage design, 270 protein markers were measured by liquid chromatography/multiple reaction monitoring/mass spectrometryÂ in plasma samples of discovery and validation sets. In the discovery set consisting of 100 newly diagnosed CRC cases and 100 age- and sex-matched controls free of neoplasm at screening colonoscopy, the algorithms predicting the presence of early- or late-stage CRC were derived by Lasso regression and .632Â +Â bootstrap. The prediction algorithms were then externally validated in an independent validation set consisting of participants of screening colonoscopy including 56 participants with CRC, 99 with AA and 99 controls without any colorectal neoplasms. Three different signatures for all-, early- and late-stageÂ CRC consisting of five-, three- and eight-protein markers were obtained in the discovery set with areas under the curves (AUCs) after .632Â +Â bootstrap adjustment of 0.85, 0.83 and 0.96, respectively. External validation in the representative screening population yielded AUCs of 0.79 (95% CI, 0.70-0.86), 0.79 (95% CI, 0.66-0.89) and 0.80 (95% CI, 0.70-0.89) for all-, early- and late-stage CRCs, respectively. The three-marker early-stage algorithm yielded an AUC of 0.65 (95% CI, 0.56-0.73) for detection of AA in the validation set. Although not yet competitive with available stool-based tests for CRC early detection, the identified proteins may contribute to the development of powerful blood-based tests for early detection of CRC and its precursors AAs.",2020,European journal of cancer
Long non-coding RNA identification over mouse brain development by integrative modeling of chromatin and genomic features,"In silico prediction of genomic long non-coding RNAs (lncRNAs) is prerequisite to the construction and elucidation of non-coding regulatory network. Chromatin modifications marked by chromatin regulators are important epigenetic features, which can be captured by prevailing high-throughput approaches such as ChIP sequencing. We demonstrate that the accuracy of lncRNA predictions can be greatly improved when incorporating high-throughput chromatin modifications over mouse embryonic stem differentiation toward adult Cerebellum by logistic regression with LASSO regularization. The discriminating features include H3K9me3, H3K27ac, H3K4me1, open reading frames and several repeat elements. Importantly, chromatin information is suggested to be complementary to genomic sequence information, highlighting the importance of an integrated model. Applying integrated model, we obtain a list of putative lncRNAs based on uncharacterized fragments from transcriptome assembly. We demonstrate that the putative lncRNAs have regulatory roles in vicinity of known gene loci by expression and Gene Ontology enrichment analysis. We also show that the lncRNA expression specificity can be efficiently modeled by the chromatin data with same developmental stage. The study not only supports the biological hypothesis that chromatin can regulate expression of tissue-specific or developmental stage-specific lncRNAs but also reveals the discriminating features between lncRNA and coding genes, which would guide further lncRNA identifications and characterizations.",2013,Nucleic Acids Research
MÃ©thodes quasi-Monte Carlo et Monte Carlo : application aux calculs des estimateurs Lasso et Lasso bayÃ©sien,"La these contient 6 chapitres. Le premier chapitre contient une introduction a la regression lineaire et aux problemes Lasso et Lasso bayesien. Le chapitre 2 rappelle les algorithmes dâ€™optimisation convexe et presente lâ€™algorithme FISTA pour calculer lâ€™estimateur Lasso. La statistique de la convergence de cet algorithme est aussi donnee dans ce chapitre en utilisant lâ€™entropie et lâ€™estimateur de Pitman-Yor. Le chapitre 3 est consacre a la comparaison des methodes quasi-Monte Carlo et Monte Carlo dans les calculs numeriques du Lasso bayesien. Il sort de cette comparaison que les points de Hammersely donne les meilleurs resultats. Le chapitre 4 donne une interpretation geometrique de la fonction de partition du Lasso bayesien et lâ€™exprime en fonction de la fonction Gamma incomplete. Ceci nous a permis de donner un critere de convergence pour lâ€™algorithme de Metropolis Hastings. Le chapitre 5 presente lâ€™estimateur bayesien comme la loi limite dâ€™une equation differentielle stochastique multivariee. Ceci nous a permis de calculer le Lasso bayesien en utilisant les schemas numeriques semi implicite et explicite dâ€™Euler et les methodes de Monte Carlo, Monte Carlo a plusieurs couches (MLMC) et lâ€™algorithme de Metropolis Hastings. La comparaison des couts de calcul montre que le couple (schema semi-implicite dâ€™Euler, MLMC) gagne contre les autres couples (schema, methode). Finalement dans le chapitre 6 nous avons trouve la vitesse de convergence du Lasso bayesien vers le Lasso lorsque le rapport signal/bruit est constant et le bruit tend vers 0. Ceci nous a permis de donner de nouveaux criteres pour la convergence de lâ€™algorithme de Metropolis Hastings.",2016,
RiskAnalytics: an R package for real time processing of Nasdaq and Yahoo finance data and parallelized quantile lasso regression methods,"In order to integrate and facilitate the research, calculation and analysis methods around the Financial Risk Meter (FRM) project, the R package RiskAnalytics has been developed. Its main goal is to provide data processing and parallelized quantile lasso regression methods for risk analysis based on NASDAQ data, Yahoo Finance data and some macro variables. The derived â€œRisk Analyticsâ€ can help to forecast and evaluate the systemic risk for the corresponding markets. The visualization and the up-to-date FRM can be found on http://frm.wiwi.hu-berlin.de. Supplementary R codes are published on www.quantlet.de with the keyword FRM. The RiskAnalytics package is a convenient tool with the purpose of integrating lasso penalized quantile regression methods with full solution paths and cluster computing support around the topic â€œRisk Analytics and FRMâ€.",2017,
Using LASSO to Model Interactions and Nonlinearities in Survey Data,"The LASSO and its variants have become a core part of the machine learning toolkit. Similar to OLS and logistic regression, the LASSO can be applied to continuous or binary data. The LASSO is a form of penalized regression, shrinking some coefficients exactly to zero. Because of that, it is especially useful for variable selection â€” for example, in situations where there are many potential covariates, only a few of which are likely relevant. In this article, we introduce the LASSO (and Adaptive LASSO) and show how it can be applied in situations where the researcher thinks the outcome variable is a nonlinear and/or interacted function of the covariates. Our motivating example is survey response. We provide an example showing how to model survey response using the LASSO and a polynomial expansion of the covariates. Our resulting model has better out-of-sample prediction for survey response than does a traditional logistic regression model. Example R code is provided in the supplemental materials.",2018,Survey practice
A Simulation Study to Evaluate Bayesian LASSOâ€™s Performance in Zero-Inflated Poisson (ZIP) Models,"When modelling count data, it is possible to have excessive zeros in the data in many applications. My thesis concentrates on the variable selection in zero-inflated Poisson (ZIP) models. This thesis work is motivated by Brown et al. (2015), who considered the excessive amount of zero in their data structure and the site-specific random effects, and used Bayesian LASSO method for variable selection in their post-fire tree recruitment study in interior Alaska, USA and north Yukon, Canada. However, the above study has not carried out systematic simulation studies to evaluate Bayesian LASSOâ€™s performance under different scenarios. Therefore, my thesis conducts a series of simulation studies to evaluate Bayesian LASSOâ€™s performance with respect to different setting of some simulation factors. My thesis considers three simulation factors: the number of subjects (N), the number of repeated measurements (R) and the true values of regression coefficients in the ZIP models. With different settings of the three factors, the proposed Bayesian LASSOâ€™s performance would be evaluated using three indicators: the sensitivity, the specificity and the exact fit rate. For applied practitioners, my thesis would be a useful example demonstrating under what circumstances one can expect Bayesian LASSO to have good performance in ZIP models. After sorting out the simulation results, we can find that Bayesian LASSOâ€™s performance is jointly affected by all the three simulation factors, while this method of variable selection is more reliable when the true coefficients are not close to zero. My thesis also has some limitations. Primarily, with the time limitation of my thesis, it is impossible to consider all the factors that can potentially affect the simulation results, and using other penalty forms other than L1 penalty is also left for future researchers to work on. Moreover, the current variable selection method is only for fixed effects selection while the variable selection for the mixed effect selection in ZIP models can be a direction for future work.",2016,
Instance-Dependent Cost-Sensitive Learning for Detecting Transfer Fraud,"Card transaction fraud is a growing problem affecting card holders worldwide. Financial institutions increasingly rely upon data-driven methods for developing fraud detection systems, which are able to automatically detect and block fraudulent transactions. From a machine learning perspective, the task of detecting fraudulent transactions is a binary classification problem. Classification models are commonly trained and evaluated in terms of statistical performance measures, such as likelihood and AUC, respectively. These measures, however, do not take into account the actual business objective, which is to minimize the financial losses due to fraud. Fraud detection is to be acknowledged as an instance-dependent cost-sensitive classification problem, where the costs due to misclassification vary between instances, and requiring adapted approaches for learning a classification model. In this article, an instance-dependent threshold is derived, based on the instance-dependent cost matrix for transfer fraud detection, that allows for making the optimal cost-based decision for each transaction. Two novel classifiers are presented, based on lasso-regularized logistic regression and gradient tree boosting, which directly minimize the proposed instance-dependent cost measure when learning a classification model. The proposed methods are implemented in the R packages cslogit and csboost, and compared against state-of-the-art methods on a publicly available data set from the machine learning competition website Kaggle and a proprietary card transaction data set. The results of the experiments highlight the potential of reducing fraud losses by adopting the proposed methods.",2020,
Hedge Fund Replication Using Shrinkage Methodologies,"In this article, the authors replicate major Hedge Fund Research, Inc., style indexes using alternative methods. These methods include stepwise regression, ridge regression, the lasso method, the elastic net, dynamic linear regression, principal component regression, and partial least squares regression. They find generally that, across the major hedge fund style indexes, the best replication results are obtained with methods that employ shrinkage of parameters.",2014,The Journal of Alternative Investments
Lasso for hierarchical polynomial models.,"In a polynomial regression model, the divisibility conditions implicit in polynomial hierarchy give way to a natural construction of constraints for the model parameters. We use this principle to derive versions of strong and weak hierarchy and to extend existing work in the literature, which at the moment is only concerned with models of degree two. We discuss how to estimate parameters in lasso using standard quadratic programming techniques and apply our proposal to both simulated data and examples from the literature. The proposed methodology compares favorably with existing techniques in terms of low validation error and model size.",2020,arXiv: Computation
