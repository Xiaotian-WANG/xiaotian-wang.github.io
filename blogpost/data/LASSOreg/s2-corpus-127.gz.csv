title,abstract,year,journal
Sparse Poisson Regression with Penalized Weighted Score Function,"We proposed a new penalized method in this paper to solve sparse Poisson Regression problems. Being different from $\ell_1$ penalized log-likelihood estimation, our new method can be viewed as penalized weighted score function method. We show that under mild conditions, our estimator is $\ell_1$ consistent and the tuning parameter can be pre-specified, which shares the same good property of the square-root Lasso.",2017,arXiv: Statistics Theory
Using the EM algorithm for Bayesian variable selection in logistic regression models with related covariates,"ABSTRACT We develop a Bayesian variable selection method for logistic regression models that can simultaneously accommodate qualitative covariates and interaction terms under various heredity constraints. We use expectation-maximization variable selection (EMVS) with a deterministic annealing variant as the platform for our method, due to its proven flexibility and efficiency. We propose a variance adjustment of the priors for the coefficients of qualitative covariates, which controls false-positive rates, and a flexible parameterization for interaction terms, which accommodates user-specified heredity constraints. This method can handle all pairwise interaction terms as well as a subset of specific interactions. Using simulation, we show that this method selects associated covariates better than the grouped LASSO and the LASSO with heredity constraints in various exploratory research scenarios encountered in epidemiological studies. We apply our method to identify genetic and non-genetic risk factors associated with smoking experimentation in a cohort of Mexican-heritage adolescents.",2018,Journal of Statistical Computation and Simulation
Forecasting Chinese GDP with Mixed Frequency Data Set: A Generalized Lasso Granger Method,"In this paper, we introduce an effective machine learning method which can capture the temporal causal structures between irregular time series to forecast China GDP growth rate with Mixed Frequency data set. The introduced method first generalized the inner product operator via kernels so that regression-based temporal casual models can be applicable to irregular time series, then the temporal casual relationships among the irregular time series are studied by Generalized Lasso Granger (GLG) graphical models. The main advantage of this approach is that it does not directly estimate the values of missing data of low frequency time series or has restricted assumptions about the generation process of the time series. By applying this method to a 17 macroeconomic indicators GLG model, the forecasting accuracy is better than the autoregressive (AR) benchmark model and a widely used mixed-data sampling (MIDAS) model.",2013,
Chemical-agnostic hazard prediction: statistical inference of in vitro toxicity pathways from proteomics responses to chemical mixtures.,"Toxicity pathways have been defined as normal cellular pathways that, when sufficiently perturbed as a consequence of chemical exposure, lead to an adverse outcome. If an exposure alters one or more normal biological pathways to an extent that leads to an adverse toxicity outcome, a significant correlation must exist between the exposure, the extent of pathway alteration, and the degree of adverse outcome. Biological pathways are regulated at multiple levels, including transcriptional, post-transcriptional, post-translational, and targeted degradation, each of which can affect the levels and extents of modification of proteins involved in the pathways. Significant alterations of toxicity pathways resulting from changes in regulation at any of these levels therefore are likely to be detectable as alterations in the proteome. We hypothesize that significant correlations between exposures, adverse outcomes, and changes in the proteome have the potential to identify putative toxicity pathways, facilitating selection of candidate targets for high throughput screening, even in the absence of a priori knowledge of either the specific pathways involved or the specific agents inducing the pathway alterations. We explored this hypothesis in vitro in BEAS-2B human airway epithelial cells exposed to different concentrations of Ni2+, Cd2+, and Cr6+, alone and in defined mixtures. Levels and phosphorylation status of a variety of signaling pathway proteins and cytokines were measured after 48 hours exposure, together with cytotoxicity. Least Absolute Shrinkage and Selection Operator (LASSO) multiple regression was used to identify a subset of these proteins that constitute a putative toxicity pathway capable of predicting cytotoxicity. The putative toxicity pathway for cytotoxicity of these metals and metal mixtures identified by LASSO is composed of phospho-RPS6KB1, phospho-p53, cleaved CASP3, phospho-MAPK8, IL-10, and Hif-1Î±. As this approach does not depend on knowledge of the chemical composition of the mixtures, it may be generally useful for identifying sets of proteins predictive of adverse effects for a variety of mixtures, including complex environmental mixtures of unknown composition.",2017,Computational toxicology
Predictor selection for downscaling GCM data with LASSO,"[1]Â Over the last 10Â years, downscaling techniques, including both dynamical (i.e., the regional climate model) and statistical methods, have been widely developed to provide climate change information at a finer resolution than that provided by global climate models (GCMs). Because one of the major aims of downscaling techniques is to provide the most accurate information possible, data analysts have tried a number of approaches to improve predictor selection, which is one of the most important steps in downscaling techniques. Classical methods such as regression techniques, particularly stepwise regression (SWR), have been employed for downscaling. However, SWR presents some limits, such as deficiencies in dealing with collinearity problems, while also providing overly complex models. Thus, the least absolute shrinkage and selection operator (LASSO) technique, which is a penalized regression method, is presented as another alternative for predictor selection in downscaling GCM data. It may allow for more accurate and clear models that can properly deal with collinearity problems. Therefore, the objective of the current study is to compare the performances of a classical regression method (SWR) and the LASSO technique for predictor selection. A data set from 9 stations located in the southern region of Quebec that includes 25 predictors measured over 29Â years (from 1961 to 1990) is employed. The results indicate that, due to its computational advantages and its ease of implementation, the LASSO technique performs better than SWR and gives better results according to the determination coefficient and the RMSE as parameters for comparison.",2012,Journal of Geophysical Research
A Bayesian Approach for Graph-constrained Estimation for High-dimensional Regression.,"Many different biological processes are represented by network graphs such as regulatory networks, metabolic pathways, and protein-protein interaction networks. Since genes that are linked on the networks usually have biologically similar functions, the linked genes form molecular modules to affect the clinical phenotypes/outcomes. Similarly, in large-scale genetic association studies, many SNPs are in high linkage disequilibrium (LD), which can also be summarized as a LD graph. In order to incorporate the graph information into regression analysis with high dimensional genomic data as predictors, we introduce a Bayesian approach for graph-constrained estimation (Bayesian GRACE) and regularization, which controls the amount of regularization for sparsity and smoothness of the regression coefficients. The Bayesian estimation with their posterior distributions can provide credible intervals for the estimates of the regression coefficients along with standard errors. The deviance information criterion (DIC) is applied for model assessment and tuning parameter selection. The performance of the proposed Bayesian approach is evaluated through simulation studies and is compared with Bayesian Lasso and Bayesian Elastic-net procedures. We demonstrate our method in an analysis of data from a case-control genome-wide association study of neuroblastoma using a weighted LD graph.",2010,International journal of systems and synthetic biology
Frequency estimation for monophonical music by using a modified VMD method,"In this paper, a new Variational Mode Decomposition (VMD) is introduced, and applied to the fundamental frequency estimation of monophonical Turkish maqam music. VMD is a method to decompose an input signal into an ensemble of sub-signals (modes) which is entirely non-recursive. It determines the relevant bands adaptively, and estimates the corresponding modes concurrently. In order to optimally decompose a given signal, VMD seeks an ensemble of modes with narrow-band properties corresponding to the Intrinsic Mode Function (IMF) definition used in Empirical Mode Decomposition (EMD). In our proposed modified VMD approach, in order to obtain the bandwidth of a mode, each mode is shifted to baseband by mixing an exponential that is adjusted to the respective center frequency. The bandwidth is estimated through elastic net method that linearly combines penalties of the Lasso and Ridge Regression methods. Simulation results on fundamental frequency estimation of real music and synthetic test data show better performance compared to classical VMD based approach, and other common methods used for music signals, such as YIN and MELODIA based methods.",2017,2017 25th European Signal Processing Conference (EUSIPCO)
Generalized â„“1-penalized quantile regression with linear constraints,"Abstract In many application areas, prior subject matter knowledge can be formulated as constraints on parameters in order to get a more accurate fit. A generalized l 1 -penalized quantile regression with linear constraints on parameters is considered, including either linear inequality or equality constraints or both. It allows a general form of penalization, including the usual lasso, the fused lasso and the adaptive lasso as special cases. The KKT conditions of the optimization problem are derived and the whole solution path is computed as a function of the tuning parameter. A formula for the number of degrees of freedom is derived, which is used to construct model selection criteria for selecting optimal tuning parameters. Finally, several simulation studies and two real data examples are presented to illustrate the proposed method.",2020,Comput. Stat. Data Anal.
Sparse optimization models with robust sketching and applications,"Author(s): Pham, Vu | Advisor(s): El Ghaoui, Laurent | Abstract: Sparse machine learning has recently emerged as powerful tool to obtain models of high-dimensional data with high degree of interpretability, at low computational cost. The approach has been successfully used in many areas, such as signal and image processing. In sparse learning classification, for example, the prediction accuracy or some other classical measure of performance is not the sole concern: we also wish to be able to better understand which few features are relevant as markers for classification. Furthermore, many of sparse learning tasks in practice, including cross-validation, parameter search, or leave-one-out analysis, involve multiple instances of similar problems, each instance sharing a large part of learning data with the others. In this thesis, we introduce a robust framework for solving these multiple sparse regressions in the form of square-root LASSO problems, based on a sketch of the learning data that uses low-rank approximations. Our approach allows a dramatic reduction in computational effort, while not sacrificingâ€”sometimes even improvingâ€”the statistical performance.We present our technique by first studying sparse optimization with applications in different domain of interests, from text analytics to system design, and then developing theories for robust solutions for sparse regression in multi-instance setting. We also provide comparisons with other heuristics to obtain sparse models in various applications. In more detail, our central contributions from this thesis include:- Identifying key tasks in domains of interests under real-world setting,- Suggesting models that are suitable for these tasks along the axes of computational complexity and model understandability,- Exploiting problem structures when working with multiple instances to robustly improve computation while maintaining high learning performance, and- Proposing applications of our robust solutions in high-dimensional setting.",2016,
"Sleep duration, daytime napping, markers of obstructive sleep apnea and stroke in a population of southern China","Sleep habits are associated with stroke in western populations, but this relation has been rarely investigated in China. Moreover, the differences among stroke subtypes remain unclear. This study aimed to explore the associations of total stroke, including ischemic and hemorrhagic type, with sleep habits of a population in southern China. We performed a case-control study in patients admitted to the hospital with first stroke and community control subjects. A total of 333 patients (nâ€‰=â€‰223, 67.0%, with ischemic stroke; nâ€‰=â€‰110, 23.0%, with hemorrhagic stroke) and 547 controls were enrolled in the study. Participants completed a structured questionnaire to identify sleep habits and other stroke risk factors. Least absolute shrinkage and selection operator (Lasso) and multiple logistic regression were performed to identify risk factors of disease. Incidence of stroke, and its subtypes, was significantly associated with snorting/gasping, snoring, sleep duration, and daytime napping. Snorting/gasping was identified as an important risk factor in the Lasso logistic regression model (Lasso' Î²â€‰=â€‰0.84), and the result was proven to be robust. This study showed the association between stroke and sleep habits in the southern Chinese population and might help in better detecting important sleep-related factors for stroke risk.",2016,Scientific Reports
"Gene expression network analysis of lymph node involvement in colon cancer identifies AHSA2, CDK10, and CWC22 as possible prognostic markers","Colon cancer has been well studied using a variety of molecular techniques, including whole genome sequencing. However, genetic markers that could be used to predict lymph node (LN) involvement, which is the most important prognostic factor for colon cancer, have not been identified. In the present study, we compared LN(+) and LN(âˆ’) colon cancer patients using differential gene expression and network analysis. Colon cancer gene expression data were obtained from the Cancer Genome Atlas and divided into two groups, LN(+) and LN(âˆ’). Gene expression networks were constructed using LASSO (Least Absolute Shrinkage and Selection Operator) regression. We identified hub genes, such as APBB1, AHSA2, ZNF767, and JAK2, that were highly differentially expressed. Survival analysis using selected hub genes, such as AHSA2, CDK10, and CWC22, showed that their expression levels were significantly associated with the survival rate of colon cancer patients, which indicates their possible use as prognostic markers. In addition, protein-protein interaction network, GO enrichment, and KEGG pathway analysis were performed with selected hub genes from each group to investigate the regulatory relationships between hub genes and LN involvement in colon cancer; these analyses revealed differences between the LN(âˆ’) and LN(+) groups. Our network analysis may help narrow down the search for novel candidate genes for the treatment of colon cancer, in addition to improving our understanding of the biological processes underlying LN involvement. All R implementation codes are available at journal website as Supplementary Materials.",2020,Scientific Reports
Pattern Alternating Maximization Algorithm for High-Dimensional Missing Data,"We propose a new and computationally efficient algorithm for maximizing the observed log-likelihood for a multivariate normal data matrix with missing values. We show that our procedure based on iteratively regressing the missing on the observed variables, generalizes the traditional EM algorithm by alternating between different complete data spaces and performing the E-Step incrementally. In this nonstandard setup we prove numerical convergence to a stationary point of the observed log-likelihood. For high-dimensional data, where the number of variables may greatly exceed sample size, we add a Lasso penalty in the regression part of our algorithm and perform coordinate descent approximations. This leads to a computationally very attractive technique with sparse regression coefficients for missing data imputation. Simulations and results on four microarray datasets show that the new method often outperforms alternative imputation techniques as k-nearest neighbors imputation, nuclear norm minimization or a penalized likelihood approach with an l1-penalty on the inverse covariance matrix.",2010,
Genomic selection for boar taint compounds and carcass traits in a commercial pig population,"This study aimed to compare two different Genome-Wide Selection (GWS) methods (Ridge Regression BLUP âˆ’ RR-BLUP and Bayesian LASSO âˆ’ BL) to predict the genomic estimated breeding values (GEBV) of four phenotypes, including two boar taint compounds, i.e., the concentrations of androstenone (andro) and skatole (ska), and two carcass traits, i.e., backfat thickness (fat) and loin depth (loin), which were measured in a commercial male pig line. Six hundred twenty-two boars were genotyped for 2,500 previously selected single nucleotide polymorphisms (SNPs). The accuracies of the GEBV using both methods were estimated based on Jack-knife cross-validation. The BL showed the best performance for the andro, ska and loin traits, which had accuracy values of 0.65, 0.58 and 0.33, respectively; for the fat trait, the RR-BLUP accuracy of 0.61 outperformed the BL accuracy of 0.56. Considering that BL was more accurate for the majority of the traits, this method is the most favoured for GWS under the conditions of this study. The most relevant SNPs for each trait were located in the chromosome regions that were previously indicated as QTL regions in other studies, i.e., SSC6 for andro and ska, SSC2 for fat, and SSC11, SSC15 and SSC17 for loin.",2015,Livestock Science
Incorporating prior information with fused sparse group lasso: Application to prediction of clinical measures from neuroimages.,"Predicting clinical variables from whole-brain neuroimages is a high-dimensional problem that can potentially benefit from feature selection or extraction. Penalized regression is a popular embedded feature selection method for high-dimensional data. For neuroimaging applications, spatial regularization using the â„“ 1 or â„“ 2 norm of the image gradient has shown good performance, yielding smooth solutions in spatially contiguous brain regions. Enormous resources have been devoted to establishing structural and functional brain connectivity networks that can be used to define spatially distributed yet related groups of voxels. We propose using the fused sparse group lasso (FSGL) penalty to encourage structured, sparse, and interpretable solutions by incorporating prior information about spatial and group structure among voxels. We present optimization steps for FSGL penalized regression using the alternating direction method of multipliers algorithm. With simulation studies and in application to real functional magnetic resonance imaging data from the Autism Brain Imaging Data Exchange, we demonstrate conditions under which fusion and group penalty terms together outperform either of them alone.",2019,Biometrics
Consistency analysis and regularization parameter selection for direction-of-arrival estimation based on compressed sensing techniques,"In this report we address the well known problem of estimating the Direction Of Arrival (DOAs) from sensor array data, and discuss it as a linear regression problem by assuming a narrow band, far field model of the sources. Recently, the Least Absolute Shrinkage and Selection Operator (LASSO) is proposed for such a problem as an approximation to the computationally hard, but precise solution of Maximum Likelihood (ML). We explain the implementation using convex programming tools, and show the superiority of this method by discussing the theoretical bounds of consistency and comparing the results to that of conventional estimators. Furthermore, we give two different solutions for selecting the regularization parameter in the LASSO method. First, by viewing the problem as a model order selection and using Minimum Description Length (MDL) principle and second, by taking the Bayesian nature of regularization into account and deriving an ML estimator for the regularization parameter. Finally, we discuss about the theoretical consistency of such a method for the DOA estimation in some extreme cases. We particularly show that for the noiseless case the method may not be consistent for very close sources. This shows the fundamental resolution of LASSO for the DOA estimation.",2010,
Predicting Physiological Concentrations of Metabolites from Their Molecular Structure,"Physiological concentrations of metabolites can partly be explained by their molecular structure. We hypothesize that substances containing certain chemical groups show increased or decreased concentration in cells. We consider here, as chemical groups, local atomic configurations, describing an atom, its bonds, and its direct neighbor atoms. To test our hypothesis, we fitted a linear statistical model that relates experimentally determined logarithmic concentrations to feature vectors containing count numbers of the chemical groups. In order to determine chemical groups that have a clear effect on the concentration, we use a regularized (lasso) regression. In a dataset on 41 substances of central metabolism in different organisms, we found that the physical concentrations are increased by the occurrence of amino and hydroxyl groups, while aldehydes, ketones, and phosphates show decreased concentrations. The model explains about 22% of the variance of the logarithmic mean concentrations.",2005,Journal of computational biology : a journal of computational molecular cell biology
"Regularized estimation in sparse high-dimensional multivariate regression, with application to a DNA methylation study","Abstract In this article, we consider variable selection for correlated high dimensional DNA methylation markers as multivariate outcomes. A novel weighted square-root LASSO procedure is proposed to estimate the regression coefficient matrix. A key feature of this method is tuning-insensitivity, which greatly simplifies the computation by obviating cross validation for penalty parameter selection. A precision matrix obtained via the constrained â„“1 minimization method is used to account for the within-subject correlation among multivariate outcomes. Oracle inequalities of the regularized estimators are derived. The performance of our proposed method is illustrated via extensive simulation studies. We apply our method to study the relation between smoking and high dimensional DNA methylation markers in the Normative Aging Study (NAS).",2017,Statistical Applications in Genetics and Molecular Biology
The group exponential lasso for bi-level variable selection.,"In many applications, covariates possess a grouping structure that can be incorporated into the analysis to select important groups as well as important members of those groups. One important example arises in genetic association studies, where genes may have several variants capable of contributing to disease. An ideal penalized regression approach would select variables by balancing both the direct evidence of a feature's importance as well as the indirect evidence offered by the grouping structure. This work proposes a new approach we call the group exponential lasso (GEL) which features a decay parameter controlling the degree to which feature selection is coupled together within groups. We demonstrate that the GEL has a number of statistical and computational advantages over previously proposed group penalties such as the group lasso, group bridge, and composite MCP. Finally, we apply these methods to the problem of detecting rare variants in a genetic association study.",2015,Biometrics
Approximate Residual Balancing: De-Biased Inference of Average Treatment Effects in High Dimensions.,"There are many settings where researchers are interested in estimating average treatment effects and are willing to rely on the unconfoundedness assumption, which requires that the treatment assignment be as good as random conditional on pre-treatment variables. The unconfoundedness assumption is often more plausible if a large number of pre-treatment variables are included in the analysis, but this can worsen the performance of standard approaches to treatment effect estimation. In this paper, we develop a method for de-biasing penalized regression adjustments to allow sparse regression methods like the lasso to be used for sqrt{n}-consistent inference of average treatment effects in high-dimensional linear models. Given linearity, we do not need to assume that the treatment propensities are estimable, or that the average treatment effect is a sparse contrast of the outcome model parameters. Rather, in addition standard assumptions used to make lasso regression on the outcome model consistent under 1-norm error, we only require overlap, i.e., that the propensity score be uniformly bounded away from 0 and 1. Procedurally, our method combines balancing weights with a regularized regression adjustment.",2016,arXiv: Methodology
RI-WS-3 Une technique originale de calibration des tips (transjugular intrahepatic portosystemic shunt),"Objectifs Le but de notre etude est dâ€™evaluer lâ€™interet, la faisabilite et lâ€™efficacite dâ€™une technique innovante de calibration de shunt par endoprothese couverte cintree en cas dâ€™encephalopathie hepatique post-TIPS. Materiels et methodes Sept patients presentant une encephalopathie hepatique refractaire au traitement medical apres TIPS ont beneficie dâ€™une reduction de shunt utilisant une endoprothese couverte montee sur ballon, retrecie en son milieu en forme de sablier grÃ¢ce a un lasso insere parallelement a la prothese, puis retire. Le diametre du retrecissement etait module par dilatation ou striction jusquâ€™a obtention du gradient porto-systemique (GPS) souhaite. Le delai moyen TlPS-calibration etait de 55 jours (9-108). Le GPS moyen avant reduction etait de 3,4 mmHg (0-7). Resultats Une augmentation significative du gradient a ete obtenue chez tous les patients avec un GPS moyen apres reduction de 14,4 mmHg (8-20). Dans un cas, le geste sâ€™est complique dâ€™une migration du stent lors du retrait du lasso. Tous les patients ont presente une amelioration clinique immediate avec regression complete de lâ€™encephalopathie (n = 5) ou partielle (n = 2). Un patient est decede a J7. Conclusion II sâ€™agit dâ€™une technique simple, utilisant du materiel dâ€™usage courant, permettant un ajustement precis et immediat du diametre du shunt au gradient porto-systemique souhaite.",2009,Journal De Radiologie
Regularity Properties for Sparse Regression,"Statistical and machine learning theory has developed several conditions ensuring that popular estimators such as the Lasso or the Dantzig selector perform well in high-dimensional sparse regression, including the restricted eigenvalue, compatibility, and $$\ell _q$$â„“q sensitivity properties. However, some of the central aspects of these conditions are not well understood. For instance, it is unknown if these conditions can be checked efficiently on any given dataset. This is problematic, because they are at the core of the theory of sparse regression. Here we provide a rigorous proof that these conditions are NP-hard to check. This shows that the conditions are computationally infeasible to verify, and raises some questions about their practical applications. However, by taking an average-case perspective instead of the worst-case view of NP-hardness, we show that a particular condition, $$\ell _q$$â„“q sensitivity, has certain desirable properties. This condition is weaker and more general than the others. We show that it holds with high probability in models where the parent population is well behaved, and that it is robust to certain data processing steps. These results are desirable, as they provide guidance about when the condition, and more generally the theory of sparse regression, may be relevant in the analysis of high-dimensional correlated observational data.",2016,Communications in Mathematics and Statistics
Constructing generalized exponential predictors via penalty methods: empirical analysis on gold price,"We construct generalized exponential predictors for forecasting gold price using different loss and penalty functions.The construction methods include: 1) ridge regression and 2) selection of linear combinations of EWMA predictors with different parameters by adding LASSO and SCAD penalties based on L1,L2 and the LM loss function which combines both L1 and L2.Practical data show that our models improve the single parameter EWMA model effectively and they perform better than the models suggested in the literature.",2012,Journal of Graduate University of Chinese Academy of Sciences
Predictors of High Profit and High Deficit Outliers under SwissDRG of a Tertiary Care Center,"PRINCIPLES
Case weights of Diagnosis Related Groups (DRGs) are determined by the average cost of cases from a previous billing period. However, a significant amount of cases are largely over- or underfunded. We therefore decided to analyze earning outliers of our hospital as to search for predictors enabling a better grouping under SwissDRG.


METHODS
28,893 inpatient cases without additional private insurance discharged from our hospital in 2012 were included in our analysis. Outliers were defined by the interquartile range method. Predictors for deficit and profit outliers were determined with logistic regressions. Predictors were shortlisted with the LASSO regularized logistic regression method and compared to results of Random forest analysis. 10 of these parameters were selected for quantile regression analysis as to quantify their impact on earnings.


RESULTS
Psychiatric diagnosis and admission as an emergency case were significant predictors for higher deficit with negative regression coefficients for all analyzed quantiles (p<0.001). Admission from an external health care provider was a significant predictor for a higher deficit in all but the 90% quantile (p<0.001 for Q10, Q20, Q50, Q80 and p = 0.0017 for Q90). Burns predicted higher earnings for cases which were favorably remunerated (p<0.001 for the 90% quantile). Osteoporosis predicted a higher deficit in the most underfunded cases, but did not predict differences in earnings for balanced or profitable cases (Q10 and Q20: p<0.00, Q50: p = 0.10, Q80: p = 0.88 and Q90: p = 0.52). ICU stay, mechanical and patient clinical complexity level score (PCCL) predicted higher losses at the 10% quantile but also higher profits at the 90% quantile (p<0.001).


CONCLUSION
We suggest considering psychiatric diagnosis, admission as an emergency case and admission from an external health care provider as DRG split criteria as they predict large, consistent and significant losses.",2015,PLoS ONE
Risk Factors Associated with Hospital-Acquired Infections for COVID-19 Patients in ICU,"Background: COVID-19 is an emerging global threat. The severe patients were given supportive treatment in the ICU where is the primary site for the hospital-acquired infections (HAIs). HAIs are an increasing problem resulting in adverse effects for hospitalized patients. Nevertheless, the impact of HAIs on the COVID-19 patients in ICU and its consequences has not been studied. This study is to investigate the HAI rates, impact factors, consequences and bacteria etiology of HAIs for the severe COVID-19 patients in ICU, so as to raise the awareness of the hospital infection control. 
 
Methods: In this retrospective cohort study, we screened 62 severe COVID-19 pneumonia patients in the ICU from January 3 rd to March 1 st , 2020 at Zhongnan Hospital of Wuhan University. Demographic and clinical data were collected. The HAI was according to the standard ECDC criteria. The differences of related factors (including demographic characters, onset symptoms, comorbidities, respiratory support, laboratory findings, mortality, hospital stay and costs) between HAI and Non-HAI cohorts were analyzed by Mannâ€“Whitney U tests and t-tests. The independent risk factors of HAIs were performed with LASSO Logistic regression and Multivariable logistic regression. 
 
Findings: The incidence of HAI for the severe COVID-19 patients in ICU were 45.2%. Compared with the patients in Non-HAI group, higher frequency of utilization of invasive ventilation (IV) ( p <0.001), decreased platelet count ( p =0.009) and SpO2 ( p =0.015), prolonged prothrombin time ( p =0.009), higher level of lactate dehydrogenase (LDH) ( p =0.047), aspartate aminotransferase (AST) ( p =0.013), C-reactive protein ( p =0.029), IL-6 ( p =0.035), hospitalization stay ( p =0.010), ICU stay ( p =0.020) and costs ( p <0.001) were observed in HAI group. Although the death rate of HAI group was higher than that in Non-HAI group (32.1% vs. 14.7%), there was no significant difference of mortality between the two groups. The independent risk factors for HAIs were prothrombin time (PT)(OR=2.0), AST (OR=1.032), invasive ventilation (NIV vs IV, OR=0.026), SpO2 (OR=0.884) and length of ICU (OR=1.239). Among these substantial factors, PT and AST were the novel independent risk factors for HAI. Multidrug-resistant Acinetobacter baumannii (46%) was the most common strain isolated from patients in the HAI group and the lower respiratory tract (61%) was the most common place for nosocomial infection. 
 
Interpretation: We found that PT, AST, IV, SpO2 and ICU stay were the independent risk factors for HAI for the severe COVID-19 patients. The monitoring and prevention methods targeting these factors of HAI should be developed to control the occurrence of nosocomial infection and to reduce the hospitalization time and costs. 
 
Funding Statement: None. 
 
Declaration of Interests: All authors have no interest conflicts in this study. 
 
Ethics Approval Statement: This clinical study was approved by the ethics committee of Zhongnan Hospital of Wuhan University.",2020,
Regularization for Spatial Panel Time Series Using the Adaptive LASSO,"This paper proposes a model for estimating the underlying cross-sectional dependence structure of a large panel of time series. Technical difficulties meant such a structure is usually assumed before further analysis. We propose to estimate this by penalizing the elements in the spatial weight matrices using the adaptive LASSO proposed by Zou (2006). Non-asymptotic oracle inequalities and the asymptotic sign consistency of the estimators are proved when the dimension of the time series can be larger than the sample size, and they tend to infinity jointly. Asymptotic normality of the LASSO/adaptive LASSO estimator for the model regression parameter is also presented. All the proofs involve non-standard analysis of LASSO/adaptive LASSO estimators, since our model, albeit like a standard regression, always has the response vector as one of the covariates. A block coordinate descent algorithm is introduced, with simulations and a real data analysis carried out to demonstrate the performance of our estimators.",2014,
Firm Characteristics and Expected Stock Returns,"Complementing the widely used conventional multiple regression approach â€” which can suffer from overfitting with a large number of predictors â€” we propose a combination Lasso (C-Lasso) approach to improve out-of-sample forecasts of cross-sectional expected stock returns via shrinkage. Using 99 firm characteristics and an out-of-sample period spanning more than four decades, an approach that blends conventional and C-Lasso forecasts delivers unbiased estimates of the cross-sectional dispersion in expected returns. Similarly, combining spread portfolios formed from conventional and C-Lasso forecasts generates substantial performance gains. Our results indicate that more characteristics matter for cross-sectional expected returns than previously believed, due to time-varying characteristic premia.",2019,
A Gene-Related Nomogram for Preoperative Prediction of Lymph Node Metastasis in Colorectal Cancer.,"PURPOSE
To develop and validate a gene-related nomogram for predicting the risk of lymph node (LN) metastasis preoperatively in patients with colorectal cancer (CRC).


METHODS
RNA-seq data of 581 CRC and 51 normal cases with clinical features were downloaded from TCGA database. In the evaluation cohort with 381 CRC cases, the LASSO regression was used to reduce dimensionality of gene signatures extracted to build gene score. A gene-related nomogram was performed based on the multivariable logistic regression analysis. The performance of the nomogram was assessed by the discrimination, calibration, and clinical usefulness not only in the evaluation, but also in the validation cohort with 200 CRC cases.


RESULTS
A total of 12,590 differentially expressed genes were selected, in which 59 candidates associated with LN metastasis in differentially expressed genes set were screened by LASSO to form the gene score. Based on the analysis of multivariate logistic regression, the gene-related nomogram showed good calibration and discrimination not only in the evaluation cohort (concordance-index 0.93; 95%CI 0.91-0.96), but also in the validation cohort (concordance-index 0.70; 95%CI 0.63-0.78). The decision curve analysis of the gene-related nomogram also provides constructive guidance for the design of operation plan, preoperatively.


CONCLUSIONS
The presented genes nomogram may predict the LN metastasis in CRC patients, preoperatively. And 59 hub genes were defined related to LN metastasis of CRC, which can serve as treatment targets for the further study. Preoperative biopsy and gene analysis are needed to develop the operation plan in clinical practice.",2019,Journal of investigative surgery : the official journal of the Academy of Surgical Research
An adaptive group lasso based multi-label regression approach for facial expression analysis,"In the realm of facial expression analysis, numerous attempts have been made to link each facial picture to one affective category. Nevertheless, in our daily life, few of the facial expressions are exactly one of the predefined affective states. Therefore, to analyze the facial expressions more effectively, this paper proposes an Adaptive Group Lasso based Multilabel Regression approach, which depicts each facial expression with multiple continuous values of predefined affective states. Adaptive Group Lasso is adopted to depict the relationship between different labels which different facial expressions share some same affective facial areas (patches). Moreover, to solve the multi-label regression problem, a convex optimization formulation is presented, which would guarantee a global optimal solution. The experiment results based on JAFFE dataset have verified the superior performance of our approach.",2014,2014 IEEE International Conference on Image Processing (ICIP)
On Bayesian lasso variable selection and the specification of the shrinkage parameter,"We propose a Bayesian implementation of the lasso regression that accomplishes both shrinkage and variable selection. We focus on the appropriate specification for the shrinkage parameter Î» through Bayes factors that evaluate the inclusion of each covariate in the model formulation. We associate this parameter with the values of Pearson and partial correlation at the limits between significance and insignificance as defined by Bayes factors. In this way, a meaningful interpretation of Î» is achieved that leads to a simple specification of this parameter. Moreover, we use these values to specify the parameters of a gamma hyperprior for Î». The parameters of the hyperprior are elicited such that appropriate levels of practical significance of the Pearson correlation are achieved and, at the same time, the prior support of Î» values that activate the Lindley-Bartlett paradox or lead to over-shrinkage of model coefficients is avoided. The proposed method is illustrated using two simulation studies and a real dataset. For the first simulation study, results for different prior values of Î» are presented as well as a detailed robustness analysis concerning the parameters of the hyperprior of Î». In all examples, detailed comparisons with a variety of ordinary and Bayesian lasso methods are presented.",2013,Statistics and Computing
A Bayesian approach with generalized ridge estimation for high-dimensional regression and testing,"ABSTRACT This paper adopts a Bayesian strategy for generalized ridge estimation for high-dimensional regression. We also consider significance testing based on the proposed estimator, which is useful for selecting regressors. Both theoretical and simulation studies show that the proposed estimator can simultaneously outperform the ordinary ridge estimator and the LSE in terms of the mean square error (MSE) criterion. The simulation study also demonstrates the competitive MSE performance of our proposal with the Lasso under sparse models. We demonstrate the method using the lung cancer data involving high-dimensional microarrays.",2017,Communications in Statistics - Simulation and Computation
Evaluation of Penalized Estimation Methods for Big Data Analysis,"In this paper we described the sparse Laplacian shrinkage (SLS) method which is a penalized method for variable selection and estimation in big data analysis that uses a combination of the minimax concave penalty (MCP) and Laplacian quadratic as the penalty. The SLS uses the MCP to promote sparsity and Laplacian quadratic penalty to encourage smoothness among coefficients associated with the correlated predictors. An important advantage of the MCP over the penalty is that it leads to estimators that are nearly unbiased and achieve selection consistency under weaker conditions. In some problems such as genomic data analysis, partial external information may also be available on the graphical structure of some genes used as predictors in the model. It would be interesting to consider approaches for combining external information on the graphical structure with existing data in constructing the Laplacian quadratic penalty. We discussed a comparative study with ridge regression (Ridge), Lasso, MCP and SLS estimator. For different sample and variable size, our simulation studies demonstrate that SLS estimator is the best estimator. Keywords: Big data, minimax concave penalty (MCP), sparse Laplacian shrinkage (SLS) estimator Cite this Article Rahman MS, Rahman MM, Matin MA. Evaluation of Penalized Estimation Methods for Big Data Analysis. Research & Reviews: A Journal of Bioinformatics. 2015; 2(2): 49â€“55p.",2015,
Marginal false discovery rate control for likelihood-based penalized regression models.,"The popularity of penalized regression in high-dimensional data analysis has led to a demand for new inferential tools for these models. False discovery rate control is widely used in high-dimensional hypothesis testing, but has only recently been considered in the context of penalized regression. Almost all of this work, however, has focused on lasso-penalized linear regression. In this paper, we derive a general method for controlling the marginal false discovery rate that can be applied to any penalized likelihood-based model, such as logistic regression and Cox regression. Our approach is fast, flexible and can be used with a variety of penalty functions including lasso, elastic net, MCP, and MNet. We derive theoretical results under which the proposed method is valid, and use simulation studies to demonstrate that the approach is reasonably robust, albeit slightly conservative, when these assumptions are violated. Despite being conservative, we show that our method often offers more power to select causally important features than existing approaches. Finally, the practical utility of the method is demonstrated on gene expression datasets with binary and time-to-eventÂ outcomes.",2019,Biometrical journal. Biometrische Zeitschrift
An Extragradient-Based Alternating Direction Method for Convex Minimization,"In this paper, we consider the problem of minimizing the sum of two convex functions subject to linear linking constraints. The classical alternating direction type methods usually assume that the two convex functions have relatively easy proximal mappings. However, many problems arising from statistics, image processing and other fields have the structure that while one of the two functions has an easy proximal mapping, the other function is smoothly convex but does not have an easy proximal mapping. Therefore, the classical alternating direction methods cannot be applied. To deal with the difficulty, we propose in this paper an alternating direction method based on extragradients. Under the assumption that the smooth function has a Lipschitz continuous gradient, we prove that the proposed method returns an $$\epsilon $$Ïµ-optimal solution within $$O(1/\epsilon )$$O(1/Ïµ) iterations. We apply the proposed method to solve a new statistical model called fused logistic regression. Our numerical experiments show that the proposed method performs very well when solving the test problems. We also test the performance of the proposed method through solving the lasso problem arising from statistics and compare the result with several existing efficient solvers for this problem; the results are very encouraging.",2017,Foundations of Computational Mathematics
Estimating Survival of Hospitalized COVID-19 Patients from Admission Information,"Background While clinical characteristics and a range of mortality risk factors of COVID-19 patients have been reported, a practical early clinical survival calculator specialized for the unique cohort of patients has not yet been introduced. Such a tool would provide timely and valuable guidance in clinical care decision-making during this global pandemic. Methods Demographic, laboratory, clinical, and treatment data (from 13 acute care facilities at Northwell Health) were extracted from electronic medical records and used to build and test the predictive accuracy of a survival probability calculator-the Northwell COVID-19 Survival (NOCOS) calculator-for hospitalized COVID-19 patients. The NOCOS calculator was constructed using multivariate regression with L1 regularization (LASSO). Model predictive performance was measured using Receiver Operating Characteristic (ROC) curves and the Area Under the Curve (AUC) of the calculators tested. Results A total of 5,233 inpatients were included in the study. Patient age, serum blood urea nitrogen (BUN), Emergency Severity Index (ESI), red cell distribution width (RCDW), absolute neutrophil count, serum bicarbonate, and glucose were identified as the optimal early predictors of survival by multivariate LASSO regression. The predictive performance of the Northwell COVID-19 Survival (NOCOS) calculator was assessed for 14 consecutive days. Conclusions We present a rapidly developed and deployed estimate of survival probability that outperforms other general risk models. The 7 early predictors of in-hospital survival can help clinicians identify patients with increased probabilities of survival and provide critical decision support.",2020,
Sparse Logistic Regression for Text Categorization,"This paper studies regularized logistic regression and its application to text categorization. In particular we examine a Bayesian approach, lasso logistic regression, that simultaneously selects variables and provides regularization. We present an efficient training algorithm for this approach, and show that the resulting classifiers are both compact and have state-of-the-art effectiveness on a range of text categorization tasks.",2005,
Approaches to Regularized Regression - A Comparison between Gradient Boosting and the Lasso.,"BACKGROUND
Penalization and regularization techniques for statistical modeling have attracted increasing attention in biomedical research due to their advantages in the presence of high-dimensional data. A special focus lies on algorithms that incorporate automatic variable selection like the least absolute shrinkage operator (lasso) or statistical boosting techniques.


OBJECTIVES
Focusing on the linear regression framework, this article compares the two most-common techniques for this task, the lasso and gradient boosting, both from a methodological and a practical perspective.


METHODS
We describe these methods highlighting under which circumstances their results will coincide in low-dimensional settings. In addition, we carry out extensive simulation studies comparing the performance in settings with more predictors than observations and investigate multiple combinations of noise-to-signal ratio and number of true non-zero coeffcients. Finally, we examine the impact of different tuning methods on the results.


RESULTS
Both methods carry out penalization and variable selection for possibly highdimensional data, often resulting in very similar models. An advantage of the lasso is its faster run-time, a strength of the boosting concept is its modular nature, making it easy to extend to other regression settings.


CONCLUSIONS
Although following different strategies with respect to optimization and regularization, both methods imply similar constraints to the estimation problem leading to a comparable performance regarding prediction accuracy and variable selection in practice.",2016,Methods of information in medicine
