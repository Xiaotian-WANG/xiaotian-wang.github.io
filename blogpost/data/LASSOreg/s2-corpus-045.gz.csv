title,abstract,year,journal
Forecasting and trading the EUR/USD exchange rate with stochastic Neural Network combination and time-varying leverage,"The motivation of this paper is to investigate the use of a Neural Network (NN) architecture, the Psi Sigma Neural Network (PSN), when applied to the task of forecasting and trading the Euro/Dollar (EUR/USD) exchange rate using the European Central Bank (ECB) fixing series and to explore the utility of Kalman Filters in combining NN forecasts. This is done by benchmarking the statistical and trading performance of PSN with a Naive Strategy, an Autoregressive Moving Average (ARMA) model and two different NN architectures, a Multi-Layer Perceptron (MLP) and a Recurrent Network (RNN). We combine our NN forecasts with Kalman Filter, a traditional Simple Average, the Bayesian Average, the Granger-Ramanathan's Regression Approach (GRR) and the Least Absolute Shrinkage and Selection Operator (LASSO). Finally, we apply a time-varying leverage strategy based on RiskMetrics volatility forecasts in order to further improve the forecasting performance of our models and combinations. The statistical and trading performance of our models is estimated throughout the period of 2002-2010, using the last two years for out-of-sample testing. In terms of our results, the PSN outperforms all models' individual performances in terms of statistical accuracy and trading performance. The forecast combinations also present improved empirical evidence, with Kalman Filters outperforming by far its benchmarks. We also note that after the application of the time varying leverage, all models except ARMA show a substantial increase in their trading performance.",2012,Decis. Support Syst.
Regresi Kuantil Bayesian Dengan Penalti Adaptif Lasso Untuk Estimasi Pengaruh Pendidikan Terhadap Pendapatan Di Provinsi Sulawesi Selatan,"Pendidikan diharapkan dapat mendorong peningkatan produktivitas 
yang pada akhirnya bermuara pada peningkatan pendapatan masyarakat. 
Hubungan antara pendidikan dan pendapatan dapat dianalisis dengan 
persamaan Mincer. Studi ini bertujuan untuk meneliti hubungan antara lama 
sekolah (variabel yang mewakili pendidikan) dan potensi pengalaman 
(umur - lama sekolah) terhadap pendapatan. Pengaruh pendidikan terhadap 
pendapatan digambarkan oleh koefisien dari variabel lama sekolah yang 
umumnya dikenal sebagai return pendidikan. Regresi kuantil digunakan 
dalam penelitian ini untuk melihat efek pendidikan terhadap pendapatan 
pada berbagai tingkatan kuantil, bukan hanya pada ukuran pemusatan 
distribusi dari pendapatan. Persamaan Mincer ditaksir menggunakan tiga 
pendekatan, yaitu: (i) Quantile Regression (QR), (ii) Bayesian Quantile 
Regression (BQR), dan (iii) Bayesian Adaptive Lasso Quantile Regression 
(BALQR). Metode BALQR ini adalah perluasan dari metode BQR dengan 
memberikan penalti yang berbeda pada setiap koefisien regresi. Invers 
gamma digunakan sebagai distribusi prior untuk parameter penalti. Data 
yang digunakan untuk penelitian ini adalah hasil survei angkatan kerja 
nasional (SAKERNAS) 2014 di Provinsi Sulawesi Selatan. Hasil studi 
menunjukkan bahwa metode BALQR relatif lebih baik dibanding dengan 
dua metode lainnya berdasarkan hasil backtesting dan perbandingan nilai 
standar error. Selain itu, terdapat perbedaan plot garis regresi kuantil untuk 
sektor pertanian dan jasa-jasa. Return pendidikan pada sektor pertanian 
relatif sama antar kuantil sementara pada sektor jasa return pendidikan 
antar kuantil sebagian besar berbeda secara signifikan. 
================================================================================================================== 
Education plays an important role toward the increasing in 
productivity and earning. Using so-called mincer earning function, we 
investigated the effect of education and earning. This study using years of 
schooling (interpretation of education) and potensial experience as 
predictor variables. Effect of education represented by coefficient of 
variable years of schooling, commonly known as return to education. With 
quantile regression, allowing to specify the effect of covariate at different 
quantile levels not only at the center of its distribution, but also at its 
spread. We employed three methods to estimate parameters in mincer 
equation: (i) Quantile Regression (QR), (ii) Bayesian Quantile Regression 
(BQR) and (iii) Bayesian Adaptive Lasso Quantile Regression (BALQR). 
The latter method extends the bayesian Lasso penalty term by employing 
different penalty function with an adaptive tuning parameter accomodated 
in the inverse gamma prior distribution. Data used in this paper is samples 
from workers in agricultural and services sectors in South Sulawesi. 
Empirical results showed that BALQR relative outperformed over BQR and 
QR because it resulted better in backtesting and smaller standart error (SE). 
In addition, there are different pattern quantile regression line for 
agricultural and services sectors. Return to education in agricultural sector 
in most of quantile of earning are not different. More over, return to 
education in services different in most of quantile of earning.",2016,
Understanding hedge fund alpha using replication methodologies,"Abstract: In this paper we estimate alpha for major hedge fund indexes.Â  To set the stage for estimating alpha, we examine several alternative methods for replicating Hedge Fund Research Inc. hedge fund indexes.Â  The replication methods include stepwise regression,variations of the lasso shrinkage method, principal component regression, partial least squares regression, and dynamic linear regression.Â  We find that the lasso methods and dynamic regression are superior for generating hedge fund index replications and that the performance of the replications corresponds closely to that of the respective actual indexes.Â  Using these superior replications provides us with a solid platform for estimating alpha.Â  We find that at the height of the financial crisis the alphas computed with our methods generally were negative, in early 2009 when the stock market was rising alphas were generally positive, and inthe current environment of low volatility and low interest rates the alphas computed with our methods generally are close to zero and tend to exhibit low volatility.",2014,The Journal of Alternative Investments
Abstract IA15: Predicting drug sensitivity from cancer cell lines,"High-throughput molecular characterization technologies have enabled detailed genetic and genomic characterization of large panels of cancer cell lines, including profiling of gene expression, copy number variation (CNV), SNP, mutation, and RNA-seq. The same cell lines have also been profiled for sensitivity to potential anti-cancer compounds, allowing development of computational models used to predict genotype-specific drug treatments linked to tumor molecular subtypes. Inferring such models is challenging because the model inputs contain far more features than observations, known as the p>>n problem, precluding the use of classical statistical models such as least squares (a.k.a. multiple linear regression). Recently, generalized linear models or penalized linear models have been proposed and extended for feature selection and overcoming the p>>n. Bayesian extension of such methods have also been developed, using algorithms such as Metropolis-Hasting and Markov Chain Monte Carlo, and demonstrated to improve prediction accuracy at the expense of increased computing cost. A comprehensive evaluation of predictive modeling techniques is essential to leverage cell line studies to infer the most accurate genetic predictors of drug sensitivity, which can then be used to inform patient selection strategies in clinical trials and to identify functional genetic determinants of drug sensitivity or resistance. In this study, we evaluate state-of-the-art predictive models which utilize dimension reduction methods (e.g., partial least square, support vector machine, principal component regression), feature selection (e.g., LASSO, RIDGE, and elastic-net), and Bayesian feature selection (e.g., Bayesian LASSO and Bayesian RIDGE). We assess each method based on 1) the accuracy of sensitivity predictions in a cross validation setting and in an independent dataset, and 2) the biological coherence of inferred predictive features by comparison to publicly available pathway databases. Citation Format: Adam Arne Margolin, In Sock Jang, Stephen Friend. Predicting drug sensitivity from cancer cell lines. [abstract]. In: Proceedings of the AACR Special Conference on Chemical Systems Biology: Assembling and Interrogating Computational Models of the Cancer Cell by Chemical Perturbations; 2012 Jun 27-30; Boston, MA. Philadelphia (PA): AACR; Cancer Res 2012;72(13 Suppl):Abstract nr IA15.",2012,Cancer Research
The Cost of Type II Diabetes Mellitus: A Machine Learning Perspective,"In this study, the burden of type II diabetes mellitus is investigated using machine learning methods. In particular, it is mainly aimed at obtaining an accurate quantification of the burden of diabetes by computing the number of indicators that provide the highest discrimination rate between normal people and patients. Assuming that the cardinality of the best-fitting feature set can be used to quantify the magnitude of the overall burden, several healthcare related features are extracted from demographic, diagnosis, medication and lab test records. Experimental results have shown that there are about 200 relevant indicators and the highest classification performance achieved in discriminating diabetic and normal people is remarkably superior to that of the baseline system. In other words, the burden of diabetes is not limited to a small group of complications, medications or lab tests. In the second phase of experiments, the relative effects of different indicators are evaluated by employing Lasso and Ridge regression algorithms. It is observed that the best set of indicators have different levels of effects in discriminating between diabetic and normal people.",2016,
Deconvolution of fMRI BOLD signal in time-domain using an exponential operator and Lasso optimization,"Many techniques have been explored so far in the study of neural activations using the blood oxygenated level dependent (BOLD) signal. Among them, deconvolution methods have been developed in order to explore spontaneous brain activity when the brain is in resting-state. These techniques are powerful since they do not require a priori knowledge about timing and duration of activations [2]. In this work, we propose a regularized deconvolution technique which uses an exponential operator, whose shape and performance can be adjusted by tuning a parameter Î±, and the Least-Angle Regression (LARS) algorithm, by using the least absolute shrinkage and selection operator (LASSO) model.",2017,
Nonasymptotic Analysis of Semiparametric Regression Models with High-Dimensional Parametric Coefficients,"We consider a two-step projection based Lasso procedure for estimating a partially linear regression model where the number of coefficients in the linear component can exceed the sample size and these coefficients belong to the l_{q}-â€œballsâ€ for q in [0, 1]. Our theoretical results are nonasymptotic and include the upper bounds on the l_{2}-errors of the proposed estimators and a result on variable selection. In particular, we establish a new non-asymptotic â€œoracleâ€ result: Although the prediction error of the nonparametric projection per se has the scaling t_{n} in the first step, it only contributes a scaling of t_{n}^{2} in the l_{2}-error of the second-step estimator for the linear coefficients. This new â€œoracleâ€ result holds for a unified framework of nonparametric least squares procedures and regularized nonparametric least squares procedures for the first-step estimation and the driver behind it lies in the projection strategy. We specialize our analysis to the estimation of a semiparametric sample selection model and provide a simple method with theoretical guarantees for choosing the regularization parameter in practice.",2017,Annals of Statistics
Comparison of high-dimensional confounder summary scores in comparative studies of newly marketed medications.,"OBJECTIVE
To compare confounding adjustment by high-dimensional propensity scores (hdPSs) and historically developed high-dimensional disease risk scores (hdDRSs) in three comparative study examples of newly marketed medications: (1) dabigatran vs. warfarin on major hemorrhage; (2) on death; and (3) cyclooxygenase-2 inhibitors vs. nonselective nonsteroidal anti-inflammatory drugs on gastrointestinal bleeds.


STUDY DESIGN AND SETTING
In each example, we constructed a concurrent cohort of new and old drug initiators using US claims databases. In historical cohorts of old drug initiators, we developed hdDRS models including investigator-specified plus empirically identified variables and using principal component analysis and lasso regression for dimension reduction. We applied the models to the concurrent cohorts to obtain predicted outcome probabilities, which we used for confounding adjustment. We compared the resulting estimates to those from hdPS.


RESULTS
The crude odds ratio (OR) comparing dabigatran to warfarin was 0.52 (95% confidence interval: 0.37-0.72) for hemorrhage and 0.38 (0.26-0.55) for death. Decile stratification yielded an OR of 0.64 (0.46-0.90) for hemorrhage using hdDRS vs. 0.70 (0.49-1.02) for hdPS. ORs for death were 0.69 (0.45-1.06) and 0.73 (0.48-1.10), respectively. The relative performance of hdDRS in the cyclooxygenase-2 inhibitors example was similar.


CONCLUSION
hdDRS achieved similar or better confounding adjustment compared to conventional regression approach but worked slightly less well than hdPS.",2016,Journal of clinical epidemiology
Stability selection using a genetic algorithm and logistic linear regression on healthcare records,"This paper presents a Genetic Algorithm (GA) application to measuring feature importance in machine learning (ML) from a large-scale database. Too many input features may cause over-fitting, therefore a feature selection is desirable. Some ML algorithms have feature selection embedded, e.g., lasso penalized linear regression or random forests. Others do not include such functionality and are sensitive to over-fitting, e.g., unregularized linear regression. The latter algorithms require that proper features are chosen before learning.
 Therefore, we propose a novel stability selection (SS) approach using GA-based feature selection. The proposed SS approach iteratively applies GA on a subsample of records and features. Each GA individual represents a binary vector of selected features in the subsample. An unregularized logistic linear regression model is then trained and tested using GA-selected features through cross-validation of the subsamples. GA fitness is evaluated by area under the curve (AUC) and optimized during a GA run.
 AUC is assessed with an unregularized logistic regression model on multiple-subsampled healthcare records, collected under the Healthcare Cost, and Utilization Project (HCUP), utilizing the National (Nationwide) Inpatient Sample (NIS) database.
 Reported results show that averaging feature importance from top-4 SS and the SS using GA (GASS), improves these AUC results.",2017,Proceedings of the Genetic and Evolutionary Computation Conference Companion
Relational Lasso - An Improved Method Using the Relations Among Features -,"Relational lasso is a method that incorporates feature relations within machine learning. By using automatically obtained noisy relations among features, relational lasso learns an additional penalty parameter per feature, which is then incorporated in terms of a regularizer within the target optimization function. Relational lasso has been tested on three different tasks: text categorization, polarity estimation, and parsing, where it was compared with conventional lasso and adaptive lasso (Zou, 2006) when using a multi-class logistic regression optimization method. Relational lasso outperformed these other lasso methods in the tests.",2011,
Multilinear Regression for Embedded Feature Selection with Application to fMRI Analysis,"Embedded feature selection is effective when both prediction 
and interpretation are needed. The Lasso and its extensions 
are standard methods for selecting a subset of features while 
optimizing a prediction function. In this paper, we are interested 
in embedded feature selection for multidimensional 
data, wherein (1) there is no need to reshape the multidimensional 
data into vectors and (2) structural information from 
multiple dimensions are taken into account. Our main contribution 
is a new method called Regularized multilinear regression 
and selection (Remurs) for automatically selecting a subset 
of features while optimizing prediction for multidimensional 
data. Both nuclear norm and the `1-norm are carefully 
incorporated to derive a multi-block optimization algorithm 
with proved convergence. In particular, Remurs is motivated 
by fMRI analysis where the data are multidimensional and it 
is important to find the connections of raw brain voxels with 
functional activities. Experiments on synthetic and real data 
show the advantages of Remurs compared to Lasso, Elastic 
Net, and their multilinear extensions.",2017,
Flexible Edge Arrangement Templates for Object Detection,"We present a novel feature representation for categorical object detection. Unlike previous approaches that have concentrated on generic interest-point detectors, we construct object-specific features directly from the training images. Our feature is represented by a collection of Flexible Edge Arrangement Templates (FEATs). We propose a two-stage semi-supervised learning approach to feature selection. A subset of frequent templates are first selected from a large template pool. In the second stage, we formulate feature selection as a regression problem and use LASSO method to find the most discriminative templates from the preselected ones. FEATs adaptively capture the image structure and naturally accommodate local shape variations. We show that this feature can be complemented by the traditional holistic patch method, thus achieving both efficiency and accuracy. We evaluate our method on three well-known car datasets, showing performance competitive with existing methods.",2008,2008 IEEE Workshop on Applications of Computer Vision
Shrinkage estimation and selection for a logistic regression model,"This paper considers the problem of variable selection and the esti- mation for a logistic regression model via shrinkage and three penalty methods. We develop a large sample theory for the shrinkage estimators including as- ymptotic distributional bias and risk. We show that if the shrinkage dimension exceeds two, the asymptotic risk of the shrinkage estimator is strictly less than the classical estimators for a wide class of models. This reduction holds glob- ally in the parameter space. Furthermore, we consider three different penalty estimators: the LASSO, adaptive LASSO, and SCAD and compare their rel- ative performance with the shrinkage estimators numerically. A Monte Carlo simulation study is conducted for different combinations of inactive predictors and the performance of each method is evaluated in terms of a simulated mean squared error. This study indicates that shrinkage method is comparable to the LASSO, adaptive LASSO, and SCAD when the number of inactive pre- dictors in the model is relatively large. A real data example is presented to illustrate the proposed methodologies.",2014,
Direct and label-free gram classification of bacterial colonies on agar using hyperspectral imaging,"Diffuse reflectance spectra of bacterial colonies, from hyperspectral images, allowed for a label-free Gram classification into Gram-positive (GP) and Gram-negative (GN) types. Thirty-eight strains belonging to 14 bacterial species typically encountered in urinary tract infections (UTI) were cultivated on chromID CPS Elite translucent chromogenic culture medium to build training and testing sets. Using Support Vector Machine (SVM) supervised learning models, we demonstrated excellent classification rates with a percentage of correctly classified samples as high as 95%. Because determination of discriminant spectral channels is critical both for fundamental reasons to help understand the origin of the discriminant signal and for practical reasons to envision simpler multispectral systems, parsimonious analysis was conducted employing a Fused LASSO (Least Absolute Shrinkage and Selection Operator) or based on an uncertainty test in Partial least squares PLS regression analysis. Two prominent distinct spectral regions were thus identified allowing to hypothesize that cytochrome ratios might be, at least in part, at the origin of the differences observed between Gram-negative and Gram-positive bacteria populations.",2018,
Parallel Lasso for Large-Scale Video Concept Detection,"Existing video concept detectors are generally built upon the kernel based machine learning techniques, e.g., support vector machines, regularized least squares, and logistic regression, just to name a few. However, in order to build robust detectors, the learning process suffers from the scalability issues including the high-dimensional multi-modality visual features and the large-scale keyframe examples. In this paper, we propose parallel lasso (Plasso) by introducing the parallel distributed computation to significantly improve the scalability of lasso (the <i>l</i><sub>1</sub> regularized least squares). We apply the parallel incomplete Cholesky factorization to approximate the covariance statistics in the preprocess step, and the parallel primal-dual interior-point method with the Sherman-Morrison-Woodbury formula to optimize the model parameters. For a dataset with <i>n</i> samples in a <i>d</i>-dimensional space, compared with lasso, Plasso significantly reduces complexities from the original <i>O</i>(<i>d</i><sup>3</sup>) for computational time and <i>O</i>(<i>d</i><sup>2</sup>) for storage space to <i>O</i>(<i>h</i><sup>2</sup><i>d</i>/<i>m</i>) and <i>O</i>(<i>hd</i>/<i>m</i>) , respectively, if the system has <i>m</i> processors and the reduced dimension <i>h</i> is much smaller than the original dimension <i>d</i> . Furthermore, we develop the kernel extension of the proposed linear algorithm with the sample reweighting schema, and we can achieve similar time and space complexity improvements [time complexity from <i>O</i>(<i>n</i><sup>3</sup>) to <i>O</i>(<i>h</i><sup>2</sup><i>n</i>/<i>m</i>) and the space complexity from <i>O</i>(<i>n</i><sup>2</sup>) to <i>O</i>(<i>hn</i>/<i>m</i>), for a dataset with <i>n</i> training examples]. Experimental results on TRECVID video concept detection challenges suggest that the proposed method can obtain significant time and space savings for training effective detectors with limited communication overhead.",2012,IEEE Transactions on Multimedia
Reprioritizing Genetic Associations in Hit Regions Using LASSO-Based Resample Model Averaging,"Significance testing one SNP at a time has proven useful for identifying genomic regions that harbor variants affecting human disease. But after an initial genome scan has identified a ""hit region"" of association, single-locus approaches can falter. Local linkage disequilibrium (LD) can make both the number of underlying true signals and their identities ambiguous. Simultaneous modeling of multiple loci should help. However, it is typically applied ad hoc: conditioning on the top SNPs, with limited exploration of the model space and no assessment of how sensitive model choice was to sampling variability. Formal alternatives exist but are seldom used. Bayesian variable selection is coherent but requires specifying a full joint model, including priors on parameters and the model space. Penalized regression methods (e.g., LASSO) appear promising but require calibration, and, once calibrated, lead to a choice of SNPs that can be misleadingly decisive. We present a general method for characterizing uncertainty in model choice that is tailored to reprioritizing SNPs within a hit region under strong LD. Our method, LASSO local automatic regularization resample model averaging (LLARRMA), combines LASSO shrinkage with resample model averaging and multiple imputation, estimating for each SNP the probability that it would be included in a multi-SNP model in alternative realizations of the data. We apply LLARRMA to simulations based on case-control genome-wide association studies data, and find that when there are several causal loci and strong LD, LLARRMA identifies a set of candidates that is enriched for true signals relative to single locus analysis and to the recently proposed method of Stability Selection.",2012,Genetic Epidemiology
Survival-Associated Alternative Messenger RNA Splicing Signatures in Pancreatic Ductal Adenocarcinoma: A Study Based on RNA-Sequencing Data.,"Multiple studies have shown that cancer-specific alternative splicing (AS) alterations are associated with clinical outcome. In this study, we aimed to profile prognostic AS signatures for pancreatic ductal adenocarcinoma (PDAC). We integrated the percent-spliced-in (PSI) data of AS in 140 PDAC patients based on the Cancer Genome Atlas (TCGA) dataset. We identified overall survival (OS)-associated AS events using univariate Cox regression analysis. Then, prognostic AS signatures were constructed for OS and chemoresistance prediction using the least absolute shrinkage and selection operator (LASSO) method. We also analyzed splicing factors (SFs) regulatory networks by Pearson's correlation. We detected 677 OS-related AS events in 485 genes by profiling 10,354 AS events obtained from 140 PDAC patients. Gene functional enrichment analysis demonstrated the pathways enriched by survival-associated AS. The AS signatures constructed with significant survival-associated AS events revealed high performance in predicting PDAC survival and gemcitabine chemoresistance. The area under the receiver operator characteristic curve was 0.937 in training cohort and 0.748 in validation cohort at 2000 days of OS. Furthermore, we identified prognostic SFs (e.g., ESRP1 and HNRNPC) to build the AS regulatory network. We constructed AS signatures for OS and gemcitabine chemoresistance in PDAC patients, which may provide clues for further experiment-based mechanism study.",2019,DNA and cell biology
Data-driven discovery of mid-pregnancy immune markers associated with maternal lifetime stress: results from an urban pre-birth cohort.,"Changes to the maternal inflammatory milieu may be a mechanism through which maternal psychosocial stress is transmitted to the fetus. Research investigating a limited number of immune markers may miss important signals. We take a proteomics approach to investigate maternal lifetime stress and 92 biomarkers of immune system status. Participants were enrolled in an urban, dual-site (Boston, nâ€‰=â€‰301 and New York City, nâ€‰=â€‰110) pregnancy cohort. We measured maternal lifetime history of stress and trauma using the validated Life Stressor Checklist-Revised (LSC-R). We measured a panel of 92 immune-related proteins in mid-pregnancy serum using proximity extension assay technology. We leveraged the dual-site study design to perform variable selection and inference within the cohort. First, we used LASSO to select immune markers related to maternal stress among Boston mothers. Then, we performed OLS regression to examine associations between maternal stress and LASSO-selected proteins among New York City mothers. LASSO regression selected 19 immune proteins with non-null coefficients (CCL11, CCL23, CD244, CST5, CXCL1, CXCL5, CXCL10, CX3CL1, FGF-23, IL-5, IL-7, IL-10, IL-17C, MCP-2, MMP-1, SLAMF1, ST1A1, TNF-Î², and TWEAK). Of these, only the chemotactic cytokine CX3CL1 (i.e., fractalkine) was significantly associated with maternal stress among the validation sample (percent change in LSC-R score per 1% increase in relative fractalkine expression: 0.74, 95% confidence interval: 0.19, 1.28). Expanding research suggests fractalkine plays an important role in many aspects of pregnancy and fetal development and is stress-sensitive. We found that maternal lifetime history of stress and trauma was significantly associated with elevated serum fractalkine levels during pregnancy.",2019,Stress
Predicting radiation-induced valvular heart damage.,"PURPOSE
To develop a predictive multivariate normal tissue complication probability (NTCP) model for radiation-induced heart valvular damage (RVD). The influence of combined heart-lung irradiation on RVD development was included.


MATERIAL AND METHODS
Multivariate logistic regression modeling with the least absolute shrinkage and selection operator (LASSO) was used to build an NTCP model to predict RVD based on a cohort of 90 Hodgkin lymphoma patients treated with sequential chemo-radiation therapy. In addition to heart irradiation factors, clinical variables, along with left and right lung dose-volume histogram statistics, were included in the analysis. To avoid overfitting, 10-fold cross-validation (CV) was used for LASSO logistic regression modeling, with 50 reshuffled cycles. Model performance was assessed using the area under the receiver operating characteristic (ROC) curve (AUC) and Spearman's correlation coefficient (Rs).


RESULTS
At a median follow-up time of 55 months (range 12-92 months) after the end of radiation treatment, 27 of 90 patients (30%) manifested at least one kind of RVD (mild or moderate), with a higher incidence of left-sided valve defects (64%). Fourteen prognostic factors were frequently selected (more than 100/500 model fits) by LASSO, which included mainly heart and left lung dosimetric variables along with their volume variables. The averaged cross-validated performance was AUC-CV = 0.685 and Rs = 0.293. The overall performance of a final NTCP model for RVD obtained applying LASSO logistic regression to the full dataset was satisfactory (AUC = 0.84, Rs = 0.55, p < 0.001).


CONCLUSION
LASSO proved to be an improved and flexible modeling method for variable selection. Applying LASSO, we showed, for the first time, the importance of jointly considering left lung irradiation and left lung volume size in the prediction of subclinical radiation-related heart disease resulting in RVD.",2015,Acta oncologica
Linear convergence of SDCA in statistical estimation,"SVRG and its variants are among the state of art optimization algorithms for large scale machine learning problems. It is well known that SVRG converges linearly when the objective function is strongly convex. However this setup can be restrictive, and does not include several important formulations such as Lasso, group Lasso, logistic regression, and some non-convex models including corrected Lasso and SCAD. In this paper, we prove that, for a class of statistical M-estimators covering examples mentioned above, SVRG solves the formulation with {\em a linear convergence rate} without strong convexity or even convexity. Our analysis makes use of {\em restricted strong convexity}, under which we show that SVRG converges linearly to the fundamental statistical precision of the model, i.e., the difference between true unknown parameter $\theta^*$ and the optimal solution $\hat{\theta}$ of the model.",2017,ArXiv
Identification of a three-m6A related gene risk score model as a potential prognostic biomarker in clear cell renal cell carcinoma,"Background
Clear cell renal cell carcinoma (ccRCC) is one of the most prevalent malignancies worldwide, N6-methyladenosine (m6A) has been shown to play important roles in regulating gene expression and phenotypes in both health and disease. Here, our purpose is to construct a m6A-regulrator-based risk score (RS) for prediction of the prognosis of ccRCC.


Methods
We used clinical and expression data of m6A related genes from The Cancer Genome Atlas (TCGA) dataset and the Least Absolute Shrinkage and Selection Operator (LASSO) Cox regression analysis to develop an RS to predict survival of patients with ccRCC, and analyzed correlations between RS and other clinical indicators such as age, grade and stage. Validation of this RS was then engaged in another cohort, E-MTAB-1980 from the ArrayExpress dataset. Finally, we used quantitative real-time PCR to analyze the expression profile of genes consists of the RS.


Results
A three-gene RS including METTL3, METTL14 and HNRNPA2B1 which can predict overall survival (OS) of ccRCC patients from TCGA. After applying this RS into the validation cohort from Arrayexpress, we found that it successfully reproduced the result; furthermore, the results of PCR validation were in line with our analysis.


Conclusion
To sum up, our study has identified an RS composed of m6A related genes that may predict the prognosis of ccRCC patients, which might be helpful for future therapeutic strategies. Our results call for further experimental studies for validations.",2020,PeerJ
Preoperative assessment of lymph node metastasis in clinically node-negative rectal cancer patients based on a nomogram consisting of five clinical factors,"Background: Currently, reliable approaches for accurate assessment of lymph node metastases (LNM), which is an important indication of preoperative chemoradiotherapy (CRT), are not available for clinically node-negative rectal cancer patients. This study aims to identify clinical factors associated with LNM and to establish a nomogram for LNM prediction in clinically node-negative rectal cancer patients. 
 Methods: The least absolute shrinkage and selection operator (LASSO) aggression and multivariate logistic regression analyses were applied to identify clinical factors associated with LNM. A nomogram was established to predict the probability of LNM in clinically node-negative rectal cancer patients based on the multivariate logistic regression model. 
 Results: Six potential risk factors were selected on the basis of LASSO aggression analysis, and five of them were identified as independent risk factors for LNM based on multivariate analysis, including MRI-reported tumor location, clinical T classification, MRI-reported tumor diameter, white blood cell count (WBC), and preoperative elevated tumor markers. A nomogram consisting of the five clinical factors was established and showed good discrimination. Decision curve analysis demonstrated that the established nomogram was reliable and accurate for LNM prediction in clinically node-negative rectal cancer patients. Conclusions: A nomogram based on five clinical factors, including MRI-reported tumor location, clinical T classification, MRI-reported tumor diameter, WBC, and preoperative elevated tumor markers, are useful for assessing LNM in clinically node-negative rectal cancer patients, which is important for preoperative CRT regimens.",2019,Annals of Translational Medicine
Radiomics Features of Multiparametric MRI as Novel Prognostic Factors in Advanced Nasopharyngeal Carcinoma.,"Purpose: To identify MRI-based radiomics as prognostic factors in patients with advanced nasopharyngeal carcinoma (NPC).Experimental Design: One-hundred and eighteen patients (training cohort: n = 88; validation cohort: n = 30) with advanced NPC were enrolled. A total of 970 radiomics features were extracted from T2-weighted (T2-w) and contrast-enhanced T1-weighted (CET1-w) MRI. Least absolute shrinkage and selection operator (LASSO) regression was applied to select features for progression-free survival (PFS) nomograms. Nomogram discrimination and calibration were evaluated. Associations between radiomics features and clinical data were investigated using heatmaps.Results: The radiomics signatures were significantly associated with PFS. A radiomics signature derived from joint CET1-w and T2-w images showed better prognostic performance than signatures derived from CET1-w or T2-w images alone. One radiomics nomogram combined a radiomics signature from joint CET1-w and T2-w images with the TNM staging system. This nomogram showed a significant improvement over the TNM staging system in terms of evaluating PFS in the training cohort (C-index, 0.761 vs. 0.514; P < 2.68 Ã— 10-9). Another radiomics nomogram integrated the radiomics signature with all clinical data, and thereby outperformed a nomogram based on clinical data alone (C-index, 0.776 vs. 0.649; P < 1.60 Ã— 10-7). Calibration curves showed good agreement. Findings were confirmed in the validation cohort. Heatmaps revealed associations between radiomics features and tumor stages.Conclusions: Multiparametric MRI-based radiomics nomograms provided improved prognostic ability in advanced NPC. These results provide an illustrative example of precision medicine and may affect treatment strategies. Clin Cancer Res; 23(15); 4259-69. Â©2017 AACR.",2017,Clinical cancer research : an official journal of the American Association for Cancer Research
Improved Oracle Complexity of Variance Reduced Methods for Nonsmooth Convex Stochastic Composition Optimization,"We consider the nonsmooth convex composition optimization problem where the objective is a composition of two finite-sum functions and analyze stochastic compositional variance reduced gradient (\textsf{SCVRG}) methods for them. \textsf{SCVRG} and its variants have recently drawn much attention given their edge over stochastic compositional gradient descent (\textsf{SCGD}); but the theoretical analysis exclusively assumes strong convexity of the objective, which excludes several important examples such as Lasso, logistic regression, principle component analysis and deep neural nets. In contrast, we prove non-asymptotic incremental first-order oracle (\textsf{IFO}) complexity of \textsf{SCVRG} or its novel variants for nonsmooth convex composition optimization and show that they are provably faster than \textsf{SCGD} and gradient descent. More specifically, our method achieves the total \textsf{IFO} complexity of $O\left((m+n)\log\left(1/\epsilon\right)+1/\epsilon^3\right)$ which improves that of $O\left(1/\epsilon^{3.5}\right)$ and $O\left((m+n)/\sqrt{\epsilon}\right)$ obtained by \textsf{SCGD} and accelerated gradient descent respectively. Experiments on sparse mean-variance optimization problem demonstrates that our method outperforms other competing methods.",2018,ArXiv
Lasso and equivalent quadratic penalized regression models,"The least absolute shrinkage and selection operator (lasso) and ridge regression produce usually different estimates although input, loss function and parameterization of the penalty are identical. In this paper we look for ridge and lasso models with identical solution set. It turns out, that the lasso model with shrink vector and a quadratic penalized model with shrink matrix as outer product of with itself are equivalent, in the sense that they have equal solutions. To achieve this, we have to restrict the estimates to be positive. This doesnâ€™t limit the area of application since we can decompose every estimate in a positive and negative part. The resulting problem can be solved with a non negative least square algorithm and may benet from algorithms with high numerically accuracy. This model can also deal with mixtures of ridge and lasso penalties like the elastic net, leading to a continuous solution path as a function of the mixture proportions. Beside this quadratic penalized model, an augmented regression model with positive bounded estimates is developed which is also equivalent to the lasso model, but is probably faster to solve.",2014,
Simultaneous Support Recovery in High Dimensions: Benefits and Perils of Block $\ell _{1}/\ell _{\infty} $-Regularization,"Given a collection of <i>r</i> â‰¥ 2 linear regression problems in <i>p</i> dimensions, suppose that the regression coefficients share partially common supports of size at most <i>s</i>. This set-up suggests the use of â„“<sub>1</sub>/â„“<sub>âˆž</sub>-regularized regression for joint estimation of the <i>p</i>Ã—<i>r</i> matrix of regression coefficients. We analyze the high-dimensional scaling of â„“<sub>1</sub>/â„“<sub>âˆž</sub>-regularized quadratic programming, considering both consistency rates in â„“<sub>âˆž</sub>-norm, and how the minimal sample size <i>n</i> required for consistent variable selection scales with model dimension, sparsity, and overlap between the supports. We first establish bounds on the â„“<sub>âˆž</sub>-error as well sufficient conditions for exact variable selection for fixed design matrices, as well as for designs drawn randomly from general Gaussian distributions. Specializing to the case <i>r</i> = 2 linear regression problems with standard Gaussian designs whose supports overlap in a fraction Î± âˆˆ [0,1] of their entries, we prove that â„“<sub>1</sub>/â„“<sub>âˆž</sub>-regularized method undergoes a phase transition characterized by the rescaled sample size Î¸<sub>1,âˆž</sub>(<i>n</i>, <i>p</i>, <i>s</i>, Î±) = <i>n</i>/{(4 - 3 Î±) <i>s</i> log(<i>p</i>-(2- Î±) <i>s</i>)}. An implication is that the use of â„“<sub>1</sub>/â„“<sub>âˆž</sub>-regularization yields improved statistical efficiency if the overlap parameter is large enough ( Î± >; 2/3), but has worse statistical efficiency than a naive Lasso-based approach for moderate to small overlap (Î± <; 2/3 ). Empirical simulations illustrate the close agreement between theory and actual behavior in practice. These results show that caution must be exercised in applying <i>â„“</i><sub>1</sub>/â„“<sub>âˆž</sub> block regularization: if the data does not match its structure very closely, it can impair statistical performance relative to computationally less expensive schemes.",2011,IEEE Transactions on Information Theory
"Penalized regression methods with application to generalized linear models, generalized additive models, and smoothing","Recently, penalized regression has been used for dealing problems which found in maximum likelihood estimation such as correlated parameters and a large number of predictors. The main issues in this regression is how to select the optimal model. In this thesis, Schallâ€™s algorithm is proposed as an automatic selection of weight of penalty. The algorithm has two steps. First, the coefficient estimates are obtained with an arbitrary penalty weight. Second, an estimate of penalty weight Î» can be calculated by the ratio of the variance of error and the variance of coefficient. The iteration is continued from step one until an estimate of penalty weight converge. The computational cost is minimized because the optimal weight of penalty could be obtained within a small number of iterations. 
In this thesis, Schallâ€™s algorithm is investigated for ridge regression, lasso regression and two-dimensional histogram smoothing. The proposed algorithm are applied to real data sets and simulation data sets. In addition, a new algorithm for lasso regression is proposed. The performance of results of the algorithm was almost comparable in all applications. Schallâ€™s algorithm can be an efficient algorithm for selection of weight of penalty.",2017,
High-order covariate interacted Lasso for feature selection,"High-order covariates interaction is considered into Lasso-type variable selection.We evaluate the significance of feature by considering their neighborhood dependency.Having too few features in not necessarily a good feature selection result.Some interactive features may be lost in the process of removing redundancy. Lasso-type feature selection has been demonstrated to be effective in handling high dimensional data. Most existing Lasso-type models over emphasize the sparsity and overlook the interactions among covariates. Here on the other hand, we devise a new regularization term in the Lasso regression model to impose high order interactions between covariates and responses. Specifically, we first construct a feature hypergraph to model the high-order relations among covariates, in which each node corresponds to a covariate and each hyperedge has a weight corresponding to the interaction information among covariates connected by that hyperedge. For the hyperedge weight, we use multidimensional interaction information (MII) to measure the significance of different covariate combinations with respect to response. Secondly, we use the feature hypergraph as a regularizer on the covariate coefficients which can automatically adjust the relevance measure between a covariate and the response by the interaction weights obtained from hypergraph. Finally, an efficient alternating direction method of multipliers (ADMM) is presented to solve the resulting sparse optimization problem. Extensive experiments on different data sets show that although our proposed model is not a convex problem, it outperforms both its approximately convex counterparts and a number of state-of-the-art feature selection methods.",2017,Pattern Recognit. Lett.
Refocusing the lens on engagement in MOOCs,"Massive open online courses (MOOCs) continue to see increasing enrollment and adoption by universities, although they are still not fully understood and could perhaps be significantly improved. For example, little is known about the relationships between the ways in which students choose to use MOOCs (e.g., sampling lecture videos, discussing topics with fellow students) and their overall level of engagement with the course, although these relationships are likely key to effective course implementation. In this paper we propose a multilevel definition of student engagement with MOOCs and explore the connections between engagement and students' behaviors across five unique courses. We modeled engagement using ordinal penalized logistic regression with the least absolute shrinkage and selection operator (LASSO), and found several predictors of engagement that were consistent across courses. In particular, we found that discussion activities (e.g., viewing forum posts) were positively related to engagement, whereas other types of student behaviors (e.g., attempting quizzes) were consistently related to less engagement with the course. Finally, we discuss implications of unexpected findings that replicated across courses, future work to explore these implications, and relevance of our findings for MOOC course design.",2018,Proceedings of the Fifth Annual ACM Conference on Learning at Scale
An outcome model for human bladder cancer: A comprehensive study based on weighted gene coâ€expression network analysis,"The precision evaluation of prognosis is crucial for clinical treatment decision of bladder cancer (BCa). Therefore, establishing an effective prognostic model for BCa has significant clinical implications. We performed WGCNA and DEG screening to initially identify the candidate genes. The candidate genes were applied to construct a LASSO Cox regression analysis model. The effectiveness and accuracy of the prognostic model were tested by internal/external validation and pan-cancer validation and time-dependent ROC. Additionally, a nomogram based on the parameter selected from univariate and multivariate cox regression analysis was constructed. Eight genes were eventually screened out as progression-related differentially expressed candidates in BCa. LASSO Cox regression analysis identified 3 genes to build up the outcome model in E-MTAB-4321 and the outcome model had good performance in predicting patient progress free survival of BCa patients in discovery and test set. Subsequently, another three datasets also have a good predictive value for BCa patients' OS and DFS. Time-dependent ROC indicated an ideal predictive accuracy of the outcome model. Meanwhile, the nomogram showed a good performance and clinical utility. In addition, the prognostic model also exhibits good performance in pan-cancer patients. Our outcome model was the first prognosis model for human bladder cancer progression prediction via integrative bioinformatics analysis, which may aid in clinical decision-making.",2019,Journal of Cellular and Molecular Medicine
