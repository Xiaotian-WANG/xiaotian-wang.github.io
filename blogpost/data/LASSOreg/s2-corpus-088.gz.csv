title,abstract,year,journal
Estimation and Feature Selection in High-Dimensional Mixtures-of-Experts Models,"This thesis deals with the problem of modeling and estimation of high-dimensional MoE models, towards effective density estimation, prediction and clustering of such heterogeneous and high-dimensional data. We propose new strategies based on regularized maximum-likelihood estimation (MLE) of MoE models to overcome the limitations of standard methods, including MLE estimation with Expectation-Maximization (EM) algorithms, and to simultaneously perform feature selection so that sparse models are encouraged in such a high-dimensional setting. We first introduce a mixture-of-experts' parameter estimation and variable selection methodology, based on $\ell_1$ (lasso) regularizations and the EM framework, for regression and clustering suited to high-dimensional contexts. Then, we extend the method to regularized mixture of experts models for discrete data, including classification. We develop efficient algorithms to maximize the proposed $\ell_1$-penalized observed-data log-likelihood function. Our proposed strategies enjoy the efficient monotone maximization of the optimized criterion, and unlike previous approaches, they do not rely on approximations on the penalty functions, avoid matrix inversion, and exploit the efficiency of the coordinate ascent algorithm, particularly within the proximal Newton-based approach.",2019,
Erratum to: Model selection by LASSO methods in a change-point model,"The paper considers a linear regression model with multiple change-points occurring at unknown times. The LASSO technique is very interesting since it allows the parametric estimation, including the change-points, and automatic variable selection simultaneously. The asymptotic properties of the LASSO-type (which has as particular case the LASSO estimator) and of the adaptive LASSO estimators are studied. For this last estimator the oracle properties are proved. In both cases, a model selection criterion is proposed. Numerical examples are provided showing the performances of the adaptive LASSO estimator compared to the LS estimator.",2014,Statistical Papers
A Lasso regression model for the construction of microRNA-target regulatory networks,"MOTIVATION
MicroRNAs have recently emerged as a major class of regulatory molecules involved in a broad range of biological processes and complex diseases. Construction of miRNA-target regulatory networks can provide useful information for the study and diagnosis of complex diseases. Many sequence-based and evolutionary information-based methods have been developed to identify miRNA-mRNA targeting relationships. However, as the amount of available miRNA and gene expression data grows, a more statistical and systematic method combining sequence-based binding predictions and expression-based correlation data becomes necessary for the accurate identification of miRNA-mRNA pairs.


RESULTS
We propose a Lasso regression model for the identification of miRNA-mRNA targeting relationships that combines sequence-based prediction information, miRNA co-regulation, RISC availability and miRNA/mRNA abundance data. By comparing this modelling approach with two other known methods applied to three different datasets, we found that the Lasso regression model has considerable advantages in both sensitivity and specificity. The regression coefficients in the model can be used to determine the true regulatory efficacies in tissues and was demonstrated using the miRNA target site type data. Finally, by constructing the miRNA regulatory networks in two stages of prostate cancer (PCa), we found the several significant miRNA-hubbed network modules associated with PCa metastasis. In conclusion, the Lasso regression model is a robust and informative tool for constructing the miRNA regulatory networks for diagnosis and treatment of complex diseases.


AVAILABILITY
The R program for predicting miRNA-mRNA targeting relationships using the Lasso regression model is freely available, along with the described datasets and resulting regulatory network, at http://biocompute.bmi.ac.cn/CZlab/alarmnet/. The source code is open for modification and application to other miRNA/mRNA expression datasets.


CONTACT
zhangcg@bmi.ac.cn


SUPPLEMENTARY INFORMATION
Supplementary data are available at Bioinformatics online.",2011,Bioinformatics
Poverty Prediction by Selected Remote Sensing CNN Features Final Report,"Remote sensing images with the convolutional neural network (CNN) model are proved to be an alternative approach to night-lights in poverty prediction. However, CNN model creates a high dimensional dataset, which may cause overfitting, and limit its performance. In this paper, we select on remote sensing CNN features to improve its performance. We leverage five feature selection methods: forward search, correlation search, principle components analysis (PCA), variational autoencoder (VAE) and lasso. All these features are then evaluated via linear, ridge and lasso regression method as well as XGBoost gradient boosting methods. We obtain robust feature sets that outperform night-lights intensities in poverty prediction.",2017,
Robust estimation and variable selection in sufficient dimension reduction,"Dimension reduction and variable selection play important roles in high dimensional data analysis. Minimum Average Variance Estimation (MAVE) is an efficient approach among many others. However, because of the use of least squares criterion, MAVE is not robust to outliers in the dependent variable or errors with heavy tailed distributions. A robust extension of MAVE through modal regression is proposed. This new approach can adapt to different error distributions and thus brings robustness to the contamination in the response variable. The estimator is shown to have the same convergence rate as the original MAVE. Furthermore, the proposed method is combined with adaptive LASSO to select informative variables. The efficacy of this new solution is illustrated through simulation studies and a data analysis on Hong Kong air quality.",2017,Comput. Stat. Data Anal.
Regression methods for microarray data,"In the past decade, DNA and oligonucleotide microarray technology has been developed, allowing gene expression levels to be measured on a genome-wide scale. Use of this massive amount of molecular information appears to be promising for discovering genetic networks. Classification based on microarray experiments has been studied extensively. In comparison, microarray gene expression data has been analyzed less frequently in a regression set-up. From a statistical point of view, the challenge with analyzing microarray gene expression data is due to the very large number of genes, which far exceeds the sample size, i.e., the so-called â€œlarge p, small nâ€ scenario. The lasso (least absolute shrinkage and selection operator) method is a promising regression method that incorporates automatic variable selection by imposing an L1 penalty on the regression coefficients. However the lasso method has its limitations in the â€œlarge p, small nâ€ scenario. When p > n, the lasso method can select up to n variables before it saturates. And the lasso method does not offer a â€œgrouped selectionâ€ effect. Therefore we propose two new methods, based on lasso, that are particularly suitable for microarray data regression analysis. The methods can produce sparse, interpretable regression models that relate clusters of co-expressed genes to a quantitative phenotype. Our methods are tested on simulated data sets as well as real microarray data sets. 
Besides the proposal of novel regression methods, we also propose quantitative definitions for evaluating the strength of the â€œgrouped variableâ€ effect in fitted regression models. The new definitions allow us to compare regression models quantitatively. We then discuss a need for supervised clustering of genes, that is, the phenotype ought to have an influence on how genes are clustered. One potential approach is to re-define the distances between pairs of genes by incorporating the phenotype into the definition of the new distance metric.",2005,
Identifying Groups of Strongly Correlated Variables through Smoothed Ordered Weighted L1-norms,"The failure of LASSO to identify groups of correlated predictors in linear regression has sparked significant research interest. Recently, various norms [1, 2] were proposed, which can be best described as instances of ordered weighted l1 norms (OWL) [3], as an alternative to l1 regularization used in LASSO. OWL can identify groups of correlated variables but it forces the model to be constant within a group. This artifact induces unnecessary bias in the model estimation. In this paper we take a submodular perspective and show that OWL can be posed as the LovÃ¡sz extension of a suitably defined submodular function. The submodular perspective not only explains the groupwise constant behavior of OWL, but also suggests alternatives. The main contribution of this paper is smoothed OWL (SOWL), a new family of norms, which not only identifies the groups but also allows the model to be flexible inside a group. We establish several algorithmic and theoretical properties of SOWL including group identification and model consistency. We also provide algorithmic tools to compute the SOWL norm and its proximal operator, whose computational complexity O(d log d) is significantly better than that of general purpose solvers in O(d log d). In our experiments, SOWL compares favorably with respect to OWL in the regimes of interest. Proceedings of the 20 International Conference on Artificial Intelligence and Statistics (AISTATS) 2017, Fort Lauderdale, Florida, USA. JMLR: W&CP volume 54. Copyright 2017 by the author(s).",2017,
Statistical learning and selective inference.,"We describe the problem of ""selective inference."" This addresses the following challenge: Having mined a set of data to find potential associations, how do we properly assess the strength of these associations? The fact that we have ""cherry-picked""--searched for the strongest associations--means that we must set a higher bar for declaring significant the associations that we see. This challenge becomes more important in the era of big data and complex statistical modeling. The cherry tree (dataset) can be very large and the tools for cherry picking (statistical learning methods) are now very sophisticated. We describe some recent new developments in selective inference and illustrate their use in forward stepwise regression, the lasso, and principal components analysis.",2015,Proceedings of the National Academy of Sciences of the United States of America
Using random subspace method for prediction and variable importance assessment in linear regression,A random subset method (RSM) with a new weighting scheme is proposed and investigated for linear regression with a large number of features. Weights of variables are defined as averages of squared values of pertaining t-statistics over fitted models with randomly chosen features. It is argued that such weighting is advisable as it incorporates two factors: a measure of importance of the variable within the considered model and a measure of goodness-of-fit of the model itself. Asymptotic weights assigned by such a scheme are determined as well as assumptions under which the method leads to consistent choice of significant variables in the model. Numerical experiments indicate that the proposed method behaves promisingly when its prediction errors are compared with errors of penalty-based methods such as the lasso and it has much smaller false discovery rate than the other methods considered.,2014,Comput. Stat. Data Anal.
FRM Financial Risk Meter,"A systemic risk measure is proposed accounting for links and mutual dependencies between financial institutions utilising tail event information. FRM (Financial Risk Meter) is based on Lasso quantile regression designed to capture tail event co-movements. The FRM focus lies on understanding active set data characteristics and the presentation of interdependencies in a network topology. Two FRM indices are presented, namely, FRM@Americas and FRM@Europe. The FRM indices detect systemic risk at selected areas and identifies risk factors. In practice, FRM is applied to the return time series of selected financial institutions and macroeconomic risk factors. We identify companies exhibiting extreme ""co-stress"", as well as ""activators"" of stress. With the SRM@EuroArea, we extend to the government bond asset class, and to credit default swaps with FRM@iTraxx. FRM is a good predictor for recession probabilities, constituting the FRM-implied recession probabilities. Thereby, FRM indicates tail event behaviour in a network of financial risk factors.",2019,
Radiomics Analysis of Dynamic Contrast-Enhanced Magnetic Resonance Imaging for the Prediction of Sentinel Lymph Node Metastasis in Breast Cancer,"Purpose: To investigate whether a combination of radiomics and automatic machine learning applied to dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) of primary breast cancer can non-invasively predict axillary sentinel lymph node (SLN) metastasis. Methods: 62 patients who received a DCE-MRI breast scan were enrolled. Tumor resection and sentinel lymph node (SLN) biopsy were performed within 1 week after the DCE-MRI examination. According to the time signal intensity curve, the volumes of interest (VOIs) were delineated on the whole tumor in the images with the strongest enhanced phase. Datasets were randomly divided into two sets including a training set (~80%) and a validation set (~20%). A total of 1,409 quantitative imaging features were extracted from each VOI. The select K best and least absolute shrinkage and selection operator (Lasso) were used to obtain the optimal features. Three classification models based on the logistic regression (LR), XGboost, and support vector machine (SVM) classifiers were constructed. Receiver Operating Curve (ROC) analysis was used to analyze the prediction performance of the models. Both feature selection and models construction were firstly performed in the training set, then were further tested in the validation set by the same thresholds. Results: There is no significant difference between all clinical and pathological variables in breast cancer patients with and without SLN metastasis (P > 0.05), except histological grade (P = 0.03). Six features were obtained as optimal features for models construction. In the validation set, with respect to the accuracy and MSE, the SVM demonstrated the highest performance, with an accuracy, AUC, sensitivity (for positive SLN), specificity (for positive SLN) and Mean Squared Error (MSE) of 0.85, 0.83, 0.71, 1, 0.26, respectively. Conclusions: We demonstrated the feasibility of combining artificial intelligence and radiomics from DCE-MRI of primary tumors to predict axillary SLN metastasis in breast cancer. This non-invasive approach could be very promising in application.",2019,Frontiers in Oncology
Nonidentical twins: Comparison of frequentist and Bayesian lasso for Cox models.,"One important task in translational cancer research is the search for new prognostic biomarkers to improve survival prognosis for patients. The use of high-throughput technologies allows simultaneous measurement of genome-wide gene expression or other genomic data for all patients in a clinical trial. Penalized likelihood methods such as lasso regression can be applied to such high-dimensional data, where the number of (genomic) covariables is usually much larger than the sample size. There is a connection between the lasso and the Bayesian regression model with independent Laplace priors on the regression parameters, and understanding this connection has been useful for understanding the properties of lasso estimates in linear models (e.g. Park and Casella, 2008). In this paper, we study the lasso in the frequentist and Bayesian frameworks in the context of Cox models. For the Bayesian lasso we extend the approach by Lee et al. (2011). In particular, we impose the lasso penalty only on the genome features, but not on relevant clinical covariates, to allow the mandatory inclusion of important established factors. We investigate the models in high- and low-dimensional simulation settings and in an application to chronic lymphocytic leukemia.",2015,Biometrical journal. Biometrische Zeitschrift
Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø¹Ø¶ Ø·Ø±Ø§Ø¦Ù‚ ØªÙ‚Ø¯ÙŠØ± Ù³Ù†Ù…ÙˆØ°Ø¬ Scheff'e Ø§Ù„Ø®Ù„ÙŠØ·,"Ù†Ø¸Ø±Ø§ Ù„Ù…Ø§ ØªØ¹Ø§Ù†ÙŠÙ€Ù‡ ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø®Ù„ÙŠØ· Ù…Ù† Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø§Ø±ØªØ¨Ù€Ø§Ø·Ø§Øª Ø§Ù„Ø¹Ø§Ù„ÙŠØ© ÙˆÙˆØ¬ÙˆØ¯ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªØ¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© ÙˆØ°Ù„Ùƒ Ù„ÙˆØ¬ÙˆØ¯ Ù‚ÙŠØ¯ Ø§Ù„ÙˆØ­Ø¯Ø© ÙˆØ§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø¨ÙŠÙ†Ù‡Ø§ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù…Ø§ ÙŠØ²ÙŠØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù†ÙˆØ¶ÙŠØ­ÙŠØ© ÙˆÙ‡Ø°Ø§ Ù…Ø§ ÙŠÙˆØ¶Ø­Ù‡ Ø¹Ø§Ù…Ù„ ØªØ¶Ø®Ù… Ø§Ù„ØªØ¨Ø§ÙŠÙ† Variance Inflation Vector (VIF) , ÙƒØ°Ù„Ùƒ ØªÙ… Ø§Ù„ØªØ·Ù€Ø±Ù‚ Ø§Ù„Ù‰ Ø§Ø³ØªØ®Ù€Ø¯Ø§Ù… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø²Ø§Ø¦ÙØ© Ù„Ù„Ø­Ù€Ø¯ÙˆØ¯ Ø§Ù„Ø¯Ù†ÙŠØ§ (L-Pseudo component) Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø¨ÙŠÙ† Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø®Ù„ÙŠØ· . 
Â Â  Ù„ØªÙ‚Ø¯ÙŠØ± Ù…Ø¹Ø§Ù„Ù… Ù³Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø®Ù„ÙŠØ· Ø§Ø¹ØªÙ…Ø¯Ù†Ø§ ÙÙŠ Ø¨Ø­Ø«Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±Ø§Ø¦Ù‚ ØªÙ‚Ø¯ÙŠØ± ØªØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ­ÙŠØ² ÙˆØªÙ‚Ù„Ù„ Ù…Ù† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ù…Ù†Ù‡Ø§ Ø·Ø±ÙŠÙ‚Ø© Ù³Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø­Ø±Ù Ridge Regression Method ÙˆØ·Ø±ÙŠÙ‚Ø© ØªÙ‚Ø¯ÙŠØ± (Least Absolute Shrinkage and Selection Operator) (LASSO) ÙØ¶Ù„Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚Ø© ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ù…Ø±Ù†Ø© Elastic Net , ÙˆØªÙ…Ø«ÙŠÙ„Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø¨Ù„ØºØ© R Ø¨Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…ØªÙˆØ³Ø· Ù…Ø·Ù„Ù‚ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù†Ø³Ø¨ÙŠ Mean Absolute Percentage Error (MAPE).",2019,
An extended variable inclusion and shrinkage algorithm for correlated variables,"The problem of variable selection for linear regression in a high dimension model is considered. A new method, called Extended-VISA (Ext-VISA), is proposed to simultaneously select variables and encourage a grouping effect where strongly correlated predictors tend to be in or out of the model together. Moreover, Ext-VISA is capable of selecting a sparse model while avoiding the overshrinkage of a Lasso-type estimator. It combines the idea of the VISA algorithm which avoids the overshrinkage problem of regression coefficients and those of the Lasso-type estimators, based on ? 1 + ? 2 penalty, that overcome the limitation of the grouping effect of Lasso in high dimension. It is based on a modified VISA algorithm, so it is also computationally efficient. Three interesting cases of Ext-VISA are examined. The first case is Smooth-VISA (SVISA), where the variations among successive regression coefficients are low. The second case is VISA-Net (VNET), where the correlations between predictors are taken into account. The third case is Laplacian-VISA (LVISA), where the predictors are measured on an undirected graph. A theoretical property on sparsity inequality of Ext-VISA is established. A detailed simulation study in small and high dimensional settings is performed, which illustrates the advantages of the new approach in relation to several other possible methods. Finally, we apply VNET, SVISA and LVISA to a GC-retention data set.",2013,Comput. Stat. Data Anal.
Classification of Defoliated Trees Using Tree-Level Airborne Laser Scanning Data Combined with Aerial Images,"Climate change and rising temperatures have been observed to be related to the increase of forest insect damage in the boreal zone. The common pine sawfly (Diprion pini L.) (Hymenoptera, Diprionidae) is regarded as a significant threat to boreal pine forests. Defoliation by D. pini can cause severe growth loss and tree mortality in Scots pine (Pinus sylvestris L.) (Pinaceae). In this study, logistic LASSO regression, Random Forest (RF) and Most Similar Neighbor method (MSN) were investigated for predicting the defoliation level of individual Scots pines using the features derived from airborne laser scanning (ALS) data and aerial images. Classification accuracies from 83.7% (kappa 0.67) to 88.1% (kappa 0.76) were obtained depending on the method. The most accurate result was produced using RF with a combination of data from the two sensors, while the accuracies when using ALS and image features separately were 80.7% and 87.4%, respectively. Evidently, the combination of ALS and aerial images in detecting needle losses is capable of providing satisfactory estimates for individual trees.",2010,Remote Sensing
Implementing machine learning in bipolar diagnosis in China,"Bipolar disorder (BPD) is often confused with major depression, and current diagnostic questionnaires are subjective and time intensive. The aim of this study was to develop a new Bipolar Diagnosis Checklist in Chinese (BDCC) by using machine learning to shorten the Affective Disorder Evaluation scale (ADE) based on an analysis of registered Chinese multisite cohort data. In order to evaluate the importance of each item of the ADE, a case-control study of 360 bipolar disorder (BPD) patients, 255 major depressive disorder (MDD) patients and 228 healthy (no psychiatric diagnosis) controls (HCs) was conducted, spanning 9 Chinese health facilities participating in the Comprehensive Assessment and Follow-up Descriptive Study on Bipolar Disorder (CAFÃ‰-BD). The BDCC was formed by selected items from the ADE according to their importance as calculated by a random forest machine learning algorithm. Five classical machine learning algorithms, namely, a random forest algorithm, support vector regression (SVR), the least absolute shrinkage and selection operator (LASSO), linear discriminant analysis (LDA) and logistic regression, were used to retrospectively analyze the aforementioned cohort data to shorten the ADE. Regarding the area under the receiver operating characteristic (ROC) curve (AUC), the BDCC had high AUCs of 0.948, 0.921, and 0.923 for the diagnosis of MDD, BPD, and HC, respectively, despite containing only 15% (17/113) of the items from the ADE. Traditional scales can be shortened using machine learning analysis. By shortening the ADE using a random forest algorithm, we generated the BDCC, which can be more easily applied in clinical practice to effectively enhance both BPD and MDD diagnosis.",2019,Translational Psychiatry
Recurrent neural networks for real-time prediction of TBM operating parameters,"Abstract With tunnel boring machines (TBMs) widely used in tunnel construction, the adaptable adjustment of TBM operating status has become a research focus. Since the prediction of tunnel geological conditions is still challenging before excavation, the prediction of important TBM operating parameters plays an important role in the research on TBM adaptable adjustment. In this paper, we use three kinds of recurrent neural networks (RNNs), including traditional RNNs, long-short term memory (LSTM) networks and gated recurrent unit (GRU) networks, to deal with the real-time prediction of TBM operating parameters based on TBM in-situ operating data. The experimental results show that the proposed three kinds of RNN-based predictors can provide accurate prediction values of some important TBM operating parameters during next period including the torque, the velocity, the thrust and the chamber pressure. We also make a comparison with several classical regression models (e.g., support vector regression (SVR), random forest (RF) and Lasso) which actually cannot act as real-time predictors in a real sense, and the comparative experiments show that the proposed RNN-based predictors outperform the regression models in most cases. The feasibility of RNNs for the real-time prediction of TBM operating parameters indicates that RNNs can afford the analysis and the forecasting of the time-continuous in-situ data collected from various construction equipments.",2019,Automation in Construction
Network constrained covariate coefficient and connection sign estimation,"Often, variables are linked to each other via a network. When such a network structure is known, this knowledge can be incorporated into regularized regression settings. In particular, an additional network penalty can be added on top of another penalty term, such as a Lasso penalty. However, when the type of interaction via the network is unknown (that is, whether connections are of an activating or a repressing type), the connection signs have to be estimated simultaneously with the covariate coefficients. This can be done with an algorithm iterating a connection sign estimation step and a covariate coefficient estimation step. We show detailed simulation results of such an algorithm. The algorithm performs well in a variety of settings. We also briefly describe the R-package that we developed for this purpose, which is publicly available.",2018,
Development and validation of a novel predictive score for sepsis risk among trauma patients,"BackgroundPatients suffering from major trauma often experience complications such as sepsis. The early recognition of patients at high risk of sepsis after trauma is critical for precision therapy. We aimed to derive and validate a novel predictive score for sepsis risk using electronic medical record (EMR) data following trauma.Materials and methodsClinical and laboratory variables of 684 trauma patients within 24â€‰h after admission were collected, including 411 patients in the training cohort and 273 in the validation cohort. The least absolute shrinkage and selection operator (LASSO) technique was adopted to identify variables contributing to the early prediction of traumatic sepsis. Then, we constructed a traumatic sepsis score (TSS) using a logistic regression model based on the variables selected in the LASSO analysis. Moreover, we evaluated the discrimination and calibration of the TSS using the area under the curve (AUC) and the Hosmer-Lemeshow (H-L) goodness-of-fit test.ResultsBased on the LASSO, seven variables (injury severity score, Glasgow Coma Scale, temperature, heart rate, albumin, international normalized ratio, and C-reaction protein) were selected for construction of the TSS. Our results indicated that the incidence of sepsis after trauma increased with an increasing TSS (Ptrendâ€‰=â€‰7.44â€‰Ã—â€‰10âˆ’21 for the training cohort and Ptrendâ€‰=â€‰1.16â€‰Ã—â€‰10âˆ’13 for the validation cohort). The areas under the receiver operating characteristic (ROC) curve of TSS were 0.799 (0.757â€“0.837) and 0.790 (0.736â€“0.836) for the training and validation datasets, respectively. The discriminatory power of our model was superior to that of a single variable and the sequential organ failure assessment (SOFA) score (Pâ€‰<â€‰0.001). Moreover, the TSS was well calibrated (Pâ€‰>â€‰0.05).ConclusionsWe developed and validated a novel TSS with good discriminatory power and calibration for the prediction of sepsis risk in trauma patients based on the EMR data.",2019,World Journal of Emergency Surgery : WJES
Assessment and relevance of the putative DNA/RNA helicase Schlafen-11 in ovarian and breast cancer,"Schlafen 11 (SLFN11) is a putative DNA/RNA helicase, first described for its role in thymocyte development and differentiation in mouse models. SLFN11 is part of a family of proteins with various degree of homology across species, but intriguingly being consistently present only in vertebrates and especially in mammals. Recently, the role of this putative DNA/RNA helicase, SLFN11, was causally associated with sensitivity to DNA damaging agents, such as platinum salts, topoisomerase I and II inhibitors, and other alkylators in the NCI-60 panel of cancer cell lines. In the first study, we validate an anti-SLFN11 antibody in formalin-fixed paraffin-embedded (FFPE) high-grade serous ovarian carcinoma (HGSOC) samples, developing an immunohistochemistry (IHC) protocol in order to determinate the expression of SLFN11 in our series of HGSOC. Indeed, we tested and validated a reliable SLFN 11 antibody (Ab) in IHC choosing between two anti-SLFN11 Ab used normally for Western Blot (WB) in culture cell block (CCB) of ovarian carcinoma and in an independent series of HGSOCs tissue micro-array (TMA). For each case, we evaluated both the Intensity Score (IS) and the Distribution Score (DS) evaluating at least 300 cells. A Histological Score (HS)was obtained as follow: HS=IS x DS. Successively, we applied our protocol to a large case series of HGSOC samples to confirm our preliminary results. We found one antibody to be reliable in CCB and TMA series allowing to determinate clearly IHC expression of SLFN11. These results were confirmed in our large case series of FFPE HGSOC samples. Briefly, as for TMA independent series, we found that the HS for SLFN11 expression presents a normal distribution with a prevalent (â‰ˆ 60%) intermediate expression. Parallel SLFN11 was not expressed in practically 40% of cases that clinically corresponded to the platinum resistant patients in about 60% of cases (16/27). So, we believe that low IHC expression of SLFN 11 should be correlated to response to the platinum-based chemotherapy. In the second study, we investigate the transcriptional landscape of SLFN11 in breast cancer performing a gene expression microarray meta-analysis of more than 7000 cases from 35 publicly available data sets. By correlation analysis, we identified 537 transcripts in the top 95th percentile of Pearsonâ€™s coefficients with SLFN11 identifying â€œimmune responseâ€, â€œlymphocyte activationâ€ and â€œT cell activationâ€ as top Gene Ontology enriched processes. Furthermore, we reported very strong association of SLFN11 with immune signatures in breast cancer through penalized maximum likelihood lasso regression. Finally, through multiple corresponded analysis we discovered a subgroup of patients, defined â€œSLF11-hot clusterâ€, characterized by high SLFN11 levels, estrogen receptor(ER) negativity, basal-like phenotype, elevated CD3D, STAT1 signature, and young age. Using Cox proportional hazard regression, we characterized that SLFN11 high levels, high proliferation index, and ER negativity are independent parameters for longer disease-free interval in patients undergoing chemotherapy. We believe that our second work supports proof of concept that: i) A clear and specific role for SLFN11 in breast cancer, in likely connection with the immune system modulation in such disease entity, ii) a strong correlation between high SFLN 11 and specific molecular subtype of breast cancer (estrogen receptor negativity, basal-like phenotype). Further studies will be performed to confirm our hypothesis in order to: 1) better understand the function of SLFN 11 in cancer cell, 2) validate an easy, reliable and standardized IHC protocol to assessment SLFN11, 3) use SFLN11expression as a predictive biomarker of response to DDA and PARP inhibitors and 4) determinate the relationship with immune system",2019,
Effects of Multicollinearity in All Possible Mixed Model Selection,"The effects of multicollinearity in all possible model selection of fixed effects including quadratic and cross products in the presence of random and repeated measures effects are presented here. The user-friendly SAS macro application ALLMIXED2 complements the model selection option currently available in the SAS macro applications â€˜REGDIAGâ€™ and â€˜LOGISTICâ€™ for multiple linear and logistic regressions respectively. Options are also available in this macro to select the best covariance structure associated with the user-specified fully saturated repeated measures model; to graphically explore and to detect statistical significance of user specified linear, quadratic, interaction terms for fixed effects; and to diagnose multicollinearity, via the VIF statistic for each continuous predictors involved in each model selection step. The effects multicollinarity and sample size in pre-screening the variables in GLMSELECT using the LASSO selection method and in all possible subset selection within user-specified subset range are investigated using simulated repeated measures data with time independent auto-correlated error structure. A combination of two sample sizes (25 and 100 subjects) and two levels of mulicollinarity ( r < 0.2 and r > 0.8) among selected covariates were used in simulating 4 repeated measures data sets. Two model selection criteria, AICC (corrected Akaike Information Criterion) and MDL (minimal description length) were used in all possible model selection and summaries of the best model selection are compared graphically. The outcome of the model selection based on information criteria (AICC or MDL) was not influenced by the degree of multicollinarity. However, the sample size had a major impact on the accuracy of best candidate model selection. Instructions for downloading and running this user-friendly macro application, ALLMIXED2 are included.",2007,
"A Comparative Investigation of the Combined Effects of Pre-Processing, Wavelength Selection, and Regression Methods on Near-Infrared Calibration Model Performance","Near-infrared (NIR) spectroscopy is being widely used in various fields ranging from pharmaceutics to the food industry for analyzing chemical and physical properties of the substances concerned. Its advantages over other analytical techniques include available physical interpretation of spectral data, nondestructive nature and high speed of measurements, and little or no need for sample preparation. The successful application of NIR spectroscopy relies on three main aspects: pre-processing of spectral data to eliminate nonlinear variations due to temperature, light scattering effects and many others, selection of those wavelengths that contribute useful information, and identification of suitable calibration models using linear/nonlinear regression . Several methods have been developed for each of these three aspects and many comparative studies of different methods exist for an individual aspect or some combinations. However, there is still a lack of comparative studies for the interactions among these three aspects, which can shed light on what role each aspect plays in the calibration and how to combine various methods of each aspect together to obtain the best calibration model. This paper aims to provide such a comparative study based on four benchmark data sets using three typical pre-processing methods, namely, orthogonal signal correction (OSC), extended multiplicative signal correction (EMSC) and optical path-length estimation and correction (OPLEC); two existing wavelength selection methods, namely, stepwise forward selection (SFS) and genetic algorithm optimization combined with partial least squares regression for spectral data (GAPLSSP); four popular regression methods, namely, partial least squares (PLS), least absolute shrinkage and selection operator (LASSO), least squares support vector machine (LS-SVM), and Gaussian process regression (GPR). The comparative study indicates that, in general, pre-processing of spectral data can play a significant role in the calibration while wavelength selection plays a marginal role and the combination of certain pre-processing, wavelength selection, and nonlinear regression methods can achieve superior performance over traditional linear regression-based calibration.",2017,Applied Spectroscopy
A globally convergent algorithm for lasso-penalized mixture of linear regression models,"Variable selection is an old and pervasive problem in regression analysis. One solution is to impose a lasso penalty to shrink parameter estimates toward zero and perform continuous model selection. The lasso-penalized mixture of linear regressions model (L-MLR) is a class of regularization methods for the model selection problem in the fixed number of variables setting. A new algorithm is proposed for the maximum penalized-likelihood estimation of the L-MLR model. This algorithm is constructed via the minorizationâ€“maximization algorithm paradigm. Such a construction allows for coordinate-wise updates of the parameter components, and produces globally convergent sequences of estimates that generate monotonic sequences of penalized log-likelihood values. These three features are missing in the previously presented approximate expectationâ€“maximization algorithms. The previous difficulty in producing a globally convergent algorithm for the maximum penalized-likelihood estimation of the L-MLR model is due to the intractability of finding exact updates for the mixture model mixing proportions in the maximization-step. This issue is resolved by showing that it can be converted into a simple numerical root finding problem that is proven to have a unique solution. The method is tested in simulation and with an application to Major League Baseball salary data from the 1990s and the present day, where the concept of whether player salaries are associated with batting performance is investigated.",2018,Comput. Stat. Data Anal.
