title,abstract,year,journal
Supervised Learning for Dynamical System Learning,"Recently there has been substantial interest in spectral methods for learning dynamical systems. These methods are popular since they often offer a good tradeoff between computational and statistical efficiency. Unfortunately, they can be difficult to use and extend in practice: e.g., they can make it difficult to incorporate prior information such as sparsity or structure. To address this problem, we present a new view of dynamical system learning: we show how to learn dynamical systems by solving a sequence of ordinary supervised learning problems, thereby allowing users to incorporate prior knowledge via standard techniques such as L1 regularization. Many existing spectral methods are special cases of this new framework, using linear regression as the supervised learner. We demonstrate the effectiveness of our framework by showing examples where nonlinear regression or lasso let us learn better state representations than plain linear regression does; the correctness of these instances follows directly from our general analysis.",2015,Advances in neural information processing systems
Optimal Two-Step Prediction in Regression,"High-dimensional prediction typically comprises variable selection followed by least-squares refitting on the selected variables. However, the standard variable selection procedures, such as the lasso and thresholded ridge regression, hinge on tuning parameters that need to be calibrated. Cross-validation, the most popular calibration scheme, is computationally costly and does not provide theoretical guarantees for high-dimensional prediction. In this paper, we introduce an alternative scheme that is computationally more efficient than cross-validation and, in addition, provides optimal finite sample guarantees. While our scheme allows for a range of variable selection procedures, we provide explicit numerical and theoretical results for least-squares refitting on variables selected by the lasso and by thresholded ridge regression. These results demonstrate that our calibration scheme can outperform cross-validation in terms of speed, accuracy, and theoretical guarantees.",2014,arXiv: Methodology
EM-type algorithms for non-convex and high-dimensional problems,"Todayâ€™s trend is to analyse high-dimensional datasets through convex optimization. A famous example is the Lasso for estimation and variable selection in the high-dimensional regression model. Another currently very popular example is the so-called matrix completion problem, where the goal is to recover missing entries in large low-rank matrices by solving a simple convex optimization program. The main advantages of convex problems are that they can be numerically solved very efficiently and that they have a unique solution which can be mathematically analysed using powerful tools from convex analysis. Despite the advantages of convex optimization problems, we believe that convex functions are often too limited to take into account the complex structure present in real data applications. In this thesis, we therefore move on and use more advanced and flexible modelling techniques to describe high-dimensional data. The resulting optimization problems are very challenging, far from being convex and may have several optimal solutions. However, we demonstrate that in a sparse context, where only a small number of the model parameters are nonzero, it is possible to solve such problems very efficiently. Furthermore, we will also show on real datasets that there is a considerable gain in terms of statistical performance over convex methods. In a first project, Chapter 2 in this thesis, we extend estimation and variable selection in a high-dimensional setup to a finite mixture of regressions (FMR) model, which can deal with a heterogeneous population consisting of different unknown subgroups. We propose a penalized maximum likelihood estimator using a novel parameterization, analyse its asymptotic properties and derive oracle inequalities. From a compu-",2010,
Prediction-Oriented Marker Selection (PROMISE): With Application to High-Dimensional Regression,"In personalized medicine, biomarkers are used to select therapies with the highest likelihood of success based on an individual patientâ€™s biomarker/genomic profile. Two goals are to choose important biomarkers that accurately predict treatment outcomes and to cull unimportant biomarkers to reduce the cost of biological and clinical verifications. These goals are challenging due to the high dimensionality of genomic data. Variable selection methods based on penalized regression (e.g., the lasso and elastic net) have yielded promising results. However, selecting the right amount of penalization is critical to simultaneously achieving these two goals. Standard approaches based on cross-validation (CV) typically provide high prediction accuracy with high true positive rates (TPRs) but at the cost of too many false positives. Alternatively, stability selection (SS) controls the number of false positives, but at the cost of yielding too few true positives. To circumvent these issues, we propose prediction-oriented marker selection (PROMISE), which combines SS with CV to conflate the advantages of both methods. Our application of PROMISE with the lasso and elastic net in data analysis shows that, compared to CV, PROMISE produces sparse solutions, few false positives, and small type IÂ +Â type II error, and maintains good prediction accuracy, with a marginal decrease in the TPRs. Compared to SS, PROMISE offers better prediction accuracy and TPRs. In summary, PROMISE can be applied in many fields to select regularization parameters when the goals are to minimize false positives and maximize prediction accuracy.",2017,Statistics in Biosciences
Ridge and Lasso Regression Models for Cross-Version Defect Prediction,"Sorting software modules in order of defect count can help testers to focus on software modules with more defects. One of the most popular methods for sorting modules is generalized linear regression. However, our previous study showed the poor performance of these regression models, which might be caused by severe multicollinearity. Ridge regression (RR) can improve the prediction performance for multicollinearity problems. Lasso regression (LAR) is a worthy competitor to RR. Therefore, we investigate both RR and LAR models for cross-version defect prediction. Cross-version defect prediction is an approximate to real applications. It constructs prediction models from a previous version of projects and predicts defects in the next version. Experimental results based on 11 projects from the PROMISE repository consisting of 41 different versions show that: 1) there exist severe multicollinearity problems in the experimental datasets; 2) both RR and LAR models perform better than linear regression and negative binomial regression for cross-version defect prediction; and 3) compared with two best methods in our previous study for sorting software modules according to the predicted number of defects, RR has comparable performance and less model construction time.",2018,IEEE Transactions on Reliability
PO-073 Small non-coding RNA in serum from testicular germ cell tumour patientsidentified by machine learning,"Introduction Testicular germ cell tumour (TGCT) is a malignancy present in males with the highest incidence rates in younger age ranges. The aetiology is still largely unknown; however, several genome-wide association studies have identified up to 30 independent loci influencing TGCT risk, confirming its inherited genetic susceptibility. Machine learning can be utilised as a modelling technique to identify patterns within genetic and lifestyle data that allows classification and identification of biomarkers. We aim to identify potential biomarkers and perform accurate classifications in the small non-coding RNAs (sncRNAs) of 147 pre-diagnostic serum samples. Material and methods The serum samples were obtained from the Janus Serum Bank, with life-style covariates, such as smoking habits, BMI and exercise habits also recorded for each sample. A total of 69 TGCT samples and 78 control sample sncRNA reads were used to train machine learning algorithms including linear regression, LASSO, decision trees and neural networks. These cases and controls are matched by age at blood sampling. Results and discussions Preliminary results from LASSO and decision tree methods show differentiation in the miRNA/piRNA patterns between the control and the TGCT samples after adjusting individual read counts for age at sampling. Classification performance was better when trained using piRNAs, 58% of control samples were classified as normal and 60% of TGCT cases being classified as TGCT patients. Further inclusion of life-style covariates in the model as well as age and time of diagnosis is still to be performed to increase classification performance further. By using interpretable machine learning methods, we aim to identify biomarkers that allow the accurate classification of the samples. Conclusion These results show that the piRNA composition seen in pre-diagnostic serum samples may contain potential biomarkers that can lead to accurate classification of whether a patient was at increased risk of testicular cancer before the initial diagnosis. Preliminary results should be further expanded with different sncRNA datasets and lifestyle covariates.",2018,
MPGL: An Efficient Matching Pursuit Method for Generalized LASSO,"Unlike traditional LASSO enforcing sparsity on the variables, Generalized LASSO (GL) enforces sparsity on a linear transformation of the variables, gaining flexibility and success in many applications. However, many existing GL algorithms do not scale up to high-dimensional problems, and/or only work well for a specific choice of the transformation. We propose an efficient Matching Pursuit Generalized LASSO (MPGL) method, which overcomes these issues, and is guaranteed to converge to a global optimum. We formulate the GL problem as a convex quadratic constrained linear programming (QCLP) problem and tailor-make a cutting plane method. More specifically, our MPGL iteratively activates a subset of nonzero elements of the transformed variables, and solves a subproblem involving only the activated elements thus gaining significant speed-up. Moreover, MPGL is less sensitive to the choice of the trade-off hyper-parameter between data fitting and regularization, and mitigates the longstanding hyper-parameter tuning issue in many existing methods. Experiments demonstrate the superior efficiency and accuracy of the proposed method over the state-of-the-arts in both classification and image processing tasks. Introduction Learning with sparsity-inducing norms has gained much success in many applications including medical data analysis (Tibshirani and Wang 2008), image processing (Rudin, Osher, and Fatemi 1992), feature selection (Tan, Tsang, and Wang 2014) and so on. One efficient way to enforce sparsity on the variables is to use the `1-norm as LASSO (Tibshirani 1996) instead of the `0-norm. Since then, many methods have been proposed to enforce some additional constraints (Huang, Zhang, and Metaxas 2011; Kim and Xing 2010; Tibshirani et al. 2011) to improve the results. A group of methods among them is called generalized LASSO (Tibshirani et al. 2011), which promotes the sparsity of the variables after a linear transformation (Liu, Yuan, and Ye 2013) instead of the variables themselves. The choice of such a transformation represents the property of the variables to be desired, and often depends on the application. Generalized LASSO. Let x âˆˆ R denote the target variable and D âˆˆ RlÃ—n be a linear transformation operator. A natural The first two authors contributed equally. Copyright c Â© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. way to seek x with sparsity on Dx is as follows (Liu, Yuan, and Ye 2013), min x f(x) + Î»â€–Dxâ€–0, (1) where f : R â†’ R is a loss function (sometimes known as data fitting term) depending on the application, â€–Â·â€–0 denotes the `0-norm regularizer, and Î» â‰¥ 0 is known as the trade-off hyper-parameter between the data fitting and the regularization. By letting A âˆˆ RmÃ—n be a designing matrix, y âˆˆ R be a response vector, n âˆˆ R be a vector of Gaussian noise, and assuming a linear regression model y = Ax + n, a typical choice of f is f(x) = 1 2â€–y âˆ’Axâ€– 2 2, which will be used throughout the rest of the paper. Since problem (1) is NP-hard, a convex relaxation is widely used:",2017,
Breast Cancer Progression Modeling Using Static Sample Data ( Supplementary Data ),"Mathematically, a cancer progression trajectory can be viewed as a complex manifold with a branching structure embedded in a high-dimensional genomic space. Since only a small fraction of genes may involve in tumor growth and spread, the first step is to identify cancer progression related genes supporting a complex manifold. This problem has been extensively studied in both the statistics and oncology communities in different contexts. One of the most commonly used approaches is correlation analysis. A gene with its expression levels highly correlated with patient survival time is likely to play a role in cancer development. However, correlation analysis can only find genes with linear dependency with survival time. Moreover, by analyzing one gene at a time, correlation analysis ignores possible interactions among genes. In molecular classification, a commonly used approach is to first partition patients into a bad or good prognostic group at a predefined end point (usually 5-years survival or time to metastasis) and then perform feature selection for classification analysis [1]. A major drawback of this approach is that patients with survival time slightly larger or smaller than the end point will be put into two different groups. In order to explore the magnitude information of response variables, we propose to address the problem of selecting cancer progression related genes within the regression framework. The idea is not new, and has been widely used in the statistics and oncology community. There are a number of excellent algorithms exemplified by Lasso [2] and its variants [3, 4] that operate under a linear-model assumption. However, the dependency between gene expression changes and disease progression is unlikely to be linear. Recent results have shown that cancer progression processes can be complicated and can be represented by a phylogenetic tree-like structure [5]. We develop a new feature-selection algorithm for nonlinear regression. The basic idea is to decompose a nonlinear regression problem into a set of linear classification problems and learn the feature relevance within a large-margin framework. It is built logically based on our previous work on feature selection for high-dimensional classification problems [6]. We first develop a new approach to estimating sample responses and prediction errors. We then use a feature weighting strategy to find a feature subspace where an error function is minimized. We formulate it as an optimization problem with a well-defined objective function within the SVM framework, and solve it using an iterative approach. In",2014,
"Genomic prediction and GWAS of yield, quality and disease-related traits in spring barley and winter wheat","Genome-wide association study (GWAS) and genomic prediction (GP) are extensively employed to accelerate genetic gain and identify QTL in plant breeding. In this study, 1,317 spring barley and 1,325 winter wheat breeding lines from a commercial breeding program were genotyped with the Illumina 9â€‰K barley or 15â€‰K wheat SNP-chip, and phenotyped in multiple years and locations. For GWAS, in spring barley, a QTL on chr. 4H associated with powdery mildew and ramularia resistance were found. There were several SNPs on chr. 4H showing genome-wide significance with yield traits. In winter wheat, GWAS identified two SNPs on chr. 6A, and one SNP on chr. 1B, significantly associated with quality trait moisture, as well as one SNP located on chr. 5B associated with starch content in the seeds. The significant SNPs identified by multiple trait GWAS were generally the same as those found in single trait GWAS. GWAS including genotype-location information in the model identified significant SNPs in each tested location, which were not found previously when including all locations in the GWAS. For GP, in spring barley, GP using the Bayesian Power Lasso model had higher accuracy than ridge regression BLUP in powdery mildew and yield traits, whereas the prediction accuracies were similar using Bayesian Power Lasso model and rrBLUP for yield traits in winter wheat.",2020,Scientific Reports
Post-selection inference for l 1-penalized likelihood models Presenter :,"According to the article[2], we present a new method for post-selection inference for l1(lasso)penalized likelihood models, including generalized regression models. Our approach generalizes the post-selection framework presented in Lee et al. (2013)[1]. The method provides P-values and confidence intervals that are asymptotically valid, conditional on the inherent selection done by the lasso. We present applications of this work to (regularized) logistic regression, Coxâ€™s proportional hazards model, and the graphical lasso. We do not provide rigorous proofs here of the claimed results, but rather conceptual and theoretical sketches.",2017,
Is Feature Selection Secure against Training Data Poisoning?,"Learning in adversarial settings is becoming an important task for application domains where attackers may inject malicious data into the training set to subvert normal operation of data-driven technologies. Feature selection has been widely used in machine learning for security applications to improve generalization and computational efficiency, although it is not clear whether its use may be beneficial or even counterproductive when training data are poisoned by intelligent attackers. In this work, we shed light on this issue by providing a framework to investigate the robustness of popular feature selection methods, including LASSO, ridge regression and the elastic net. Our results on malware detection show that feature selection methods can be significantly compromised under attack (we can reduce LASSO to almost random choices of feature sets by careful insertion of less than 5% poisoned training samples), highlighting the need for specific countermeasures.",2015,
Safe Feature Elimination for the LASSO and Sparse Supervised Learning Problems,"We describe a fast method to eliminate features (variables) in l1 -penalized least-square regression (or LASSO) problems. The elimination of features leads to a potentially substantial reduction in running time, specially for large values of the penalty parameter. Our method is not heuristic: it only eliminates features that are guaranteed to be absent after solving the LASSO problem. The feature elimination step is easy to parallelize and can test each feature for elimination independently. Moreover, the computational effort of our method is negligible compared to that of solving the LASSO problem - roughly it is the same as single gradient step. Our method extends the scope of existing LASSO algorithms to treat larger data sets, previously out of their reach. We show how our method can be extended to general l1 -penalized convex problems and present preliminary results for the Sparse Support Vector Machine and Logistic Regression problems.",2010,arXiv: Learning
Can user and task characteristics be used as predictors of success in health information retrieval sessions?,"Introduction. The concept and study of relevance has been a central subject in information science. Although research in information retrieval has been focused on topical relevance, other kinds of relevance are also important and justify further study. Motivational relevance is typically inferred by criteria such as user satisfaction and success. Method. Using an existing dataset composed by an annotated set of health Web documents assessed for relevance and comprehension by a group of users, we build a multivariate prediction model for the motivational relevance of search sessions. Analysis. The analysis was based on lasso variable selection, followed by model selection using multiple logistic regression. Results. We have built two regression models; the full model, which considers all variables of the dataset, has a lower estimated prediction error than the reduced model, which contains the statistically-significant variables from the full model. The higher values of evaluation metrics, including accuracy, specificity and sensitivity in the full model support this finding. The full model has an accuracy of 91.94%, and is better at predicting motivational relevance. Conclusions. Our findings suggest features that can be considered by search engines to estimate motivational relevance, to be used in addition to topical relevance. Among these features, a high level of success in Web search and in health information search on social networks and chats are some of the most influencing user features. This shows that users with higher computer literacy might feel more satisfied and successful after completing the search tasks. In terms of task features, the results suggest that users with clearer goals feel more successful. Moreover, results show that users would benefit from the help of the system in clarifying the retrieved documents.",2018,Inf. Res.
Efficient Feature Selection With Large and High-dimensional Data,"Driven by the advances in technology, large and high-dimensional data have become the rule rather than the exception. Approaches that allow for feature selection with such data are thus highly sought after, in particular, since standard methods, like cross-validated Lasso, can be computationally intractable and, in any case, lack theoretical guarantees. In this paper, we propose a novel approach to feature selection in regression. Consisting of simple optimization steps and tests, it is computationally more efficient than existing methods and, therefore, suited even for very large data sets. Moreover, in contrast to standard methods, it is equipped with sharp statistical guarantees. We thus expect that our algorithm can help to leverage the increasing volume of data in Biology, Public Health, Astronomy, Economics, and other fields.",2016,arXiv: Methodology
"Bayesian statistics 8 : proceedings of the Eighth Valencia International Meeting, June 2-6, 2006","Generative or Discriminative? Getting the Best of Both Worlds Assessing the Effect of Genetic Mutation - A Bayesian Framework for Determining Population History from DNA Sequence Data Some Aspects of Bayesian Model Selection for Prediction Nonparametric Function Estimation Using Overcomplete Dictionaries Sequential Monte Carlo for Bayesian Computation Dynamic Gaussian Process Priors, with Applications to The Analysis of Space-time Data Bayesian Nonparametric Modelling for Spatial Data Using Dirichlet Processes Bayesian Nonparametric Latent Feature Models Objective Bayesian Analysis of Multiple Changepoints for Linear Models Bayesian Relaxation: Boosting, The Lasso, and other L norms The Bayesian Approach to the Analysis of Finite Population Surveys Detecting selection in DNA sequences: Bayesian Modelling and Inference Deriving Bayesian and frequentist estimators from time-invariance estimating equations: a unifying approach FDR and Bayesian Multiple Comparisons Rules Estimating the Integrated Likelihood via Posterior Simulation Using the Harmonic Mean Identity. Approximating Interval Hypothesis: p-values and Bayes Factors Bayesian Probability in Quantum Mechanics Fast Bayesian Shape Matching Using Geometric Algorithms Nested Sampling for Bayesian Computations Objective Bayesian Analysis for the Multivariate Normal Model CONTRIBUTED PAPERS Almeida, C. and Mouchart, M.: Bayesian Encompassing Specification Test Under Not Completely Known Partial Observability Bernardo, J. M. and P'erez, S.: Comparing Normal Means: New Methods for an Old Problem Cano, J. A., Kessler, M. and Salmer'on, D.: Integral Priors for the One Way Random Effects Model Carvalho, C. M. and West, M.: Dynamic Matrix-Variate Graphical Models Cowell, R. G., Lauritzen, S.L. and Mortera, J.: A Gamma Model for DNA Mixture Analyses Denham, R. J. and Mengersen, K.: Geographically Assisted Elicitation of Expert Opinion for Regression Models Duki'c, V. and Dignam, J.: Hierarchical Multiresolution Hazard Model for Breast Cancer Recurrence Hutter, M.: Bayesian Regression of Piecewise Constant Functions Jirsa, J., Quinn, A. and Varga, F.: Identification of Thyroid Gland Activity in Radiotherapy. Kokolakis, G. and Kouvaras, G.: Partial Convexification of Random Probability Measures Ma, H. and Carlin, B. P.: Bayesian Multivariate Areal Wombling Madrigal, A. M.: Cluster Allocation Design Networks Mertens, B. J. A.: Logistic Regression Modelling of Proteomic Mass Spectra in a Case-Control Study on Diagnosis for Colon Cancer Moller, J. and Mengersen, K.: Ergodic Averages Via Dominating Processes Perugia, M.: Bayesian Model Diagnostics Based on Artificial Autoregressive Errors Short, M. B., Higdon, D. M. and Kronberg, P. P.: Estimation of Faraday Rotation Measures of the Near Galactic Sky, Using Gaussian Process Models Spitzner, D. J.: An Asymptotic Viewpoint on High-Dimensional Bayesian Testing Wallstrom, T. C.: The Marginalization Paradox and Probability Limits Xing, E. P. and Sohn, K.-A.: A Hidden Markov Dirichlet Process Model for Genetic Recombination in Open Ancestral Space",2007,
Identification of Novel lncRNA Markers in Glioblastoma Multiforme and Their Clinical Significance: A Study Based on Multiple Sequencing Data,"Background
Long non-coding RNAs (lncRNAs) have been verified to have a vital role in the progression of glioblastoma multiforme (GBM). Our research was about to identify the potential lncRNAs which was closely associated with the pathogenesis and prognosis of glioblastoma multiforme.


Methods
All RNA sequence profiling data from patients with GBM were obtained from The Genotype-Tissue Expression (GTEx) and The Cancer Genome Atlas (TCGA). Differently expressed genes identified from GBM and control samples were used to construct competing endogenous RNA (ceRNA) network and perform corresponding functional enrichment analysis. Univariate Cox regression followed by lasso regression and multivariate Cox was used to validate independent lncRNA factors and construct a risk prediction model. Quantitative polymerase chain reaction (qPCR) was performed to verify the expression levels of potential lncRNA biomarkers in human GBM clinical specimens. A gene set enrichment analysis (GSEA) was subsequently conducted to explore potential signaling pathways in which critical lncRNAs may be involved. Moreover, nomogram plot was applied based on our prediction model and significant clinical covariates to visualize the prognosis of GBM patients.


Results
A total of 2023 differentially expressed genes (DEGs) including 56 lncRNAs, 1587 message RNAs (mRNAs) and 380 other RNAs were included. Based on predictive databases, 16lncRNAs, 32 microRNAs (miRNAs) and 99 mRNAs were used to construct a ceRNA network. Moreover, we performed a novel risk prediction model with 5 potential prognostic lncRNAs, in which 4 of them were newly identified in GBM, to predict the prognosis of GBM patients. Finally, a nomogram plot was constructed to illustrate the potential relationship between the prognosis of GBM and our risk prediction model and significant clinical covariates.


Conclusion
In this study, we identified 4 novel potential lncRNA biomarkers and constructed a prediction model of GBM prognosis. A simple-to-use nomogram was provided for further clinical application.",2020,OncoTargets and therapy
The Rotate Stress of Steam Turbine Prediction Method Based on Stacking Ensemble Learning,"The rotor is one of the most durable parts for a steam turbine. The main shaft, blades or impellers will generate huge transient stress due to high rotate speed, strong torque, and high-temperature steam in the starting up and stopping and other processes, thus, the rotor will face the acid test. As a result, the analysis and prediction of the transient stress of the rotor become the key point in steam turbine life management. The steam turbine is always in high-speed rotation under different poor working conditions, and it is difficult to measure the transient stress directly. In actual production, the finite element analysis is the main method to obtain the stress distribution, lacking measurement accuracy and timeliness. In this paper, we proposed a novel calculation method based on data-driven. Firstly, building a single prediction model based on the Lasso regression, the Elastic net, and the Random forest. Secondly, utilize an ensemble learning based on the stacking to combines a single prediction model to acquire better prediction accuracy. Finally, the case result indicates the effectiveness of the proposed method. Keywordsâ€”Transient stress, Steam turbine, Ensemble learning, Prediction",2019,2019 IEEE 19th International Symposium on High Assurance Systems Engineering (HASE)
Evaluating Imputation Algorithms for Low-Depth Genotyping-By-Sequencing (GBS) Data,"Well-powered genomic studies require genome-wide marker coverage across many individuals. For non-model species with few genomic resources, high-throughput sequencing (HTS) methods, such as Genotyping-By-Sequencing (GBS), offer an inexpensive alternative to array-based genotyping. Although affordable, datasets derived from HTS methods suffer from sequencing error, alignment errors, and missing data, all of which introduce noise and uncertainty to variant discovery and genotype calling. Under such circumstances, meaningful analysis of the data is difficult. Our primary interest lies in the issue of how one can accurately infer or impute missing genotypes in HTS-derived datasets. Many of the existing genotype imputation algorithms and software packages were primarily developed by and optimized for the human genetics community, a field where a complete and accurate reference genome has been constructed and SNP arrays have, in large part, been the common genotyping platform. We set out to answer two questions: 1) can we use existing imputation methods developed by the human genetics community to impute missing genotypes in datasets derived from non-human species and 2) are these methods, which were developed and optimized to impute ascertained variants, amenable for imputation of missing genotypes at HTS-derived variants? We selected Beagle v.4, a widely used algorithm within the human genetics community with reportedly high accuracy, to serve as our imputation contender. We performed a series of cross-validation experiments, using GBS data collected from the species Manihot esculenta by the Next Generation (NEXTGEN) Cassava Breeding Project. NEXTGEN currently imputes missing genotypes in their datasets using a LASSO-penalized, linear regression method (denoted 'glmnet'). We selected glmnet to serve as a benchmark imputation method for this reason. We obtained estimates of imputation accuracy by masking a subset of observed genotypes, imputing, and calculating the sample Pearson correlation between observed and imputed genotype dosages at the site and individual level; computation time served as a second metric for comparison. We then set out to examine factors affecting imputation accuracy, such as levels of missing data, read depth, minor allele frequency (MAF), and reference panel composition.",2016,PLoS ONE
Individual tree detection and area-based approach in retrieval of forest inventory characteristics from low-pulse airborne laser scanning data,"The two main approaches to derive forest information from small-footprint laser scanner data are the statistical area-based approach (ABA) and individual tree detection (ITD). In the present study we tested the accuracies of two ABA estimation methods, namely the k-nearest neighbour (k-NN) and a LASSO regression (LASSO) with ITD. In the estimation a practical low-pulse density (1.8/m 2 ) airborne laser scanning (ALS) dataset was used with same-date aerial photographs. The field data consisted of a test dataset of 97 plots and a modelling dataset of 236 plots. The modelling dataset included 20 plots that were used for bias calibration of forest characteristics calculated from ITD results. The root-mean-squared errors (RMSEs) for basal area, mean volume, mean height and mean diameter with ITD were 33.5%, 33.3%, 4.5% and 11.0% without calibration. The respective accuracies after calibration were 17.9%, 22.8%, 4.4% and 15.4%. With LASSO, the accuracies were 19.8%, 22.1%, 6.4% and 10.3% and with k-NN 24.6%, 25.8%, 9.1% and 13.5%. The ITD method gave as accurate results as did the ABAs when 20 plots were used in calibration.",2011,
A QST-based Pain Phenotype in Adults with Sickle Cell Disease: Sensitivity and Specificity of Quality Descriptors.,"BACKGROUND
We sought to refine a screening measure for discriminating a sensitized or normal sensation pain phenotype among African American adults with sickle cell disease (SCD).


OBJECTIVE
To develop scoring schemes based on sensory pain quality descriptors; evaluate their performance on classifying patients with SCD who had sensitization or normal sensation, and compare with scores on the Self-report Leeds Assessment of Neuropathic Symptoms and Signs (S-LANSS) and the Neuropathic Pain Symptom Inventory (NPSI).


METHODS
Participants completed PAINReportItÂ® , quantitative sensory testing (QST), S-LANSS, and NPSI. Conventional binary logistic regression and lasso (least absolute shrinkage and selection operator) regression were used to obtain two sets of weights resulting in two scores: PR-Logistic and PR-Lasso. Performance of the proposed scores and the existing scores were evaluated.


RESULTS
Lasso regression resulted in a parsimonious model with non-zero weights assigned to two neuropathic descriptors, cold and spreading. We found positive correlations between the PR-Lasso and other scores: S-LANSS (r=.22, p<.01), NPSI (r=.22, p<.01), and PR-Logistic (r=.35, p<.01). The NPSI and PR-Lasso performed similarly at different levels of required specificity and outperformed the S-LANSS and PR-Logistic at the various specificity points.


CONCLUSION
The PR-Lasso offers a way to discriminate a SCD pain phenotype.",2019,Pain practice : the official journal of World Institute of Pain
Post-l1-penalized estimators in high-dimensional linear regression models,"In this paper we study post-penalized estimators which apply ordinary, unpenalized linear regression to the model selected by first-step penalized estimators, typically LASSO. It is well known that LASSO can estimate the regression function at nearly the oracle rate, and is thus hard to improve upon. We show that post-LASSO performs at least as well as LASSO in terms of the rate of convergence, and has the advantage of a smaller bias. Remarkably, this performance occurs even if the LASSO-based model selection 'fails' in the sense of missing some components of the 'true' regression model. By the 'true' model we mean here the best s-dimensional approximation to the regression function chosen by the oracle. Furthermore, post-LASSO can perform strictly better than LASSO, in the sense of a strictly faster rate of convergence, if the LASSO-based model selection correctly includes all components of the 'true' model as a subset and also achieves a sufficient sparsity. In the extreme case, when LASSO perfectly selects the 'true' model, the post-LASSO estimator becomes the oracle estimator. An important ingredient in our analysis is a new sparsity bound on the dimension of the model selected by LASSO which guarantees that this dimension is at most of the same order as the dimension of the 'true' model. Our rate results are non-asymptotic and hold in both parametric and nonparametric models. Moreover, our analysis is not limited to the LASSO estimator in the first step, but also applies to other estimators, for example, the trimmed LASSO, Dantzig selector, or any other estimator with good rates and good sparsity. Our analysis covers both traditional trimming and a new practical, completely data-driven trimming scheme that induces maximal sparsity subject to maintaining a certain goodness-of-fit. The latter scheme has theoretical guarantees similar to those of LASSO or post-LASSO, but it dominates these procedures as well as traditional trimming in a wide variety of experiments.",2010,
An Improved Prediction Model for Ovarian Cancer Using Urinary Biomarkers and a Novel Validation Strategy,"This study was designed to analyze urinary proteins associated with ovarian cancer (OC) and investigate the potential urinary biomarker panel to predict malignancy in women with pelvic masses. We analyzed 23 biomarkers in urine samples obtained from 295 patients with pelvic masses scheduled for surgery. The concentration of urinary biomarkers was quantitatively assessed by the xMAP bead-based multiplexed immunoassay. To identify the performance of each biomarker in predicting cancer over benign tumors, we used a repeated leave-group-out cross-validation strategy. The prediction models using multimarkers were evaluated to develop a urinary ovarian cancer panel. After the exclusion of 12 borderline tumors, the urinary concentration of 17 biomarkers exhibited significant differences between 158 OCs and 125 benign tumors. Human epididymis protein 4 (HE4), vascular cell adhesion molecule (VCAM), and transthyretin (TTR) were the top three biomarkers representing a higher concentration in OC. HE4 demonstrated the highest performance in all samples withOC(mean area under the receiver operating characteristic curve (AUC) 0.822, 95% CI: 0.772-0.869), whereas TTR showed the highest efficacy in early-stage OC (AUC 0.789, 95% CI: 0.714-0.856). Overall, HE4 was the most informative biomarker, followed by creatinine, carcinoembryonic antigen (CEA), neural cell adhesion molecule (NCAM), and TTR using the least absolute shrinkage and selection operator (LASSO) regression models. A multimarker panel consisting of HE4, creatinine, CEA, and TTR presented the best performance with 93.7% sensitivity (SN) at 70.6% specificity (SP) to predict OC over the benign tumor. This panel performed well regardless of disease status and demonstrated an improved performance by including menopausal status. In conclusion, the urinary biomarker panel with HE4, creatinine, CEA, and TTR provided promising efficacy in predicting OC over benign tumors in women with pelvic masses. It was also a non-invasive and easily available diagnostic tool.",2019,International Journal of Molecular Sciences
Identification of prognostic gene signature associated with microenvironment of lung adenocarcinoma,"Background
Lung cancer has the highest morbidity and mortality worldwide, and lung adenocarcinoma (LADC) is the most common pathological subtype. Accumulating evidence suggests the tumor microenvironment (TME) is correlated with the tumor progress and the patient's outcome. As the major components of TME, the tumor-infiltrated immune cells and stromal cells have attracted more and more attention. In this study, differentially expressed immune and stromal signature genes were used to construct a TME-related prognostic model for predicting the outcomes of LADC patients.


Methods
The expression profiles of LADC samples with clinical information were obtained from The Cancer Genome Atlas (TCGA) and Gene Expression Omnibus (GEO). The differentially expressed genes (DEGs) related to the TME of LADC were identified using TCGA dataset by Wilcoxon rank sum test. The prognostic effects of TME-related DEGs were analyzed using univariate Cox regression. Then, the least absolute shrinkage and selection operator (LASSO) regression was performed to reduce the overfit and the number of genes for further analysis. Next, the prognostic model was constructed by step multivariate Cox regression and risk score of each sample was calculated. Then, survival and Receiver Operating Characteristic (ROC) analyses were conducted to validate the model using TCGA and GEO datasets, respectively. The Kyoto Encyclopedia of Genes and Genomes analysis of gene signature was performed using Gene Set Enrichment Analysis (GSEA). Finally, the overall immune status, tumor purity and the expression profiles of HLA genes of high- and low-risk samples was further analyzed to reveal the potential mechanisms of prognostic effects of the model.


Results
A total of 93 TME-related DEGs were identified, of which 23 DEGs were up-regulated and 70 DEGs were down-regulated. The univariate cox analysis indicated that 23 DEGs has the prognostic effects, the hazard ratio ranged from 0.65 to 1.25 (p < 0.05). Then, seven genes were screened out from the 23 DEGs by LASSO regression method and were further analyzed by step multivariate Cox regression. Finally, a three-gene (ADAM12, Bruton Tyrosine KinaseÂ (BTK), ERG) signature was constructed, and ADAM12, BTK can be used as independent prognostic factors. The three-gene signature well stratified the LADC patients in both training (TCGA) and testing (GEO) datasets as high-risk and low-risk groups, the 3-year area under curve (AUC) of ROC curves of three GEO sets were 0.718Â (GSE3141), 0.646Â (GSE30219) and 0.643Â (GSE50081).Â The GSEA analysis indicated that highly expressed ADAM12, BTK, ERG mainly correlated with the activation of pathways involving in focal adhesion, immune regulation. The immune analysis indicated that the low-risk group has more immune activities and higher expression of HLA genes than that of the high-risk group. In sum, we identified and constructed a three TME-related DEGs signature, which could be used to predict the prognosis of LADC patients.",2019,PeerJ
Possible relationship between common genetic variation and white matter development in a pilot study of preterm infants,"BACKGROUND
The consequences of preterm birth are a major public health concern with high rates of ensuing multisystem morbidity, and uncertain biological mechanisms. Common genetic variation may mediate vulnerability to the insult of prematurity and provide opportunities to predict and modify risk.


OBJECTIVE
To gain novel biological and therapeutic insights from the integrated analysis of magnetic resonance imaging and genetic data, informed by prior knowledge.


METHODS
We apply our previously validated pathway-based statistical method and a novel network-based method to discover sources of common genetic variation associated with imaging features indicative of structural brain damage.


RESULTS
Lipid pathways were highly ranked by Pathways Sparse Reduced Rank Regression in a model examining the effect of prematurity, and PPAR (peroxisome proliferator-activated receptor) signaling was the highest ranked pathway once degree of prematurity was accounted for. Within the PPAR pathway, five genes were found by Graph Guided Group Lasso to be highly associated with the phenotype: aquaporin 7 (AQP7), malic enzyme 1, NADP(+)-dependent, cytosolic (ME1), perilipin 1 (PLIN1), solute carrier family 27 (fatty acid transporter), member 1 (SLC27A1), and acetyl-CoA acyltransferase 1 (ACAA1). Expression of four of these (ACAA1, AQP7, ME1, and SLC27A1) is controlled by a common transcription factor, early growth response 4 (EGR-4).


CONCLUSIONS
This suggests an important role for lipid pathways in influencing development of white matter in preterm infants, and in particular a significant role for interindividual genetic variation in PPAR signaling.",2016,Brain and Behavior
Genomeâ€wide association studies using a penalized movingâ€window regression,"Motivation: Genomeâ€wide association studies (GWAS) have played an important role in identifying genetic variants underlying human complex traits. However, its success is hindered by weak effect at causal variants and presence of noise at nonâ€causal variants. In an effort to overcome these difficulties, a previous study proposed a regularized regression method that penalizes on the difference of signal strength between two consecutive singleâ€nucleotide polymorphisms (SNPs). Results: We provide a generalization to the aforeâ€mentioned method so that more adjacent SNPs can be incorporated. The choice of optimal number of SNPs is studied. Simulation studies indicate that when consecutive SNPs have similar absolute coefficients our method performs better than using LASSO penalty. In other situations, our method is still comparable to using LASSO penalty. The practical utility of the proposed method is demonstrated by applying it to Genetic Analysis Workshop 16 rheumatoid arthritis GWAS data. Availability and implementation: An implementation of the proposed method is provided in R package MWLasso. Contact: kaiâ€wang@uiowa.edu",2017,Bioinformatics
Survival prediction from clinico-genomic models - a comparative study,"BackgroundSurvival prediction from high-dimensional genomic data is an active field in today's medical research. Most of the proposed prediction methods make use of genomic data alone without considering established clinical covariates that often are available and known to have predictive value. Recent studies suggest that combining clinical and genomic information may improve predictions, but there is a lack of systematic studies on the topic. Also, for the widely used Cox regression model, it is not obvious how to handle such combined models.ResultsWe propose a way to combine classical clinical covariates with genomic data in a clinico-genomic prediction model based on the Cox regression model. The prediction model is obtained by a simultaneous use of both types of covariates, but applying dimension reduction only to the high-dimensional genomic variables. We describe how this can be done for seven well-known prediction methods: variable selection, unsupervised and supervised principal components regression and partial least squares regression, ridge regression, and the lasso. We further perform a systematic comparison of the performance of prediction models using clinical covariates only, genomic data only, or a combination of the two. The comparison is done using three survival data sets containing both clinical information and microarray gene expression data. Matlab code for the clinico-genomic prediction methods is available at http://www.med.uio.no/imb/stat/bmms/software/clinico-genomic/.ConclusionsBased on our three data sets, the comparison shows that established clinical covariates will often lead to better predictions than what can be obtained from genomic data alone. In the cases where the genomic models are better than the clinical, ridge regression is used for dimension reduction. We also find that the clinico-genomic models tend to outperform the models based on only genomic data. Further, clinico-genomic models and the use of ridge regression gives for all three data sets better predictions than models based on the clinical covariates alone.",2009,BMC Bioinformatics
"Integration of transcriptomics and metabonomics: improving diagnostics, biomarker identification and phenotyping in ulcerative colitis","A systems biology approach to multi-faceted diseases has provided an opportunity to establish a holistic understanding of the processes at play. Thus, the current study merges transcriptomics and metabonomics data in order to improve diagnostics, biomarker identification and to explore the possibilities of a molecular phenotyping of ulcerative colitis (UC) patients. Biopsies were obtained from the descending colon of 43 UC patients (22 active UC and 21 quiescent UC) and 15 controls. Genome-wide gene expression analyses were performed using Affymetrix GeneChip Human Genome U133 Plus 2.0. Metabolic profiles were generated using 1 H Nuclear magnetic reso- nance spectroscopy (Bruker 600 MHz, Bruker BioSpin, Rheinstetten, Germany). Data were analyzed with the use of orthogonal-projection to latent structure-discriminant analysis and a multivariate logistic regression model fitted by lasso. Prediction performance was evaluated using nested Monte Carlo cross-validation. The prediction per- formance of the merged data sets and that of relative small (\20 variables) multivariate biomarker panels suggest that it is possible to discriminate between active UC, quiescent UC, and controls; between patients with or without steroid dependency, as well as between early or late disease onset. Consequently, this study demonstrates that the novel approach of integrating metabonomics and transcriptomics combines the better of the two worlds, and provides us with clinical applicable candidate biomarker panels. These combined panels improve diagnostics and more impor- tantly also the molecular phenotyping in UC and provide insight into the pathophysiological processes at play, making optimized and personalized medication a possibility.",2014,
Differential expression analysis with global network adjustment,"BackgroundLarge-scale chromosomal deletions or other non-specific perturbations of the transcriptome can alter the expression of hundreds or thousands of genes, and it is of biological interest to understand which genes are most profoundly affected. We present a method for predicting a geneâ€™s expression as a function of other genes thereby accounting for the effect of transcriptional regulation that confounds the identification of genes differentially expressed relative to a regulatory network. The challenge in constructing such models is that the number of possible regulator transcripts within a global network is on the order of thousands, and the number of biological samples is typically on the order of 10. Nevertheless, there are large gene expression databases that can be used to construct networks that could be helpful in modeling transcriptional regulation in smaller experiments.ResultsWe demonstrate a type of penalized regression model that can be estimated from large gene expression databases, and then applied to smaller experiments. The ridge parameter is selected by minimizing the cross-validation error of the predictions in the independent out-sample. This tends to increase the model stability and leads to a much greater degree of parameter shrinkage, but the resulting biased estimation is mitigated by a second round of regression. Nevertheless, the proposed computationally efficient â€œover-shrinkageâ€ method outperforms previously used LASSO-based techniques. In two independent datasets, we find that the median proportion of explained variability in expression is approximately 25%, and this results in a substantial increase in the signal-to-noise ratio allowing more powerful inferences on differential gene expression leading to biologically intuitive findings. We also show that a large proportion of gene dependencies are conditional on the biological state, which would be impossible with standard differential expression methods.ConclusionsBy adjusting for the effects of the global network on individual genes, both the sensitivity and reliability of differential expression measures are greatly improved.",2013,BMC Bioinformatics
Sparse Gaussian Process Regression via L1 Penalization,"To handle massive data, a variety of sparse Gaussian Process (GP) methods have been proposed to reduce the computational cost. Many of them essentially map the large dataset into a small set of basis points. A common approach to learn these basis points is evidence maximization. Nevertheless, evidence maximization may lead to overfitting and cause a high computational cost. In this paper, we propose a novel sparse GP regression approach, GPLasso, that explicitly represents the trade-off between its approximation quality and the model sparsity. GPLasso minimizes a l1-penalized KL divergence between the exact and sparse GP posterior processes. Optimizing this convex cost function leads to sparse GP parameters. Furthermore, we use incomplete Cholesky factorization to obtain low-rank matrix approximations to speed up the optimization procedure. Experimental results on synthetic and real data demonstrate that, compared with several state-of-the-art sparse GP methods and a direct low-rank matrix approximation method, GPLasso achieves a significantly improved trade-off between prediction accuracy and computational cost.",2010,
Optimizing Location of Car-Sharing Stations Based on Potential Travel Demand and Present Operation Characteristics: The Case of Chengdu,"Car-sharing is becoming an increasingly popular travel mode in China and many companies invest plenty of money on that including vehicle enterprises and Internet companies. But most of them build car-sharing stations by their experience or randomly as long as there is parking space in the early development of their business. This results in many stations with low operational efficiency and causes capital loss. This study aims to use different data source with statistical models and machine learning algorithm to help car-sharing operator to choose the optimal location of new stations and adjust the location of existing stations. We select Chengdu where there are huge amounts of car-sharing travel demand and several large car-sharing operators as the research area and two main operators as the research objects. Chengdu is divided into 58724 squared grids each of which is 0.5kmâŽ0.5km instead of focusing on the buffers generated by stations. We try to find a model to estimate a potential travel demand value for each small grid with three data sources: order data, population data, and Point of Interest (POI) data. This problem is transformed into a binary form and five different methods, Logistic Regression, Logistic Regression with LASSO, Naive Bayes, Linear Discriminant Analysis, and Quadratic Discriminant Analysis, are implemented. The optimal model, Logistic Regression with LASSO, is chosen to estimate the probability of existence of demand in all grids. With car-sharing order data from different operators, an existing order heat value is also computed for each grid. Then we analyze and classify all the grids into four groups. For different groups of grids, we give different suggestions on the optimal location of stations. This study focuses on a more competitive market and finds the influential factors on order number. Suggestions on the optimal location of stations are given in consideration of competitors. We hope that our research can help operators improve their business and make rational plans.",2019,Journal of Advanced Transportation
