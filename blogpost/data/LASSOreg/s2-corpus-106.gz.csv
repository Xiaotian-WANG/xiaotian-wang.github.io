title,abstract,year,journal
Modeling Item-item Similarities for Personalized Recommendations on Yahoo! Front Page,"We consider the problem of algorithmically recommending items to users on a Yahoo! front page module. Our approach is based on a novel multilevel hierarchical model that we refer to as a User Profile Model with Graphical Lasso (UPG). The UPG provides a personalized recommendation to users by simultaneously incorporating both user covariates and historical user interactions with items in a model based way. In fact, we build a per-item regression model based on a rich set of user covariates and estimate individual user affinity to items by introducing a latent random vector for each user. The vector random effects are assumed to be drawn from a prior with a precision matrix that measures residual partial associations among items. To ensure better estimates of a precision matrix in high-dimensions, the matrix elements are constrained through a Lasso penalty. Our model is fitted through a penalized-quasi likelihood procedure coupled with a scalable EM algorithm. We employ several computational strategies like multi-threading, conjugate gradients and heavily exploit problem structure to scale our computations in the E-step. For the M-step we take recourse to a scalable variant of the Graphical Lasso algorithm for covariance selection. Through extensive experiments on a new data set obtained from Yahoo! front page and a benchmark data set from a movie recommender application, we show that our UPG model significantly improves performance compared to several state-of-the-art methods in the literature, especially those based on a bilinear random effects model (BIRE). In particular, we show that the gains of UPG are significant compared to BIRE when the number of users is large and the number of items to select from is small. For large item sets and relatively small user sets the results of UPG and BIRE are comparable. The UPG leads to faster model building and produces outputs which are interpretable.",2011,The Annals of Applied Statistics
A large cohort study identifying a novel prognosis prediction model for lung adenocarcinoma through machine learning strategies,"BackgroundPredicting lung adenocarcinoma (LUAD) risk is crucial in determining further treatment strategies. Molecular biomarkers may improve risk stratification for LUAD.MethodsWe analyzed the gene expression profiles of LUAD patients from The Cancer Genome Atlas (TCGA) and Gene Expression Omnibus (GEO). We initially used three distinct algorithms (sigFeature, random forest, and univariate Cox regression) to evaluate each geneâ€™s prognostic relevance. Survival related genes were then fitted into the least absolute shrinkage and selection operator (LASSO) model to build a risk prediction model for LUAD. After 100,000 times of calculation and model construction, a 16-gene-based prediction model capable of classifying LUAD patients into high-risk and low-risk groups was successfully built.ResultsUsing a combined strategy, we initially identified 2472 significant survival-related genes. Functional enrichment analysis demonstrated these genesâ€™ relevance to tumor initiation and progression. Using the LASSO method, we successfully built a reliable risk prediction model. The risk model was validated in two external sets and an independent set. The expression of these 16 genes was highly correlated with patientsâ€™ risk. High-risk group patients witnessed poorer recurrence-free survival (RFS) and overall survival (OS) compared to low-risk group patients. Moreover, stratification analysis and decision curve analysis (DCA) confirmed the independence and potential translational value of this predictive tool. We also built a nomogram comprising risk model and stage to predict OS for LUAD patients.ConclusionsOur risk model may serve as a practical and reliable prognosis predictive tool for LUAD and could provide novel insights into the understanding of the molecular mechanism of this disease.",2019,BMC Cancer
Data Science par Analyse des DonnÃ©es Symboliques,"Une nouvelle facon d analyser les donnees classiques, complexes et massives a partir des classes Applications avec Syr et R La numerisation croissante de notre societe alimente des bases de donnees de taille grandissante (Big Data). Ces donnees sont souvent complexes (heterogenes et multi-tables) et peuvent etre la source de creation de valeur considerable a condition qu elles soient exploitees avec des methodes d analyse adequates. Un Â« Data Scientist Â» a justement pour objectif d extraire des connaissances de ce type de donnees et c est l objectif de cet ouvrage. Les classes constituent un pivot central de la decouverTe de connaissances. En Analyse des Donnees Symboliques (ADS), les classes sont decrites par des variables dites symboliques prenant en compte leur variabilite interne sous forme de distributions, d intervalles, d histogrammes, de diagrammes de frequences, etc. Le livre debute par la construction de differents types de variables symboliques a partir de classes donnees. Des statistiques descriptives, une methode de discretisation automatique adaptee aux donnees massives (Big Data) suivies par des indices de proximite etendus aux donnees symboliques y sont presentes. Vient ensuite un ensemble de methodes presente dans le contexte de l ADS. Il s agit de la methode des nuees dynamiques (MND), de la decomposition de melange par partition (issue de la MND) ou par partition floue (EM), de l analyse en composantes principales, de l algorithme Apriori, des regles d association et des arbres de decision. Pour la prevision, le livre presente des methodes de regressions dont celles penalisees Â« ridge Â», Â« lasso Â» et Â« elastic Â», et des series temporelles. Pour la mise en application de ces premieres methodes, des exercices et des applications concretes realisees aupres d administrations, d industriels, de financiers et de scientifiques sont proposes. Leur mise en uvre s appuie aussi bien sur le logiciel innovant Syr que sur le logiciel statistique R. Cet ouvrage d introduction a l ADS s adresse aux etudiants, aux ingenieurs, aux universitaires, ainsi qu a tous ceux qui desirent comprendre cette nouvelle facon de penser en Science des Donnees.",2018,
Quantification of miRNA-mRNA Interactions,"miRNAs are small RNA molecules (' 22nt) that interact with their corresponding target mRNAs inhibiting the translation of the mRNA into proteins and cleaving the target mRNA. This second effect diminishes the overall expression of the target mRNA. Several miRNA-mRNA relationship databases have been deployed, most of them based on sequence complementarities. However, the number of false positives in these databases is large and they do not overlap completely. Recently, it has been proposed to combine expression measurement from both miRNA and mRNA and sequence based predictions to achieve more accurate relationships. In our work, we use LASSO regression with non-positive constraints to integrate both sources of information. LASSO enforces the sparseness of the solution and the non-positive constraints restrict the search of miRNA targets to those with down-regulation effects on the mRNA expression. We named this method TaLasso (miRNA-Target LASSO).We used TaLasso on two public datasets that have paired expression levels of human miRNAs and mRNAs. The top ranked interactions recovered by TaLasso are especially enriched (more than using any other algorithm) in experimentally validated targets. The functions of the genes with mRNA transcripts in the top-ranked interactions are meaningful. This is not the case using other algorithms.TaLasso is available as Matlab or R code. There is also a web-based tool for human miRNAs at http://talasso.cnb.csic.es/.",2012,PLoS ONE
Irritability uniquely predicts prefrontal cortex activation during preschool inhibitory control among all temperament domains: A LASSO approach,"&NA; Temperament, defined as individual variation in the reactivity and regulation of emotional, motor, and attentional processes, has been shown to influence emotional and cognitive development during the preschool period (ages 4â€“5). While relationships between temperament and neural activity have been investigated previously, these have typically investigated individual temperament dimensions selected ad hoc. Since significant correlations exist between various temperament dimensions, it remains unclear whether these findings would replicate while analyzing all temperament dimensions simultaneously. Using functional near infrared spectroscopy (fNIRS), 4â€5â€yearâ€old children (N = 118) were administered a Go/Noâ€Go task to assess prefrontal cortex activation during inhibitory control. The relationship between PFC activation and all 15 temperament domains defined by the Children's Behavior Questionnaire (CBQ) was assessed using automatic feature selection via LASSO regression. Results indicate that only the Anger/Frustration dimension was predictive of activation during the inhibitory control task. These findings support previous work showing relationships between irritability and prefrontal activation during executive function and extend those findings by demonstrating the specificity of the activationâ€irritability relationship among temperament dimensions. Graphical abstract Figure. No caption available. HighlightsPFC activation was assessed in 118 preschool children during Go/Noâ€Go using fNIRS.Reaction time increase predicted inhibitory controlâ€related activation increase.All 15 CBQ temperament dimensions were entered as predictors into a LASSO model.The LASSO selected only Anger/Frustration as a significant predictor of activation.",2019,NeuroImage
2 Regularization Methods for Grouped Variable Selection,"In this study, we consider several regularization path algorithms with grouped variable selection for modeling gene-interactions. When fitting with categorical factors, including the genotype measurements, we often define a set of dummy variables that represent a single factor/interaction of factors. Yuan & Lin (2006) proposed the groupLars and the group-Lasso methods through which these groups of indicators can be selected simultaneously. Here we introduce another version of group-Lars. In addition, we propose a path-following algorithm for the group-Lasso method applied to generalized linear models. We then use all these path algorithms, which select the grouped variables in a smooth way, to identify gene-interactions affecting disease status in an example. We further compare their performances to that of L2 penalized logistic regression with forward stepwise variable selection discussed in Park & Hastie (2006b).",2006,
Bio-statistical approaches to evaluate the link between specific nutrients and methylation patterns in a breast cancer case-control study nested within the European Prospective Investigation into Cancer and Nutrition (EPIC) study. (Approches bio-statistiques pour Ã©valuer le lien entre nutriments et ,"Epigenetics data are challenging sets characterized by hundreds of thousands of features. The main objective of this thesis was to evaluate the performance of some of the existing statistical methods to handle sets of large dimension data, exploring the association between dietary factors related to breast cancer (BC) and DNA methylation within the EPIC study.In order to investigate the characteristics of epigenetics data, the identification of random and systematic sources of variability of methylation measurements was attempted, via the principal component partial R-square (PC-PR2) method. Using this technique, the performance of three popular normalization techniques to correct for unwanted sources of variability was evaluated by quantifying epigenetics variability attributed to laboratory factors before and after the application of each correction method.Once a suitable normalization procedure was identified, the association between alcohol intake, dietary folate and methylation levels was examined by means of three approaches: an analysis of individual CpG sites, of differentially methylated regions (DMRs) and using fused lasso regression. The last two methods aim at the identification of specific regions of the epigenome using the potential correlation between neighboring CpG sites. Global methylation levels were used to investigate the relationship between methylation and BC risk.By performing an exhaustive evaluation of the statistical tools used to disclose complexity of DNA methylation data, this thesis provides informative insights for studies focusing on epigenetics, with promising potentials to apply similar methodology to the analysis of other -omics data",2018,
"ë…¼ë¬¸ : ì˜ˆëŒ€ê¸ˆë¦¬ì°¨ ê²°ì •ìš”ì¸ ëª¨í˜•ì˜ ì˜ˆì¸¡ë ¥ ë¹„êµ ì—°êµ¬ -Ridge, LASSO ë° Elastic Net ë°©ë²•ë¡ ì„ ì¤‘ì‹¬ìœ¼ë¡œ-","ë³¸ ì—°êµ¬ì—ì„œëŠ” 2001ë…„ë¶€í„° 2011ë…„ê¹Œì§€ 11ë…„ ê°„ 52ê°œ êµ­ê°€ì˜ ê¸ˆìœµ ë° ê±°ì‹œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì˜ˆëŒ€ê¸ˆë¦¬ì°¨ ê²°ì •ìš”ì¸ ëª¨í˜•ì„ êµ¬ì„±í•˜ê³ , ì´ë“¤ì˜ ì˜ˆì¸¡ë ¥ì„ ë¹„êµí•˜ì˜€ë‹¤. ê´€ì¸¡ì¹˜ë³´ë‹¤ ë§Žì€ìˆ˜ì˜ ìž ìž¬ ì„¤ëª…ë³€ìˆ˜ë¥¼ ê³ ë ¤í•¨ê³¼ ë™ì‹œì— ëª¨í˜•ì˜ ì˜ˆì¸¡ë ¥ì„ ë†’ì´ê¸° ìœ„í•˜ì—¬ íšŒê·€ê³„ìˆ˜ë¥¼ ì¶•ì†Œí•˜ì—¬ ì¶”ì •í•˜ëŠ” ëŠ¥í˜•íšŒê·€(ridge regression), LASSO(Least Absolute Shrinkage and Selection Operator) ë° elastic net ë°©ë²•ë¡ ì„ ì´ìš©í•˜ì˜€ë‹¤. ë¶„ì„ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì²«ì§¸, ì›ë³€ìˆ˜ë§Œì„ í™œìš©í•œ ë‹¨ê³„ë³„ íšŒê·€ë¶„ì„ ëŒ€ë¹„ ë²Œì í™” ì¶•ì†Œì¶”ì • ê¸°ë²•ì˜ ì˜ˆì¸¡ë ¥ì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•˜ì˜€ë‹¤. ì´ëŠ” ë²Œì í™” ì¶•ì†Œì¶”ì • ê¸°ë²•ì˜ ê²½ìš° ìž ìž¬ ì„¤ëª…ë³€ìˆ˜ë¥¼ ëª¨ë‘ ê³ ë ¤í•  ìˆ˜ ìžˆìœ¼ë©°, íšŒê·€ê³„ìˆ˜ì˜ ë¶„ì‚°ì„ ì¤„ì—¬ ì˜ˆì¸¡ë ¥ì„ ë†’ì´ê¸° ë•Œë¬¸ì¸ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ë‘˜ì§¸, ë²Œì í™” ì¶•ì†Œì¶”ì • ê¸°ë²• ì¤‘ì—ì„œëŠ” elasticnet ëª¨í˜•(î‚ î‡î€½î“î€º)ê³¼ LASSOê°€ ê°€ìž¥ ì¢‹ì€ ì˜ˆì¸¡ë ¥ì„ ë³´ì—¬ ì£¼ì—ˆë‹¤. ì…‹ì§¸, ì˜ˆëŒ€ê¸ˆë¦¬ì°¨ ê²°ì •ìš”ì¸ ëª¨í˜•ì„ ë³´ë©´ ì›ë³€ìˆ˜ì˜ ìƒí˜¸ìž‘ìš©í•­ ì¤‘ ì¼ë¶€ ë³€ìˆ˜ë“¤ì´ ì˜ˆëŒ€ê¸ˆë¦¬ì°¨ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤. íŠ¹ížˆ 1ì¸ë‹¹ GDPëŠ” ê¸°íƒ€ë³€ìˆ˜ë“¤ê³¼ì˜ ìƒí˜¸ìž‘ìš©í•­ì´ ì˜ˆëŒ€ê¸ˆë¦¬ì°¨ì— ì˜í–¥ë ¥ì„ ë³´ì˜€ëŠ”ë°, ì´ëŠ” ê²½ì œìˆ˜ì¤€ë³„ë¡œ ì˜ˆëŒ€ê¸ˆë¦¬ì°¨ ê²°ì •ìš”ì¸ì˜ ì˜í–¥ ì •ë„ê°€ ìƒì´í•  ìˆ˜ ìžˆìŒì„ ì‹œì‚¬í•œë‹¤.",2015,
Modern Statistical Methods,"In this course we will study a selection of important modern statistical methods. This selection is heavily biased towards my own interests, but I hope it will nevertheless give you a flavour of some of the most important recent methodological developments in statistics. Over the last 25 years, the sorts of datasets that statisticians have been challenged to study have changed greatly. Where in the past, we were used to datasets with many observations with a few carefully chosen variables, we are now seeing datasets where the number of variables can run into the thousands and greatly exceed the number of observations. For example, with microarray data, we typically have gene expression values measured for several thousands of genes, but only for a few hundred tissue samples. The classical statistical methods are often simply not applicable in these â€œhigh-dimensionalâ€ situations. The course is divided into 4 chapters (of unequal size). Our first chapter will start by introducing ridge regression, a simple generalisation of ordinary least squares. Our study of this will lead us to some beautiful connections with functional analysis and ultimately one of the most successful and flexible classes of learning algorithms: kernel machines. The second chapter concerns the Lasso and its extensions. The Lasso has been at the centre of much of the developments that have occurred in high-dimensional statistics, and will allow us to perform regression in the seemingly hopeless situation when the number of parameters we are trying to estimate is larger than the number of observations. In the third chapter we will study graphical modelling and provide an introduction to the exciting field of causal inference. Where the previous chapters consider methods for relating a particular response to a large collection of (explanatory) variables, graphical modelling will give us a way of understanding relationships between the variables themselves. Ultimately we would like to infer causal relationships between variables based on (observational) data. This may seem like a fundamentally impossible task, yet we will show how by developing the graphical modelling framework further, we can begin to answer such causal questions. Statistics is not only about developing methods that can predict well in the presence of noise, but also about assessing the uncertainty in our predictions and estimates. In the final chapter we will tackle the problem of how to handle performing thousands of hypothesis tests at the same time and more generally the task of quantifying uncertainty in high-dimensional settings. Before we begin the course proper, we will briefly review two key classical statistical methods: ordinary least squares and maximum likelihood estimation. This will help to set the scene and provide a warm-up for the modern methods to come later.",2017,
Beyond Early Warning Indicators: High School Dropout and Machine Learning,"This paper provides an algorithm to predict which students are going to drop out of high schools relying only on information from 9th grade. It verifies that using a parsimonious early warning system - as implemented in many schools - leads to poor results. It shows that schools can obtain more precise predictions by exploiting the available high-dimensional data jointly with machine learning tools such as Support Vector Machine, Boosted Regression and Post-LASSO. It carefully selects goodness-of-fit criteria based on the context and the underlying theoretical framework: model parameters are calibrated by taking into account policy goals and budget constraints. Finally, it uses unsupervised machine learning to divide students at risk of dropping out into different clusters.",2019,Oxford Bulletin of Economics and Statistics
Variable selection for multiply-imputed data with penalized generalized estimating equations,"Generalized estimating equations (GEE) are useful tools for marginal regression analysis for longitudinal data. Having a high number of variables along with the presence of missing data presents complex issues when working in a longitudinal context. In variable selection for instance, penalized generalized estimating equations have not been systematically developed to integrate missing data. The MI-PGEE: multiple imputation-penalized generalized estimating equations, an extension of the multiple imputation-least absolute shrinkage and selection operator (MI-LASSO) is presented. MI-PGEE allows integration of missing data and within-subject correlation in variable selection procedures. Missing data are dealt with using multiple imputation, and variable selection is performed using a group LASSO penalty. Estimated coefficients for the same variable across multiply-imputed datasets are considered as a group while applying penalized generalized estimating equations, leading to a unique model across multiply-imputed datasets. In order to select the tuning parameter, a new BIC-like criterion is proposed. In a simulation study, the advantage of using MI-PGEE compared to simple imputation PGEE is shown. The usefulness of the new method is illustrated by an application to a subgroup of the placebo arm of the strontium ranelate efficacy in knee osteoarthritis trial study.",2017,Comput. Stat. Data Anal.
Grayscale Ultrasound Radiomic Features and Shear-Wave Elastography Radiomic Features in Benign and Malignant Breast Masses.,"PURPOSE
â€‚To identify and compare diagnostic performance of radiomic features between grayscale ultrasound (US) and shear-wave elastography (SWE) in breast masses.


MATERIALS AND METHODS
â€‚We retrospectively collected 328Â pathologically confirmed breast masses in 296 women who underwent grayscale US and SWE before biopsy or surgery. A representative SWE image of the mass displayed with a grayscale image in split-screen mode was selected. An ROI was delineated around the mass boundary on the grayscale image and copied and pasted to the SWE image by a dedicated breast radiologist for lesion segmentation. A total of 730 candidate radiomic features including first-order statistics and textural and wavelet features were extracted from each image. LASSO regression was used for data dimension reduction and feature selection. Univariate and multivariate logistic regression was performed to identify independent radiomic features, differentiating between benign and malignant masses with calculation of the AUC.


RESULTS
â€‚Of 328 breast masses, 205 (62.5â€Š%) were benign and 123 (37.5â€Š%) were malignant. Following radiomic feature selection, 22 features from grayscale and 6 features from SWE remained. On univariate analysis, all 6 SWE radiomic features (Pâ€Š<â€Š0.0001) and 21 of 22 grayscale radiomic features (Pâ€Š<â€Š0.03) were significantly different between benign and malignant masses. After multivariate analysis, three grayscale radiomic features and two SWE radiomic features were independently associated with malignant breast masses. The AUC was 0.929 for grayscale US and 0.992 for SWE (Pâ€Š<â€Š0.001).


CONCLUSION
â€‚US radiomic features may have the potential to improve diagnostic performance for breast masses, but further investigation of independent and larger datasets is needed.",2019,Ultraschall in der Medizin
Predicting Days on Market to Optimize Real Estate Sales Strategy,"Irregularities and frauds are frequent in the real estate market in Bulgaria due to the substantial lack of rigorous legislation. For instance, agencies frequently publish unreal or unavailable apartment listings for a cheap price, as a method to attract the attention of unaware potential new customers. For this reason, systems able to identify unreal listings and improve the transparency of listings authenticity and availability are much on demand. Recent research has highlighted that the number of days a published listing remains online can have a strong correlation with the probability of a listing being unreal. For this reason, building an accurate predictive model for the number of days a published listing will be online can be very helpful to accomplish the task of identifying fake listings. In this paper, we investigate the use of four different machine learning algorithms for this task: Lasso, Ridge, Elastic Net, and Artificial Neural Networks. The results, obtained on a vast dataset made available by the Bulgarian company Homeheed, show the appropriateness of Lasso regression.",2020,Complexity
Guaranteed Sufficient Decrease for Stochastic Variance Reduced Gradient Optimization,"In this paper, we propose a novel sufficient decrease technique for stochastic variance reduced gradient descent methods such as SVRG and SAGA. In order to make sufficient decrease for stochastic optimization, we design a new sufficient decrease criterion, which yields sufficient decrease versions of stochastic variance reduction algorithms such as SVRG-SD and SAGA-SD as a byproduct. We introduce a coefficient to scale current iterate and to satisfy the sufficient decrease property, which takes the decisions to shrink, expand or even move in the opposite direction, and then give two specific update rules of the coefficient for Lasso and ridge regression. Moreover, we analyze the convergence properties of our algorithms for strongly convex problems, which show that our algorithms attain linear convergence rates. We also provide the convergence guarantees of our algorithms for non-strongly convex problems. Our experimental results further verify that our algorithms achieve significantly better performance than their counterparts.",2018,
Nouvelle mÃ©thode bayÃ©sienne de sÃ©lection de variables pour des Ã©chantillons de petite taille incorporant lâ€™expertise clinique. Application au cancer colorectal,"Introduction Lâ€™utilisation de donnees cliniques pour modeliser les decisions medicales sequentielles de modification de dose dans les chimiotherapies souleve des defis methodologiques. Les medecins ont souvent acces a de nombreuses variables quâ€™ils peuvent utiliser pour prendre leurs decisions. Ils priorisent generalement certaines covariables par rapport a dâ€™autres, suivant les caracteristiques, lâ€™histoire du patient, et leur propre experience. Dans le contexte des echantillons de petite taille, les methodes de selection de variables bayesiennes peuvent aider a determiner quelles variables sont reellement utilisees dans la pratique quotidienne et permettent dâ€™incorporer lâ€™expertise des cliniciens dans les distributions a priori. Parmi celles-ci, la methode de selection stochastique de variables (SSVS) identifie et estime les distributions a posteriori en supposant que la distribution a priori de chaque coefficient de regression est un melange de deux distributions normales centrees sur zero mais de variances tres differentes. Motives par une application sur les adaptations de doses dâ€™Irinotecan dans le cadre du cancer colorectal metastatique, nous proposons une modification de la methode SSVS, que nous appelons WBS, pour integrer lâ€™expertise clinique dans les distributions a priori. Methodes Pour modeliser la relation entre la dose dâ€™Irinotecan a chaque cycle, les caracteristiques du patient (Ã¢ge, perte de poids) et les toxicites, dans le cadre du cancer metastatique colorectal, nous supposons un modele lineaire a effets mixtes. Des medecins experts ont specifie la pertinence de chaque variable dans les reductions de dose sur une echelle allant de 0Â a 100. Ces poids sont ensuite utilises pour construire des distributions a priori pour les parametres du modele qui regissent lâ€™inclusion/lâ€™exclusion des covariables. Nous avons analyse les performances du modele WBS par rapport a celles du Lasso et du modele SSVS grÃ¢ce a une etude de simulation. Nous avons simule un echantillon de patients traites pour un cancer metastatique colorectal par Irinotecan, suivant les distributions de nos donnees. Quatre scenarios ont ete simulesÂ : deux impliquant lâ€™expertise du clinicien 1Â et deux impliquant celle du clinicien 2. Nous avons egalement applique la methode WBS a notre situation reelle. Resultats Comparee a la methode SSVS habituelle, la methode WBS a montre de meilleures performances quel que soit le critere de performance considere (RMSE, Â«Â log predictive densityÂ Â») et a produit les taux les plus faibles de faux positifs et de faux negatifs. La performance de la methode WBS depend non seulement des poids des variables, mais aussi de la somme des poids qui doit etre soigneusement calibree pour selectionner le nombre approprie de covariables. Le Lasso a montre une performance mediocre par rapport aux methodes WBS et SSVS, confirmant une meilleure performance de lâ€™approche bayesienne par rapport a lâ€™approche frequentiste lorsquâ€™il sâ€™agit de petits echantillons. Lâ€™application de la methode WBS a notre situation reelle a mis en evidence que les poids de pertinence clinique obtenus avec les medecins etaient loin des effets estimes sur les donnees reelles. Conclusion Nous proposons une methode de selection de variables bayesienne tres performante pour integrer lâ€™expertise dans des modeles sur des petits echantillons.",2018,Revue D Epidemiologie Et De Sante Publique
Rectal gonorrhoea asan independent risk factor forHIVinfection inacohort ofhomosexual men,"Objective-To determine whether certain sexually transmitted diseases areinde- pendent riskfactors forHIVtransmission inacohort ofhomosexual men. Methods-Eligible caseswereidentified asthosewhohadseroconverted between November1982andNovember1990. Two persistently HIV-seronegative control participants wererandomlyselected for eachcasefrom allparticipants who remainedseronegative in November 1990.Forcases, riskfactordatawere takenfroman indexvisitwhichwas definedas thefirstseropositive visit, whileforcontrols thesedatawere obtained froma matchedvisitwhich occurred within twomonthsoftheindex visit forthecorresponding case.Mantel- Haenszel methodsandlogistic regression wereusedtocomparedifferences inrisk factors forseroconversion betweencases andcontrols. Results-A total of125casesand250con- trols wereeligible forthisstudy. Cases weresignificantly morelikely tohavehad reported anygonorrhoea (17%versus6%; OR =2.94; 95%CI:1.51-5.73) orsyphilis (7% versus2%; OR = 3.78;95% CI: 1-33-10.79) thancontrols during thesero- conversion period. Multivariate logistic regression revealed rectal gonorrhoea to beindependently associated withriskof seroconversion (oddsratio = 3*18;p = 0.044), whereasurethral gonorrhoea (p= 0.479) andpharyngeal gonorrhoea (p= 0.434) werenotafter inclusion ofrectal gonorrhoea. Inaddition, thefollowing variables werealsoshowntoexertan independent effect on seroconversion: frequency ofanalintercourse, useof illicit drugs,number of male sexual partners, andlackofa post-secondary education. Conclusions-In thisobservational study, rectal gonorrhoea wasfoundtobeassoci- atedwithHIV seroconversion after adjustment foranumberofHIVriskfac- tors.We cannotruleoutthatrectal gon- orrhoeawasnotdirectly associated with HIVinfection butrather withotherresid- uallifestyle factors notfully adjusted for intheanalysis. However, therelationship withgonococcal involvement ofaspecific anatomicsitelendssupport toabiologi- calassociation betweengonorrhoea and HIVinfection, rather thantoalternative non-biologic explanations. Our findings are consistent withprevious studies reporting an association betweenHIV infection and non-ulcerative sexually transmitted diseases. Suchadirect asso- ciation mightbeexplained bypostulating thatgonorrhoea results ininflamed rec- talmucosa andcompromised epithelial integrity, thereby predisposing an indi- vidual tosubsequent HIVinfection. (Genitourin Med1995;71:150-154)",1995,
Marginalized lasso in sparse regression,"Abstract We propose marginalized lasso, a new nonconvex penalization for variable selection in regression problem. The marginalized lasso penalty is motivated from integrating out the penalty parameter in the original lasso penalty with a gamma prior distribution. This study provides a thresholding rule and a lasso-based iterative algorithm for parameter estimation in the marginalized lasso. We also provide a coordinate descent algorithm to efficiently optimize the marginalized lasso penalized regression. Numerical comparison studies are provided to demonstrate its competitiveness over the existing sparsity-inducing penalizations and suggest some guideline for tuning parameter selection.",2019,Journal of The Korean Statistical Society
Synergistic drug combinations from electronic health records and gene expression,"Objective
Using electronic health records (EHRs) and biomolecular data, we sought to discover drug pairs with synergistic repurposing potential. EHRs provide real-world treatment and outcome patterns, while complementary biomolecular data, including disease-specific gene expression and drug-protein interactions, provide mechanistic understanding.


Method
We applied Group Lasso INTERaction NETwork (glinternet), an overlap group lasso penalty on a logistic regression model, with pairwise interactions to identify variables and interacting drug pairs associated with reduced 5-year mortality using EHRs of 9945 breast cancer patients. We identified differentially expressed genes from 14 case-control human breast cancer gene expression datasets and integrated them with drug-protein networks. Drugs in the network were scored according to their association with breast cancer individually or in pairs. Lastly, we determined whether synergistic drug pairs found in the EHRs were enriched among synergistic drug pairs from gene-expression data using a method similar to gene set enrichment analysis.


Results
From EHRs, we discovered 3 drug-class pairs associated with lower mortality: anti-inflammatories and hormone antagonists, anti-inflammatories and lipid modifiers, and lipid modifiers and obstructive airway drugs. The first 2 pairs were also enriched among pairs discovered using gene expression data and are supported by molecular interactions in drug-protein networks and preclinical and epidemiologic evidence.


Conclusions
This is a proof-of-concept study demonstrating that a combination of complementary data sources, such as EHRs and gene expression, can corroborate discoveries and provide mechanistic insight into drug synergism for repurposing.",2017,Journal of the American Medical Informatics Association : JAMIA
Highly Sensitive Marker Panel for Guidance in Lung Cancer Rapid Diagnostic Units,"While evidence for lung cancer screening implementation in Europe is awaited, Rapid Diagnostic Units have been established in many hospitals to accelerate the early diagnosis of lung cancer. We seek to develop an algorithm to detect lung cancer in a symptomatic population attending such unit, based on a sensitive serum marker panel. Serum concentrations of Epidermal Growth Factor, sCD26, Calprotectin, Matrix Metalloproteinases -1, -7, -9, CEA and CYFRA 21.1 were determined in 140 patients with respiratory symptoms (lung cancer and controls with/without benign pathology). Logistic Lasso regression was performed to derive a lung cancer prediction model, and the resulting algorithm was tested in a validation set. A classification rule based on EGF, sCD26, Calprotectin and CEA was established, able to reasonably discriminate lung cancer with 97% sensitivity and 43% specificity in the training set, and 91.7% sensitivity and 45.4% specificity in the validation set. Overall, the panel identified with high sensitivity stage I non-small cell lung cancer (94.7%) and 100% small-cell lung cancers. Our study provides a sensitive 4-marker classification algorithm for lung cancer detection to aid in the management of suspicious lung cancer patients in the context of Rapid Diagnostic Units.",2017,Scientific Reports
Texture analysis on gadoxetic acid enhanced-MRI for predicting Ki-67 status in hepatocellular carcinoma: A prospective study,"Objective
To investigate the value of whole-lesion texture analysis on preoperative gadoxetic acid enhanced magnetic resonance imaging (MRI) for predicting tumor Ki-67 status after curative resection in patients with hepatocellular carcinoma (HCC).


Methods
This study consisted of 89 consecutive patients with surgically confirmed HCC. Texture features were extracted from multiparametric MRI based on whole-lesion regions of interest. The Ki-67 status was immunohistochemical determined and classified into low Ki-67 (labeling index â‰¤15%) and high Ki-67 (labeling index >15%) groups. Least absolute shrinkage and selection operator (LASSO) and multivariate logistic regression were applied for generating the texture signature, clinical nomogram and combined nomogram. The discrimination power, calibration and clinical usefulness of the three models were evaluated accordingly. Recurrence-free survival (RFS) rates after curative hepatectomy were also compared between groups.


Results
A total of 13 texture features were selected to construct a texture signature for predicting Ki-67 status in HCC patients (C-index: 0.878, 95% confidence interval: 0.791-0.937). After incorporating texture signature to the clinical nomogram which included significant clinical variates (AFP, BCLC-stage, capsule integrity, tumor margin, enhancing capsule), the combined nomogram showed higher discrimination ability (C-index: 0.936vs. 0.795, P<0.001), good calibration (P>0.05 in Hosmer-Lemeshow test) and higher clinical usefulness by decision curve analysis. RFS rate was significantly lower in the high Ki-67 group compared with the low Ki-67 group after curative surgery (63.27%vs. 85.00%, P<0.05).


Conclusions
Texture analysis on gadoxetic acid enhanced MRI can serve as a noninvasive approach to preoperatively predict Ki-67 status of HCC after curative resection. The combination of texture signature and clinical factors demonstrated the potential to further improve the prediction performance.",2019,Chinese Journal of Cancer Research
Some Methods Of Quantile Regression For Analysis Of The Poverty In Iraq,"World Bank has mentioned that approximately half of the worldâ€™s poor people live in countries with high income and many of these countries are oil producer countries. In this paper we study some of the economic variables (unemployment, average monthly per capita income, average monthly per capita spending on basic food, the rise in prices of these basic food goods and average taxes imposed on the Iraqi citizen) that impact on the increasing number of poor households in Iraq. We employ a regression model based on classical quantile regression for building the models which represent the relationship between the response variable and the covariates, through five quantile lines (0.16, 0.33, 0.50, 0.66, 0.83). We also use Bayes Lasso quantile regression for variable selection. The data were taken from an economic survey made by the Central Bureau of Statistics in 2007. We use R packages quantreg and bayesQR",2016,
Cancer mortality intheBritish rubber industry,"Themortality experienced byacohort of36445rubber workers during 1946-80 hasbeen investigated. Theseworkers were allmaleoperatives first employed inany one ofthe13par- ticipating factories in1946-60; allhadworked continuously intheindustry for aminimumperiod ofone year.Compared withthegeneral population, statistically significant excessesrelating to cancermortality werefound for cancerofthestomach (E= 245-9, 0 = 282, SMR = 115), primary canceroftheliver (E= 12-8, 0 = 22,SMR = 172), cancerofthelung(E= 892-7, 0 = 1191, SMR = 133), andallneoplasms (E= 2165-2, 0 = 2487,SMR = 115). Statistically significant deficits werefound for canceroftheprostate (E= 79.7, 0 = 59,SMR = 74)andcancerofthetestis (E= 10-3, 0 = 4,SMR = 39). Themethod ofregression models inlife tables (RMLT)was used to comparetheduration ofemployment intheindustry, theduration in""dust exposed"" jobs, andthe duration in""fumeand/or solvent exposed"" jobsofthose dying from causesofinterest withthose of allmatching survivors. Significant positive associations werefoundonlyfor cancerofthestomach andcancerofthelung. Theresults oftheRMLT analysis areindependent ofthose fromtheSMR analysis, andthestudy hasprovided further evidence ofacausal association between therisks of lungandstomach cancerandcertain occupational exposuresintherubber industry. In1982theHealth Research UnitoftheBritish Rub- berManufacturers' Association andtheCancer Epidemiology Research UnitoftheUniversity of Birmingham published a reportdescribing themor- tality experience ofa large cohort ofrubber workers intheUnited Kingdom.' Thestudy found an""overall excesscancermortality intheBritish rubber industry thatisaccounted foralmost entirely bytheobserved excessoflungandstomach cancer."" Apartfroma small excessofoesophageal cancer,there was no evi- denceofany significant excesscancermortality for othersites ofcancer.Theabsence ofany excessof bladder canceraffecting men whoentered theindus- tryafter 1950 was noted. AnIARCworking groupalsopublished an evalu- ation ofcarcinogenic risks intherubber industry in thesame year.2Forlung cancerandstomach cancer, this reportconcluded thatthere was sufficient evi- denceforan excessoccurrenceinrubber workers and limited evidence fora causalassociation with occupational exposures.",1986,
Recurrenceâ€associated gene signature optimizes recurrenceâ€free survival prediction of colorectal cancer,"High throughput gene expression profiling has showed great promise in providing insight into molecular mechanisms. Metastasis-related mRNAs may potentially enrich genes with the ability to predict cancer recurrence, therefore we attempted to build a recurrence-associated gene signature to improve prognostic prediction of colorectal cancer (CRC). We identified 2848 differentially expressed mRNAs by analyzing CRC tissues with or without metastasis. For the selection of prognostic genes, a LASSO Cox regression model (least absolute shrinkage and selection operator method) was employed. Using this method, a 13-mRNA signature was identified and then validated in two independent Gene Expression Omnibus cohorts. This classifier could successfully discriminate the high-risk patients in discovery cohort [hazard ratio (HR)Â =Â 5.27, 95% confidence interval (CI) 2.30-12.08, PÂ <Â 0.0001). Analysis in two independent cohorts yielded consistent results (GSE14333: HRÂ =Â 4.55, 95%Â CI 2.18-9.508, PÂ <Â 0.0001; GSE33113: HRÂ =Â 3.26, 95% CI 2.16-9.16, PÂ =Â 0.0176). Further analysis revealed that the prognostic value of this signature was independent of tumor stage, postoperative chemotherapy and somatic mutation. Receiver operating characteristic (ROC) analysis showed that the area under ROC curve of this signature was 0.8861 and 0.8157 in the discovery and validation cohort, respectively. A nomogram was constructed for clinicians, and did well in the calibration plots. Furthermore, this 13-mRNA signature outperformed other known gene signatures, including oncotypeDX colon cancer assay. Single-sample gene-set enrichment analysis revealed that a group of pathways related to drug resistance, cancer metastasis and stemness were significantly enriched in the high-risk patients. In conclusion, this 13-mRNA signature may be a useful tool for prognostic evaluation and will facilitate personalized management of CRC patients.",2017,Molecular Oncology
A New Multiple Single-Nucleotide Polymorphisms Based Predictive Model for Grades III to IV and Extensive Graft Versus Host Disease after Identical HLA-Allogeneic Stem-Cell,"![Graphic][1] 

Introduction

Graft versus host disease (GVHD) is the main cause of morbi-mortality after allogeneic stem cell transplantation (allo-SCT). Despite considerable advances in our understanding of the pathophysiology, nowdays anticipation of GVHD is an unresolved matter. Several single-nucleotide polymorphisms (SNPs) in cytokine genes have shown to be associated with donor-recipient alloreactivity and, ultimately, with SCT outcome. In the present study, we propose a novel predictive model based on both clinical and genetic (SNP) variables applying an innovative estimation linear regression model, the least absolute shrinkage and selection operator (LASSO), in a large cohort of HLA-identical sibling donor allo-SCT.

Patients and Methods

The study evaluated 25 SNPs in 12 genes (Table 1) in genomic DNA obtained from PB samples from 273 patients with available acute GVHD (aGVHD) data and 213 patients with chronic GVHD (cGVHD) data included in the DNA Bank of the Spanish Group for Hematopoietic Stem Cell Transplantation (GETH) and their HLA-identical sibling donors. Each SNP was assessed for different models of transmission (recessive, dominant, co-dominant and additive), producing 25 SNPs x 4 models = 100 variables. Clinical variables known to influence the development of GVHD were also considered (Table 1). Univariate regression analysis was performed using Cox regression (data not shown). Multivariant analysis was made with LASSO, an innovative estimation method for linear regression models which is able to select a set of optimal predictors from a large set of potential predictor variables and was considered as a variables selection method under the estimation of a Logit regression model. In this model, the strength of the penalty term is controlled by a smoothing parameter (Î»), which is chosen by maximizing the area under ROC curve (AUC) and the correct classification rate (CCR). The statistical model was fitted (goodness-of-fit assessment) by randomly selecting the 85% of the data (the so-called ""training set""), and the predictive ability was computed with the remaining 15% (the so-called ""testing set""). In order to evaluate the performance and the prediction ability of each model, training and testing samples were randomly selected a total of 100 times. The distribution of the CCR and the AUC over the 100 samplings, were shown by means of box plots and statistical summary in the results data. Finally, for prediction purposes, we considered a cut-off value according to the proportion of Y=1 in the sample (0.28 for grades II-IV aGVHD, 0.11 for grades III-IV aGVHD and 0.30 for extensive cGVHD).

Results

The best model to predict aGVHD II-IV included 11 genetic variables and no clinical variables with a CCR for patients who developed (CCR1) aGVHD II-IV of 63.6% (Figure 2). The best model to predict aGVHD III-IV included 20 genetic and 7 clinical variables with a CCR1 for aGVHD III-IV of 100%. The best model to predict extensive chronic GVHD included 10 genetic and 3 clinical variables with a CCR1 for extensive cGVHD of 80%. On the other hand, predictive models with only clinical variables showed a poorer CCR1 for patients who developed aGVHD II-IV, aGVHD III-IV and extensive cGVHD (55.6%, 50% and 66.7% respectively; Figure 1). Based on the results from LASSO multivariate analyses, a risk score was calculated for grades II-IV and III-IV aGVHD as well as for cGVHD and extensive cGVHD. Patients were categorized into two groups: low risk (below the cut-off value) and high risk (above the cut-off). Such risk model was able to stratify patients who develop grades II-IV aGVHD (p<0.001), grades III-IV aGVHD (p<0.001) and extensive cGVHD (p<0.001) more consistently than models only considering clinical variables (Figure 2).

Conclusions

Identification of biomarkers useful for the estimation of the risk of GVHD constitutes an unmet need in the clinical management of GVHD. The novel predictive model proposed here, based on clinical and genetic factors, allows significantly improved anticipation of aGVHD III-IV (100% accuracy) and extensive cGVHD (80%) after HLA-identical sibling donor allo-SCT. This approach would allow a personalized risk-adapted clinical management of patients after transplantation.

![Figure][2] 



![Figure][2] 

![Figure][2] 

Disclosures No relevant conflicts of interest to declare.

 [1]: /embed/inline-graphic-2.gif
 [2]: pending:yes",2015,Blood
Validation of an Electronic Medical Record-Based Algorithm for Identifying Posttraumatic Stress Disorder in U.S. Veterans.,"We developed an algorithm for identifying U.S. veterans with a history of posttraumatic stress disorder (PTSD), using the Department of Veterans Affairs (VA) electronic medical record (EMR) system. This work was motivated by the need to create a valid EMR-based phenotype to identify thousands of cases and controls for a genome-wide association study of PTSD in veterans. We used manual chart review (n = 500) as the gold standard. For both the algorithm and chart review, three classifications were possible: likely PTSD, possible PTSD, and likely not PTSD. We used Lasso regression with cross-validation to select statistically significant predictors of PTSD from the EMR and then generate a predicted probability score of being a PTSD case for every participant in the study population (range: 0-1.00). Comparing the performance of our probabilistic approach (Lasso algorithm) to a rule-based approach (International Classification of Diseases [ICD] algorithm), the Lasso algorithm showed modestly higher overall percent agreement with chart review than the ICD algorithm (80% vs. 75%), higher sensitivity (0.95 vs. 0.84), and higher accuracy (AUC = 0.95 vs. 0.90). We applied a 0.7 probability cut-point to the Lasso results to determine final PTSD case-control status for the VA population. The final algorithm had a 0.99 sensitivity, 0.99 specificity, 0.95 positive predictive value, and 1.00 negative predictive value for PTSD classification (grouping possible PTSD and likely not PTSD) as determined by chart review. This algorithm may be useful for other research and quality improvement endeavors within the VA.",2019,Journal of traumatic stress
Optimal Regularization in Distribution of Relaxation Times applied to Electrochemical Impedance Spectroscopy: Ridge and Lasso Regression Methods - A Theoretical and Experimental Study,"The Distribution of Relaxation Times (DRT) is an approach of particular interest to the interpretation of Electrochemical Impedance Spectroscopy (EIS) measurements. The DRT allows direct access to the time characteristics of the electrochemical system under study. Obtaining the DRT from noisy EIS data requires solving an ill-posed problem using regularization methods. In this work we investigate the optimal choice of the regularization parameter in the case of ridge regression. For this purpose we propose two novel sets of test functions known as real and imaginary discrepancy test function, and real and imaginary cross-validation test functions. Furthermore, we show the validity of these tests with synthetic and real experiments. By applying the optimal regularization parameters, the DRT results from the synthetic experiments (an RC circuit, a ZARC, and a fractal element) successfully reproduce the known exact DRT. Additionally, in the cases taken from electrochemical practice (a collection of RC circuits, a symmetric cell, and a commercial Li-ion battery) our approach confirms the ability to identify various timescales. Additionally, we study the output of the regularization using Least Absolute Shrinkage and Selection Operator (Lasso) and we highlight the added value given by the synergetic use of Lasso and ridge regression.",2014,Electrochimica Acta
Regression for Analysis of Genomic Data,"We consider estimation and variable selection in high-dimensional Cox regression when a prior knowledge of the relationships among the covariates, de- scribed by a network or graph, is available. A limitation of the existing methodology for survival analysis with high-dimensional genomic data is that a wealth of struc- tural information about many biological processes, such as regulatory networks and pathways, has often been ignored. In order to incorporate such prior network information into the analysis of genomic data, we propose a network-based regu- larization method for high-dimensional Cox regression, by using an '1-penalty to induce sparsity of the regression coecients and a quadratic Laplacian penalty to encourage smoothness between the coecients of neighboring variables on a given network. The proposed method is implemented by an ecient coordinate descent algorithm. In the setting where the dimensionality p may grow exponentially fast with the sample size n, we establish model selection consistency and estimation bounds for the proposed estimators. The theoretical results provide insights into the gain from taking into account the network structural information. Extensive simulation studies indicate that our method outperforms Lasso and elastic net in terms of variable selection accuracy and stability. We apply our method to a breast cancer gene expression study and identify several biologically plausible subnetworks and pathways that are associated with breast cancer distant metastasis.",2013,
A classification model for predicting diabetic retinopathy based on patient characteristics and biochemical measures,"Purpose: In the United Kingdom (UK), The NHS Diabetic Eye Screening Program offers an annual eye examination to all people with diabetes aged 12 or over, aiming at the early detection of people at high risk of visual loss due to diabetic retinopathy. The purpose of this study was the design of a model to predict patients at risk of developing retinopathy with the use of patient characteristics and clinical measures.Â  Methods: We investigated data from 2011 to 2016 from the population-based Diabetic Eye Screening Program in East Anglia. The data comprised retinal eye screening results, patient characteristics, and routine biochemical measures of HbA1c, blood pressure, Albumin to Creatinine ratio (ACR), estimated Glomerular Filtration rate (eGFR), serum creatinine, cholesterol and Body Mass Index (BMI). Individuals were classified according to the presence or absence of retinopathy as indicated by their retinal eye examinations. A lasso regression, random forest, gradient boosting machine and regularized gradient boosting model were built and cross-validated for their predictive ability.Â  Results: A total of 6,375 subjects with recorded information for all available biochemical measures were identified from the cohorts. Of these, 5,969 individuals had no signs of diabetic retinopathy. Of the remainder 406 individuals with signs of diabetic retinopathy, 352 had background diabetic retinopathy and 54 had referable diabetic retinopathy. The highest value of the10-fold cross-validated Area under the Curve (AUC) was achieved by the gradient boosting machine 0.73 Â± 0.03 and the minimum required set of variables to yield this performance included 4 variables: duration of diabetes, HbA1c, ACR and age. A subsequent analysis on the predictive power of the biochemical measures showed that when HbA1c and ACR measurements were available for longer time periods, the performance of the models was greatly enhanced. When HbA1c and ACR measurements for a 5-year period prior to the event of study were available, gradient boosting machine cross-validated AUC was 0.77 Â± 0.04 in comparison to the cross-validated AUC of 0.68 Â± 0.04 when only information for the 1-year period for these variables was available. Similarly, an increment from 0.70 Â± 0.02 to 0.75 Â± 0.04 was observed with random forest. The dataset with the 1-year measurements comprised 4,857 subjects, of whom, 4,572 had no retinopathy and the remainder 285 had signs of retinopathy. The dataset with the 5-year measurements comprised 757 subjects, of whom, 696 had no retinopathy and the remainder 51 had signs of retinopathy.Â  Conclusions: The utilization of patient information and routine biochemical measures can be used to identify patients at risk of developing retinopathy. The effective differentiation between patients with and without retinopathy could significantly reduce the number of screening visits without compromising patientsâ€™ health.",2017,
Pd13-12â€ƒtof-ms Based Urine Dna Methylation Classifier: a Fast and Effective Technique for Non-invasive Diagnosis and Monitoring of Bladder Cancer,"INTRODUCTION AND OBJECTIVES: The gold standard method used to detect and monitor bladder cancer is cystoscopy, which leads to high diagnostic costs and a high patient burden. The currently available non-invasive approaches either show unsatisfying sensitivity in low-grade tumors or possess limited specificity. This study aimed to develop a new non-invasive strategy based on urine methylation biomarker to diagnose bladder cancer effectively. METHODS: To identify the bladder cancer specific markers, genome-wide methylation analysis was performed on 21 paired bladder tumors and normal tissues from The Cancer Genome Atlas (TCGA) cohort, and 20 paired bladder tumors and normal tissues from Sun Yat-sen Memorial Hospital (SYMH) cohort. Next, Time of Flight Mass Spectrometer (TOF-MS) analysis was performed to access markers efficiency in large cohort. We enrolled 423 patients diagnosed with bladder cancer, 82 healthy participants and 276 controls with benign diseases from SYMH cohort. DNA of 781 urine samples extracted from the urinary cells and bisulfite modificated, and methylation status was analyzed using TOF-MS. In training set, 314 urine samples were used to develop a gene classifier by LASSO regression. An additional 467 urine samples were analyzed using the 5-gene classifier for independent validation. RESULTS: We firstly identified 40 significant methylation markers in a combined analysis of TCGA cohort and SYMH cohort. 28 of 40 markers showed good concordance (87.0%) in the assessments of patient tumor tissues and urine. The TOF-MS based methylation classifier yield a good AUC of 0.915 (with a sensitivity of 89.3% and a specificity of 83.6%) in the training group. The validation group also showed an AUC of 0.903, with a sensitivity of 88.1% and a specificity of 82.4%. The methylation classifier also exhibited a significantly improved sensitivity compared to voided urine cytology and FISH. In addition, this approach could analyze 128 samples in max one time and provide clinical report less than 2 days, which facilitated doctor make decision on time. CONCLUSIONS: TOF-MS based urine DNA methylation classifier showed high accuracy and strong diagnostic power, even in early-stage/low-grade tumor patients. Therefore, it may be used as a non-invasive fast and high-through approach for diagnosis and recurrence surveillance in bladder cancer prior to the use of cystoscopy, which would greatly reduce the burden on patients. Source of Funding: This study was supported by the National Natural Science Foundation of China (Grant No. 81825016, 81702523)",2019,The Journal of Urology
Accelerating band gap prediction for solar materials using feature selection and regression techniques,"Abstract We present a novel approach to apply machine learning techniques to build a more robust prediction model for band-gap energies (BG-E) of chalcopyrites, a class of materials for energy applications in the fields of solar energy, photocatalysis, and thermoelectrics. Guided by knowledge from domain experts and by previous works on the field, we aim to accelerate the discovery of new solar materials. Our objectives are two folds: (i) Identify the optimal set of features that best describes a given predicted variable. (ii) Boost prediction accuracy via applying various regression algorithms. Ordinary Least Square, Partial Least Square and Lasso regressions, combined with well adjusted feature selection techniques are applied and tested to predict the band gap energy of chalcopyrites materials. Compared to the results reported in Zeng et al. (2002), Suh et al. (1999, 2004), and Dey et al. (2014), our approach shows that learning and using only a subset of relevant features can improve the prediction accuracy by about 40 % .",2018,Computational Materials Science
Health Data Driven on Continuous Blood Pressure Prediction Based on Gradient Boosting Decision Tree Algorithm,"Diseases related to issues with blood pressure are becoming a major threat to human health. With the development of telemedicine monitoring applications, a growing number of corresponding devices are being marketed, such as the use of remote monitoring for the purposes of increasing the autonomy of the elderly and thus encouraging a healthier and longer health span. Using machine learning algorithms to measure blood pressure at a continuous rate is a feasible way to provide models and analysis for telemedicine monitoring data and predicting blood pressure. For this paper, we applied the gradient boosting decision tree (GBDT) while predicting blood pressure rates based on the human physiological data collected by the EIMO device. EIMO equipment-specific signal acquisition includes ECG and PPG. In order to avoid over-fitting, the optimal parameters are selected via the cross-validation method. Consequently, our method has displayed a higher accuracy rate and better performance in calculating the mean absolute error evaluation index than methods, such as the traditional least squares method, ridge regression, lasso regression, ElasticNet, SVR, and KNN algorithm. When predicting the blood pressure of a single individual, calculating the systolic pressure displays an accuracy rate of above 70% and above 64% for calculating the diastolic pressure with GBDT, with the prediction time being less than 0.1 s. In conclusion, applying the GBDT is the best method for predicting the blood pressure of multiple individuals: with the inclusion of data such as age, body fat, ratio, and height, algorithm accuracy improves, which in turn indicates that the inclusion of new features aids prediction performance.",2019,IEEE Access
Penalized Regression Methods in Time Series and Functional Data Analysis,"In this thesis, we study penalized methods in time series and functional data analysis. In the first part, we introduce regularized periodograms for spectral analysis of unevenly spaced time series. The regularized periodograms, called regularized least squares periodogram and regularized quantile periodogram, are derived from trigonometric least squares and quantile regression with Group Lasso penalty. A simple model provides a theoretical justification for the use of regularized least squares periodogram as a tool for detecting hidden frequency in the time series. We give a data-dependent procedure for selection of the regularization parameter. An extensive simulation studies are conducted to examine whether our periodogram functions have the power to detect frequencies from the unevenly spaced time series with big gaps and outliers. In the second part, we propose a penalized likelihood approach for the estimation of the spectral density of a stationary time series. The approach involves L1 penalties, which were shown to be an attractive regularization device for nonparametric regression, image reconstruction, and model selection. We explore the use of penalties based on the total variation of the estimated derivatives of spectral density. An asymptotic analysis of the integrated absolute error between the estimator and the true spectral density is presented and gives a consistency result under certain regularity conditions. We also investigate the convergence of the total variation penalized Whittle likelihood estimator to the true spectral density via simulations. In the third part, we treat discrete time series data have as functional covariates in functional regression models with a scalar response. We develop an efficient",2017,
