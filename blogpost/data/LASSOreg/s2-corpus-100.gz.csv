title,abstract,year,journal
Efficient Feature Group Sequencing for Anytime Linear Prediction,"We consider \textit{anytime} linear prediction in the common machine learning setting, where features are in groups that have costs. We achieve anytime (or interruptible) predictions by sequencing the computation of feature groups and reporting results using the computed features at interruption. We extend Orthogonal Matching Pursuit (OMP) and Forward Regression (FR) to learn the sequencing greedily under this group setting with costs. We theoretically guarantee that our algorithms achieve near-optimal linear predictions at each budget when a feature group is chosen. With a novel analysis of OMP, we improve its theoretical bound to the same strength as that of FR. In addition, we develop a novel algorithm that consumes cost $4B$ to approximate the optimal performance of \textit{any} cost $B$, and prove that with cost less than $4B$, such an approximation is impossible. To our knowledge, these are the first anytime bounds at \textit{all} budgets. We test our algorithms on two real-world data-sets and evaluate them in terms of anytime linear prediction performance against cost-weighted Group Lasso and alternative greedy algorithms.",2016,ArXiv
Urban distribution grid topology reconstruction via Lasso,"The growing integration of distributed energy resources (DERs) in urban areas raises various reliability issues. To ensure robust distribution grid operation, grid monitoring tools are needed, where the topology reconstruction serves as the first step. However, the topology reconstruction is hard in distribution grid. This is because 1) the branches are difficult and expensive to monitor since most of them are underground in urban areas; and 2) the assumption of radial topology in many studies is inappropriate for meshed urban grids. To address these drawbacks, we propose a new data-driven approach to reconstruct distribution grid topology by utilizing the newly available smart meter data. Specifically, a graphical model is built to model the probabilistic relationships among different voltage measurements. With proof, the topology reconstruction problem is formulated as a regularized linear regression problem (Lasso) to deal with meshed network structures. Simulation results show highly accurate estimation in IEEE standard distribution test systems with and without loops using real smart meter data.",2016,2016 IEEE Power and Energy Society General Meeting (PESGM)
Characterization and machine learning prediction of allele-specific DNA methylation.,"A large collection of Single Nucleotide Polymorphisms (SNPs) has been identified in the human genome. Currently, the epigenetic influences of SNPs on their neighboring CpG sites remain elusive. A growing body of evidence suggests that locus-specific information, including genomic features and local epigenetic state, may play important roles in the epigenetic readout of SNPs. In this study, we made use of mouse methylomes with known SNPs to develop statistical models for the prediction of SNP associated allele-specific DNA methylation (ASM). ASM has been classified into parent-of-origin dependent ASM (P-ASM) and sequence-dependent ASM (S-ASM), which comprises scattered-S-ASM (sS-ASM) and clustered-S-ASM (cS-ASM). We found that P-ASM and cS-ASM CpG sites are both enriched in CpG rich regions, promoters and exons, while sS-ASM CpG sites are enriched in simple repeat and regions with high frequent SNP occurrence. Using Lasso-grouped Logistic Regression (LGLR), we selected 21 out of 282 genomic and methylation related features that are powerful in distinguishing cS-ASM CpG sites and trained the classifiers with machine learning techniques. Based on 5-fold cross-validation, the logistic regression classifier was found to be the best for cS-ASM prediction with an ACC of 0.77, an AUC of 0.84 and an MCC of 0.54. Lastly, we applied the logistic regression classifier on human brain methylome and predicted 608 genes associated with cS-ASM. Gene ontology term enrichment analysis indicated that these cS-ASM associated genes are significantly enriched in the category coding for transcripts with alternative splicing forms. In summary, this study provided an analytical procedure for cS-ASM prediction and shed new light on the understanding of different types of ASM events.",2015,Genomics
A Genomic Classifier for Predicting Clinically Aggressive Luminal Bladder Tumors with Higher Rates of Pathological Upstaging.,"BACKGROUND
Urothelial carcinoma (UC) of the luminal molecular subtype is associated with lower rates of pathological upstaging from clinical stage T1-T2 to non-organ confined (NOC; â‰¥pT3 and/or pN+) disease at radical cystectomy (RC). However, approximately one-third of luminal UC were upstaged to NOC disease, and these patients may be undertreated if neoadjuvant chemotherapy (NAC) is withheld. Here, we trained a genomic classifier to predict luminal NOC disease in patients diagnosed with clinically organ confined (OC; cT1/T2) disease.


MATERIALS & METHODS
Specimens from transurethral resected high grade cT1-T2N0M0 UC of the bladder that belonged to the luminal subtype (Seiler 2017) were randomly split into training (n=75) and testing (n=25) sets for the development of a single-sample luminal upstaging classifier (LUC) using lasso/ridge-penalized logistic regression. All patients underwent RC without NAC and the primary endpoint was upstaging to NOC disease. A radical cystectomy and a platinum-treated NAC cohort were used to evaluate the LUC.


RESULTS
Upstaging to NOC disease occurred in 34% of luminal patients. The LUC predicted upstaging in 32/34 cases, with six false positives (AUC 0.96). The sensitivity for detection of luminal pN+ disease was 95% (20/21). Patients with predicted NOC luminal tumors had worse survival than OC luminal tumors (p=0.001). On multivariable analysis, the LUC was a significant predictor of overall survival (OS) after adjusting for clinical variables available at time of transurethral resection. The LUC also predicted OS for aggressive luminal TCGA patients (n=83, p=0.043). In the NAC cohort, the LUC predicted nine upstaging cases, all of which had excellent prognosis.


CONCLUSION
A LUC was developed that distinguishes a subset of cT1-T2N0M0 luminal UC patients who are at high risk of upstaging to NOC at RC and of death. Validation of this model in an independent large patient cohort is necessary to determine how molecular stratification of luminal tumors could be used to guide treatment of these patients.",2020,The Journal of urology
Lasso tree for cancer staging with survival data.,"The tumor-node-metastasis staging system has been the lynchpin of cancer diagnosis, treatment, and prognosis for many years. For meaningful clinical use, an orderly grouping of the T and N categories into a staging system needs to be defined, usually with respect to a time-to-event outcome. This can be reframed as a model selection problem with respect to features arranged on a partially ordered two-way grid, and a penalized regression method is proposed for selecting the optimal grouping. Instead of penalizing the L1-norm of the coefficients like lasso, in order to enforce the stage grouping, we place L1 constraints on the differences between neighboring coefficients. The underlying mechanism is the sparsity-enforcing property of the L1 penalty, which forces some estimated coefficients to be the same and hence leads to stage grouping. Partial ordering constraints is also required as both the T and N categories are ordinal. A series of optimal groupings with different numbers of stages can be obtained by varying the tuning parameter, which gives a tree-like structure offering a visual aid on how the groupings are progressively made. We hence call the proposed method the lasso tree. We illustrate the utility of our method by applying it to the staging of colorectal cancer using survival outcomes. Simulation studies are carried out to examine the finite sample performance of the selection procedure. We demonstrate that the lasso tree is able to give the right grouping with moderate sample size, is stable with regard to changes in the data, and is not affected by random censoring.",2013,Biostatistics
Overlapping Group Logistic Regression with Applications to Genetic Pathway Selection,"Discovering important genes that account for the phenotype of interest has long been a challenge in genome-wide expression analysis. Analyses such as gene set enrichment analysis (GSEA) that incorporate pathway information have become widespread in hypothesis testing, but pathway-based approaches have been largely absent from regression methods due to the challenges of dealing with overlapping pathways and the resulting lack of available software. The R package grpreg is widely used to fit group lasso and other group-penalized regression models; in this study, we develop an extension, grpregOverlap, to allow for overlapping group structure using a latent variable approach. We compare this approach to the ordinary lasso and to GSEA using both simulated and real data. We find that incorporation of prior pathway information can substantially improve the accuracy of gene expression classifiers, and we shed light on several ways in which hypothesis-testing approaches such as GSEA differ from regression approaches with respect to the analysis of pathway data.",2016,Cancer Informatics
"Low-dimensional decomposition, smoothing and forecasting of sparse functional data","We propose a new generic method ROPES (Regularized Optimization for Prediction and Estimation with Sparse data) for decomposing, smoothing and forecasting two-dimensional sparse data. In some ways, ROPES is similar to Ridge Regression, the LASSO, Principal Component Analysis (PCA) and Maximum-Margin Matrix Factorisation (MMMF). Using this new approach, we propose a practical method of forecasting mortality rates, as well as a new method for interpolating and extrapolating sparse longitudinal data. We also show how to calculate prediction intervals for the resulting estimates.",2014,
Least Angle Regression and LASSO for Large Datasets,"Least-Angle Regression and the LASSO (`1-penalized regression) offer a number of advantages in variable selection applications over procedures such as stepwise or ridge regression, including prediction accuracy, stability and interpretability. We discuss formulations of these algorithms that extend to datasets in which the number of observations could be so large that it would not be possible to access the matrix of predictors as a unit in computations. Our methods require a single pass through the data for orthogonal transformation, effectively reducing the dimension of the computations required to obtain the regression coefficients and residual sums-of-squares to the number of predictors, rather than the number of observations.",2009,Statistical Analysis and Data Mining
A Novel Triage Tool of Artificial Intelligence Assisted Diagnosis Aid System for Suspected COVID-19 Pneumonia in Fever Clinics,"Background: Currently, the prevention and control of COVID-19 outside Hubei province in China, and other countries has become more and more critically serious. We developed and validated a diagnosis aid model without CT images for early identification of suspected COVID-19 pneumonia (S-COVID-19-P) on admission in adult fever patients and made the validated model available via an online triage calculator. 
 
Methods: Patients admitted from Jan 14 to Feb 26, 2020 with the epidemiological history of exposure to COVID-19 were included [Model development (n = 132) and validation (n = 32)]. Candidate features included clinical symptoms, routine laboratory tests and other clinical information on admission. Features selection and model development were based on Lasso regression. The primary outcome is the development and validation of a diagnosis aid model for S-COVID-19-P early identification on admission. 
 
Findings: The development cohort contains 26 S-COVID-19-P and 7 confirmed COVID-19 pneumonia cases. The final selected features included 1 variables of demographic information, 4 variables of vital signs, 5 variables of blood routine values, 7 variables of clinical signs and symptoms, 1 infection-related biomarker. The model performance in held-out testing set and validation cohort resulted in AUCs of 0.841 and 0.938, F-1 score of 0.571 and 0.667, recall of 1.000 and 1.000, specificity of 0.727 and 0.778, and the precision of 0.400 and 0.500. The top 5 important features were Age, IL-6, SYS_BP, MONO%, and Fever classification. Based on this model, an optimized strategy for S-COVID-19-P early identification in fever clinics has also been designed. 
 
Interpretation: S-COVID-19-P could be identified early by a machine-learning model only used collected clinical information without CT images on admission in fever clinics with 100% recall score. The well performed and validated model has been deployed as an online triage tool, which is available at: https://intensivecare.shinyapps.io/COVID19/ . 
 
Funding Statement: The present study was supported by grants from the PLA Science and Technology Project (14CXZ005, AWS15J004, 16BJZ19), National Key R&D Program of China (2019YFF0302300), Construction Project of Key Disciplines in the 13th Five-Year Plan of the PLA (Traumatic Surgery in the Battlefield, 2019-126, 2019-513), Beijing Science and Technology New Star Project (XX2018019/Z181100006218028), the PLA General Hospital Science and technology Project (2019XXJSYX20, 2018XXFC-20, ZH19016). 
 
Declaration of Interests: The authors declare that they have no conflict of interest. 
 
Ethics Approval Statement: Data collection was passive and had no impact on patient safety. This study was approved by the PLA General Hospital ethics committee.",2020,medRxiv
"Trust, but verify: benefits and pitfalls of least-squares refitting in high dimensions","Least-squares refitting is widely used in high dimensional regression to reduce the prediction bias of l1-penalized estimators (e.g., Lasso and Square-Root Lasso). We present theoretical and numerical results that provide new insights into the benefits and pitfalls of least-squares refitting. In particular, we consider both prediction and estimation, and we pay close attention to the effects of correlations in the design matrices of linear regression models, since these correlations - although often neglected - are crucial in the context of linear regression, especially in high dimensional contexts. First, we demonstrate that the benefit of least-squares refitting strongly depends on the setting and task under consideration: least-squares refitting can be beneficial even for settings with highly correlated design matrices but is not advisable for all settings, and least-squares refitting can be beneficial for estimation but performs better for prediction. Finally, we introduce a criterion that indicates whether least-squares refitting is advisable for a specific setting and task under consideration, and we conduct a thorough simulation study involving the Lasso to show the usefulness of this criterion.",2013,arXiv: Methodology
Abstract P2-03-11: Interaction between smoking history and gene expression levels impacts survival of breast carcinoma patients,"Our investigations explore the association of cigarette smoking on breast cancer risk of recurrence and progression, in contrast to studies that focused on tobacco use and risk of breast cancer occurrence. The goal was to decipher the interaction between smoking history and expression levels of 22 gene candidates selected from microarray data obtained from laser capture microdissected carcinoma cells from 247 de-identified patient tissue biopsies on disease recurrence and overall patient survival of breast cancer patients. qRT-PCR was used to determine expression levels for NAT1, NAT2, COMT, SOD1, SOD2, BRCA1, BRCA2, APOC1, ARID1B, CTNNBL1, MSX1, UBE2F, IRF2, NCOA1, LECT2, THAP4, RIPK1, AGPAT1, C7orf23, CENPN, CETN1 and YTHDC2 selected from a previous study for 50 breast cancer patients with a history of cigarette smoking and 51 patients who had never smoked. For smokers and non-smokers separately, L1-penalized multivariable Cox regression models were fit to predict patient disease-free and overall survival, with 1000 splits of the data into training (70%) and test (30%) sets to determine predictive accuracy based on the C-index. The LASSO penalty was used to perform variable selection in each of the training sets, and a permutation procedure was used to determine a significance threshold for the number of times a variable was kept in the model. Multivariable analyses using the LASSO revealed CENPN, CETN1, CYP1A1, IRF2, LECT2, and NCOA1 to be significant predictors for both disease recurrence and mortality among smokers. Additionally, COMT was highly associated with recurrence, and NAT1 and RIPK1 were associated with mortality. In contrast, only IRF2, CETN1, and CYP1A1 were significant for disease recurrence and mortality among non-smokers, with NAT2 additionally significant for survival. Median, 25th percentile, and 75th percentile for the C-indexes based on the gene expression models are given in Table 1. Analysis of interaction between smoking status and gene expression values using the combined samples revealed significant interactions between smoking status and CYP1A1, LECT2, CETN1. Molecular signatures consisting of 7-8 genes were highly predictive for breast cancer recurrence and overall survival among smokers, with median C-index values of 0.8 and 0.73 for overall survival and recurrence, respectively. In contrast, the median C-index values for non-smokers was only 0.59. Hence, significant interactions between expression of crucial genes and cigarette smoking status appear to play a key role in predicting clinical outcomes of breast carcinoma patients. Supported in part by a grant from the Phi Beta Psi Charity Trust (TSK & JLW) and a Research of Women (ROW) grant to JLW from the EVP for Research and Innovation, University of Louisville. Citation Format: James L Wittliff, Sarah A Andres, Mohammad A Alatoum, Katie E Bickett, Theodore S Kalbfleisch, Guy N Brock. Interaction between smoking history and gene expression levels impacts survival of breast carcinoma patients [abstract]. In: Proceedings of the Thirty-Seventh Annual CTRC-AACR San Antonio Breast Cancer Symposium: 2014 Dec 9-13; San Antonio, TX. Philadelphia (PA): AACR; Cancer Res 2015;75(9 Suppl):Abstract nr P2-03-11.",2015,Cancer Research
Quantifying dwarf shrub biomass in an arid environment: comparing empirical methods in a high dimensional setting,"Abstract Remote sensing based biomass estimation in arid environments is essential for monitoring degradation and carbon dynamics. However, due to the low vegetation cover in these regions, satellite-based research is challenging. Numerous potentially useful remotely-sensed predictor variables have been proposed, and several statistical and machine-learning techniques are available for empirical spatial modeling, but their predictive performance is yet unknown in this context. We therefore modeled total biomass in the Eastern Pamirs of Tajikistan, a region with extremely low vegetation cover, with a large set of satellite based predictors derived from two commonly used sensors (Landsat OLI, RapidEye), and assessed their utility in this environment using several suitable modeling approaches (stepwise, lasso, partial least squares and ridge regression, random forest). The best performing model (lasso regression) resulted in a RMSE of 992Â kgÂ haâˆ’Â 1 in spatial cross-validation, indicating that biomass quantification in this arid setting is feasible but subject to large uncertainties. Furthermore, pronounced over-fitting in some commonly used models (e.g. stepwise regression, random forest) underlined the importance of adequate variable selection and shrinkage techniques in spatial modeling of high dimensional data. The applied sensors showed very similar performance and a combination of both only slightly improved results of better performing models. A permutation-based assessment of variable importance showed that some of the most frequently used vegetation indices are not suitable for dwarf shrub biomass prediction in this environment. We suggest that predictor variables based on several bands accounting for vegetation as well as background information are required in this arid setting.",2015,Remote Sensing of Environment
An Adaptive Ridge Procedure for L0 Regularization,"Penalized selection criteria like AIC or BIC are among the most popular methods for variable selection. Their theoretical properties have been studied intensively and are well understood, but making use of them in case of high-dimensional data is difficult due to the non-convex optimization problem induced by L0 penalties. In this paper we introduce an adaptive ridge procedure (AR), where iteratively weighted ridge problems are solved whose weights are updated in such a way that the procedure converges towards selection with L0 penalties. After introducing AR its specific shrinkage properties are studied in the particular case of orthogonal linear regression. Based on extensive simulations for the non-orthogonal case as well as for Poisson regression the performance of AR is studied and compared with SCAD and adaptive LASSO. Furthermore an efficient implementation of AR in the context of least-squares segmentation is presented. The paper ends with an illustrative example of applying AR to analyze GWAS data.",2016,PLoS ONE
High-dimensional Gaussian and generalized linear mixed models,"Nowadays, statisticians are faced with new challenges due to the availability of high-dimensional data sets in many scientific fields such as biology and information technology. To be more precise, â€highdimensionalâ€ means that we consider situations where the number of observations is much smaller than the number of unknown model parameters. In the simplest example of a linear model, the ordinary least squares estimator is ill-posed in the high-dimensional setup. It is therefore necessary to make additional assumptions in order to deal with this problem. One common approach is based on a sparsity scenario. In other words, it is believed that only a few variables (out of hundreds or thousands) are relevant and hence only a small number of the unknown model parameters is indeed different from zero. Under this sparsity assumption, high-dimensional linear regression problems have been extensively studied over the past years. There has been substantial interest in Lasso-type estimators. The Lasso enforces sparsity by setting some model coefficients exactly to zero. In nearly all these works parameter estimation involves examining convex optimization problems. And therein convexity is a crucial tool for establishing nice statistical theory as well as for developing fast computational algorithms. However, in this thesis, we study a specific class of models involving regularized non-convex optimization problems. We specialise in high-dimensional data which are heterogenous in the sense that the observations are not independent but grouped. More precisely, we assume that observations between units are independent, but measurements within each unit are dependent. This kind of data structure leads to mixed-effects models. The purpose of the present work is to",2011,
"Prism: Multiple spline regression with regularization, dimensionality reduction, and feature selection","Prism uses a combination of statistical methods to conduct spline-based multiple regression. Prism conducts this regression using regularization, dimensionality reduction, and feature selection, through a combination of smoothing spline regression, PCA, and RVR/LASSO. Smoothing splines can be used to model non-parametric relationships using piece-wise cubic functions (Wahba and Wold 1975; Fox 2000). Relevance vector regression (RVR) refers to application of a relevance vector machine (RVM) to a regression problem; broadly, RVM is similar to multiple linear regression with regularization, using automatic relevance determination for feature selection (Tipping 2000). RVM shares many commonalities with SVM, and is implemented as a special case of a Sparse Bayesian framework (Tipping 2001; Tipping and Faul 2003).",2016,J. Open Source Software
Seismic Deconvolution Using Sparse Spike Inversion vs . Basis Pursuit Inversion,"In this paper, we compare two methods for seismic inversion Sparse Spike Inversion (SSI) and Basis Pursuit Inversion (BPI). Both methods utilize sparse inversion techniques. We employ a Least-Angle Regression (LARS) Least Absolute Shrinkage and Selection Operator (LASSO) solver for their implementation. Experimental results confirm that L1 penalization in the LASSO optimization improves the performance in terms of recovering reflection coefficients.",2015,
A Greedy Homotopy Method for Regression with Nonconvex Constraints,"The goal of this paper is to estimate sparse linear regression models, where for a given partition G of input variables, the selected variables are chosen from a diverse set of groups in G. We consider a novel class of nonconvex constraint functions, and develop RepLasso, a greedy homotopy method that exploits geometrical properties of the constraint functions to build a sequence of suitably adapted convex surrogate problems. We prove that in some situations RepLasso recovers the global minima path of the nonconvex problem. Moreover, even if it does not recover the global minima, we prove that it will often do no worse than the Lasso in terms of (signed) support recovery, while in practice outperforming it. We show empirically that the strategy can also be used to improve over various other Lasso-style algorithms. Finally, a GWAS of ankylosing spondylitis highlights our methodâ€™s practical utility.",2015,
Bauxite quality classification by shrinkage methods,"Abstract Geochemically, bauxite ore may contain some clay minerals, aluminum oxides-hydroxides, and insoluble materials such as quartz and magnetite. The amounts of the geochemical components and their ratios (modules) have critical importance in bauxite quality classification. A classification study was conducted by way of Al2O3/SiO2 module and its corresponding indicators such as spatial coordinates, thickness, and some of the geochemical contributors. The classification was made benefit of two advanced regularization methods such as ridge and the Lasso regression methods. Accuracy, interpretability and simplicity were appraised. Both the algorithms had influence on reducing variance. The smoothing levels of the algorithms also were discussed. The resulting classification provided by the strong estimators can provide a reliable tool for industrial decision making and control.",2018,Journal of Geochemical Exploration
Model-Consistent Sparse Estimation through the Bootstrap,"We consider the least-square linear regression problem with regularization by the $\ell^1$-norm, a problem usually referred to as the Lasso. In this paper, we first present a detailed asymptotic analysis of model consistency of the Lasso in low-dimensional settings. For various decays of the regularization parameter, we compute asymptotic equivalents of the probability of correct model selection. For a specific rate decay, we show that the Lasso selects all the variables that should enter the model with probability tending to one exponentially fast, while it selects all other variables with strictly positive probability. We show that this property implies that if we run the Lasso for several bootstrapped replications of a given sample, then intersecting the supports of the Lasso bootstrap estimates leads to consistent model selection. This novel variable selection procedure, referred to as the Bolasso, is extended to high-dimensional settings by a provably consistent two-step procedure.",2009,ArXiv
Application of support vector regression to genome-assisted prediction of quantitative traits,"A byproduct of genome-wide association studies is the possibility of carrying out genome-enabled prediction of disease risk or of quantitative traits. This study is concerned with predicting two quantitative traits, milk yield in dairy cattle and grain yield in wheat, using dense molecular markers as predictors. Two support vector regression (SVR) models, Îµ-SVR and least-squares SVR, were explored and compared to a widely applied linear regression model, the Bayesian Lasso, the latter assuming additive marker effects. Predictive performance was measured using predictive correlation and mean squared error of prediction. Depending on the kernel function chosen, SVR can model either linear or nonlinear relationships between phenotypes and marker genotypes. For milk yield, where phenotypes were estimated breeding values of bulls (a linear combination of the data), SVR with a Gaussian radial basis function (RBF) kernel had a slightly better performance than with a linear kernel, and was similar to the Bayesian Lasso. For the wheat data, where phenotype was raw grain yield, the RBF kernel provided clear advantages over the linear kernel, e.g., a 17.5% increase in correlation when using the Îµ-SVR. SVR with a RBF kernel also compared favorably to the Bayesian Lasso in this case. It is concluded that a nonlinear RBF kernel may be an optimal choice for SVR, especially when phenotypes to be predicted have a nonlinear dependency on genotypes, as it might have been the case in the wheat data.",2011,Theoretical and Applied Genetics
Strong rules for discarding predictors in lasso-type problems.,"We consider rules for discarding predictors in lasso regression and related problems, for computational efficiency. El Ghaoui and his colleagues have propose 'SAFE' rules, based on univariate inner products between each predictor and the outcome, which guarantee that a coefficient will be 0 in the solution vector. This provides a reduction in the number of variables that need to be entered into the optimization. We propose strong rules that are very simple and yet screen out far more predictors than the SAFE rules. This great practical improvement comes at a price: the strong rules are not foolproof and can mistakenly discard active predictors, i.e. predictors that have non-zero coefficients in the solution. We therefore combine them with simple checks of the Karush-Kuhn-Tucker conditions to ensure that the exact solution to the convex problem is delivered. Of course, any (approximate) screening method can be combined with the Karush-Kuhn-Tucker, conditions to ensure the exact solution; the strength of the strong rules lies in the fact that, in practice, they discard a very large number of the inactive predictors and almost never commit mistakes. We also derive conditions under which they are foolproof. Strong rules provide substantial savings in computational time for a variety of statistical optimization problems.",2012,"Journal of the Royal Statistical Society. Series B, Statistical methodology"
Sex dependent risk factors for mortality after myocardial infarction: individual patient data meta-analysis,"BackgroundAlthough a number of risk factors are known to predict mortality within the first years after myocardial infarction, little is known about interactions between risk factors, whereas these could contribute to accurate differentiation of patients with higher and lower risk for mortality. This study explored the effect of interactions of risk factors on all-cause mortality in patients with myocardial infarction based on individual patient data meta-analysis.MethodsProspective data for 10,512 patients hospitalized for myocardial infarction were derived from 16 observational studies (MINDMAPS). Baseline measures included a broad set of risk factors for mortality such as age, sex, heart failure, diabetes, depression, and smoking. All two-way and three-way interactions of these risk factors were included in Lasso regression analyses to predict time-to-event related all-cause mortality. The effect of selected interactions was investigated with multilevel Cox regression models.ResultsLasso regression selected five two-way interactions, of which four included sex. The addition of these interactions to multilevel Cox models suggested differential risk patterns for males and females. Younger women (age <50) had a higher risk for all-cause mortality than men in the same age group (HR 0.7 vs. 0.4), while men had a higher risk than women if they had depression (HR 1.4 vs. 1.1) or a low left ventricular ejection fraction (HR 1.7 vs. 1.3). Predictive accuracy of the Cox model was better for men than for women (area under the curves: 0.770 vs. 0.754).ConclusionsInteractions of well-known risk factors for all-cause mortality after myocardial infarction suggested important sex differences. This study gives rise to a further exploration of prediction models to improve risk assessment for men and women after myocardial infarction.",2014,BMC Medicine
The effect and correlation factors of segmental pulmonary veins isolation for paroxysmal and persistent atrial fibrillation,"Objective To evaluate the effect of segmental pulmonary veins isolation for atrial fibrillation (AF) and investigate the possible factors that may affect its result. Methods In 120 (105 men; age 50.0Â±8.6 years) consecutive patients with paroxysmal (n=99) or persistent (n=21) AF, segmental PVs electrical isolation with Lasso mapping catheters was performed. The relationship of the outcome of the initial procedure and factors such as age, sex, type of AF, left atrial diameter, case history, left ventricular ejection fraction and presence of hypertension were analyzed by statistical methods. Results 52 (52.5%) out of the 99 patients with paroxysmal AF and 6 (28.5%) out of the 21 with persistent AF were free of AF after a single ablation procedure. Univariate analysis revealed that left atrial enlargement (P=0.001), persistent AF (P=0.046) and old age (P=0.047) were related to the recurrence of AF after the first procedure. Patients with paroxysmal AF apparently had a better outcome than those with persistent AF after repeat ablation but of no statistical significance (P=0.094). Logistic regression analysis revealed that left atrial enlargement was the only independent risk factor of recurrent AF after the first procedure. Conclusion About 50% of the patients with paroxysmal AF are free of AF after single ablation. Left atrial enlargement is the only independent risk factor of recurrent AF while old age and persistent AF influence the outcome of the first procedure.",2005,Chinese Journal of Interventional Cardiology
Mobile application for predictive modelling in hurdles race,"This paper presents a mobile expert system for Android platform, named R-tificial Trainer, to support the work of a hurdles coach in planning training programmes. The main feature of the developed application is the ability to generate training loads and predict results for an athlete. It includes a database of players and allows the user to generate training plan in PDF format. The application has been tested on a dataset of athletes practising hurdles on the 110 metres. The database contains 120 training programmes made by 18 athletes. The application uses the Predictive Model Markup Language standard. The predictive models include linear models in the form of ordinary least squares and LASSO regressions and nonlinear model in the form of a multilayer perceptron with exponential function. To choose the best method, the leave-one-out cross-validation is used. The lowest validation error was achieved by multilayer perceptron.",2018,"2018 2nd International Conference on Technology and Innovation in Sports, Health and Wellbeing (TISHW)"
Comparison of subset selection methods in linear regression in the context of health-related quality of life and substance abuse in Russia,"BackgroundAutomatic stepwise subset selection methods in linear regression often perform poorly, both in terms of variable selection and estimation of coefficients and standard errors, especially when number of independent variables is large and multicollinearity is present. Yet, stepwise algorithms remain the dominant method in medical and epidemiological research.MethodsPerformance of stepwise (backward elimination and forward selection algorithms using AIC, BIC, and Likelihood Ratio Test, pâ€‰=â€‰0.05 (LRT)) and alternative subset selection methods in linear regression, including Bayesian model averaging (BMA) and penalized regression (lasso, adaptive lasso, and adaptive elastic net) was investigated in a dataset from a cross-sectional study of drug users in St. Petersburg, Russia in 2012â€“2013. Dependent variable measured health-related quality of life, and independent correlates included 44 variables measuring demographics, behavioral, and structural factors.ResultsIn our case study all methods returned models of different size and composition varying from 41 to 11 variables. The percentage of significant variables among those selected in final model varied from 100Â % to 27Â %. Model selection with stepwise methods was highly unstable, with most (and all in case of backward elimination: BIC, forward selection: BIC, and backward elimination: LRT) of the selected variables being significant (95Â % confidence interval for coefficient did not include zero). Adaptive elastic net demonstrated improved stability and more conservative estimates of coefficients and standard errors compared to stepwise. By incorporating model uncertainty into subset selection and estimation of coefficients and their standard deviations, BMA returned a parsimonious model with the most conservative results in terms of covariates significance.ConclusionsBMA and adaptive elastic net performed best in our analysis. Based on our results and previous theoretical studies the use of stepwise methods in medical and epidemiological research may be outperformed by alternative methods in cases such as ours. In situations of high uncertainty it is beneficial to apply different methodologically sound subset selection methods, and explore where their outputs do and do not agree. We recommend that researchers, at a minimum, should explore model uncertainty and stability as part of their analyses, and report these details in epidemiological papers.",2015,BMC Medical Research Methodology
A microRNA expression profile for vascular invasion can predict overall survival in hepatocellular carcinoma.,"BACKGROUND
The presence of vascular invasion (VI) in pathology specimens is a well-known unfavorable prognostic factor of hepatocellular carcinoma (HCC) recurrence and overall survival (OS). We investigated the vascular invasion related microRNA (miRNA) expression profiles and potential of prognostic value in HCC.


METHODS
MiRNA and mRNA expression data for HCC were accessed from The Cancer Genome Atlas (TCGA). LASSO logistic regression models were used to develop a miRNA-based classifier for predicting VI. The predictive capability was accessed by area under receiver operating characteristics (AUC). Concordance index (C-index) and time-dependent receiver operating characteristic (td-ROC) were used to determine its prognostic value. We validated the predictive and prognostic accuracy of this classifier in an external independent cohort of 127 patients. Functionally relevant targets of miRNAs were determined using miRNA target prediction, experimental validation and correlation of miRNA and mRNA expression data.


RESULTS
A 16-miRNA-based classifier was developed which identified VI accurately, with AUC of 0.731 and 0.727 in TCGA set and validation cohort, respectively. C-index and td-ROC showed that the classifier was able to stratify patients into risk groups strongly associated with OS. When stratified by tumor characteristics, the classifier was still a clinically and statistically significant prognostic model. The predictive and prognostic accuracy of the classifier was confirmed in validation cohort. Vascular invasion related miRNA/target pairs were identified by integrating expression patterns of predicted targets, which were validated in cell lines.


CONCLUSIONS
A multi-miRNA-based classifier developed based on the presence of VI, which could effectively predict OS in HCC.",2017,Clinica chimica acta; international journal of clinical chemistry
