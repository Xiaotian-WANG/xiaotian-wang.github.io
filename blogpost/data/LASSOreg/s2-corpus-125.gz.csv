title,abstract,year,journal
Additive Models for Quantile Regression: An Analysis of Risk Factors for Malnutrition in India,"This brief report describes some recent developments of the R quantreg package to incorporate methods for additive models. The methods are illustrated with an application to modeling childhood malnutrition in India. Models with additive nonparametric effects offer a valuable dimension re- duction device throughout applied statistics. In this paper we describe some recent developments of additive models for quantile regression. These meth- ods employ the total variation smoothing penalties introduced in (9) for uni- variate components and (7) for bivariate components. We focus on selection of smoothing parameters including lasso-type selection of parametric compo- nents, and on post selection inference methods. Additive models have received considerable attention since their intro- duction by Hastie and Tibshirani (1986, 1990). They provide a pragmatic approach to nonparametric regression modeling; by restricting nonparamet- ric components to be composed of low-dimensional additive pieces we can circumvent some of the worst aspects of the notorious curse of dimension- ality. It should be emphasized that we use the word ""circumvent"" advisedly, in full recognition that we have only swept difficulties under the rug by the assumption of additivity. When conditions for additivity are violated there will obviously be a price to pay.",2010,
Predicting disability progression in multiple sclerosis: Insights from advanced statistical modeling.,"BACKGROUND
There is an unmet need for precise methods estimating disease prognosis in multiple sclerosis (MS).


OBJECTIVE
Using advanced statistical modeling, we assessed the prognostic value of various clinical measures for disability progression.


METHODS
Advanced models to assess baseline prognostic factors for disability progression over 2â€‰years were applied to a pooled sample of patients from placebo arms in four different phase III clinical trials. least absolute shrinkage and selection operator (LASSO) and ridge regression, elastic nets, support vector machines, and unconditional and conditional random forests were applied to model time to clinical disability progression confirmed at 24â€‰weeks. Sensitivity analyses for different definitions of a combined endpoint were carried out, and bootstrap was used to assess prediction model performance.


RESULTS
A total of 1582 patients were included, of which 434 (27.4%) had disability progression in a combined endpoint over 2â€‰years. Overall model discrimination performance was relatively poor (all C-indicesâ€‰â©½â€‰0.65) across all models and across different definitions of progression.


CONCLUSION
Inconsistency of prognostic factor importance ranking confirmed the relatively poor prediction ability of baseline factors in modeling disease progression in MS. Our findings underline the importance to explore alternative predictors as well as alternative definitions of commonly used endpoints.",2019,Multiple sclerosis
51â€…Does degree of low amplitude atrial voltage correlate with poor left atrial function in atrial fibrillation?,"Background Patients with atrial fibrillation (AF) frequently have atrial scarring characterised by discrete regions of low voltage. Pre-existing left atrial scarring is an independent predictor of pulmonary vein isolation (PVI) failure. Novel mapping algorithms have also been developed to assess the degree of atrial fibrosis. This may be expressed as a percentage of the total left atrial (LA) volume mapped. In addition to the electrical remodelling seen, structural remodelling occurs, with dilatation and reduced function. The most accurate determinant of LA function is debated, but the most frequently used method is transmitral A Wave velocity on pulsed-wave Doppler. The relationship between LA function and electrical changes seen in AF has not been defined. Methods This was a single centre observational study. Left atrial voltage maps were created in patients undergoing PVI for the first time in the Mater Private Hospital between August 2016 and April 2017. LA voltage maps were initially created with a Lasso catheter with some further points taken with a Smarttouch ablation catheter (both Biosense Webster, Diamond Bar, California). Voltage greater than 0.5 mV was accepted as normal tissue and voltages < 0.2 mV scar. After creation of the voltage maps, the percentage scar was assessed using a novel computer algorithm (Biosense Webster). Pre-ablation echocardiograms were studied and the LA function was assessed by measuring the trans-mitral pulse wave Doppler. Assessments were only made in sinus rhythm. Results Out of 96 patients who had undergone PVI, only 24 were found to have had sinus rhythm on pre-procedural echo. The mean age was 63.5 (standard deviation or SD 10.6) years. 66% of the group were men. 58% had paroxysmal AF. The mean amplitude of the A-wave in the study was 0.61 (SD 0.16) ms-1. An average of 1269.7 (SD 857.0) mapping points were taken. The mean LA percentage scar was 25.1 (SD 20.3) %. Using linear regression, adjusted for age at time of procedure, there was a significant negative association between a wave (in ms-1) and % LA scar (Beta coefficient -72.44, 95% CI -122.99 to -21.88, p=0.007). Using pairwise correlation, the correlation coefficient between LA scar and A wave was -0.38, p=0.06. Abstract 51 Figure 1 Two-way scatterplot with fitted regression line between left atrial scar and transmitral A wave velocity. A wave measure in ms-1, LA scar expressed as a percentage Conclusion Our study found an inverse correlation between transmitral A wave and degree of left atrial scarring when LA function was adjusted for patient age, indicating that LA electrical remodelling as measure by percentage scar is associated with decreased LA function in patients with AF. However, there were only 24 patients in this study and ongoing research with more patients is warranted to further substantiate this.",2017,Heart
Development and Validation of a Prediction Pneumothorax Model in CT-Guided Transthoracic Needle Biopsy for Solitary Pulmonary,"Computed tomography-guided transthoracic needle biopsy (CT-TNB) is widely used in the diagnosis of solitary pulmonary nodule (SPN). However, CT-TNB-induced pneumothorax occurs frequently. This study aimed to establish a predictive model for pneumothorax following CT-TNB for SPN. The prediction model was developed in a cohort that consisted of 311 patients with SPN who underwent CT-TNB. An independent external validation cohort contained 227 consecutive patients. The least absolute shrinkage and selection operator (Lasso) regression analysis was used for data dimension reduction and predictors selection. Multivariable logistic regression was used to develop the predictive model, which was presented with a nomogram. Area under the curve (AUC) was used to determine the discrimination of the proposed model. The calibration was used to test the goodnessof-fit of themodel, and decision curve analysis (DCA)was used for evaluating its clinical usefulness. Five variables (age, diagnosis of nodule, puncture times, puncture distance, and puncture position) were filtered by Lasso regression. AUC of the predictive model and the validation were 0.801 (95%CI, 0.738-0.865) and 0.738 (95%CI, 0.656-0.820), respectively.Themodel was well-calibrated (P > 0.05), and DCA demonstrated its clinical usefulness. Thus, this predictive model might facilitate the individualized preoperative prediction of pneumothorax in CT-TNB for SPN.",2019,
A clinical-radiomic model for improved prognostication of surgical candidates with colorectal liver metastases.,"BACKGROUND AND OBJECTIVES
Colorectal cancer with liver metastases is potentially curable with surgical resection however clinical prognostic factors can insufficiently stratify patients. This study aims to assess whether radiomic features are prognostic and can inform clinical decision making.


METHODS
This single-site retrospective study included 102 patients who underwent colorectal liver metastases resection with preoperative computed tomography (CT), magnetic resonance imaging (MRI) with gadoxetic acid (EOB) and clinical covariates. A lasso-regularized multivariate Cox proportional hazards model was applied to 114 features (10 clinical, 104 radiomic) to determine association with disease-free survival (DFS). A prognostic index was derived using the significant Cox regression coefficients and their corresponding input features and a threshold was determined to classify patients into high- and low-risk groups, and DFS compared using log-rank tests.


RESULTS
Four covariates were significantly associated with DFS; bilobar disease (hazard ratio [HR]=â€‰1.56; Pâ€‰=â€‰.0043), complete pathological response (HR=â€‰0.67; Pâ€‰=â€‰.025), minimum pixel value (HR=â€‰1.66; Pâ€‰=â€‰.00016), and small area emphasis (HR=â€‰0.62; Pâ€‰=â€‰.0013) from the EOB-MRI data. Radiomic CT features were not prognostic. The prognostic index strongly stratified high- and low-risk prognostic groups (HRâ€‰=â€‰0.31; Pâ€‰=â€‰.00068).


CONCLUSION
Radiomic MRI features provided meaningful prognostic information above clinical covariates alone. This merits further validation for potential clinical implementation to inform management.",2019,Journal of surgical oncology
Assessment of the cardiovascular adverse effects of drug-drug interactions through a combined analysis of spontaneous reports and predicted drug-target interactions,"Adverse drug effects (ADEs) are one of the leading causes of death in developed countries and are the main reason for drug recalls from the market, whereas the ADEs that are associated with action on the cardiovascular system are the most dangerous and widespread. The treatment of human diseases often requires the intake of several drugs, which can lead to undesirable drug-drug interactions (DDIs), thus causing an increase in the frequency and severity of ADEs. An evaluation of DDI-induced ADEs is a nontrivial task and requires numerous experimental and clinical studies. Therefore, we developed a computational approach to assess the cardiovascular ADEs of DDIs. This approach is based on the combined analysis of spontaneous reports (SRs) and predicted drug-target interactions to estimate the five cardiovascular ADEs that are induced by DDIs, namely, myocardial infarction, ischemic stroke, ventricular tachycardia, cardiac failure, and arterial hypertension. We applied a method based on least absolute shrinkage and selection operator (LASSO) logistic regression to SRs for the identification of interacting pairs of drugs causing corresponding ADEs, as well as noninteracting pairs of drugs. As a result, five datasets containing, on average, 3100 potentially ADE-causing and non-ADE-causing drug pairs were created. The obtained data, along with information on the interaction of drugs with 1553 human targets predicted by PASS Targets software, were used to create five classification models using the Random Forest method. The average area under the ROC curve of the obtained models, sensitivity, specificity and balanced accuracy were 0.837, 0.764, 0.754 and 0.759, respectively. The predicted drug targets were also used to hypothesize the potential mechanisms of DDI-induced ventricular tachycardia for the top-scoring drug pairs. The created five classification models can be used for the identification of drug combinations that are potentially the most or least dangerous for the cardiovascular system.",2019,PLoS Computational Biology
[Analysis of the genetic factors controlling malarial infection in man].,"Genetic factors have clearly been shown to play a role in controlling malarial infection in animal models. There is now also increasing evidence for the genetic control of malaria in man. We carried out a segregation analysis based on blood parasite load phenotype for a population of the town of Bobo-Dioulasso (Burkina-Faso). This analysis demonstrated a strong genetic effect. Our results were not consistent with the segregation of a major gene and thus suggest that parasite load is under the control of minor genes. The genetic effect was stronger in children than in adults. We carried out a regression analysis in children and found that there was an association between the phenotype for blood parasite load and the q31-33 region of chromosome 5. We identified a gene in this region, Pfil1 (Plasmodium falciparum infection levels 1), which accounted for almost 50% of the variance in blood parasite load and which played a fundamental role in the control of infection. The 5q31-33 region contains several genes encoding cytokines that regulate T lymphocytes. The identification of genes controlling malarial infection opens up new possibilities for preventive and treatment strategies. It should be possible in the near future to identify individuals at risk of malaria, who would derive the greatest benefit from preventive and therapeutic measures. Finally, a deeper understanding of these genes controlling protective immune responses could be of value for the development of vaccines.",1999,Sante
SNAP: A semismooth Newton algorithm for pathwise optimization with optimal local convergence rate and oracle properties,"We propose a semismooth Newton algorithm for pathwise optimization (SNAP) for the LASSO and Enet in sparse, high-dimensional linear regression. SNAP is derived from a suitable formulation of the KKT conditions based on Newton derivatives. It solves the semismooth KKT equations efficiently by actively and continuously seeking the support of the regression coefficients along the solution path with warm start. At each knot in the path, SNAP converges locally superlinearly for the Enet criterion and achieves an optimal local convergence rate for the LASSO criterion, i.e., SNAP converges in one step at the cost of two matrix-vector multiplication per iteration. Under certain regularity conditions on the design matrix and the minimum magnitude of the nonzero elements of the target regression coefficients, we show that SNAP hits a solution with the same signs as the regression coefficients and achieves a sharp estimation error bound in finite steps with high probability. The computational complexity of SNAP is shown to be the same as that of LARS and coordinate descent algorithms per iteration. Simulation studies and real data analysis support our theoretical results and demonstrate that SNAP is faster and accurate than LARS and coordinate descent algorithms.",2018,ArXiv
A Holistic Clustering Methodology for Liver Transplantation Survival,"Background Liver transplants account for a high number of procedures with major investments from all stakeholders involved; however, limited studies address liver transplant population heterogeneity pretransplant predictive of posttransplant survival. Objective The aim of the study was to identify novel and meaningful patient clusters predictive of mortality that explains the heterogeneity of liver transplant population, taking a holistic approach. Methods A retrospective cohort study of 344 adult patients who underwent liver transplantation between 2008 through 2014. Predictors were summarized severity scores for comorbidities and other suboptimal health states grouped into 11 body systems, the primary reason for transplantation, demographics/environmental factors, and Model for End Liver Disease score. Logistic regression was used to compute the severity scores, hierarchical clustering with weighted Euclidean distance for clustering, Lasso-penalized regression for characterizing the clusters, and Kaplanâ€“Meier analysis to compare survival across the clusters. Results Cluster 1 included patients with more severe circulatory problems. Cluster 2 represented older patients with more severe primary disease, whereas Cluster 3 contained healthiest patients. Clusters 4 and 5 represented patients with musculoskeletal (e.g., pain) and endocrine problems (e.g., malnutrition), respectively. There was a statistically significant difference for mortality between clusters (p < .001). Conclusions This study developed a novel methodology to address heterogeneous and high-dimensional liver transplant population characteristics in a single study predictive of survival. A holistic approach for data modeling and additional psychosocial risk factors has the potential to address holistically nursing challenges on liver transplant care and research.",2018,Nursing Research
Evaluating the Potential of Sentinel-2 for Low Severity Mites Infestation Detection in Grapes,"The Mite is one of the major sucking pests in grape which goes undetected in its initial phase as the symptoms are not easily visible to the naked eyes. In this paper, we address the problem of mites infestation detection using temporal hyperspectral data and also evaluate the potential of using Sentinel-2 data for mites infestation detection. The reflectance data from grape leaves with healthy and low infestations of mites have been collected using spectroradiometer. The hyperspectral remote sensing data is collected from 213 bands with wavelength ranging from 350 nm to 1052 nm during 15th Jan â€“ 18th Feb 2017. Variations observed in the spectral reflectance over time makes the detection based on multitemporal data difficult. Data in 213 narrow contiguous bands is used as feature set for hyperspectral data analysis but this large feature set may cause the over-fitting problem and also poses the requirement of large storage and greater processing time. To avoid this, feature selection using Least Absolute Shrinkage and Selection Operator (LASSO) has been carried out to get the optimum band set. Features selected by LASSO were fed to classifiers such as Random Forest (RF), Artificial Neural Network (ANN) and Logistic Regression (LR) to evaluate their performance. Results suggest that LR based model provides maximum accuracy of 93.24%. In addition to this, to investigate the potential of using Sentinel-2, data in 213 narrow bands were simulated to Sentinel-2. Data has been simulated to 10 and 20m spatial resolution bands available in 350â€“1050nm range. This simulated 8 band feature set has been fed to the same set of classifiers to evaluate their performance. Results suggests that LR provides maximum classification accuracy of 89.12% using simulated Sentinel-2 bands. Further to validate the algorithm using actual ground observations from the field, we have implemented simulated Sentinel-2 based algorithm on two Sentinel-2 images available during the study period and results are compared with actual ground observations about mites infestation. Results suggest mites detection accuracy of 83.33% which shows the good agreement and potential of Sentinel-2 for mites infestation detection.",2018,IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium
Sleep/wake classification using cardiorespiratory features extracted from photoplethysmogram,"Human sleep cyclically alternates between wakefulness and different sleep stages. There are various physiological changes that occur during wakefulness and sleep transitions. In particular, fluctuations occur in cardiorespiratory activity, mainly determined by the autonomic nervous system. The purpose of this study was to implement a multivariate logistic regression model to classify 30-second epochs of an overnight sleep dataset into awake and sleep states using the features extracted from the photoplethysmogram (PPG). The extracted features provided information about heart rate variability, respiratory activity, vascular tone and body movement. Overnight PPG signals were collected using a smartphone-based pulse oximeter, simultaneously with standard polysomnography from 160 children at the British Columbia Children's hospital. The sleep technician scored all wake/sleep epochs throughout the PSG study. We divided the dataset into training data, used to develop the model using LASSO, and test data, used to validate the model. The developed model was assessed epoch-by-epoch for each subject individually, andfor the complete test dataset. The performance of the model on the full test dataset showed a median accuracy of 77%, sensitivity of 80%, and specificity of 70%. Thus, providing a detailed epoch-by-epoch analysis with at-home pulse oximetry alone is feasible with accuracy, sensitivity and specificity values above 70%. However, the performance of the model might decrease when analyzing subjects with a high number epochs of wakefulness.",2016,2016 Computing in Cardiology Conference (CinC)
Selecting Spatial Scale of Area-Level Covariates in Regression Models,"SELECTING SPATIAL SCALE OF AREA-LEVEL COVARIATES IN REGRESSION MODELS By Lauren P. Grant, Ph.D. A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy at Virginia Commonwealth University. Virginia Commonwealth University, 2016 Director: David C. Wheeler, Ph.D., MPH Assistant Professor, Department of Biostatistics Director: Chris Gennings, Ph.D. Research Professor, Department of Preventive Medicine Icahn School of Medicine at Mount Sinai In epidemiological and environmental studies, investigators are often interested in the contextual or area-level effects that are associated with a specific health outcome. Area-based covariates are typically available at multiple spatial scales (i.e., areal units or buffer distances). Studies have found that the level of association between an area-level covariate and an outcome can vary depending on the spatial scale (SS) of a particular covariate. However, covariates used in regression models are customarily modeled at the same spatial unit. In this dissertation, we developed four SS model selection algorithms that select the best spatial scale for each area-level covariate. The SS forward stepwise, SS incremental forward stagewise, SS least angle regression (LARS), and SS lasso algorithms allow for the selection of different area-level",2016,
Promising key genes associated with tumor microenvironments and prognosis of hepatocellular carcinoma,"Abstract Background Despite significant advances in multimodality treatments, hepatocellular carcinoma (HCC) remains one of the common malignant tumors. Tumor microenvironments play an important role in progress of HCC. The study aimed to identify potential key genes associated with tumor microenvironments and prognosis of HCC. Methods The infiltration level of immune cells and stromal cells were calculated and quantified based on the ESTIMATE algorithm. Differentially expressed genes (DEGs) between high and low groups according to immune or stromal scores were screened using the gene expression profile of HCC pateitns in The Cancer Genome Atlas (TCGA) and were further linked to prognosis of HCC. These genes were validated in four independent HCC cohorts. Survival-related key genes were identified by LASSO Cox regression model. Results HCC patients with high immune/stromal score had better survival benefits than patients with low score. A total of 899 DEGs were identified and involved in immune responses and extracellular matrices, 147 of which were associated with overall survival. Subsequently, 52 of 147 survival-related DEGs were valided in additional cohorts. Finally, 10â€‰key genes were selected (STSL2, TMC5, DOK5, RASGRP2, NLRC3, KLRB1, CD5L, CFHR3, ADH1C and UGT2B15) and used to construct a prognostic gene signature, presenting good performance in predicting overall survival. Conclusions This study extracted a list of genes associated with tumor microenvironments and the prognosis of HCC and would provide several valuable directions for the prognostic prediction and molecular targeted therapy of HCC in the future. Legal entity responsible for the study Xiujun Cai. Funding Has not received any funding. Disclosure All authors have declared no conflicts of interest.",2020,World Journal of Gastroenterology
Severity of Bulimia Nervosa,"Aims: In order to identify the most important components of the severity of bulimia nervosa (as well as identifying clinical cases), we explored the relation between dimensional and categorical assessment. This was achieved by studying the performance of variables from standard instruments (measuring specific and general psychopathology) in predicting an expert rating of overall syndrome severity. Method: In total, 213 cases were selected (across the whole range of severity). We applied regression with optimal scaling to model nonlinear relations in the data, and the lasso method with bootstrapping for predictor selection. The best model contained 2 scales of the Eating Disorders Inventory (â€˜bulimiaâ€™ and â€˜drive for thinnessâ€™) and the frequency of the binges. The sensitivity and specificity of case classification using the obtained model was determined. Results: The model can predict the probability of being a clinical case at a rate of 88%. The presented statistical methods are innovative and promising approaches that can help researchers and clinicians to better define sets of variables for treatment evaluation and outcome studies. Conclusion: The results indicate that severity and outcome in bulimia nervosa should be determined by measuring both cognitive and behavioral aspects of the symptoms.",2008,Psychopathology
DNA Methylation and All-Cause Mortality in Middle-Aged and Elderly Danish Twins,"Several studies have linked DNA methylation at individual CpG sites to aging and various diseases. Recent studies have also identified single CpGs whose methylation levels are associated with all-cause mortality. In this study, we perform an epigenome-wide study of the association between CpG methylation and mortality in a population of 435 monozygotic twin pairs from three Danish twin studies. The participants were aged 55-90 at the time of blood sampling and were followed for up to 20 years. We validated our results by comparison with results from a British and a Swedish cohort, as well as results from the literature. We identified 2806 CpG sites associated with mortality (false discovery rate ( FDR ) < 0.05 ), of which 24 had an association p-value below 10 - 7 . This was confirmed by intra-pair comparison controlling for confounding effects. Eight of the 24 top sites could be validated in independent datasets or confirmed by previous studies. For all these eight sites, hypomethylation was associated with poor survival prognosis, and seven showed monozygotic correlations above 35%, indicating a potential moderate to strong heritability, but leaving room for substantial shared or unique environmental effects. We also set up a predictor for mortality using least absolute shrinkage and selection operator (LASSO) regression. The predictor showed good performance on the Danish data under cross-validation, but did not perform very well in independent samples.",2018,Genes
On the use of multi-step cost functions for generating forecasts,"Accurate forecasts are of principal importance for operations. Exponential smoothing is widely used due to its simplicity, relatively good forecast accuracy, ease of implementation and automation. The literature has continuously improved upon many of its initial limitations, yet novel applications of exponential smoothing have brought new forecasting challenges that have revealed additional pitfalls in its use. In this work, we examine potential reasons for these issues and argue that special attention should be drawn to the cost function used to estimate model parameters. Conventional cost functions assume that the postulated model is an accurate reflection of underlying demand, which is not the case for the majority of real applications. We propose the use of alternative cost functions based on multi-step ahead predictions and trace forecasts. We show that these are univariate shrinkage estimators. We describe the nature of shrinkage and show that it differs from established shrinkage approaches, such as ridge and LASSO regression, offering new modelling capabilities. Using retailing sales, we construct forecasts and empirically demonstrate this shrinkage, validate our theoretical understanding, and provide evidence of both economic and forecast accuracy gains. We discuss implications for practice and limitations of the shrinkage caused by the multi-step cost functions.",2018,
"Penalized regression, standard errors, and Bayesian lassos","Penalized regression methods for simultaneous variable selection and coe-cient estimation, especially those based on the lasso of Tibshirani (1996), have received a great deal of attention in recent years, mostly through frequen- tist models. Properties such as consistency have been studied, and are achieved by difierent lasso variations. Here we look at a fully Bayesian formulation of the problem, which is âˆžexible enough to encompass most versions of the lasso that have been previously considered. The advantages of the hierarchical Bayesian for- mulations are many. In addition to the usual ease-of-interpretation of hierarchical models, the Bayesian formulation produces valid standard errors (which can be problematic for the frequentist lasso), and is based on a geometrically ergodic Markov chain. We compare the performance of the Bayesian lassos to their fre- quentist counterparts using simulations, data sets that previous lasso papers have used, and a di-cult modeling problem for predicting the collapse of governments around the world. In terms of prediction mean squared error, the Bayesian lasso performance is similar to and, in some cases, better than, the frequentist lasso.",2010,Bayesian Analysis
Variable Selection for Regression Models with Missing Data.,"We consider the variable selection problem for a class of statistical models with missing data, including missing covariate and/or response data. We investigate the smoothly clipped absolute deviation penalty (SCAD) and adaptive LASSO and propose a unified model selection and estimation procedure for use in the presence of missing data. We develop a computationally attractive algorithm for simultaneously optimizing the penalized likelihood function and estimating the penalty parameters. Particularly, we propose to use a model selection criterion, called the IC(Q) statistic, for selecting the penalty parameters. We show that the variable selection procedure based on IC(Q) automatically and consistently selects the important covariates and leads to efficient estimates with oracle properties. The methodology is very general and can be applied to numerous situations involving missing data, from covariates missing at random in arbitrary regression models to nonignorably missing longitudinal responses and/or covariates. Simulations are given to demonstrate the methodology and examine the finite sample performance of the variable selection procedures. Melanoma data from a cancer clinical trial is presented to illustrate the proposed methodology.",2010,Statistica Sinica
An Examination of the Relationship Between the Temporal and Spatial Organization of a Student's Handwritten Statics Solution and Its Correctness,"Author(s): Van Arsdale, Timothy | Advisor(s): Stahovich, Thomas | Abstract: The purpose of this project is to understand how the organization of a student's solution to a problem relates to the correctness of that work. Understanding this relationship will enable software to provide early warnings and targeted feedback to students who are struggling in a course. In this study, students in an undergraduate statics course completed their work, including homework, quizzes, and exams, using LivescribeTM Smartpens. These devices record the handwritten solutions as time-stamped pen strokes, enabling the examination of not only the final ink on the page, but also the order in which it was written. This unique database of student work was used to examine how the history of the solution construction process correlates with the correctness of the work. Solution histories were characterized by a number of quantitative features describing the temporal and spatial organization of the work. For example, some features describe the order in which various problem-solving activities, such as the construction of free body diagrams and equilibrium equations, are performed and others describe the amount of time spent on each activity. The spatial organization of the work is characterized by the extent to which a student revisits earlier parts of a solution to revise his/her work. Cross-validated regression models were constructed using the relaxed lasso method to determine the correlation between these features and student performance. On average, the models explained 43% of the variance in performance. This is a surprising result in that the features do not actually consider the semantic content of the writing. The relaxed lasso method also identified which features were most predictive of problem correctness, thus giving insights into which student behaviors are indicative of high or low performance. For example, revising work long after it was written indicates low performance. While our work has focused on engineering statics, we expect that these techniques will generalize to other domains for which problem solutions include both diagrams and equations.",2012,
Pooling optimal combinations of energy thresholds in spectroscopic CT,"Photon counting detectors used in spectroscopic CT are often based on small pixels and therefore offer only limited space to include energy discriminators and their associated counters in each pixel cell. For this reason, it is important to make efficient use of the available energy discriminators in order to achieve an optimized material contrast at a radiation dose as low as possible. Unfortunately, the complexity of evaluating every possible combination of energy thresholds, given a fixed number of counters, rapidly increases with the resolution at which this search is performed, and makes brute-force approaches to this problem infeasible. In this work, we introduce methods from machine learning, in particular sparse regression, to perform a feature selection to determine optimal combinations of energy thresholds. We will demonstrate how methods enforcing row-sparsity on a linear regressionâ€™s coefficient matrix can be applied to the multiple response problem in spectroscopic CT, i.e. the case in which a single set of energy thresholds is sought to simultaneously retrieve concentrations pertaining to a multitude of materials in an optimal way. These methods are applied to CT images experimentally obtained with a Medipix3RX detector operated in charge summing mode and with a CdTe sensor at a pixel pitch of 110Î¼m. We show that the least absolute shrinkage and selection operator (lasso), generalized to the multiple response case, chooses four out of 20 possible threshold positions that allow discriminating PMMA, iodine and gadolinium in a contrast agent phantom at a higher accuracy than with equally spaced thresholds. Finally, we illustrate why it might be unwise to use a higher number of energy thresholds than absolutely necessary.",2014,
Penalized expectile regression: an alternative to penalized quantile regression,"This paper concerns the study of the entire conditional distribution of a response given predictors in a heterogeneous regression setting. A common approach to address heterogeneous data is quantile regression, which utilizes the minimization of the $$L_1$$L1 norm. As an alternative to quantile regression, we consider expectile regression, which relies on the minimization of the asymmetric $$L_2$$L2 norm and detects heteroscedasticity effectively. We assume that only a small set of predictors is relevant to the response and develop penalized expectile regression with SCAD and adaptive LASSO penalties. With properly chosen tuning parameters, we show that the proposed estimators display oracle properties. A numerical study using simulated and real examples demonstrates the competitive performance of the proposed penalized expectile regression, and its combined use with penalized quantile regression would be helpful and recommended for practitioners.",2019,Annals of the Institute of Statistical Mathematics
Screening and Identification of Potential Prognostic Biomarkers in Adrenocortical Carcinoma,"Objective: Adrenocortical carcinoma (ACC) is a rare but aggressive malignant cancer that has been attracting growing attention over recent decades. This study aims to integrate protein interaction networks with gene expression profiles to identify potential biomarkers with prognostic value in silico. Methods: Three microarray data sets were downloaded from the Gene Expression Omnibus (GEO) database to identify differentially expressed genes (DEGs) according to the normalization annotation information. Enrichment analyses were utilized to describe biological functions. A protein-protein interaction network (PPI) of the DEGs was developed, and the modules were analyzed using STRING and Cytoscape. LASSO Cox regression was used to identify independent prognostic factors. The Kaplan-Meier method for the integrated expression score was applied to analyze survival outcomes. A receiver operating characteristic (ROC) curve was constructed with area under curve (AUC) analysis to determine the diagnostic ability of the candidate biomarkers. Results: A total of 150 DEGs and 24 significant hub genes with functional enrichment were identified as candidate prognostic biomarkers. LASSO Cox regression suggested that ZWINT, PRC1, CDKN3, CDK1 and CCNA2 were independent prognostic factors in ACC. In multivariate Cox analysis, the integrated expression scores of the modules showed statistical significance in predicting disease-free survival (DFS, P = 0.019) and overall survival (OS, P < 0.001). Meanwhile, ROC curves were generated to validate the ability of the Cox model to predict prognosis. The AUC index for the integrated genes scores was 0.861 (P < 0.0001). Conclusion: In conclusion, the present study identifies DEGs and hub genes that may be involved in poor prognosis and early recurrence of ACC. The expression levels of ZWINT, PRC1, CDKN3, CDK1 and CCNA2 are of high prognostic value, and may help us understand better the underlying carcinogenesis or progression of ACC. Further studies are required to elucidate molecular pathogenesis and alteration in signaling pathways for these genes in ACC.",2019,Frontiers in Genetics
Graphical Models Concepts in Compressed Sensing,"This paper surveys recent work in applying ideas from graphical models and message passing algorithms to solve large scale regularized regression problems. In particular, the focus is on compressed sensing reconstruction via ell_1 penalized least-squares (known as LASSO or BPDN). We discuss how to derive fast approximate message passing algorithms to solve this problem. Surprisingly, the analysis of such algorithms allows to prove exact high-dimensional limit results for the LASSO risk. 
This paper will appear as a chapter in a book on `Compressed Sensing' edited by Yonina Eldar and Gitta Kutyniok.",2012,ArXiv
Data driven discovery of nonlinear dynamics,"We demonstrate that sparse regression and compressive sensing techniques are capable of accurately determining a set of functions governing a nonlinear dynamical system. We analyze a technique introduced by Brunton, Proctor, and Kutz, 2016 [1] that builds a sparse representation of a dynamical system by computing sequential least squares fittings of the data to identify the governing equations. By computing the sparse regression in such a fashion, this method quickly identifies nonzero coefficients and allows them to converge to their respective weight. The result is a sparse representation of the dynamical system in the nonlinear function space. We look at the mechanics of the lasso, discuss the introduction of sparsity to a system by choice of the l1-norm, and investigate the algorithm used in sparse identification of nonlinear dynamics through a sequential least squares method.",2016,
bayesQR: A Bayesian Approach to Quantile Regression,"After its introduction by Koenker and Basset (1978), quantile regression has become an important and popular tool to investigate the conditional response distribution in regression. The R package bayesQR contains a number of routines to estimate quantile regression parameters using a Bayesian approach based on the asymmetric Laplace distribution. The package contains functions for the typical quantile regression with continuous dependent variable, but also supports quantile regression for binary dependent variables. For both types of dependent variables, an approach to variable selection using the adaptive lasso approach is provided. For the binary quantile regression model, the package also contains a routine that calculates the fitted probabilities for each vector of predictors. In addition, functions for summarizing the results, creating traceplots, posterior histograms and drawing quantile plots are included. This paper starts with a brief overview of the theoretical background of the models used in the bayesQR package. The main part of this paper discusses the computational problems that arise in the implementation of the procedure and illustrates the usefulness of the package through selected examples.",2017,Journal of Statistical Software
Estimating the Structure of Social Interactions Using Panel Data,"I consider settings where outcomes depend on own characteristics and on the characteristics of other individuals in the sample. I propose a method to identify individuals generating spillovers and their strength using panel data on outcomes and characteristics. This is in contrast to existing approaches, which require a priori knowledge of the structure of interactions. The method is suitable when the structure of interactions is stable over time and few individuals generate spillovers distinct in magnitude from the rest. To estimate the model, I introduce the Pooled Lasso estimator, a paneldata counterpart of the Lasso estimator and develop an iterative algorithm for computation that alternates between Lasso estimation and pooled panel regression. Average marginal spillover effects across individuals enjoy gains in the rate of convergence under independence of model selection noise. I apply this methodology to study technological spillovers in productivity in a panel of US firms. I find evidence that spillovers are asymmetric across firms, arising mostly from small, highly productive firms.",2013,
IPF-LASSO: Integrative L 1-Penalized Regression with Penalty Factors for Prediction Based on Multi-Omics Data,"As modern biotechnologies advance, it has become increasingly frequent that different modalities of high-dimensional molecular data (termed ""omics"" data in this paper), such as gene expression, methylation, and copy number, are collected from the same patient cohort to predict the clinical outcome. While prediction based on omics data has been widely studied in the last fifteen years, little has been done in the statistical literature on the integration of multiple omics modalities to select a subset of variables for prediction, which is a critical task in personalized medicine. In this paper, we propose a simple penalized regression method to address this problem by assigning different penalty factors to different data modalities for feature selection and prediction. The penalty factors can be chosen in a fully data-driven fashion by cross-validation or by taking practical considerations into account. In simulation studies, we compare the prediction performance of our approach, called IPF-LASSO (Integrative LASSO with Penalty Factors) and implemented in the R package ipflasso, with the standard LASSO and sparse group LASSO. The use of IPF-LASSO is also illustrated through applications to two real-life cancer datasets. All data and codes are available on the companion website to ensure reproducibility.",2017,Computational and Mathematical Methods in Medicine
Clinical application of ICF key codes to evaluate patients with dysphagia following stroke,"AbstractThis study was aimed to identify and evaluate the International Classification of Functioning (ICF) key codes for dysphagia in stroke patients. Thirty patients with dysphagia after stroke were enrolled in our study. To evaluate the ICF dysphagia scale, 6 scales were used as comparisons, namely the Barthel Index (BI), Repetitive Saliva Swallowing Test (RSST), Kubota Water Swallowing Test (KWST), Frenchay Dysarthria Assessment, Mini-Mental State Examination (MMSE), and the Montreal Cognitive Assessment (MoCA). Multiple regression analysis was performed to quantitate the relationship between the ICF scale and the other 7 scales. In addition, 60 ICF scales were analyzed by the least absolute shrinkage and selection operator (LASSO) method. A total of 21 ICF codes were identified, which were closely related with the other scales. These included 13 codes from Body Function, 1 from Body Structure, 3 from Activities and Participation, and 4 from Environmental Factors. A topographic network map with 30 ICF key codes was also generated to visualize their relationships. The number of ICF codes identified is in line with other well-established evaluation methods. The network topographic map generated here could be used as an instruction tool in future evaluations. We also found that attention functions and biting were critical codes of these scales, and could be used as treatment targets.",2016,Medicine
A Novel Predictive Model to Estimate the Number of Mature Oocytes Required for Obtaining at Least One Euploid Blastocyst for Transfer in Couples Undergoing in vitro Fertilization/Intracytoplasmic Sperm Injection: The ART Calculator,"The POSEIDON group (Patient-Oriented Strategies Encompassing IndividualizeD Oocyte Number) has introduced ""the ability to retrieve the number of oocytes needed to achieve at least one euploid embryo for transfer"" as an intermediate marker of successful outcome in IVF/ICSI cycles. This study aimed to develop a novel calculator to predict the POSEIDON marker. We analyzed clinical and embryonic data of infertile couples who underwent IVF/ICSI with the intention to have trophectoderm biopsy for preimplantation genetic testing for aneuploidy. We used the negative binomial distribution to model the number of euploid blastocysts and the adaptive LASSO (Least Absolute Shrinkage and Selection Operator) method for variable selection. The fitted model selected female age, sperm source used for ICSI, and the number of mature (metaphase II) oocytes as predictors (p < 0.0001). Female age was the most important factor for predicting the probability of a blastocyst being euploid given each mature oocyte (loglikelihood of age [adjusted for sperm source]: 30.9; df = 2; p < 0.0001). The final predictive model was developed using logistic regression analysis, and internally validated by the holdout method. The predictive ability of the model was assessed by the ROC curve, which resulted in an area under the curve of 0.716. Using the final model and mathematical equations, we calculated the individualized probability of blastocyst euploidy per mature retrieved oocyte and the minimum number of mature oocytes required to obtain â‰¥1 euploid blastocyst-with their 95% confidence interval [CI]-for different probabilities of success. The estimated predicted probabilities of a mature oocyte turn into a euploid blastocyst decreased progressively with female age and was negatively modulated overall by use of testicular sperm across age (p < 0.001). A calculator was developed to make two types of predictions automatically, one using pretreatment information to estimate the minimum number of mature oocytes to achieve â‰¥1 euploid blastocyst, and another based on the actual number of mature oocytes collected/accumulated to estimate the chances of having a euploid blastocyst using that oocyte cohort for IVF/ICSI. The new ART calculator may assist in clinical counseling and individualized treatment planning regarding the number of oocytes required for at least one euploid blastocyst in IVF/ICSI procedures.",2019,Frontiers in Endocrinology
The Frischâ€“Waughâ€“Lovell theorem for the lasso and the ridge regression,"ABSTRACT The Frischâ€“Waughâ€“Lovell (FWL) (partitioned regression) theorem is essential in regression analysis. This is partly because it is quite useful to derive theoretical results. The lasso regression and the ridge regression, both of which are penalized least-squares regressions, have become popular statistical techniques. This article describes that the FWL theorem remains valid for these penalized least-squares regressions. More precisely, we demonstrate that the covariates corresponding to unpenalized regression parameters in these penalized least-squares regression can be projected out. Some other results related to the FWL theorem in such penalized least-squares regressions are also presented.",2017,Communications in Statistics - Theory and Methods
Semi-Smooth Second-order Type Methods for Composite Convex Programs,"The goal of this paper is to study approaches to bridge the gap between first-order and second-order type methods for composite convex programs. Our key observations are: i) Many well-known operator splitting methods, such as forward-backward splitting (FBS) and Douglas-Rachford splitting (DRS), actually define a possibly semi-smooth and monotone fixed-point mapping; ii) The optimal solutions of the composite convex program and the solutions of the system of nonlinear equations derived from the fixed-point mapping are equivalent. Solving the system of nonlinear equations rediscovers a paradigm on developing second-order methods. Although these fixed-point mappings may not be differentiable, they are often semi-smooth and its generalized Jacobian matrix is positive semidefinite due to monotonicity. By combining a regularization approach and a known hyperplane projection technique, we propose an adaptive semi-smooth Newton method and establish its convergence to global optimality. A semi-smooth Levenberg-Marquardt (LM) method in terms of handling the nonlinear least squares formulation is further presented. In practice, the second-order methods can be activated until the first-order type methods reach a good neighborhood of the global optimal solution. Preliminary numerical results on Lasso regression, logistic regression, basis pursuit, linear programming and quadratic programming demonstrate that our second-order type algorithms are able to achieve quadratic or superlinear convergence as long as the fixed-point residual of the initial point is small enough.",2016,arXiv: Optimization and Control
Bed utilisation and increased risk of Clostridium difficile infections in acute hospitals in England in 2013/2014,"Background The study aimed to identify thresholds for hospital bed utilisation which are independently associated with significantly higher risks for Clostridium difficile infections (CDI) in acute hospitals in England. Method A retrospective analysis was carried out on reported data from the English National Health Service (NHS) for the financial year 2013/2014. Reported rates of CDI were used as a proxy for hospital infection rates in acute NHS hospital trusts. Multivariate linear regression was used to assess the relationship between bed utilisation values and CDI controlling for confounding factors. Hospitals were finally plotted in a Pabon Lasso graph according to their average bed occupancy rate (BOR) and bed turnover rate (BTR) per year to visualise the relationship between bed utilisation and CDI. Results Among English hospital NHS trusts, increasing BTR and decreasing BOR were associated with a decrease in CDI. However, this effect was not large, and patient mix had a larger impact on CDI rates than bed utilisation. Conclusions While policymakers and managers wishing to target healthcare providers with high CDI rates should look at bed utilisation measures, focusing on these alone is unlikely to have the desired impact. Instead, strategies to combat CDI must take a wider perspective on contributory factors at the institutional level.",2017,BMJ Quality & Safety in Health Care
Bank Credit Risk Networks: Evidence from the Eurozone Crisis,The European nancial crisis has shown that the credit risk of large nancial institutions is highly interconnected as a results of a number of linkages between entities like exposure to common assets and interbank lending. In this work we propose a novel methodology to study credit risk interdependence in large panels of nancial institutions. We introduce a credit risk model in which bank defaults can be triggered both by systematic economy wide and idiosyncratic bank specic shocks. The idiosyncratic shocks are assumed to have a sparse conditional dependence structure that we call the bank credit risk network. An estimation strategy based on CDS data and Lasso-type regression allows to estimate the parameters of the model and to recover the bank credit risk network structure. We apply this technique to analyse the interdependence of large European nancial institutions between 2006 and 2013. Results show that the credit risk network captures a substantial amount of dependence on top of what can be explained by systematic,2014,
Comparative Study of Regression Techniques in the Estimation of UPDRS Score for Parkinsonâ€™s disease,"Studies have shown that instances of Parkinsonâ€™s disease have been on the rise over the past 30 years. A metric that measures the extremity of Parkinsonâ€™s disease in a person is their Unified Parkinsonâ€™s Disease Rating Scale (UPDRS) score. Thus, an algorithm that can predict the UPDRS score of a Parkinsonâ€™s patient will be effective in determining the severity of the patientâ€™s condition. This paper aims to forecast a patientâ€™s UPDRS score by inferring patterns from historical figures and other independent parameter values that affect the patientsâ€™ UPDRS score. Four regression techniques namely multilinear, ridge, robust and LASSO regression are being used to predict the UPDRS scores. This will be done using the R language and through the use of the MASS, glmnet packages.",2018,International journal of engineering and technology
Automatic Scoring of Multiple Semantic Attributes With Multi-Task Feature Leverage: A Study on Pulmonary Nodules in CT Images.,"The gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (CAD) performance from clinical usage. To bridge this gap, we exploit three multi-task learning (MTL) schemes to leverage heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (SDAE) and convolutional neural network (CNN), as well as hand-crafted Haar-like and HoG features, for the description of 9 semantic features for lung nodules in CT images. We regard that there may exist relations among the semantic features of ""spiculation"", ""texture"", ""margin"", etc., that can be explored with the MTL. The Lung Image Database Consortium (LIDC) data is adopted in this study for the rich annotation resources. The LIDC nodules were quantitatively scored w.r.t. 9 semantic features from 12 radiologists of several institutes in U.S.A. By treating each semantic feature as an individual task, the MTL schemes select and map the heterogeneous computational features toward the radiologists' ratings with cross validation evaluation schemes on the randomly selected 2400 nodules from the LIDC dataset. The experimental results suggest that the predicted semantic scores from the three MTL schemes are closer to the radiologists' ratings than the scores from single-task LASSO and elastic net regression methods. The proposed semantic attribute scoring scheme may provide richer quantitative assessments of nodules for better support of diagnostic decision and management. Meanwhile, the capability of the automatic association of medical image contents with the clinical semantic terms by our method may also assist the development of medical search engine.",2017,IEEE transactions on medical imaging
SMPFRAME : A Distributed Framework for Scheduled Model Parallel Machine Learning,"Machine learning (ML) problems commonly applied to big data by existing distributed systems share and update all ML model parameters at each machine using a partition of data â€” a strategy known as data-parallel. An alternative and complimentary strategy, model-parallel, partitions model parameters for non-shared parallel access and update, periodically repartitioning to facilitate communication. Model-parallelism is motivated by two challenges that data-parallelism does not usually address: (1) parameters may be dependent, thus naive concurrent updates can introduce errors that slow convergence or even cause algorithm failure; (2) model parameters converge at different rates, thus a small subset of parameters can bottleneck ML algorithm completion. We propose scheduled model parallellism (SMP), a programming approach where selection of parameters to be updated (the schedule) is explicitly separated from parameter update logic. The schedule can improve ML algorithm convergence speed by planning for parameter dependencies and uneven convergence. To support SMP at scale, we develop an archetype software framework SMPFRAME which optimizes the throughput of SMP programs, and benchmark four common ML applications written as SMP programs: LDA topic modeling, matrix factorization, sparse least-squares (Lasso) regression and sparse logistic regression. By improving ML progress per iteration through SMP programming whilst improving iteration throughput through SMPFRAME we show that SMP programs running on SMPFRAME outperform non-model-parallel ML implementations: for example, SMP LDA and SMP Lasso respectively achieve 10x and 5x faster convergence than recent, well-established baselines.",2015,
Prediction of major international soccer tournaments based on team-specific regularized Poisson regression: An application to the FIFA World Cup 2014,"Abstract In this article an approach for the analysis and prediction of international soccer match results is proposed. It is based on a regularized Poisson regression model that includes various potentially influential covariates describing the national teamsâ€™ success in previous FIFA World Cups. Additionally, within the generalized linear model (GLM) framework, also differences of team-specific effects are incorporated. In order to achieve variable selection and shrinkage, we use tailored Lasso approaches. Based on preceding FIFA World Cups, two models for the prediction of the FIFA World Cup 2014 are fitted and investigated. Based on the model estimates, the FIFA World Cup 2014 is simulated repeatedly and winning probabilities are obtained for all teams. Both models favor the actual FIFA World Champion Germany.",2015,Journal of Quantitative Analysis in Sports
