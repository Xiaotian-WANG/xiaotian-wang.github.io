title,abstract,year,journal
Learning and Estimation Applications of an Online Homotopy Algorithm for a Generalization of the Lasso,"The LASSO is a widely used shrinkage and selection method for linear regression. We propose a generalization of the LASSO in which the $l_1$ penalty is applied on a linear transformation of the regression parameters, allowing to input prior information on the structure of the problem and to improve interpretability of the results. We also study time varying system with an $l_1$-penalty on the variations of the state, leading to estimates that exhibit few ``jumps''. We propose a homotopy algorithm that updates the solution as additional measurements are available. The algorithm takes advantage of the sparsity of the solution for computational efficiency and is promising for mining large datasets. The algorithm is implemented on three experimental data sets representing applications to traffic estimation from sparsely sampled probe vehicles, flow estimation in tidal channels and text analysis of on-line news.",2013,Discrete and Continuous Dynamical Systems - Series S
Ensembles of Regularized Linear Models,"We propose an approach for building ensembles of regularized linear models by optimizing a novel objective function, that encourages sparsity within each model and diversity among them. Our procedure works on top of a given penalized linear regression estimator (e.g., Lasso, Elastic Net, SCAD) by fitting it to possibly overlapping subsets of features, while at the same time encouraging diversity among the subsets, to reduce the correlation between the predictions that result from each fitted model. The predictions from the models are then aggregated. For the case of an Elastic Net penalty and orthogonal predictors, we give a closed form solution for the regression coefficients in each of the ensembled models. An extensive simulation study and real-data applications show that the proposed method systematically improves the prediction accuracy of the base linear estimators being ensembled. Extensions to GLMs and other models are discussed.",2017,
Structural determinants of health among women who started selling sex as minors in Burkina Faso.,"OBJECTIVES
To explore the prevalence of and factors associated with initiation of selling sex as a minor.


DESIGN
Data were drawn from cross-sectional studies of adult female sex workers (FSW) recruited through respondent-driven sampling in Ouagadougou and Bobo-Dioulasso, Burkina Faso.


METHODS
FSW completed a questionnaire that included a retrospective question regarding the age at which they started selling sex. Separate multivariate logistic regression analyses were conducted for each city to examine associations with initiation of selling sex as a minor (<18 year old), controlling for current age.


RESULTS
Of study participants, 27.8% (194/698) reported selling sex as a minor, ranging from 24.4% (85/349) in Bobo-Dioulasso to 31.2% (85/349) in Ouagadougou. In Ouagadougou, early initiates were more than twice as likely to report someone ever forced them to have sex [age-adjusted odds ratio (aaOR): 2.54, 95% confidence interval (CI): 1.53 to 4.23]. In Bobo-Dioulasso, those who started as minors were more likely to report someone ever tortured them (aaOR: 2.29, 95% CI: 1.28 to 4.10). In both cities, early initiates were more likely to not use a condom with a client if offered more money (Ouagadougou aaOR: 2.34, 95% CI: 1.23 to 4.47; Bobo-Dioulasso aaOR: 2.37, 95% CI: 1.29 to 4.36). In Ouagadougou, women who had started selling sex at a young age were half as likely to have been tested for HIV more than once ever (aaOR: 0.50, 95% CI: 0.26 to 0.94). In Bobo-Dioulasso, early initiates were less likely to attend HIV-related talks or meetings (aaOR: 0.56, 95% CI: 0.33 to 0.97).


CONCLUSIONS
A substantial proportion of FSW in Burkina Faso started selling sex as minors. The findings show that there are heightened vulnerabilities associated with selling sex below age 18 years, including physical and sexual violence, client-related barriers to condom use, and lower access to HIV-related services.",2015,Journal of acquired immune deficiency syndromes
Adaptive LASSO for general transformation models with right censored data,"In this paper, we consider variable selection for general transformation models with right censored data and propose a unified procedure for both variable selection and estimation. We conduct the proposed procedure by maximizing penalized log-marginal likelihood function with Adaptive LASSO penalty (ALASSO) on regression coefficients. Two main advantages of this procedure are as follows: (i) the penalties can be assigned to regression coefficients adaptively by data according to the importance of corresponding covariates; (ii) it is free of baseline survival function and censoring distribution. Under some regular conditions, we show that the penalized estimates with ALASSO are n-consistent and enjoy oracle properties. Some simulation examples and Primary Biliary Cirrhosis Data application illustrate that our proposed procedure works very well for moderate sample size.",2012,Comput. Stat. Data Anal.
IntÃ©grer les donnÃ©es manquantes dans la sÃ©lection de variables pour donnÃ©es longitudinales,"Les Generalized estimating equations (GEE) sont une methode de regression utile pour l'analyse marginale en presence de mesures repetees. Dans le contexte longi-tudinale, il est frequent de faire face aux donnees manquantes ainsi qu'a de nombreuses variables mesurees au cours du temps. L'imputation multiple, outil populaire pour le traitement des donnees manquantes et plus particulierement les MI-GEE peuventetre utilises pour l'inference. Bien que les methodes pour traiter les donnees manquantes telles que les MI-GEE aientete mises place, la selection de variables pour GEE n'a pasete systematiquement developpee pour integrer les donnees manquantes. Le multiple imputation-least absolute shrinkage and selection operator (MI-LASSO) propose une selection consistante au sein des jeux de donnees imputes, mais ne permet pas de prendre en compte les correlations intra-patient. Nous presentons le MI-PGEE, multiple imputation-penalized generalized estimating equations, extension du MI-LASSO pour les donnees longitudinales. Cette methode utilise les GEE penalises par une penalite ridge et des poids adaptatifs qui sont communsa l'ensemble des coefficients de regression estimes de la meme variable sur lesechantillons multi-imputes. Nous presentons un critere de type BIC pour le choix du parametre de regularisation. Le MI-PGEE fournit une selection consistante sur l'ensemble des imputations, ce qui en fait une methode de selection pour donnees longitudinales capable d'integrer les donnees manquantes et les correlations intra-sujet. Une application sur le sous groupe placebo de la base de donnees Strontium ranelate Efficacy in Knee OsteoarthrItis triAl (SEKOIA) est presentee.",2016,
The Factor-Lasso and K-Step Bootstrap Approach for Inference in High-Dimensional Economic Applications,"We consider inference about coefficients on a small number of variables of interest in a linear panel data model with additive unobserved individual and time specific effects and a large number of additional time-varying confounding variables. We allow the number of these additional confounding variables to be larger than the sample size, and suppose that, in addition to unrestricted time and individual specific effects, these confounding variables are generated by a small number of common factors and high-dimensional weakly-dependent disturbances. We allow that both the factors and the disturbances are related to the outcome variable and other variables of interest. To make informative inference feasible, we impose that the contribution of the part of the confounding variables not captured by time specific effects, individual specific effects, or the common factors can be captured by a relatively small number of terms whose identities are unknown. Within this framework, we provide a convenient computational algorithm based on factor extraction followed by lasso regression for inference about parameters of interest and show that the resulting procedure has good asymptotic properties. We also provide a simple k-step bootstrap procedure that may be used to construct inferential statements about parameters of interest and prove its asymptotic validity. The proposed bootstrap may be of substantive independent interest outside of the present context as the proposed bootstrap may readily be adapted to other contexts involving inference after lasso variable selection and the proof of its validity requires some new technical arguments. We also provide simulation evidence about performance of our procedure and illustrate its use in two empirical applications.",2016,arXiv: Methodology
Estimation and Variable Selection for Semiparametric Additive Partial Linear Models (SS-09-140).,"Semiparametric additive partial linear models, containing both linear and nonlinear additive components, are more flexible compared to linear models, and they are more efficient compared to general nonparametric regression models because they reduce the problem known as ""curse of dimensionality"". In this paper, we propose a new estimation approach for these models, in which we use polynomial splines to approximate the additive nonparametric components and we derive the asymptotic normality for the resulting estimators of the parameters. We also develop a variable selection procedure to identify significant linear components using the smoothly clipped absolute deviation penalty (SCAD), and we show that the SCAD-based estimators of non-zero linear components have an oracle property. Simulations are performed to examine the performance of our approach as compared to several other variable selection methods such as the Bayesian Information Criterion and Least Absolute Shrinkage and Selection Operator (LASSO). The proposed approach is also applied to real data from a nutritional epidemiology study, in which we explore the relationship between plasma beta-carotene levels and personal characteristics (e.g., age, gender, body mass index (BMI), etc.) as well as dietary factors (e.g., alcohol consumption, smoking status, intake of cholesterol, etc.).",2011,Statistica Sinica
Signature Selection for Grouped Features with a Case Study on Exon Microarrays,"When features are grouped, it is desirable to perform feature selection groupwise in addition to selecting individual features. It is typically the case in data obtained by modern high-throughput genomic profiling technologies such as exon microarrays, which measure the amount of gene expression in fine resolution. Exons are disjoint subsequences corresponding to coding regions in genes, and exon microarrays enable us to study the event of different usage of exons, called alternative splicing, which is presumed to contribute to development of diseases. To identify such events, all exons that belong to a relevant gene may have to be selected, perhaps with different weights assigned to them to detect most relevant ones. In this chapter we discuss feature selection methods to handle grouped features. A popular shrinkage method, lasso, and its variants will be our focus, that are based on regularized regression with generalized linear models. Data from exon microarrays will be used for a case study.",2015,
Forecasting college football game outcomes using modern modeling techniques,"There are many reasons why data scientists and fans of college football would want to forecast the outcome of games â€“ gambling, game preparation and academic research, for example. As advanced statistical methods become more readily accessible, so do the opportunities to develop robust forecasting models. Using data from the 2011 to 2014 seasons, we implemented a variety of advanced modeling techniques to determine which best forecasts the outcome of games. These methods included ridge regression, the lasso, the elastic net, neural networks, random forests, k-nearest neighbors, stochastic gradient boosting, and a Bayesian regression model. To evaluate the efficacy of the proposed models, we tested them on data from the 2015 season. The top performers â€“ lasso regression, a Bayesian regression with team-specific variances, stochastic gradient boosting, and random forests â€“ predicted the correct outcome over 70% of the time, and the lasso model proved most accurate at predicting win-loss outcomes in the 2015 test data set. 7",2020,Journal of Systems Architecture
Application d'un modÃ¨le de prÃ©vision de la santÃ© des enfants en relation avec les conditions environnementales,"La determination des risques de sante a l'enfance implique une tÃ¢che predictive importante. Identifier ces facteurs de risques permet d'intervenir rapidement et de reduire les consequences nefastes d'une mauvaise sante de l'enfant sur sa vie future. Bien que plusieurs determinants socioeconomiques aient deja ete montres comme causes importantes de mauvaise sante chez l'enfant, peu d'etudes utilisent des variables environnementales dans leur modele. C'est en ce sens que ce memoire s'interesse a l'apport de variables environnementales dans la prediction de la sante de l'enfant. Les donnees utilisees proviennent de l'echantillon d'enfants longitudinal de l'Enquete longitudinale nationale sur les enfants et les jeunes (ELNEJ) et de la Base de donnees pancanadienne sur la qualite de l'air (BDPQA). Les predictions sont faites avec differents modeles de regressions et de methodes en arbre a plusieurs stades de l'enfance, avec et sans variables environnementales. Les resultats revelent que les deux meilleures methodes de predictions sont la methode lasso avec forme fonctionnelle Logit, ainsi que la methode boosting. Les trois variables les plus predictives de la sante de l'enfant sont la sante de la mere a la naissance, la sante de l'enfant a la naissance et le revenu familial. L'ajout de variables environnementales dans la prediction semble surspecifier les modeles et ainsi, nuire a leur performance. 
______________________________________________________________________________ 
MOTS-CLES DE Lâ€™AUTEUR : sante, enfant, modeles de prediction, Logit, Probit, apprentissage automatique, ELNEJ, BDPQA",2018,
Developing deterioration models for Wyoming bridges.,"Deterioration models for the Wyoming Bridge Inventory were developed using both stochastic and deterministic models. The selection of explanatory variables is investigated and a new method using Least Absolute Shrinkage and Selection Operator (LASSO) regression to eliminate human bias in explanatory variable selection.The cross validation technique is used to determine the minimum number of explanatory variables. The relative significance of candidate variables is used to rank the explanatory variables in hierarchical order. The deterministic deterioration models are developed by using curve-fitting methods for the mean of bridge ages for each condition rating. In order to improve the accuracy in the model, bridges are split into the multiple subsets using first two explanatory variables for deck, superstructure, and substructure. Although the deterministic deterioration model is insufficient to predict condition ratings for a specific bridge, it is worthy to observe a general feature of how the functionality of bridges becomes worse over time. The stochastic models are developed to capture the uncertainty in the deterioration process using the Markov chain. The transition probability matrix is estimated using percentage prediction method,which counts the numbers corresponding to the element of transition probability matrix. The same subsets used in the deterministic deterioration models are considered. For each subset, zoning technique is used such that the bridge data is grouped for every 30 years to estimate transition probability matrix separately. The source codes are provided for the future update of bridge inventory and stochastic deterioration models. A computer program is used develop and plot deterioration models. A simple guideline is also included so that the user can access the source codes conveniently.",2016,
Identify Predictive SNP groups in Genome Wide Association Study: A Sparse Learning Approach,"Genome-Wide Association Study (GWAS) aims to identify genetic variants that are significantly associated with genetic traits. To analyze GWAS data that often contains 0.5 to 1 million Single Nucleotide Polymorphisms (SNPs) genotyped from thousands of individuals, stringent statistical significant thresholds are pre-defined for multiple testing adjustment, e.g., with p-value < 10 âˆ’8 for single SNP detection and at least < 10 âˆ’12 for SNP-SNP interaction detection. Such stringent thresholds were used for efficiency computation but it hinders the discovery of many true genetic variants and more practical approaches are needed to conduct GWAS. In this paper, we propose a machine learning approach to identify groups of predictive SNPs in GWAS analysis. Our method differs from other methods by first translates the genomics knowledge into SNP grouping as priors, then select a list of most predictive SNP groups using linear regression regularized by group sparse constraints, solved by Group-lasso (Least Absolute Shrinkage and Selection Operator). The selected SNPs groups compose a sparse feature space which yields a higher predictive power for continuous trait prediction. We conduct experiment on SiMES (Singapore Malay Eye Study) data set, with 3280 Malay individuals genotyped on Illumina 610 quad arrays. We investigate one discrete trait (Glaucoma) and two glaucoma-related quantitative traits, optic Disc-Cup-Ratio (CDR) and Intraocular Pressure (IOP). The hypothesis is that, with more biological knowledge embedded, a learning mechanism yields higher predictive power. Our preliminary results support the above hypothesis. Further analysis reveals that our approach can identify groups of SNPs highly associated with a particular genetic trait, in spite of the small sample size and the incomplete biological knowledge.",2012,
Tuning parameter selection for the adaptive LASSO in the autoregressive model,"Abstract We study the adaptive least absolute shrinkage and selection operator (LASSO) for the sparse autoregressive model (AR). Here, the sparsity of the AR model implies some of the autoregression coefficients are exactly zero, that must be excluded from the AR model. We propose the modified Bayesian information criterion (MBIC) as a way of selecting an optimal tuning parameter for the adaptive LASSO, which must be the most critical point in using the adaptive LASSO for the AR model. We prove that the adaptive LASSO obtained by minimizing the MBIC correctly distinguishes the true autoregression coefficients from zero asymptotically. The results hold even when the numbers of zero and nonzero true autoregression coefficients are diverging to infinity and the minimum of the absolute values of nonzero true autoregression coefficients decreases toward zero as the sample size increases. A small number of numerical studies are conducted to confirm the theoretical results.",2017,Journal of The Korean Statistical Society
Regularized matrix regression.,"Modern technologies are producing a wealth of data with complex structures. For instance, in two-dimensional digital imaging, flow cytometry and electroencephalography, matrix-type covariates frequently arise when measurements are obtained for each combination of two underlying variables. To address scientific questions arising from those data, new regression methods that take matrices as covariates are needed, and sparsity or other forms of regularization are crucial owing to the ultrahigh dimensionality and complex structure of the matrix data. The popular lasso and related regularization methods hinge on the sparsity of the true signal in terms of the number of its non-zero coefficients. However, for the matrix data, the true signal is often of, or can be well approximated by, a low rank structure. As such, the sparsity is frequently in the form of low rank of the matrix parameters, which may seriously violate the assumption of the classical lasso. We propose a class of regularized matrix regression methods based on spectral regularization. A highly efficient and scalable estimation algorithm is developed, and a degrees-of-freedom formula is derived to facilitate model selection along the regularization path. Superior performance of the method proposed is demonstrated on both synthetic and real examples.",2014,"Journal of the Royal Statistical Society. Series B, Statistical methodology"
Prediction of carcass composition and individual carcass cuts of Japanese Black steers.,"The objective of this study was to develop equations to predict carcass tissue weights and percentages and boneless carcass non-trimmed cut weights by using the cold carcass weight (CCW) and three other traits at the 6-7th rib section, which are routinely collected in carcass markets in Japan. Carcasses from 94 Japanese Black steers were used for the multiple regression analysis with a stepwise procedure and a novel Least Absolute Shrinkage and Selection Operator (LASSO). The accuracies of prediction (R(2)) and RMSEs for the carcass tissue and cut weights were similar between the two procedures. In contrast, LASSO appeared to be the better procedure for predicting carcass tissue percentages. The longissimus muscle area and subcutaneous fat thickness were the important predictors for the lean percentage in the stepwise procedure, and CCW was additionally selected when the LASSO procedure was used.",2014,Meat science
Analysis of multiple exposures in the case-crossover design via sparse conditional likelihood.,"We adapt the least absolute shrinkage and selection operator (lasso) and other sparse methods (elastic net and bootstrapped versions of lasso) to the conditional logistic regression model and provide a full R implementation. These variable selection procedures are applied in the context of case-crossover studies. We study the performances of conventional and sparse modelling strategies by simulations, then empirically compare results of these methods on the analysis of the association between exposure to medicinal drugs and the risk of causing an injurious road traffic crash in elderly drivers. Controlling the false discovery rate of lasso-type methods is still problematic, but this problem is also present in conventional methods. The sparse methods have the ability to provide a global analysis of dependencies, and we conclude that some of the variants compared here are valuable tools in the context of case-crossover studies with a large number of variables.",2012,Statistics in medicine
Sparse Correspondence Analysis,"Since the introduction of the lasso in regression, various sparse methods have been developped in an unsupervised context like sparsePCA which is a combination of feature selection and dimension reduction. Their interest is to simplify the interpretation of the pseudo principal components since each is expressed as a linear combination of only a small number of variables. The disadvantages lie on the one hand in the difficulty of choosing the number of non-zero coefficients in the absence of a criterion and on the other hand in the loss of orthogonality properties for the components and/or the loadings. In this paper we are interested in sparse variants of correspondence analysis (CA) for large contingency tables like documents-terms matrices. We use the fact that CA is both a PCA (or a weighted SVD) and a canonical analysis, in order to develop column sparse CA and rows and columns doubly sparse CA.",2019,
ACOs with risk-bearing experience are likely taking steps to reduce low-value medical services.,"OBJECTIVES
Accountable care organizations (ACOs) are groups of healthcare providers responsible for quality of care and spending for a defined patient population. The elimination of low-value medical services will improve quality and reduce costs and, therefore, ACOs should actively work to reduce the use of low-value services. We set out to identify ACO characteristics associated with implementation of strategies to reduce overuse.


STUDY DESIGN
Survey analysis.


METHODS
We used the National Survey of ACOs to determine the percentage of responding ACOs aware of the Choosing Wisely campaign and to what degree ACOs have taken steps to reduce the use of low-value services. We identified characteristics of ACOs associated with implementing low-value care-reducing strategies using 3 statistical models (stepwise and LASSO logistic regression and random forest).


RESULTS
Responding executives of 155 of 267 ACOs (58%) were aware of Choosing Wisely. Eighty-four of those 155Â ACO leaders said that their ACOs also actively implemented strategies to reduce the use of low-value services, largely through educating physicians and stimulating shared decision making. All 3 models identified the presence of at least 1 commercial payer contract and prior joint experience pursuing risk-based payment contracts as the most important predictors of an ACO actively implementing strategies to reduce low-value care.


CONCLUSIONS
In the first year of implementation, just one-third of ACOs had taken steps to reduce the use of low-value medical services. Safety-net ACOs and those with little experience as a risk-bearing organization need more time and support from healthcare payers and the Choosing Wisely campaign to prioritize the reduction of overuse.",2018,The American journal of managed care
Risk assessment models for genetic risk predictors of lung cancer using two-stage replication for Asian and European populations,"In the past ten years, great successes have been accumulated by taking advantage of both candidate-gene studies and genome-wide association studies. However, limited studies were available to systematically evaluate the genetic effects for lung cancer risk with large-scale and different ethnic populations. We systematically reviewed relevant literatures and filtered out 241 important genetic variants identified in 124 articles. A two-stage case-control study within specific subgroups was performed to assess the effects [Training set: 2,331 cases vs. 3,077 controls (Chinese population); testing set: 1,937 cases vs. 1,984 controls (European population)]. Variable selection and model development were used LASSO penalized regression and genetic risk score (GRS) system. Further change in area under the receiver operator characteristic curves (AUC) made by the epidemiologic model with and without GRS was used to compare predictions. It kept 38 genetic variants in our study and the ratios of lung cancer risk for subjects in the upper quartile GRS was three times higher compared to that in the low quartile (odds ratio: 4.64, 95% CI: 3.87-5.56). In addition, we found that adding genetic predictors to smoking risk factor-only model improved lung cancer predictive value greatly: AUC, 0.610 versus 0.697 (P < 0.001). Similar performance was derived in European population and the combined two data sets. Our findings suggested that genetic predictors could improve the predictive ability of risk model for lung cancer and highlighted the application among different populations, indicating that the lung cancer risk assessment model will be a promising tool for high risk population screening and prediction.",2017,Oncotarget
Introducing novel and comprehensive models for predicting recurrence in breast cancer using the group LASSO approach: are estimates of early and late recurrence different?,"BackgroundIn here, we constructed personalized models for predicting breast cancer (BC) recurrence according to timing of recurrence (as early and late recurrence).MethodsAn efficient algorithm called group LASSO was used for simultaneous variable selection and risk factor prediction in a logistic regression model.ResultsFor recurrence <â€‰5Â years, age (OR 0.96, 95% CIâ€‰=â€‰0.95â€“0.97), number of pregnancies (OR 0.94, 95% CIâ€‰=â€‰0.89â€“0.99), family history of other cancers (OR 0.73, 95% CIâ€‰=â€‰0.60â€“0.89), hormone therapy (OR 0.76, 95% CIâ€‰=â€‰0.61â€“0.96), dissected lymph nodes (OR 0.98, 95% CIâ€‰=â€‰0.97â€“0.99), right-sided BC (OR 0.87, 95% CIâ€‰=â€‰0.77â€“0.99), diabetes (OR 0.77, 95% CIâ€‰=â€‰0.60â€“0.98), history of breast operations (OR 0.38, 95% CIâ€‰=â€‰0.17â€“0.88), smoking (OR 5.72, 95% CIâ€‰=â€‰2.11â€“15.55), history of breast disease (OR 3.32, 95% CIâ€‰=â€‰1.92â€“5.76), in situ component (OR 1.58, 95% CIâ€‰=â€‰1.35â€“1.84), tumor necrosis (OR 1.87, 95% CIâ€‰=â€‰1.57â€“2.22), sentinel lymph node biopsy (SLNB) (OR 2.90, 95% CIâ€‰=â€‰2.05â€“4.11) and SLNB+axillary node dissection (OR 3.50, 95% CIâ€‰=â€‰2.26â€“5.42), grade 3 (OR 1.79, 95% CIâ€‰=â€‰1.46â€“2.21), stage 2 (OR 2.71, 95% CIâ€‰=â€‰2.18â€“3.35), stages 3 and 4 (OR 5.01, 95% CIâ€‰=â€‰3.52â€“7.13), and mastectomy+radiotherapy (OR 2.97, 95% CIâ€‰=â€‰2.39â€“3.68) were predictors of recurrence <â€‰5Â years. Moreover, relative to mastectomy without radiotherapy (as reference for comparison), quadrantectomy without radiotherapy had a noticeably higher odds ratio compared to quadranectomy with radiotherapy for recurrence <â€‰5Â years. (OR 17.58, 95% CIâ€‰=â€‰6.70â€“46.10 vs. OR: 2.50, 95% CIâ€‰=â€‰2â€“3.12).Accuracy, sensitivity, and specificity of the model were 82%, 75.6%, and 74.9%, respectively.For recurrence >â€‰5Â years, stage 2 cancer (OR 1.67, 95% CIâ€‰=â€‰1.31â€“2.14) and radiotherapy+mastectomy (OR 2.45, 95% CIâ€‰=â€‰1.81â€“3.32) were significant predictors; furthermore, relative to mastectomy without radiotherapy (as reference for comparison), quadranectomy without radiotherapy had a noticeably higher odds ratio compared to quadranectomy with radiotherapy for recurrence >â€‰5Â years (OR 7.62, 95% CIâ€‰=â€‰1.52â€“38.15 vs. OR 1.75, 95% CIâ€‰=â€‰1.32â€“2.32). Accuracy, sensitivity, and specificity of the model were 71%, 78.8%, and 55.8%, respectively.ConclusionFor the first time, we constructed models for estimating recurrence based on timing of recurrence which are among the most applicable models with excellent accuracy (>â€‰80%).",2018,World Journal of Surgical Oncology
Simple principal component analysis using Lasso,"In this study, a simple principal component analysis using Lasso is proposed. This method consists of two steps. The first step is to compute principal components by the principal component analysis. The second step is to regress each principal component on the original data matrix by Lasso regression method. Each of new principal components is computed as the linear combination of original data matrix using the scaled estimated Lasso regression coefficient as the coefficients of the combination. This method leads to easily interpretable principal components with more 0 coefficients by the properties of Lasso regression models. This is because the estimator of the regression of each principal component on the original data matrix is the corresponding eigenvector. This method is applied to real and simulated data sets with the help of an R package for Lasso regression and its usefulness is demonstrated.",2013,
Triple categorical regression for genomic selection: application to cassava breeding,"Genome-wide selection (GWS) is currently a technique of great importance in plant breeding, since it improves efficiency of genetic evaluations by increasing genetic gains. The process is based on genomic estimated breeding values (GEBVs) obtained through phenotypic and dense marker genomic information. In this context, GEBVs of N individuals are calculated through appropriate models, which estimate the effect of each marker on phenotypes, allowing the early identification of genetically superior individuals. However, GWS leads to statistical challenges, due to high dimensionality and multicollinearity problems. These challenges require the use of statistical methods to approach the regularization of the estimation process. Therefore, we aimed to propose a method denominated as triple categorical regression (TCR) and compare it with the genomic best linear unbiased predictor (G-BLUP) and Bayesian least absolute shrinkage and selection operator (BLASSO) methods that have been widely applied to GWS. The methods were evaluated in simulated populations considering four different scenarios. Additionally, a modification of the G-BLUP method was proposed based on the TCR-estimated (TCR/G-BLUP) results. All methods were applied to real data of cassava (Manihot esculenta) with to increase efficiency of a current breeding program. The methods were compared through independent validation and efficiency measures, such as prediction accuracy, bias, and recovered genomic heritability. The TCR method was suitable to estimate variance components and heritability, and the TCR/G-BLUP method provided efficient GEBV predictions. Thus, the proposed methods provide new insights for GWS.",2019,Scientia Agricola
Using Modified Lasso Regression to Learn Large Undirected Graphs in a Probabilistic Framework,"Learning the structures of large undirected graphs with thousands of nodes from data has been an open challenge. In this paper, we use graphical Gaussian model (GGM) as the underlying model and propose a novel ARD style Wishart prior for the precision matrix of the GGM. which encodes the graph structure we want to learn. With this prior, we can get the MAP estimation of the precision matrix by solving (a modified version of) Lasso regressions and achieve a sparse solution. We use our approach to learn genetic regulatory networks from genome-wide expression microarray data and protein-binding location analysis data. Evaluated on the basis of consistency with the GO annotations, the experiments show that our approach has a much better performance than the clustering-based approaches and BN learning approaches in discovering gene regulatory modules.",2005,
Sparsity-Cognizant Total Least-Squares for Perturbed Compressive Sampling,"Solving linear regression problems based on the total least-squares (TLS) criterion has well-documented merits in various applications, where perturbations appear both in the data vector as well as in the regression matrix. However, existing TLS approaches do not account for sparsity possibly present in the unknown vector of regression coefficients. On the other hand, sparsity is the key attribute exploited by modern compressive sampling and variable selection approaches to linear regression, which include noise in the data, but do not account for perturbations in the regression matrix. The present paper fills this gap by formulating and solving (regularized) TLS optimization problems under sparsity constraints. Near-optimum and reduced-complexity suboptimum sparse (S-) TLS algorithms are developed to address the perturbed compressive sampling (and the related dictionary learning) challenge, when there is a mismatch between the true and adopted bases over which the unknown vector is sparse. The novel S-TLS schemes also allow for perturbations in the regression matrix of the least-absolute selection and shrinkage selection operator (Lasso), and endow TLS approaches with ability to cope with sparse, under-determined â€œerrors-in-variablesâ€ models. Interesting generalizations can further exploit prior knowledge on the perturbations to obtain novel weighted and structured S-TLS solvers. Analysis and simulations demonstrate the practical impact of S-TLS in calibrating the mismatch effects of contemporary grid-based approaches to cognitive radio sensing, and robust direction-of-arrival estimation using antenna arrays.",2011,IEEE Transactions on Signal Processing
Restarting the accelerated coordinate descent method with a rough strong convexity estimate,"We propose new restarting strategies for the accelerated coordinate descent method. Our main contribution is to show that for a well chosen sequence of restarting times, the restarted method has a nearly geometric rate of convergence. A major feature of the method is that it can take profit of the local quadratic error bound of the objective function without knowing the actual value of the error bound. We also show that under the more restrictive assumption that the objective function is strongly convex, any fixed restart period leads to a geometric rate of convergence. Finally, we illustrate the properties of the algorithm on a regularized logistic regression problem and on a Lasso problem.",2020,Computational Optimization and Applications
A Novel Predictive Method Incorporating Parameters of Main Pulmonary Artery Bifurcation for Short-Term Prognosis in Non-high-risk Acute Pulmonary Embolism Patients,"The aim of this study was to build a formula to predict short-term prognosis using main pulmonary artery (MPA) parameters reconstructed from computed tomographic pulmonary angiography in non-high-risk acute pulmonary embolism (PE) patients. After reconstructing the MPA and its centerline, the MPA, the right and left pulmonary artery inlet, and the MPA outlet plane were differentiated to measure the cross-sectional area (CSA), the maximal diameter and the hydraulic diameter. The MPA bifurcation area, volume and angle were measured. MPA dilation was defined as >29 mm at the transverse section plane. The patients were randomly divided into a training set and a validation set. A least absolute shrinkage and selection operator (LASSO) logistic regression algorithm was used to build a predictive formula. The performances of the predictive formula from LASSO were tested by the area under the receiver operating characteristic curve (AUC) and precision-recall (PR) curve with 10-fold cross-validation. The clinical utility was assessed by decision curve analysis (DCA). In total, 296 patients were enrolled and randomly divided (50:50) into a training set and a validation set. The LASSO predictive formula (lambda.1SE) was as follows: 0.92 Ã— MPA bifurcation area + 0.50 Ã— MPA outlet hydraulic diameter + 0.10 Ã— MPA outlet CSA. The AUCs of the predictive formula were 0.860 (95% CI: 0.795â€“0.912) and 0.943 (95% CI: 0.892â€“0.975) in the training set and validation set, respectively. The LASSO predictive formula had a higher average area under the PR curve than MPA dilation (0.71 vs. 0.23 in the training set and 0.55 vs. 0.23 in the validation set) and added a net benefit in clinical utility by DCA. Integration of MPA outlet CSA, hydraulic diameter, and bifurcation area with the LASSO predictive formula as a novel weighting method facilitated the prediction of poor short-term prognosis within 30 days after hospital admission in non-high-risk acute PE patients.",2020,
$L_1$-Penalization in Functional Linear Regression with Subgaussian Design,"We study functional regression with random subgaussian design and real-valued response. The focus is on the problems in which the regression function can be well approximated by a functional linear model with the slope function being ""sparse"" in the sense that it can be represented as a sum of a small number of well separated ""spikes"". This can be viewed as an extension of now classical sparse estimation problems to the case of infinite dictionaries. We study an estimator of the regression function based on penalized empirical risk minimization with quadratic loss and the complexity penalty defined in terms of $L_1$-norm (a continuous version of LASSO). The main goal is to introduce several important parameters characterizing sparsity in this class of problems and to prove sharp oracle inequalities showing how the $L_2$-error of the continuous LASSO estimator depends on the underlying sparsity of the problem.",2013,arXiv: Statistics Theory
Investigation of factors affecting the intelligence quotient (IQ) of intellectually disabled children and adolescents using modern regression approaches,"Abstract 
Background: Research shows that in addition to biological factors, psychological and social risk factors play a role in the development of intellectual disability. 
Objectives: This study aimed to investigate the familial, personal and educational factors affecting the intelligence quotient (IQ) levels of intellectually disabled children and adolescents via regularized regression approaches (RRAs) and to compare the results with those of conventional regression approach (CRA). 
Methods: A total of sixty characteristics were examined along with dummy variables of 205 children and adolescents selected according to the study protocol. Compact, Lasso, Ridge and Ridged Lasso RRAs were used in the dataset. 
Results: The optimal model was obtained with the Lasso approach and contained ten risk factors having a significant effect on IQ levels: diagnosis of cerebral palsy, age at onset of speech, duration of education, age at onset of walking, presence of elimination disorders, presence of attention-deficit hyperactivity disorder, family income, and number of siblings, residence and age. The RRAs provided opportunity to examine more factors than CRAs without requiring the fulfillment of strict CRA assumptions. 
Conclusions: Due to the advantages of RRAs, expanding their clinical usage for very large datasets was recommended. [Ethiop. J. Health Dev. 2018;32(1):21-28] 
Keywords: Intelligence quotient, intellectual disability, regularized regression, Lasso, Ridged Lass",2018,Ethiopian Journal of Health Development
A New Estimator By Generalized Modified Jackknife Ridge Regression Estimator,"Multicollinearity is an important problem in regression which produces undesirable effects on the least squares estimator. Ridge regression is one of the well known solutions to the multicollinearity problem.Specifically, the Generalized Ridge Regression (GRR) estimation leads to reduction in the sampling variance whereas Jackknifed Ridge Regression (JRR) estimation leads to reduction in the bias. Batah et al. [1] proposed Modified Jackknife Ridge R egression Estimator (MJR) by combining th e i deas of GRR and JRR estimators. In this article, we propose a new estimator namely, Generalized Jackknife Ridge Regression Estimator (GJR) by generalizing the MJR. We showed that new proposed estimator (GJR) is superior in the Mean Square Error (MSE) sense to the LASSO estimator, Generalized Ridge Regression estimator, Jackknifed Ridge Regression estimator and Modified Jackknifed Ridge Regression estimator.",2011,
