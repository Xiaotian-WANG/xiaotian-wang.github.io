title,abstract,year,journal
Detection of Prostatic Inflammation From Peripheral Lymphocyte Count and Free/Total PSA Ratio in Men With LUTS/BPH,"Objective Identifying biomarkers of prostatic inflammation has been a question of great interest in the development of anti-inflammatory pharmacotherapy for lower urinary tract symptoms suggestive of benign prostatic hyperplasia (LUTS/BPH). Systemic inflammation and serum prostate-specific antigen (PSA) have been linked with prostatic inflammation. This study set out to develop a diagnostic model for prostatic inflammation using clinical and laboratory parameters. Methods We included LUTS/BPH patients undergoing transurethral resection of the prostate. The severity of prostatic inflammation was determined by pathological review. Clinical manifestations and preoperative laboratory test results were recorded. We used LASSO regression with 10-fold cross-validation to select variables with the most diagnostic value of prostatic inflammation. Furthermore, we used multivariable logistic regression analysis to develop the diagnostic model, presented in a nomogram. The discrimination, calibration of the post-LASSO diagnostic model, and the model supplemented with clinical parameters were assessed. Decision curve analysis was performed. Results A total of 164 patients were included. Of all patients, 97 (59.1%) had no or mild prostatic inflammation, and 67 (40.9%) had moderate to severe prostatic inflammation. A higher peripheral white blood cell count, higher peripheral lymphocyte count, lower free/total (f/t) PSA ratio, and acute urinary retention history were associated with a higher risk of moderate to severe prostatic inflammation. Peripheral lymphocyte count and f/t PSA ratio were selected by the LASSO method and entered into the nomogram. The post-LASSO diagnostic model had an AUC of 0.756 (95% CI: 0.684â€“0.829) and good calibration. The addition of clinical parameters failed to show incremental diagnostic value. The decision curve analysis demonstrated that the post-LASSO laboratory nomogram was clinically useful. Conclusion Our findings demonstrated that peripheral lymphocyte count and f/t PSA ratio appear to be reliable diagnostic markers, based on which we build a clinically useful nomogram for prostatic inflammation. This diagnostic model could facilitate the development of anti-inflammatory pharmacotherapy for LUTS/BPH. Before this model is adopted in clinical practice, future validation is needed to determine its clinical utility.",2020,
Simultaneous estimation and factor selection in quantile regression via adaptive sup-norm regularization,"Some regularization methods, including the group lasso and the adaptive group lasso, have been developed for the automatic selection of grouped variables (factors) in conditional mean regression. In many practical situations, such a problem arises naturally when a set of dummy variables is used to represent a categorical factor and/or when a set of basis functions of a continuous variable is included in the predictor set. Complementary to these earlier works, the simultaneous and automatic factor selection is examined in quantile regression. To incorporate the factor information into regularized model fitting, the adaptive sup-norm regularized quantile regression is proposed, which penalizes the empirical check loss function by the sum of factor-wise adaptive sup-norm penalties. It is shown that the proposed method possesses the oracle property. A simulation study demonstrates that the proposed method is a more appropriate tool for factor selection than the adaptive lasso regularized quantile regression.",2012,Comput. Stat. Data Anal.
Additive Models for Quantile Regression: Some New Methods for R,"This brief report describes some recent developments of the R quantreg package to incorporate methods for additive models. The methods are illustrated with an application to modeling childhood malnutrition in India. Models with additive nonparametric effects offer a valuable dimension reduction device throughout applied statistics. In this paper we describe some recent developments of additive models for quantile regression. These methods employ the total variation smoothing penalties introduced in Koenker, Ng, and Portnoy (1994) for univariate components and Koenker and Mizera (2004) for bivariate components. We focus on selection of smoothing parameters including lasso-type selection of parametric components, and on post selection inference methods. Additive models have received considerable attention since their introduction by Hastie and Tibshirani (1986, 1990). They provide a pragmatic approach to nonparametric regression modeling; by restricting nonparametric components to be composed of low-dimensional additive pieces we can circumvent some of the worst aspects of the notorious curse of dimensionality. It should be emphasized that we use the word â€œcircumventâ€™ advisedly, in full recognition that we have only swept difficulties under the rug by the assumption of additivity. When conditions for additivity are violated there will obviously be a price to pay. 1. Additive Models for Quantile Regression Our approach to additive models for quantile regression and especially our implementation of methods in R is heavily influenced by Wood (2006, 2009) . In some fundamental respects the approaches are quite distinct: Gaussian likelihood is replaced by (Laplacean) quantile fidelity, squared L2 norms as measures of the roughness of fitted functions are replaced by corresponding L1 norms measuring total variation, and truncated basis expansions are supplanted by sparse algebra as a computational expedient. But in other respects the structure of the models is quite similar. We will consider models for conditional quantiles of the general form: Version: September 5, 2009. This research was partially supported by NSF grant SES-08-50060. I would like to express my appreciation to Ying Li for excellent research assistance. All of the methods described below have been implemented in version 4.42 of the quantreg package for R, Koenker (2009).",2010,
Toward Probabilistic Diagnosis and Understanding of Depression Based on Functional MRI Data Analysis with Logistic Group LASSO,"Diagnosis of psychiatric disorders based on brain imaging data is highly desirable in clinical applications. However, a common problem in applying machine learning algorithms is that the number of imaging data dimensions often greatly exceeds the number of available training samples. Furthermore, interpretability of the learned classifier with respect to brain function and anatomy is an important, but non-trivial issue. We propose the use of logistic regression with a least absolute shrinkage and selection operator (LASSO) to capture the most critical input features. In particular, we consider application of group LASSO to select brain areas relevant to diagnosis. An additional advantage of LASSO is its probabilistic output, which allows evaluation of diagnosis certainty. To verify our approach, we obtained semantic and phonological verbal fluency fMRI data from 31 depression patients and 31 control subjects, and compared the performances of group LASSO (gLASSO), and sparse group LASSO (sgLASSO) to those of standard LASSO (sLASSO), Support Vector Machine (SVM), and Random Forest. Over 90% classification accuracy was achieved with gLASSO, sgLASSO, as well as SVM; however, in contrast to SVM, LASSO approaches allow for identification of the most discriminative weights and estimation of prediction reliability. Semantic task data revealed contributions to the classification from left precuneus, left precentral gyrus, left inferior frontal cortex (pars triangularis), and left cerebellum (c rus1). Weights for the phonological task indicated contributions from left inferior frontal operculum, left post central gyrus, left insula, left middle frontal cortex, bilateral middle temporal cortices, bilateral precuneus, left inferior frontal cortex (pars triangularis), and left precentral gyrus. The distribution of normalized odds ratios further showed, that predictions with absolute odds ratios higher than 0.2 could be regarded as certain.",2015,PLoS ONE
An Ordered Search for Subset Selection in Support Vector Orthogonal Regression,"Subset selection is an important task in many problems, especially when dealing with high dimensional problems, such as classification, regression, and others. In this sense, this work proposes an ordered search to select variables in orthogonal regression problems based on support vectors. The admissible search is based on a monotone property of the radius parameter. Thus, we use the radius of the SV-regression as an evaluation measure for the search, making it able to find the subsets with the smallest radius in each dimension of the problem without exhaustively exploring all possibilities. The main reason for choosing the orthogonal regression is due to the fact that this model also considers the existence of error in dependent variables. The obtained results, represented by the test error, when compared to the LASSO and a recursive feature elimination technique, demonstrate the efficiency of the method.",2019,
"AF Ablation ITarget of ablation of peri-mitral flutter: mitral valve isthmus or triggers?Comparison of sensitivity of transthoracic, transoesophageal, and intracardiac echocardiography for guiding transeptal puncturePulmonary antrum radial-linear ablation: a new therapy for atrial fibrillationPulmon","# Target of ablation of peri-mitral flutter: mitral valve isthmus or triggers? {#article-title-2}

Introduction Patients with previous ablation for atrial fibrillation (AF) may experience the recurrence of peri-mitral flutter (PMFL). These arrhythmias are usually triggered from sources that may also induce atrial fibrillation. We sought to determine whether ablation of triggers or completing mitral valve isthmus (MVI) block prevents more arrhythmia recurrences.

Methods A total of 65 patients with recurrent PMFL after initial ablation of long-standing persistent AF were included in the study. Thirty-two were randomized to MVI ablation only (Group 1) and 33 were randomized to cardioversion and repeat pulmonary vein (PV) isolation plus ablation of others non-PV triggers (Group 2).

Results MVI bidirectional block was achieved in all but one patient from Group 1. In Group 2, reconnection of 17 PVs was detected in 14 patients (42%, 1.21 veins per patient). With isoproterenol challenge, 44 non-PV trigger sites were identified in 28 patients (85%, 1.57 sites per patient). With a follow-up of 18 months, 27 patients (84%) from Group 1 had recurrent atrial arrhythmias and 15 remained on AAD, while 28 patients from Group 2 (85%, P < 0.0001 vs. Group 1) were free of arrhythmia off AAD. Cox regression model revealed that the ablation strategy used in Group 2 was associated with a significant lower risk of recurrence of atrial tachyarrhythmia (hazard ratio = 0.10, 95% CI = 0.04â€“0.28, P < 0.001). The Kaplanâ€“Meier curves demonstrated significant better arrhythmia-free survival in Group 2 compared with Group 1 (log rank P < 0.0001).

Conclusions In patients presenting with PMFL after ablation for long-standing persistent AF, MVI block had limited impact on arrhythmia recurrence. On the other hand, elimination of all PV and non-PV triggers achieved higher freedom from atrial arrhythmias at follow-up.

# Comparison of sensitivity of transthoracic, transoesophageal, and intracardiac echocardiography for guiding transeptal puncture {#article-title-3}

Objective Compare the sensitivity of transthoracic (TTE), transoesophageal (TEE), and intracardiac (ICE) echocardiography for guiding interatrial septum (IAS) puncture.

Methods The study consisted of 208 patients (48 females, mean age 56.4 Â± 11.3 years) who underwent RFA of LA because of atrial fibrillation. Transeptal puncture was performed after IAS visualization using TTE in 32 (15.4%), TEE in 26 (12.5%), ICE in 150 (72.1%) patients. Adequate contact of transeptal needle with IAS was defined as a tension of septum using echocardiographic techniques. Verification of tenting and following transeptal puncture with LA catheterization was defined as a true positive result. Lack of visualization of tenting with successful transeptal puncture under fluoroscopy was defined as a false-negative result.

Results Clear visualization of the IAS using TTE technique was demonstrated in 2 (6%) cases, and the sensitivity amounted for 6.7%. Obvious verification of IAS by TEE was revealed in 20 (77%) patients, and sensitivity of this technique was 86.9%. ICE control of septum puncture was performed in 127 patients. ICE allowed visualizing septum and tenting in 125 patients and the tension of septum was unable to be determined in two cases despite of the efforts of specialists. ICE sensitivity for IAS verification was 98.4%.

Conclusion ICE is the most sensitive ultrasound technique for verification of optimal location of the transeptal needle in the region of IAS comparing with TTE and TEE.

# Pulmonary antrum radial-linear ablation: a new therapy for atrial fibrillation {#article-title-4}

The abnormality of substrates in pulmonary vein antrum (PVA) plays a critical role in maintaining atrial fibrillation (AF). PVA radial-linear ablation (PVARA) was performed for an organized modification of substrates in paroxysmal AF. This study consisted of two phases: preclinical phase using 22 canine models with acutely induced AF, and clinical phase in patients with paroxysmal AF ( n = 15) in paired control with PV isolation. Radial-linear lesions were created from PV orifice to left atrium-PV junction in both dogs and patients. Successful creation of chronic radial-linear lesions was confirmed pathologically in dogs. The AF inducibility and duration decreased by 89 and 90%, respectively, after ablation in dogs. All the patients showed inducible AF prior to the procedure. No AF was inducible immediately after PVARA in 14 patients. The procedural time was significantly shorter in patients with PVARA than PV isolation. Within 1 week after ablation, there were six patients with early recurrent AF and seven with atrial tachycardia (AT) in PVARA group, and three patients with AF and six with AT in control. During follow-up of 6â€“12 months, 11 patients were free of AF and AT with four patients taking propafenone or amiodarone in the PVARA group, and nine patients free of AF and AT with seven patients taking propafenone or amiodarone in control. No complication related to the ablation developed in the two groups. This pilot study demonstrated that PVARA was a simple and safe strategy for paroxysmal AF ablation, and might provide a better long-term outcome than PV isolation.

# Pulmonary vein isolation with a multi-electrode ablation catheter using duly-cycled bipolar and unipolar radiofrequency energy {#article-title-5}

Background Traditional catheter ablation of atrial fibrillation (AF) requires long procedure times and high level of operator skill. A multielectrode catheter (PVAC, ablation frontier) combining circular mapping and duly-cycled bipolar and unipolar radiofrequency energy delivery has been developed to map and isolate the pulmonary veins.

Aim The aim of this study to evaluate the efficacy of PVAC for pulmonary vein isolation in paroxysmal AF ablation.

Methods Fifty consecutive patients with paroxysmal AF who had failed at least one anti-arrhythmic drug and eligible for catheter ablation were included in the study. All four pulmonary veins were isolated and confirmed the absence of pulmonary vein potentials with PVAC. At six months, 48 h Holter monitoring was performed to determine freedom of AF.

Results All patients had structurally normal hearts with a mean duration of AF of 4.28 + 4.39 years. The mean procedure time was 109.74 + 28.35Â min. Mean fluoroscopy time was 36.52 + 12.29Â min. Mean number of RF applications were 27.79 + 13.80 min. The mean follow-up duration was 9.39 + 4.90 months. After AF ablation with PVAC, 36 patients completed 6-month follow-up and 25 patients (69.4%) were in sinus rhythm without drugs. No procedure-related complication was observed.

Conclusions Pulmonary vein isolation using the PVAC has a success rate of âˆ¼70% with the first ablation.

# Autonomic mechanism for complex fractionated atrial electrograms: evidence by pathology {#article-title-6}

Background The mechanism(s) underlying complex fractionated atrial electrograms (CFAEs) has not been well elucidated. The present study addressed to observe the histological characteristics at the area with CFAEs in canine atria to investigate the mechanism of CFAEs.

Methods Ten adult mongrel dogs were involved in the present study. AF was induced through rapid atrial pacing with vagosympathetic nerve stimulation. CFAEs was recorded by Lasso catheter. Irrigated ablation was performed at sites with CFAEs. After finishing procedures above, all dogs were sacrificed and the whole hearts were taken out and fixed in 4Â¢Hformalin for more than 48 hours for histological examination. The specimens were divided into CFAEs group and non-CFAEs group. Serial sections were taken and stained with hematoxylin and eosin(HE) and general neural marker protein gene product 9.50(PGP9.50), respectively. Compare the characteristics of myocardial and autonomic nerve distribution between the CFAEs and non-CFAEs groups.

Results Sections stained by HE: The myocardium in non-CFAEs group was well-arranged, usually in parallel with little interstitial and epicardial adipose tissue. However, the myocardium in CFAEs group distributed in disorganization with more interstitial tissue and epicardial adipose tissue. Nerve fibers and ganglionated plexi (autonomic nerves) in CFAEs group were more abundant than non-CFAEs group (7Â±5.4 vs. 1.9Â±2.7; P<0.001). Autonomic nerves were abundant in epicardium.

Conclusion Disorganized myocardial distribution and abundant autonomic nerves may account for CFAEs formation, which may play an important role in the initiation and maintenance of AF.",2011,Europace
Use of a novel evolutionary algorithm for genomic selection,"Background: In the context of genomic selection in animal breeding, an 
important objective is to look for explicative markers for a phenotype under 
study. The challenge of this study was to propose a model, based on a small 
number of markers, to predict a quantitative trait. To deal with a high number of 
markers, we propose using combinatorial optimization to perform variable 
selection, associated with a multiple regression model in a first approach and a 
mixed model in a second, to predict the phenotype. 
Results:The efficiency of our two approaches, the first assuming that animals are 
independent and the second integrating familial relationships, was evaluated on 
real datasets. This reveals the importance of taking familial relationships into 
account as the performances of the second approach were better. For example, 
on PIC data the correlation is around 0.15 higher using our approach taking 
familial relationships into account than with the Lasso bounded to 96 selected 
markers. We also studied the importance of familial relationships on phenotypes 
with different heritabilities. Finally, we compared our approaches with classic 
approaches and obtained comparable results, sometimes better. 
Conclusion: This study shows the relevance of combining combinatorial 
optimization with a regression model to propose a predictive model based on a 
reasonable number of markers. Although this implies more parameters to be 
estimated and, therefore, takes longer to execute, it seems interesting to use a 
mixed model in order to take familial relationships between animals into account.",2015,
Task-Dependent Visual-Codebook Compression,"A visual codebook serves as a fundamental component in many state-of-the-art computer vision systems. Most existing codebooks are built based on quantizing local feature descriptors extracted from training images. Subsequently, each image is represented as a high-dimensional bag-of-words histogram. Such highly redundant image description lacks efficiency in both storage and retrieval, in which only a few bins are nonzero and distributed sparsely. Furthermore, most existing codebooks are built based solely on the visual statistics of local descriptors, without considering the supervise labels coming from the subsequent recognition or classification tasks. In this paper, we propose a task-dependent codebook compression framework to handle the above two problems. First, we propose to learn a compression function to map an originally high-dimensional codebook into a compact codebook while maintaining its visual discriminability. This is achieved by a codeword sparse coding scheme with Lasso regression, which minimizes the descriptor distortions of training images after codebook compression. Second, we propose to adapt our codebook compression to the subsequent recognition or classification tasks. This is achieved by introducing a label constraint kernel (LCK) into our compression loss function. In particular, our LCK can model heterogeneous kinds of supervision, i.e., (partial) category labels, correlative semantic annotations, and image query logs. We validated our codebook compression in three computer vision tasks: 1) object recognition in PASCAL Visual Object Class 07; 2) near-duplicate image retrieval in UKBench; and 3) web image search in a collection of 0.5 million Flickr photographs. Our compressed codebook has shown superior performances over several state-of-the-art supervised and unsupervised codebooks.",2012,IEEE Transactions on Image Processing
Whole genome analysis identifies the association of TP53 genomic deletions with lower survival in Stage III colorectal cancer,"DNA copy number aberrations (CNA) are frequently observed in colorectal cancers (CRC). There is an urgent need for CNA-based biomarkers in clinics,. n For Stage III CRC, if combined with imaging or pathologic evidence, these markers promise more precise care. We conducted this Stage III specific biomarker discovery with a cohort of 134 CRCs, and with a newly developed high-efficiency CNA profiling protocol. Specifically, we developed the profiling protocol for tumor-normal matched tissue samples based on low-coverage clinical whole-genome sequencing (WGS). We demonstrated the protocolâ€™s accuracy and robustness by a systematic benchmark with microarray, high-coverage whole-exome and -genome approaches, where the low-coverage WGS-derived CNA segments were highly accordant (PCC >0.95) with those derived from microarray, and they were substantially less variable if compared to exome-derived segments. A lasso-based model and multivariate cox regression analysis identified a chromosome 17p loss, containing the TP53 tumor suppressor gene, that was significantly associated with reduced survival (Pâ€‰=â€‰0.0139, HRâ€‰=â€‰1.688, 95% CIâ€‰=â€‰[1.112â€“2.562]), which was validated by an independent cohort of 187 Stage III CRCs. In summary, this low-coverage WGS protocol has high sensitivity, high resolution and low cost and the identified 17p-loss is an effective poor prognosis marker for Stage III patients.",2020,Scientific Reports
Using LASSO Regression to Predict Rheumatoid Arthritis Treatment Efficacy,"Rheumatoid arthritis (RA) accounts for one-fifth of the deaths due to arthritis, the leading cause of disability in the United States. Finding effective treatments for managing arthritis symptoms are a major challenge, since the mechanisms of autoimmune disorders are not fully understood and disease presentation differs for each patient. The American College of Rheumatology clinical guidelines for treatment consider the severity of the disease when deciding treatment, but do not include any prediction of drug efficacy. Using Electronic Health Records and Biomedical Linked Open Data (LOD), we demonstrate a method to classify patient outcomes using LASSO penalized regression. We show how Linked Data improves prediction and provides insight into how drug treatment regimes have different treatment outcome. Applying classifiers like this to decision support in clinical applications could decrease time to successful disease management, lessening a physical and financial burden on patients individually and the healthcare system as a whole.",2016,AMIA Summits on Translational Science Proceedings
Fall Ascertainment and Development of a Risk Prediction Model Using Electronic Medical Records.,"OBJECTIVES
To examine the use of electronic medical record (EMR) data to ascertain falls and develop a fall risk prediction model in an older population.


DESIGN
Retrospective longitudinal study using 10 years of EMR data (2004-2014). A series of 3-year cohorts included members continuously enrolled for a minimum of 3 years, requiring 2 years pre-fall (no previous record of a fall) and a 1-year fall risk period.


SETTING
Kaiser Permanente Hawaii, an ambulatory setting.


PARTICIPANTS
A total of 57 678 adults, age 60â€‰years and older.


MEASUREMENTS
Initial EMR searches were guided by current literature and geriatricians to understand coding sources of falls as our outcome. Falls were captured by two coding sources: International Classification of Diseases, Ninth Revision (ICD-9) codes (E880-889) and/or a fall listed as a ""primary reason for visit."" A comprehensive list of EMR predictors of falls were included into prediction models enabling statistical subset selection from many variables and modeling by logistic regression.


RESULTS
Although 72% of falls in the training data set were coded as ""primary reason for visit,"" 22% of falls were coded as ICD-9 and 6% coded as both. About 80% were reported in face-to-face encounters (eg, emergency department). A total of 2164 individuals had a fall in the risk period. Using the 13 key predictors (age, comorbidities, female sex, other mental disorder, walking issues, Parkinson's disease, urinary incontinence, depression, polypharmacy, psychotropic and anticonvulsant medications, osteoarthritis, osteoporosis) identified through LASSO regression, the final model had a sensitivity of 67%, specificity of 69%, positive predictive value of 8%, negative predictive value of 98%, and area under the curve of .74.


CONCLUSION
This study demonstrated how the EMR can be used to ascertain falls and develop a fall risk prediction model with moderate sensitivity/specificity. Concurrent work with clinical providers to enhance fall documentation will improve the ability of the EMR to capture falls and consequently may improve the model to predict fall risk.",2019,Journal of the American Geriatrics Society
Understanding the spectrum of residential energy-saving behaviours: French evidence using disaggregated data,"Analysing household energy-saving behaviours is crucial to improve energy consumption predictions and energy policy making. How should we quantitatively measure them ? What are their determinants ? This study explores the main factors influencing residential energy-saving behaviours based on a bottom-up multivariate statistical approach using data from the recent French PHEBUS survey. Firstly, we assess energy-saving behaviours on a one-dimension scale using IRT. Secondly, we use linear regression with an innovative variable selection method via adaptive lasso to tease out the effects of both macro and micro factors on the behavioural score. The results highlight the impact of five main attributes incentivizing energy-saving behaviours based on cross-variable analyses : energy price, household income, education level, age of head of household and dwelling energy performance. In addition, our results suggest that the analysis of the inverted U-shape impact of age enables the expansion of the energy consumption life cycle theory to energy-saving behaviours.",2016,
Forecasting Nord Pool day-ahead prices with Python,"This paper presents a Nord Pool forecast model for hourly day-ahead prices, utilizing the Python software. The model is an autoregressive model based on [1] and the data spans the period from 2004 to 2011. The targets (i.e. dependent variables) are the hourly day-ahead prices for a certain hour during the day while the features (i.e. independent variables) are the prices for the same hour the previous two days and the previous week, the minimum price for the previous day, four weekday dummy variables, including the demand and wind for the actual hour. We test the model in a simple linear regression framework with cross-validation. Next, we utilize regularized regressions including Ridge and Lasso. Â Finally, we utilize a Keras neural network. The models are evaluated with the mean absolute percentage error (MAPE) criterion, R-square and scatterplots. The results demonstrate that the models perform well and could add value for a market player.",2018,
Hyperparameter selection for group-sparse regression: A probabilistic approach,"This work analyzes the effects on support recovery for different choices of the hyper- or regularization parameter in LASSO-like sparse and group-sparse regression problems. The hyperparameter implicitly selects the model order of the solution, and is typically set using cross-validation (CV). This may be computationally prohibitive for large-scale problems, and also often overestimates the model order, as CV optimizes for prediction error rather than support recovery. In this work, we propose a probabilistic approach to select the hyperparameter, by quantifying the type I error (false positive rate) using extreme value analysis. From Monte Carlo simulations, one may draw inference on the upper tail of the distribution of the spurious parameter estimates, and the regularization level may be selected for a specified false positive rate. By solving the e group-LASSO problem, the choice of hyperparameter becomes independent of the noise variance. Furthermore, the effects on the false positive rate caused by collinearity in the dictionary is discussed, including ways of circumventing them. The proposed method is compared to other hyperparameter-selection methods in terms of support recovery, false positive rate, false negative rate, and computational complexity. Simulated data illustrate how the proposed method outperforms CV and comparable methods in both computational complexity and support recovery. (Less)",2018,Signal Process.
Bootstrap methods for lasso-type estimators under a moving-parameter framework,"We study the distributions of Lasso-type regression estimators in a moving-parameter asymptotic framework, and consider various bootstrap methods for estimating them accordingly. We show, in particular, that the distribution functions of Lasso-type estimators, including even those possessing the oracle properties such as the adaptive Lasso and the SCAD, cannot be consistently estimated by the bootstraps uniformly over the space of the regression parameters, especially when some of the regression coefficients lie close to the origin. Such lack of uniform consistency poses difficulties in practical applications of the bootstraps for making Lasso-based inferences. In the light of this seemingly negative result, we seek, however, to develop criteria for assessing the relative risks, phrased in terms of their uniform consistency properties, of the various bootstrap methods, based on which an optimal bootstrap strategy may be formulated in an adaptive manner. A simulation study is provided to demonstrate the non-normal nature of the distributions of Lasso-type estimators, and to assess the performances of various bootstrap estimates of such distributions across different values of regression parameters.",2012,
Predicting recreational water quality advisories: A comparison of statistical methods,"Epidemiological studies indicate that fecal indicator bacteria (FIB) in beach water are associated with illnesses among people having contact with the water. In order to mitigate public health impacts, many beaches are posted with an advisory when the concentration of FIB exceeds a beach action value. The most commonly used method of measuring FIB concentration takes 18-24 h before returning a result. In order to avoid the 24?h lag, it has become common to ""nowcast"" the FIB concentration using statistical regressions on environmental surrogate variables. Most commonly, nowcast models are estimated using ordinary least squares regression, but other regression methods from the statistical and machine learning literature are sometimes used. This study compares 14 regression methods across 7 Wisconsin beaches to identify which consistently produces the most accurate predictions. A random forest model is identified as the most accurate, followed by multiple regression fit using the adaptive LASSO. Fourteen regression methods were compared for water-quality prediction.A random forest method produced the most accurate predictions of all methods.Adaptive LASSO produced the most accurate predictions of the linear model options.",2016,Environ. Model. Softw.
Pass or Fail? Prediction of Students? Exam Outcomes from Self-reported Measures and Study Activities,"Technical educations often exhibit poor student performance and consequently high rates of attrition. Providing students with early feedback on their learning progress can assist them in self-study activities or in their decision-making process regarding a change in educational direction. In this paper, we present a set of instruments designed to identify at-risk undergraduate students in a Problem-based Learning (PBL) university, using an introductory programming course as a case study. Collectively, these instruments form the basis of a proposed learning ecosystem designed to identify struggling students by predicting their final exam grades in this course. We implemented this ecosystem and analyzed how well the obtained data predicted the final exam scores. Best-subset-regression and lasso regressions yielded several significant predictors. Apart from relevant predictors known from the literature on exam scores and drop-out factors such as midterm exam results and student retention factors, data from self-assessment quizzes, peer reviewing activities, and interactive online exercises helped predict exam performance and identified struggling students.",2018,IxD&A
Ð¤Ð°ÐºÑ‚Ð¾Ñ€Ñ‹ Ð Ð¸ÑÐºÐ° ÐžÑ‚Ñ€Ð°ÑÐ»ÐµÐ¹ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽÑ‰ÐµÐ¹ ÐŸÑ€Ð¾Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸,"In the work a comparison of risk factors influencing the probability of a negative value of companies (stage of prebankruptcy), for various manufacturing industries: the range of financial variables and corporate governance factors. The idea of corporate financial architecture were confirmed in the Russian industry: factors affecting the corporate structure of the company (characteristics of the CEO and ownership concentration) can be effectively applied for the analysis of financial stability of companies along with traditional financial indicators, improving the predictive quality of the models. Good stability of the obtained results was confirmed by serial build and comparison of logistic regression with lasso regularization and logistic regression models for all subsets. Next, were confirmed the statistical significance of 88,1% of the explaining factors of all final specifications. During the study period 2011â€“2015 dynamics of the intensity of bankruptcies in the manufacturing sector were not always uniform. In the analyzed period were identified both specific and general risk factors for considered sectors. The forecast quality of the final specifications for the industries demonstrated its high level in the control samples, the value of AUC (area under ROC-curve) is in the range from 85,06% in metallurgical production to 96,12% in mechanical engineering. Empirical results show that the sectoral differentiation of risk factors in the Russian manufacturing industry can be taken into consideration by enterprises, credit institutions and regulatory authorities in the conduct of crisis management and branch transformation of the existing methodological recommendations for developing financial and investment policy of the company.",2018,
"Infection with Human Papillomavirus (HPV) 6 and 11, and associations with genital warts, HIV and other risk factors in high-risk women in Burkina Faso.","Infection with Human Papillomavirus (HPV) 6 and 11, and associations with genital warts, HIV and other risk factors in highrisk women in Burkina Faso A. Low, I. Konate, N. Nagot, A. Ouedraogo, M.N. Didelot-Rousseau, T. Clayton, P. Van de Perre, M. Segondy, P. Mayaud 1 London School of Hygiene & Tropical Medicine, London, UK 2 Centre Muraz, Bobo-Dioulasso, Burkina Faso 3 CHU Montpellier, Montpellier, France Background Human papillomavirus (HPV) types 6 and 11 are known causative agents of genital warts (GW) but little is known about their epidemiology in Africa. We describe the prevalence of cervical HPV 6/11 DNA among high-risk women in Burkina Faso, and their association with GW, HIV, and other risk factors. Methods 306 women were enrolled. HIV status and CD4 counts were determined. Among other genital samples, a cervical sample was collected for liquid-based cytology using a Cervex swab and the ThinPrep 2000 processor and HPV genotyping using INNO-LiPA genotyping v2. Statistical analysis was conducted using logistic regression. Results HIV-1 prevalence was 40% (123/306). HPV DNA was detected in 55% (100/183) of HIV-uninfected women, 84% (78/93) of HIV-1 infected women with CD4 counts >200 cells/Î¼l and 97% (29/30) of women with CD4 counts â‰¤200 cells/Î¼l (p 200 cells/Î¼l, and 20% (6/30) in women with CD4 counts â‰¤200 cells/Î¼l (ptrend=0.04). 18 women (6%) had GW; there was a strong association between HPV 6 and GW (adjusted OR=6.16, 95% CI 1.25â€“ 30.88, p=0.03) but none between HPV 11 and GW. In multivariable analysis, cervical HPV 6/11 was detected more frequently in women who had genital ulcers (aOR=5.22, 95% CI 1.21â€“22.57, p=0.03), or whose last menses was more than 15 days prior to examination (aOR=2.71, 95% CI 1.07â€“ 6.98, p=0.03). Regular vaginal douching was protective (aOR=0.25, 95% CI 0.07â€“ 0.88, p=0.03). There were no associations with HIV-1 plasma viral load, other STI or bacterial vaginosis. Conclusions Prevalence of HPV 6 and 11 was high in this population and occurred more frequently in HIV-1 infected immunosuppressed women. Vaginal douching and follicular phase of menstrual cycle were protective, which might be secondary to mechanical or hormonal factors, decreasing DNA detection.",2009,
Accelerated Block Coordinate Proximal Gradients with Applications in High Dimensional Statistics,"Nonconvex optimization problems arise in different research fields and arouse lots of attention in signal processing, statistics and machine learning. In this work, we explore the accelerated proximal gradient method and some of its variants which have been shown to converge under nonconvex context recently. We show that a novel variant proposed here, which exploits adaptive momentum and block coordinate update with specific update rules, further improves the performance of a broad class of nonconvex problems. In applications to sparse linear regression with regularizations like Lasso, grouped Lasso, capped $\ell_1$ and SCAP, the proposed scheme enjoys provable local linear convergence, with experimental justification.",2017,ArXiv
Prediction Error Meta Classification in Semantic Segmentation: Detection via Aggregated Dispersion Measures of Softmax Probabilities,"We present a method that ""meta"" classifies whether segments (objects) predicted by a semantic segmentation neural network intersect with the ground truth. To this end, we employ measures of dispersion for predicted pixel-wise class probability distributions, like classification entropy, that yield heat maps of the input scene's size. We aggregate these dispersion measures segment-wise and derive metrics that are well-correlated with the segment-wise $\mathit{IoU}$ of prediction and ground truth. In our tests, we use two publicly available DeepLabv3+ networks (pre-trained on the Cityscapes data set) and analyze the predictive power of different metrics and different sets of metrics. To this end, we compute logistic LASSO regression fits for the task of classifying $\mathit{IoU}=0$ vs. $\mathit{IoU} > 0$ per segment and obtain classification rates of up to $81.91\%$ and AUROC values of up to $87.71\%$ without the incorporation of advanced techniques like Monte-Carlo dropout. We complement these tests with linear regression fits to predict the segment-wise $\mathit{IoU}$ and obtain prediction standard deviations of down to $0.130$ as well as $R^2$ values of up to $81.48\%$. We show that these results clearly outperform single-metric baseline approaches.",2018,ArXiv
A coordinate-wise optimization algorithm for the Fused Lasso,"L1-penalized regression methods such as the Lasso (Tibshirani 1996) that achieve both variable selection and shrinkage have been very popular. An extension of this method is the Fused Lasso (Tibshirani and Wang 2007), which allows for the incorporation of external information into the model. In this article, we develop new and fast algorithms for solving the Fused Lasso which are based on coordinate-wise optimization. This class of algorithms has recently been applied very successfully to solve L1-penalized problems very quickly (Friedman et al. 2007). As a straightforward coordinate-wise procedure does not converge to the global optimum in general, we adapt it in two ways, using maximum-flow algorithms and a Huber penalty based approximation to the loss function. In a simulation study, we evaluate the speed of these algorithms and compare them to other standard methods. As the Huber-penalty based method is only approximate, we also evaluate its accuracy. Apart from this, we also extend the Fused Lasso to logistic as well as proportional hazards models and allow for a more flexible penalty structure.",2010,arXiv: Computation
Introduction to the LASSO,"The term â€˜high-dimensionalâ€™ refers to the case where the number of unknown parameters to be estimated, p, is of much larger order than the number of observations, n, that is p â‰« n. Since traditional statistical methods assume many observations and a few unknown variables, they can not cope up with the situations when p â‰« n. In this article, we study a statistical method, called the â€˜Least Absolute Shrinkage and Selection Operatorâ€™ (LASSO), that has got much attention in solving high-dimensional problems. In particular, we consider the LASSO for high-dimensional linear regression models. We aim to provide an introduction of the LASSO method as a constrained quadratic programming problem, and we discuss the convex optimization based approach to solve the LASSO problem. We also illustrate applications of LASSO method using a simulated and a real data examples.",2018,Resonance
Clinical Outcome Prediction Based on Multi-Omics Data,"Predicting clinical outcomes via a set of omics data, consisting for example of genomics, proteomics or metabolomics data requires statistical methods which can deal with the situation of a huge number of covariates vs. a relatively small number of observations. One option is the application of penalized regression methods like the Lasso which also results in sparse models because variable selection is part of the model building process. In contrast to the standard Lasso model, the IPFLasso penalizes the various omics groups (modalities) of a multi-omics data set individually. However, this advantage has to be paid with exponentially increasing computation time, when there are more than two or three modalities involved. In this study, several two-step modifications of the IPF-Lasso model have been evaluated and compared to the original IPF-Lasso and some other competitors by analyzing simulated and real data sets. The results show that for a given data set, the new two-step IPF-Lasso model needs only a fraction of the computation time of the original IPF-Lasso and nevertheless can compete in terms of prediction performance.",2017,
Genomic prediction of genetic values for resistance to wheat rusts,"Durable resistance to the rust diseases of wheat (Triticum aestivum L.) can be achieved by developing lines that have race-nonspecific adult plant resistance conferred by multiple minor slow-rusting genes. Genomic selection (GS) is a promising tool for accumulating favorable alleles of slow-rusting genes. In this study, five CIMMYT wheat populations evaluated for resistance were used to predict resistance to stem rust (Puccinia graminis) and yellow rust (Puccinia striiformis) using Bayesian least absolute shrinkage and selection operator (LASSO) (BL), ridge regression (RR), and support vector regression with linear or radial basis function kernel models. All parents and populations were genotyped using 1400 Diversity Arrays Technology markers and different prediction problems were assessed. Results show that prediction ability for yellow rust was lower than for stem rust, probably due to differences in the conditions of infection of both diseases. For within population and environment, the correlation between predicted and observed values (Pearsonâ€™s correlation [ ]) was greater than 0.50 in 90% of the evaluations whereas for yellow rust, ranged from 0.0637 to 0.6253. The BL and RR models have similar prediction ability, with a slight superiority of the BL confirming reports about the additive nature of rust resistance. When making predictions between environments and/or between populations, including information from another environment or environments or another population or populations improved prediction.",2012,The Plant Genome
Satellite Based Nowcasting of PV Energy over Peninsular Spain,"In this work we will study the use of satellite-measured irradiances as well as clear sky radiance estimates as features for the nowcasting of photovoltaic energy productions over Peninsular Spain. We will work with three Machine Learning models (Lasso and linear and Gaussian Support Vector Regression-SVR) plus a simple persistence model. We consider prediction horizons of up to three hours, for which Gaussian SVR is the clear winner, with a quite good performance and whose errors increase slowly with time. Possible ways to further improve these results are also proposed.",2017,
Stepwise Group Sparse Regression (SGSR): Gene-Set-Based Pharmacogenomic Predictive Models with Stepwise Selection of Functional Priors,"Complex mechanisms involving genomic aberrations in numerous proteins and pathways are believed to be a key cause of many diseases such as cancer. With recent advances in genomics, elucidating the molecular basis of cancer at a patient level is now feasible, and has led to personalized treatment strategies whereby a patient is treated according to his or her genomic profile. However, there is growing recognition that existing treatment modalities are overly simplistic, and do not fully account for the deep genomic complexity associated with sensitivity or resistance to cancer therapies. To overcome these limitations, large-scale pharmacogenomic screens of cancer cell lines--in conjunction with modern statistical learning approaches--have been used to explore the genetic underpinnings of drug response. While these analyses have demonstrated the ability to infer genetic predictors of compound sensitivity, to date most modeling approaches have been data-driven, i.e. they do not explicitly incorporate domain-specific knowledge (priors) in the process of learning a model. While a purely data-driven approach offers an unbiased perspective of the data--and may yield unexpected or novel insights--this strategy introduces challenges for both model interpretability and accuracy. In this study, we propose a novel prior-incorporated sparse regression model in which the choice of informative predictor sets is carried out by knowledge-driven priors (gene sets) in a stepwise fashion. Under regularization in a linear regression model, our algorithm is able to incorporate prior biological knowledge across the predictive variables thereby improving the interpretability of the final model with no loss--and often an improvement--in predictive performance. We evaluate the performance of our algorithm compared to well-known regularization methods such as LASSO, Ridge and Elastic net regression in the Cancer Cell Line Encyclopedia (CCLE) and Genomics of Drug Sensitivity in Cancer (Sanger) pharmacogenomics datasets, demonstrating that incorporation of the biological priors selected by our model confers improved predictability and interpretability, despite much fewer predictors, over existing state-of-the-art methods.",2015,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
Developing an individualized risk calculator for psychopathology among young people victimized during childhood: A population-representative cohort study,"BACKGROUND
Victimized children are at greater risk for psychopathology than non-victimized peers. However, not all victimized children develop psychiatric disorders, and accurately identifying which victimized children are at greatest risk for psychopathology is important to provide targeted interventions. This study sought to develop and internally validate individualized risk prediction models for psychopathology among victimized children.


METHODS
Participants were members of the Environmental Risk (E-Risk) Longitudinal Twin Study, a nationally-representative British birth cohort of 2,232 twins born in 1994-1995. Victimization exposure was measured prospectively between ages 5 and 12 years, alongside a comprehensive range of individual-, family-, and community-level predictors of psychopathology. Structured psychiatric interviews took place at age-18 assessment. Logistic regression models were estimated with Least Absolute Shrinkage and Selection Operator (LASSO) regularization to avoid over-fitting to the current sample, and internally validated using 10-fold nested cross-validation.


RESULTS
26.5% (nâ€¯=â€¯591) of E-Risk participants had been exposed to at least one form of severe childhood victimization, and 60.4% (nâ€¯=â€¯334) of victimized children met diagnostic criteria for any psychiatric disorder at age 18. Separate prediction models for any psychiatric disorder, internalizing disorders, and externalizing disorders selected parsimonious subsets of predictors. The three internally validated models showed adequate discrimination, based on area-under-the-curve estimates (rangeÂ =Â =0.66-0.73), and good calibration.


LIMITATIONS
External validation in wholly-independent data is needed before clinical implementation.


CONCLUSIONS
Findings offer proof-of-principle evidence that prediction modeling can be useful in supporting identification of victimized children at greatest risk for psychopathology. This has the potential to inform targeted interventions and rational resource allocation.",2019,Journal of Affective Disorders
Optimization of Neural Networks with Multi-Objective LASSO Algorithm,This paper presents a bi-objective algorithm that optimizes the error and the sum of the absolute weights of a Multi-Layer Perceptron neural network. The algorithm is based on the linear Least Absolute Shrinkage and Selection Operator (LASSO) and provides simultaneous generalization and weight selection optimization. The algorithm searches for a set of optimal solutions called Pareto set from which a single weight vector with best performance and reduced number of weights is selected based on a validation criterion. The method is applied to classification and regression real problems and compared with the norm based multi-objective algorithm. Results show that the neural networks obtained have improved generalization performance and reduced topology.,2006,The 2006 IEEE International Joint Conference on Neural Network Proceedings
Enhancing Security Attacks Analysis Using Regularized Machine Learning Techniques,"With the increasing threats of security attacks, Machine learning (ML) has become a popular technique todetect those attacks. However, most of the ML approaches areblack-box methods and their inner-workings are difficult tounderstand by human beings. In the case of network security, understanding the dynamics behind the classification model isa crucial element towards creating safe and human-friendlysystems. In this article, we investigate the most important featuresin identifying well-known security attacks by using SupportVector Machines (SVMs) and l1-regularized method with LeastAbsolute Shrinkage and Selection Operator (LASSO) for robustregression both to binary and multiclass attack classification. SVMs are one of the standards of ML classification techniques thatgive a reasonably good performance but with some drawbacksin terms of interpretability. On the other hand, LASSO is aregularized regression method often performing comparably welland it has extra compelling advantages of being very easilyinterpretable. LASSO provides coefficients that contribute howindividual features affect the probability of specific security attackclasses to occur. Hence, we finally use LASSO in particular formulticlass classification to help us better understand which actualfeatures shared by attacks in a network are the most importantones. To perform our analysis, we use the recent NSL-KDDintrusion detection public dataset where the data are labeledinto either anomalous (denial-of-service (DoS), remote-to-local(R2L), user-to-root (U2R) and probe attack classes) or normal. Empirical results of the analysis and computational performancecomparison over the competing methods used are also presentedand discussed. We believe that the methodology presented in this paper may strengthen a future research in network intrusiondetection settings.",2017,2017 IEEE 31st International Conference on Advanced Information Networking and Applications (AINA)
Nomogram Based on microRNA Signature Contributes to Improve Survival Prediction of Clear Cell Renal Cell Carcinoma,"Objective
Numerous microRNAs (miRNAs) have been identified in ccRCC and recommended to be used for predicting clear cell renal cell carcinoma (ccRCC) prognosis. However, it is not clear whether a miRNA-based nomogram results in improved survival prediction in patients with ccRCC.


Methods
miRNA profiles from tumors and normal tissues were downloaded from The Cancer Genome Atlas (TCGA) database and analyzed using the ""limma"" package. The association between differentially expressed miRNAs and patient prognosis was identified using univariate, least absolute shrinkage and selection operator (LASSO), and multivariate Cox regression analyses. Next, all patients were randomly divided into development and validation cohorts at a ratio of 1â€‰:â€‰1. A nomogram was established based on independent prognostic factors in the development cohort. The prognostic performance of the nomogram was validated in both cohorts using the concordance index (C-index) and calibration plots.


Results
Multivariate Cox analysis identified the 13-miRNA signature, as well as AJCC stage and age, as independent prognostic factors after adjusting for other clinical covariates. The nomogram was built based on the independent variables. In the development cohort, the C-index for the constructed nomogram to predict overall survival (OS) was 0.792, which was higher than the C-index (0.731) of the AJCC staging system and C-index (0.778) of the miRNA signature. The nomogram demonstrated good discriminative ability in the validation cohort in predicting OS, with a C-index of 0.762. The calibration plots indicated an excellent agreement between the nomogram predicted survival probability and the actual observed outcomes. Furthermore, decision curve analysis (DCA) indicated that the nomogram was superior to the AJCC staging system in increasing the net clinical benefit.


Conclusions
The novel proposed nomogram based on a miRNA signature is a more reliable and robust tool for predicting the OS of patients with ccRCC compared to AJCC staging system, thus, improving clinical decision-making.",2020,BioMed Research International
Stepwise Paring down Variation for Identifying Influential Multi-factor Interactions Related to a Continuous Response Variable,"Although several model-based methods are promising for the identification of influential single factors and multi-factor interactions, few are widely used in real applications for most of the model-selection procedures are complex and/or infeasible in computation for high-dimensional data. In particular, the ability of the methods to reveal more true factors and fewer false ones often relies heavily on the selection of appropriate values of tuning parameters, which is still a difficult task to practical analysts. This article provides a simple algorithm modified from stepwise forward regression for the identification of influential factors. Instead of keeping the identified factors in the next models for adjustment in stepwise regression, we propose to subtract the effects of identified factors in each run and always fit a single-term model to the effect-subtracted responses. The computation is lighter as the proposed method only involves calculations of a simple test statistic; and therefore it could be applied to screen ultrahigh-dimensional data for important single factors and multi-factor interactions. Most importantly, we have proposed a novel stopping rule of using a constant threshold for the simple test statistic, which is different from the conventional stepwise regression with AIC or BIC criterion. The performance of the new algorithm has been confirmed competitive by extensive simulation studies compared to several methods available in R packages, including the popular group lasso, surely independence screening, Bayesian quantitative trait locus mapping methods and others. Findings from two real data examples, including a genome-wide association study, demonstrate additional useful information of high-order interactions that can be gained from implementing the proposed algorithm.",2012,Statistics in Biosciences
Correlated Feature Selection with Extended Exclusive Group Lasso,"In many high dimensional classification or regression problems set in a biological context, the complete identification of the set of informative features is often as important as predictive accuracy, since this can provide mechanistic insight and conceptual understanding. Lasso and related algorithms have been widely used since their sparse solutions naturally identify a set of informative features. However, Lasso performs erratically when features are correlated. This limits the use of such algorithms in biological problems, where features such as genes often work together in pathways, leading to sets of highly correlated features. In this paper, we examine the performance of a Lasso derivative, the exclusive group Lasso, in this setting. We propose fast algorithms to solve the exclusive group Lasso, and introduce a solution to the case when the underlying group structure is unknown. The solution combines stability selection with random group allocation and introduction of artificial features. Experiments with both synthetic and real-world data highlight the advantages of this proposed methodology over Lasso in comprehensive selection of informative features.",2020,ArXiv
A Radiomics nomogram for predicting bone metastasis in newly diagnosed prostate cancer patients.,"PURPOSE
To establish and validate a radiomics nomogram for predicting bone metastasis (BM) in patients with newly diagnosed prostate cancer (PCa).


METHOD
One-hundred and sixteen patients (training cohort: nâ€¯=â€¯81; validation cohort: nâ€¯=â€¯35) who underwent prostate MR imaging and confirmed by pathology with newly diagnosed PCa from January 2014 to January 2019 were enrolled. Radiomic features were extracted from diffusion-weighted, axial T2-weighted fat suppression, and dynamic contrast-enhanced T1-weighted MRI of each patient. Dimension reduction, feature selection, and radiomics feature construction were performed using the least absolute shrinkage and selection operator (LASSO) regression. Combined with independent clinical risk factors, a multivariate logistic regression model was used to establish a radiomics nomogram. Nomogram calibration and discrimination were evaluated in training cohort and verified in the validation cohort. Finally, the clinical usefulness of the nomogram was estimated through decision curve analysis (DCA).


RESULTS
Radiomics signature consisting of 12 selected features was significantly correlated with bone status (P < 0.001 for both training and validation sets). The radiomics nomogram combined a radiomics signature from multiparametric MR images with independent clinic risk factors. The model showed good discrimination and calibration in the training cohort (AUC 0.93, 95% CI, 0.86 to 0.99) and the validation cohort (AUC 0.92, 95% CI, 0.84 to 0.99). DCA also demonstrated the clinical use of the radiomics model.


CONCLUSION
The radiomics nomogram, which incorporates the multiparametric MRI-based radiomics signature and clinical risk factors, can be conveniently used to promote individualized prediction of BM in patients with newly diagnosed PCa.",2020,European journal of radiology
Comparative Profiling of Serum Protein Biomarkers in Rheumatoid Arthritis-associated Interstitial Lung Disease and Idiopathic Pulmonary Fibrosis.,"BACKGROUND
Interstitial lung disease (ILD) is a frequent complication of rheumatoid arthritis (RA), occurring in up to 40% of individuals during the course of their disease. Early diagnosis is critical, particularly given the shared clinico-epidemiological features between advanced RA-ILD and idiopathic pulmonary fibrosis (IPF). We therefore sought to define the molecular basis of this overlap through comparative profiling of serum proteins in RA-ILD and IPF.


METHODS
Multiplex ELISA was used to profile 45 protein biomarkers encompassing cytokines/chemokines, growth factors, and matrix metalloproteinases in sera derived from RA patients with/without ILD, individuals with IPF, and healthy controls. Levels of selected serum proteins were compared between patient subgroups using adjusted linear regression, Principal Component Analysis (PCA), and LASSO modeling.


RESULTS
Multiplex ELISA-based assessment of sera from two independent cohorts (VA, ACR) of RA patients revealed a number of non-overlapping biomarkers distinguishing RA-ILD from RA-no ILD in adjusted regression models. Parallel analysis of sera from IPF patients also yielded a discriminatory panel of protein markers in age/sex/smoking adjusted models that showed differential overlap with profiles linked to RA-ILD in the VA versus ACR cohorts. PCA revealed several distinct functional groups of RA-ILD-associated markers that, in the VA cohort, encompassed pro-inflammatory cytokines/chemokines as well as two different subsets of MMPs. Finally, LASSO regression modeling in the ACR and VA cohorts revealed distinct biomarker combinations capable of discriminating RA-ILD from RA-no ILD.


CONCLUSIONS
Comparative serum protein biomarker profiling represents a viable method for distinguishing RA-ILD from RA-no ILD and identifying population-specific mediators shared with IPF.",2019,Arthritis & rheumatology
Application of fused lasso logistic regression to the study of corpus callosum thickness in early Alzheimer's disease,"We propose a fused lasso logistic regression to analyze callosal thickness profiles. The fused lasso regression imposes penalties on both the l1-norm of the model coefficients and their successive differences, and finds only a small number of non-zero coefficients which are locally constant. An iterative method of solving logistic regression with fused lasso regularization is proposed to make this a practical procedure. In this study we analyzed callosal thickness profiles sampled at 100 equal intervals between the rostrum and the splenium. The method was applied to corpora callosa of elderly normal controls (NCs) and patients with very mild or mild Alzheimer's disease (AD) from the Open Access Series of Imaging Studies (OASIS) database. We found specific locations in the genu and splenium of AD patients that are proportionally thinner than those of NCs. Callosal thickness in these regions combined with the Mini Mental State Examination scores differentiated AD from NC with 84% accuracy.",2014,Journal of Neuroscience Methods
On Testing Continuity and the Detection of Failures,"Estimation of discontinuities is pervasive in applied economics: from the study of sheepskin effects to prospect theory and â€œbunchingâ€ of reported income on tax returns, models that predict discontinuities in outcomes are uniquely attractive for empirical testing. However, existing empirical methods often rely on assumptions about the number of discontinuities, the type, the location, or the underlying functional form of the model. We develop a nonparametric approach to the study of arbitrary discontinuities â€” point discontinuities as well as jump discontinuities in the nth derivative, where n = 0,1,... â€” that does not require such assumptions. Our approach exploits the development of false discovery rate control methods for lasso regression as proposed by Gâ€™Sell et al. (2015). This framework affords us the ability to construct valid tests for both the null of continuity as well as the significance of any particular discontinuity without the computation of nonstandard distributions. We illustrate the method with a series of Monte Carlo examples and by replicating prior work detecting and measuring discontinuities, in particular Lee (2008), Card et al. (2008), Reinhart and Rogoff (2010), and Backus et al. (2018b).",2019,National Bureau of Economic Research
Second order Poincar\'e inequalities and de-biasing arbitrary convex regularizers when $p/n \to \gamma$,"A new Central Limit Theorem (CLT) is developed for random variables of the form $\xi=z^\top f(z) - \text{div} f(z)$ where $z\sim N(0,I_n)$. The normal approximation is proved to hold when the squared norm of $f(z)$ dominates the squared Frobenius norm of $\nabla f(z)$ in expectation. 
Applications of this CLT are given for the asymptotic normality of de-biased estimators in linear regression with correlated design and convex penalty in the regime $p/n\to \gamma\in (0,{\infty})$. For the estimation of linear functions $\langle a_0,\beta\rangle$ of the unknown coefficient vector $\beta$, this analysis leads to asymptotic normality of the de-biased estimate for most normalized directions $a_0$, where ""most"" is quantified in a precise sense. This asymptotic normality holds for any coercive convex penalty if $\gamma<1$ and for any strongly convex penalty if $\gamma\ge 1$. In particular the penalty needs not be separable or permutation invariant. For the group Lasso, a simple condition is given that grants asymptotic normality for a fixed direction $a_0$. For the lasso, this condition reduces to $\lambda^2\|\Sigma^{-1}a_0\|_1^2/\bar{R}\to0$ where $\bar{R}$ is the noiseless prediction risk.",2019,arXiv: Statistics Theory
