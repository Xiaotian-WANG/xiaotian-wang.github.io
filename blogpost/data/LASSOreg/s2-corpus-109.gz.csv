title,abstract,year,journal
Incidence of and causes for all-cause hospitalizations in patients with atrial fibrillation,"Background: Atrial fibrillation (AF) is the most common cardiac arrhythmia in clinical practice, and its prevalence is expected to further increase in the future. AF patients not only have a high number of comorbidities, but they also have an increased risk of hospital admissions compared to individuals without AF. Nevertheless, predicting hospital admission risk among patients with AF remains difficult, and possible preventive strategies unclear. 
Based on these gaps in knowledge, the overall goal of this PhD thesis was to investigate the incidence of and causes for all-cause hospital admission in patients with AF. The specific aims were (1) to perform a systematic review and meta-analysis summarizing the current evidence of the incidence of and associated risk factors for hospital admissions in AF patients; (2) to identify risk factors for hospital admissions in our own cohorts and subsequently use this knowledge to develop and validate a risk score for predicting hospital admissions; (3) to identify psychosocial factors associated with hospital admissions in patients with AF. 
Methods: For the meta-analysis, we performed a comprehensive literature search in PubMed, EMBASE and CENTRAL, and pooled incidence rates for hospital admissions using random-effects models. Factors associated with observed between-study heterogeneity were identified using meta-regression analysis. 
For the second and third study, we used data of two ongoing, prospective observational cohort studies, the Basel Atrial Fibrillation Cohort Study (BEAT-AF) and the Swiss Atrial Fibrillation Cohort Study (Swiss-AF) in which 3,968 patients with diagnosed AF were enrolled. Unplanned hospital admissions were defined as any unpredicted admission leading to at least one overnight stay. For the second study, we used the Swiss-AF data set as the derivation cohort and performed a variable selection using the least absolute shrinkage and selection operator (LASSO) method. Multivariable adjusted Cox regression analyses were performed to assess the effect of the selected variables on all-cause hospitalization. Based on regression coefficients we constructed a risk score and subsequently validated the score in the external validation cohort (BEAT-AF). 
For the third study, we used psychosocial factors, such as marital status, education, level of depression and health perception, and investigated their effects on risk of hospital admission. Cox regression analyses adjusted for conventional risk factors for hospital admission were performed to calculate hazard ratio (HR). 
Results: We included 35 studies of 311â€™314 AF patients in the meta-analysis. The pooled incidence of all-cause hospital admissions was 43.7 per 100 person-years. AF patients were more often admitted for cardiovascular causes (26.3 per 100 person-years), but the risk of non-cardiovascular hospitalizations was substantial (15.7 per 100 person-years). Associated factors for hospital admission were older age, longer follow-up time and prevalent chronic pulmonary disease or cancer. 
In the second study we found that the most important predictors for all-cause hospital admission were age (75-79 years: adjusted hazard ratio [aHR], 1.33; 95% confidence interval [95% CI], 1.00-1.77; 80-84 years: aHR, 1.51; 95% CI, 1.12-2.03; ï‚³85 years: aHR, 1.88; 95% CI, 1.35-2.61), prior pulmonary vein isolation (aHR, 0.74; 95% CI, 0.60-0.90), hypertension (aHR, 1.16; 95% CI, 0.99-1.36), diabetes (aHR, 1.38; 95% CI, 1.17-1.62), coronary heart disease (aHR, 1.18; 95% CI, 1.02-1.37), prior stroke/TIA (aHR, 1.28; 95% CI, 1.10-1.50), heart failure (aHR, 1.21; 95% CI, 1.04-1.41), peripheral artery disease (aHR, 1.31; 95% CI, 1.06-1.63), cancer (aHR, 1.33; 95% CI, 1.13-1.57), renal failure (aHR, 1.18, 95% CI, 1.01-1.38), and previous falls (aHR, 1.44; 95% CI, 1.16-1.78). A risk score with these variables was well calibrated, and achieved a C statistic of 0.64 (95% CI, 0.61-0.66) in the derivation and 0.59 (95% CI, 0.56-0.63) in the external validation cohort. 
In the third study including patients from Swiss-AF, 1582 (67.1%) were married, 156 (6.6%) were single, 287 (12.2%) were divorced, and 333 (14.1%) were widowed. Two hundred and seventy six patients (11.7%) had at most a primary education, 1171 (49.7) had secondary education, and 911 (38.6%) had a college or university degree. Depression or depressive symptoms was present in 99 (4.2%) patients. Median health perception was 75 (interquartile range [IQR], 60-85) on a scale ranging from 0-100, with higher scores indicated better health perception. The highest risk of all-cause hospital admission was observed in single (aHR, 1.35; 95% CI, 1.05-1.75) or divorced patients (aHR, 1.26; 95% CI, 1.03-1.54), and in those who reported low health perception (aHR for <75 points, 1.40; 95% CI, 1.21-1.61). 
Conclusions: The overall incidence of hospital admissions in patients with AF is high. The risk of hospital admissions is related to multiple cardiovascular and non-cardiovascular risk factors, including several psychosocial factors and subjective health perception. 
Outlook: Given the high risk among AF patients of being admitted to the hospital and the high burden of associated risk factors, new multidisciplinary preventive strategies are needed with the goal to reduce hospital admissions, unfavorable patient outcomes and healthcare costs.",2019,
LARS: Stata module to perform least angle regression,"Least Angle Regression is a model-building algorithm that considers parsimony as well as prediction accuracy. This method is covered in detail by the paper Efron, Hastie, Johnstone and Tibshirani (2004), published in The Annals of Statistics. Their motivation for this method was a computationally simpler algorithm for the Lasso and Forward Stagewise regression. There are many criticisms of stepwise regression, one of which is that it is a ""greedy"" algorithm and that the regression coefficients are too large. Ridge regression is one method of model-building that shrinks the coefficients by making the sum of the squared coefficients less than some constant. The Lasso is similar but the constaint is that the sum of the ""mod"" coefficients is less than a constant. One implication of this will be that the solution will contain coefficients that are exactly 0 and hence have the property of parsimony i.e. a simpler model.",2006,Statistical Software Components
Factors affecting genomic selection revealed by empirical evidence in maize,"Abstract Genomic selection (GS) as a promising molecular breeding strategy has been widely implemented and evaluated for plant breeding, because it has remarkable superiority in enhancing genetic gain, reducing breeding time and expenditure, and accelerating the breeding process. In this study the factors affecting prediction accuracy (rMG) in GS were evaluated systematically, using six agronomic traits (plant height, ear height, ear length, ear diameter, grain yield per plant and hundred-kernel weight) evaluated in one natural and two biparental populations. The factors examined included marker density, population size, heritability, statistical model, population relationships and the ratio of population size between the training and testing sets, the last being revealed by resampling individuals in different proportions from a population. Prediction accuracy continuously increased as marker density and population size increased and was positively correlated with heritability; rMG showed a slight gain when the training set increased to three times as large as the testing set. Low predictive performance between unrelated populations could be attributed to different allele frequencies, and predictive ability and prediction accuracy could be improved by including more related lines in the training population. Among the seven statistical models examined, including ridge regression best linear unbiased prediction (RR-BLUP), genomic BLUP (GBLUP), BayesA, BayesB, BayesC, Bayesian least absolute shrinkage and selection operator (Bayesian LASSO), and reproducing kernel Hilbert space (RKHS), the RKHS and additive-dominance model (Addâ€¯+â€¯Dom model) showed credible ability for capturing non-additive effects, particularly for complex traits with low heritability. Empirical evidence generated in this study for GS-relevant factors will help plant breeders to develop GS-assisted breeding strategies for more efficient development of varieties.",2018,Crop Journal
Building and validating a predictive model for DVM academic performance,"Background: Predicting success in the veterinary curriculum with admissions variables is a longstanding interest of veterinary faculty. As linear models have consistently outperformed experts' opinions when making quantitative estimates, integrating them into admissions could both improve the outcome and reduce the burden of the admissions process. Aims and Objectives: To build and test linear models for predicting first year grade point average (GPA) and practice readiness in the Doctor of Veterinary Medicine (DVM) program. Materials and Methods: The authors built and validated models for predicting first year GPA and clinical rotation performance using data from the college's application management system and internal records. Lasso regression was used to select the subset of variables that best predicted both first year GPA and clinical faculty's ratings of practice readiness. Results: Validated models indicated no application variables reliably predicted practice readiness. Only total undergraduate GPA, GRE verbal/quantitate score, reference letter positivity, and number of unexplained course withdrawals reliably predicted first year GPA. Conclusion: Selecting applicants who will be successful in the first year of the veterinary curriculum is an important objective, particularly given the challenges many students face during this part of the veterinary curriculum. The overarching goal of a veterinary curriculum, however, is to produce practice ready veterinarians, thus additional work must be done to improve our ability to identify applicants who will be poised for success upon graduation.",2019,Education in the Health Professions
Preliminary test and Stein-type shrinkage LASSO-based estimators,"Suppose the regression vector-parameter is subjected to lie in a subspace hypothesis in a linear regression model. In situations where the use of least absolute and shrinkage selection operator (LASSO) is desired, we propose a restricted LASSO estimator. To improve its performance, LASSO-type shrinkage estimators are also developed and their asymptotic performance is studied. For numerical analysis, we used relative efficiency and mean prediction error to compare the estimators which resulted in the shrinkage estimators to have better performance compared to the LASSO.",2018,Sort-statistics and Operations Research Transactions
"Determinants of dividend payout and dividend propensity in an emerging market, Iran: an application of the LASSO","Accurate prediction of dividends is important for market participants such as investors, firm managers, and monitoring authorities, as they can, respectively, invest, manage dividend decisions, and monitor dividend policies more effectively. We identify the most relevant variables for predicting the dividend payout of the firms in an emerging market, Iran, using the least absolute shrinkage and selection operator (LASSO). The advantages of the LASSO include: enhancing the prediction accuracy of the dividend model, improving interpretation of the results, and applicability to high-dimensional data. We obtain several results. First, some fundamental determinants of dividends in the industrialized economies such as market-to-book ratio and current ratio, do not play a role in deciding dividends in Iran. Second, LASSO-selected variables outperform the variables commonly used in the literature in terms of model fit and prediction accuracy. Third, business risk, leverage, return on assets and effective tax rate are the most important predictors of dividend propensity of the Iranian firms. Fourth, if the support vector machine algorithm, an often-used classification method, is combined with LASSO-selected variables, it can better discriminate between dividend-paying and dividend non-paying firms than other methods such as logistic regression and linear discriminant analysis.Abbreviations: LASSO: Least Absolute Shrinkage and Selection Operator; TSE: Tehran Stock Exchange; RMSE: Root Mean Squared Errors; MAE: Mean Absolute Errors; ROC: Receiver Operating Characteristics; GMM: Generalized Method of Moments; MENA: Middle East and North Africa region; AIC: Akaike Information Criterion; BIC: Bayesian Information Criterion; LARS: Least Angel Regression; OLS: Ordinary Least Squares; AUC: Area Under Curve; BS: Brier Score ; OA: Overall Accuracy; LDA: Linear Discriminant Analysis; SVM: Support Vector Machine algorithm; LR: Logistic Regression.",2019,Applied Economics
A New Perspective on Boosting in Linear Regression via Subgradient Optimization and Relatives,"In this paper we analyze boosting algorithms in linear regression from a new perspective: that of modern first-order methods in convex optimization. We show that classic boosting algorithms in linear regression, namely the incremental forward stagewise algorithm (FS$_\varepsilon$) and least squares boosting (LS-Boost($\varepsilon$)), can be viewed as subgradient descent to minimize the loss function defined as the maximum absolute correlation between the features and residuals. We also propose a modification of FS$_\varepsilon$ that yields an algorithm for the Lasso, and that may be easily extended to an algorithm that computes the Lasso path for different values of the regularization parameter. Furthermore, we show that these new algorithms for the Lasso may also be interpreted as the same master algorithm (subgradient descent), applied to a regularized version of the maximum absolute correlation loss function. We derive novel, comprehensive computational guarantees for several boosting algorithms in linear regression (including LS-Boost($\varepsilon$) and FS$_\varepsilon$) by using techniques of modern first-order methods in convex optimization. Our computational guarantees inform us about the statistical properties of boosting algorithms. In particular they provide, for the first time, a precise theoretical description of the amount of data-fidelity and regularization imparted by running a boosting algorithm with a prespecified learning rate for a fixed but arbitrary number of iterations, for any dataset.",2015,ArXiv
Comparison of regression techniques to predict response of oilseed rape yield to variation in climatic conditions in Denmark,"Abstract Statistical regression models represent alternatives to process-based dynamic models for predicting the response of crop yields to variation in climatic conditions. Regression models can be used to quantify the effect of change in temperature and precipitation on yields. However, it is difficult to identify the most relevant input variables that should be included in regression models due to the high number of candidate variables and to their correlations. This paper compares several regression techniques for modeling response of winter oilseed rape yield to a high number of correlated input variables. Several statistical regression methods were fitted to a dataset including 689 observations of winter oilseed rape yield from replicated field experiments conducted in 239 sites in Denmark, covering nearly all regions of the country from 1992 to 2013. Regression methods were compared by cross-validation. The regression methods leading to the most accurate yield predictions were Lasso and Elastic Net, and the least accurate methods were ordinary least squares and stepwise regression. Partial least squares and ridge regression methods gave intermediate results. The estimated relative yield change for a +1Â°C temperature increase during flowering was estimated to range between 0 and +6 %, depending on choice of regression method. Precipitation was found to have an adverse effect on yield during autumn and winter. It was estimated that an increase in precipitation of +1 mm/day would result in a relative yield change ranging from 0 to âˆ’4 %. Soil type was also important for crop yields with lower yields on sandy soils compared to loamy soils. Later sowing was found to result in increased crop yield. The estimated effect of climate on yield was highly sensitive to the chosen regression method. Regression models showing similar performance led in some cases to different conclusions with respect to effect of temperature and precipitation. Hence, it is recommended to apply an ensemble of regression models, in order to account for the sensitivity of the data driven models for projecting crop yield under climate change.",2017,European Journal of Agronomy
Perturbation Bootstrap in Adaptive Lasso,"The Adaptive Lasso(Alasso) was proposed by Zou [\textit{J. Amer. Statist. Assoc. \textbf{101} (2006) 1418-1429}] as a modification of the Lasso for the purpose of simultaneous variable selection and estimation of the parameters in a linear regression model. Zou (2006) established that the Alasso estimator is variable-selection consistent as well as asymptotically Normal in the indices corresponding to the nonzero regression coefficients in certain fixed-dimensional settings. In an influential paper, Minnier, Tian and Cai [\textit{J. Amer. Statist. Assoc. \textbf{106} (2011) 1371-1382}] proposed a perturbation bootstrap method and established its distributional consistency for the Alasso estimator in the fixed-dimensional setting. In this paper, however, we show that this (naive) perturbation bootstrap fails to achieve second order correctness in approximating the distribution of the Alasso estimator. We propose a modification to the perturbation bootstrap objective function and show that a suitably studentized version of our modified perturbation bootstrap Alasso estimator achieves second-order correctness even when the dimension of the model is allowed to grow to infinity with the sample size. As a consequence, inferences based on the modified perturbation bootstrap will be more accurate than the inferences based on the oracle Normal approximation. We give simulation studies demonstrating good finite-sample properties of our modified perturbation bootstrap method as well as an illustration of our method on a real data set.",2017,arXiv: Methodology
Development and reliability of metrics to characterize types and sources of stigma among men who have sex with men and female sex workers in Togo and Burkina Faso,"BackgroundStigma is a multifaceted concept that potentiates Human Immunodeficiency Virus and sexually transmitted infection acquisition and transmission risks among key populations, including men who have sex with men (MSM) and female sex workers (FSW). Despite extensive stigma literature, limited research has characterized the types and sources of stigma reported by key populations in Sub-Saharan Africa.MethodsThis study leveraged data collected from 1356 MSM and 1383 FSW in Togo and Burkina Faso, recruited via respondent-driven sampling. Participants completed a survey instrument including stigma items developed through systematic reviews and synthesis of existing metrics. Using exploratory factor analysis with promax oblique rotation, 16 items were retained in a stigma metric for MSM and 20 in an FSW stigma metric. To assess the measuresâ€™ convergent validity, their correlations with expected variables were examined through bivariate logistic regression models.ResultsOne factor, experienced stigma, included actions that were carried out by multiple types of perpetrators and included being arrested, verbally harassed, blackmailed, physically abused, tortured, or forced to have sex. Other factors were differentiated by source of stigma including healthcare workers, family and friends, or police. Specifically, stigma from healthcare workers loaded on two factors: experienced healthcare stigma included being denied care, not treated well, or gossiped about by healthcare workers and anticipated healthcare stigma included fear of or avoiding seeking healthcare. Stigma from family and friends included feeling excluded from family gatherings, gossiped about by family, or rejected by friends. Stigma from police included being refused police protection and items related to police confiscation of condoms. The Cronbachâ€™s alpha ranged from 0.71â€“0.82. Median stigma scores, created for each participant by summing the number of affirmative responses to each stigma item, among MSM were highest in Ouagadougou and among FSW were highest in both Ouagadougou and Bobo-Dioulasso. Validation analyses demonstrated higher stigma was generally significantly associated with suicidal ideation, disclosure of involvement in sex work or same-sex practices, and involvement in organizations for MSM or FSW.ConclusionsTaken together, these data suggest promising reliability and validity of metrics for measuring stigma affecting MSM and FSW in multiple urban centers across West Africa.",2019,BMC Infectious Diseases
Hybrid graphical least square estimation and its application in portfolio selection,"This paper proposes a new regression method based on the idea of graphical models to deal with regression problems with the number of covariates v larger than the sample size N. Unlike the regularization methods such as ridge regression, LASSO and LARS, which always give biased estimates for all parameters, the proposed method can give unbiased estimates for important parameters (a certain subset of all parameters). The new method is applied to a portfolio selection problem under the linear regression framework and, compared to other existing methods, it can assist in improving the portfolio performance by increasing its expected return and decreasing its risk. Another advantage of the proposed method is that it constructs a non-sparse (saturated) portfolio, which is more diversiï¬ed in terms of stocks and reduces the stock-speciï¬c risk. Overall, four simulation studies and a real data analysis from London Stock Exchange showed that our method outperforms other existing regression methods when N < v.",2019,Statistics and Its Interface
Statistical Analyses of High Dimensional MicroRNA Data in Relation to Incidence and Survival After Cancer,"Pancreatic cancer is globally the 4 most common cause of cancer death and the overall 5-year survival rate among patients is less than 5%. Often the pancreatic cancer is already at advance stages when discovered, so the difficulties of an early diagnosis makes the life prognosis for these patients very dismal. Part of the problem with detecting this type of cancer in time, is that there are no typical symptoms. Incidence and prognosis prediction from high dimensional gene expression data have been subject to much research during recent years. This thesis examines the relationship between microRNA expression profiles and their ability to predict correct diagnostics and expected survival from time of operation. This research area can hopefully reform future courses of treatment by providing patients with pancreatic cancer earlier diagnosis, and thus improve their prognosis. This thesis deals with the statistical modelling of microRNA measurements from serum samples of both pancreatic patients and healthy controls. The analyses are divided into two parts. The incidence part focuses on the logistic model for predicting a binary outcome and the prognostic part considers Coxâ€™s proportional hazards model in order to handle censored survival times. However since parsimonious models are of clinical relevance, these models are used in combination with coefficient shrinkage techniques, where the shrinkage methods used here are univariate selection, backwards stepwise selection, Ridge regression, Lasso regression and nÃ¤Ä±ve elastic net regression. These shrinkage methods require estimation of penalty parameters for which cross-validation have served as an excellent tool.",2012,
Evaluation of Lymph Node Metastasis in Advanced Gastric Cancer Using Magnetic Resonance Imaging-Based Radiomics,"Objective: To develop and evaluate a diffusion-weighted imaging (DWI)-based radiomic nomogram for lymph node metastasis (LNM) prediction in advanced gastric cancer (AGC) patients. Overall Study: This retrospective study was conducted with 146 consecutively included pathologically confirmed AGC patients from two centers. All patients underwent preoperative 3.0 T magnetic resonance imaging (MRI) examination. The dataset was allocated to a training cohort (n = 71) and an internal validation cohort (n = 47) from one center along with an external validation cohort (n = 28) from another. A summary of 1,305 radiomic features were extracted per patient. The least absolute shrinkage and selection operator (LASSO) logistic regression and learning vector quantization (LVQ) methods with cross-validations were adopted to select significant features in a radiomic signature. Combining the radiomic signature and independent clinical factors, a radiomic nomogram was established. The MRI-reported N staging and the MRI-derived model were built for comparison. Model performance was evaluated considering receiver operating characteristic (ROC) analysis, calibration curves, and decision curve analysis (DCA). Results: A two-feature radiomic signature was found significantly associated with LNM (p < 0.01, training and internal validation cohorts). A radiomic nomogram was established by incorporating the clinical minimum apparent diffusion coefficient (ADC) and MRI-reported N staging. The radiomic nomogram showed a favorable classification ability with an area under ROC curve of 0.850 [95% confidence interval (CI), 0.758-0.942] in the training cohort, which was then confirmed with an AUC of 0.857 (95% CI, 0.714-1.000) in internal validation cohort and 0.878 (95% CI, 0.696-1.000) in external validation cohort. Meanwhile, the specificity, sensitivity, and accuracy were 0.846, 0.853, and 0.851 in internal validation cohort, and 0.714, 0.952, and 0.893 in external validation cohort, compensating for the MRI-reported N staging and MRI-derived model. DCA demonstrated good clinical use of radiomic nomogram. Conclusions: This study put forward a DWI-based radiomic nomogram incorporating the radiomic signature, minimum ADC, and MRI-reported N staging for individualized preoperative detection of LNM in patients with AGC.",2019,Frontiers in Oncology
Safe optimization algorithms for variable selection and hyperparameter tuning,"Massive and automatic data processing requires the development of techniques able to filter the most important information. Among these methods, those with sparse structures have been shown to improve the statistical and computational efficiency of estimators in a context of large dimension. They can often be expressed as a solution of regularized empirical risk minimization and generally lead to non differentiable optimization problems in the form of a sum of a smooth term, measuring the quality of the fit, and a non-smooth term, penalizing complex solutions. Although it has considerable advantages, such a way of including prior information, unfortunately introduces many numerical difficulties both for solving the underlying optimization problem and to calibrate the level of regularization. Solving these issues has been at the heart of this thesis. A recently introduced technique, called ""Screening Rules"", proposes to ignore some variables during the optimization process by benefiting from the expected sparsity of the solutions. These elimination rules are said to be safe when the procedure guarantees to not reject any variable wrongly. In this work, we propose a unified framework for identifying important structures in these convex optimization problems and we introduce the ""Gap Safe Screening Rules"". They allows to obtain significant gains in computational time thanks to the dimensionality reduction induced by this method. In addition, they can be easily inserted into iterative algorithms and apply to a large number of problems.To find a good compromise between minimizing risk and introducing a learning bias, (exact) homotopy continuation algorithms offer the possibility of tracking the curve of the solutions as a function of the regularization parameters. However, they exhibit numerical instabilities due to several matrix inversions and are often expensive in large dimension. Another weakness is that a worst-case analysis shows that they have exact complexities that are exponential in the dimension of the model parameter. Allowing approximated solutions makes possible to circumvent the aforementioned drawbacks by approximating the curve of the solutions. In this thesis, we revisit the approximation techniques of the regularization paths given a predefined tolerance and we propose an in-depth analysis of their complexity w.r.t. the regularity of the loss functions involved. Hence, we propose optimal algorithms as well as various strategies for exploring the parameters space. We also provide calibration method (for the regularization parameter) that enjoys globalconvergence guarantees for the minimization of the empirical risk on the validation data.Among sparse regularization methods, the Lasso is one of the most celebrated and studied. Its statistical theory suggests choosing the level of regularization according to the amount of variance in the observations, which is difficult to use in practice because the variance of the model is oftenan unknown quantity. In such case, it is possible to jointly optimize the regression parameter as well as the level of noise. These concomitant estimates, appeared in the literature under the names of Scaled Lasso or Square-Root Lasso, and provide theoretical results as sharp as that of theLasso while being independent of the actual noise level of the observations. Although presenting important advances, these methods are numerically unstable and the currently available algorithms are expensive in computation time. We illustrate these difficulties and we propose modifications based on smoothing techniques to increase stability of these estimators as well as to introduce a faster algorithm.",2018,
Robust variable selection in modal varying-coefficient models with longitudinal,"In this article we present a robust and efficient variable selection procedure by using modal regression for varying-coefficient models with longitudinal data. The new method is proposed based on basis function approximations and a group version of the adaptive LASSO penalty, which can select significant variables and estimate the non-zero smooth coefficient functions simultaneously. Under suitable conditions, we establish the consistency in variable selection and the oracle property in estimation. A simulation study and two real data examples are undertaken to assess the finite sample performance of the proposed variable selection procedure.",2015,Journal of Statistical Computation and Simulation
On Mixture Regression Shrinkage and Selection Via the MR-Lasso,"In finite mixture regression models, we generalize the application of the least absolute shrinkage and selection operator (LASSO) to obtain MR-Lasso, which incorporates both mixture and regression penalties. Because MR-Lasso jointly penalizes both regression coeficients and mixture components, it enables simultaneous identification of significant variables and determination of important mixture components. Simulation studies indicate that MR-Lasso outperforms LASSO. Extensions to mixture non-Gaussian and mixture time series models are briefly described.",2008,
A machine learning approach for the prediction of pulmonary hypertension,"BACKGROUND
Machine learning (ML) is a powerful tool for identifying and structuring several informative variables for predictive tasks. Here, we investigated how ML algorithms may assist in echocardiographic pulmonary hypertension (PH) prediction, where current guidelines recommend integrating several echocardiographic parameters.


METHODS
In our database of 90 patients with invasively determined pulmonary artery pressure (PAP) with corresponding echocardiographic estimations of PAP obtained within 24 hours, we trained and applied five ML algorithms (random forest of classification trees, random forest of regression trees, lasso penalized logistic regression, boosted classification trees, support vector machines) using a 10 times 3-fold cross-validation (CV) scheme.


RESULTS
ML algorithms achieved high prediction accuracies: support vector machines (AUC 0.83; 95% CI 0.73-0.93), boosted classification trees (AUC 0.80; 95% CI 0.68-0.92), lasso penalized logistic regression (AUC 0.78; 95% CI 0.67-0.89), random forest of classification trees (AUC 0.85; 95% CI 0.75-0.95), random forest of regression trees (AUC 0.87; 95% CI 0.78-0.96). In contrast to the best of several conventional formulae (by Aduen et al.), this ML algorithm is based on several echocardiographic signs and feature selection, with estimated right atrial pressure (RAP) being of minor importance.


CONCLUSIONS
Using ML, we were able to predict pulmonary hypertension based on a broader set of echocardiographic data with little reliance on estimated RAP compared to an existing formula with non-inferior performance. With the conceptual advantages of a broader and unbiased selection and weighting of data our ML approach is suited for high level assistance in PH prediction.",2019,PLoS ONE
EPSâ€LASSO: test for highâ€dimensional regression under extreme phenotype sampling of continuous traits,"Motivation: Extreme phenotype sampling (EPS) is a broadlyâ€used design to identify candidate genetic factors contributing to the variation of quantitative traits. By enriching the signals in extreme phenotypic samples, EPS can boost the association power compared to random sampling. Most existing statistical methods for EPS examine the genetic factors individually, despite many quantitative traits have multiple genetic factors underlying their variation. It is desirable to model the joint effects of genetic factors, which may increase the power and identify novel quantitative trait loci under EPS. The joint analysis of genetic data in highâ€dimensional situations requires specialized techniques, e.g. the least absolute shrinkage and selection operator (LASSO). Although there are extensive research and application related to LASSO, the statistical inference and testing for the sparse model under EPS remain unknown. Results: We propose a novel sparse model (EPSâ€LASSO) with hypothesis test for highâ€dimensional regression under EPS based on a decorrelated score function. The comprehensive simulation shows EPSâ€LASSO outperforms existing methods with stable type I error and FDR control. EPSâ€LASSO can provide a consistent power for both lowâ€ and highâ€dimensional situations compared with the other methods dealing with highâ€dimensional situations. The power of EPSâ€LASSO is close to other lowâ€dimensional methods when the causal effect sizes are small and is superior when the effects are large. Applying EPSâ€LASSO to a transcriptomeâ€wide gene expression study for obesity reveals 10 significant body mass index associated genes. Our results indicate that EPSâ€LASSO is an effective method for EPS data analysis, which can account for correlated predictors. Availability and implementation: The source code is available at https://github.com/xu1912/EPSLASSO. Supplementary information: Supplementary data are available at Bioinformatics online.",2018,Bioinformatics
Association mapping identified novel candidate loci affecting wood formation in Norway spruce,"âž¢ Norway spruce (Picea abies) is an important boreal forest tree species of significant ecological and economic importance. Hence there is a strong imperative to dissect the genetics controlling important wood quality traits in Norway spruce. âž¢ We performed a functional genome-wide association mapping of 17 wood quality traits in Norway spruce using 178101 single-nucleotide polymorphisms (SNPs) generated from exome genotyping of 517 mother trees. The wood quality traits were defined using functional modelling of wood properties across annual growth rings. âž¢ Association mapping was performed using a multilocus LASSO penalized regression method and we detected a total of 51 significant SNPs from 39 candidate genes that are involved in wood formation. âž¢ Our study represents the first functional multi-locus genome-wide association mapping (AM) in Norway spruce. The results advance our understanding of the genetics influencing wood traits, identify novel candidate genes for further functional studies and support current Norway spruce breeding efforts.",2018,bioRxiv
Genome prediction accuracy of common bean via Bayesian models,"EnglishWe aimed to apply genomic information based on SNP (single nucleotide polymorphism) markers for the genetic evaluation of the traits â€œstay-greenâ€ (SG), plant architecture (PA), grain aspect (GA) and grain yield (GY) in common bean through Bayesian models. These models were compared in terms of prediction accuracy and ability for heritability estimation for each one of the mentioned traits. A total of 80 cultivars were genotyped for 377 SNP markers, whose effects were estimated by five different Bayesian models: Bayes A (BA), B (BB), C (BC), LASSO (BL) e Ridge regression (BRR). Although, prediction accuracies calculated by means of cross-validation have been similar within each trait, the BB model stood out for the trait SG, whereas the BRR was indicated for the remaining traits. The heritability estimates for the traits SG, PA, GA and GY were 0.61, 0.28, 0.32 and 0.29, respectively. In summary, the Bayesian methods applied here were effective and ease to be implemented. The used SNP markers can help in the early selection of promising genotypes, since incorporating genomic information increase the prediction accuracy of the estimated genetic merit. Key words: Phaseolus vulgaris; SNP markers; cross-validation portuguesObjetivou-se incorporar informacoes genomicas de marcadores SNP (â€œsingle nucleotide polymorphismâ€) na avaliacao genetica das caracteristicas â€œstay-greenâ€ (SG), arquitetura de planta (AP), aspecto de graos (AG) e produtividade de graos (PG) em feijoeiro-comum via modelos Bayesianos. Estes modelos foram comparados quanto a acuracia de predicao e habilidade de estimacao da herdabilidade para cada caracteristica. Utilizaram-se informacoes de 80 cultivares genotipadas para 377 marcadores SNP, cujos efeitos de substituicao alelica foram estimados por meio de cinco diferentes modelos Bayesianos: Bayes A (BA), B (BB), C (BC), LASSO (BL) e regressao â€œridgeâ€ (BRR). Embora as acuracias de predicao calculadas por meio de analise de validacao cruzada tenham sido similares dentro de cada caracteristica, o modelo BB se destacou para a caracteristica SG, enquanto o modelo BRR foi indicado para as demais. As herdabilidades estimadas para SG, AP, AG e PG foram, respectivamente, 0,61, 0,28, 0,32 e 0,29. Em resumo, os metodos contemplados mostraram-se efetivos e de facil implementacao. O conjunto de marcadores utilizado pode auxiliar na selecao precoce de genotipos promissores, uma vez que a incorporacao de informacoes genomicas aumenta a acuracia de predicao do merito genetico estimado. Palavras-chave: Phaseolus vulgaris; marcadores SNP; validacao cruzada",2018,Ciencia Rural
Learning L2 Continuous Regression Functionals via Regularized Riesz Representers,"Many objects of interest can be expressed as an L2 continuous functional of a regression, including average treatment effects, economic average consumer surplus, expected conditional covariances, and discrete choice parameters that depend on expectations. Debiased machine learning (DML) of these objects requires a learning a Riesz representer (RR). We provide here Lasso and Dantzig learners of the RR and corresponding learners of affine and other nonlinear functionals. We give an asymptotic variance estimator for DML. We allow for a wide variety of regression learners that can converge at relatively slow rates. We give conditions for root-n consistency and asymptotic normality of the functional learner. We give results for non affine functionals in addition to affine functionals.",2018,arXiv: Statistics Theory
Exploiting Covariate Similarity in Sparse Regression via the Pairwise Elastic Net,"A new approach to regression regularization called the Pairwise Elastic Net is proposed. Like the Elastic Net, it simultaneously performs automatic variable selection and continuous shrinkage. In addition, the Pairwise Elastic Net encourages the grouping of strongly correlated predictors based on a pairwise similarity measure. We give examples of how the approach can be used to achieve the objectives of Ridge regression, the Lasso, the Elastic Net, and Group Lasso. Finally, we present a coordinate descent algorithm to solve the Pairwise Elastic Net.",2010,
Predicting the Internet â€™ s Evolution with Decision Trees and Lasso Logistic Regression Models,"The Internet self-evolves rapidly and its dynamic structure poses many interesting questions for researchers in network analysis. In this paper I show how we can simplify the entire Internet as a mathematical graph and then extract its structural characteristics; these characteristics in turn help us build statistical models that can predict how the Internet will evolve. The data describing the Internet structure are both clustered and unbalanced. I hence test various models, including lasso logistic regression, gradient-boosted decision trees and random forest decision trees, to see how well they cope with unbalanced and clustered data. The best performing model was created through a gradient-boosted decision tree that balances flexibility in fitting with robustness in prediction. I show that we can achieve good predicting power using fairly simple explanatory variables, but I also discuss how we can extract more sophisticated variables to improve the modelsâ€™ performance.",2014,
Machine Learning for Pavement Friction Prediction Using Scikit-Learn,"During the last decades, the advent of Artificial Intelligence (AI) has been taking place in several technical and scientific areas. Despite its success, AI applications to solve real-life problems in pavement engineering are far from reaching its potential. In this paper, a Python machine learning library, scikit-learn, is used to predict asphalt pavement friction. Using data from the Long-Term Pavement Performance (LTPP) database, 113 different sections of asphalt concrete pavement, spread all over the United States, were selected. Two machine learning models were built from these data to predict friction, one based on linear regression and the other on regularized regression with lasso. Both models showed to be feasible and perform similarly. According to the results, initial friction plays an essential role in the way friction evolves over time. The results of this study also showed that scikit-learn can be a versatile tool to solve pavement engineering problems. By applying machine learning methods to predict asphalt pavements friction, this paper emphasizes how theory and practice can be effectively coupled to solve real-life problems in contemporary transportation.",2017,
Integrating biomarkers across omic platforms: an approach to improve stratification of patients with indolent and aggressive prostate cancer,"Classifying indolent prostate cancer represents a significant clinical challenge. We investigated whether integrating data from different omic platforms could identify a biomarker panel with improved performance compared to individual platforms alone. DNA methylation, transcripts, protein and glycosylation biomarkers were assessed in a single cohort of patients treated by radical prostatectomy. Novel multiblock statistical data integration approaches were used to deal with missing data and modelled via stepwise multinomial logistic regression, or LASSO. After applying leave-one-out cross-validation to each model, the probabilistic predictions of disease type for each individual panel were aggregated to improve prediction accuracy using all available information for a given patient. Through assessment of three performance parameters of area under the curve (AUC) values, calibration and decision curve analysis, the study identified an integrated biomarker panel which predicts disease type with a high level of accuracy, with Multi AUC value of 0.91 (0.89, 0.94) and Ordinal C-Index (ORC) value of 0.94 (0.91, 0.96), which was significantly improved compared to the values for the clinical panel alone of 0.67 (0.62, 0.72) Multi AUC and 0.72 (0.67, 0.78) ORC. Biomarker integration across different omic platforms significantly improves prediction accuracy. We provide a novel multiplatform approach for the analysis, determination and performance assessment of novel panels which can be applied to other diseases. With further refinement and validation, this panel could form a tool to help inform appropriate treatment strategies impacting on patient outcome in early stage prostate cancer.",2018,Molecular Oncology
Modeling of various biological networks via LCMARS,"Abstract In system biology, the interactions between components such as genes, proteins, can be represented by a network. To understand the molecular mechanism of complex biological systems, construction of their networks plays a crucial role. However, estimation of these biological networks is a challenging problem because of their high dimensional and sparse structures. Several statistical methods are proposed to overcome this issue. The Conic Multivariate Adaptive Regression Splines (CMARS) is one of the recent nonparametric methods developed for high dimensional and correlated data. This model is suggested to improve the performance of the Multivariate Adaptive Regression Spline (MARS) approach which is a complex model under the generalized additive models. From previous studies, it has been shown that MARS can be a promising model for the description of steady-state activations of biological networks if it is modified as a lasso-type regression via the main effects. In this study, we convert the full description of CMARS as a loop-based approach, so-called LCMARS, by including both main and second-order interaction effects since this description has performed better in benchmark real datasets. Here, we generate various scenarios based on distinct distributions and dimensions to compare the performance of LCMARS with MARS and Gaussian Graphical Model (GGM) in terms of accuracy measures via Monte Carlo runs. Additionally, different real biological datasets are used to observe the performance of underlying methods.",2018,J. Comput. Sci.
The Prognostic Value of m6A RNA Methylation Regulators in Colon Adenocarcinoma,"BACKGROUND The RNA-seq FPKM data of 331 colorectal adenocarcinoma samples in The Cancer Genome Atlas database with matching clinical data were analyzed in order to reveal the prognostic value of m6A RNA methylation regulators in colon adenocarcinoma. MATERIAL AND METHODS The expression of 13 m6A RNA methylated regulators in samples were analyzed. The samples were classified into Cluster I and II by consistent clustering. The gene distribution was analyzed by principal component analysis. Further functional analysis of selected m6A RNA genes was performed and potential risk characteristics was developed using Lasso Cox regression algorithm. Using minimum criteria, the risk coefficients of YTHDF1 and HNRNPC were detected for Cluster II. Patients were divided into high-risk and low-risk subgroups based on the risk characteristics. The clinical data were analyzed by univariate and multivariate Cox regression analysis. RESULTS Expression of the detected m6A RNA methylated regulators except YTHDC2 in tumors were significantly different from their adjacent mucosa. Among them, only ALKBH5 and METTL4 were downregulated in tumors. The gene distribution between the 2 subgroups were different. The expression of m6A RNA methylation regulators including YTHDF1, HNRNPC, YTHDC2, YTHDC1, ZC3H13, and RBM15 were different between the 2 groups (P<0.05). The prognostic characteristics between the high-risk and low-risk groups were significant different (P<0.05), which had a good predictive significance of prognosis area under the curve (AUC)=0.62). Risk scores were less than 0.05, suggesting risk score was an independent prognostic factor for colon adenocarcinoma. CONCLUSIONS m6A RNA methylation regulators YTHDF1 and HNRNPC can be used as prognostic factors of colon cancer, which has potential value for colon cancer treatment.",2019,Medical Science Monitor : International Medical Journal of Experimental and Clinical Research
GWAS-based machine learning approach to predict duloxetine response in major depressive disorder.,"Major depressive disorder (MDD) is one of the most prevalent psychiatric disorders and is commonly treated with antidepressant drugs. However, large variability is observed in terms of response to antidepressants. Machine learning (ML) models may be useful to predict treatment outcomes. A sample of 186 MDD patients received treatment with duloxetine for up to 8 weeks were categorized as ""responders"" based on a MADRS change >50% from baseline; or ""remitters"" based on a MADRS score â‰¤10â€¯at end point. The initial dataset (Nâ€¯=â€¯186) was randomly divided into training and test sets in a nested 5-fold cross-validation, where 80% was used as a training set and 20% made up five independent test sets. We performed genome-wide logistic regression to identify potentially significant variants related to duloxetine response/remission and extracted the most promising predictors using LASSO regression. Subsequently, classification-regression trees (CRT) and support vector machines (SVM) were applied to construct models, using ten-fold cross-validation. With regards to response, none of the pairs performed significantly better than chance (accuracy pâ€¯>â€¯.1). For remission, SVM achieved moderate performance with an accuracyâ€¯=â€¯0.52, a sensitivityâ€¯=â€¯0.58, and a specificityâ€¯=â€¯0.46, and 0.51 for all coefficients for CRT. The best performing SVM fold was characterized by an accuracyâ€¯=â€¯0.66 (pâ€¯=â€¯.071), sensitivityâ€¯=â€¯0.70 and a sensitivityâ€¯=â€¯0.61. In this study, the potential of using GWAS data to predict duloxetine outcomes was examined using ML models. The models were characterized by a promising sensitivity, but specificity remained moderate at best. The inclusion of additional non-genetic variables to create integrated models may improve prediction.",2018,Journal of psychiatric research
Projection-based Inference for High-dimensional Linear Models,"We develop a new method to estimate the projection direction in the debiased Lasso estimator. The basic idea is to decompose the overall bias into two terms corresponding to strong and weak signals respectively. We propose to estimate the projection direction by balancing the squared biases associated with the strong and weak signals as well as the variance of the projection-based estimator. Standard quadratic programming solver can efficiently solve the resulting optimization problem. In theory, we show that the unknown set of strong signals can be consistently estimated and the projection-based estimator enjoys the asymptotic normality under suitable assumptions. A slight modification of our procedure leads to an estimator with a potentially smaller order of bias comparing to the original debiased Lasso. We further generalize our method to conduct inference for a sparse linear combination of the regression coefficients. Numerical studies demonstrate the advantage of the proposed approach concerning coverage accuracy over some existing alternatives.",2019,
Incorporating diffusion- and perfusion-weighted MRI into a radiomics model improves diagnostic performance for pseudoprogression in glioblastoma patients,"BACKGROUND
Pseudoprogression is a diagnostic challenge in early posttreatment glioblastoma. We therefore developed and validated a radiomics model using multiparametric MRI to differentiate pseudoprogression from early tumor progression in patients with glioblastoma.


METHODS
The model was developed from the enlarging contrast-enhancing portions of 61 glioblastomas within 3 months after standard treatment with 6472 radiomic features being obtained from contrast-enhanced T1-weighted imaging, fluid-attenuated inversion recovery imaging, and apparent diffusion coefficient (ADC) and cerebral blood volume (CBV) maps. Imaging features were selected using a LASSO (least absolute shrinkage and selection operator) logistic regression model with 10-fold cross-validation. Diagnostic performance for pseudoprogression was compared with that for single parameters (mean and minimum ADC and mean and maximum CBV) and single imaging radiomics models using the area under the receiver operating characteristics curve (AUC). The model was validated with an external cohort (n = 34) imaged on a different scanner and internal prospective registry data (n = 23).


RESULTS
Twelve significant radiomic features (3 from conventional, 2 from diffusion, and 7 from perfusion MRI) were selected for model construction. The multiparametric radiomics model (AUC, 0.90) showed significantly better performance than any single ADC or CBV parameter (AUC, 0.57-0.79, P < 0.05), and better than a single radiomics model using conventional MRI (AUC, 0.76, P = 0.012), ADC (AUC, 0.78, P = 0.014), or CBV (AUC, 0.80, P = 0.43). The multiparametric radiomics showed higher performance in the external validation (AUC, 0.85) and internal validation (AUC, 0.96) than any single approach, thus demonstrating robustness.


CONCLUSIONS
Incorporating diffusion- and perfusion-weighted MRI into a radiomics model improved diagnostic performance for identifying pseudoprogression and showed robustness in a multicenter setting.",2019,Neuro-Oncology
Penalized Regression for Genome-Wide Association Screening of Sequence Data,"Whole exome and whole genome sequencing are likely to be potent tools in the study of common diseases and complex traits. Despite this promise, some very difficult issues in data management and statistical analysis must be squarely faced. The number of rare variants identified by sequencing is apt to be much larger than the number of common variants encountered in current association studies. The low frequencies of rare variants alone will make association testing difficult. This article extends the penalized regression framework for model selection in genome-wide association data to sequencing data with both common and rare variants. Previous research has shown that lasso penalties discourage irrelevant predictors from entering a model. The Euclidean penalties dealt with here group variants by gene or pathway. Pertinent biological information can be incorporated by calibrating penalties by weights. The current paper examines some of the tradeoffs in using pure lasso penalties, pure group penalties, and mixtures of the two types of penalty. All of the computational and statistical advantages of lasso penalized estimation are retained in this richer setting. The overall strategy is implemented in the free statistical genetics analysis software MENDEL and illustrated on both simulated and real data.",2011,Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
Development and validation of a radiomics signature on differentially expressed features of 18F-FDG PET to predict treatment response of concurrent chemoradiotherapy in thoracic esophagus squamous cell carcinoma.,"BACKGROUND AND PURPOSE
To investigate potential image markers for early prediction of treatment response on thoracic esophagus squamous cell carcinoma (ESCC) treated with concurrent chemoradiotherapy (CCRT).


MATERIALS AND METHODS
159 thoracic ESCC patients enrolled from two institutions were divided into training and validation sets. A total of 944 radiomics features were extracted from pretreatment 18F-FDG PET images. We first performed the inter-observer reproducibility test in 10 pairs of patients (responders vs. nonresponders), and the limma package was used to identify differentially expressed features (DEFs). Then the least absolute shrinkage and selection operator (LASSO) logistic regression model with 10-fold cross-validation was used to construct a treatment response related radiomics signature. Finally, the performance was assessed in both sets with receiver operating characteristic (ROC) curves and Kaplan-Meier analysis.


RESULTS
After the inter-observer test, 691 features were considered reproducible and been retained (ICCÂ >Â 0.9). 61 DEFs were selected from limma and entered into the LASSO logistic regression model. The radiomics signature was significantly associated with treatment response in the training (pÂ <Â 0.001) and validation set (pÂ =Â 0.026), which achieved area under curve (AUC) values of 0.844 and 0.835, respectively. Delong test results of two ROCs showed no significant difference (pÂ =Â 0.918). The cut-off value of the radiomics signature could successfully divide patients into high-risk and low-risk groups in both sets.


CONCLUSION
This study indicated that the proposed radiomics signature could be a useful image marker to predict the therapeutic response of thoracic ESCC patients treated with CCRT.",2020,Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology
Bootstrapping Lasso Estimators,"In this article, we consider bootstrapping the Lasso estimator of the regression parameter in a multiple linear regression model. It is known that the standard bootstrap method fails to be consistent. Here, we propose a modified bootstrap method, and show that it provides valid approximation to the distribution of the Lasso estimator, for all possible values of the unknown regression parameter vector, including the case where some of the components are zero. Further, we establish consistency of the modified bootstrap method for estimating the asymptotic bias and variance of the Lasso estimator. We also show that the residual bootstrap can be used to consistently estimate the distribution and variance of the adaptive Lasso estimator. Using the former result, we formulate a novel data-based method for choosing the optimal penalizing parameter for the Lasso using the modified bootstrap. A numerical study is performed to investigate the finite sample performance of the modified bootstrap. The methodology prop...",2011,Journal of the American Statistical Association
