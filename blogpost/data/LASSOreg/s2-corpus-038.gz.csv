title,abstract,year,journal
Application of Machine Learning Techniques to High-Dimensional Clinical Data to Forecast Postoperative Complications,"OBJECTIVE
To compare performance of risk prediction models for forecasting postoperative sepsis and acute kidney injury.


DESIGN
Retrospective single center cohort study of adult surgical patients admitted between 2000 and 2010.


PATIENTS
50,318 adult patients undergoing major surgery.


MEASUREMENTS
We evaluated the performance of logistic regression, generalized additive models, naÃ¯ve Bayes and support vector machines for forecasting postoperative sepsis and acute kidney injury. We assessed the impact of feature reduction techniques on predictive performance. Model performance was determined using the area under the receiver operating characteristic curve, accuracy, and positive predicted value. The results were reported based on a 70/30 cross validation procedure where the data were randomly split into 70% used for training the model and the 30% for validation.


MAIN RESULTS
The areas under the receiver operating characteristic curve for different models ranged between 0.797 and 0.858 for acute kidney injury and between 0.757 and 0.909 for severe sepsis. Logistic regression, generalized additive model, and support vector machines had better performance compared to NaÃ¯ve Bayes model. Generalized additive models additionally accounted for non-linearity of continuous clinical variables as depicted in their risk patterns plots. Reducing the input feature space with LASSO had minimal effect on prediction performance, while feature extraction using principal component analysis improved performance of the models.


CONCLUSIONS
Generalized additive models and support vector machines had good performance as risk prediction model for postoperative sepsis and AKI. Feature extraction using principal component analysis improved the predictive performance of all models.",2016,PLoS ONE
A hybrid Bayesian-network proposition for forecasting the crude oil price,"This paper proposes a hybrid Bayesian Network (BN) method for short-term forecasting of crude oil prices. The method performed is a hybrid, based on both the aspects of classification of influencing factors as well as the regression of the out-of-sample values. For the sake of performance comparison, several other hybrid methods have also been devised using the methods of Markov Chain Monte Carlo (MCMC), Random Forest (RF), Support Vector Machine (SVM), neural networks (NNET) and generalized autoregressive conditional heteroskedasticity (GARCH). The hybrid methodology is primarily reliant upon constructing the crude oil price forecast from the summation of its Intrinsic Mode Functions (IMF) and its residue, extracted by an Empirical Mode Decomposition (EMD) of the original crude price signal. The Volatility Index (VIX) as well as the Implied Oil Volatility Index (OVX) has been considered among the influencing parameters of the crude price forecast. The final set of influencing parameters were selected as the whole set of significant contributors detected by the methods of Bayesian Network, Quantile Regression with Lasso penalty (QRL), Bayesian Lasso (BLasso) and the Bayesian Ridge Regression (BRR). The performance of the proposed hybrid-BN method is reported for the three crude price benchmarks: West Texas Intermediate, Brent Crude and the OPEC Reference Basket.",2019,Financial Innovation
Risk classification in high dimensional survival models,"Sparse regression models are an actively burgeoning area of statistical learning research. A subset of these models seek to separate out significant and non-trivial main effects from noise effects within the regression framework (yielding so-called â€œsparseâ€ coefficient estimates, where many estimated effects are zero) by imposing penalty terms on a likelihood-based estimator. As this area of the field is relatively recent, many published techniques have not yet been investigated under a wide range of applications. Our goal is to fit several penalty-based estimators for the Cox semiparametric survival model in the context of genomic covariates on breast cancer survival data where there are potentially many more covariates than observations. We use the elastic net family of estimators, special cases of which are the LASSO and ridge regression. Simultaneously, we aim to investigate whether the finer resolution of next-generation genetic sequencing techniques adds improved predictive power to the breast cancer patient survival models. Models are compared using estimates of concordance, namely the c-statistic and a variant which we refer to as Unoâ€™s C. We find that ridge regression models best fit our dataset. Concordance estimates suggest finer resolution genetic covariates improve model predictions, though further work with more observations is required.",2016,
Machine Learning Approach for Data Analysis of Magnetic Orbital Moments and Magnetocrystalline Anisotropy in Transition-Metal Thin Films on MgO(001),"Using the Least Absolute Shrinkage and Selection Operator (LASSO) technique, we analyze a long-standing issue in the field of magnetism: the relationship between orbital magnetic moments and magnetocrystalline anisotropy (MCA) energy in transition-metal thin films. Our LASSO regression utilizes the data obtained from first principles calculations for single slabs with six atomic-layers of binary Au-Fe, Au-Co, and Fe-Co films on MgO(001). In the case of Fe-Co thin films, we have successfully regressed the MCA energy against the anisotropy of orbital moments along the in-plane and the perpendicular plane directions, giving a linear behavior. For the Au-Fe and Au-Co thin films, however, our data-driven analysis shows no relation between the MCA energy and the anisotropy of orbital moments.",2018,Journal of Electronic Materials
Bayesian model combining linkage and linkage disequilibrium analysis for low density-based genomic selection in animal breeding,"ABSTRACTWe combined linkage (LA) and linkage disequilibrium (LDA) analyses (emerging the term â€˜LALDAâ€™) for genomic selection (GS) purposes. The models were fitted to a simulated dataset and to a real data of feed conversion ratio in pigs. Firstly, the significant QTLs (quantitative trait locus) were identified through LA-based mixed models considering the QTL-genotypes as random effects by means of genotypic identity by descent matrix. This matrix was calculated at the positions of significant QTLs (based on LA) allowing to include the QTL-genotype effects additionally to SNP (single nucleotide polymorphism) markers (based on LDA) and additive polygenic effects in several GS models (Bayesian Ridge Regression â€“ BRR; Bayes A â€“ BA; Bayes B â€“ BB; Bayes C â€“ BC and Bayesian LASSOÂ â€“ BL). These models combing all mentioned effects were denominated LALDA. Goodness-of-fit and predictive ability analyses were performed to evaluate the efficiency of these models. For the real data, although slightly, the superiority ...",2018,Journal of Applied Animal Research
A genomic-clinical nomogram predicting recurrence-free survival for patients diagnosed with hepatocellular carcinoma,"Liver resection surgery is the most commonly used treatment strategy for patients diagnosed with hepatocellular carcinoma (HCC). However, there is still a chance for recurrence in these patients despite the survival benefits of this procedure. This study aimed to explore recurrence-related genes (RRGs) and establish a genomic-clinical nomogram for predicting postoperative recurrence in HCC patients. A total of 123 differently expressed genes and three RRGs (PZP, SPP2, and PRC1) were identified from online databases via Cox regression and LASSO logistic regression analyses and a gene-based risk model containing RRGs was then established. The Harrell's concordance index (C-index), receiver operating characteristic (ROC) curves and calibration curves showed that the model performed well. Finally, a genomic-clinical nomogram incorporating the gene-based risk model, AJCC staging system, and Eastern Cooperative Oncology Group performance status was constructed to predict the 1-, 2-, and 3-year recurrence-free survival rates (RFS) for HCC patients. The C-index, ROC analysis, and decision curve analysis were good indicators of the nomogram's performance. In conclusion, we identified three reliable RRGs associated with the recurrence of cancer and constructed a nomogram that performed well in predicting RFS for HCC patients. These findings could enrich our understanding of the mechanisms for HCC recurrence, help surgeons predict patients' prognosis, and promote HCC treatment.",2019,PeerJ
Methods of plant breeding in the genome era.,"Methods of genomic value prediction are reviewed. The majority of the methods are related to mixed model methodology, either explicitly or implicitly, by treating systematic environmental effects as fixed and quantitative trait locus (QTL) effects as random. Six different methods are reviewed, including least squares (LS), ridge regression, Bayesian shrinkage, least absolute shrinkage and selection operator (Lasso), empirical Bayes and partial least squares (PLS). The LS and PLS methods are non-Bayesian because they do not require probability distributions for the data. The PLS method is introduced as a special dimension reduction scheme to handle high-density marker information. Theory and methods of cross-validation are described. The leave-one-out cross-validation approach is recommended for model validation. A working example is used to demonstrate the utility of genome selection (GS) in barley. The data set contained 150 double haploid lines and 495 DNA markers covering the entire barley genome, with an average marker interval of 2Â·23 cM. Eight quantitative traits were included in the analysis. GS using the empirical Bayesian method showed high predictability of the markers for all eight traits with a mean accuracy of prediction of 0Â·70. With traditional marker-assisted selection (MAS), the average accuracy of prediction was 0Â·59, giving an average gain of GS over MAS of 0Â·11. This study provided strong evidence that GS using marker information alone can be an efficient tool for plant breeding.",2010,Genetics research
Sparse Volterra and Polynomial Regression Models: Recoverability and Estimation,"Volterra and polynomial regression models play a major role in nonlinear system identification and inference tasks. Exciting applications ranging from neuroscience to genome-wide association analysis build on these models with the additional requirement of parsimony. This requirement has high interpretative value, but unfortunately cannot be met by least-squares based or kernel regression methods. To this end, compressed sampling (CS) approaches, already successful in linear regression settings, can offer a viable alternative. The viability of CS for sparse Volterra and polynomial models is the core theme of this work. A common sparse regression task is initially posed for the two models. Building on (weighted) Lasso-based schemes, an adaptive RLS-type algorithm is developed for sparse polynomial regressions. The identifiability of polynomial models is critically challenged by dimensionality. However, following the CS principle, when these models are sparse, they could be recovered by far fewer measurements. To quantify the sufficient number of measurements for a given level of sparsity, restricted isometry properties (RIP) are investigated in commonly met polynomial regression settings, generalizing known results for their linear counterparts. The merits of the novel (weighted) adaptive CS algorithms to sparse polynomial modeling are verified through synthetic as well as real data tests for genotype-phenotype analysis.",2011,IEEE Transactions on Signal Processing
A descent method for least absolute deviation lasso problems,"Variable selection is an important method to analyze large quantity of data and extract useful information. Although least square regression is the most widely used scheme for its flexibility in obtaining explicit solutions, least absolute deviation (LAD) regression combined with lasso penalty becomes popular for its resistance to heavy-tailed errors in response variable, denoted as LAD-LASSO. In this paper, we consider the LAD-LASSO problem for variable selection. Based on a dynamic optimality condition of nonsmooth optimization problem, we develop a descent method to solve the nonsmooth optimization problem. Numerical experiments are conducted to confirm that the proposed method is more efficient than existing methods.",2019,Optimization Letters
Development and Validation of Predictive Indices for a Continuous Outcome Using Gene Expression Profiles,"There have been relatively few publications using linear regression models to predict a continuous response based on microarray expression profiles. Standard linear regression methods are problematic when the number of predictor variables exceeds the number of cases. We have evaluated three linear regression algorithms that can be used for the prediction of a continuous response based on high dimensional gene expression data. The three algorithms are the least angle regression (LAR), the least absolute shrinkage and selection operator (LASSO), and the averaged linear regression method (ALM). All methods are tested using simulations based on a real gene expression dataset and analyses of two sets of real gene expression data and using an unbiased complete cross validation approach. Our results show that the LASSO algorithm often provides a model with somewhat lower prediction error than the LAR method, but both of them perform more efficiently than the ALM predictor. We have developed a plug-in for BRB-ArrayTools that implements the LAR and the LASSO algorithms with complete cross-validation.",2010,Cancer Informatics
In silico Prioritization of Transporterâ€“Drug Relationships From Drug Sensitivity Screens,"The interplay between drugs and cell metabolism is a key factor in determining both compound potency and toxicity. In particular, how and to what extent transmembrane transporters affect drug uptake and disposition is currently only partially understood. Most transporter proteins belong to two protein families: the ATP-Binding Cassette (ABC) transporter family, whose members are often involved in xenobiotic efflux and drug resistance, and the large and heterogeneous family of Solute carriers (SLCs). We recently argued that SLCs are collectively a rather neglected gene group, with most of its members still poorly characterized, and thus likely to include many yet-to-be-discovered associations with drugs. We searched publicly available resources and literature to define the currently known set of drugs transported by ABCs or SLCs, which involved ~500 drugs and more than 100 transporters. In order to extend this set, we then mined the largest publicly available pharmacogenomics dataset, which involves approximately 1000 molecularly annotated cancer cell lines and their response to 265 chemical compounds, and used regularized linear regression models (Elastic Net, LASSO) to predict drug responses based on SLC and ABC data (expression levels, SNVs, CNVs). The most predictive models included both known and previously unidentified associations between drugs and transporters. To our knowledge, this represents the first application of regularized linear regression to this set of genes, providing an extensive prioritization of potentially pharmacologically interesting interactions.",2018,Frontiers in Pharmacology
Pulp tooth ratio in the estimation of age: A study on mandibular premolars,"The aim of the study was to use Cameriereâ€™s radiographic method of age estimation 
using pulp/tooth ratio of mandibular premolars on a South Indian sample and derive 
population-specific equations for a more accurate estimation of age. This retrospective 
study was carried out using 150 digital orthopantomograms of patients (age between 20- 
70 years) of Indian origin from the records of our institution. Approval from the 
institutional ethics committee was obtained prior to commencing the study. The images of 
the orthopantomograms were recorded on computer files. Following the technique 
proposed by Cameriere et al. the radiographic images were saved as high resolution JPEG 
files and imported to Photoshop Image processing software and Image J (NIH USA). The 
focus of the study was the mandibular first and second premolar. A lasso tool was used to 
delineate the external perimeter of the tooth as well as the pulpal perimeter and two 
variables obtained. Linear regression equations were derived for predicting the age of the 
individuals separately for each gender. The pulp/tooth area ratio of mandibular premolar 
was seen to decrease significantly with age. Multiple regression equations were derived 
based on age as the dependent variable and the tooth/pulp ratios as predictors. Thus, the 
pulp/tooth ratio is a valuable method in the estimation of age of subjects of Indian origin.",2017,
Regularization and Model Selection with Categorical Covariates,"The challenge in regression problems with categorical covariates is the high number of parameters involved. Common regularization methods like the Lasso, which allow for selection of predictors, are typically designed for metric predictors. If independent variables are categorical, selection strategies should be based on modified penalties. For categorical predictor variables with many categories a useful strategy is to search for clusters of categories with similar effects. We focus on generalized linear models and present L 1-penalty approaches for factor selection and clustering of categories. The methods proposed are investigated in simulation studies and applied to a real world classification problem.",2013,
Hypoglycaemia with tramadol,"Analysis of reports to the US FDAâ€™s Adverse Event Reporting System (FAERS) suggests ""a potential signal between hypoglycaemia and tramadol use in patients not taking diabetes medications and patients <4 years old"", according to study results reported in the Annals of Pharmacotherapy. The study found 605 reported cases of tramadolassociated hypoglycaemia, which was the strongest association with hypoglycaemia among medications with Î¼-opioid agonist properties. The number of cases increased over time, and although the fifth percentile of the Empirical Bayesian geometric mean distribution (EB05) was elevated at 1.590, this was not statistically significant (>2). There were 352 cases in patients also taking antidiabetes medications, but no signal was detected, as the fifth percentile of the logistic regression odds ratio [LR05] was 1.5631 (significant value >2) and the EB05 was 0.856. There were 253 cases in patients not taking antidiabetes medications, which resulted in a significant signal (EB05=2.256; LR05=2.2104). The authors note that ""the signal for hypoglycaemia in the database is likely masked because of the use of diabetic medications"". There were 10 cases in patients with renal impairment, but this was not significant (EB05=1.572; Interaction Signal Score [INTSS]=0.865). Age did not increase the odds of tramadol-associated hypoglycaemia overall (LR05=1.6425), but hypoglycaemia was more likely in patients 0â€“1 years of age (LR05=3.0240) or 2â€“4 years of age (LR05=2.6853). ""The results of our study suggest that the 3 subpopulations noted to have a predisposition for tramadol-associated hypoglycemia in the package insert â€”patients with renal insufficiency, increasing age, and/ or diabetesâ€”did not have an increased risk"", note the authors. They add that ""it is important to note that our findings do not indicate causality and require further epidemiological studies for confirmation in these subpopulations"".",2019,Reactions Weekly
Correcting Bias in Crowdsourced Data to Map Bicycle Ridership of All Bicyclists,"Traditional methods of counting bicyclists are resource-intensive and generate data with sparse spatial and temporal detail. Previous research suggests big data from crowdsourced fitness apps offer a new source of bicycling data with high spatial and temporal resolution. However, crowdsourced bicycling data are biased as they oversample recreational riders. Our goals are to quantify geographical variables, which can help in correcting bias in crowdsourced, data and to develop a generalized method to correct bias in big crowdsourced data on bicycle ridership in different settings in order to generate maps for cities representative of all bicyclists at a street-level spatial resolution. We used street-level ridership data for 2016 from a crowdsourced fitness app (Strava), geographical covariate data, and official counts from 44 locations across Maricopa County, Arizona, USA (training data); and 60 locations from the city of Tempe, within Maricopa (test data). First, we quantified the relationship between Strava and official ridership data volumes. Second, we used a multi-step approach with variable selection using LASSO followed by Poisson regression to integrate geographical covariates, Strava, and training data to correct bias. Finally, we predicted bias-corrected average annual daily bicyclist counts for Tempe and evaluated the modelâ€™s accuracy using the test data. We found a correlation between the annual ridership data from Strava and official counts (R2 = 0.76) in Maricopa County for 2016. The significant variables for correcting bias were: The proportion of white population, median household income, traffic speed, distance to residential areas, and distance to green spaces. The model could correct bias in crowdsourced data from Strava in Tempe with 86% of road segments being predicted within a margin of Â±100 average annual bicyclists. Our results indicate that it is possible to map ridership for cities at the street-level by correcting bias in crowdsourced bicycle ridership data, with access to adequate data from official count programs and geographical covariates at a comparable spatial and temporal resolution.",2019,
Development of an Algorithm to Classify Colonoscopy Indication from Coded Health Care Data,"INTRODUCTION
Electronic health data are potentially valuable resources for evaluating colonoscopy screening utilization and effectiveness. The ability to distinguish screening colonoscopies from exams performed for other purposes is critical for research that examines factors related to screening uptake and adherence, and the impact of screening on patient outcomes, but distinguishing between these indications in secondary health data proves challenging. The objective of this study is to develop a new and more accurate algorithm for identification of screening colonoscopies using electronic health data.


METHODS
Data from a case-control study of colorectal cancer with adjudicated colonoscopy indication was used to develop logistic regression-based algorithms. The proposed algorithms predict the probability that a colonoscopy was indicated for screening, with variables selected for inclusion in the models using the Least Absolute Shrinkage and Selection Operator (LASSO).


RESULTS
The algorithms had excellent classification accuracy in internal validation. The primary, restricted model had AUC= 0.94, sensitivity=0.91, and specificity=0.82. The secondary, extended model had AUC=0.96, sensitivity=0.88, and specificity=0.90.


DISCUSSION
The LASSO approach enabled estimation of parsimonious algorithms that identified screening colonoscopies with high accuracy in our study population. External validation is needed to replicate these results and to explore the performance of these algorithms in other settings.",2015,eGEMs
Multi-Task Learning for Spatio-Temporal Event Forecasting,"Spatial event forecasting from social media is an important problem but encounters critical challenges, such as dynamic patterns of features (keywords) and geographic heterogeneity (e.g., spatial correlations, imbalanced samples, and different populations in different locations). Most existing approaches (e.g., LASSO regression, dynamic query expansion, and burst detection) are designed to address some of these challenges, but not all of them. This paper proposes a novel multi-task learning framework which aims to concurrently address all the challenges. Specifically, given a collection of locations (e.g., cities), we propose to build forecasting models for all locations simultaneously by extracting and utilizing appropriate shared information that effectively increases the sample size for each location, thus improving the forecasting performance. We combine both static features derived from a predefined vocabulary by domain experts and dynamic features generated from dynamic query expansion in a multi-task feature learning framework; we investigate different strategies to balance homogeneity and diversity between static and dynamic terms. Efficient algorithms based on Iterative Group Hard Thresholding are developed to achieve efficient and effective model training and prediction. Extensive experimental evaluations on Twitter data from four different countries in Latin America demonstrated the effectiveness of our proposed approach.",2015,
New estimation and inference procedures for a single-index conditional distribution model,"This article employs a more flexible single-index regression model to characterize the conditional distribution. The pseudo least integrated squares approach is proposed to estimate the index coefficients. As shown in the numerical results, our estimator outperforms the existing ones in terms of the mean squared error. Moreover, we provide the generalized cross-validation criteria for bandwidth selection and utilize the frequency distributions of weighted bootstrap analogues for the estimation of asymptotic variance and the construction of confidence intervals. With a defined residual process, a test rule is built to check the correctness of an applied single-index conditional distribution model. To tackle the problem of sparse variables, a multi-stage adaptive Lasso algorithm is developed to enhance the ability of identifying significant variables. All of our procedures are found to be easily implemented, numerically stable, and highly adaptive to a variety of data structures. In addition, we assess the finite sample performances of the proposed estimation and inference procedures through extensive simulation experiments. Two empirical examples from the house-price study in Boston and the environmental study in New York are further used to illustrate applications of the methodology.",2012,J. Multivar. Anal.
Sparse Reduced-Rank Regression for Simultaneous Dimension Reduction and Variable Selection,"The reduced-rank regression is an effective method in predicting multiple response variables from the same set of predictor variables. It reduces the number of model parameters and takes advantage of interrelations between the response variables and hence improves predictive accuracy. We propose to select relevant variables for reduced-rank regression by using a sparsity-inducing penalty. We apply a group-lasso type penalty that treats each row of the matrix of the regression coefficients as a group and show that this penalty satisfies certain desirable invariance properties. We develop two numerical algorithms to solve the penalized regression problem and establish the asymptotic consistency of the proposed method. In particular, the manifold structure of the reduced-rank regression coefficient matrix is considered and studied in our theoretical analysis. In our simulation study and real data analysis, the new method is compared with several existing variable selection methods for multivariate regression...",2012,Journal of the American Statistical Association
Predicting student's psychomotor domain on the vocational senior high school using linear regression,"The educational data can be mined to produce the useful knowledge. This paper focuses on the educational data processing to predict student's psychomotor domain. Here, we apply linear regression method to do it. On process stage, we use 4 regularizations, namely: no regularization, ridge regression, lasso regression and elastic net regression. Furthermore, we exploit 2 sampling methods as the evaluation technique, for examples: cross-validation sampling and random sampling. The experimental result indicates that the best regularization on cross-validation and random sampling are an elastic net regression because this regularization achieves the lowest predicting error. On cross-validation, values of MSE, RMSE, and MAE are 40.079, 6.330 and 5.183, respectively. Additionally, for random sampling, respectively, values of MSE, RMSE, and MAE are 86.910, 8.428 and 6.511.",2018,2018 International Conference on Information and Communications Technology (ICOIACT)
High-Dimensional Inference for Personalized Treatment Decision.,"Recent development in statistical methodology for personalized treatment decision has utilized high-dimensional regression to take into account a large number of patients' covariates and described personalized treatment decision through interactions between treatment and covariates. While a subset of interaction terms can be obtained by existing variable selection methods to indicate relevant covariates for making treatment decision, there often lacks statistical interpretation of the results. This paper proposes an asymptotically unbiased estimator based on Lasso solution for the interaction coefficients. We derive the limiting distribution of the estimator when baseline function of the regression model is unknown and possibly misspecified. Confidence intervals and p-values are derived to infer the effects of the patients' covariates in making treatment decision. We confirm the accuracy of the proposed method and its robustness against misspecified function in simulation and apply the method to STAR*D study for major depression disorder.",2018,Electronic journal of statistics
"A User-Friendly, Web-Based Integrative Tool (ESurv) for Survival Analysis: Development and Validation Study.","BACKGROUND
Prognostic genes or gene signatures have been widely used to predict patient survival and aid in making decisions pertaining to therapeutic actions. Although some web-based survival analysis tools have been developed, they have several limitations.


OBJECTIVE
Taking these limitations into account, we developed ESurv (Easy, Effective, and Excellent Survival analysis tool), a web-based tool that can perform advanced survival analyses using user-derived data or data from The Cancer Genome Atlas (TCGA). Users can conduct univariate analyses and grouped variable selections using multiomics data from TCGA.


METHODS
We used R to code survival analyses based on multiomics data from TCGA. To perform these analyses, we excluded patients and genes that had insufficient information. Clinical variables were classified as 0 and 1 when there were two categories (for example, chemotherapy: no or yes), and dummy variables were used where features had 3 or more outcomes (for example, with respect to laterality: right, left, or bilateral).


RESULTS
Through univariate analyses, ESurv can identify the prognostic significance for single genes using the survival curve (median or optimal cutoff), area under the curve (AUC) with C statistics, and receiver operating characteristics (ROC). Users can obtain prognostic variable signatures based on multiomics data from clinical variables or grouped variable selections (lasso, elastic net regularization, and network-regularized high-dimensional Cox-regression) and select the same outputs as above. In addition, users can create custom gene signatures for specific cancers using various genes of interest. One of the most important functions of ESurv is that users can perform all survival analyses using their own data.


CONCLUSIONS
Using advanced statistical techniques suitable for high-dimensional data, including genetic data, and integrated survival analysis, ESurv overcomes the limitations of previous web-based tools and will help biomedical researchers easily perform complex survival analyses.",2020,Journal of medical Internet research
Fecal Calprotectin Evaluation in Patients with Ulcerative Colitis,"Dear Editor, We read with great interest the article by Burri et al. [1] entitled â€˜â€˜Fecal calprotectin and the clinical activity index are both useful to monitor medical treatment in patients with ulcerative colitisâ€™â€™ in which the investigators suggested that fecal calprotectin (FC) was useful to monitor disease activity of ulcerative colitis during medical treatment and identified endoscopic disease activity reliably. However, there are some points that should be discussed. FC is a confirmed noninvasive biomarker in inflammatory bowel diseases. Previous studies showed that various medications such as nonsteroidal anti-inflammatory drugs, aspirin, and statins could alter FC levels beside stated medications [2]. Also, dietary supplements such as zinc, vitamin D, fatty acids, and several probiotics can affect FC levels too [3, 4]. We believe above contributing factors have to be stated to provide robust study population. Lasson et al. [5] suggested that there was a great instability in the concentrations of FC in stool samples collected during a single day. Body mass indices of participants and pregnancy status of female participants should be expressed due to being other contributing factors [6, 7]. We believe these variables could be effective on the measurement of FC. These confounders should be expressed, and multivariate regression analysis has to be applied to obtain meaningful data. Single measurement of FC may not be sufficiently accurate to evaluate the disease activity of ulcerative colitis, and other markers such as platelet and leukocyte count, albumin, C-reactive protein, lactoferrin, alpha-1 acid glycoprotein, and polymorphonuclear elastase may be required [8, 9]. In conclusion, clarifying above concerns will certainly provide a clearer picture to the readers.",2015,Digestive Diseases and Sciences
"Comparison of Supervised , Semi-supervised and Unsupervised Learning Methods in Network Intrusion Detection System ( NIDS ) Application","With the emergence of the fourth industrial revolution (Industrie 4.0) of cyber physical systems, intrusion detection systems are highly necessary to detect industrial network attacks. Recently, the increase in application of specialized machine learning techniques is gaining critical attention in the intrusion detection community. A wide variety of learning techniques proposed for different network intrusion detection system (NIDS) problems can be roughly classified into three broad categories: supervised, semi-supervised and unsupervised. In this paper, a comparative study of selected learning methods from each of these three kinds is carried out. In order to assess these learning methods, they are subjected to investigate network traffic datasets from an Airplane Cabin Demonstrator. In addition to this, the imbalanced classes (normal and anomaly classes) that are present in the captured network traffic data is one of the most crucial issues to be taken into consideration. From this investigation, it has been identified that supervised learning methods (logistic and lasso logistic regression methods) perform better than other methods when historical data on former attacks are available. The results of this study have also showed that the performance of semisupervised learning method (One class support vector machine) is comparatively better than unsupervised learning method (Isolation Forest) when historical data on former attacks are not available.",2017,
Identifying risk of poor physical and mental health recovery following a road traffic crash: An industry-specific screening tool.,"This study aimed to develop an industry-specific tool to identify risk of poor physical and mental recovery following minor to moderate injuries sustained in a road traffic crash (RTC). Existing tools are often designed for implementation by health professionals rather than insurer case managers who may not have a background in health. This study is a secondary analysis of a longitudinal cohort study using data collected at 2-6 months and 24 months post-RTC. Participants were claimants (nâ€¯=â€¯254; Mean ageâ€¯=â€¯50 years; 65% female) with mild-moderate injuries recruited through the common-law 'fault-based' compulsory third party scheme in Queensland, Australia. Sociodemographic, functional and psychological health factors were collected at baseline (2-6 months post RTC) and used as potential predictors for physical and mental health-related quality of life (Short Form 36 v2) at the 2-year follow-up. The LASSO (Least Absolute Shrinkage and Selection Operator) analysis identified six disability items (from the World Health Organization Disability Assessment Schedule 2) to predict poor physical and one item to predict poor mental health-related quality of life. Logistic regressions of these items in addition to age and gender were used to develop a screening tool. Using the tool, 90% of those at risk of poor physical and 80% of those at risk of poor mental health-related quality of life were identified correctly. To conclude, this study presents an 8-item, context-specific tool to help injury managers identify individuals at risk of poor physical and mental health recovery following mild-moderate RTC-related injuries. The tool requires validation in a new cohort and confirmation of acceptability by end-users.",2019,Accident; analysis and prevention
Tuning-Free Heterogeneity Pursuit in Massive Networks,"Heterogeneity is often natural in many contemporary applications involving massive data. While posing new challenges to effective learning, it can play a crucial role in powering meaningful scientific discoveries through the understanding of important differences among subpopulations of interest. In this paper, we exploit multiple networks with Gaussian graphs to encode the connectivity patterns of a large number of features on the subpopulations. To uncover the heterogeneity of these structures across subpopulations, we suggest a new framework of tuning-free heterogeneity pursuit (THP) via large-scale inference, where the number of networks is allowed to diverge. In particular, two new tests, the chi-based test and the linear functional-based test, are introduced and their asymptotic null distributions are established. Under mild regularity conditions, we establish that both tests are optimal in achieving the testable region boundary and the sample size requirement for the latter test is minimal. Both theoretical guarantees and the tuning-free feature stem from efficient multiple-network estimation by our newly suggested approach of heterogeneous group square-root Lasso (HGSL) for high-dimensional multi-response regression with heterogeneous noises. To solve this convex program, we further introduce a tuning-free algorithm that is scalable and enjoys provable convergence to the global optimum. Both computational and theoretical advantages of our procedure are elucidated through simulation and real data examples.",2016,arXiv: Methodology
Weighted SPICE: A unifying approach for hyperparameter-free sparse estimation,"Abstract In this paper we present the SPICE approach for sparse parameter estimation in a framework that unifies it with other hyperparameter-free methods, namely LIKES, SLIM and IAA. 1 Specifically, we show how the latter methods can be interpreted as variants of an adaptively reweighted SPICE method. Furthermore, we establish a connection between SPICE and the l 1 -penalized LAD estimator as well as the square-root LASSO method. We evaluate the four methods mentioned above in a generic sparse regression problem and in an array processing application.",2014,Digit. Signal Process.
Multicenter Development and Validation of a Novel Risk Nomogram for Early Prediction of Severe 2019-Novel Coronavirus Pneumonia,"Background: Severe cases of coronavirus disease 2019 (COVID-19) rapidly develop acute respiratory distress leading to respiratory failure, with remarkably high short-term mortality rates. At present, there is no reliable risk stratification tool for COVID-19 patients. We aimed to construct and validate a model for early identification of severe cases of COVID-19. 
 
Methods: SARS-CoV-2 infected patients from two centers in Guangzhou and one center in Wuhan were included retrospectively, and divided into the train and external validation cohorts. All patients with non-severe COVID-19 during hospitalization were followed for more than 15 days following admission and patients who deteriorated to severe COVID-19 were assigned to the severe group. Least absolute shrinkage and selection operator (LASSO) algorithm and logistic regression model were used to construct a nomogram for risk prediction in the train cohort. The predictive accuracy and discriminative ability of nomogram were evaluated by area under the curve (AUC) and calibration curve. Decision curve analysis (DCA) and clinical impact curve analysis (CICA) were conducted to evaluate the clinical applicability of our nomogram. 
 
Findings: The train cohort consisted of 189 patients, while the two independent validation cohorts consisted of 165 and 18 patients. Among all cases, 72 (19.35%) patients developed severe COVID-19. We generated the nomogram containing one clinical and six serological indicators (age, serum lactate dehydrogenase, C-reactive protein, the coefficient of variation of red blood cell distribution width, blood urea nitrogen, albumin, direct bilirubin) that could early identify severe COVID-19 patients. The nomogram showed remarkably high diagnostic accuracy in distinguishing individuals with severe COVID-19 from non-severe COVID-19 (AUC 0.914 [95% CI 0.852â€“0.976] in the train cohort; 0.856 [0.795-0.916] in validation cohort 1. The calibration curve for probability of severe COVID-19 showed optimal agreement between prediction by nomogram and actual observation. DCA and CICA further indicated that our nomogram conferred significantly high clinical net benefit. 
 
Interpretation: Our nomogram is a potentially useful prediction tool for risk assessment of COVID-19 patients and early identification of severe COVID-19 patients. Risk stratification will enable better management and optimal use of medical resources via patient prioritization and thus significantly reduce mortality rates. 
 
Funding Statement: Science and Technology Program of Guangzhou, China (201804010474) 
 
Declaration of Interests: The author(s) declare(s) that there is no conflict of interest regarding the publication of this paper. 
 
Ethics Approval Statement: The study was approved by the Ethics Committee of the Eighth People's Hospital of Guangzhou (20200547). Written informed consent was waived by the Ethics Commission of the Third Affiliated Hospital of Sun Yat-sen University for emerging infectious diseases.",2020,
Feature Relevance for Kernel Logistic Regression and Application to Action Classification,"An approach is proposed for incorporating feature relevance in mutinomial kernel logistic regression (MKLR) for classification. MKLR is a supervised classification method designed for separating classes with non-linear boundaries. However, it assumes all features are equally important, which may decrease classification performance when dealing with high-dimensional or noisy data. We propose a feature weighting algorithm for MKLR which automatically tunes features contribution according to their relevance for classification and reduces data over-fitting. The proposed algorithm produces more interpretable models and is more generalizable than MKLR, Kernel-SVM and LASSO methods. Application to simulated data and video action classification has provided very promising results compared to the aforementioned classification methods.",2014,2014 22nd International Conference on Pattern Recognition
Combining heterogeneous data sources for civil unrest forecasting,"Detecting and forecasting civil unrest events (protests, strikes, etc.) is of key interest to social scientists and policy makers because these events can lead to significant societal and cultural changes. We analyze protest dynamics in six countries of Latin America on a daily level, from November 2012 through August 2014, using multiple data sources that capture social, political and economic contexts within which civil unrest occurs. We use logistic regression models with Lasso to select a sparse feature set from our diverse datasets, in order to predict the probability of occurrence of civil unrest events in these countries. The models contain predictors extracted from social media sites (Twitter and blogs) and news sources, in addition to volume of requests to Tor, a widely-used anonymity network. Two political event databases and country-specific exchange rates are also used. Our forecasting models are evaluated using a Gold Standard Report (GSR), which is compiled by an independent group of social scientists and experts on Latin America. The experimental results, measured by F1-scores, are in the range 0.68 to 0.95, and demonstrate the efficacy of using a multi-source approach for predicting civil unrest. Case studies illustrate the insights into unrest events that are obtained with our methods.",2015,2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)
The linearized alternating direction method of multipliers for sparse group LAD model,"While the least absolute shrinkage and selection operator (LASSO) became a popular method due to its wide applications in high dimensional settings, some generalized LASSO models were developed. The sparse group LASSO is one of the important lasso-type methods, which aims to solve the linear regression problems with grouped covariates and tends to produce a solution with sparse effects both on a group and within group level. At the same time, we know that the least absolute deviation (LAD) is a useful and robust method when the noise distribution may be heavy-tailed or heterogeneous. In this paper, we combine these two classical ideas together to develop sparse group LAD model. We show that the sparse group LAD estimator achieves near oracle performance, i.e., with high probability, the $$L_2$$L2 norm of the estimation error is of order $$O(\sqrt{k\text{ log }p/n}).$$O(klogp/n). Moreover, with the help of the linearization technique we propose the linearized alternating direction method of multipliers to solve the sparse group LAD estimator and establish its convergence. Numerical experiments are reported to illustrate the efficiency of the proposed algorithm.",2019,Optimization Letters
Machine Learning based Predicting House Prices using Regression Techniques,"Predictive models for determining the sale price of houses in cities like Bengaluru is still remaining as more challenging and tricky task. The sale price of properties in cities like Bengaluru depends on a number of interdependent factors. Key factors that might affect the price include area of the property, location of the property and its amenities. In this research work, an analytical study has been carried out by considering the data set that remains open to the public by illustrating the available housing properties in machine hackathon platform. The data set has nine features. In this study, an attempt has been made to construct a predictive model for evaluating the price based on the factors that affect the price. Modeling explorations apply some regression techniques such as multiple linear regression (Least Squares), Lasso and Ridge regression models, support vector regression, and boosting algorithms such as Extreme Gradient Boost Regression (XG Boost). Such models are used to build a predictive model, and to pick the best performing model by performing a comparative analysis on the predictive errors obtained between these models. Here, the attempt is to construct a predictive model for evaluating the price based on factors that affects the price.",2020,2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)
"An evaluation of machine-learning for predicting phenotype: studies in yeast, rice, and wheat","In phenotype prediction the physical characteristics of an organism are predicted from knowledge of its genotype and environment. Such studies, often called genome-wide association studies, are of the highest societal importance, as they are of central importance to medicine, crop-breeding, etc. We investigated three phenotype prediction problems: one simple and clean (yeast), and the other two complex and real-world (rice and wheat). We compared standard machine learning methods; elastic net, ridge regression, lasso regression, random forest, gradient boosting machines (GBM), and support vector machines (SVM), with two state-of-the-art classical statistical genetics methods; genomic BLUP and a two-step sequential method based on linear regression. Additionally, using the clean yeast data, we investigated how performance varied with the complexity of the biological mechanism, the amount of observational noise, the number of examples, the amount of missing data, and the use of different data representations. We found that for almost all the phenotypes considered, standard machine learning methods outperformed the methods from classical statistical genetics. On the yeast problem, the most successful method was GBM, followed by lasso regression, and the two statistical genetics methods; with greater mechanistic complexity GBM was best, while in simpler cases lasso was superior. In the wheat and rice studies the best two methods were SVM and BLUP. The most robust method in the presence of noise, missing data, etc. was random forests. The classical statistical genetics method of genomic BLUP was found to perform well on problems where there was population structure. This suggests that standard machine learning methods need to be refined to include population structure information when this is present. We conclude that the application of machine learning methods to phenotype prediction problems holds great promise, but that determining which methods is likely to perform well on any given problem is elusive and non-trivial.",2019,Machine Learning
