title,abstract,year,journal
Robust Lasso Regression with Student-t Residuals,"The lasso, introduced by Robert Tibshirani in 1996, has become one of the most popular techniques for estimating Gaussian linear regression models. An important reason for this popularity is that the lasso can simultaneously estimate all regression parameters as well as select important variables, yielding accurate regression models that are highly interpretable. This paper derives an efficient procedure for fitting robust linear regression models with the lasso in the case where the residuals are distributed according to a Student-t distribution. In contrast to Gaussian lasso regression, the proposed Student-t lasso regression procedure can be applied to data sets which contain large outlying observations. We demonstrate the utility of our Student-t lasso regression by analysing the Boston housing data set.",2017,
Complexity Selection with Cross-validation for Lasso and Sparse Partial Least Squares Using High-Dimensional Data,"Sparse regression and classification methods are commonly applied to high-dimensional data to simultaneously build a prediction rule and select relevant predictors. The well-known lasso regression and the more recent sparse partial least squares (SPLS) approach are important examples. In such procedures, the number of identified relevant predictors typically depends on a complexity parameter that has to be adequately tuned. Most often, parameter tuning is performed via cross validation (CV). In the context of lasso penalized logistic regression and SPLS classification, this paper addresses three important questions related to complexity selection: (1) Does the number of folds in CV affect the results of the tuning procedure? (2) Should CV be repeated several times to yield less variable tuning results?, and (3) Is complexity selection robust against resampling?",2013,
A Shot Quality Adjusted Plus-Minus for the NHL,"We explore two regression models for creating an adjusted plus-minus statistic for the NHL. We compare an OLS regression models and a penalized gamma-lasso regression model. The traditional plus-minus metric is a simple marginal statistic that allocates a +1 to players for scoring a goal and a -1 for allowing a goal according to whether they were on the ice. This is a very noisy and uninformative statistic since it does not take into account the quality of the other players on the ice with an individual. We build off of previous research to create a more informative statistic that takes into account all of the players on the ice. This previous research has focused on goals to build an adjusted plus-minus, which is information deficient due to the fact that there are only approximately 5 goals scored per game. We improve upon this by instead using shots which provides us with ten times as much information per game. We use shot location data from 2007 to 2013 to create a smoothed probability map for the probability of scoring a goal from all locations in the offensive zone. We then model the shots from 2014-2015 season to get player estimates. Two models are compared, an OLS regression and a penalized regression (lasso). Finally, we compare our adjusted plusminus to the traditional plus-minus and complete a salary analysis to determine if teams are properly valuing players for the quality of shots they are taking and allowing.",2016,
Improved centroids estimation for the nearest shrunken centroid classifier,"MOTIVATION
The nearest shrunken centroid (NSC) method has been successfully applied in many DNA-microarray classification problems. The NSC uses 'shrunken' centroids as prototypes for each class and identifies subsets of genes that best characterize each class. Classification is then made to the nearest (shrunken) centroid. The NSC is very easy to implement and very easy to interpret, however, it has drawbacks.


RESULTS
We show that the NSC method can be interpreted in the framework of LASSO regression. Based on that, we consider two new methods, adaptive L(infinity)-norm penalized NSC (ALP-NSC) and adaptive hierarchically penalized NSC (AHP-NSC), with two different penalty functions for microarray classification, which improve over the NSC. Unlike the L(1)-norm penalty used in LASSO, the penalty terms that we consider make use of the fact that parameters belonging to one gene should be treated as a natural group. Numerical results indicate that the two new methods tend to remove irrelevant genes more effectively and provide better classification results than the L(1)-norm approach.


AVAILABILITY
R code for the ALP-NSC and the AHP-NSC algorithms are available from authors upon request.",2007,Bioinformatics
"Local Minimax Learning of Functions With Best Finite Sample Estimation Error Bounds: Applications to Ridge and Lasso Regression, Boosting, Tree Learning, Kernel Machines, and Inverse Problems","Optimal local estimation is formulated in the minimax sense for inverse problems and nonlinear regression. This theory provides best mean squared finite sample error bounds for some popular statistical learning algorithms and also for several optimal improvements of other existing learning algorithms such as smoothing splines and kernel regularization. The bounds and improved algorithms are not based on asymptotics or Bayesian assumptions and are truly local for each query, not depending on cross validating estimates at other queries to optimize modeling parameters. Results are given for optimal local learning of approximately linear functions with side information (context) using real algebraic geometry. In particular, finite sample error bounds are given for ridge regression and for a local version of lasso regression. The new regression methods require only quadratic programming with linear or quadratic inequality constraints for implementation. Greedy additive expansions are then combined with local minimax learning via a change in metric. An optimal strategy is presented for fusing the local minimax estimators of a class of experts-providing optimal finite sample prediction error bounds from (random) forests. Local minimax learning is extended to kernel machines. Best local prediction error bounds for finite samples are given for Tikhonov regularization. The geometry of reproducing kernel Hilbert space is used to derive improved estimators with finite sample mean squared error (MSE) bounds for class membership probability in two class pattern classification problems. A purely local, cross validation free algorithm is proposed which uses Fisher information with these bounds to determine best local kernel shape in vector machine learning. Finally, a locally quadratic solution to the finite Fourier moments problem is presented. After reading the first three sections the reader may proceed directly to any of the subsequent applications sections.",2009,IEEE Transactions on Information Theory
Lagged kernel machine regression for identifying time windows of susceptibility to exposures of complex mixtures.,"The impact of neurotoxic chemical mixtures on children's health is a critical public health concern. It is well known that during early life, toxic exposures may impact cognitive function during critical time intervals of increased vulnerability, known as windows of susceptibility. Knowledge on time windows of susceptibility can help inform treatment and prevention strategies, as chemical mixtures may affect a developmental process that is operating at a specific life phase. There are several statistical challenges in estimating the health effects of time-varying exposures to multi-pollutant mixtures, such as: multi-collinearity among the exposures both within time points and across time points, and complex exposure-response relationships. To address these concerns, we develop a flexible statistical method, called lagged kernel machine regression (LKMR). LKMR identifies critical exposure windows of chemical mixtures, and accounts for complex non-linear and non-additive effects of the mixture at any given exposure window. Specifically, LKMR estimates how the effects of a mixture of exposures change with the exposure time window using a Bayesian formulation of a grouped, fused lasso penalty within a kernel machine regression (KMR) framework. A simulation study demonstrates the performance of LKMR under realistic exposure-response scenarios, and demonstrates large gains over approaches that consider each time window separately, particularly when serial correlation among the time-varying exposures is high. Furthermore, LKMR demonstrates gains over another approach that inputs all time-specific chemical concentrations together into a single KMR. We apply LKMR to estimate associations between neurodevelopment and metal mixtures in Early Life Exposures in Mexico and Neurotoxicology, a prospective cohort study of child health in Mexico City.",2018,Biostatistics
Dual Extrapolation for Faster Lasso Solvers,"Convex sparsity-inducing regularizations are ubiquitous in high-dimension machine learning, but their non-differentiability requires the use of iterative solvers. To accelerate such solvers, state-of-the-art approaches consist in reducing the size of the optimization problem at hand. In the context of regression, this can be achieved either by discarding irrelevant features (screening techniques) or by prioritizing features likely to be included in the support of the solution (working set techniques). Duality comes into play at several steps in these techniques. Here, we propose an extrapolation technique starting from a sequence of iterates in the dual that leads to the construction of an improved dual point. This enables a tighter control of optimality as used in stopping criterion, as well as better screening performance of Gap Safe rules. Finally, we propose a working set strategy based on an aggressive use of Gap Safe rules and our new dual point construction, which improves state-of-the-art time performance on Lasso problems.",2018,
Leveraging input and output structures for joint mapping of epistatic and marginal eQTLs,"MOTIVATION
As many complex disease and expression phenotypes are the outcome of intricate perturbation of molecular networks underlying gene regulation resulted from interdependent genome variations, association mapping of causal QTLs or expression quantitative trait loci must consider both additive and epistatic effects of multiple candidate genotypes. This problem poses a significant challenge to contemporary genome-wide-association (GWA) mapping technologies because of its computational complexity. Fortunately, a plethora of recent developments in biological network community, especially the availability of genetic interaction networks, make it possible to construct informative priors of complex interactions between genotypes, which can substantially reduce the complexity and increase the statistical power of GWA inference.


RESULTS
In this article, we consider the problem of learning a multitask regression model while taking advantage of the prior information on structures on both the inputs (genetic variations) and outputs (expression levels). We propose a novel regularization scheme over multitask regression called jointly structured input-output lasso based on an â„“(1)/â„“(2) norm, which allows shared sparsity patterns for related inputs and outputs to be optimally estimated. Such patterns capture multiple related single nucleotide polymorphisms (SNPs) that jointly influence multiple-related expression traits. In addition, we generalize this new multitask regression to structurally regularized polynomial regression to detect epistatic interactions with manageable complexity by exploiting the prior knowledge on candidate SNPs for epistatic effects from biological experiments. We demonstrate our method on simulated and yeast eQTL datasets.


AVAILABILITY
Software is available at http://www.sailing.cs.cmu.edu/.",2012,Bioinformatics
Machine learning derived risk prediction of anorexia nervosa,"BackgroundAnorexia nervosa (AN) is a complex psychiatric disease with a moderate to strong genetic contribution. In addition to conventional genome wide association (GWA) studies, researchers have been using machine learning methods in conjunction with genomic data to predict risk of diseases in which genetics play an important role.MethodsIn this study, we collected whole genome genotyping data on 3940 AN cases and 9266 controls from the Genetic Consortium for Anorexia Nervosa (GCAN), the Wellcome Trust Case Control Consortium 3 (WTCCC3), Price Foundation Collaborative Group and the Childrenâ€™s Hospital of Philadelphia (CHOP), and applied machine learning methods for predicting AN disease risk. The prediction performance is measured by area under the receiver operating characteristic curve (AUC), indicating how well the model distinguishes cases from unaffected control subjects.ResultsLogistic regression model with the lasso penalty technique generated an AUC of 0.693, while Support Vector Machines and Gradient Boosted Trees reached AUCâ€™s of 0.691 and 0.623, respectively. Using different sample sizes, our results suggest that larger datasets are required to optimize the machine learning models and achieve higher AUC values.ConclusionsTo our knowledge, this is the first attempt to assess AN risk based on genome wide genotype level data. Future integration of genomic, environmental and family-based information is likely to improve the AN risk evaluation process, eventually benefitting AN patients and families in the clinical setting.",2016,BMC Medical Genomics
Evaluating and Predicting the Probability of Death in Patients with Non-Metastatic Osteosarcoma: A Population-Based Study,"BACKGROUND Osteosarcoma is one of the most common bone tumors, with strong local aggressiveness and early metastasis. The aim of this study was to describe the epidemiological data and evaluate the prognostic factors for overall survival (OS) and cause-specific survival (CSS) in patients with non-metastatic osteosarcoma. MATERIAL AND METHODS Patients histologically diagnosed with non-metastatic osteosarcoma between 2005 and 2014 were selected from the Surveillance, Epidemiology, and End Results (SEER) database. Survival analysis, machine learning, and Lasso regression were used to identify the prognostic factors for OS and CSS, and the accuracy of the nomograms was tested and compared with the American Joint Committee on Cancer (AJCC) staging systems. RESULTS The entire cohort comprised 1000 patients with non-metastatic osteosarcoma. The multivariable analysis suggested that age, tumor size, grade, and American Joint Committee on Cancer (AJCC) T staging were independent prognostic factors for OS and CSS. Additionally, the nomograms based on these results could better predict probability of OS (Internal validation C-index, 0.7095) and CSS (0.7100) compared with the sixth (OS: 0.613; CSS: 0.628) and seventh edition AJCC staging systems (0.602, 0.613). CONCLUSIONS Relatively young age and low histopathological grade were favorable factors for both OS and CSS. Nomograms based on multivariable models worked well in predicting the probability of death for patients with non-metastatic osteosarcoma.",2019,Medical Science Monitor : International Medical Journal of Experimental and Clinical Research
A biological mechanism for Bayesian feature selection: Weight decay and raising the LASSO,"Biological systems are capable of learning that certain stimuli are valuable while ignoring the many that are not, and thus perform feature selection. In machine learning, one effective feature selection approach is the least absolute shrinkage and selection operator (LASSO) form of regularization, which is equivalent to assuming a Laplacian prior distribution on the parameters. We review how such Bayesian priors can be implemented in gradient descent as a form of weight decay, which is a biologically plausible mechanism for Bayesian feature selection. In particular, we describe a new prior that offsets or ""raises"" the Laplacian prior distribution. We evaluate this alongside the Gaussian and Cauchy priors in gradient descent using a generic regression task where there are few relevant and many irrelevant features. We find that raising the Laplacian leads to less prediction error because it is a better model of the underlying distribution. We also consider two biologically relevant online learning tasks, one synthetic and one modeled after the perceptual expertise task of Krigolson et al. (2009). Here, raising the Laplacian prior avoids the fast erosion of relevant parameters over the period following training because it only allows small weights to decay. This better matches the limited loss of association seen between days in the human data of the perceptual expertise task. Raising the Laplacian prior thus results in a biologically plausible form of Bayesian feature selection that is effective in biologically relevant contexts.",2015,Neural networks : the official journal of the International Neural Network Society
Bootstrapping LASSO-type estimators in regression models,"Abstract We study the consistency of the standard (non-parametric) bootstrap, the m -out-of- n bootstrap, and the oracle bootstrap distributions of some popular LASSO-type estimators in regression models with random predictors. These estimators have an oracle property and are often used in estimation of sparse regression models. A local asymptotic analysis further reveals the behavior of these estimators and of their bootstrap distributions when some regression coefficients approach zero at various rates. In a simulation study, we assess the finite sample properties of the estimators and of their bootstrap distributions for various sample sizes and model parameters. The analysis of a prostate cancer data set shows an application of LASSO-type inference and bootstrap methods in practice.",2019,Journal of Statistical Planning and Inference
2 Model and Methods 2 . 1 Spatial Regression with GIS Layers,"Geographic information systems (GIS) organize spatial data in multiple two-dimensional arrays called layers. In many applications, a response of interest is observed on a set of sites in the landscape, and it is of interest to build a regression model from the GIS layers to predict the response at unsampled sites. Model selection in this context then consists not only of selecting appropriate layers, but also of choosing appropriate neighborhoods within those layers. We formalize this problem and propose the use of Lasso to simultaneously select variables, choose neighborhoods, and estimate parameters. Spatial smoothness in selected coefficients is incorporated through use of a priori spatial covariance structure, and this leads to a modification of the Lasso procedure. The LARS algorithm, which can be used in a fast implementation of Lasso, is also modified to yield a fast implementation of spatial Lasso. The spatial Lasso performs well in numerical examples, including an application to prediction of soil moisture.",2006,
A Delta-radiomics model for preoperative evaluation of Neoadjuvant chemotherapy response in high-grade osteosarcoma,"The difficulty of assessment of neoadjuvant chemotherapeutic response preoperatively may hinder personalized-medicine strategies that depend on the results from pathological examination. A total of 191 patients with high-grade osteosarcoma (HOS) were enrolled retrospectively from November 2013 to November 2017 and received neoadjuvant chemotherapy (NCT). A cutoff time of November 2016 was used to divide the training set and validation set. All patients underwent diagnostic CTs before and after chemotherapy. By quantifying the tumor regions on the CT images before and after NCT, 540 delta-radiomic features were calculated. The interclass correlation coefficients for segmentations of inter/intra-observers and feature pair-wise correlation coefficients (Pearson) were used for robust feature selection. A delta-radiomics signature was constructed using the lasso algorithm based on the training set. Radiomics signatures built from single-phase CT were constructed for comparison purpose. A radiomics nomogram was then developed from the multivariate logistic regression model by combining independent clinical factors and the delta-radiomics signature. The prediction performance was assessed using area under the ROC curve (AUC), calibration curves and decision curve analysis (DCA). The delta-radiomics signature showed higher AUC than single-CT based radiomics signatures in both training and validation cohorts. The delta-radiomics signature, consisting of 8 selected features, showed significant differences between the pathologic good response (pGR) (necrosis fraction â‰¥90%) group and the non-pGR (necrosis fraction <â€‰90%) group (Pâ€‰<â€‰0.0001, in both training and validation sets). The delta-radiomics nomogram, which consisted of the delta-radiomics signature and new pulmonary metastasis during chemotherapy showed good calibration and great discrimination capacity with AUC 0.871 (95% CI, 0.804 to 0.923) in the training cohort, and 0.843 (95% CI, 0.718 to 0.927) in the validation cohort. The DCA confirmed the clinical utility of the radiomics model. The delta-radiomics nomogram incorporating the radiomics signature and clinical factors in this study could be used for individualized pathologic response evaluation after chemotherapy preoperatively and help tailor appropriate chemotherapy and further treatment plans.",2020,Cancer Imaging
Studying the Impact of Water Supply on Wheat Yield by using Principle Lasso Radial Machine Learning Model,"Wheat plays a vital role in the food production as it fulfills 60% requirements of calories and proteins to the 35% of the world population. Owing to wheat importance in food, wheat demand is increasing continuously. Wheat yield is committed to the availability of water supply. Due to climatic and environmental variations of different countries, water supply is not available in constant and desire quantity that is necessary for better wheat yield. So, there is a strong relationship and dependency that exists between water supply and wheat yield. Therefore, water supply is becoming an issue because it directly effects wheat yield. In this research, a Principle Lasso Radial (PLR) model is proposed using Machine Learning technique to measure the effect of water supply on wheat yield. In this Principle Lasso Radial (PLR) model, various experiments are conducted with respect to the performance metrics, i.e. relative water contents, waxiness, grain per spike and plant height. Principle Lasso Radial (PLR) modelâ€™s produced reduced dimensional data with respect to performance metrics. That data is provided to Radial Basis Neural Network (RBNN), and it showed regression values R under different water supply conditions. Principle Lasso Radial (PLR) model achieved an accuracy of 89% among variance Machine Learning techniques.",2018,International Journal of Advanced Computer Science and Applications
Sparse group variable selection based on quantile hierarchical Lasso,"The group Lasso is a penalized regression method, used in regression problems where the covariates are partitioned into groups to promote sparsity at the group level [27]. Quantile group Lasso, a natural extension of quantile Lasso [25], is a good alternative when the data has group information and has many outliers and/or heavy tails. How to discover important features that are correlated with interest of outcomes and immune to outliers has been paid much attention. In many applications, however, we may also want to keep the flexibility of selecting variables within a group. In this paper, we develop a sparse group variable selection based on quantile methods which select important covariates at both the group level and within the group level, which penalizes the empirical check loss function by the sum of square root group-wise L1-norm penalties. The oracle properties are established where the number of parameters diverges. We also apply our new method to varying coefficient model with categorial effect modifiers. Simulations and real data example show that the newly proposed method has robust and superior performance.",2014,Journal of Applied Statistics
Spectral Dynamic Causal Modelling of Resting-State fMRI: Relating Effective Brain Connectivity in the Default Mode Network to Genetics,"We conduct a novel imaging genetics study with the goal of examining how effective brain connectivity is related to genetics within the context of dementia. Our study develops an analysis examining a sample obtained from the Alzheimer's Disease Neuroimaging Initiative with resting-state fMRI (rs-fMRI) and genetic data obtained from 112 subjects, where each subject is classified as either cognitively normal (CN), as having mild cognitive impairment (MCI), or as having Alzheimer's Disease (AD). A Dynamic Causal Model (DCM) is fit to the rs-fMRI time series in the spectral domain (spectral DCM) in order to estimate a directed network representing effective brain connectivity within the default mode network (DMN), a key network commonly known to be active when the brain is at rest. These networks are then used as a phenotype and related to a set of genetic markers potentially related to disease using the Bayes factor, where the set of markers is selected based on a genome-wide association study. Our exploratory analysis reveals a potential path of aligned connections within the network being studied forming a path from the medial prefrontal cortex to the right intraparietal cortex through the left right intraparietal cortex that is potentially associated with a genetic signal from chromosome 11. In a separate analysis examining the influence of genetics on disease, this same genetic signal is selected as potentially associated with the probability of Alzheimer's Disease using LASSO penalized multinomial logistic regression. Our analysis serves to motivate a number of further studies with the goal of replicating our findings in a larger sample size and with the goal of expanding the network of brain regions included in the network.",2019,arXiv: Neurons and Cognition
Functional Linear Models for Brain Data,"Background. Modern neuroimaging data has provided a much needed window into the intricacies of the human brain. Neuroimaging techniques such as functional magnetic resonance imaging (fMRI), magnetoencephalography (MEG), and diffusion tensor imaging (DTI), often contain many thousands of functional observations per subject. While some success has been had using heuristical summary statistics of neuroimaging functional covariates to build predictive models, there is a lack of a flexible and principled framework to build models from neuroimaging techniques. Aim. Our aim is to develop a general, principled framework for supervised learning that scales to many thousands of neuroimaging functional covariates per subject without resorting to heuristical summary statistics. In particular, we look to more accurately regress a subjectâ€™s age given neuroimaging data through the use of functional covariates than previous approaches that considered only summary statistics. Data. Diffusion magnetic resonance (MR) images were acquired from a total of 90 subjects. The subjects ranged in age from 13 to 60 years old, and included 45 males and 45 females. The subjects had no known history of neurological or mental disorder. We used per-voxel functional covariates of diffusion orientation distribution functions (dODFs) in our models and real-valued fractional anisotropy (FA) summary statistic covariates as a baseline. dODFs are functions that represent the amount of water molecules, or spins, undergoing diffusion in different orientations over the S sphere. FA values are the peak of the dODF and have previously been used as a summary statistic of dODFs for age regression. In total, 25K voxels were considered in a shared template-space. Methods. We develop and empirically test a linear functional model for neuroimaging data. We use a model that represents neuroimaging functional observations nonparametrically using orthonormal basis projections. The age response is modelled as a sparse additive linear combination of inner products. We show that our model may be optimized using a group-LASSO approach. Results. Our functional sparse linear model was able to predict age with a 29.15% lower mean squared error (MSE) than previous heuristic-based methods that used summary statistics. Our approach yielded an MSE of 58.49. Results were found to be statistically significant with a pvalue of 0.04 using a paired t-test. Conclusions. In this work we have developed and tested a principled framework for building predictive supervised models with functional neuroimaging data. This framework allows one to use functional neuro-data in a statistically principled fashion without resorting to heuristical summary statistics.",2016,
Communication-efficient Sparse Regression,"We devise a communication-efficient approach to distributed sparse regression in the high-dimensional setting. The key idea is to average ""debiased"" or ""desparsified"" lasso estimators. We show the approach converges at the same rate as the lasso as long as the dataset is not split across too many machines, and consistently estimates the support under weaker conditions than the lasso. On the computational side, we propose a new parallel and computationally-efficient algorithm to compute the approximate inverse covariance required in the debiasing approach, when the dataset is split across samples. We further extend the approach to generalized linear models.",2017,J. Mach. Learn. Res.
Group Lasso for Functional Logistic Regression,"The principal component analysis allows for removal of redundant information on a univariate basis. There is also a need to select only those predictors which provide relevant information to the model. We will select a subset of variables with the use of the group lasso for logistic regression developed by Meier, et al (2008). â€¢A hybrid L1 and L2 variable selection technique that will shrink entire groups of variables to zero â€¢Each of the M sets of basis coefficients is a group â€¢Exclusion from model: a set of basis coefficients is identically zero â€¢ Inclusion in model: a set of basis coefficients is all nonzero",2013,
"LASSO, Iterative Feature Selection and the Correlation Selector: Oracle Inequalities and Numerical Performances","We propose a general family of algorithms for regression estimation with quadratic loss. Our algorithms are able to select relevant functions into a large dictionary. We prove that a lot of algorithms that have already been studied for this task (LASSO and Group LASSO, Dantzig selector, Iterative Feature Selection, among others) belong to our family, and exhibit another particular member of this family that we call Correlation Selector in this paper. Using general properties of our family of algorithm we prove oracle inequalities for IFS, for the LASSO and for the Correlation Selector, and compare numerical performances of these estimators on a toy example.",2007,arXiv: Statistics Theory
Multivariate rational regression and its application in semiconductor device modeling,"Physics equation-based semiconductor device modeling is accurate but time and money consuming. The need for studying new material and devices is increasing so that there has to be an efficient and accurate device modeling method. In this paper, two methods based on multivariate rational regression (MRR) for device modeling are proposed. They are single-pole MRR and double-pole MRR. The two MRR methods are proved to be powerful in nonlinear curve fitting and have good numerical stability. Two methods are compared with OLS and LASSO by fitting the SMIC 40 nm MOS-FET Iâ€“V characteristic curve and the normalized mean square error of Single-pole MRR is \begin{document}$3.02 \times {10^{{\rm{ - }}8}}$\end{document} which is 4 magnitudes less than an ordinary least square. The Iâ€“V characteristics of CNT-FET and performance indicators (noise factor, gain, power) of a low noise amplifier are also modeled by using MRR methods. The results show MRR methods are very powerful methods for semiconductor device modeling and have a strong nonlinear curve fitting ability.",2018,Journal of Semiconductors
Covariance selection and estimation via penalised normal likelihood,"We propose a nonparametric method to identify parsimony and to produce a statistically efficient estimator of a large covariance matrix. We reparameterise a covariance matrix through the modified Cholesky decomposition of its inverse or the one-step-ahead predictive representation of the vector of responses and reduce the nonintuitive task of modelling covariance matrices to the familiar task of model selection and estimation for a sequence of regression models. The Cholesky factor containing these regression coefficients is likely to have many off-diagonal elements that are zero or close to zero. Penalised normal likelihoods in this situation with L1 and L2 penalties are shown to be closely related to Tibshiraniâ€™s (1996) LASSO approach and to ridge regression. Adding either penalty to the likelihood helps to produce more stable estimators by introducing shrinkage to the elements in the Cholesky factor, while, because of its singularity, the L1 penalty will set some elements to zero and produce interpretable models. An algorithm is developed to compute the estimator and select the tuning parameter. The proposed maximum penalised likelihood estimator is illustrated using simulation and a real dataset involving estimation of a 102 Ã— 102 covariance matrix.",2005,
L-RBF: A Customer Churn Prediction Model Based on Lasso + RBF,"With the development of market economic, customer churn prediction play a critical role in the company management. How-ever, customer information is complex, it contains multi-dimensional features. What's worse, the number of customer churn very small among the whole consumers, and the features of customer are dynamically changing, which is challenging for traditional statistical methods. Fortunately, as the rise of edge computing, more computing related to data-intensive applications will be de-centralized to edge smart terminals. Moreover, edge computing focuses on real-time, short-cycle analysis, which is useful for dealing with dynamic changes problems in customer features. Therefore, to address these issues about customer messages, this paper proposes a simple and effective model to predictive customer churn with a higher accuracy, named L-RBF. The basic idea is to utilize Lasso Regression algorithm (Lasso) for optimizing Radial Basis Function Neural Network (RBF). At first, placing customer features on edge terminals, and Lasso is utilized to extract the correlated features of customer churn. Then, according to the correlated features and lasso regression equation, we can automatically set the topology and parameter information of RBF. Finally, experimental results indicate that L-RBF has a higher recall rate and stronger prediction classification ability compared with the previous work, included Logistic Regression (Log-R), RBF and Boosting.",2019,"2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)"
Predicting hypoxia status using a combination of contrast-enhanced computed tomography and [18F]-Fluorodeoxyglucose positron emission tomography radiomics features.,"BACKGROUND AND PURPOSE
Hypoxia is a known prognostic factor in head and neck cancer. Hypoxia imaging PET radiotracers such as 18F-FMISO are promising but not widely available. The aim of this study was therefore to design a surrogate for 18F-FMISO TBRmax based on 18F-FDG PET and contrast-enhanced CT radiomics features, and to study its performance in the context of hypoxia-based patient stratification.


METHODS
121 lesions from 75 head and neck cancer patients were used in the analysis. Patients received pre-treatment 18F-FDG and 18F-FMISO PET/CT scans. 79 lesions were used to train a cross-validated LASSO regression model based on radiomics features, while the remaining 42 were held out as an internal test subset.


RESULTS
In the training subset, the highest AUC (0.873Â±0.008) was obtained from a signature combining CT and 18F-FDG PET features. The best performance on the unseen test subset was also obtained from the combined signature, with an AUC of 0.833, while the model based on the 90th percentile of 18F-FDG uptake had a test AUC of 0.756.


CONCLUSION
A radiomics signature built from 18F-FDG PET and contrast-enhanced CT features correlates with 18F-FMISO TBRmax in head and neck cancer patients, providing significantly better performance with respect to models based on 18F-FDG PET only. Such a biomarker could potentially be useful to personalize head and neck cancer treatment at centers for which dedicated hypoxia imaging PET radiotracers are unavailable.",2018,Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology
"Risk factors for acute human brucellosis in Ijara, north-eastern Kenya","Brucellosis is an important zoonotic disease globally, with particularly high burdens in pastoral settings. While the zoonotic transmission routes for Brucella spp. are well known, the relative importance of animal contact, food-handling and consumption practices can vary. Understanding the local epidemiology of human brucellosis is important for directing veterinary and public health interventions, as well as for informing clinical diagnostic decision making. We conducted a cross-sectional study in Ijara District Hospital, north-eastern Kenya. A total of 386 individuals seeking care and reporting symptoms of febrile illness were recruited in 2011. Samples were tested for the presence of Brucella spp. using a real-time PCR (RT-PCR) and results compared to those from the test for brucellosis used at Ijara District Hospital, the febrile Brucella plate agglutination test (FBAT). A questionnaire was administered to all participants and risk factors for brucellosis identified using logistic regression with an information theoretic (IT) approach and least absolute shrinkage and selection (LASSO). Sixty individuals were RT-PCR positive, resulting in a prevalence of probable brucellosis of 15.4% (95% CI 12.0-19.5). The IT and LASSO approaches both identified consuming purchased milk as strongly associated with elevated risk and boiling milk before consumption strongly associated with reduced risk. There was no evidence that livestock keepers were at different risk of brucellosis than non-livestock keepers. The FBAT had poor diagnostic performance when compared to RT-PCR, with an estimated sensitivity of 36.6% (95% CI 24.6-50.1) and specificity of 69.3% (95% CI 64.0-74.3). Brucellosis is an important cause of febrile illness in north-eastern Kenya. Promotion of pasteurisation of milk in the marketing chain and health messages encouraging the boiling of raw milk before consumption could be expected to lead to large reductions in the incidence of brucellosis in Ijara. This study supports the growing evidence that the FBAT performs very poorly in the diagnosis of brucellosis.",2020,PLoS Neglected Tropical Diseases
Constrained Sparse Functional Connectivity Networks for MCI Classification,"Mild cognitive impairment (MCI) is difficult to diagnose due to its subtlety. Recent emergence of advanced network analysis techniques utilizing resting-state functional Magnetic Resonance Imaging (rs-fMRI) has made the understanding of neurological disorders more comprehensively at a whole-brain connectivity level. However, inferring effective brain connectivity from fMRI data is a challenging task, particularly when the ultimate goal is to obtain good control-patient classification performance. Incorporating sparsity into connectivity modeling can potentially produce results that are biologically more meaningful since most biologically networks are formed by a relatively few number of connections. However, this constraint, when applied at an individual level, will degrade classification performance due to inter-subject variability. To address this problem, we consider a constrained sparse linear regression model associated with the least absolute shrinkage and selection operator (LASSO). Specifically, we introduced sparsity into brain connectivity via l1-norm penalization, and ensured consistent non-zero connections across subjects via l2-norm penalization. Our results demonstrate that the constrained sparse network gives better classification performance than the conventional correlation-based network, indicating its greater sensitivity to early stage brain pathologies.",2012,Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention
Humour and dystopia: the comedy of entropy in Saramago and Ballard,"Se le maggiori distopie del Novecento sono tetri incubi dâ€™ordine, dâ€™implacabili meccanismi repressivi nelle mani di oligarchie dispotiche, la fine del secolo, e ancor piu lâ€™inizio del Ventunesimo, vedono il prevalere di apocalittiche visioni di entropia politico-sociale e collasso morale, capaci di portare non solo a unâ€™assurda sofferenza universale, ma finanche allâ€™estinzione della stessa vita sul pianeta. Colpisce come al mutare della forma si accompagni anche un cambiamento di tono, con lâ€™affiorare di un umorismo nero che tradisce il senso di impotenza di fronte a un deragliamento che pare connaturato allâ€™essere umano, e che sul piano della retorica si esprime (anche) nel recupero ironico di modalita di narrazione anacronistiche e in parodie serie di testi fondativi della cultura occidentale. Lâ€™articolo esplora, confronta e discute le diverse strategie retoriche e umoristiche impiegate da Jose Saramago in Ensaio sobre aÂ  cegueira (1995) e J.G. Ballard in High Rise (1975) per ritrarre scene ugualmente deprimenti di regressione alla barbarie, mettendo in evidenza la natura profondamente divergente della loro prospettiva.",2016,Between
Evaluation of logistic Bayesian LASSO for identifying association with rare haplotypes,"It has been hypothesized that rare variants may hold the key to unraveling the genetic transmission mechanism of many common complex traits. Currently, there is a dearth of statistical methods that are powerful enough to detect association with rare haplotypes. One of the recently proposed methods is logistic Bayesian LASSO for case-control data. By penalizing the regression coefficients through appropriate priors, logistic Bayesian LASSO weeds out the unassociated haplotypes, making it possible for the associated rare haplotypes to be detected with higher powers. We used the Genetic Analysis Workshop 18 simulated data to evaluate the behavior of logistic Bayesian LASSO in terms of its power and type I error under a complex disease model. We obtained knowledge of the simulation model, including the locations of the functional variants, and we chose to focus on two genomic regions in the MAP4 gene on chromosome 3. The sample size was 142 individuals and there were 200 replicates.Despite the small sample size, logistic Bayesian LASSO showed high power to detect two haplotypes containing functional variants in these regions while maintaining low type I errors. At the same time, a commonly used approach for haplotype association implemented in the software hapassoc failed to converge because of the presence of rare haplotypes. Thus, we conclude that logistic Bayesian LASSO can play an important role in the search for rare haplotypes.",2014,BMC Proceedings
A U-statistic estimator for the variance of resampling-based error estimators,"We revisit resampling procedures for error estimation in binary classification in terms of U-statistics. In particular, we exploit the fact that the error rate estimator involving all learning-testing splits is a U-statistic. Therefore, several standard theorems on properties of U-statistics apply. 
In particular, it has minimal variance among all unbiased estimators and is asymptotically normally distributed. Moreover, there is an unbiased estimator for this minimal variance if the total sample size is at least the double learning set size plus two. In this case, we exhibit such an estimator which is another U-statistic. It enjoys, again, various optimality properties and yields an asymptotically exact hypothesis test of the equality of error rates when two learning algorithms are compared. Our statements apply to any deterministic learning algorithms under weak non-degeneracy assumptions. 
In an application to tuning parameter choice in lasso regression on a gene expression data set, the test does not reject the null hypothesis of equal rates between two different parameters.",2013,arXiv: Statistics Theory
"Predictors of weight loss after bariatric surgeryâ€”a cross-disciplinary approach combining physiological, social, and psychological measures","Bariatric surgery leads to a substantial weight loss (WL), however, a subset of patients undergoing surgery fails to achieve adequate WL. The reason for the individual variation in WL remains unexplained. Using an exploratory cross-disciplinary approach, we aimed to identify preoperative and early postoperative factors explaining the variation in WL after bariatric surgery. Sixty-one subjects were recruited. Eighteen subjects did not receive surgery and three subjects dropped out, leaving a total sample of 40 subjects. Physiological, social, and psychological data were collected before and 6 months after surgery. All variables were analyzed in combination using a least absolute shrinkage and selection operator (LASSO) regression to explain the variation in WL 18 months after Roux-en-Y gastric bypass (nâ€‰=â€‰30) and sleeve gastrectomy (nâ€‰=â€‰10). Mean WL was 31% (range: 10â€“52%). The following preoperative factors predicted 59% of the variation in WL: type of surgery (14%), diabetes status (12%), economic resources (9%), sex (7%), binge eating disorder (7%), degree of depression (5%), household type (3%), and physical activity (1%). Including information on early responses after surgery increased the ability to predict WL to 78% and was explained by early WL (47%), changes in energy density of food consumed from a buffet meal (9%), changes in glicentin (5%), degree of depression (5%), sex (5%), type of surgery (2%), economic resources (2%), and changes in drive for thinness (1%). Using a cross-disciplinary approach, a substantial part of the individual variation in WL was explained by a combination of basic patient characteristics, psychological profile, and social conditions as well as physiological, psychological and behavioral responses to surgery. These results suggest that patient characteristics collected in a cross-disciplinary approach may help determine predictors for less successful WL after bariatric surgery. If verified in larger cohorts this may form the basis for individualized postoperative support to optimize WL outcome.",2020,International Journal of Obesity
SeleÃ§Ã£o de modelos multinÃ­veis para dados de avaliaÃ§Ã£o educacional,"COELHO, F. R. Selection of multilevel models for educational evaluation data. 2017. 173 p. DissertaÃ§Ã£o (Mestrado em EstatÃ­stica â€“ Programa Interinstitucional de PÃ³s-GraduaÃ§Ã£o em EstatÃ­stica) â€“ Instituto de CiÃªncias MatemÃ¡ticas e de ComputaÃ§Ã£o, Universidade de SÃ£o Paulo, SÃ£o Carlos â€“ SP, 2017. When a dataset contains a hierarchical data structure, a possible approach is the multilevel regression modelling, which is justified by the significative amout of the data variability that can be explained by macro level processes. In this work, a selection of multilevel regression models for educational data is developed. This analysis is divided into two parts: variable selection and model selection. The latter is subdivided into two categories: classical and Bayesian modeling. Traditional criteria for model selection such as Lasso, AIC, BIC, and WAIC, among others are used in this study as an attempt to identify the factors influencing ninth grade studentsâ€™ performance in Mathematics of elementary education in the State of SÃ£o Paulo. Likewise, an investigation was conducted to evaluate the performance of each variable selection criteria and model selection methods applied to fitted models that will be mentioned throughout this work. It was possible to conclude that, under the frequentist approach, BIC is the most efficient, whereas under the bayesian approach, WAIC presented better results. Using Lasso under the frequentist approach, a decrease of 34% on the number of predictors was observed. Finally, we identified that the performance in Mathematics of students in the ninth year of elementary school in the state of SÃ£o Paulo is most influenced by the following covariates: motherâ€™s educational level, frequency of book reading, time spent with recreation in classroom, the fact of liking Math, school global performance in Mathematics, performance in Portuguese, school administrative dependence, gender, fatherâ€™s educational degree, failures and age-grade distortion.",2017,
Variable Selection in Nonparametric and Semiparametric Regression Models,"This chapter reviews the literature on variable selection in nonparametric and semiparametric regression models via shrinkage. We highlight recent developments on simultaneous variable selection and estimation through the methods of least absolute shrinkage and selection operator (Lasso), smoothly clipped absolute deviation (SCAD) or their variants, but restrict our attention to nonparametric and semiparametric regression models. In particular, we consider variable selection in additive models, partially linear models, functional/varying coefficient models, single index models, general nonparametric regression models, and semiparametric/nonparametric quantile regression models. JEL Classifications: C14, C52",2014,
On the sign recovery given by the thresholded LASSO and thresholded Basis Pursuit,"We consider the regression model, when the number of observations is smaller than the number of explicative variables. It is well known that the popular Least Absolute Shrinkage and Selection Operator (LASSO) can recover the sign of regression coefficients only if a very stringent irrepresentable condition is satisfied. In this article, in a first step, we provide a new result about the irrepresentable condition: the probability to recover the sign with LASSO is smaller than 1/2 once the irrepresentable condition does not hold. Next, we revisit properties of thresholded LASSO and provide new theoretical results in the asymptotic setup under which the design matrix is fixed and the magnitudes of nonzero regression coefficients tend to infinity. Apart from LASSO, our results cover also basis pursuit, which can be thought of as a limiting case of LASSO when the tuning parameter tends to 0. Compared to the classical asymptotics, our approach allows for reduction of the technical burden. We formulate an easy identifiability condition which turns out to be sufficient and necessary for thresholded LASSO to recover the sign of the sufficiently large signal. Our simulation study illustrates the difference between the irrepresentable and the identifiability condition. Interestingly, while irrepresentable condition becomes more difficult to be satisfied for strongly correlated designs, it does not seem to be true for identifiability condition. Actually, when the correlations are positive and the nonzero coefficients are of the same sign, the identifiability condition allows the number of nonzero coefficients to be larger than in case where the regressors are independent.",2018,arXiv: Methodology
A Hierarchical Integrative Group LASSO (HiGLASSO) Framework for Analyzing Environmental Mixtures,"Environmental health studies are increasingly measuring multiple pollutants to characterize the joint health effects attributable to exposure mixtures. However, the underlying dose-response relationship between toxicants and health outcomes of interest may be highly nonlinear, with possible nonlinear interaction effects. Existing penalized regression methods that account for exposure interactions either cannot accommodate nonlinear interactions while maintaining strong heredity or are computationally unstable in applications with limited sample size. In this paper, we propose a general shrinkage and selection framework to identify noteworthy nonlinear main and interaction effects among a set of exposures. We design hierarchical integrative group LASSO (HiGLASSO) to (a) impose strong heredity constraints on two-way interaction effects (hierarchical), (b) incorporate adaptive weights without necessitating initial coefficient estimates (integrative), and (c) induce sparsity for variable selection while respecting group structure (group LASSO). We prove sparsistency of the proposed method and apply HiGLASSO to an environmental toxicants dataset from the LIFECODES birth cohort, where the investigators are interested in understanding the joint effects of 21 urinary toxicant biomarkers on urinary 8-isoprostane, a measure of oxidative stress. An implementation of HiGLASSO is available in the higlasso R package, accessible through the Comprehensive R Archive Network.",2020,arXiv: Methodology
A safe reinforced feature screening strategy for lasso based on feasible solutions,"Abstract As a popular method in machine learning, lasso performs regression and feature selection simultaneously. However, for large datasets, the training efficiency of lasso remains a challenge. Recently, an Enhanced screening rule via Dual Polytope Projection (EDPP) was proposed to substantially reduce the scale of lasso by deleting inactive features beforehand. However, EDPP may mistakenly discard active features in practice due to the unavailable optimal solutions. To solve this problem, a safe reinforced feature screening rule based on EDPP and feasible solutions (S-EDPP) is introduced in this paper. By utilizing feasible solutions and estimating a proper upper bound of the deviation, S-EDPP can be guaranteed to be safe both in theory and in practice. Theoretical analysis of the deviation term in S-EDPP is given to verify its efficiency. Furthermore, S-EDPP is also extended to accelerate the Elastic Net, which is a corrective method of lasso. Experiments on synthetic and real datasets verify that S-EDPP is a safe modification of EDPP and it gives superior performance than other existing safe rules.",2019,Inf. Sci.
