title,abstract,year,journal
Sparsity-based approaches for damage detection in plates,"Abstract The data deluge in Structural Health Monitoring (SHM) and the need for automated online damage detection systems necessitates a move away from traditional model-based approaches. To that end, we propose sparsity-based algorithms for damage detection in plates. Instead of high-fidelity models, our proposed algorithms use dictionaries, consisting of response signals acquired directly from the system of interest, as the key feature to both detect and localize damages. We address the damage detection problem both when the damage is located on or off a grid of possible damage coordinates defined by the dictionary. This gives rise to two classes of problems, namely, on the grid and off the grid problems. In our sparsity-based on the grid damage detection (SDD-ON) platform, we solve a LASSO regression problem, where, the unknown vector is a pointer for existence of damage at the various locations defined on the grid used for dictionary construction. In our proposed off the grid damage detection (SDD-OFF) platform, we use a penalized regression algorithm to extend the dictionary of measured damage signals to points off-the-grid by linear interpolation. We evaluate the performance of both SDD frameworks, in detecting damages on plates, using finite element simulations as well as laboratory experiments involving a pitch-catch setup using a single actuator-sensor pair. Our results suggest that the proposed algorithms perform damage detection in plates efficiently. We obtain area under receiver operating characteristic (ROC) curves of 0.997 and 0.8314 for SDD-ON and SDD-OFF, respectively.",2019,Mechanical Systems and Signal Processing
Combining Value-at-Risk forecasts using penalized quantile regressions,"Penalized quantile regressions are proposed for the combination of Value-at-Risk forecasts. The primary reason for regularization of the quantile regression estimator with the elastic net, lasso and ridge penalties is multicollinearity among the standalone forecasts, which results in poor forecast performance of the non-regularized estimator due to unstable combination weights. This new approach is applied to combining the Value-at-Risk forecasts of a wide range of frequently used risk models for stocks comprising the Dow Jones Industrial Average Index. Within a thorough comparison analysis, the penalized quantile regressions perform better in terms of backtesting and tick losses than the standalone models and several competing forecast combination approaches. This is particularly evident during the global financial crisis of 2007â€“2008.",2017,Econometrics and Statistics
A learning-based CT prostate segmentation method via joint transductive feature selection and regression,"In1 recent years, there has been a great interest in prostate segmentation, which is a important and challenging task for CT image guided radiotherapy. In this paper, a learning-based segmentation method via joint transductive feature selection and transductive regression is presented, which incorporates the physician's simple manual specification (only taking a few seconds), to aid accurate segmentation, especially for the case with large irregular prostate motion. More specifically, for the current treatment image, experienced physician is first allowed to manually assign the labels for a small subset of prostate and non-prostate voxels, especially in the first and last slices of the prostate regions. Then, the proposed method follows the two step: in prostate-likelihood estimation step, two novel algorithms: tLasso and wLapRLS, will be sequentially employed for transductive feature selection and transductive regression, respectively, aiming to generate the prostate-likelihood map. In multi-atlases based label fusion step, the final segmentation result will be obtained according to the corresponding prostate-likelihood map and the previous images of the same patient. The proposed method has been substantially evaluated on a real prostate CT dataset including 24 patients with 330 CT images, and compared with several state-of-the-art methods. Experimental results show that the proposed method outperforms the state-of-the-arts in terms of higher Dice ratio, higher true positive fraction, and lower centroid distances. Also, the results demonstrate that simple manual specification can help improve the segmentation performance, which is clinically feasible in real practice.",2016,Neurocomputing
Variable Selection in the Chlamydia Pneumoniae Lung Infection Study,"In this study, the data based on nucleic acid amplication tech- niques (Polymerase chain reaction) consisting of 23 dierent transcript vari- ables which are involved to investigate genetic mechanism regulating chlamy- dial infection disease by measuring two dierent outcomes of muring C. pneumonia lung infection (disease expressed as lung weight increase and C. pneumonia load in the lung), have been analyzed. A model with fewer reduced transcript variables of interests at early infection stage has been obtained by using some of the traditional (stepwise regression, partial least squares regression (PLS)) and modern variable selection methods (least ab- solute shrinkage and selection operator (LASSO), forward stagewise regres- sion and least angle regression (LARS)). Through these variable selection methods, the variables of interest are selected to investigate the genetic mechanisms that determine the outcomes of chlamydial lung infection. The transcript variables Tim3, GATA3, Lacf, Arg2 (X4, X5, X8 and X13) are being detected as the main variables of interest to study the C. pneumonia disease (lung weight increase) or C. pneumonia lung load outcomes. Models including these key variables may provide possible answers to the problem of molecular mechanisms of chlamydial pathogenesis.",2013,
Identification of a metabolic gene panel to predict the prognosis of myelodysplastic syndrome.,"Myelodysplastic syndrome (MDS) is clonal disease featured by ineffective haematopoiesis and potential progression into acute myeloid leukaemia (AML). At present, the risk stratification and prognosis of MDS need to be further optimized. A prognostic model was constructed by the least absolute shrinkage and selection operator (LASSO) regression analysis for MDS patients based on the identified metabolic gene panel in training cohort, followed by external validation in an independent cohort. The patients with lower risk had better prognosis than patients with higher risk. The constructed model was verified as an independent prognostic factor for MDS patients with hazard ratios of 3.721 (1.814-7.630) and 2.047 (1.013-4.138) in the training cohort and validation cohort, respectively. The AUC of 3-year overall survival was 0.846 and 0.743 in the training cohort and validation cohort, respectively. The high-risk score was significantly related to other clinical prognostic characteristics, including higher bone marrow blast cells and lower absolute neutrophil count. Moreover, gene set enrichment analyses (GSEA) showed several significantly enriched pathways, with potential indication of the pathogenesis. In this study, we identified a novel stable metabolic panel, which might not only reveal the dysregulated metabolic microenvironment, but can be used to predict the prognosis of MDS.",2020,Journal of cellular and molecular medicine
Cluster feature selection in high-dimensional linear models,"This paper concerns with variable screening when highly correlated variables exist in high-dimensional linear models. We propose a novel cluster feature selection (CFS) procedure based on the elastic net and linear correlation variable screening to enjoy the benefits of the two methods. When calculating the correlation between the predictor and the response, we consider highly correlated groups of predictors instead of the individual ones. This is in contrast to the usual linear correlation variable screening. Within each correlated group, we apply the elastic net to select variables and estimate their parameters. This avoids the drawback of mistakenly eliminating true relevant variables when they are highly correlated like LASSO [R. Tibshirani, Regression shrinkage and selection via the lasso, J. R. Stat. Soc. Ser. B 58 (1996) 268â€“288] does. After applying the CFS procedure, the maximum absolute correlation coefficient between clusters becomes smaller and any common model selection methods like sure independence screening (SIS) [J. Fan and J. Lv, Sure independence screening for ultrahigh dimensional feature space, J. R. Stat. Soc. Ser. B 70 (2008) 849â€“911] or LASSO can be applied to improve the results. Extensive numerical examples including pure simulation examples and semi-real examples are conducted to show the good performances of our procedure.",2017,
The correction of TEOM $${\hbox {PM}}_{10}$$ PM 10 measurements at different monitoring sites and climates,"The reference method for $${\hbox {PM}}_{{10}}$$
 and $${\hbox {PM}}_{2.5}$$
 measurement in Europe is active sampling with subsequent gravimetric analysis. Also tapered element oscillating microbalance (TEOM) monitors are widely used across Europe for the assessment of particulate matter (PM), even though they are known to be biased due to the loss of semi-volatile materials attributed to sample heating. In our work we correct TEOM $${\hbox {PM}}_{{10}}$$
 measurements at eight different monitoring sites located in different surroundings and different climates across Slovenia to replicate reference measurements. We use simultaneous reference and TEOM measurements from a period of seven years (2011â€“2017) and assess the advantage of custom defined correction factors (with linear and orthogonal regression) compared to default correction factors. We further try to improve the corrections by adding meteorological parameters as inputs and training a linear model (lasso) and nonlinear model (random forest). Random forest and lasso models also enable us to evaluate the impact of different meteorological parameters or chemical compounds on TEOM measurements. Our results show that TEOM measurements can be efficiently corrected using correction factors defined with two linear regressions (for summer and winter) at most locations across continental Slovenia. Koper, which lies at the sea side, was the most problematic measurement site. There the measurements were the most affected by the meteorological situation, and they could not be successfully corrected. When examining the effect of the chemical composition at two different locations, levels of $${\hbox {NH}}_4^+$$
 , $${\hbox {NO}}_3^{-}$$
 , and organic carbon exhibited major impact on the discrepancies between reference and TEOM measurements.",2019,
Censored linear model in high dimensions,"Censored data are quite common in statistics and have been studied in depth in the last years [for some references, see Powell (J Econom 25(3):303â€“325, 1984), Murphy et al. (Math Methods Stat 8(3):407â€“425, 1999), Chay and Powell (J Econ Perspect 15(4):29â€“42, 2001)]. In this paper, we consider censored high-dimensional data. High-dimensional models are in some way more complex than their low-dimensional versions, therefore some different techniques are required. For the linear case, appropriate estimators based on penalised regression have been developed in the last years [see for example Bickel et al. (Ann Stat 37(4):1705â€“1732, 2009), Koltchinskii (Bernoulli 15:799â€“828, 2009)]. In particular, in sparse contexts, the $$l_1$$l1-penalised regression (also known as LASSO) [see Tibshirani (J R Stat Soc Ser B 58:267â€“288, 1996), BÃ¼hlmann and van de Geer (Statistics for high-dimensional data. Springer, Heidelberg, 2011) and reference therein] performs very well. Only few theoretical work was done to analyse censored linear models in a high-dimensional context. We therefore consider a high-dimensional censored linear model, where the response variable is left censored. We propose a new estimator, which aims to work with high-dimensional linear censored data. Theoretical non-asymptotic oracle inequalities are derived.",2014,TEST
Sparse Projections over Graph,"Recent study has shown that canonical algorithms such as Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) can be obtained from graph based dimensionality reduction framework. However, these algorithms yield projective maps which are linear combination of all the original features. The results are difficult to be interpreted psychologically and physiologically. This paper presents a novel technique for learning a sparse projection over graphs. The data in the reduced subspace is represented as a linear combination of a subset of the most relevant features. Comparing to PCA and LDA, the results obtained by sparse projection are often easier to be interpreted. Our algorithm is based on a graph embedding model, which encodes the discriminating and geometrical structure in terms of the data affinity. Once the embedding results are obtained, we then apply regularized regression for learning a set of sparse basis functions. Specifically, by using L1-norm regularizer (e.g. lasso), the sparse projections can be efficiently computed. Experimental results on two document databases demonstrate the effectiveness of our method.",2008,
Group Lasso Estimation of High-dimensional Covariance Matrices,"In this paper, we consider the Group Lasso estimator of the covariance matrix of a stochastic process corrupted by an additive noise. We propose to estimate the covariance matrix in a high-dimensional setting under the assumption that the process has a sparse representation in a large dictionary of basis functions. Using a matrix regression model, we propose a new methodology for high-dimensional covariance matrix estimation based on empirical contrast regularization by a group Lasso penalty. Using such a penalty, the method selects a sparse set of basis functions in the dictionary used to approximate the process, leading to an approximation of the covariance matrix into a low dimensional space. Consistency of the estimator is studied in Frobenius and operator norms and an application to sparse PCA is proposed.",2011,J. Mach. Learn. Res.
Acoustic Greenâ€™s Function Estimation using Numerical Simulations and Application to Extern Aeroacoustic Beamforming,"Acoustic imaging techniques aims at characterizing the different acoustic sources of noise on an aircraft (jet, fans, wing, landing gears, etc.) using microphone array measurements. Those source identification techniques, among whom the beamforming is the most popular, require the knowledge of the acoustic Green's function of the medium between the estimated sources and the microphones of the array. Unfortunately, those propagation functions are known only for cases of relatively simple complexity. 
In the presence of complex flows, cavities, reecting surfaces like wings and tails, the Green's function is not known and the use of beamforming techniques based on approximate Green's function can lead to errors in the estimation of the location and amplitudes of the sources and can even lead to the apparition of spurious sources. 
The main aim of this thesis is to set up a numerical method for the estimation of the Green's function for aeroacoustic imaging applications. The method must have a minimal computational cost and provide a sufficiently accurate estimation to be used on realistic industrial configurations. 
The proposed methodology takes advantage of the sparsity of the Green's functions in the time-domain to minimize the required simulation time. The close relationship with the domain of system identification makes possible the use of a wide variety of sparsity-based regression algorithms like, among others, the stepwise regression, the lasso and the elastic net. First, the method is validated on complex 3D numerical test cases in the presence of flows and diffracting objects that are typical of those encountered in the industry. For the configurations involving a high number of focus points, the reverse-flow reciprocity decreases significantly the Green's function estimation problem. 
The methodology is finally applied on experimental data obtained on a high lift 2D wing placed in the ONERA CEPRA19 open section anechoic wind tunnel justifying the applicability of the method on realistic industrial configurations.",2018,
cqrReg: An R Package for Quantile and Composite Quantile Regression and Variable Selection,"The cqrReg package for R is the first to introduce a family of robust, high-dimensional regression models for quantile and composite quantile regression, both with and without an adaptive lasso penalty for variable selection. In this paper, we reformulate these quantile regression problems and present the estimators we implement in cqrReg using alternating direction method of multipliers (ADMM), majorize-minimization (MM), and coordinate descent (CD) algorithms. Our new approaches address the lack of publicly-available methods for (composite) quantile regression, both with and without regularization. We demonstrate the need for a variety of algorithms in later simulation studies. For comparison, we also introduce the widely-used interior point (IP) formulation and test our methods against the advanced IP algorithms in the existing quantreg package. Our simulation studies show that each of our methods, particularly MM and CD, excel in different settings such as with large or high-dimensional data sets, respectively, and outperform the methods currently implemented in quantreg. ADMM offers particular promise for future developments in its amenability to parallelization.",2017,arXiv: Computation
Behavior of Lasso Quantile Regression with Small Sample Sizes,"Quantile regression is a statistical technique intended to estimate, and conduct inference about the conditional quantile functions. Just as the classical linear regression methods estimate models for conditional mean function, quantile regression offers a mechanism for estimating models for conditional median function, and the full range of other conditional quantile functions. In this paper describe, compare, and apply the two quantile regression (L1-Lasso, L2-Lasso) suggested approaches. The two quantile regression suggested approaches used to select the best subset of variables and estimate the parameters of the quantile regression equation when small sample sizes are used. The aim of this study is to study the behavior of L1Lasso and L2 -Lasso quantile regression method when small sample sizes are generated. Simulations show that the proposed approaches are very competitive in terms of variable selection, estimation accuracy and efficient when small sample sizes are used. All results showed superiority of L1 -Lasso compared with L2 -Lasso linear programming methods. Keywordsâ€”Quantile Regression â€“ Small Sample size â€“ Selection of Variables estimated risk â€“ relative estimated risk.",2015,
Improving case definition of Crohn's disease and ulcerative colitis in electronic medical records using natural language processing: a novel informatics approach.,"BACKGROUND
Previous studies identifying patients with inflammatory bowel disease using administrative codes have yielded inconsistent results. Our objective was to develop a robust electronic medical record-based model for classification of inflammatory bowel disease leveraging the combination of codified data and information from clinical text notes using natural language processing.


METHODS
Using the electronic medical records of 2 large academic centers, we created data marts for Crohn's disease (CD) and ulcerative colitis (UC) comprising patients with â‰¥1 International Classification of Diseases, 9th edition, code for each disease. We used codified (i.e., International Classification of Diseases, 9th edition codes, electronic prescriptions) and narrative data from clinical notes to develop our classification model. Model development and validation was performed in a training set of 600 randomly selected patients for each disease with medical record review as the gold standard. Logistic regression with the adaptive LASSO penalty was used to select informative variables.


RESULTS
We confirmed 399 CD cases (67%) in the CD training set and 378 UC cases (63%) in the UC training set. For both, a combined model including narrative and codified data had better accuracy (area under the curve for CD 0.95; UC 0.94) than models using only disease International Classification of Diseases, 9th edition codes (area under the curve 0.89 for CD; 0.86 for UC). Addition of natural language processing narrative terms to our final model resulted in classification of 6% to 12% more subjects with the same accuracy.


CONCLUSIONS
Inclusion of narrative concepts identified using natural language processing improves the accuracy of electronic medical records case definition for CD and UC while simultaneously identifying more subjects compared with models using codified data alone.",2013,Inflammatory bowel diseases
Development and Validation of an MRI-Based Radiomics Signature for the Preoperative Prediction of Lymph Node Metastasis in Bladder Cancer,"BACKGROUND
Preoperative lymph node (LN) status is important for the treatment of bladder cancer (BCa). However, a proportion of patients are at high risk for inaccurate clinical nodal staging by current methods. Here, we report an accurate magnetic resonance imaging (MRI)-based radiomics signature for the individual preoperative prediction of LN metastasis in BCa.


METHODS
In total, 103 eligible BCa patients were divided into a training set (nâ€¯=â€¯69) and a validation set (nâ€¯=â€¯34). And 718 radiomics features were extracted from the cancerous volumes of interest (VOIs) on T2-weighted MRI images. A radiomics signature was constructed using the least absolute shrinkage and selection operator (LASSO) algorithm in the training set, whose performance was assessed and then validated in the validation set. Stratified analyses were also performed. Based on the multivariable logistic regression analysis, a radiomics nomogram was developed incorporating the radiomics signature and selected clinical predictors. Discrimination, calibration and clinical usefulness of the nomogram were assessed.


FINDINGS
Consisting of 9 selected features, the radiomics signature showed a favorable discriminatory ability in the training set with an AUC of 0.9005, which was confirmed in the validation set with an AUC of 0.8447. Encouragingly, the radiomics signature also showed good discrimination in the MRI-reported LN negative (cN0) subgroup (AUC, 0.8406). The nomogram, consisting of the radiomics signature and the MRI-reported LN status, showed good calibration and discrimination in the training and validation sets (AUC, 0.9118 and 0.8902, respectively). The decision curve analysis indicated that the nomogram was clinically useful.


INTERPRETATION
The MRI-based radiomics nomogram has the potential to be used as a non-invasive tool for individualized preoperative prediction of LN metastasis in BCa. External validation is further required prior to clinical implementation.",2018,EBioMedicine
The Role of 22 Genes Expression in Bladder Cancer by Adaptive LASSO,"Background: Genetic expression has been frequently considered as an efficient method for early diagnosis of cancer. In this study, we examined the simultaneous effect of 22 genes on contribution to bladder cancer. Objectives: Since these 22 genes are known as the most important risk factors in many cancers, we aimed to investigate them as potential effective genes in bladder cancer. Methods: The data consist of 25 patients with bladder cancer (the case group) and 23 matched healthy individuals as a control group. Univariate analysis was performed and differences between two groups were analyzed through the independent T-test. A multivariate gene expression model was implemented using the least absolute shrinkage and selection operator (LASSO) and Adaptive LASSO regression. Standard error of coefficients was obtained using the bootstrap method. We used two methods for classification and compared areas under the curve (AUC), using receiver operating characteristic (ROC) curve. Results: Independent T-test showed that 11 genes had a significant difference between the two groups. Also multivariate analysis using the LASSO revealed that 12 genes have a significant effect on bladder cancer and adaptive lasso regression represented SDF1, CTLA-4, Her2 and IL-23 genes as the most effective genes. The AUC for LASSO and Adaptive LASSO were 0.71 and 0.89, respectively which was statistically significant (P = 0.009). Our multivariable results for SDF1, CTLA-4 and IL-23 confirm the findings of many studies in this field. Conclusions: Among all genes were examined, SDF1, CTLA-4, Her2 and IL-23 which were selected by the two methods has the greatest contribution to bladder cancer.",2016,Iranian journal of cancer prevention
Correlation Between Tumor Metabolism and Semiquantitative Perfusion Magnetic Resonance Imaging Metrics in Non-Small Cell Lung Cancer.,"PURPOSE
To correlate semiquantitative parameters derived from dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) and 18F-fluorodeoxyglucose positron emission tomography (18F-FDG-PET) for non-small cell lung cancer (NSCLC).


METHODS AND MATERIALS
Twenty-four NSCLC patients who underwent pretreatment 18F-FDG-PET and DCE-MRI were analyzed. The maximum standardized uptake value (SUVmax) was measured from 18F-FDG-PET. Dynamic contrast-enhanced MRI was obtained on a 3T MRI scanner using 4-dimensional T1-weighted high-resolution imaging with a volume excitation sequence. The DCE-MRI parameters, consisting of mean, median, standard deviation (SD), and median absolute deviation (MAD) of peak enhancement, time to peak (TTP), time to half peak (TTHP), wash-in slope (WIS), wash-out slope (WOS), initial gradient, wash-out gradient, signal enhancement ratio, and initial area under the relative signal enhancement curve taken up to 30, 60, 90, 120, 150, and 180Â seconds, TTP, and TTHP (IAUCtthp), were calculated for each lesion. Univariate analysis (UVA) was performed using Spearman correlation. A linear regression model to predict SUVmax from DCE-MRI parameters was developed by multivariate analysis (MVA) using least absolute shrinkage selection operator in combination with leave-one-out cross-validation (LOOCV).


RESULTS
In UVA, mean(WOS) (ÏÂ =Â -0.456, PÂ =Â .025), mean(IAUCtthp) (ÏÂ =Â -0.439, PÂ =Â .032), median(IAUCtthp) (ÏÂ =Â -0.543, PÂ =Â .006), and MAD(IAUCtthp) (ÏÂ =Â -0.557, PÂ =Â .005) were statistically significant; all these parameters were negatively correlated with SUVmax. In MVA, a linear combination of SD(WIS), SD(TTP), MAD(TTHP), and MAD(IAUCtthp) was statistically significant for predicting SUVmax (LOOCV-based adjusted R2Â =Â 0.298, PÂ =Â .0006). A decrease in SD(WIS), MAD(TTHP), and MAD(IAUCtthp) and an increase in SD(TTP) were associated with a significant increase in SUVmax.


CONCLUSION
An association was found between SUVmax, the SD, and MAD of DCE-MRI metrics derived during contrast uptake in NSCLC, reflecting that intratumoral heterogeneity in wash-in contrast kinetics is associated with tumor metabolism. Although MAD(IAUCtthp) was a significant feature in both UVA and MVA, the LASSO-based multivariate regression model yielded better predictability of SUVmax than a univariate regression model using MAD(IAUCtthp). This study will facilitate understanding of the complex relationship between tumor vascularization and metabolism and eventually help in guiding targeted therapy.",2018,"International journal of radiation oncology, biology, physics"
"Health Effects of PM2.5 and Its Components on Mortality, Blood Pressure, and DNA Methylation","Epidemiological studies have examined the association between PM2.5 mass and mortality, but there remains uncertainty about the relative importance of species. PM2.5 contains various species, such as organic carbon, elemental carbon, and metals. Determining the differential toxicity of PM2.5 species and identifying species with greatest toxicity is of great importance to emissioncontrol strategies and regulations. In the dissertation thesis, effects of PM2.5 species on health outcomes on different levels were estimated. The first study examined the association between PM2.5 species and mortality on approximately 4.5 million deaths for all causes, cardiovascular diseases, myocardial infarction, stroke, and respiratory diseases in 75 U.S. cities for 2000-2006, using city-season specific Poisson regression and multivariate meta-regression controlled for infiltration. Since cardiovascular diseases are leading causes of death within U.S. population, the second study aimed to determine which PM2.5 species are associated with blood pressure, an indicator of cardiovascular health, in a longitudinal cohort. Linear mixed-effects models with the adaptive LASSO penalty were applied to longitudinal data from 718 elderly men in the Veterans Affairs Normative Aging Study (NAS),",2018,
"MÃ©tabolomique, mÃ©tabolome alimentaire et dÃ©clin cognitif du sujet Ã¢gÃ©","Discipline Epidemiologie. Introduction et but de lâ€™etude Le vieillissement cognitif et les maladies associees, comme la demence, representent une charge societale majeure, pour lesquels la prevention primaire est une piste a privilegier. Parmi les facteurs de risque a cibler pour la prevention, la nutrition, pilier de la sante vasculaire et metabolique, est prometteuse. Alors que lâ€™alimentation apporte environ 30Â 000Â composes (et pres de 100Â 000Â metabolites derives), tres peu de bioactifs ont ete etudies dans le vieillissement cognitif. Lâ€™analyse du metabolome, notamment celui en lien avec lâ€™alimentation, pourrait permettre dâ€™identifier de nouvelles cibles preventives. Notre objectif etait dâ€™investiguer, par une approche metabolomique non ciblee (profilage agnostique de tous les metabolites quantifiables dans un biofluide) une signature metabolique precoce du declin cognitif chez le sujet Ã¢geâ€“avec un interet particulier pour les metabolites derives de lâ€™alimentation. Materiel et methodes Nous avons construit un cas temoin niche dans la cohorte des 3Â cites, Bordeaux (taille cibleeÂ âˆ¼Â 400Â participants), parmi les 1293Â participants (Â â‰¥Â 65Â ans) non dements ayant accepte un prelevement sanguin a lâ€™inclusion en 1999â€“2000Â et suivi sur le plan cognitif jusquâ€™a 12Â annees. Nous avonsÂ : â€“Â estime les pentes individuelles de declin cognitif en appliquant un modele lineaire mixte aux mesures repetees dâ€™un score composite incluant 5Â tests cognitifsÂ ; â€“Â identifie les 220Â sujets avec les pentes les plus importantes (cas)Â ; â€“Â apparies, avec succes, 209Â dâ€™entre eux a 209Â temoins avec une cognition plus stable (penteÂ >Â pente mediane) et de meme Ã¢ge, sexe et niveau dâ€™etudes. Lâ€™analyse metabolomique non ciblee a ete realisee par spectrometrie de masse (301Â ions apres pretraitement des donnees). Le profil metabolique le plus associe au declin cognitif a ete identifie par regression LASSO pour donnees appariees (ajustee sur les facteurs dâ€™appariement, lâ€™IMC, le nombre de medicaments regulierement consommes, et le niveau cognitif a lâ€™inclusion) combinee a un re-echantillonnage bootstrap. Resultats et analyse statistique Nous avons identifie une vingtaine de metabolites associes au declin cognitifÂ ; ajoutes a un modele de facteurs cliniques standards, ces metabolites amelioraient la capacite discriminante dâ€™un AUC cross-valide de 62Â % (IC 95Â %Â : 56â€“67Â %) a 75Â % (IC 95Â %Â : 70â€“80Â %). La confrontation des metabolites aux bases de donnees existantes et/ou standards a permis lâ€™identification formelle ou probable deÂ : â€“Â trois biomarqueurs du cafe, notamment lâ€™atractyligenin glucuronide associe a un moindre declinÂ ; â€“Â un biomarqueur du jus dâ€™orange, la proline betaine, associe a un plus fort declinÂ ; â€“Â un marqueur possible du chocolat, le cyclo (prolyl-valyl), associe a un moindre declin. De plus, la signature incluait plusieurs metabolites endogenes. Conclusion Nous avons identifie des metabolites precocement associes au declin cognitif, dont plusieurs marqueurs du metabolome alimentaire. Ces resultats necessitent dâ€™etre valides dans une population externe. Neanmoins, ils offrent des pistes interessantes pour etablir de nouvelles formulations preventives du declin cognitif.",2019,Nutrition Clinique Et Metabolisme
Constrain to perform : Regularization of habitat models,"Predictive habitat models are an important tool for ecological research and conservation. A major cause of unreliable models is excessive model complexity, and regularization methods aim to improve the predictive performance by adequately constraining model complexity. We compare three regularization methods for logistic regression: variable selection, lasso, and ridge. They differ in the way model complexity is measured: variable selection uses the number of estimated parameters, the lasso uses the sum of the absolute values of the parameter estimates, and the ridge uses the sum of the squared values of the parameter estimates. 
 
We performed a simulation study with environmental data of a real landscape and artificial species occupancy data. We investigated the effect of three factors on relative model performance: (1) the number of parameters (16, 10, 6, 2) in the â€˜trueâ€™ model that determined the distribution of the artificial species, (2) the prevalence, i.e. the proportion of sites occupied by the species, and (3) the sample size (measured in events per variable, EPV). 
 
Regularization improved model discrimination and calibration. However, no regularization method performed best under all circumstances: the ridge generally performed best in the 16-parameter scenario. The lasso generally performed best in the 10-parameter scenario. Variable selection with AIC was best at large sample sizes (EPVâ‰¥10) when less than half of the variables influenced the species distribution. However, at low sample sizes (EPV<10), ridge and lasso always performed best, regardless of the parameter scenario or prevalence. Overall, calibration was best in ridge models. Other methods showed overconfidence, particularly at low sample sizes. The percentage of correctly identified models was low for both lasso and variable selection. 
 
Variable selection should be used with caution. Although it can produce the best performing models under certain conditions, these situations are difficult to infer from the data. Ridge and lasso are risk-averse model strategies that can be expected to perform well under a wide range of underlying speciesâ€“habitat relationships, particularly at small sample sizes.",2006,Ecological Modelling
Development of a Prediction Model for Stress Fracture During an Intensive Physical Training Program: The Royal Marines Commandos,"Background: Stress fractures (SFs) are one of the more severe overuse injuries in military training, and therefore, knowledge of potential risk factors is needed to assist in developing mitigating strategies. Purpose: To develop a prediction model for risk of SF in Royal Marines (RM) recruits during an arduous military training program. Study Design: Case-control study; Level of evidence, 3. Methods: RM recruits (N = 1082; age range, 16-33 years) who enrolled between September 2009 and July 2010 were prospectively followed through the 32-week RM training program. SF diagnosis was confirmed from a positive radiograph or magnetic resonance imaging scan. Potential risk factors assessed at week 1 included recruit characteristics, anthropometric assessment, dietary supplement use, lifestyle habits, fitness assessment, blood samples, 25(OH)D, bone strength as measured by heel broadband ultrasound attention, history of physical activity, and previous and current food intake. A logistic least absolute shrinkage and selection operator (LASSO) regression with 10-fold cross-validation was used to select potential predictors among 47 candidate variables. Model performance was assessed using measures of discrimination (c-index) and calibration. Bootstrapping was used for internal validation of the developed model and to quantify optimism. Results: A total of 86 (8%) volunteer recruits presented at least 1 SF during training. Twelve variables were identified as the most important risk factors of SF. Variables strongly associated with SF were age, body weight, pretraining weightbearing exercise, pretraining cycling, and childhood intake of milk and milk products. The c-index for the prediction model, which represents the model performance in future volunteers, was 0.73 (optimism-corrected c-index, 0.68). Although 25(OH)D and VO2max had only a borderline statistically significant association with SF, the inclusion of these factors improved the performance of the model. Conclusion: These findings will assist in identifying recruits at greater risk of SF during training and will support interventions to mitigate this injury risk. However, external validation of the model is still required.",2017,Orthopaedic Journal of Sports Medicine
Selecting pre-screening items for early intervention trials of dementia--a case study.,"Our goal was to review and extend statistical methods for discriminating between normal subjects and those with dementia or cognitive impairment. We compared six different methods to one constructed by expert opinion, in their brevity and predictive power. The methods include logistic regression and neural networks, with standard and least absolute shrinkage and selection operator (LASSO) variable selection, as well as decision trees with and without boosting. These methods were applied to the baseline data of a subgroup of subjects in a dementia study, using their screening interview items to predict their clinical diagnosis of normal or non-normal (cognitively impaired or demented). The derived models were then validated on a different subgroup of subjects in the same study who had the screening and clinical diagnosis two to five years later. Performance of different models was compared based on their sensitivity and specificity in the validation sample. Generally, the six statistical methods performed slightly to moderately better than the expert-opinion model. Neural networks generally performed better than the logistic and decision tree models. LASSO improved the performance of logistic and neural network models, but it eliminated few input variables in the neural network. The single decision tree performed at least as well as the standard logistic model, and with fewer items, making it an attractive pre-screening tool. Using the boosting option for decision trees did not substantially improve the performance. We recommend that for each situation, different methods of classification should be attempted to obtain optimal results for a given purpose.",2004,Statistics in medicine
A Stepwise Algorithm for Generalized Linear Mixed Models,"Stepwise regression includes regression models in which the predictive variables are selected by an automated algorithm. The stepwise method involves two approaches, namely, backward elimination and forward selection. Currently, SAS has several regression procedures capable of performing stepwise regression. Among them are REG, LOGISTIC, GLMSELECT and PHREG. PROC REG handles linear regression model but does not support a CLASS statement. PROC LOGISTIC handles binary responses and allows for logit, probit and complementary log-log link functions. It also allows for CLASS statements. The GLMSELECT procedure performs selections in the framework of general linear models. It allows for a variety of model selection methods, including the LASSO method of Tibshirani (1996) and the related LAR method of Efron et al. (2004). GLMSELECT supports a CLASS statement. PHREG is appropriate for proportional hazard survival regression. We present a stepwise algorithm for Generalized Linear Mixed Models for both marginal and conditional models. We illustrate the algorithm using data from a longitudinal observational study aimed to investigate parentsâ€™ beliefs, behaviors, feeding practices that associate positively or negatively with indices of sleep quality.",2014,
Islands beneath islands: phylogeography of a groundwater amphipod crustacean in the Balearic archipelago,"BackgroundMetacrangonyctidae (Amphipoda, Crustacea) is an enigmatic continental subterranean water family of marine origin (thalassoid). One of the species in the genus, Metacrangonyx longipes, is endemic to the Balearic islands of Mallorca and Menorca (W Mediterranean). It has been suggested that the origin and distribution of thalassoid crustaceans could be explained by one of two alternative hypotheses: (1) active colonization of inland freshwater aquifers by a marine ancestor, followed by an adaptative shift; or (2) passive colonization by stranding of ancestral marine populations in coastal aquifers during marine regressions. A comparison of phylogenies, phylogeographic patterns and age estimations of clades should discriminate in favour of one of these two proposals.ResultsPhylogenetic relationships within M. longipes based on three mitochondrial DNA (mtDNA) and one nuclear marker revealed five genetically divergent and geographically structured clades. Analyses of cytochrome oxidase subunit 1 (cox1) mtDNA data showed the occurrence of a high geographic population subdivision in both islands, with current gene flow occurring exclusively between sites located in close proximity. Molecular-clock estimations dated the origin of M. longipes previous to about 6 Ma, whereas major cladogenetic events within the species took place between 4.2 and 2.0 Ma.ConclusionsM. longipes displayed a surprisingly old and highly fragmented population structure, with major episodes of cladogenesis within the species roughly correlating with some of the major marine transgression-regression episodes that affected the region during the last 6 Ma. Eustatic changes (vicariant events) -not active range expansion of marine littoral ancestors colonizing desalinated habitats-explain the phylogeographic pattern observed in M. longipes.",2011,BMC Evolutionary Biology
Explanatory Model of Dry Eye Disease Using Health and Nutrition Examinations: Machine Learning and Network-Based Factor Analysis From a National Survey,"BACKGROUND
Dry eye disease (DED) is a complex disease of the ocular surface, and its associated factors are important for understanding and effectively treating DED.


OBJECTIVE
This study aimed to provide an integrative and personalized model of DED by making an explanatory model of DED using as many factors as possible from the Korea National Health and Nutrition Examination Survey (KNHANES) data.


METHODS
Using KNHANES data for 2012 (4391 sample cases), a point-based scoring system was created for ranking factors associated with DED and assessing patient-specific DED risk. First, decision trees and lasso were used to classify continuous factors and to select important factors, respectively. Next, a survey-weighted multiple logistic regression was trained using these factors, and points were assigned using the regression coefficients. Finally, network graphs of partial correlations between factors were utilized to study the interrelatedness of DED-associated factors.


RESULTS
The point-based model achieved an area under the curve of 0.70 (95% CI 0.61-0.78), and 13 of 78 factors considered were chosen. Important factors included sex (+9 points for women), corneal refractive surgery (+9 points), current depression (+7 points), cataract surgery (+7 points), stress (+6 points), age (54-66 years; +4 points), rhinitis (+4 points), lipid-lowering medication (+4 points), and intake of omega-3 (0.43%-0.65% kcal/day; -4 points). Among these, the age group 54 to 66 years had high centrality in the network, whereas omega-3 had low centrality.


CONCLUSIONS
Integrative understanding of DED was possible using the machine learning-based model and network-based factor analysis. This method for finding important risk factors and identifying patient-specific risk could be applied to other multifactorial diseases.",2020,JMIR Medical Informatics
Gradient descent with sparsification: an iterative algorithm for sparse recovery with restricted isometry property,"We present an algorithm for finding an <i>s</i>-sparse vector <i>x</i> that minimizes the <i>square-error</i> âˆ¥<i>y</i> -- Î¦<i>x</i>âˆ¥<sup>2</sup> where Î¦ satisfies the <i>restricted isometry property</i> (RIP), with <i>isometric constant</i> Î”<sub>2<i>s</i></sub> < 1/3. Our algorithm, called <b>GraDeS</b> (Gradient Descent with Sparsification) iteratively updates <i>x</i> as: [EQUATION]
 where Î³ > 1 and <i>H<sub>s</sub></i> sets all but <i>s</i> largest magnitude coordinates to zero. <b>GraDeS</b> converges to the correct solution in constant number of iterations. The condition Î”<sub>2<i>s</i></sub> < 1/3 is most general for which a <i>near-linear time</i> algorithm is known. In comparison, the best condition under which a polynomial-time algorithm is known, is Î”<sub>2<i>s</i></sub> < âˆš2 -- 1.
 Our Matlab implementation of <b>GraDeS</b> outperforms previously proposed algorithms like Subspace Pursuit, StOMP, OMP, and Lasso by an order of magnitude. Curiously, our experiments also uncovered cases where L1-regularized regression (Lasso) fails but <b>GraDeS</b> finds the correct solution.",2009,
Graphical user interface (GUI) for the least absolute shrinkage and selection operator (LASSO) regression,"In Data Science, we usually encounter High-dimensional data. In this situation, the Classical Regression method usually cannot perform well because it is impossible to include all covariates in the model since the number of a parameter to be estimated is larger than the sample size. Least absolute shrinkage and selection operator (Lasso) method is one of the methods which can deal with this problem. Lasso regression perform the selection of covariates so that only the most influential covariates are used in the model. Unfortunately, most of Lasso method should be performed in CLI Software which is difficult to use for the general user. For this reason, we develop a web application by using Shiny to perform the Lasso method based on GUI which is easier to use. It allows users to analyze high-dimensional data without using programming language. The paper contains an implementation of Lasso Regression using web application on olive pomade oil data.",2019,
A hybrid data mining approach for identifying the temporal effects of variables associated with breast cancer survival,"Abstract Predicting breast cancer survival is crucial for practitioners to determine possible outcomes and make better treatment plans for the patients. In this study, a hybrid data mining based methodology was constructed to differentiate the variables whose importance for survival change over time. Therefore, the importance of variables was determined for three different time periods (i.e. one, five, and ten years). To conduct such an analysis, the most parsimonious models were constructed by employing one regression analysis methodâ€”Least Absolute Shrinkage and Selection Operator (LASSO), and one metaheuristic optimization method, namely a Genetic Algorithm (GA). Due to the high imbalance between the number of survivals and deaths, two well-known resampling proceduresâ€”Random Under-sampling (RUS) and Synthetic Minority Over-sampling Technique (SMOTE)â€”were applied to increase the performance of the classification models. In the final stage, two data mining models, namely Artificial Neural Networks (ANNs) and Logistic Regression (LR), were utilized along with 10-fold cross-validation. Sensitivity analysis (SA) was conducted for each model to identify the importance of each variable for a certain model and time period. The obtained results revealed that certain variables lose their importance over time, while others gain importance. This information can assist medical practitioners in identifying specific subsets of variables to focus on in different periods, which will in turn lead to a more effective and efficient cancer care. Moreover, the study findings indicate that extremely parsimonious models can be developed by adopting a purely data-driven approach, rather than eliminating the variables manually. Such methodology can also be applied in treating other types of cancer.",2020,Expert Syst. Appl.
On high dimensional regression : computational and statistical perspectives Ã‰cole Normale SupÃ©rieure,"This dissertation essentially covers the work done by the author as a â€œMaÃ®tre de ConfÃ©rencesâ€ at the Laboratoire de Traitement et Communication de lâ€™Information (LTCI), at TÃ©lÃ©com ParisTech, since December 2012. During this period, the author strengthened his contributions to high-dimensional statistics and in particular sparse regression methods. In particular, the main focus of the dissertation is on computational aspects and to speed-up algorithms for Lasso-type problems, on means to better take into account the unknown noise and on corrections against the bias non-smooth convex regression methods suffer from. This report is not meant to present comprehensive description of the results developed by the author, but rather a synthetic view of his main contributions. The interested reader may consult the referenced articles for additional details and more precise treatment of the topics presented here.",2018,
A CpG Methylation Classifier to Predict Relapse in Adults with T-cell Lymphoblastic Lymphoma.,"PURPOSE
Adults with T-cell lymphoblastic lymphoma (T-LBL) generally benefit from treatment with acute lymphoblastic leukemia (ALL)-like regimens, but approximately 40% will relapse after such treatment. We evaluated the value of CpG methylation in predicting relapse for adults with T-LBL treated with ALL-like regimens.


EXPERIMENTAL DESIGN
A total of 549 adults with T-LBL from 27 medical centers were included in the analysis. Using the Illumina Methylation 850K Beadchip, 44 relapse-related CpGs were identified from 49 T-LBL samples by two algorithms, Least Absolute Shrinkage and Selector Operation (LASSO) and Support Vector Machine-Recursive Feature Elimination (SVM-RFE). We built a four-CpG classifier using LASSO Cox regression based on association between the methylation level of CpGs and relapse-free survival (RFS) in the training cohort (n=160).The four-CpG classifier was validated in the internal testing cohort (n=68) and independent validation cohort (n=321) Results: The four-CpG-based classifier discriminated T-LBL patients at high risk of relapse in the training cohort from those at low risk (p<0.001).This classifier also showed good predictive value in the internal testing cohort (p<0.001) and the independent validation cohort(p<0.001). A nomogram incorporating 5 independent prognostic factors including the CpG-based classifier, lactate dehydrogenase levels, ECOG-PS, central nervous system involvement and NOTCH1/FBXW7 status showed a significantly higher predictive accuracy than each single variable. Stratification into different subgroups by the nomogram helped identify the subset of patients who most benefited from more intensive chemotherapy and/or sequential hematopoietic stem cell transplantation.


CONCLUSIONS
Our four-CpG-based classifier could predict disease relapse in patients with T-LBL, and could be used to guide treatment decision.",2020,Clinical cancer research : an official journal of the American Association for Cancer Research
C-HiLasso: A Collaborative Hierarchical Sparse Modeling Framework,"Sparse modeling is a powerful framework for data analysis and processing. Traditionally, encoding in this framework is performed by solving an l1-regularized linear regression problem, commonly referred to as Lasso or Basis Pursuit. In this work we combine the sparsity-inducing property of the Lasso at the individual feature level, with the block-sparsity property of the Group Lasso, where sparse groups of features are jointly encoded, obtaining a sparsity pattern hierarchically structured. This results in the Hierarchical Lasso (HiLasso), which shows important practical advantages. We then extend this approach to the collaborative case, where a set of simultaneously coded signals share the same sparsity pattern at the higher (group) level, but not necessarily at the lower (inside the group) level, obtaining the collaborative HiLasso model (C-HiLasso). Such signals then share the same active groups, or classes, but not necessarily the same active set. This model is very well suited for applications such as source identification and separation. An efficient optimization procedure, which guarantees convergence to the global optimum, is developed for these new models. The underlying presentation of the framework and optimization approach is complemented by experimental examples and theoretical results regarding recovery guarantees.",2011,IEEE Transactions on Signal Processing
Aspects Related to Body Image and Eating Behaviors in Healthy Brazilian Undergraduate Students,"The discrepancy between oneâ€™s actual body and the ideal body, especially among young adults, can lead to body dissatisfaction in both men and women, which is commonly accepted to be central to eating disorders. We explored aspects of body image and eating disorders in healthy Brazilian students (n = 219) using two standardized measures (Body Shape Questionnaire [BSQ-34] and Eating Attitudes Test [EAT-26]) and assessing height, weight, Body Mass Index (BMI), and the history of physical activity. We also analyzed the ability of one measure to predict another. Linear multiple regression was used to verify which variables best predicted the scale outcomes. The Least Absolute Shrinkage and Selection Operator (LASSO) was used for variable selection. The results suggested that women have a greater risk of body dissatisfaction and eating disorders. Both instruments had variables that significantly predicted each otherâ€™s results, whereas BMI was only associated with BSQ-34 scores. These findings broaden our understanding of eating disorders and body image.",2018,
Portfolio Optimization with Return Prediction Models Evidence for Industry Portfolios,"Several studies suggest that using prediction models instead of historical averages results in more efficient asset allocations, thus providing investors with higher risk-adjusted returns. While earlier studies focus on predicting the U.S. equity market risk-premium, we investigate the predictability of industry returns and hypothesize that forecasting returns on the industry level rather than on the aggregate stock market level allows for superior asset allocation decisions. Moreover, we extend the commonly tested dataset of predictive variables by including additional macro variables, reflecting the business cycle and technical indicators using information on investor behavior. We analyze industry return forecasts in-sample and out-ofsample and evaluate the economic benefits of industry level predictions in an asset allocation framework based on the Black-Litterman model. We first analyze the predictive power of individual variables using bivariate regressions and then examine multivariate predictive regression models including OLS, a regularization technique (LASSO), predictive regressions based on principal components, a target-relevant latent factor approach (3PRF), as well as forecast combinations. Our results suggest that return forecast models predict future returns better than historical averages for most industries. Moreover, our results reveal that asset allocations based on return predictions significantly outperform asset allocations based on historical averages as well as passive equally weighted (1/N) portfolios. Most importantly, using industry return predictions results in more efficient asset allocation decisions providing investors with higher risk-adjusted returns.",2015,
Ridle for sparse regression with mandatory covariates with application to the genetic assessment of histologic grades of breast cancer,"BackgroundMany questions in statistical genomics can be formulated in terms of variable selection of candidate biological factors for modeling a trait or quantity of interest. Often, in these applications, additional covariates describing clinical, demographical or experimental effects must be included a priori as mandatory covariates while allowing the selection of a large number of candidate or optional variables. As genomic studies routinely require mandatory covariates, it is of interest to propose principled methods of variable selection that can incorporate mandatory covariates.MethodsIn this article, we propose the ridge-lasso hybrid estimator (ridle), a new penalized regression method that simultaneously estimates coefficients of mandatory covariates while allowing selection for others. The ridle provides a principled approach to mitigate effects of multicollinearity among the mandatory covariates and possible dependency between mandatory and optional variables. We provide detailed empirical and theoretical studies to evaluate our method. In addition, we develop an efficient algorithm for the ridle. Software, based on efficient Fortran code with R-language wrappers, is publicly and freely available at https://sites.google.com/site/zhongyindaye/software.ResultsThe ridle is useful when mandatory predictors are known to be significant due to prior knowledge or must be kept for additional analysis. Both theoretical and comprehensive simulation studies have shown that the ridle to be advantageous when mandatory covariates are correlated with the irrelevant optional predictors or are highly correlated among themselves. A microarray gene expression analysis of the histologic grades of breast cancer has identified 24 genes, in which 2 genes are selected only by the ridle among current methods and found to be associated with tumor grade.ConclusionsIn this article, we proposed the ridle as a principled sparse regression method for the selection of optional variables while incorporating mandatory ones. Results suggest that the ridle is advantageous when mandatory covariates are correlated with the irrelevant optional predictors or are highly correlated among themselves.",2017,BMC Medical Research Methodology
Variable Clustering in High Dimensional Probit Regression,"Dimension reduction is a major issue in high-dimensional regression models. We recently introduced the CLusterwise Effect REgression (CLERE) methodology [1] in the context of linear regression for variable clustering as a way of reducing the dimensionality. We propose in this paper, an extension of the CLERE methodology to high dimensional Probit regression. The proposed extension was compared to LASSO and Ridge logistic regressions. This comparison achieved on both simulated and real data, revealed the good predictive performances of our method.",2014,
High-Dimensional Bayesian Regularised Regression with the BayesReg Package,"Bayesian penalized regression techniques, such as the Bayesian lasso and the Bayesian horseshoe estimator, have recently received a significant amount of attention in the statistics literature. However, software implementing state-of-the-art Bayesian penalized regression, outside of general purpose Markov chain Monte Carlo platforms such as STAN, is relatively rare. This paper introduces bayesreg, a new toolbox for fitting Bayesian penalized regression models with continuous shrinkage prior densities. The toolbox features Bayesian linear regression with Gaussian or heavy-tailed error models and Bayesian logistic regression with ridge, lasso, horseshoe and horseshoe$+$ estimators. The toolbox is free, open-source and available for use with the MATLAB and R numerical platforms.",2016,arXiv: Computation
Validation of ART Calculator for Predicting the Number of Metaphase II Oocytes Required for Obtaining at Least One Euploid Blastocyst for Transfer in Couples Undergoing in vitro Fertilization/Intracytoplasmic Sperm Injection,"This multicenter study evaluated the reliability of the recently published ART calculator for predicting the minimum number of metaphase II (MII) oocytes (MIImin) to obtain at least one euploid blastocyst in patients undergoing in vitro fertilization/intracytoplasmic sperm injection (IVF/ICSI). We used clinical and embryonic retrospective data of 1,464 consecutive infertile couples who underwent IVF/ICSI with the intention to have preimplantation genetic testing for aneuploidy. The validation procedure followed a stepwise approach. Firstly, we assessed the distribution of euploid blastocysts per patient and found that it followed a negative binomial distribution. Secondly, we used generalized linear models and applied the Lasso procedureâ€“including MII oocytes to adjust the dataâ€“to select the factors predicting the response variable â€œeuploid blastocyst.â€ Third, a logistic regression modelâ€“fit to the binomial response euploid (yes/no) for each MII oocyteâ€“was built using the relevant factors. The observational unit was the â€œwomanâ€ whereas the response was the pair (m, n), where n is the number of retrieved MII oocytes and m the corresponding number of euploid blastocysts. The model was internally validated by randomly splitting the data into training and validation sets. The R-squares (~0.25) and the area under the ROC curve (~0.70) did not differ between the training and validation datasets. Fourth, mathematical equations and the calculated probabilities generated by the validation model were used to determine the MIImin required for obtaining at least one euploid blastocyst according to different success probabilities. Lastly, we compared the fittings generated by the validation model and the ART calculator and assessed the predictive value of the latter using the validation dataset. The fittings were sufficiently close for both the estimated probabilities of blastocyst euploid per MII oocyte (r = 0.91) and MIImin (r = 0.88). The ART calculator positive predictive values, i.e., the frequency of patients with at least one euploid blastocyst among those who achieved the estimated MIImin, were 84.8%, 87.5%, and 90.0% for 70%, 80%, and 90% predicted probabilities of success, respectively. The ART calculator effectively predicts the MIImin needed to achieve at least one euploid blastocyst in individual patients undergoing IVF/ICSI. The prediction tool might be used for counseling and planning IVF/ICSI treatments.",2019,Frontiers in Endocrinology
Gene selection with guided regularized random forest,"The regularized random forest (RRF) was recently proposed for feature selection by building only one ensemble. In RRF the features are evaluated on a part of the training data at each tree node. We derive an upper bound for the number of distinct Gini information gain values in a node, and show that many features can share the same information gain at a node with a small number of instances and a large number of features. Therefore, in a node with a small number of instances, RRF is likely to select a feature not strongly relevant. Here an enhanced RRF, referred to as the guided RRF (GRRF), is proposed. In GRRF, the importance scores from an ordinary random forest (RF) are used to guide the feature selection process in RRF. Experiments on 10 gene data sets show that the accuracy performance of GRRF is, in general, more robust than RRF when their parameters change. GRRF is computationally efficient, can select compact feature subsets, and has competitive accuracy performance, compared to RRF, varSelRF and LASSO logistic regression (with evaluations from an RF classifier). Also, RF applied to the features selected by RRF with the minimal regularization outperforms RF applied to all the features for most of the data sets considered here. Therefore, if accuracy is considered more important than the size of the feature subset, RRF with the minimal regularization may be considered. We use the accuracy performance of RF, a strong classifier, to evaluate feature selection methods, and illustrate that weak classifiers are less capable of capturing the information contained in a feature subset. Both RRF and GRRF were implemented in the ''RRF'' R package available at CRAN, the official R package archive.",2013,Pattern Recognit.
Adjusting the Penalized Term for the Regularized Regression Models,"More attention has been given to regularization methods in the last two decades as a result of exiting high-dimensional ill-posed data. This paper proposes a new method of introducing the penalized term in regularized regression. The proposed penalty is based on using the least squares estimatorâ€™s variances of the regression parameters. The proposed method is applied to some penalized estimators like ridge, lasso, and elastic net, which are used to overcome both the multicollinearity problem and selecting variables. Good results are obtained using the average mean squared error criterion (AMSE) for simulated data, also real data are shown best results in the form of less average prediction errors (APE) of the resulting estimators. Keywords: Elastic-Net, Lasso, Penalized regression; Regularization; Ridge regression; Shrinkage; Variable selection AMS 2010 Mathematics Subject Classification : 62J05; 62J07",2018,Journal of Animal Science
Tests in adaptive regression via the Kac-Rice formula,"We derive an exact p-value for testing a global null hypothesis in a general adaptive regression problem. The general approach uses the Kac-Rice formula, as described in (Adler & Taylor 2007). The resulting formula is exact in finite samples, requiring only Gaussianity of the errors. We apply the formula to the lasso, group lasso, and principal components and matrix completion problems. In the case of the lasso, the new test relates closely to the recently proposed covariance test of Lockhart et al. (2013).",2013,arXiv: Methodology
Local Buckling of Stiffe ned and Unstiffe ned Elements under Nonuniform Compression,"Thin plates subjected to linearly varying inplane compression in one direction may undergo local buckling before failure. An analytical procedure is presented for evaluating the local buckling strength based on which equations for the local buckling stress of unstiffened and stiffened elements are presented. INTRODUCTION Thin walled members are composed of plate elements which are supported along both edges parallel to the direction of compression (referred to as stiffened elements) and supported along only one edge parallel to the direction of compression with the other completely free (referred to as unstiffened elements). These t~lin plate elements may experience elastic local buckling and stable postbuckling behaviour when subject to inplane compressive, bending or shear stress. Due to initial imperfections, the bifurcation type of local buckling indicated by small deflection theory is not usually experienced by elements of commercially manufactured thin walled members. However, the postbuckling behaviour expressed in the form of effective width equations is a function of the elastic local buckling stress and hence the theoretical calculation of elastic local buckling stress of thin walled elements is of practical interest. Furthermore, the out of plane deflection of imperfect plates increases drastically at local buckling stress and hence is of interest to deSigners. Stowell (1939). Timoshenko (1961), Winter (1959), and Kalyanaraman (1979), have presented methods for evaluating local buckling strength of thin plate elements and members subjected to uniform in plane compression. Rhodes and Harvey (1971) and Walker (1967), have presented analytical procedures for evaluating the local and postbuckling behaviour of t~lin walled stiffened and unstiffened elements subjected to linearly varying in plane compression. Ramakrishna and Kalyanaraman (1984) have presented closed form equations for local and post buckling strength of thin walled stiffened elements subjected to linearly varying inplane compression based on regression of analytical results. In this paper Galerkin's procedure has been used to solve the governing differential equation for calculating the Iqcal buckling stress of non-uniformly compressed stiffened and unstiffened elements having elastically rotationally restrained longitudinal edges. Through regression, equations developed [Jayabalan (1989)] for the local buckling coefficient are presented as a function of the edge rotational restraint factor, and the non-uniform compression factor. The results of the proposed equations are compared with experimental results. ANALYTICAL STUDY Governing Equations A thin flat rectangular plate compressed by linearly varying displacements in the longitudinal direction asshown in Fig. 1 is considered, where the unloaded longitudinal edges may have one of the following boundary conditions. Both edges are completely restrained against out of plane translation Prolassor, Structural Engineering Division, Dept. 01 Civil Engineering, Indian Institute 01 Technology, MadrasÂ· 600 036. Lecturer, Dept. 01 Civil Engineering, Regional Engineering College, TiruchirappalliÂ· 620 015.",1994,
