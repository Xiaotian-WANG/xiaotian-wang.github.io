title,abstract,year,journal
Sparse Logistic Regression with Logical Features,"Modeling interactions in regression models poses both computational as well as statistical challenges: the computational resources and the amount of data required to solve them increases sharply with the size of the problem. We focus on logistic regression with categorical variables and propose a method for learning dependencies that are expressed as general Boolean formulas. The computational and statistical challenges are solved by applying a technique called transformed Lasso, which involves a matrix transformation of the original covariates. We compare the method to an earlier related method, LogicReg, and show that our method scales better in terms of the number of covariates as well as the order and complexity of the interactions.",2016,
Prognostic miRNA classifier in early-stage mycosis fungoides: development and validation in a Danish nationwide study.,"Mycosis fungoides (MF) is the most frequent form of cutaneous T-cell lymphoma. The disease often takes an indolent course, but in approximately one-third of the patients, the disease progresses to an aggressive malignancy with a poor prognosis. At the time of diagnosis, it is impossible to predict which patients develop severe disease and are in need of aggressive treatment. Accordingly, we investigated the prognostic potential of microRNAs (miRNAs) at the time of diagnosis in MF. Using a quantitative reverse transcription polymerase chain reaction platform, we analyzed miRNA expression in diagnostic skin biopsies from 154 Danish patients with early-stage MF. The patients were subdivided into a discovery cohort (n = 82) and an independent validation cohort (n = 72). The miRNA classifier was built using a LASSO (least absolute shrinkage and selection operator) Cox regression to predict progression-free survival (PFS). We developed a 3-miRNA classifier, based on miR-106b-5p, miR-148a-3p, and miR-338-3p, which successfully separated patients into high-risk and low-risk groups of disease progression. PFS was significantly different between these groups in both the discovery cohort and the validation cohort. The classifier was stronger than existing clinical prognostic factors and remained a strong independent prognostic tool after stratification and adjustment for these factors. Importantly, patients in the high-risk group had a significantly reduced overall survival. The 3-miRNA classifier is an effective tool to predict disease progression of early-stage MF at the time of diagnosis. The classifier adds significant prognostic value to existing clinical prognostic factors and may facilitate more individualized treatment of these patients.",2018,Blood
Statistical inference in sparse high-dimensional additive models.,"In this paper we discuss the estimation of a nonparametric component $f_1$ of a nonparametric additive model $Y=f_1(X_1) + ...+ f_q(X_q) + \epsilon$. We allow the number $q$ of additive components to grow to infinity and we make sparsity assumptions about the number of nonzero additive components. We compare this estimation problem with that of estimating $f_1$ in the oracle model $Z= f_1(X_1) + \epsilon$, for which the additive components $f_2,\dots,f_q$ are known. We construct a two-step presmoothing-and-resmoothing estimator of $f_1$ and state finite-sample bounds for the difference between our estimator and some smoothing estimators $\hat f_1^{\text{(oracle)}}$ in the oracle model. In an asymptotic setting these bounds can be used to show asymptotic equivalence of our estimator and the oracle estimators; the paper thus shows that, asymptotically, under strong enough sparsity conditions, knowledge of $f_2,\dots,f_q$ has no effect on estimation accuracy. Our first step is to estimate $f_1$ with an undersmoothed estimator based on near-orthogonal projections with a group Lasso bias correction. We then construct pseudo responses $\hat Y$ by evaluating a debiased modification of our undersmoothed estimator of $f_1$ at the design points. In the second step the smoothing method of the oracle estimator $\hat f_1^{\text{(oracle)}}$ is applied to a nonparametric regression problem with responses $\hat Y$ and covariates $X_1$. Our mathematical exposition centers primarily on establishing properties of the presmoothing estimator. We present simulation results demonstrating close-to-oracle performance of our estimator in practical applications.",2019,arXiv: Statistics Theory
Forecasting Time Series Water Levels on Mekong River Using Machine Learning Models,"Forecasting water levels on Mekong river is an important problem needed to be studied for flood warning. In this paper, we investigate the application to forecasting of daily water levels at Thakhek station on Mekong river using machine learning models such as LASSO, Random Forests and Support Vector Regression (SVR). Experimental results showed that SVR was able to achieve feasible results, the mean absolute error of SVR is 0.486(m) while the acceptable error of a flood forecast model required by the Mekong River Commission is between 0.5(m) and 0.75(m).",2015,2015 Seventh International Conference on Knowledge and Systems Engineering (KSE)
Multiple Kernel Learning with High Order Kernels,"Previous Multiple Kernel Learning approaches (MKL) employ different kernels by their linear combination. Though some improvements have been achieved over methods using single kernel, the advantages of employing multiple kernels for machine learning are far from being fully developed. In this paper, we propose to use â€œhigh order kernelsâ€ to enhance the learning of MKL when a set of original kernels are given. High order kernels are generated by the products of real power of the original kernels. We incorporate the original kernels and high order kernels into a unified localized kernel logistic regression model. To avoid over-fitting, we apply group LASSO regularization to the kernel coefficients of each training sample. Experiments on image classification prove that our approach outperforms many of the existing MKL approaches.",2010,2010 20th International Conference on Pattern Recognition
Do Local and Global Factors Impact the Emerging Marketsâ€™s Sovereign Yield Curves? Evidence from a Data-Rich Environment,"This paper investigates the relation between yield curve and macroeconomic factors for ten emerging sovereign bond markets using the sample from January 2006 to April 2019. To this end, the diffusion indices obtained under four categories (global variables, inflation, domestic financial variables, and economic activity) are incorporated by estimating dynamic panel data regressions together with the yield curve factors. Besides, in order to capture dynamic interaction between yield curve and macroeconomic/financial factors, a panel VAR analysis based on the system GMM approach is utilized. Empirical results suggest that the level factor responds to shocks originated from inflation, domestic financial variables and global variables. Furthermore, the slope factor is affected by shocks in global variables, and the curvature factor appears to be influenced by domestic financial variables. We also show that macroeconomic/financial factors captures significant predictive information over yield curve factors by running individual country factor-augmented predictive regressions and variable selection algorithms such ridge regression, LASSO and Elastic Net. Our findings have important implications for policymakers and fund managers by explaining the underlying forces of movements in the yield curve and forecasting accurately dynamics of yield curve factors.",2020,
PrÃ©diction de la survie sans mÃ©tastase dans le cancer du sein primaire Ã  partir de modÃ¨les de Cox de grande dimension,"Introduction Lâ€™etude de donnees dâ€™expression issues des puces a ADN a permis dâ€™identifier des signatures predictives de la rechute metastatique dans le cancer du sein primaire. En general, les procedures de selection appliquees en vue de reduire le nombre de genes lies a la prediction ne prennent pas en compte les correlations. Dans le cadre de ce travail, nous proposons dâ€™etudier les performances de methodes de regression de grande dimensionÂ â€“Â CoxBoost, LASSO et Elastic netÂ â€“Â dans lâ€™identification de signatures pronostiques du statut metastatique de patientes atteintes dâ€™un cancer du sein primaire. Methodes Lâ€™analyse a ete menee sur trois jeux de donnees publiques et retrospectives, correspondant a un total de 384Â patientes atteintes dâ€™un cancer du sein sans envahissement ganglionnaire. Le jeu dâ€™apprentissage original de vanâ€™t Veer et al. (2002) a ete utilise pour determiner les sets optimaux de genes a partir dâ€™une procedure automatique de selection basee sur la cross-validation. Les classificateurs ont ete construits a partir de seuils sur les predicteurs lineaires issus des modeles selectionnes correspondant a un taux de mal classes inferieur a 10Â % dans le groupe de mauvais pronostic (pas de metastase dans les cinq premieres annees de suivi). La validation sâ€™est faite sur les sets de van de Vijver et al. (2002) et de Desmedt et al. (2007), et les performances des classificateurs comparees a celles de la signature dâ€™Amsterdam a 70Â genes. Resultats La procedure de selection a permis lâ€™identification de sets de genes predictifs plus parcimonieux, jusquâ€™a six genes seulement. Sur les deux jeux de validation, Elastic net, LASSO et CoxBoost ont conduit a la definition de signatures genomiques predictives du statut metastatique a cinq ans avec des performances comparables. Sur la population de Desmedt, elles presentent des resultats respectifs de 59Â %, 56Â % et 54Â % en precision globale, de 83Â %, 75Â % et 83Â % en sensibilite, et de 53Â %, 52Â % et 48Â % en specificite. En comparaison, la signature dâ€™Amsterdam a 45Â % en precision globale, 97Â % en sensibilite et 34Â % en specificite. Le recoupement des listes de genes et les concordances de classifications entre les trois methodes sont eleves. Toutes apportent une information pronostique significative en analyse multivariee avec les facteurs classiques (Ã¢ge, diametre tumoral, grade SBR, statuts ER et HER2). Les ontologies associees aux genes surexprimes dans le groupe predit de mauvais pronostic sont concordantes entre elles et sont majoritairement liees a la proliferation cellulaire. Les signatures rapportent egalement une tres bonne sensibilite pour predire le statut metastatique jusquâ€™a quatre ans de suivi. Conclusion Puisquâ€™elles permettent la detection de sets de genes relativement restreints et ainsi de faciliter leur application dans les essais cliniques, les methodes de regression a grande dimension sont attrayantes et renforcent la robustesse des modeles selectionnes en limitant le nombre de genes predisant a tort un mauvais pronostic. Avec seulement six genes, la signature issue de CoxBoost predit le statut metastatique a quatre ans avec 93Â % de sensibilite dans le jeu de Desmedt. Ainsi, la selection future de genes lies a des ontologies differentes de la proliferation cellulaire pourrait eventuellement ameliorer les performances en termes de sensibilite globale. Ce travail a ete soumis pour publication au journal Cancer Informatics le 2Â decembre 2014Â et a ete finance par lâ€™IRESP (AAR 2013â€“14).",2015,Revue D Epidemiologie Et De Sante Publique
Erratum to: Ultrahigh dimensional variable selection through the penalized maximum trimmed likelihood estimator,"The penalized maximum likelihood estimator (PMLE) has been widely used for variable selection in high-dimensional data. Various penalty functions have been employed for this purpose, e.g., Lasso, weighted Lasso, or smoothly clipped absolute deviations. However, the PMLE can be very sensitive to outliers in the data, especially to outliers in the covariates (leverage points). In order to overcome this disadvantage, the usage of the penalized maximum trimmed likelihood estimator (PMTLE) is proposed to estimate the unknown parameters in a robust way. The computation of the PMTLE takes advantage of the same technology as used for PMLE but here the estimation is based on subsamples only. The breakdown point properties of the PMTLE are discussed using the notion of $$d$$ -fullness. The performance of the proposed estimator is evaluated in a simulation study for the classical multiple linear and Poisson linear regression models. Copyright Springer-Verlag Berlin Heidelberg 2014",2014,Statistical Papers
A new SMOS sea surface salinity retrieval method,"Sea surface roughness and foam have great influence on the retrieval accuracy of sea surface salinity (SSS) from satellite measured L-band brightness temperature (TB). A lot of work need to be done to improve the SSS retrieval accuracy especially using the forward model to reduce the error induced by sea surface roughness and foam. In this paper, seven factors, whitecap coverage, significant wave height (SWH), wave steepness, wavelength, sea surface temperature (SST), foam thickness, Water droplets density, their second-order items, and interaction items are selected as our model input candidates, and the Least Absolute Shrinkage and Selection Operation (LASSO) method is used for critical factor selection. As a result, two factors, SST and SWH, are carefully picked up to establish the new model to calculate the TB variants with quadratic curve regression formulas. The model shows that the mean absolute error (MAE) is 1.09psu and the root mean square (RMSE) is 1.70psu compared with Argo SSS data, in the meanwhile, the MEA of SMOS L2 SSS is 1.69psu and the RMSE is 2.48psu respectively. Results show that the new model can improve the retrieval accuracy for SMOS SSS measurements.",2017,2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)
Quantum annealing versus classical machine learning applied to a simplified computational biology problem,"Transcription factors regulate gene expression, but how these proteins recognize and specifically bind to their DNA targets is still debated. Machine learning models are effective means to reveal interaction mechanisms. Here we studied the ability of a quantum machine learning approach to classify and rank binding affinities. Using simplified data sets of a small number of DNA sequences derived from actual binding affinity experiments, we trained a commercially available quantum annealer to classify and rank transcription factor binding. The results were compared to state-of-the-art classical approaches for the same simplified data sets, including simulated annealing, simulated quantum annealing, multiple linear regression, LASSO, and extreme gradient boosting. Despite technological limitations, we find a slight advantage in classification performance and nearly equal ranking performance using the quantum annealer for these fairly small training data sets. Thus, we propose that quantum annealing might be an effective method to implement machine learning for certain computational biology problems.Quantum annealing: Solving a biological model with quantum machine learningA quantum algorithm has competitive performance with several standard machine learning methods for classifying and ranking binding affinities of gene-regulating molecules to DNA. Transcription factor proteins play a key role in controlling gene expression by attaching to DNA, but constructing a quantitative model to predict the binding strength is difficult. Richard Li and colleagues from the University of Southern California compared the performance of classical machine learning with a quantum learning algorithm implemented on a quantum annealing processor. While traditional classical protocols worked best when large training sets were used, the annealing approach outperformed them with smaller datasets. These results indicate that, even while a general speedup compared to classical computing is yet to be established, quantum annealing processors may help improve machine learning approaches to practical problems where training data are scarce.",2018,npj Quantum Information
High Dimensional Regression with Binary Coefficients. Estimating Squared Error and a Phase Transtition,"We consider a sparse linear regression model Y=X\beta^{*}+W where X has a Gaussian entries, W is the noise vector with mean zero Gaussian entries, and \beta^{*} is a binary vector with support size (sparsity) k. Using a novel conditional second moment method we obtain a tight up to a multiplicative constant approximation of the optimal squared error \min_{\beta}\|Y-X\beta\|_{2}, where the minimization is over all k-sparse binary vectors \beta. The approximation reveals interesting structural properties of the underlying regression problem. In particular, a) We establish that n^*=2k\log p/\log (2k/\sigma^{2}+1) is a phase transition point with the following ""all-or-nothing"" property. When n exceeds n^{*}, (2k)^{-1}\|\beta_{2}-\beta^*\|_0\approx 0, and when n is below n^{*}, (2k)^{-1}\|\beta_{2}-\beta^*\|_0\approx 1, where \beta_2 is the optimal solution achieving the smallest squared error. With this we prove that n^{*} is the asymptotic threshold for recovering \beta^* information theoretically. b) We compute the squared error for an intermediate problem \min_{\beta}\|Y-X\beta\|_{2} where minimization is restricted to vectors \beta with \|\beta-\beta^{*}\|_0=2k \zeta, for \zeta\in [0,1]. We show that a lower bound part \Gamma(\zeta) of the estimate, which corresponds to the estimate based on the first moment method, undergoes a phase transition at three different thresholds, namely n_{\text{inf,1}}=\sigma^2\log p, which is information theoretic bound for recovering \beta^* when k=1 and \sigma is large, then at n^{*} and finally at n_{\text{LASSO/CS}}. c) We establish a certain Overlap Gap Property (OGP) on the space of all binary vectors \beta when n\le ck\log p for sufficiently small constant c. We conjecture that OGP is the source of algorithmic hardness of solving the minimization problem \min_{\beta}\|Y-X\beta\|_{2} in the regime n",2017,
Comparison of Lasso Type Estimators for High-Dimensional Data,"Abstract This paper compares of lasso type estimators in various high-dimensional data situations with sparse param-eters. Lasso, adaptive lasso, fused lasso and elastic net as lasso type estimators and ridge estimator are comparedvia simulation in linear models with correlated and uncorrelated covariates and binary regression models withcorrelated covariates and discrete covariates. Each method is shown to have advantages with diï¬€erent penaltyconditions according to sparsity patterns of regression parameters. We applied the lasso type methods to Ara-bidopsis microarray gene expression data to ï¬nd the strongly signiï¬cant genes to distinguish two groups.Keywords: Adaptive Lasso, elastic net, fused lasso, high-dimensional data, lasso, ridge. 1. Introduction High-dimensional data refers to a situation where the number of unknown parameters p are estimatedto be larger than the number of samples n in the data ( p >> n ). High-dimensional data arise in theareas like information technology, bioinformatics, astronomy and brain research. Classical statisticalinference cannot be used for high-dimensional problems. High-dimensional statistical inference isimpossible without additional assumptions or restrictions to a certain class of models. For example,least-squaresï¬ttingofalinearmodelhavingmanyunknownparametersthanobservationsisill-posed.A well-posed framework for ï¬tting is based on assuming structural smoothness. Shifting the focusfromsmoothnesstosparsityforhigh-dimensionaldataopensthewayformanymoreapplicationsthatinvolve complex data.The lasso, proposed by Tibshirani (1996), is an acronym for Least Absolute Shrinkage and Selec-tion Operator. The lasso estimates a vector of regression coeï¬ƒcients by minimizing the residual sumof squares subject to a constraint on",2014,Communications for Statistical Applications and Methods
Estimation of sensitivity coefficient based on lasso-type penalized linear regression,ABSTRACTWe proposed the penalized regression â€˜adaptive smooth-lassoâ€™ for the estimation of sensitivity coefficients of the neutronics parameters. The proposed method utilizes the variation of the m...,2018,Journal of Nuclear Science and Technology
Using empirical covariance matrix in enhancing prediction accuracy of linear models with Missing Information,"Inference and Estimation in Missing Information (MI) scenarios are important topics in Statistical Learning Theory and Machine Learning (ML). In ML literature, attempts have been made to enhance prediction through precise feature selection methods. In sparse linear models, LASSO is well-known in extracting the desired support of the signal and resisting against noisy systems. When sparse models are also suffering from MI, the sparse recovery and inference of the missing models are taken into account simultaneously. In this paper, we will introduce an approach which enjoys sparse regression and covariance matrix estimation to improve matrix completion accuracy, and as a result enhancing feature selection preciseness which leads to reduction in prediction Mean Squared Error (MSE). We will compare the effect of employing covariance matrix in enhancing estimation accuracy to the case it is not used in feature selection. Simulations show the improvement in the performance as compared to the case where the covariance matrix estimation is not used.",2017,2017 International Conference on Sampling Theory and Applications (SampTA)
Neural networks versus Logistic regression for 30â€‰days all-cause readmission prediction,"Heart failure (HF) is one of the leading causes of hospital admissions in the US. Readmission within 30 days after a HF hospitalization is both a recognized indicator for disease progression and a source of considerable financial burden to the healthcare system. Consequently, the identification of patients at risk for readmission is a key step in improving disease management and patient outcome. In this work, we used a large administrative claims dataset to (1) explore the systematic application of neural network-based models versus logistic regression for predicting 30 days all-cause readmission after discharge from a HF admission, and (2) to examine the additive value of patientsâ€™ hospitalization timelines on prediction performance. Based on data from 272,778 (49% female) patients with a mean (SD) age of 73 years (14) and 343,328 HF admissions (67% of total admissions), we trained and tested our predictive readmission models following a stratified 5-fold cross-validation scheme. Among the deep learning approaches, a recurrent neural network (RNN) combined with conditional random fields (CRF) model (RNNCRF) achieved the best performance in readmission prediction with 0.642 AUC (95% CI, 0.640â€“0.645). Other models, such as those based on RNN, convolutional neural networks and CRF alone had lower performance, with a non-timeline based model (MLP) performing worst. A competitive model based on logistic regression with LASSO achieved a performance of 0.643 AUC (95% CI, 0.640â€“0.646). We conclude that data from patient timelines improve 30 day readmission prediction, that a logistic regression with LASSO has equal performance to the best neural network model and that the use of administrative data result in competitive performance compared to published approaches based on richer clinical datasets.",2019,Scientific Reports
LESS: a model-based classifier for sparse subspaces,"In this paper, we specifically focus on high-dimensional data sets for which the number of dimensions is an order of magnitude higher than the number of objects. From a classifier design standpoint, such small sample size problems have some interesting challenges. The first challenge is to find, from all hyperplanes that separate the classes, a separating hyperplane which generalizes well for future data. A second important task is to determine which features are required to distinguish the classes. To attack these problems, we propose the LESS (lowest error in a sparse subspace) classifier that efficiently finds linear discriminants in a sparse subspace. In contrast with most classifiers for high-dimensional data sets, the LESS classifier incorporates a (simple) data model. Further, by means of a regularization parameter, the classifier establishes a suitable trade-off between subspace sparseness and classification accuracy. In the experiments, we show how LESS performs on several high-dimensional data sets and compare its performance to related state-of-the-art classifiers like, among others, linear ridge regression with the LASSO and the support vector machine. It turns out that LESS performs competitively while using fewer dimensions.",2005,IEEE Transactions on Pattern Analysis and Machine Intelligence
Blood-based multi-tissue gene expression inference with Bayesian ridge regression.,"MOTIVATION
Gene expression profiling is widely used in basic and cancer research but still not feasible in many clinical applications because tissues such as brain samples are difficult and not ethnical to collect. Gene expression in uncollected tissues can be computationally inferred using genotype and eQTLs. No methods can infer unmeasured gene expression of multiple tissues with single tissue gene expression profile as input.


RESULTS
We here present a Bayesian ridge regression based method (B-GEX) to infer gene expression profiles of multiple tissues from blood gene expression profile. For each gene in a tissue, a low dimensional feature vector was extracted from whole blood gene expression profile by feature selection. We used GTEx RNAseq data of16 tissues to train inference models to capture the cross-tissue expression correlations between each target gene in a tissue and its preselected feature genes in peripheral blood. We compared B-GEX with Least Square Regression, LASSO Regression and Ridge Regression. B-GEX outperforms the other three models in most tissues in terms of Mean Absolute Error, Pearson correlation coefficient and Root Mean Squared Error. Moreover, B-GEX infers expression level of tissue-specific genes as well as those of non-tissue-specific genes in all tissues. Unlike previous methods which require genomic features or gene expression profiles of multiple tissues, our model only requires whole blood expression profile as input. B-GEX helps gain insights into gene expressions of uncollected tissues from more accessible data of blood.


AVAILABILITY
B-GEX is available at https://github.com/xuwenjian85/B-GEX.


SUPPLEMENTARY INFORMATION
Supplementary data are available at Bioinformatics online.",2020,Bioinformatics
Volatile organic compounds increase the likelihood of detecting malignant pleural mesothelioma,"Background: Globally, 125 million people are still exposed to asbestos and at risk for developing malignant pleural mesothelioma (MPM). Since MPM is diagnosed at advanced stage due to non-specific symptoms and investigations, it is thought that only an early diagnosis will improve patient9s outcome (van Meerbeeck et al, 2011). Breathomics has emerged as a new research field, allowing to detect breath volatile organic compounds (VOCs) which can be used as non-invasive markers for MPM (Lamote et al, 2014). Aim: We investigated the effect of breath analysis added to clinical variables for MPM diagnosis. Methods: Alveolar air was sampled from 23 MPM patients, 10 healthy asbestos-exposed individuals and 12 healthy non-exposed persons after fasting for 2 hours using the BioScout Multicapillary Column/Ion Mobility Spectrometer (MCC/IMS, B&S Analytik, Germany). VOCs were visually selected and their analysis was done by LASSO regression in R. The added value of these VOCs on the diagnostic performance of clinical variables for MPM was compared by ROC-analysis. Results: Modeling smoking status, asbestos exposure and gender did not result in discriminating MPM patients from controls. Adding VOCs to the model increased the AUCROC from 0.52 to 0.71, the diagnostic accuracy from 58% to 71%, the sensitivity from 65% to 87% and the specificity from 50% to 55%. Positive (PPV) and negative predictive values (NPV) increased from 0.58 to 0.67 and from 0.58 to 0.80 respectively. Conclusion: The large increase in accuracy, sensitivity and NPV of the diagnostic model when including VOCs suggests the possibility to use breath analysis as a step up tool in order to rule out MPM.",2015,European Respiratory Journal
Efficient methods for estimating constrained parameters with applications to lasso logistic regression.,"Fitting logistic regression models is challenging when their parameters are restricted. In this article, we first develop a quadratic lower-bound (QLB) algorithm for optimization with box or linear inequality constraints and derive the fastest QLB algorithm corresponding to the smallest global majorization matrix. The proposed QLB algorithm is particularly suited to problems to which EM-type algorithms are not applicable (e.g., logistic, multinomial logistic, and Cox's proportional hazards models) while it retains the same EM ascent property and thus assures the monotonic convergence. Secondly, we generalize the QLB algorithm to penalized problems in which the penalty functions may not be totally differentiable. The proposed method thus provides an alternative algorithm for estimation in lasso logistic regression, where the convergence of the existing lasso algorithm is not generally ensured. Finally, by relaxing the ascent requirement, convergence speed can be further accelerated. We introduce a pseudo-Newton method that retains the simplicity of the QLB algorithm and the fast convergence of the Newton method. Theoretical justification and numerical examples show that the pseudo-Newton method is up to 71 (in terms of CPU time) or 107 (in terms of number of iterations) times faster than the fastest QLB algorithm and thus makes bootstrap variance estimation feasible. Simulations and comparisons are performed and three real examples (Down syndrome data, kyphosis data, and colon microarray data) are analyzed to illustrate the proposed methods.",2008,Computational statistics & data analysis
A Prototype Knockoff Filter for Group Selection with FDR Control,"In many applications, we need to study a linear regression model that consists of a response variable and a large number of potential explanatory variables and determine which variables are truly associated with the response. In 2015, Barber and Candes introduced a new variable selection procedure called the knockoff filter to control the false discovery rate (FDR) and proved that this method achieves exact FDR control. In this paper, we propose a prototype knockoff filter for group selection by extending the Reid-Tibshirani prototype method. Our prototype knockoff filter improves the computational efficiency and statistical power of the Reid-Tibshirani prototype method when it is applied for group selection. In some cases when the group features are spanned by one or a few hidden factors, we demonstrate that the PCA prototype knockoff filter outperforms the Dai-Barber group knockoff filter. We present several numerical experiments to compare our prototype knockoff filter with the Reid-Tibshirani prototype method and the group knockoff filter. We have also conducted some analysis of the knockoff filter. Our analysis reveals that some knockoff path method statistics, including the Lasso path statistic, may lead to loss of power for certain design matrices and a specially designed response even if their signal strengths are still relatively strong.",2019,Information and Inference: A Journal of the IMA
Oracle model selection for nonlinear models based on weighted composite quantile regression accelerated failure time model,"In this paper we propose a weighted composite quantile regression (WCQR) estimation approach and study model selection for nonlinear models with a diverging number of parameters. The WCQR is augmented using a data-driven weighting scheme. With the error distribution unspecified, the proposed estimators share robustness from quantile regression and achieve nearly the same efficiency as the oracle maximum likelihood estimator for a variety of error distributions including the normal, mixed-normal, Student's t, Cauchy distributions, etc. Based on the proposed WCQR, we use the adaptive-LASSO and SCAD regularization to simultaneously estimate parameters and select models. Under regularity conditions, we establish asymptotic equivalency of the two model selection methods and show that they perform as well as if the correct submodels are known in advance. We also suggest an algorithm for fast implementation of the proposed methodology. Simulations are conducted to compare different estimators, and an example is used to illustrate their performance.",2012,Statistica Sinica
Positive graphical lasso estimation of sparse inverse covariance matrices,"We explore the possibility of estimating sparse inverse covariance matrices when for scientific reasons the covariance matrix is restricted to be a non-negative matrix. The process mirrors the graphical lasso process developed by Friedman and others (2008) that did not have this additional constraint. Accordingly, the Lasso procedure is done through coordinate descent. To easily add the constraint, we modified the LARS function created by Efron and others (2004) to perform positive Lasso (pLasso) estimation. The process is demonstrated on several time series generated datasets to clearly show the effectiveness and limitations. Introduction Recent work into mapping gene regulatory networks has led to the use of Fortuinâ€“Kasteleynâ€“ Ginibre (FKG) inequalities to identify unexpected correlations. These correlations can be unexpected for various scientific reasons. However, advancing technology combined with practical/financial constraints gives rise to systems with n (~40) â‰ª p (~10,000). For example, n could be the number of gene expression samples, and p could be the number of genes for which gene expression is measured. Additionally, most of these genes will be conditionally uncorrelated. The graphical Lasso algorithm developed by Friedman and others (2008) was made to deal with this estimation of sparse inverse covariance matrices. However, the desire to eliminate the unexpected correlations from networks results in a simple constraint on this estimation problem. We develop a similar and easy to implement algorithm, utilizing previous work, for performing estimation under these conditions. Estimation of Î£ Let Î˜ = Î£ and S be the sample covariance matrix. The penalized log-likelihood is then ln|Î˜| âˆ’ tr(SÎ˜) âˆ’ Ïâ€–Î˜â€–1 (1) Paul Logan Masters Project Oregon State University 2 where â€–Î˜â€–1 = âˆ‘ |Î˜ij| i,j . We wish to find the positive semi-definite matrix Î˜ that maximizes this function. Banerjee and others (2007) showed that this is convex and instead outlined a method for estimating Î£. It is shown that the problem can be solved in block coordinate descent fashion. If W = Î˜ is the estimate of Î£, then we can partition W and S. W = ( W11 w12 w12 T w22 ) , S = ( S11 s12 s12 T s22 ) (2) Then the solution for each row and column is w12 = argminy{y W11 y âˆ¶ â€–y âˆ’ s12â€–âˆž â‰¤ Ï} . (3) By convex duality, this is equivalent to solving min Î² { 1 2 â€–W11 1 2 â„ Î² âˆ’ bâ€– 2 + Ïâ€–Î²â€–1} (4) with b = W11 âˆ’1/2 s12. Then, w12 = W11Î² is the solution to equation (3), where Î² is the solution to equation (4). Equivalence Verification To maximize the log-likelihood, we take a matrix derivative with respect to Î˜ and set equal to zero. We get W âˆ’ S âˆ’ ÏÎ“ = 0 , (5) with Î“ij = sign(Î˜ij) if Î˜ij â‰  0 and Î“ij âˆˆ [âˆ’1, 1] if Î˜ij = 0. The upper right component of this equation gives w12 âˆ’ s12 âˆ’ ÏÎ³12 = 0 . (6) To perform the minimization in equation (4), first note that 1 2 â€–W11 1 2 â„ Î² âˆ’ bâ€– 2 + Ïâ€–Î²â€–1 = 1 2 Î²W11Î² âˆ’ Î² W11 1 2 b + 1 2 bb + Ï âˆ‘ |Î²i| i (7) Therefore, taking the derivative of equation (7) with respect to Î² and setting equal to zero gives W11Î² âˆ’ s12 + ÏÎ½ = 0 , (8) with Î½ = sign(Î²). Since WÎ˜ = I, we know that W11Î¸12 + w12Î¸22 = 0, and thus Î¸12 = âˆ’Î¸22W11 w12. Then, Î³12 = sign(Î¸12) = âˆ’sign(Î¸22W11 w12) = âˆ’sign(W11 w12) = âˆ’sign(Î²) = âˆ’Î½, since Î¸22 > 0. Also, we know w12 = W11Î², thus equations (6) and (8) are equivalent. Algorithm From equation (5) it can be seen that wii = sii + Ï since Î¸ii > 0 âˆ€ i. Equation (4) is effectively Lasso regression with X = W11 1/2 and y = b = W11 âˆ’1/2 s12. Starting with W = S + ÏI, recursively solve Paul Logan Masters Project Oregon State University 3 for and replace each row/column of W, w12, by inputting the rest of W, W11, and the corresponding row/column of S, s12, through Lasso regression until convergence. FKG Inequality and MTP2 There are many biological contexts, particularly in genetics, where certain types of correlation cannot be physically possible. In these situations, if the data suggests a physically inconsistent correlation, we know it is due to noise. These occurrences are referred to as unexpected correlations. Mathematically, these are any correlations that do not satisfy the Fortuinâ€“Kasteleynâ€“Ginibre (FKG) inequalities. Fortuin and others (1971) state that if the FKG condition, Î¼(x âˆ§ y)Î¼(x âˆ¨ y) â‰¥ Î¼(x)Î¼(y), is met for some non-negative function Î¼ and x, y in a finite distributive lattice X, then if f and g are monotonically increasing functions the FKG inequality states [âˆ‘ f(x)g(x)Î¼(x) xâˆˆX ][âˆ‘ Î¼(x) xâˆˆX ] â‰¥ [âˆ‘ f(x)Î¼(x) xâˆˆX ][âˆ‘ g(x)Î¼(x) xâˆˆX ]. (9) If Î¼(x) is a probability measure, this simply becomes Cov(f(x), g(x)) â‰¥ 0. (10) Rinott and Scarsini (2006) state that a distribution whose probability measure fulfills the FKG condition is equivalently Multivariate Totally Positive of order 2 (MTP2). This is important because Karlin and Rinott (1980) showed that when a density is MTP2, then all off-diagonal elements of Î˜ = Î£ are non-positive. This then implies that all elements of W are non-negative. Estimation of positive Î£ The construction of the previous algorithm does not break down with the additional condition that w12 â‰¥ 0, since convexity remains. The only change that must be made is that the solution to the Lasso regression must be non-negative, Î² â‰¥ 0. Augmentation of the Lasso algorithm into a Positive Lasso (pLasso) regression is not simple. However, both Lasso and pLasso are specific examples of Least Angle Regression (LAR). Efron and others (2004) describe the method by which LAR is used to calculate Lasso estimates and list the few changes necessary to instead calculate pLasso estimates. New Algorithm The LAR function in R was edited so that the Lasso option instead calculated pLasso estimates. The previous algorithm was then followed with a pLasso solution instead of a Lasso solution for Î². To remove bias in particular locations in Î£ that may arise from the order in which rows/columns are updated, the order is randomly selected. This new algorithm is named pLarso. Paul Logan Masters Project Oregon State University 4 Example 1 n = 1000, p = 10, yt = 0.6ytâˆ’1 + Îµt , Îµt âˆ¼ N (0, 1 4 ) Î£1âˆ’2,1âˆ’2 âˆ’1 = 1 1âˆ’Ï2 ( 1 âˆ’Ï âˆ’Ï 1 + Ï ) = ( 1.5625 âˆ’0.9375 âˆ’0.9375 2.1250 ) The above AR(1) time series was simulated using arima.sim, where n is the number of times series simulated and p is the length of each time series. Estimates of Î£ are found in Tables 1-3 in the Appendix. While gLasso results in some sparsity, the pLarso algorithm results in the sparsest estimate. The LAR algorithm results in no sparsity, but slightly better (less biased) estimates on the tri-diagonal. Example 2 n = 10, p = 20, yt = 0.6ytâˆ’1 + Îµt, Îµt âˆ¼ N (0, 1 4 ) Î£1âˆ’2,1âˆ’2 âˆ’1 = 1 1 âˆ’ Ï2 ( 1 âˆ’Ï âˆ’Ï 1 + Ï ) = ( 1.5625 âˆ’0.9375 âˆ’0.9375 2.1250 ) The same series is simulated in Example 2, but longer and with fewer replications. In this case S is not full rank and thus not invertible. Left half of estimates of Î£ are found in Tables 4-6 in the Appendix. In terms of sparsity, the results roughly match Example 1. However, actual estimates are now all inflated. Of course, for model selection (or network mapping) this is not a concern. Example 3 n = 1000, p = 10, yt = 0.6ytâˆ’1 âˆ’ 0.2ytâˆ’2 + Îµt , Îµt âˆ¼ N (0, 1 4 ) Î£1âˆ’3,1âˆ’3 âˆ’1 = ( 1.3889 âˆ’0.8333 0.2778 âˆ’0.8333 1.8889 âˆ’1.0000 0.2778 âˆ’1.0000 1.9444 ) An AR(2) time series was chosen for Example 3 to specifically have positive off-diagonal elements in Î£. Estimates of Î£ are found in Tables 7-9 in the Appendix. Relative sparsity among the methods is similar to Example 1. However, the elements that should be equal to 0.2778 have been suppressed to zero by the pLarso algorithm. Acknowledgements I would like to acknowledge Prof. Yevgeniy Kovchegov of the Department of Mathematics and Prof. Andriy Morgun of the College of Pharmacy, Center for Genomics Research & Biocomputing, both at Oregon State University, for the inspiration to tackle the topic and for support. I would also like to Paul Logan Masters Project Oregon State University 5 acknowledge Prof. Debashis Mondal for guiding me through this project. This work was supported by the following grants: NSF DMS-1412557 (PI: Yevgeniy Kovchegov, co-PI: Andriy Morgun) and NSF DMS1519890 (PI: Debashis Mondal). References Bannerjee, O., Ghaoui, L. E., and dâ€™Aspremont, A. (2007). Model selection through sparse maximum likelihood estimation. Journal of Machine Learning Research 101. Efron, B., Hastie, T., Johnstone, I., and Tibshirani, R. (2004). Least Angle Regression. Annals of Statistics 32 (2). Fortuin, C. M., Kasteleyn, P. W., and Ginibre, J. (1971). Correlation inequalities on some partially ordered sets. Communications in Mathematical Physics 22 (2). Friedman, J., Hastie, T., and Tibshirani R. (2008). Sparse inverse covariance estimation with the graphical lasso. Biostatistics 9. Karlin, S. and Rinott, Y. (1980). Classes of orderings of measures and related correlation inequalities. M. Multivariate reverse rule distributions. Journal of Multivariate Analysis 10. Rinott, Y. and Scarsini, M. (2006). Total positivity order and the normal distribution. Journal of Multivariate Analysis 97. Paul Logan Masters Project Oregon State University 6 1.5056 -0.8674 0 -0.0238 -0.0194 0 -0.0010 0 0 0 -0.8674 2.0031 -0.8454 -0.0349 0 0 0 0 0 0 0 -0.8454 1.9612 -0.8272 0 0 0 0 0 0 -0.0238 -0.0349 -0.8272 1.9850 -0.8460 -0.0091 -0.0115 -0.0215 0 0 -0.0194 0 0 -0.8460 2.0249 -0.9069 0 0 0 0 0 0 0 -0.0091 -0.9069 1.9947 -0.8134 0 0 0 -0.0010 0 0 -0.0115 0 -0.8134 1.9847 -0.8990 0 0 0 0 0 -0.0215 0 0 -0.8990 2.0698 -0.9138 0 0 0 0 0 0 0 0 -0.9138 2.0441 -0.8744 0 0 0 0 0 0 0 0 -0.8744 1.4999 Table 1: Inverse of output (estimate of Î£) of pLarso algorithm from Example 1 1.4809 -0.8397 0 -0.0091 -0.0382 0 -0.0097 0 -0.0024 0.0173 -0.8397 1.9551 -0.8148 -0.0663 0.0412 0 0 0.0313 0 -0.0081 0 -0.8148 1.9154 -0.8007 0 0 0 0.003 0 0.0642 -0.0091 -0.0663 -0.8007 1.9527 -0.8263 -0.0116 -0.0072 -0.0508 0 0.0021 -0.0383 0.0412 0 -0.8263 1.972 -0.8746 0 0 0 0.0117 0 0 0 -0.0115 -0.8746 1.9486 -0.8006 -0.0049 0.02 0.0398 -0.0095 ",2016,
Germ Cell-Specific Gene 1-Like Protein Regulated by Splicing Factor CUGBP Elav-Like Family Member 5 and Primary Bile Acid Biosynthesis are Prognostic in Glioblastoma Multiforme,"Background Alternative splicing (AS) modifies 92-94% human genes, abnormal splicing events might relate to tumor development and invasion. Glioblastoma Multiforme (GBM) is a fatal, invasive, and malignant tumor in nervous system. The recurrence and development leads to poor prognosis. However, few studies have focused on AS in GBM. Methods RNA-seq and Alternative splicing events (ASEs) data of GBM samples were downloaded from The Cancer Genome Atlas (TCGA) and TCGASpliceSeq databases, respectively. Firstly, the Cox regression analysis was utilized to identify the overall survival splicing events (OS-SEs). Secondly, a multivariable model was applied to access the prognostic value of risk score. Then, we constructed a co-expressed network between splicing factors (SFs) and overall survival alternative splicing events (OS-SEs). Additionally, to explore the relationship between the potential prognostic signaling pathways and OS-SEs, we constructed a network between these pathways and OS-SEs. Ultimately, to better explain the results, validations from multi-dimension platforms were applied. Results In the first step, 1,062 OS-SEs were selected by Cox regression. Then, 11 OS-SEs were integrated in a multivariate model by Lasso regression. The area under the curve (AUC) of receiver operator characteristic (ROC) curve was 0.861. In addition, the risk score generated from the multivariate model was confirmed to be an independent prognostic factor (P < 0.001). What's more, in the network of SFs and ASEs, CELF5 significantly regulated GSG1L|35696|AP and GSG1L|35698|AP (P < 0.001, R = 0.511 and = -0.492). Additionally, GSG1L|35696|AP (P = 0.006) and GSG1L|35698|AP (P = 0.007) showed a significant relationship with cancer status. Eventually, KEGG pathways related to prognosis of GBM were selected by GSVA. The primary bile acid synthesis (P < 0.001, R = 0.420) was the significant pathway co-expressed with Germ Cell-Specific Gene 1-Like Protein (GSG1L). Conclusions Based on the comprehensive bioinformatics analysis, we proposed that aberrant splicing factor CUGBP Elav-like family member 5 (CELF5) significantly, positively and negatively, regulated ASE of GSG1L, and the primary bile acid synthesis pathway might play an important role in tumorigenesis and prognosis of GBM.",2019,Frontiers in Genetics
Copula-Based Multi-Dimensional Crowdsourced Data Synthesis and Release with Local Privacy,"Various paradigms, based on differential privacy, have been proposed to release a privacy-preserving dataset with statistical approximation. Nonetheless, most existing schemes are limited when facing highly correlated attributes, and cannot prevent privacy threats from untrusted servers. In this paper, we propose a novel Copula- based scheme to efficiently synthesize and release multi-dimensional crowdsourced data with local differential privacy. In our scheme, each participant's (or user's) data is locally transformed into bit strings based on a randomized response technique, which guarantees a participant's privacy on the participant (user) side. Then, Copula theory is leveraged to synthesize multi-dimensional crowdsourced data based on univariate marginal distribution and attribute dependence. Univariate marginal distribution is estimated by the Lasso-based regression algorithm from the aggregated privacy- preserving bit strings. Dependencies among attributes are modeled as multivariate Gaussian Copula, of which parameter is estimated by Pearson correlation coefficients. We conduct experiments to validate the effectiveness of our scheme. Our experimental results demonstrate that our scheme is effective for the release of multi-dimensional data with local differential privacy guaranteed to distributed participants.",2017,GLOBECOM 2017 - 2017 IEEE Global Communications Conference
"Convex Regression: Theory, Practice, and Applications","This thesis explores theoretical, computational, and practical aspects of convex (shape-constrained) regression, providing new excess risk upper bounds, a comparison of convex regression techniques with theoretical guarantee, a novel heuristic training algorithm for max-affine representations, and applications in convex stochastic programming. The new excess risk upper bound is developed for the general empirical risk minimization setting without any shape constraints, and provides a probabilistic guarantee for cases with unbounded hypothesis classes, targets, and noise models. The strength of the general result is demonstrated by applying it to linear regression under the squared loss both for lasso and ridge regression, as well as for convex nonparametric least squares estimation, in each case allowing one to obtain near-minimax upper bounds on the risk. Next, cutting plane and alternating direction method of multipliers algorithms are compared for training the max-affine least squares estimators; estimators for which we provide explicit excess risk bounds. These techniques are also extended for the partitioned convex formulation (which is shown to enjoy optimal minimax rates). We also provide an empirical study of various heuristics for solving the non-convex optimization problem underlying the partitioned convex formulation. A novel max-affine estimator is designed, which scales well for large sample sizes and improves the generalization error of current techniques in many cases. Its training time is proportional to the adaptively set model size, making it computationally attractive for estimation problems where the target can be efficiently approximated by max-affine functions. Realistic convex regression applications are synthetized for the convex stochastic programming framework such as an energy storage optimization using a solar source with an Economy 7 tariff pricing model, as well as a multi-product assembly problem of operating a beer brewery.",2016,
"DurabilitÃ© de lâ€™offre et valeur nutritive des fourrages commercialisÃ©s en zone urbaine de Bobo-Dioulasso, Burkina Faso","La commercialisation des especes fourrageres est une activite economique significative indispensable au maintien des elevages urbains et periurbains. Les questions qui se posent concernent (i) la qualite nutritive des fourrages secs, notamment les residus de culture commercialises, (ii) la regularite de lâ€™approvisionnement des marches et des elevages en fonction des saisons et (iii) les pratiques de recolte des fourrages verts a partir des milieux naturels pour approvisionner les villes. De decembre 2007 a mars 2008, nous avons realise une etude dont lâ€™objectif etait dâ€™inventorier les fourrages commercialises et leurs utilisations dans la ville de Bobo-Dioulasso au Burkina Faso, de decrire lâ€™organisation de la filiere et de determiner la qualite nutritive des fourrages. Des prospections dans 26 sites de production et de prelevement des fourrages, ainsi que des interviews semi-structurees, ont ete realisees avec 10 agriculteurs periurbains, 20 commercants de betail et 68 vendeurs dans 15 marches dâ€™aliments fourragers permanents de la ville de Bobo-Dioulasso. Lâ€™analyse de la composition chimique de 17 especes fourrageres sur 30 identifiees a ete realisee. Dâ€™une part, lâ€™etude a revele que le systeme dâ€™exploitation des ressources, qui est en fait un systeme de cueillette, ne sera certainement pas viable a moyen terme car certaines especes fourrageres sont menacees de regression, voire de disparition. Dâ€™autre part, lâ€™etude a montre que les principales especes fourrageres commercialisees dans la zone urbaine de Bobo-Dioulasso avaient des teneurs en nutriments appreciables pour les ruminants domestiques des elevages urbains et periurbains. Cependant, il est necessaire que les acteurs de cette filiere soient mieux organises pour assurer la durabilite de lâ€™approvisionnement de la ville en fourrages et que des recherches pour la sauvegarde et la gestion appropriee des especes en voie de disparition soient entreprises pour accompagner les acteurs.",2016,Cahiers Agricultures
Local modeling approaches for estimating soil properties in selected Indian soils using diffuse reflectance data over visible to near-infrared region,"Abstract Robust calibration algorithms are needed for the accurate assessment of soil properties in the diffuse reflectance spectroscopy (DRS) approach. Despite several studies on different calibration algorithms, the prediction accuracy of soil properties using DRS need to be improved. Specifically, the utility of local modeling approaches for small spectral libraries is less examined compared with global modeling approaches. In this study, we compared global modeling approaches such as partial-least-squares regression (PLSR), lasso, ridge regression with several locally-weighted PLSR (PLSR LW ) approaches. We also examined seven different distance measures: Euclidean distance, covariance-based distance, correlation-based distance, surface difference spectrum, information-based distance, optimized principal component Mahalanobis, and locally-linear embeddings used in the PLSR LW approach for their effectiveness in modeling soil properties using DRS. A total of 954 soil samples were collected from three different states of India: West Bengal, Odisha, and Karnataka. Five soil properties such as sand content, clay content, soil organic carbon (SOC) content, extractable iron (Fe) content and extractable zinc (Zn) content were predicted using reflectance spectra over 350â€“2500â€¯nm. Root-mean-squared error (RMSE) and the coefficient of determination (R 2 ) were used as performance statistics. Among the global modeling approaches, lasso performed better than the PLSR although it is computationally more intensive than the PLSR. In general, the correlation-based PLSR LW performed significantly better than the global approaches. Specifically, the test R 2 values increased from 0.66 to 0.72 for prediction of sand content, from 0.59 to 0.70 for prediction of SOC content, and from 0.70 to 0.74 for prediction of Fe content by using the PLSR LW over PLSR. We also used depth of absorption peak of spectra at approximately 1400, 1900 and 2200â€¯nm for mineralogical characterization of soil samples. The results suggested that the improvement in prediction accuracy of soil properties using the PLSR LW was achieved because calibration samples which had same mineralogy as the test sample were given higher weights. These results suggest that the prediction accuracy of soil properties may also be improved in small spectral libraries if an appropriate local modeling scheme is selected.",2018,Geoderma
Bayesian Hyperâ€lassos with Nonâ€convex Penalization,"Summary 
 
The Lasso has sparked interest in the use of penalization of the log-likelihood for variable selection, as well as for shrinkage. We are particularly interested in the more-variables-than-observations case of characteristic importance for modern data. The Bayesian interpretation of the Lasso as the maximum a posteriori estimate of the regression coefficients, which have been given independent, double exponential prior distributions, is adopted. Generalizing this prior provides a family of hyper-Lasso penalty functions, which includes the quasi-Cauchy distribution of Johnstone and Silverman as a special case. The properties of this approach, including the oracle property, are explored, and an EM algorithm for inference in regression problems is described. The posterior is multi-modal, and we suggest a strategy of using a set of perfectly fitting random starting values to explore modes in different regions of the parameter space. Simulations show that our procedure provides significant improvements on a range of established procedures, and we provide an example from chemometrics.",2011,Australian & New Zealand Journal of Statistics
Hyperspectral Leaf Reflectance as Proxy for Photosynthetic Capacities: An Ensemble Approach Based on Multiple Machine Learning Algorithms,"Global agriculture production is challenged by increasing demands from rising population and a changing climate, which may be alleviated through development of genetically improved crop cultivars. Research into increasing photosynthetic energy conversion efficiency has proposed many strategies to improve production but have yet to yield real-world solutions, largely because of a phenotyping bottleneck. Partial least squares regression (PLSR) is a statistical technique that is increasingly used to relate hyperspectral reflectance to key photosynthetic capacities associated with carbon uptake (maximum carboxylation rate of Rubisco, Vc,max ) and conversion of light energy (maximum electron transport rate supporting RuBP regeneration, Jmax ) to alleviate this bottleneck. However, its performance varies significantly across different plant species, regions, and growth environments. Thus, to cope with the heterogeneous performances of PLSR, this study aims to develop a new approach to estimate photosynthetic capacities. A framework was developed that combines six machine learning algorithms, including artificial neural network (ANN), support vector machine (SVM), least absolute shrinkage and selection operator (LASSO), random forest (RF), Gaussian process (GP), and PLSR to optimize high-throughput analysis of the two photosynthetic variables. Six tobacco genotypes, including both transgenic and wild-type lines, with a range of photosynthetic capacities were used to test the framework. Leaf reflectance spectra were measured from 400 to 2500 nm using a high-spectral-resolution spectroradiometer. Corresponding photosynthesis vs. intercellular CO2 concentration response curves were measured for each leaf using a leaf gas-exchange system. Results suggested that the mean R 2 value of the six regression techniques for predicting Vc,max (Jmax ) ranged from 0.60 (0.45) to 0.65 (0.56) with the mean RMSE value varying from 47.1 (40.1) to 54.0 (44.7) Î¼mol m-2 s-1. Regression stacking for Vc,max (Jmax ) performed better than the individual regression techniques with increases in R 2 of 0.1 (0.08) and decreases in RMSE by 4.1 (6.6) Î¼mol m-2 s-1, equal to 8% (15%) reduction in RMSE. Better predictive performance of the regression stacking is likely attributed to the varying coefficients (or weights) in the level-2 model (the LASSO model) and the diverse ability of each individual regression technique to utilize spectral information for the best modeling performance. Further refinements can be made to apply this stacked regression technique to other plant phenotypic traits.",2019,Frontiers in Plant Science
Interpretable regularized class association rules algorithm for classification in a categorical data space,"Abstract Using association rules in classification is a great success which produces high accuracy classifiers. Even so, the principal advantage of the associative classifiers lies in interpretation. However, pruning the useless rules among the huge set of the mined rules as well as combining them to build a classifier remains a subject for improvement and further research. In this paper, we introduce a new algorithm to build a classifier based on Regularized Class Association Rules in a categorical data space called RCAR. The characteristic of this algorithm is, therefore, threefold: First, mining an exhaustive set of Class Association Rules (CARs) according to a predefined values of support and confidence thresholds. Second, applying a regularized logistic regression algorithm with Lasso penalty on the rules space to build a model that predicts the conditional probability of the existence of the outcome. Useless rules are pruned thanks to the selective nature of Lasso regularization. Third, organizing and visualizing the CARs which survive the first step of pruning by Lasso regularization using metarules. An optional step of pruning could be undertaken on the basis of the metarules and subject knowledge. Likewise, the empirical results indicate that RCAR gives comparable accuracy against Random Forest and GBM.",2019,Inf. Sci.
