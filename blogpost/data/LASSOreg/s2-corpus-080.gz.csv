title,abstract,year,journal
Modeling daily guest count prediction,"We present a novel method for analyzing data with temporal variations. In particular, the problem of modeling daily guest count forecast for a restaurant with more than 60 chain stores is presented. We study the transaction data collected from each store, perform data preprocessing and feature constructions for the data. We then discuss different forecasting techniques based on data mining and machine learning techniques. A new modeling algorithm SW-LAR-LASSO is proposed. We compare multiple regression model, poisson regression model, and the proposed SW-LAR-LASSO model for prediction. Experimental results show that the approach of combining sliding windows and LAR-LASSO produces the best results with the highest precision. This approach can also be applied to other areas where temporal variations exist in the data.",2017,
Estimation for counting processes with high-dimensional covariates,"Nous cherchons a estimer lâ€™intensite de sauts dâ€™un processus de comptage en presence dâ€™un grand nombre de covariables. Nous proposons deux approches. Dâ€™abord, nous considerons une intensite non-parametrique et nous lâ€™estimons par le meilleur modele de Cox etant donne deux dictionnaires de fonctions. Le premier dictionnaire est utilise pour construire une approximation du logarithme du risque de base et le second pour approximer le risque relatif. Nous considerons une procedure Lasso, specifique a la grande dimension, pour estimer simultanement les deux parametres inconnus du meilleur modele de Cox approximant lâ€™intensite. Nous prouvons des inegalites oracles non-asymptotiques pour lâ€™estimateur Lasso obtenu. Dans une seconde partie, nous supposons que lâ€™intensite satisfait un modele de Cox. Nous proposons deux procedures en deux etapes pour estimer les parametres inconnus du modele de Cox. La premiere etape est commune aux deux procedures, il sâ€™agit dâ€™estimer le parametre de regression en grande dimension via une procedure Lasso. Le risque de base est ensuite estime soit par selection de modeles, soit par un estimateur a noyau avec une fenetre choisie par la methode de Goldenshluger et Lepski. Nous etablissons des inegalites oracles non-asymptotiques pour les deux estimateurs du risque de base ainsi obtenus. Nous menons une etude comparative de ces estimateurs sur des donnees simulees, et enfin, nous appliquons les procedures implementees a une base de donnees sur le cancer du sein.",2014,
Comparison of the analyses of the XVth QTLMAS common dataset II: QTL analysis,"BackgroundThe QTLMAS XVth dataset consisted of the pedigrees, marker genotypes and quantitative trait performances of 2,000 phenotyped animals with a half-sib family structure. The trait was regulated by 8 QTL which display additive, imprinting or epistatic effects. This paper aims at comparing the QTL mapping results obtained by six participants of the workshop.MethodsDifferent regression, GBLUP, LASSO and Bayesian methods were applied for QTL detection. The results of these methods are compared based on the number of correctly mapped QTL, the number of false positives, the accuracy of the QTL location and the estimation of the QTL effect.ResultsAll the simulated QTL, except the interacting QTL on Chr5, were identified by the participants. Depending on the method, 3 to 7 out of the 8 QTL were identified. The distance to the real location and the accuracy of the QTL effect varied to a large extent depending on the methods and complexity of the simulated QTL.ConclusionsWhile all methods were fairly efficient in detecting QTL with additive effects, it was clear that for non-additive situations, such as parent-of-origin effects or interactions, the BayesC method gave the best results by detecting 7 out of the 8 simulated QTL, with only two false positives and a good precision (less than 1 cM away on average). Indeed, if LASSO could detect QTL even in complex situations, it was associated with too many false positive results to allow for efficient GWAS. GENMIX, a method based on the phylogenies of local haplotypes, also appeared as a promising approach, which however showed a few more false positives when compared with the BayesC method.",2012,BMC Proceedings
Survival Analysis by Penalized Regression and Matrix Factorization,"Because every disease has its unique survival pattern, it is necessary to find a suitable model to simulate followups. DNA microarray is a useful technique to detect thousands of gene expressions at one time and is usually employed to classify different types of cancer. We propose combination methods of penalized regression models and nonnegative matrix factorization (NMF) for predicting survival. We tried L1- (lasso), L2- (ridge), and L1-L2 combined (elastic net) penalized regression for diffuse large B-cell lymphoma (DLBCL) patients' microarray data and found that L1-L2 combined method predicts survival best with the smallest logrank P value. Furthermore, 80% of selected genes have been reported to correlate with carcinogenesis or lymphoma. Through NMF we found that DLBCL patients can be divided into 4 groups clearly, and it implies that DLBCL may have 4 subtypes which have a little different survival patterns. Next we excluded some patients who were indicated hard to classify in NMF and executed three penalized regression models again. We found that the performance of survival prediction has been improved with lower logrank P values. Therefore, we conclude that after preselection of patients by NMF, penalized regression models can predict DLBCL patients' survival successfully.",2013,The Scientific World Journal
Abstract 1027: Multiple Biomarkers for Long-Term Risk Stratification in Patients With Coronary Artery Disease,"Background-Multiple biomarkers have been suggested for risk prediction in coronary artery disease. Results of single and multimarker approaches have remained inconsistent. Methods and Results-We prospectively investigated 12 biomarkers reflecting inflammation (C-reactive protein, growth-differentiation factor (GDF)-15, neopterin), oxidative stress (Cu/Zn-superoxiddismutase), lipid metabolism (apolipoproteins AI, B100), renal function (cystatin C), cardiovascular function and remodeling (copeptin, C-terminal-pro-endothelin-1, mid-regional-pro-adrenomedullin (MR-proADM), midregional-pro-atrial natriuretic peptide (MR-pro-ANP), and N-terminal-pro-B-type natriuretic peptide (Nt-proBNP) in 1781 stable angina patients in relation to non-fatal myocardial infarction and cardiovascular death (n=137) over a median follow-up of 3.6 years. Using Cox regression models and C-indices, the strongest association with outcome in the validation set was observed for MR-proADM, cystatin C, GDF-15, Nt-proBNP, and MR-proANP. We developed two risk scores from forward stepwise variable selection (Nt-proBNP and GDF-15; HR 1.46, 1.12â€“1.91; C-index 0.73), through Lasso method (MR-proADM, MR-proANP, neopterin, GDF-15, Nt-proBNP; HR 1.43, 1.11â€“1.83; C-index 0.73), which performed similar to the top five single markers. Each top single marker and the scores added incremental predictive information beyond the baseline model (all p Conclusions-Comparative analysis of 12 biomarkers revealed MR-proADM, cystatin C, GDF-15, and the natriuretic peptides Nt-proBNP and MR-proANP as the strongest predictors of cardiovascular outcome in stable angina. All five biomarkers offered incremental predictive ability over established risk factors as single markers or incorporated in scores.",2009,Circulation
Clear cell renal cell carcinoma: CT-based radiomics features for the prediction of Fuhrman grade.,"OBJECTIVES
To discriminate low grade (Fuhrman I/II) and high grade (Fuhrman III/IV) clear cell renal cell carcinoma (CCRCC) by using CT-based radiomic features.


METHODS
161 and 99 patients diagnosed with low and high grade CCRCCs from January 2011 to May 2018 were enrolled in this study. 1029 radiomic features were extracted from corticomedullary (CMP), and nephrographic phase (NP) CT images of all patients. We used interclass correlation coefficient (ICC) and the least absolute shrinkage and selection operator (LASSO) regression method to select features, then the selected features were constructed three classification models (CMP, NP and with their combination) to discriminate high and low grades CCRCC. These three models were built by logistic regression method using 5-fold cross validation strategy, evaluated with receiver operating characteristics curve (ROC) and compared using DeLong test.


RESULTS
We found 11 and 24 CMP and NP features were independently significantly associated with the Fuhrman grades. The model of CMP, NP and Combined model using radiomic feature set showed diagnostic accuracy of 0.719 (AUC [area under the curve], 0.766; 95% CI [confidence interval]: 0.709-0.816; sensitivity, 0.602; specificity, 0.838), 0.738 (AUC, 0.818; 95% CI:0.765-0.838; sensitivity, 0.693; specificity, 0.838), 0.777(AUC, 0.822; 95% CI: 0.769-0.866; sensitivity, 0.677; specificity, 0.839). There were significant differences in AUC between CMP model and Combined model (Pâ€‰=â€‰0.0208), meanwhile, the differences between CMP model and NP model, NP model and Combined model reached no significant (Pâ€‰=â€‰0.0844, 0.7915).


CONCLUSIONS
Radiomic features could be used as biomarker for the preoperative evaluation of the CCRCC Fuhrman grades.",2018,European journal of radiology
An Alignment-Free Regression Approach for Estimating Allele-Specific Expression Using RNA-Seq Data,"RNA-seq technology enables large-scale studies of allele-specific expression ASE, or the expression difference between maternal and paternal alleles. Here, we study ASE in animals for which parental RNA-seq data are available. While most methods for determining ASE rely on read alignment, read alignment either leads to reference bias or requires knowledge of genomic variants in each parental strain. When RNA-seq data are available for both parental strains of a hybrid animal, it is possible to infer ASE with minimal reference bias and without knowledge of parental genomic variants. Our approach first uses parental RNA-seq reads to discover maternal and paternal versions of transcript sequences. Using these alternative transcript sequences as features, we estimate abundance levels of transcripts in the hybrid animal using a modified lasso linear regression model. 
 
We tested our methods on synthetic data from the mouse transcriptome and compared our results with those of Trinity, a state-of-the-art de novo RNA-seq assembler. Our methods achieved high sensitivity and specificity in both identifying expressed transcripts and transcripts exhibiting ASE. We also ran our methods on real RNA-seq mouse data from two F1 samples with wild-derived parental strains and were able to validate known genes exhibiting ASE, as well as confirm the expected maternal contribution ratios in all genes and genes on the X chromosome.",2014,
Fused LASSO penalized least absolute deviation estimator for high dimensional linear regression,"The least absolute shrinkage and selection operator (LASSO) has been playing an important role in variable selection and dimensionality reduction for high dimensional linear regression under the zero-mean or Gaussian assumptions of the noises. However, these assumptions may not hold in practice. In this case, the least absolute deviation is a popular and useful method. In this paper, we focus on the least absolute deviation via Fused LASSO, called Robust Fused LASSO, under the assumption that the unknown vector is sparsity for both the coefficients and its successive differences. Robust Fused LASSO estimator does not need any knowledge of standard deviation of the noises or any moment assumptions of the noises. We show that the Robust Fused LASSO estimator possesses near oracle performance, i.e. with large probability, the \begin{document} $\ell_2$ \end{document} norm of the estimation error is of order \begin{document} $O(\sqrt{k(\log p)/n})$ \end{document} . The result is true for a wide range of noise distributions, even for the Cauchy distribution. In addition, we apply the linearized alternating direction method of multipliers to find the Robust Fused LASSO estimator, which possesses the global convergence. Numerical results are reported to demonstrate the efficiency of our proposed method.",2018,"Numerical Algebra, Control and Optimization"
Statistical Inference for Large Scale Data April,"We introduce a sparse and positive definite estimator of the covariance matrix designed for high-dimensional situations in which the variables have a known ordering. Our estimator is the solution to a convex optimization problem that involves a hierarchical group lasso penalty. We show how it can be efficiently computed, compare it to other methods such as tapering by a fixed matrix, and develop several theoretical results that demonstrate its strong statistical properties. Finally, we show how using convex banding can improve the performance of high-dimensional procedures such as linear and quadratic discriminant analysis. 2. Speaker: Andreas Buja, The Wharton School, University of Pennsylvania Title: (1) Large-p Visualization ; (2) Moderate-p Post-Selection Inference Abstract: This talk will be divided into two short talks. (1) Large-p Visualization: Data with large numbers of variables pose a challenge for data exploration and visualization. Facing hundreds of variables, standard tools such as scatterplot matrices and parallel coordinate plots will quickly reach their limit. It may be necessary to abandon detailed visualization of variables and instead show simple summary measures, as in heat maps of correlation tables that are often found in genomics. In this talk we use a modification of heat maps, here called â€œblockplotsâ€, and we demonstrate an associated software tool that is both interactive and dynamic, yet wholly written in R. Called â€œAssociation Navigatorâ€, its basic operation is zooming and panning of large â€œblockplotsâ€ of correlation tables involving hundreds of variables. The tool includes, among other things: (1) display of p-values and missing value patterns in addition to correlations, (2) mark-up facilities to highlight variables and sub-tables as landmarks when navigating the larger table, (3) histograms / barcharts, scatterplots and scatterplot matrices as â€œlensesâ€ into the distributions of variables and variable pairs, as well as several other functionalities. The usefulness of the tool is less in beholding gigantic tables in their entirety and more in searching for interesting association patterns by navigating manageable but numerous and interconnected sub-tables. (2) Moderate-p Post-Selection Inference: Berk et al. (AoS 2013) proposed a stringent approach, called â€œPoSIâ€, to producing statistical inference that is valid after arbitrary variable selection in regression. The approach is controversial because of its conservative nature, yet it is the appropriate method of securing valid statistical inference after what is called p-hacking or p-value hunting. This, however, is not the main subject of the talk. Rather, it is the computational limitations of the PoSI approach. Currently our algorithm can handle up to about p = 20 predictor variables in an unconstrained model search. For â€œsparse PoSIâ€ we can handle up to about p = 80 predictors if model search is limited to model sizes 4 and lower. The algorithm relies both on a deterministic integration and a Monte Carlo simulation. It would be desirable for speeding up the algorithm if we better understood the underlying geometry of predictor adjustment. This part of the talk will therefore end with open questions. This talk will be divided into two short talks. (1) Large-p Visualization: Data with large numbers of variables pose a challenge for data exploration and visualization. Facing hundreds of variables, standard tools such as scatterplot matrices and parallel coordinate plots will quickly reach their limit. It may be necessary to abandon detailed visualization of variables and instead show simple summary measures, as in heat maps of correlation tables that are often found in genomics. In this talk we use a modification of heat maps, here called â€œblockplotsâ€, and we demonstrate an associated software tool that is both interactive and dynamic, yet wholly written in R. Called â€œAssociation Navigatorâ€, its basic operation is zooming and panning of large â€œblockplotsâ€ of correlation tables involving hundreds of variables. The tool includes, among other things: (1) display of p-values and missing value patterns in addition to correlations, (2) mark-up facilities to highlight variables and sub-tables as landmarks when navigating the larger table, (3) histograms / barcharts, scatterplots and scatterplot matrices as â€œlensesâ€ into the distributions of variables and variable pairs, as well as several other functionalities. The usefulness of the tool is less in beholding gigantic tables in their entirety and more in searching for interesting association patterns by navigating manageable but numerous and interconnected sub-tables. (2) Moderate-p Post-Selection Inference: Berk et al. (AoS 2013) proposed a stringent approach, called â€œPoSIâ€, to producing statistical inference that is valid after arbitrary variable selection in regression. The approach is controversial because of its conservative nature, yet it is the appropriate method of securing valid statistical inference after what is called p-hacking or p-value hunting. This, however, is not the main subject of the talk. Rather, it is the computational limitations of the PoSI approach. Currently our algorithm can handle up to about p = 20 predictor variables in an unconstrained model search. For â€œsparse PoSIâ€ we can handle up to about p = 80 predictors if model search is limited to model sizes 4 and lower. The algorithm relies both on a deterministic integration and a Monte Carlo simulation. It would be desirable for speeding up the algorithm if we better understood the underlying geometry of predictor adjustment. This part of the talk will therefore end with open questions. 3. Speaker: Venkat Chandrasekaran, California Institute of Technology Title: Latent-Variable Graphical Model Selection via Convex Optimization",2015,
Pathological grading of Hepatocellular Carcinomas in MRI using a LASSO algorithm,"To investigate the predictive ability of Radiomics signature for preoperative pathological grading of Hepatocellular Carcinomas (HCC), the no contrast MRI images were integrated and a comprehensive analysis was conducted to predict clinical outcomes using the radiomics features. Variable selection via LASSO and logistic regression were used to select the most-predictive Radiomics features for the pathological grading. Cross-Validation with receiver operating characteristic (ROC) analysis was performed and the area under the ROC curve (AUC) was employed as the prediction metric. Overall, the prediction performances by Radiomics features showed statistically significant correlations with pathological grading, however, improvement on the prediction performance by combining T1WI and T2WI data, classification performance obtained the AUC 0.829 in training dataset and the AUC 0.742 in validation dataset. This study consisted of 170 consecutive patients (training dataset: n=125; validation dataset, n=45). The results showed Radiomics signature was developed and validated to be a significant predictor for discrimination HCC pathological grading, which may serve as a complementary tool for the preoperative tumour grading in HCC.",2018,
LASSO NTCP predictors for the incidence of xerostomia in patients with head and neck squamous cell carcinoma and nasopharyngeal carcinoma,"To predict the incidence of moderate-to-severe patient-reported xerostomia among head and neck squamous cell carcinoma (HNSCC) and nasopharyngeal carcinoma (NPC) patients treated with intensity-modulated radiotherapy (IMRT). Multivariable normal tissue complication probability (NTCP) models were developed by using quality of life questionnaire datasets from 152 patients with HNSCC and 84 patients with NPC. The primary endpoint was defined as moderate-to-severe xerostomia after IMRT. The numbers of predictive factors for a multivariable logistic regression model were determined using the least absolute shrinkage and selection operator (LASSO) with bootstrapping technique. Four predictive models were achieved by LASSO with the smallest number of factors while preserving predictive value with higher AUC performance. For all models, the dosimetric factors for the mean dose given to the contralateral and ipsilateral parotid gland were selected as the most significant predictors. Followed by the different clinical and socio-economic factors being selected, namely age, financial status, T stage, and education for different models were chosen. The predicted incidence of xerostomia for HNSCC and NPC patients can be improved by using multivariable logistic regression models with LASSO technique. The predictive model developed in HNSCC cannot be generalized to NPC cohort treated with IMRT without validation and vice versa.",2014,Scientific Reports
Efficient differentially private learning improves drug sensitivity prediction,"BackgroundUsers of a personalised recommendation system face a dilemma: recommendations can be improved by learning from data, but only if other users are willing to share their private information. Good personalised predictions are vitally important in precision medicine, but genomic information on which the predictions are based is also particularly sensitive, as it directly identifies the patients and hence cannot easily be anonymised. Differential privacy has emerged as a potentially promising solution: privacy is considered sufficient if presence of individual patients cannot be distinguished. However, differentially private learning with current methods does not improve predictions with feasible data sizes and dimensionalities.ResultsWe show that useful predictors can be learned under powerful differential privacy guarantees, and even from moderately-sized data sets, by demonstrating significant improvements in the accuracy of private drug sensitivity prediction with a new robust private regression method. Our method matches the predictive accuracy of the state-of-the-art non-private lasso regression using only 4x more samples under relatively strong differential privacy guarantees. Good performance with limited data is achieved by limiting the sharing of private information by decreasing the dimensionality and by projecting outliers to fit tighter bounds, therefore needing to add less noise for equal privacy.ConclusionsThe proposed differentially private regression method combines theoretical appeal and asymptotic efficiency with good prediction accuracy even with moderate-sized data. As already the simple-to-implement method shows promise on the challenging genomic data, we anticipate rapid progress towards practical applications in many fields.ReviewersThis article was reviewed by Zoltan Gaspari and David Kreil.",2017,Biology Direct
Tail Event Driven ASset allocation: evidence from equity and mutual fundsâ€™ markets,"The correlation structure across assets and opposite tail movements are essential to the asset allocation problem, since they determine the level of risk in a position. Correlation alone is not informative on the distributional details of the assets. Recently introduced TEDASâ€”Tail Event Driven ASset allocation approach determines the dependence between assets at different tail measures. TEDAS uses adaptive Lasso-based quantile regression in order to determine an active set of negative coefficients. Based on these active risk factors, an adjustment for intertemporal correlation is made. In this research, authors aim to develop TEDAS, by introducing three TEDAS modifications differing in allocation weightsâ€™ determination: a Cornishâ€“Fisher Value-at-Risk minimization, Markowitz diversification rule or naÃ¯ve equal weighting. TEDAS strategies significantly outperform other widely used allocation approaches on two asset markets: German equity and Global mutual funds.",2018,Journal of Asset Management
An l1-Oracle Inequality for the Lasso,"The Lasso has attracted the attention of many authors these last years. While many efforts have been made to prove that the Lasso behaves like a variable selection procedure at the price of strong (though unavoidable) assumptions on the geometric structure of these variables, much less attention has been paid to the analysis of the performance of the Lasso as a regularization algorithm. Our first purpose here is to provide a conceptually very simple result in this direction. We shall prove that, provided that the regularization parameter is properly chosen, the Lasso works almost as well as the deterministic Lasso. This result does not require any assumption at all, neither on the structure of the variables nor on the regression function. Our second purpose is to introduce a new estimator particularly adapted to deal with infinite countable dictionaries. This estimator is constructed as an l0-penalized estimator among a sequence of Lasso estimators associated to a dyadic sequence of growing truncated dictionaries. The selection procedure automatically chooses the best level of truncation of the dictionary so as to make the best tradeoff between approximation, l1-regularization and sparsity. From a theoretical point of view, we shall provide an oracle inequality satisfied by this selected Lasso estimator. The oracle inequalities established for the Lasso and the selected Lasso estimators shall enable us to derive rates of convergence on a wide class of functions, showing that these estimators perform at least as well as greedy algorithms. Besides, we shall prove that the rates of convergence achieved by the selected Lasso estimator are optimal in the orthonormal case by bounding from below the minimax risk on some Besov bodies. Finally, some theoretical results about the performance of the Lasso for infinite uncountable dictionaries will be studied in the specific framework of neural networks. All the oracle inequalities presented in this paper are obtained via the application of a single general theorem of model selection among a collection of nonlinear models which is a direct consequence of the Gaussian concentration inequality. The key idea that enables us to apply this general theorem is to see l1-regularization as a model selection procedure among l1-balls.",2010,arXiv: Statistics Theory
Is Cervical Traction Effective in Chronic Nonspecific Neck Pain Patients with Unsatisfactory NSAIDs Control? A Nomogram to Predict the Effectiveness.,"STUDY DESIGN
A retrospective study.


OBJECTIVE
Establishing a nomogram to predict the effectiveness of cervical traction in young and middle-aged chronic nonspecific neck pain (CNNP) patients with unsatisfactory nonsteroidal anti-inflammatory drugs (NSAIDs) control.


SUMMARY OF BACKGROUND DATA
For CNNP patients with unsatisfactory NSAIDs control, the effectiveness of cervical traction varies. Neck muscle fat infiltration and clinical features may associate with the effectiveness.


METHODS
A total of 186 suitable patients were classified into a training dataset (from August 2015 to July 2018, n=118) and validation dataset (from August 2018 to June 2019, n=68) with time sequence. All patients were included to receive MRI scan to calculate posterior cervical fat and muscle features, then undergoing unified cervical traction in an outpatient clinic. The least absolute shrinkage and selection operator (LASSO) regression model was used to select potentially relevant features to predict effectiveness possibility of cervical traction. Multivariable logistic regression analysis was used to develop the predicting model, presenting with a nomogram. The performance of nomogram was assessed based on its calibration, discrimination, and clinical utility.


RESULTS
Through the Lasso regression model, we identified four predictors including gender, good exercise compliance, the ratio of the cross-sectional area (CSA) between fat and muscle on C5 level (C5 fat CSA/muscle CSA), the ratio of CSA between fat and centrum on C5 level (C5 fat CSA/centrum muscle CSA). The nomogram provided good calibration and discrimination in the training cohort, showing an area under the curve (AUC) of 0.704 (95% CI, 0.608-0.799) and good concordance between the predicted and actual probabilities with Spiegelhalter's Z-test (P=0.835). Discrimination of the model in the validation dataset were acceptable, with AUC of 0.691 (95%CI, 0.564-0.817). Decision curve analysis (DCA) revealed the nomogram was clinically useful.


CONCLUSION
Male, good exercise compliance, lower C5 fat CSA/centrum CSA and C5 fat CSA/muscle CSA could be favorable features to predict the effectiveness cervical traction in CNNP patients with unsatisfactory NSAIDs control.",2020,World neurosurgery
Analysis of Feature-Selection for LASSO Regression Models,To extract features from large data sets is a major issue in data science. Many statistical regression models exist that address this problem with many different approaches. In this project models belonging to the LASSO family are analyzed with respect to their ability and performance on feature selection in the domain of high dimensional data. LASSO models are regularized regression models aiming to create sparse models. The Aim is to develop methods to describe and compare the Feature-Selection behavior of these models with an empirical approach.,2017,
Evaluation of Machine-Learning Algorithms for Predicting Opioid Overdose Risk Among Medicare Beneficiaries With Opioid Prescriptions,"Importance
Current approaches to identifying individuals at high risk for opioid overdose target many patients who are not truly at high risk.


Objective
To develop and validate a machine-learning algorithm to predict opioid overdose risk among Medicare beneficiaries with at least 1 opioid prescription.


Design, Setting, and Participants
A prognostic study was conducted between September 1, 2017, and December 31, 2018. Participants (nâ€‰=â€‰560â€¯057) included fee-for-service Medicare beneficiaries without cancer who filled 1 or more opioid prescriptions from January 1, 2011, to December 31, 2015. Beneficiaries were randomly and equally divided into training, testing, and validation samples.


Exposures
Potential predictors (nâ€‰=â€‰268), including sociodemographics, health status, patterns of opioid use, and practitioner-level and regional-level factors, were measured in 3-month windows, starting 3 months before initiating opioids until loss of follow-up or the end of observation.


Main Outcomes and Measures
Opioid overdose episodes from inpatient and emergency department claims were identified. Multivariate logistic regression (MLR), least absolute shrinkage and selection operator-type regression (LASSO), random forest (RF), gradient boosting machine (GBM), and deep neural network (DNN) were applied to predict overdose risk in the subsequent 3 months after initiation of treatment with prescription opioids. Prediction performance was assessed using the C statistic and other metrics (eg, sensitivity, specificity, and number needed to evaluate [NNE] to identify one overdose). The Youden index was used to identify the optimized threshold of predicted score that balanced sensitivity and specificity.


Results
Beneficiaries in the training (nâ€‰=â€‰186â€¯686), testing (nâ€‰=â€‰186â€¯685), and validation (nâ€‰=â€‰186â€¯686) samples had similar characteristics (mean [SD] ageâ€‰ofâ€‰68.0â€‰[14.5] years, and approximately 63% were female, 82% were white, 35% had disabilities, 41% were dual eligible, and 0.60% had at least 1 overdose episode). In the validation sample, the DNN (C statisticâ€‰=â€‰0.91; 95% CI, 0.88-0.93) and GBM (C statisticâ€‰=â€‰0.90; 95% CI, 0.87-0.94) algorithms outperformed the LASSO (C statisticâ€‰=â€‰0.84; 95% CI, 0.80-0.89), RF (C statisticâ€‰=â€‰0.80; 95% CI, 0.75-0.84), and MLR (C statisticâ€‰=â€‰0.75; 95% CI, 0.69-0.80) methods for predicting opioid overdose. At the optimized sensitivity and specificity, DNN had a sensitivity of 92.3%, specificity of 75.7%, NNE of 542, positive predictive value of 0.18%, and negative predictive value of 99.9%. The DNN classified patients into low-risk (76.2% [142 180] of the cohort), medium-risk (18.6% [34 579] of the cohort), and high-risk (5.2% [9747] of the cohort) subgroups, with only 1 in 10â€¯000 in the low-risk subgroup having an overdose episode. More than 90% of overdose episodes occurred in the high-risk and medium-risk subgroups, although positive predictive values were low, given the rare overdose outcome.


Conclusions and Relevance
Machine-learning algorithms appear to perform well for risk prediction and stratification of opioid overdose, especially in identifying low-risk subgroups that have minimal risk of overdose.",2019,JAMA Network Open
Multi-level features combined end-to-end learning for automated pathological grading of breast cancer on digital mammograms,We propose to discriminate the pathological grades directly on digital mammograms instead of pathological images. An end-to-end learning algorithm based on the combined multi-level features is proposed. Low-level features are extracted and selected by supervised LASSO logistic regression. Convolutional Neural Network (CNN) is designed to extract high-level semantic features. These extracted multi-level features are combined to optimize the new CNN end to end to make different parts of the network learn to pay attention to different level of features. Results demonstrate that our proposed algorithm is superior to other CNN models and obtain comparable performance compared with pathological images.,2019,Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society
Application of Multi-SNP Approaches Bayesian LASSO and AUC-RF to Detect Main Effects of Inflammatory-Gene Variants Associated with Bladder Cancer Risk,"The relationship between inflammation and cancer is well established in several tumor types, including bladder cancer. We performed an association study between 886 inflammatory-gene variants and bladder cancer risk in 1,047 cases and 988 controls from the Spanish Bladder Cancer (SBC)/EPICURO Study. A preliminary exploration with the widely used univariate logistic regression approach did not identify any significant SNP after correcting for multiple testing. We further applied two more comprehensive methods to capture the complexity of bladder cancer genetic susceptibility: Bayesian Threshold LASSO (BTL), a regularized regression method, and AUC-Random Forest, a machine-learning algorithm. Both approaches explore the joint effect of markers. BTL analysis identified a signature of 37 SNPs in 34 genes showing an association with bladder cancer. AUC-RF detected an optimal predictive subset of 56 SNPs. 13 SNPs were identified by both methods in the total population. Using resources from the Texas Bladder Cancer study we were able to replicate 30% of the SNPs assessed. The associations between inflammatory SNPs and bladder cancer were reexamined among non-smokers to eliminate the effect of tobacco, one of the strongest and most prevalent environmental risk factor for this tumor. A 9 SNP-signature was detected by BTL. Here we report, for the first time, a set of SNP in inflammatory genes jointly associated with bladder cancer risk. These results highlight the importance of the complex structure of genetic susceptibility associated with cancer risk.",2013,PLoS ONE
Genomic selection in Fleckvieh/Simmental - First results,"The objective of this study was to compare partial least squares regression (PLSR), multivariate regression analysis using least absolute shrinkage and selection operator (LASSO), two Bayesian approaches (BayesA, BayesB) and an ordinary BLUP method (GS-BLUP) for the estimation of genome-wide breeding values for dual purpose Simmental Fleckvieh in Austria. A forward prediction and cross validation were carried out for fat percentage, protein yield, somatic cell count, and non return rate after 56 days in cows. Using cross validation, accuracies of genome-wide breeding values were in the range of 0.36 to 0.76. In forward prediction, obtained accuracies were between 0.20 and 0.61.",2009,Interbull Bulletin
Boosting the discriminatory power of sparse survival models via optimization of the concordance index and stability selection,"BackgroundWhen constructing new biomarker or gene signature scores for time-to-event outcomes, the underlying aims are to develop a discrimination model that helps to predict whether patients have a poor or good prognosis and to identify the most influential variables for this task. In practice, this is often done fitting Cox models. Those are, however, not necessarily optimal with respect to the resulting discriminatory power and are based on restrictive assumptions. We present a combined approach to automatically select and fit sparse discrimination models for potentially high-dimensional survival data based on boosting a smooth version of the concordance index (C-index). Due to this objective function, the resulting prediction models are optimal with respect to their ability to discriminate between patients with longer and shorter survival times. The gradient boosting algorithm is combined with the stability selection approach to enhance and control its variable selection properties.ResultsThe resulting algorithm fits prediction models based on the rankings of the survival times and automatically selects only the most stable predictors. The performance of the approach, which works best for small numbers of informative predictors, is demonstrated in a large scale simulation study: C-index boosting in combination with stability selection is able to identify a small subset of informative predictors from a much larger set of non-informative ones while controlling the per-family error rate. In an application to discover biomarkers for breast cancer patients based on gene expression data, stability selection yielded sparser models and the resulting discriminatory power was higher than with lasso penalized Cox regression models.ConclusionThe combination of stability selection and C-index boosting can be used to select small numbers of informative biomarkers and to derive new prediction rules that are optimal with respect to their discriminatory power. Stability selection controls the per-family error rate which makes the new approach also appealing from an inferential point of view, as it provides an alternative to classical hypothesis tests for single predictor effects. Due to the shrinkage and variable selection properties of statistical boosting algorithms, the latter tests are typically unfeasible for prediction models fitted by boosting.",2016,BMC Bioinformatics
A Note on the Lasso and Related Procedures in Model Selection,"The Lasso, the Forward Stagewise regression and the Lars are closely related procedures recently proposed for linear regression problems. Each of them can produce sparse models and can be used both for estimation and variable selec- tion. In practical implementations these algorithms are typically tuned to achieve optimal prediction accuracy. We show that, when the prediction accuracy is used as the criterion to choose the tuning parameter, in general these procedures are not consistent in terms of variable selection. That is, the sets of variables selected are not consistently the true set of important variables. In particular, we show that for any sample size n, when there are superuous variables in the linear regression model and the design matrix is orthogonal, the probability that these procedures correctly identify the true set of important variables is less than a constant (smaller than one) not depending on n. This result is also shown to hold for two-dimensional problems with general correlated design matrices. The results indicate that in prob- lems where the main goal is variable selection, prediction-accuracy-based criteria alone are not sucien t for this purpose. Adjustments will be discussed to make the Lasso and related procedures useful/consistent for variable selection.",2006,
A Novel Triage Tool of Artificial Intelligence Assisted Diagnosis Aid System for Suspected COVID-19 pneumonia In Fever Clinics,"Currently, the prevention and control of COVID-19 outside Hubei province in China, and other countries has become more and more critically serious. We developed and validated a diagnosis aid model without CT images for early identification of suspected COVID-19 pneumonia (S-COVID-19-P) on admission in adult fever patients and made the validated model available via an online triage calculator. Patients admitted from Jan 14 to Feb 26, 2020 with the epidemiological history of exposure to COVID-19 were included [Model development (n = 132) and validation (n = 32)]. Candidate features included clinical symptoms, routine laboratory tests and other clinical information on admission. Features selection and model development were based on Lasso regression. The primary outcome is the development and validation of a diagnosis aid model for S-COVID-19-P early identification on admission. The development cohort contains 26 S-COVID-19-P and 7 confirmed COVID-19 pneumonia cases. The model performance in held-out testing set and validation cohort resulted in AUCs of 0.841 and 0.938, F-1 score of 0.571 and 0.667, recall of 1.000 and 1.000, specificity of 0.727 and 0.778, and the precision of 0.400 and 0.500. Based on this model, an optimized strategy for S-COVID-19-P early identification in fever clinics has also been designed. S-COVID-19-P could be identified early by a machine-learning model only used collected clinical information without CT images on admission in fever clinics with 100% recall score. The well performed and validated model has been deployed as an online triage tool, which is available at: https://intensivecare.shinyapps.io/COVID19/.",2020,
Estimation of high dimensional mean regression in the absence of symmetry and light tail assumptions.,"Data subject to heavy-tailed errors are commonly encountered in various scientific fields. To address this problem, procedures based on quantile regression and Least Absolute Deviation (LAD) regression have been developed in recent years. These methods essentially estimate the conditional median (or quantile) function. They can be very different from the conditional mean functions, especially when distributions are asymmetric and heteroscedastic. How can we efficiently estimate the mean regression functions in ultra-high dimensional setting with existence of only the second moment? To solve this problem, we propose a penalized Huber loss with diverging parameter to reduce biases created by the traditional Huber loss. Such a penalized robust approximate quadratic (RA-quadratic) loss will be called RA-Lasso. In the ultra-high dimensional setting, where the dimensionality can grow exponentially with the sample size, our results reveal that the RA-lasso estimator produces a consistent estimator at the same rate as the optimal rate under the light-tail situation. We further study the computational convergence of RA-Lasso and show that the composite gradient descent algorithm indeed produces a solution that admits the same optimal rate after sufficient iterations. As a byproduct, we also establish the concentration inequality for estimating population mean when there exists only the second moment. We compare RA-Lasso with other regularized robust estimators based on quantile regression and LAD regression. Extensive simulation studies demonstrate the satisfactory finite-sample performance of RA-Lasso.",2017,"Journal of the Royal Statistical Society. Series B, Statistical methodology"
Predictors of 24-h mortality after inter-hospital transfer to a tertiary medical intensive care unit,"Purpose To identify variables associated with 24-h mortality after inter-hospital transfer. Materials and methods Single center retrospective study of adult patients transferred to a tertiary care medical ICU between 1 January 2010 and 15 April 2014. Demographic, clinical, physiologic, and laboratory data were collected. The Lasso method was used for logistic regression to identify predictors of 24-h mortality after inter-hospital ICU transfer. Results We identified 773 patients. Median age was 58 years (IQR 45â€“69), 49% were female, 83% Caucasian, and 48% had Medicare. The median length of stay at the transferring facility was 1.0 day (IQR 0â€“2). Median SOFA score on the day of ICU transfer was 5 (IQR 2â€“8). Twenty-two (3%) died within 24â€‰h after inter-hospital transfer. SOFA score of 12â€“16 the day of inter-hospital transfer (odds ratio (OR) 7.77, 95% CI 1.21â€“66.26, pâ€‰=â€‰0.037), FiO2 0.8â€“1.0 on ICU arrival, and cardiac arrest prior to transfer (OR 4.94, 95% CI 1.43â€“15.96, pâ€‰=â€‰0.009) were associated with an increased risk for 24-h mortality after inter-hospital transfer. Conclusions Our study identified biologically plausible and potentially modifiable factors associated with 24-h mortality after inter-hospital medical ICU transfer, which may serve to inform patients and families of readiness and risk for mortality after inter-hospital transfer.",2018,Journal of the Intensive Care Society
Integrating manual diagnosis into radiomics for reducing the false positive rate of 18F-FDG PET/CT diagnosis in patients with suspected lung cancer,"PurposeThe high false positive rate (FPR) of 18F-FDG PET/CT in lung cancer screening represents a severe challenge for clinical decision-making. This study aimed to develop a clinical-translatable radiomics nomogram for reducing the FPR of PET/CT in lung cancer diagnosis, and to determine the impact of integrating manual diagnosis to the performance of the radiomics nomogram.MethodsAmong 3,947 18F-FDG PET/CT-screened patients with lung lesion, 157 malignant and 111 benign patients were retrospectively enrolled and divided into training and test cohorts. The data of manual diagnosis were recorded. A total of 4,338 features were extracted from CT, thin-section CT, PET and PET/CT, and the four radiomics signatures (RS) were then generated by LASSO method. Radiomics prediction nomogram integrating imaging-based RS and manual diagnosis was developed using multivariable logistic regression. The performances of RS and prediction nomograms were independently validated through key discrimination index and clinical benefit.ResultsThe FPR of manual diagnosis was found to be 30.6%. Among the four RS, PET/CT RS exhibited the best performance. By integrating manual diagnosis, the hybrid nomogram integrating PET/CT RS and manual diagnosis demonstrated lowest FPR and highest area under curve (AUC) and Youden index (YI) in both training and test cohorts (FPR: 5.4% and 9.1%, AUC: 0.98 and 0.92, YI: 85.8% and 75.5%, respectively). This hybrid nomogram respectively corrected 78.6% and 37.5% among FPR cases produced by PET/CT RS, without significantly sacrificing its sensitivity. The net benefit of hybrid nomogram appeared highest at <85% threshold probability.ConclusionThe established hybrid nomogram integrating PET/CT RS and manual diagnosis can significantly reduce FPR, improve diagnostic accuracy and enhance clinical benefit compared to manual diagnosis. By integrating manual diagnosis, the performance of this hybrid nomogram is superior to PET/CT RS, indicating the importance of cliniciansâ€™ judgement as an essential information source for improving radiomics diagnostic approaches.",2019,European Journal of Nuclear Medicine and Molecular Imaging
Genome-Wide Identification of a Novel Eight-lncRNA Signature to Improve Prognostic Prediction in Head and Neck Squamous Cell Carcinoma,"Objectives: LncRNAs are essential survival prognostic indicators with important biological functions in tumorigenesis and tumor progression. This study aimed to establish a long non-coding RNA (lncRNA) signature that can effectively predict the prognosis of patients with head and neck squamous cell carcinoma (HNSCC) and explore the potential functions of these lncRNAs. Materials and Methods: We re-annotated RNA sequencing and obtained exhaustive RNA-seq data of 269 patients with comprehensive clinical information from the GEO database. Then an 8-lncRNA signature capable of predicting the survival prognosis of HNSCC patients and a nomogram containing this signature were established. Weighted Co-expression Network Construction (WGCNA), Gene Set Enrichment Analysis (GSEA), and Gene Ontology (GO) enrichment were then applied to predict the possible biological functions of the signature and each individual lncRNA. Results: Eight lncRNAs associated with survival in HNSCC patients, including AC010624.1, AC130456.4, LINC00608, LINC01300, MIR99AHG, AC008655.1, AC055758.2, and AC118553.1, were obtained by univariate regression, cox LASSO regression, and multivariate regression. Functionally, patients with high signature scores had abnormal immune functions via GSEA. AC010624.1 and AC130456.4 may participate in epidermal cell differentiation and skin development, and MIR99AHG in the formation of cellular structures. Other lncRNAs in the signature may also participate in important biological processes. Conclusions: Therefore, we established an 8-lncRNA signature that can effectively guide clinical prediction of the prognosis of patients with HNSCC, and individuals with high signature scores may have abnormal immune function.",2019,Frontiers in Oncology
Regularized calibrated estimation of propensity scores with model misspecification and high-dimensional data,"Propensity score methods are widely used for estimating treatment effects from observational studies. A popular approach is to estimate propensity scores by maximum likelihood based on logistic regression, and then apply inverse probability weighted estimators or extensions to estimate treatment effects. However, a challenging issue is that such inverse probability weighting methods including doubly robust methods can perform poorly even when the logistic model appears adequate as examined by conventional techniques. In addition, there is increasing difficulty to appropriately estimate propensity scores when dealing with a large number of covariates. To address these issues, we study calibrated estimation as an alternative to maximum likelihood estimation for fitting logistic propensity score models. We show that, with possible model misspecification, minimizing the expected calibration loss underlying the calibrated estimators involves reducing both the expected likelihood loss and a measure of relative errors which controls the mean squared errors of inverse probability weighted estimators. Furthermore, we propose a regularized calibrated estimator by minimizing the calibration loss with a Lasso penalty. We develop a novel Fisher scoring descent algorithm for computing the proposed estimator, and provide a high-dimensional analysis of the resulting inverse probability weighted estimators of population means, leveraging the control of relative errors for calibrated estimation. We present a simulation study and an empirical application to demonstrate the advantages of the proposed methods compared with maximum likelihood and regularization.",2017,arXiv: Methodology
Fetal weight estimation by ultrasound: development of Indian population-based models,"PURPOSE
Existing ultrasound-based fetal weight estimation models have been shown to have high errors when used in the Indian population. Therefore, the primary objective of this study was to develop Indian population-based models for fetal weight estimation, and the secondary objective was to compare their performance against established models.


METHODS
Retrospectively collected data from 173 cases were used in this study. The inclusion criteria were a live singleton pregnancy and an interval from the ultrasound scan to delivery of â‰¤7 days. Multiple stepwise regression (MSR) and lasso regression methods were used to derive fetal weight estimation models using a randomly selected training group (n=137) with cross-products of abdominal circumference (AC), biparietal diameter (BPD), head circumference (HC), and femur length (FL) as independent variables. In the validation group (n=36), the bootstrap method was used to compare the performance of the new models against 12 existing models.


RESULTS
The equations for the best-fit models obtained using the MSR and lasso methods were as follows: log10(EFW)=2.7843700+0.0004197(HCÃ—AC)+0.0008545(ACÃ—FL) and log10(EFW)=2.38 70211110+0.0074323216(HC)+0.0186555940(AC)+0.0013463735(BPDÃ—FL)+0.0004519715 (HCÃ—FL), respectively. In the training group, both models had very low systematic errors of 0.01% (Â±7.74%) and -0.03% (Â±7.70%), respectively. In the validation group, the performance of these models was found to be significantly better than that of the existing models.


CONCLUSION
The models presented in this study were found to be superior to existing models of ultrasound-based fetal weight estimation in the Indian population. We recommend a thorough evaluation of these models in independent studies.",2019,Ultrasonography
DASSO: connections between the Dantzig selector and lasso,"We propose a new algorithm, DASSO, for fitting the entire coefficient path of the Dantzig selector with a similar computational cost to the least angle regression algorithm that is used to compute the lasso. DASSO efficiently constructs a piecewise linear path through a sequential simplex-like algorithm, which is remarkably similar to the least angle regression algorithm. Comparison of the two algorithms sheds new light on the question of how the lasso and Dantzig selector are related. In addition, we provide theoretical conditions on the design matrix ""X"" under which the lasso and Dantzig selector coefficient estimates will be identical for certain tuning parameters. As a consequence, in many instances, we can extend the powerful non-asymptotic bounds that have been developed for the Dantzig selector to the lasso. Finally, through empirical studies of simulated and real world data sets we show that in practice, when the bounds hold for the Dantzig selector, they almost always also hold for the lasso. Copyright (c) 2009 Royal Statistical Society.",2009,Journal of The Royal Statistical Society Series B-statistical Methodology
Identification of TP53 mutation associated-immunotype and prediction of survival in patients with hepatocellular carcinoma.,"Background
Stratification of tumors is necessary to achieve better clinical outcomes. Hepatocellular carcinoma (HCC) is commonly associated with mutation of the TP53 gene and heterogeneity in immune cell content. However, TP53 mutation-associated immunotype of HCC has not been reported yet. This study aimed to identify the TP53 mutation-associated immunotype in HCC.


Methods
The mutation annotation format (MAF) document, mRNA expression data, and clinical data of HCC patients were downloaded from the publicly available The Cancer Genome Atlas (TCGA) data portal. Data from 332 HCC patients were analyzed in this study. Infiltrating immune cells were evaluated by the well-known CIBERSORT method. Additional mutation data of HCC patients were downloaded from the Catalogue of Somatic Mutations in Cancer (COSMIC) database.


Results
The TP53 gene harbored the highest frequency of mutations in HCC patients. Consequently, five lethal features, including TP53 mutations, were screened by least absolute shrinkage and selector operation (LASSO)-COX regression, according to TP53 mutations and 22 infiltrating immune cells. Two distinct subgroups of HCC were identified, namely, immunotypes A and B. Furthermore, the expression levels of co-inhibitory immune checkpoints were significantly upregulated, and the gene ontology (GO) terms or pathways to boost immune responses were found to be inhibited in the immunotype B subgroup compared to that in the immunotype A subgroup. Finally, we proved immunotype to be an independent adverse prognostic factor that contributed to improvement in the predictive accuracy of the immunotype-based model and helped in avoiding excessive medical treatment.


Conclusions
Two distinct immunotypes of HCC, in terms of prognosis, phenotype, and function, were identified and the traditional understanding of intratumoralCD8+ T cells was subverted. Moreover, the identified immunotypes contributed to improving the predictive accuracy of the immunotype-based model and helped in avoiding excessive medical treatment in some HCC patients.",2020,Annals of translational medicine
Sparse Overlapping Group Lasso for Integrative Multi-Omics Analysis,"Gene networks and graphs are crucial tools for understanding a heterogeneous system of cancer, since cancer is a disease that does not involve individual genes but combinations of genes associated with oncogenic process. A goal of genomic data analysis via gene networks is to identify both gene networks and individual genes within the selected networks. Existing methods, however, perform only network selection, and thus all genes in selected networks are included in models. This leads to overfitting when uncovering driver genes, and the results are not biologically interpretable. To accomplish both ""groupwise sparsity"" and ""within group sparsity"" for identifying driver genes based on biological knowledge (i.e., predefined overlapping groups of features), we propose a sparse overlapping group lasso via duplicated predictors in extended space. The proposed method effectively identifies driver genes and their interactions using known biological pathway information. Monte Carlo simulations and The Cancer Genome Atlas (TCGA) project data analysis indicate that the proposed method is effective for fitting a regression model (i.e., feature selection and prediction accuracy) constructed with duplicated predictors in overlapping groups. In the TCGA data analysis, we uncover potential cancer driver genes via expression modules and gene networks constructed by multi-omics data and identify that the uncovered genes have strong evidences as a cancer driver gene. The proposed method is a useful tool for identifying cancer driver genes and for integrative multi-omics analysis.",2015,Journal of computational biology : a journal of computational molecular cell biology
Composite quantile regression and variable selection in single-index coefficient model,"Abstract In this paper, we propose a composite minimizing average check loss estimation procedure for composite quantile regression (CQR) in the single-index coefficient model (SICM). The asymptotic normalities of the proposed estimators are established, and the asymptotic relative efficiencies (ARE) of the proposed estimators compared with those by least square method are also discussed. We further investigate a variable selection procedure by combining the proposed estimation method with adaptive LASSO penalized method in CQR of SICM. The oracle property of the proposed variable selection method is also established. Simulations with various non-normal errors and one real data application are conducted to assess the finite sample performance of the proposed estimation and variable selection methods.",2016,Journal of Statistical Planning and Inference
The lasso and elastic-net algorithms for predictive sound quality models using large pool of predictive metrics and factors,"Part of the overall perceived quality is communicated by sound quality. Sound quality studies present a twofold challenge. The first is that they rely on listening tests. However, listening tests are considered time consuming. The second challenge relates to the development of predictive sound quality models. Often, these models are derived using linear regression on a limited set of predictive metrics. However, nowadays, many potential metrics are available and there is no computational burden that should limit the number of potential metrics. An issue is that regression using more metrics than observations cannot lead to meaningful predictive models since all the metrics are selected. In this paper, different algorithms are compared to construct a sound quality predictive model that does not suffer from these limitations. These algorithms achieve an automatic selection of few metrics from a large pool. The lasso, elastic-net and stepwise algorithms are tested for the prediction of listening tests results of consumer product for which more than 100 metrics are used a potential predictors. It is shown that the most promising algorithm is the lasso which is able to efficiently limit the number of metrics and provide a model that can be used as understandable design guidelines.",2016,Canadian Acoustics
