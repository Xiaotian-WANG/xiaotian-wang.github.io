title,abstract,year,journal
"The role of self-efficacy factors, individual characteristics and WIL participation on accounting near-graduate studentsâ€™ employment outcomes","The issue of graduate employment has long been a focus in research, particularly in accounting education. Increasingly, higher education institutions promote this aspect to help them attract and retain high-quality students and maintain their competitive advantage in the market place. Given its importance, the present research analyses the association between the three self-efficacy factors of the general self-efficacy scale (GSES): initiative, effort and persistence on accounting near-graduate employment outcomes. Currently, no studies in accounting education have analysed this association in this context, so this research constitutes a contribution to the literature. Furthermore, there is limited research on the association of overall general self-efficacy (GSE) with accounting student employment outcomes. 
In addition to the three-factor GSES structure, the present study also includes studentsâ€™ individual characteristics (i.e., gender, age, residency, study mode and language), and WIL participation as potential factors impacting near-graduate accounting studentsâ€™ employment outcomes. Furthermore, the study also examines the potential association between the three factors of the GSES with studentsâ€™ participation in WIL programs during their degree course. 
The three-factor self-efficacy construct, based on a trait-like method, was adopted instead of the overall GSES structure, as the former approach enables a deeper analysis of the GSE concept via the employment of separate independent variables. Consequently, the importance of the individual factors and their impact on employment and WIL participation is clearly and distinctively revealed. 
The study sample consisted of 337 near-graduate accounting students from Victoria University and Swinburne University of Technology, both based in Melbourne, Australia. The research employed logistic regression, as well as Lasso and R-glmulti statistical techniques, to examine the main research questions. In addition, Mann-Whitney U tests and Pearson chi-square tests were conducted to examine the association between accounting studentsâ€™ individual characteristics (gender, age, residency, study mode and language) and the three factors of GSES (initiative, effort and persistence). 
The study results indicate that two out of the three GSES factors (specifically, initiative and persistence) showed a significant relationship with the employment outcomes of near-graduate accounting students. The study results also confirmed prior research findings, which found that individual characteristics (i.e., language, study mode, residency and age) were significantly associated with employment outcomes. Furthermore, the results showed no significant association between the three self-efficacy factors and studentsâ€™ WIL participation. 
The results of this study provide some important implications for accounting higher education with regard to improving the employment outcomes of accounting near-graduates. These include: (i) developing closer links with industry to improve student familiarity with workplace requirements; (ii) incorporating WIL programs into the accounting curriculum, such as in a professional degree program; (iii) tailoring parts of the curriculum, where possible, in order to improve student self-efficacy; (iv) promoting WIL and providingwider opportunities to access the program; and (v) examining the need for higher education reform to improve international student access to WIL participation during degree courses.",2018,
Stochastic Restricted LASSO-Type Estimator in the Linear Regression Model,"Among several variable selection methods, LASSO is the most desirable estimation procedure for handling regularization and variable selection simultaneously in the high-dimensional linear regression models when multicollinearity exists among the predictor variables. Since LASSO is unstable under high multicollinearity, the elastic-net (Enet) estimator has been used to overcome this issue. According to the literature, the estimation of regression parameters can be improved by adding prior information about regression coefficients to the model, which is available in the form of exact or stochastic linear restrictions. In this article, we proposed a stochastic restricted LASSO-type estimator (SRLASSO) by incorporating stochastic linear restrictions. Furthermore, we compared the performance of SRLASSO with LASSO and Enet in root mean square error (RMSE) criterion and mean absolute prediction error (MAPE) criterion based on a Monte Carlo simulation study. Finally, a real-world example was used to demonstrate the performance of SRLASSO.",2020,Journal of Probability and Statistics
Adaptive Lasso for Poisson log-linear regression model,"Aim To study adaptive Lasso for Poisson log-linear regrersion model.Methods The methods of mathematical analysis and probability theory are used.Results Under some conditions,the adaptive Lasso estimator for Poisson log-linear regression has the oracle properties which are sparsity and asymptotic normality.Conclusion Adaptive Lasso can effectively choose variables for Poisson log-linar regression model and estimate the variable coefficient.",2011,Journal of Northwest University
Paleozoicâ€”mesozoic deposits of the PiauÃ­â€”MaranhÃ£o syneclise (Brazil): geological history of a sedimentary basin,"Abstract During Middle and Late Paleozoic and Early Mesozoic times the Piauiâ€”Maranhao syneclise was an area of continuous sedimentation. Between the Late Silurian and Early Carboniferous the basin passed through a thalassocratic phase, turning geocratic between the Late Carboniferous and Middle Triassic. Based upon sedimentary properties and fossil content, many sedimentary environments could be distinguished. During the thalassocratic phase, nearshore, submarine-fan, deltaic, tidal, coastal and alluvial-plain realms existed. During the geocratic phase the recognized realms are fluvial, lacustrine and semiarid to desertic, as well as offshore to nearshore due to a short marine invasion. The sedimentary history of the Piauiâ€”Maranhao syneclise showed itself to be rather simple, with a limited number of interacting environments. The marine phase started with a slow transgression, followed by a period of fluctuating sea level and finished with a fairly rapid regression. The sedimentary response was an alternation of clastic sediments of various grain sizes. During the geocratic phase the continental environments are chiefly differentiated by variations in climate, resulting in a sedimentary sequence which presents besides variously sized clastics, also limestones and evaporites. These ancient environments have been compared with recent ones, leading to the conclusion that the climatic evolution was very important. The climate during the period of deposition changed slowly from boreal through temperate and desertic, to almost tropical, confirmed by the character of the sediments and the biota assemblage.",1977,Sedimentary Geology
Model selection and estimation in regression with grouped variables,"Summary. We consider the problem of selecting grouped variables (factors) for accurate prediction in regression. Such a problem arises naturally in many practical situations with the multifactor analysis-of-variance problem as the most important and well-known example. Instead of selecting factors by stepwise backward elimination, we focus on the accuracy of estimation and consider extensions of the lasso, the LARS algorithm and the non-negative garrotte for factor selection. The lasso, the LARS algorithm and the non-negative garrotte are recently proposed regression methods that can be used to select individual variables. We study and propose efficient algorithms for the extensions of these methods for factor selection and show that these extensions give superior performance to the traditional stepwise backward elimination method in factor selection problems. We study the similarities and the differences between these methods. Simulations and real examples are used to illustrate the methods.",2006,Journal of The Royal Statistical Society Series B-statistical Methodology
Baseline Levels of Influenza-Specific CD4 Memory T-Cells Affect T-Cell Responses to Influenza Vaccines,"BACKGROUND
Factors affecting immune responses to influenza vaccines have not been studied systematically. We hypothesized that T-cell and antibody responses to the vaccines are functions of pre-existing host immunity against influenza antigens.


METHODOLOGY/PRINCIPAL FINDINGS
During the 2004 and 2005 influenza seasons, we have collected data on cellular and humoral immune reactivity to influenza virus in blood samples collected before and after immunization with inactivated or live attenuated influenza vaccines in healthy children and adults. We first used cross-validated lasso regression on the 2004 dataset to identify a group of candidate baseline correlates with T-cell and antibody responses to vaccines, defined as fold-increase in influenza-specific T-cells and serum HAI titer after vaccination. The following baseline parameters were examined: percentages of influenza-reactive IFN-gamma(+) cells in T and NK cell subsets, percentages of influenza-specific memory B-cells, HAI titer, age, and type of vaccine. The candidate baseline correlates were then tested with the independent 2005 dataset. Baseline percentage of influenza-specific IFN-gamma(+) CD4 T-cells was identified as a significant correlate of CD4 and CD8 T-cell responses, with lower baseline levels associated with larger T-cell responses. Baseline HAI titer and vaccine type were identified as significant correlates for HAI response, with lower baseline levels and the inactivated vaccine associated with larger HAI responses. Previously we reported that baseline levels of CD56(dim) NK reactivity against influenza virus inversely correlated with the immediate T-cell response to vaccination, and that NK reactivity induced by influenza virus depended on IL-2 produced by influenza-specific memory T-cells. Taken together these results suggest a novel mechanism for the homeostasis of virus-specific T-cells, which involves interaction between memory helper T-cells, CD56(dim) NK and DC.


SIGNIFICANCE
These results demonstrate that assessment of baseline biomarkers may predict immunologic outcome of influenza vaccination and may reveal some of the mechanisms responsible for variable immune responses following vaccination and natural infection.",2008,PLoS ONE
Predicting poor response to neoadjuvant chemoradiotherapy for locally advanced rectal cancer: Model constructed using pre-treatment MRI features of structured report template.,"PURPOSE
To develop a predictive model with pre-treatment magnetic resonance imaging (MRI) findings of the structured report template and clinical parameters for poor responses prediction after neoadjuvant chemoradiotherapy (neoCRT) in locally advanced rectal cancers (LARC) patients.


METHOD
Patients with clinicopathologically confirmed LARC (training and validation datasets, nâ€¯=â€¯100 and 71, respectively) were enrolled. Patients' clinical data were retrospectively collected. MRI findings of the structured report template were analysed. The tumour regression grade (TRG) system as proposed by Mandard et al was used. Poor response was defined as TRG 3-5. Univariate logistic regression analysis and a lasso regression model were performed to select the significant predictive features from the training set. A nomogram was constructed based on a multivariable logistic regression analysis. Calibration, discrimination, and clinical usefulness of the nomogram were assessed. The calibrative and discriminative ability of our model were compared with those of models including the tumour-node-metastasis (TNM) stage and clinical factors.


RESULTS
The MRI-reported T4b stage, MRI-reported extramural venous invasion (EMVI) positivity, MRI-detected number of positive mesorectal lymph nodes (LNs)â€¯>â€¯0, and preoperative oxaliplatin and capecitabine (CAPOX) chemotherapy regimen were incorporated into our nomogram. The nomogram showed good discrimination, with areas under the receiver operating characteristic (ROC) curves of 0Â·823 and 0Â·820 in the training and test sets, respectively, and good calibration in both datasets. The decision curve analysis confirmed that the nomogram was clinically useful. The calibrative and discriminative ability of our model were better than those models including the TNM stage and clinical factors.


CONCLUSION
A nomogram based on pre-treatment MRI features of the structured report template and clinical risk factors has potential for use as a non-invasive tool to preoperatively predict poor responses in LARC patients after neoCRT.",2020,Radiotherapy and oncology : journal of the European Society for Therapeutic Radiology and Oncology
Preprint Reference Generalized and smooth James-Stein model selection,"The generalized and smooth James-Stein thresholding functions link and extend the thresholding functions employed by the James-Stein estimator, the blockand adaptive-lasso in variable selection, and the soft-, hardand block-thresholding in wavelet smoothing. The estimator is indexed by two hyperparameters for more flexibility and a smoothness parameter for better estimation of its l2-risk with the Stein unbiased risk estimate (SURE). For blocks of a fixed size, a situation that arises when observing concomitant signals (e.g., gravitational wave bursts), we derive a universal threshold, an information criterion and an oracle inequality for block thresholding. Smooth James-Stein thresholding can also be employed in parametric regression for variable selection. In that case a unique smooth estimate is defined, its smooth SURE is derived, which provides the equivalent degrees of freedom of adaptive lasso as a side result. The new estimator enjoys smoothness like ridge regression and performs variable selection like lasso. SARDY, Sylvain. Generalized and smooth James-Stein model selection. 2010",2017,
Selecting Landmark Points for Sparse Manifold Learning,"There has been a surge of interest in learning non-linear manifold models to approximate high-dimensional data. Both for computational complexity reasons and for generalization capability, sparsity is a desired feature in such models. This usually means dimensionality reduction, which naturally implies estimating the intrinsic dimension, but it can also mean selecting a subset of the data to use as landmarks, which is especially important because many existing algorithms have quadratic complexity in the number of observations. This paper presents an algorithm for selecting landmarks, based on LASSO regression, which is well known to favor sparse approximations because it uses regularization with an l1 norm. As an added benefit, a continuous manifold parameterization, based on the landmarks, is also found. Experimental results with synthetic and real data illustrate the algorithm.",2005,
Multi-level Lasso for Sparse Multi-task Regression,"We present a flexible formulation for variable selection in multi-task regression to allow for discrepancies in the estimated sparsity patterns accross the multiple tasks, while leveraging the common structure among them. Our approach is based on an intuitive decomposition of the regression coe_cients into a product between a component that is common to all tasks and another component that captures task-specificity. This decomposition yields the Multi-level Lasso objective that can be solved efficiently via alternating optimization. The analysis of the ""orthonormal design"" case reveals some interesting insights on the nature of the shrinkage performed by our method, compared to that of related work. Theoretical guarantees are provided on the consistency of Multi-level Lasso. Simulations and empirical study of micro-array data further demonstrate the value of our framework.",2012,
optimal procedures in high-dimensional variable selection,"Motivated by the recent trend in ``Big data"", we are interested in the case where both $p$, the number of variables, and $n$, the number of subjects are large, and probably $p \gg n$. When $p \gg n$, the signals are usually rare and weak, and the observation units are correlated in a complicated way. When the signals are rare and weak, it may be hard to recover them individually. In this thesis, we are interested in the problem of recovering the rare and weak signals with the assistance of correlation structure of the data. 
 
We consider the helps from two types of correlation structures, the correlation structure of the observed units, and the dependency among the unobserved factors. In Chapter \ref{chapter:gs}, in a setting of high dimensional linear regression, we study the variable selection problem when the observed predictors are correlated. In Chapter \ref{chapter:gmas}, we consider recovering the sparse mean vector of a Stein's normal means model, where the elements of the unobserved mean vector are dependent through an Ising model. In each chapter, we study the optimality in variable selection, discover the non-optimality of the conventional methods such as the lasso, subset selection and hard thresholding, and propose {\it Screen and Clean} type of variable selection procedures which are optimal in terms of the Hamming distance. The theoretical findings is supported by the simulation results and applications.",2013,
Model selection and prediction of outcomes in recent onset schizophrenia patients who undergo cognitive training,"Predicting treatment outcomes in psychiatric populations remains a challenge, but is increasingly important in the pursuit of personalized medicine. Patients with schizophrenia have deficits in cognition, and targeted cognitive training (TCT) of auditory processing and working memory has been shown to improve some of these impairments; but little is known about the baseline patient characteristics predictive of cognitive improvement. Here we use a model selection and regression approach called least absolute shrinkage and selection operator (LASSO) to examine predictors of cognitive improvement in response to TCT for patients with recent onset schizophrenia. Forty-three individuals with recent onset schizophrenia randomized to undergo TCT were assessed at baseline on measures of cognition, symptoms, functioning, illness duration, and demographic variables. We carried out 10-fold cross-validation of LASSO for model selection and regression. We followed up on these results using linear models for statistical inference. No individual variable was found to correlate with improvement in global cognition using a Pearson correlation approach, and a linear model including all variables was also found not to be significant. However, the LASSO model identified baseline global cognition, education, and gender in a model predictive of improvement on global cognition following TCT. These findings offer guidelines for personalized approaches to cognitive training for patients with schizophrenia.",2018,Schizophrenia Research: Cognition
Independently Interpretable Lasso: A New Regularizer for Sparse Regression with Uncorrelated Variables,"Sparse regularization such as $\ell_1$ regularization is a quite powerful and widely used strategy for high dimensional learning problems. The effectiveness of sparse regularization have been supported practically and theoretically by several studies. However, one of the biggest issues in sparse regularization is that its performance is quite sensitive to correlations between features. Ordinary $\ell_1$ regularization often selects variables correlated with each other, which results in deterioration of not only its generalization error but also interpretability. In this paper, we propose a new regularization method, ""Independently Interpretable Lasso"" (IILasso for short). Our proposed regularizer suppresses selecting correlated variables, and thus each active variables independently affect the objective variable in the model. Hence, we can interpret regression coefficients intuitively and also improve the performance by avoiding overfitting. We analyze theoretical property of IILasso and show that the proposed method is much advantageous for its sign recovery and achieves almost minimax optimal convergence rate. Synthetic and real data analyses also indicate the effectiveness of IILasso.",2018,
Essays on Robust Model Selection and Model Averaging for Linear Models,"Model selection is central to all applied statistical work. Selecting the variables for use in a regression model is one important example of model selection. This thesis is a collection of essays on robust model selection procedures and model averaging for linear regression models. In the first essay, we propose robust Akaike information criteria (AIC) for MMestimation and an adjusted robust scale based AIC for M and MM-estimation. Our proposed model selection criteria can maintain their robust properties in the presence of a high proportion of outliers and the outliers in the covariates. We compare our proposed criteria with other robust model selection criteria discussed in previous literature. Our simulation studies demonstrate a significant outperformance of robust AIC based on MM-estimation in the presence of outliers in the covariates. The real data example also shows a better performance of robust AIC based on MM-estimation. The second essay focuses on robust versions of the â€œLeast Absolute Shrinkage and Selection Operatorâ€ (lasso). The adaptive lasso is a method for performing simultaneous parameter estimation and variable selection. The adaptive weights used in its penalty term mean that the adaptive lasso achieves the oracle property. In this essay, we propose an extension of the adaptive lasso named the Tukeylasso. By using Tukeyâ€™s biweight criterion, instead of squared loss, the Tukeylasso is resistant to outliers in both the response and covariates. Importantly, we demonstrate that the Tukey-lasso also enjoys the oracle property. A fast accelerated proximal gradient (APG) algorithm is proposed and implemented for",2017,
Genome-wide association study of Hirschsprung disease detects a novel low-frequency variant at the RET locus,"Hirschsprung disease (HSCR) is a congenital disorder with a population incidence of ~1/5000 live births, defined by an absence of enteric ganglia along variable lengths of the colon. HSCR genome-wide association studies (GWAS) have found common associated variants at RET, SEMA3, and NRG1, but they still fail to explain all of its heritability. To enhance gene discovery, we performed a GWAS of 170 cases identified from the Danish nationwide pathology registry with 4717 controls, based on 6.2 million variants imputed from the haplotype reference consortium panel. We found a novel low-frequency variant (rs144432435), which, when conditioning on the lead RET single-nucleotide polymorphism (SNP), was of genome-wide significance in the discovery analysis. This conditional association signal was replicated in a Swedish HSCR cohort with discovery plus replication meta-analysis conditional odds ratio of 6.6 (Pâ€‰=â€‰7.7â€‰Ã—â€‰10âˆ’10; 322 cases and 4893 controls). The conditional signal was, however, not replicated in two HSCR cohorts from USA and Finland, leading to the hypothesis that rs144432435 tags a rare haplotype present in Denmark and Sweden. Using the genome-wide complex trait analysis method, we estimated the SNP heritability of HSCR to be 88%, close to estimates based on classical family studies. Moreover, by using Lasso (least absolute shrinkage and selection operator) regression we were able to construct a genetic HSCR predictor with a area under the receiver operator characteristics curve of 76% in an independent validation set. In conclusion, we combined the largest collection of sporadic Hirschsprung cases to date (586 cases) to further elucidate HSCRâ€™s genetic architecture.",2017,European Journal of Human Genetics
A Data-driven Fault Prediction Integrated Design Scheme Based on Ensemble Learning for Thermal Boiler Process,"As modern industrial systems are becoming more and more sophisticated, the reliability and safety issues of these complex industrial systems have become the most critical parts in system design. Data-driven fault diagnosis and fault prediction technology play important roles in the field of fault prediction and health management of complex industrial systems. This paper studies the machine learning aided data-driven fault prediction techniques. Three kinds of machine learning algorithms, i.e. random forest (RF), lasso regression (Lasso) and support vector machine regression (SVR), are employed to predict the fault related key performance indicator (KPI) of the thermal boiler system. The boiler's monitoring data is preprocessed, after which the characteristic variables are selected with the algorithm of RF and support vector machine-recursive feature elimination (SVM-RFE). The stacking algorithm is finally used to combine the three basic models. The proposed prediction model performs much better in fault prognosis in comparison with the original prediction model.",2020,2020 IEEE International Conference on Industrial Technology (ICIT)
Learning methods in reproducing kernel Hilbert space based on high-dimensional features,"Hojin Yang: Learning Methods in Reproducing Kernel Hilbert Space Based on High-dimensional Features (Under the direction of Joseph G. Ibrahim and Hongtu Zhu) The first topic focuses on the dimension reduction method via the regularization. We propose the selection for principle components via LASSO. This method assumes that some unknown latent variables are related to the response under the highly correlate covariates structure. L1 regularization plays a key role in adaptively finding a few liner combinations in contrast to the persistent idea that is to employ a few leading principal components. The consistency of regression coefficients and selected model are asymptotically proved and numerical performances are shown to support our suggestion. The proposed method is applied to analyze microarray data and cancer data. Second and third topics focus on the approaches of the independent screening and the dimension reduction with the machine learning approach using positive definite kernels. A Key ingredient matter of these papers is to use reproducing kernel Hilbert space (RKHS) theory. Specifically, we proposed Multiple Projection Model (MPM) and Single Index Latent Factor Model (SILFM) to build an accurate prediction model for clinical outcomes based on a massive number of features. MPM and SILFM can be summarized as three-stage estimation, screening, dimension reduction, and nonlinear fitting. Screening and dimension reduction are unique approaches of two novel methods. The convergence property of the proposed screening method and the risk bound for SILFM are systematically investigated. The results from several simulation scenarios are shown to support it. The proposed method is applied to analyze brain image data and its clinical behavior response.",2016,
Group Lasso for high dimensional sparse quantile regression models,"This paper studies the statistical properties of the group Lasso estimator for high dimensional sparse quantile regression models where the number of explanatory variables (or the number of groups of explanatory variables) is possibly much larger than the sample size while the number of variables in ""active"" groups is sufficiently small. We establish a non-asymptotic bound on the $\ell_{2}$-estimation error of the estimator. This bound explains situations under which the group Lasso estimator is potentially superior/inferior to the $\ell_{1}$-penalized quantile regression estimator in terms of the estimation error. We also propose a data-dependent choice of the tuning parameter to make the method more practical, by extending the original proposal of Belloni and Chernozhukov (2011) for the $\ell_{1}$-penalized quantile regression estimator. As an application, we analyze high dimensional additive quantile regression models. We show that under a set of suitable regularity conditions, the group Lasso estimator can attain the convergence rate arbitrarily close to the oracle rate. Finally, we conduct simulations experiments to examine our theoretical results.",2011,arXiv: Methodology
Model Selection and Estimation in Regression with Grouped Variables 4 Ming Yuan and,"We consider the problem of selecting grouped variables (factors) for accurate prediction in regression. Such a problem arises naturally in many practical situations with the multi-factor ANOVA problem as the most important and well known example. Instead of selecting factors by stepwise backward elimination, we focus on estimation accuracy and consider extensions of the LASSO, the LARS, and the nonnegative garrote for factor selection. The LASSO, the LARS, and the nonnegative garrote are recently proposed regression methods that can be used to select individual variables. We study and propose efficient algorithms for the extensions of these methods for factor selection, and show that these extensions give superior performance to the traditional stepwise backward elimination method in factor selection problems. We study the similarities and the differences among these methods. Simulations and real examples are used to illustrate the methods.",2004,
In-Group Favoritism Caused by Pokemon Go and the Use of Machine Learning for Principled Investigation of Potential Moderators,"A large body of laboratory-based research suggests that arbitrary group assignments (ie. ""minimal groups"") can lead to in-group bias. We use the release of a popular augmented reality game Pokemon Go to study this phenomenon in a hybrid lab-field experiment. We analyze the behavior of 940 Pokemon Go players randomly matched to other Pokemon Go players to participate in Prisoner's Dilemma games. We find that participants are much more cooperative when their partners is from the same Pokemon Go team, demonstrating an ecologically valid occurrence of the minimal group paradigm. We also use transformed outcome lasso regressions to look for heterogeneity in treatment effects. Machine learning, rather than manual data mining, minimizes overfitting and reduces susceptibility to multiple comparison issues and researcher degrees of freedom. We find one important moderator of the effect: the salience of Pokemon Go. As it's popularity wanes, so does the size of the group bias in our experiments. Thus our full set of results show that real-world minimal group bias is quick to arise but also potentially fragile.",2017,Social Science Research Network
Sparse Bayesian linear regression using generalized normal priors,"A sparse Bayesian linear regression model is proposed that generalizes the Bayesian Lasso to a class of Bayesian models with scale mixtures of normal distributions as priors for the regression coefficients. We assume a hierarchical Bayesian model with a binary indicator for whether a predictor variable is included in the model, a generalized normal prior distribution for the coefficients of the included variables, and a Student-t error model for robustness to heavy tailed noise. Our model out-performs other popular sparse regression estimators on synthetic and real data.",2017,IJWMIP
Simple Granger Causality Tests for Mixed Frequency Data,"This paper presents simple Granger causality tests applicable to any mixed frequency sampling data setting, which feature remarkable power properties even with a relatively small sample size. Our tests are based on a seemingly overlooked, but simple, dimension reduction technique for regression models. If the number of parameters of interest is large then in small or even large samples any of the trilogy test statistics may not be well approximated by their asymptotic distribution. A bootstrap method can be employed to improve empirical test size, but this generally results in a loss of power. A shrinkage estimator can be employed, including Lasso, Adaptive Lasso, or Ridge Regression, but these are valid only under a sparsity assumption which does not apply to Granger causality tests. The procedure, which is of general interest when testing potentially large sets of parameter restrictions, involves multiple parsimonious regression models where each model regresses a low frequency variable onto only one individual lag or lead of a high frequency series, where that lag or lead slope parameter is necessarily zero under the null hypothesis of non-causality. Our test is then based on a max test statistic that selects the largest squared estimator among all parsimonious regression models. Parsimony ensures sharper estimates and therefore improved power in small samples. We show via Monte Carlo simulations that the max test is particularly powerful for causality with a large time lag.",2017,
Reconstruction left atrium and isolation pulmonary veins of paroxysmal atrial fibrillation using single contact force catheter with zero x-ray exposure,"Background: Conventional ablation of paroxysmal atrial fibrillation (PAF) is associated with radiation risks for patients and laboratory staff. Three-dimensional (3D) mapping system capable of showing contact force (CF) and direction of catheter tip may compensate for nonfluoroscopic safety issues. Objective: The aim of this study was to investigate the feasibility of zero x-ray exposure during reconstruction left atrium (LA) and ablation. Methods: Single, CF catheter, and 3D mapping system were used to reconstruct LA and isolate pulmonary veins (PV) in all patients. The patients were randomly divided into 2 groups after LA angiography. In group 1, reconstruction LA and isolation PV was performed with the help of 3D system (without x-ray), whereas in group 2, x-ray and 3D system were utilized to reconstruct LA and ablate PV antrum. After ablation, Lasso catheter was used to confirm the PV isolation. All patients were followed up to 12 months. Results: A total of 342 PAF patients were continuously enrolled. The basic clinical characteristics between the 2 groups had no significant difference. Parameters related to the procedure, average procedure time, ablation procedure time, average contact force (CF) applied, the percentage of time within CF settings, and average power applied during radiofrequency application showed no significant difference between the 2 groups. In group 1, the average fluoroscopy time before LA reconstruction was similar to that in group 2 (2.8â€ŠÂ±â€Š0.4 vs. 2.4â€ŠÂ±â€Š0.6 minutes, Pâ€Š=â€Š.75). The average fluoroscopy time during ablation was significantly lower than that in group 2 (0 vs. 7.6â€ŠÂ±â€Š1.3 minutes, Pâ€Š<â€Š.001). The total x-ray exposure dose of the procedure in group 1 was significantly lower than that in group 2 (19.6â€ŠÂ±â€Š9.4 vs. 128.7â€ŠÂ±â€Š62.5 mGy, respectively, Pâ€Š<â€Š.001). Kaplan-Meier analysis indicated that there were no statistical differences in the probability of freedom from atrial arrhythmia (AF/AFL/AT) recurrence at 12 months between group 1 and group 2 (Pâ€Š=â€Š.152). The success rate after a single ablation procedure and without drugs (Class I/III AAD) at 12 months was not significantly different between the 2 groups (67.6%, 95% confidence interval [CI]: 62%â€“79.5% in group 1 and 68.9%, 95% CI: 63%â€“80.7% in group 2, Pâ€Š=â€Š.207). Procedural-related adverse events showed no significant different incidence between group 1 and group 2. A multivariate logistic regression analysis of risk factors was performed to evaluate the effectiveness outcome, which demonstrated that the percentage of CF (within the investigator-selected work ranges) during therapy was significantly associated with positive outcomes (odds ratio: 3.68; 95% CI: 1.65â€“10.6, Pâ€Š=â€Š.008), whereas the LA dimension was negatively associated with effectiveness outcomes (odds ratio: 0.72; 95% CI: 0.52â€“0.84, Pâ€Š=â€Š.016). Conclusions: Reconstruction LA and isolation PV ablation using single CF-assisted catheter without x-ray exposure was both safe and effective. CF was positively associated with effective outcomes and LA dimensions negatively with effective ones.",2017,Medicine
"Pattern Alternating Maximization Algorithm for Missing Data in Large P, Small N Problems","We propose a new and computationally efficient algorithm for maximizing the observed log-likelihood for a multivariate normal data matrix with missing values. We show that our procedure based on iteratively regressing the missing on the observed variables, generalizes the standard EM algorithm by alternating between different complete data spaces and performing the E-Step incrementally. In this non-standard setup we prove numerical convergence to a stationary point of the observed log-likelihood. 
For high-dimensional data, where the number of variables may greatly exceed sample size, we add a Lasso penalty in the regression part of our algorithm and perform coordinate descent approximations. This leads to a computationally very attractive technique with sparse regression coefficients for missing data imputation. Simulations and results on four microarray datasets show that the new method often outperforms other imputation techniques as k-nearest neighbors imputation, nuclear norm minimization or a penalized likelihood approach with an l1-penalty on the inverse covariance matrix.",2010,arXiv: Methodology
Quantile regression and variable selection for single-index varying-coefficient models,"ABSTRACT In this article, a new efficient iteration procedure based on quantile regression is developed for single-index varying-coefficient models. The proposed estimation scheme is an extension of the full iteration procedure proposed by Carroll et al., which is different with the method adopted by Wu et al. for single-index models that a double-weighted summation is used therein. This distinguish not only be the reason that undersmoothing should be a necessary condition in our proposed procedure, but also may reduce the computational burden especially for large-sample size. The resulting estimators are shown to be robust with regardless of outliers as well as varying errors. Moreover, to achieve sparsity when there exist irrelevant variables in the index parameters, a variable selection procedure combined with adaptive LASSO penalty is developed to simultaneously select and estimate significant parameters. Theoretical properties of the obtained estimators are established under some regular conditions, and some simulation studies with various distributed errors are conducted to assess the finite sample performance of our proposed method.",2017,Communications in Statistics - Simulation and Computation
Development and validation of CT imagingâ€“based preoperative nomogram in the prediction of unfavorable high-grade small renal masses,"Purpose
In recent years, there has been an increase in the incidence of small renal masses (SRMs) and nephrectomy was the standard management of this disease in the past. Currently, the use of active surveillance has been recommended as an alternative option in the case of some patients with SRMs due to its heterogenicity. However, limited studies focused on the regarding risk stratification. Therefore, in the current study, we developed a nomogram for the purpose of predicting the presence of high-grade SRMs on the basis of the patient information provided (clinical information, hematological indicators, and CT imaging data).


Patients and methods
A total of 329 patients (consisting of development and validation cohort) who had undergone nephrectomy for SRMs between January 2013 and May 2016 retrospectively were recruited for the present study. All preoperative information, including clinical predictors, hematological indicators, and CT predictors, were obtained. Lasso regression model was used for data dimension reduction and feature selection. Multivariable logistic regression analysis was applied for the establishment of the predicting model. The performance of the nomogram was assessed with respect to its calibration and discrimination properties and externally validated.


Results
The predictors used in the assessment of the nomogram included tumor size, CT tumor contour, CT necrosis, CT tumor exophytic properties, and CT collecting system oppression. Based on these parameters, the nomogram was evaluated to have an effective discrimination and calibration ability, and the C-index was found to be 0.883 after internal validation and 0.887 following external validation.


Conclusion
Based on the aforementioned findings, it can be concluded that CT imaging-based preoperative nomogram is an effective predictor of SRMs and hence can be used in the preoperative evaluation of SRMs, due to its calibration and discrimination abilities.",2019,Cancer Management and Research
Are higher-order factors useful in pricing the cross-section of hedge fund returns?,"This paper investigates hedge fundsâ€™ exposures to various risk factors across different investment strategies through models with both linear and second-order factors. We extend the analysis from an augmented linear model based on Fama & French (1993) and Fung & Hsieh (2001) to second-order models that include all quadratic and interaction terms by adopting a novel multistep strategy that combines the variable selection capabilities of the LASSO regression with the Fama & MacBeth (1973) two-step method. We find that, for some strategies, several quadratic and interaction terms are statistically significant. Nonetheless, there is no evidence that the second-order models have more overall explanatory or predictive power than the linear model. Moreover, while both linear and second-order models perform well for directional funds (like emerging markets, event driven and managed futures), missing factors may still remain for semi-directional funds, such as fund of funds, long/short equity hedge and multi-strategy.",2019,
Prognostic Value of a BCSC-associated MicroRNA Signature in Hormone Receptor-Positive HER2-Negative Breast Cancer,"PURPOSE
Breast cancer patients with high proportion of cancer stem cells (BCSCs) have unfavorable clinical outcomes. MicroRNAs (miRNAs) regulate key features of BCSCs. We hypothesized that a biology-driven model based on BCSC-associated miRNAs could predict prognosis for the most common subtype, hormone receptor (HR)-positive, HER2-negative breast cancer patients.


PATIENTS AND METHODS
After screening candidate miRNAs based on literature review and a pilot study, we built a miRNA-based classifier using LASSO Cox regression method in the training group (n=202) and validated its prognostic accuracy in an internal (n=101) and two external validation groups (n=308).


RESULTS
In this multicenter study, a 10-miRNA classifier incorporating miR-21, miR-30c, miR-181a, miR-181c, miR-125b, miR-7, miR-200a, miR-135b, miR-22 and miR-200c was developed to predict distant relapse free survival (DRFS). With this classifier, HR+HER2- patients were scored and classified into high-risk and low-risk disease recurrence, which was significantly associated with 5-year DRFS of the patients. Moreover, this classifier outperformed traditional clinicopathological risk factors, IHC4 scoring and 21-gene Recurrence Score (RS). The patients with high-risk recurrence determined by this classifier benefit more from chemotherapy.


CONCLUSIONS
Our 10-miRNA-based classifier provides a reliable prognostic model for disease recurrence in HR+HER2- breast cancer patients. This model may facilitate personalized therapy-decision making for HR+HER2- individuals.",2016,EBioMedicine
Magnetic resonance imaging based radiomics signature for the preoperative discrimination of stage I-II and III-IV head and neck squamous cell carcinoma.,"PURPOSE
This study aimed to investigate the predictive ability of magnetic resonance imaging (MRI) based radiomics signature for the preoperative staging in HNSCC.


METHODS
This study involved127 consecutive patients (training cohort: nâ€¯=â€¯85; testing cohort, nâ€¯=â€¯42) with stage I-IV HNSCC. A total of 970 radiomics features were extracted from T2-weighted (T2W) (nâ€¯=â€¯485) and contrast-enhanced T1-weighted (ceT1W) (nâ€¯=â€¯485) MRI for each case. Radiomics signatures were constructed with least absolute shrinkage and selection operator (LASSO) logistic regression. Associations between radiomics signatures and HNSCC staging were explored. Areas under the receiver operating characteristic curve (AUC) and classification performance of radiomics signatures were determined and compared with those of the visual assessment.


RESULTS
Ten features from T2W images, six from ceT1W images, and six from combined T2W and ceT1W images were selected by LASSO logistic regression. The three radiomics signatures of stage III-IV HNSCC were significantly higher than that for stage I-II in both cohorts (all Pâ€¯<â€¯0.05). The radiomics signatures from ceT1W and combined images performed well in the discrimination of stage I-II and III-IV HNSCC, with AUCs of 0.828 and 0.850 in the training cohort, and AUCs of 0.853 and 0.849 in the testing cohort. Based on the cut-off value of the training cohort, the radiomics signature from combined images achieved best classification performance in both cohorts, with accuracies of 0.788 and 0.857, sensitivities of 0.836 and 0.885, and specificities of 0.700 and 0.813. Significant differences in accuracy and sensitivity were found between the radiomics signature from combined images and the visual assessment of the radiologists in the training cohort.


CONCLUSION
Radiomics signature based on MRI could discriminate stage I-II from stage III-IV HNSCC, which may serve as a complementary tool for preoperative staging.",2018,European journal of radiology
Prediction Divergence Criterion for Model Selection in the Logistic Regression,"In this Master Thesis, we have analytically derived and numerically implemented three estimators of the Prediction Divergence Criterion (Avella-Medina et al., working paper) for Model Selection within the logistic regression framework. After the validation of these estimators by means of simulations, we have performed Model Selection both when the order of the variables was known in advance and when the order was correct but decided by an already existing algorithm, namely the binary lasso (Friedman et al., 2010). Finally we have produced evidences of the good performance of two of these estimators, one derived from the L2 norm error measure and the other from the binomial deviance, respectively in highly and moderately correlated settings. They have been proven better, to the extension of the simulation study, than the defaults methods, based on 10-fold Cross Validation, currently available in the glmnet(Friedman et al., 2017) R package.",2018,
Iterative L1/2 Regularization Algorithm for Variable Selection in the Cox Proportional Hazards Model,"In this paper, we investigate to use theL1/2 regularization method for variable selection based on the Cox's proportional hazards model. The L1/2 regularization method isa reweighed iterative algorithm with the adaptively weighted L1 penalty on regression coefficients. The algorithm of theL1/2 regularization method can be easily obtained by a series of L1 penalties. Simulation results based on standard artificial data show that theL1/2 regularization method can be more accurate for variable selection than Lasso and adaptive Lasso methods. The results from Primary Biliary Cirrhosis (PBC) dataset indicate theL1/2 regularization method performs competitively.",2012,
Predictive model algorithms identifying early and advanced stage ER+/HER2âˆ’ breast cancer in claims data,"PURPOSE
Claims databases offer large populations for research, but lack clinical details. We aimed to develop predictive models to identify estrogen receptor positive (ER+) and human epidermal growth factor negative (HER2-) early breast cancer (ESBC) and advanced stage breast cancer (ASBC) in a claims database.


METHODS
Female breast cancer cases in Anthem's Cancer Care Quality Program served as the gold standard validation sample. Predictive models were developed from clinical knowledge and empirically from claims data using logistic and lasso regression. Model performance was assessed by classification rates and c-statistics. Models were applied to the HealthCore Integrated Research Database (claims) to identify cohorts of women with ER+/HER2- ESBC and ASBC.


RESULTS
The validation sample included 3184 women with ER+/HER2- ESBC and 1436 with ER+/HER2- ASBC. Predictive models for ER+/HER2- ESBC and ASBC included 25 and 20 factors, respectively. Models had robust discrimination in identifying cases (c-statÂ =Â 0.92 for ESBC and 0.95 for ASBC). Compared with a traditional a priori algorithm developed with clinical insight alone, the ER+/HER2- ASBC-predictive model had better positive predictive value (PPV) (0.91, 95% CI, 0.90-0.93, vs 0.69, 95% CI, 0.66-0.73) and sensitivity (0.54 vs 0.35). Models were applied to the claims database to identify cohorts of 33Â 001 and 3198 women with ER+/HER2- ESBC and ASBC.


CONCLUSION
We conducted a validation study and developed predictive models to identify in a claims database cohorts of women with ER+/HER2- ESBC and ASBC. The models identified large cohorts in the claims data that can be used to characterize indications in the evaluation of targeted therapies.",2019,Pharmacoepidemiology and Drug Safety
The Adaptive Lasso Method for Instrumental Variable Selection,Adaptive lasso is a weighted â€˜1 penalization method for simultaneous estimation and model selection. It has oracle properties of asymptotic normality with optimal convergence rate and model selection consistency. Instrumental variable selection has become the focus of much research in areas of application for which datasets with both strong and weak instruments are available. This paper develops an adaptive lasso method to select instrumental variables. We suggest standard two-stage least squares (TSLS) regression after the selection. Adaptive lasso is continuous and convex so that it can avoid the local optimization trap. In this paper we extend the technique of adaptive lasso to multivariate linear model framework and the situation in which we have weak instruments. Adaptive lasso estimates irrelevant instruments as 0 asymptotically as if it were known. In simulations we show adaptive lasso can select the strong instrumental variable consistently therefore improve the accuracy of the inference of TSLS.,2012,
Aberrant DNA methylation characterizes juvenile myelomonocytic leukemia with poor outcome.,"Aberrant DNA methylation contributes to the malignant phenotype in virtually all types of cancer, including myeloid leukemia. We hypothesized that CpG island hypermethylation also occurs in juvenile myelomonocytic leukemia (JMML) and investigated whether it is associated with clinical, hematologic, or prognostic features. Based on quantitative measurements of DNA methylation in 127 JMML cases using mass spectrometry (MassARRAY), we identified 4 gene CpG islands with frequent hypermethylation: BMP4 (36% of patients), CALCA (54%), CDKN2B (22%), and RARB (13%). Hypermethylation was significantly associated with poor prognosis: when the methylation data were transformed into prognostic scores using a LASSO Cox regression model, the 5-year overall survival was 0.41 for patients in the top tertile of scores versus 0.72 in the lowest score tertile (P = .002). Among patients given allogeneic hematopoietic stem cell transplantation, the 5-year cumulative incidence of relapse was 0.52 in the highest versus 0.10 in the lowest score tertile (P = .007). In multivariate models, DNA methylation retained prognostic value independently of other clinical risk factors. Longitudinal analyses indicated that some cases acquired a more extensively methylated phenotype at relapse. In conclusion, our data suggest that a high-methylation phenotype characterizes an aggressive biologic variant of JMML and is an important molecular predictor of outcome.",2011,Blood
Radiomics analysis of multicenter CT images for discriminating mucinous adenocarcinoma from nomucinous adenocarcinoma in rectal cancer and comparison with conventional CT values.,"OBJECTIVE
To investigate the value of CT-based radiomics signature for preoperatively discriminating mucinous adenocarcinoma (MA) from nomucinous adenocarcinoma (NMA) in rectal cancer and compare with conventional CT values.


METHOD
A total of 225 patients with histologically confirmed MA or NMA of rectal cancer were retrospectively enrolled. Radiomics features were computed from the entire tumor volume segmented from the post-contrast phase CT images. The maximum relevance and minimum redundancy (mRMR) and LASSO regression model were performed to select the best preforming features and build the radiomics models using a training cohort of 155 cases. Then, predictive performance of the models was validated using a validation cohort of 70 cases and receiver operating characteristics (ROC) analysis method. Meanwhile, CT values in post- and pre-contrast phase, as well as their difference (D-values) of tumors in two cohorts were measured by two radiologists. ROC curves were also calculated to assess diagnostic efficacies.


RESULTS
One hundred and sixty-three patients were confirmed by pathology as NMA and 62 cases were MA. The radiomics signature comprised 19 selected features and showed good discrimination performance in both the training and validation cohorts. The areas under ROC curves (AUC) are 0.93 (95% confidence interval [CI]: 0.89-0.98) in training cohort and 0.93 (95% CI: 0.87-0.99) in validation cohort, respectively. Three sets of CT values of MA in pre- and post-contrast phase, and their difference (D-value) (31Â±7.0, 51Â±12.6 and 20Â±9.3, respectively) were lower than those of NMA (37Â±5.6, 69Â±13.3 and 32Â±11.7, respectively). Comparing to the radiomics signature, using three sets of conventional CT values yielded relatively low diagnostic performance with AUC of 0.84 (95% CI: 0.78-0.88), 0.75 (95% CI: 0.69-0.81) and 0.78 (95% CI: 0.72-0.83), respectively.


CONCLUSION
This study demonstrated that CT radiomics features could be utilized as a noninvasive biomarker to identify MA patients from NMA of rectal cancer preoperatively, which is more accurate than using the conventional CT values.",2020,Journal of X-ray science and technology
Radiomics for diagnosis of dual-phenotype hepatocellular carcinoma using Gd-EOB-DTPA-enhanced MRI and patient prognosis,"To describe the clinical characteristics and outcomes of patients with dual-phenotype hepatocellular carcinoma (DPHCC) and investigate the use of radiomics to establish an image-based signature for preoperative differential diagnosis. This study included 50 patients with a postoperative pathological diagnosis of DPHCC (observation group) and 50 patients with CK7- and CK19-negative HCC (control group) who attended our hospital between January 2015 and December 2018. All patients underwent Gd-EOB-DTPA-enhanced MRI within 1 month before surgery. Arterial phase (AP), portal venous phase (PVP), delayed phase (DP) and hepatobiliary phase (HBP) images were transferred into a radiomics platform. Volumes of interest covered the whole tumor. The dimensionality of the radiomics features were reduced using LASSO. Four classifiers, including multi-layer perceptron (MLP), support vector machines (SVM), logistic regression (LR) and K-nearest neighbor (KNN) were used to distinguish DPHCC from CK7- and CK19-negative HCC. Kaplanâ€“Meier survival analysis was used to assess 1-year disease-free survival (DFS) and overall survival (OS) in the observation and control groups. The best preoperative diagnostic power for DPHCC will likely be derived from a combination of different phases and classifiers. The sensitivity, specificity and accuracy of LR in PVP (0.740, 0.780, 0.766), DP (0.893, 0.700, 0.798), HBP (0.800, 0.720, 0.756) and MLP in PVP (0.880, 0.720, 0.798) were better performance. The 1-year DFS and OS of the patients in the observation group were 69% and 78%, respectively. The 1-year DFS and OS of the patients in the control group were 83% and 85%, respectively. Kaplanâ€“Meier survival analysis showed no statistical difference in DFS and OS between groups (Pâ€‰=â€‰0.231 and 0.326), but DFS and OS were numerically lower in patients with DPHCC. The radiomics features extracted from Gd-EOB-DTPA-enhanced MR images can be used to diagnose preoperative DPHCC. DPHCC is more likely to recur and cause death than HCC, suggesting that active postoperative management of patients with DPHCC is required.",2019,Journal of Cancer Research and Clinical Oncology
A Visual Survey of the Inshore Fish Cos of Gran Canaria ( Canary Islands ),"An in situ visual survey technique (5 minutes and 100 mZ area) was used to assess the inshore fishes off Gran Canaria. In 1996,211 visual surveys were conducted at 7 localities. Locations differed significantly among each other with regards to the number of species per survey (ANOVA: p < 0.01). The Eve most abundant species were Chrornis limbanis, Boops boops, Ponzadasys incisus, Abzidefdz$irids, and Thalassorna pavo with respective mean abundances of 65.6, 37.4, 16.7, 8.7, and 4.5 per 100 m2. Detrended Correspondence Analysis, a multivariate ordination technique showed that the major determinant of community structure is substrate type. The majority of the surveyed species had low axis I ordination scores indicating a strong association with a hard substrate. The step-wise linear regression models explained 45.3 % and 1 1.4% of the variation in the first and second axis survey ordination scores, respectively.",2013,
