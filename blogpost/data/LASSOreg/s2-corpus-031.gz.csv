title,abstract,year,journal
Comparing variable selection techniques for linear regression: LASSO and Autometrics,"In this paper, we compare two different variable selection approaches for linear regression models: Autometrics (automatic general-to-specific selection) and LASSO (?1-norm regularization). In a simulation study, we show the performance of the methods considering the predictive power (forecast out-of-sample) and the selection of the correct model and estimation (in-sample). The case where the number of candidate variables exceeds the number of observation is considered as well. We also analyze the properties of estimators comparing to the oracle estimator. Finally, we compare both methods in an application to GDP forecasting.",2013,
Feasible analysis of gene expression â€“a computational based classification for breast cancer,"Abstract Computational based classification of gene expression data for analyzing the genetic pattern provides better clinical prediction for breast cancer. Breast cancer is one of the leading cancers among women all over India. This type of cancer leads to malignant tumor developed in the breast. Recent methodologies have undergone many classification methods to analyze the characteristics of gene expression. This paper focuses on computational method such as fuzzy based logistic regression to predict the expression of the gene data. In order to bring accuracy and to solve the inefficiency in feature selection of gene expression data, LASSO Logistic Regression (LLR), a novel methodology is implemented. For computational tractable, Maximum Likelihood Estimation (MLE) is implied with regression model. Diagnosis and prognosis of breast cancer becomes a great challenge in the medical era. This research work explores the mining technology based algorithm to classify the cancer data using fuzzy methodology by evaluating few samples of gene expression data of breast cancer as a training set and the resultant test data are validated to predict the cancer at the earlier stage. For feasible analysis, Expectation Maximization (EM) algorithm is deployed for unknown or missing parameters of gene data expression.",2019,Measurement
Integration of gene expression and DNA-methylation profiles improves molecular subtype classification in acute myeloid leukemia,"BackgroundAcute Myeloid Leukemia (AML) is characterized by various cytogenetic and molecular abnormalities. Detection of these abnormalities is important in the risk-classification of patients but requires laborious experimentation. Various studies showed that gene expression profiles (GEP), and the gene signatures derived from GEP, can be used for the prediction of subtypes in AML. Similarly, successful prediction was also achieved by exploiting DNA-methylation profiles (DMP). There are, however, no studies that compared classification accuracy and performance between GEP and DMP, neither are there studies that integrated both types of data to determine whether predictive power can be improved.ApproachHere, we used 344 well-characterized AML samples for which both gene expression and DNA-methylation profiles are available. We created three different classification strategies including early, late and no integration of these datasets and used them to predict AML subtypes using a logistic regression model with Lasso regularization.ResultsWe illustrate that both gene expression and DNA-methylation profiles contain distinct patterns that contribute to discriminating AML subtypes and that an integration strategy can exploit these patterns to achieve synergy between both data types. We show that concatenation of features from both data sets, i.e. early integration, improves the predictive power compared to classifiers trained on GEP or DMP alone. A more sophisticated strategy, i.e. the late integration strategy, employs a two-layer classifier which outperforms the early integration strategy.ConclusionWe demonstrate that prediction of known cytogenetic and molecular abnormalities in AML can be further improved by integrating GEP and DMP profiles.",2015,BMC Bioinformatics
Efficient Approach to Correct Read Alignment for Pseudogene Abundance Estimates,"RNA-Sequencing has been the leading technology to quantify expression of thousands of genes simultaneously. The data analysis of an RNA-Seq experiment starts from aligning short reads to the reference genome/transcriptome or reconstructed transcriptome. However, current aligners lack the sensitivity to distinguish reads that come from homologous regions of an genome. One group of these homologies is the paralog pseudogenes. Pseudogenes arise from duplication of a set of protein coding genes, and have been considered as degraded paralogs in the genome due to their lost of functionality. Recent studies have provided evidence to support their novel regulatory roles in biological processes. With the growing interests in quantifying the expression level of pseudogenes at different tissues or cell lines, it is critical to have a sensitive method that can correctly align ambiguous reads and accurately estimate the expression level among homologous genes. Previously in PseudoLasso, we proposed a linear regression approach to learn read alignment behaviors, and to leverage this knowledge for abundance estimation and alignment correction. In this paper, we extend the work of PseudoLasso by grouping the homologous genomic regions into different communities using a community detection algorithm, followed by building a linear regression model separately for each community. The results show that this approach is able to retain the same accuracy as PseudoLasso. By breaking the genome into smaller homologous communities, the running time is improved from quadratic growth to linear with respect to the number of genes.",2017,IEEE/ACM Transactions on Computational Biology and Bioinformatics
Improvement of inspection system for common crossings by track side monitoring and prognostics,Scheduled inspections of common crossings are one of the main cost drivers of railway maintenance. Prognostics and health management (PHM) approach and modern monitoring means offer many possibilities in the optimization of inspections and maintenance. The present paper deals with data driven prognosis of the common crossing remaining useful life (RUL) that is based on an inertial monitoring system. The problem of scheduled inspections system for common crossings is outlined and analysed. The proposed analysis of inertial signals with the maximal overlap discrete wavelet packet transform (MODWPT) and Shannon entropy (SE) estimates enable to extract the spectral features. The relevant features for the acceleration components are selected with application of Lasso (Least absolute shrinkage and selection operator) regularization. The features are fused with time domain information about the longitudinal position of wheels impact and train velocities by multivariate regression. The fused structural health (SH) indicator has a significant correlation to the lifetime of crossing. The RUL prognosis is performed on the linear degradation stochastic model with recursive Bayesian update. Prognosis testing metrics show the promising results for common crossing inspection scheduling improvement.,2019,
"Discussion of 'Correlated variables in regression: Clustering and sparse estimation' by Peter BÃ¼hlmann, Philipp RÃ¼timann, Sara van de Geer and Cun-Hui Zhang","We would like to begin by congratulating the authors on their fine paper. Handling highly correlated variables is one of the most important issues facing practitioners in high-dimensional regression problems, and in some ways it is surprising that it has not received more attention up to this point. The authors have made substantial progress towards practical methodological proposals, however, and we are sure that the paper will stimulate considerable future research. In this discussion, we present a possible improvement to the cluster representative Lasso, give some further insights into the cluster group Lasso and conclude with some brief remarks on one possible new direction suggested by the work.",2013,Journal of Statistical Planning and Inference
Hyperspectral Imagery Classification via Stochastic HHSVMs,"Hyperspectral imagery (HSI) has shown promising results in real-world applications. However, the technological evolution of optical sensors poses two main challenges in HSI classification: 1) the spectral band is usually redundant and noisy and 2) HSI with millions of pixels has become increasingly common in real-world applications. Motivated by the recent success of hybrid huberized support vector machines (HHSVMs), which inherit the benefits of both lasso and ridge regression, this paper first investigates the advantages of HHSVM for HSI applications. Unfortunately, the existing HHSVM solvers suffer from prohibitive computational costs on large-scale data sets. To solve this problem, this paper proposes simple and effective stochastic HHSVM algorithms for HSI classification. In the stochastic settings, we show that with a probability of at least <inline-formula> <tex-math notation=""LaTeX"">$1-\varrho $ </tex-math></inline-formula>, our algorithms find an <inline-formula> <tex-math notation=""LaTeX"">$\epsilon $ </tex-math></inline-formula>-accurate solution using <inline-formula> <tex-math notation=""LaTeX"">$\tilde {O}({1}/{\lambda _{2}\epsilon })$ </tex-math></inline-formula> iterations. Since the convergence rate of our algorithms does not depend on the size of the training set, our algorithms are suitable for handling large-scale problems. We demonstrate the superiority of our algorithms by conducting experiments on large-scale binary and multiclass classification problems, comparing to the state-of-the-art HHSVM solvers. Finally, we apply our algorithms to real HSI classification and achieve promising results.",2019,IEEE Transactions on Image Processing
Prediction of pneumonia hospitalization in adults using health checkup data,"OBJECTIVES
Community-acquired pneumonia is a common cause of hospitalization, and pneumococcal vaccinations are recommended for high-risk individuals. Although risk factors for pneumonia have been identified, there are currently no pneumonia hospitalization prediction models based on the risk profiles of healthy subjects. This study aimed to develop a predictive model for pneumonia hospitalization in adults to accurately identify high-risk individuals to facilitate the efficient prevention of pneumonia.


METHODS
We conducted a retrospective database analysis using health checkup data and health insurance claims data for residents of Kyoto prefecture, Japan, between April 2010 and March 2015. We chose adults who had undergone health checkups in the first year of the study period, and tracked pneumonia hospitalizations over the next 5 years. Subjects were randomly divided into training and test sets. The outcome measure was pneumonia hospitalization, and candidate predictors were obtained from the health checkup data. The prediction model was developed and internally validated using a LASSO logistic regression analysis. Lastly, we compared the new model with comparative models.


RESULTS
The study sample comprised 54,907 people who had undergone health checkups. Among these, 921 were hospitalized for pneumonia during the study period. The c-statistic for the prediction model in the test set was 0.71 (95% confidence interval: 0.69-0.73). In contrast, a comparative model with only age and comorbidities as predictors had a lower c-statistic of 0.55 (95% confidence interval: 0.54-0.56).


CONCLUSIONS
Our predictive model for pneumonia hospitalization performed better than comparative models, and may be useful for supporting the development of pneumonia prevention measures.",2017,PLoS ONE
Incorporating scientific knowledge into phenotype development: penalized latent class regression.,"The field of psychiatric genetics is hampered by the lack of a clear taxonomy for disorders. Building on the work of Houseman and colleagues (Feature-specific penalized latent class analysis for genomic data. Harvard University Biostatistics Working Paper Series, Working Paper 22, 2005), we describe a penalized latent class regression aimed at allowing additional scientific information to influence the estimation of the measurement model, while retaining the standard assumption of non-differential measurement. In simulation studies, ridge and LASSO penalty functions improved the precision of estimates and, in some cases of differential measurement, also reduced bias. Class-specific penalization enhanced separation of latent classes with respect to covariates, but only in scenarios where there was a true separation. Penalization proved to be less computationally intensive than an analogous Bayesian analysis by a factor of 37. This methodology was then applied to data from normal elderly subjects from the Cache County Study on Memory and Aging. Addition of APO-E genotype and a number of baseline clinical covariates improved the dementia prediction utility of the latent classes; application of class-specific penalization improved precision while retaining that prediction utility. This methodology may be useful in scenarios with large numbers of collinear covariates or in certain cases where latent class model assumptions are violated. Investigation of novel penalty functions may prove fruitful in further refining psychiatric phenotypes.",2011,Statistics in medicine
Least Angle Regression in Tangent Space and LASSO for Generalized Linear Model,"We propose sparse estimation methods for the generalized linear models, which run Least Angle Regression (LARS) and Least Absolute Shrinkage and Selection Operator (LASSO) in the tangent space of the manifold of the statistical model. Our approach is to roughly approximate the statistical model and to subsequently use exact calculations. LARS was proposed as an efficient algorithm for parameter estimation and variable selection for the normal linear model. The LARS algorithm is described in terms of Euclidean geometry with regarding correlation as metric of the space. Since the LARS algorithm only works in Euclidean space, we transform a manifold of the statistical model into the tangent space at the origin. In the generalized linear regression, this transformation allows us to run the original LARS algorithm for the generalized linear models. The proposed methods are efficient and perform well. Real-data analysis shows that the proposed methods output similar results as that of the $l_1$-penalized maximum likelihood estimation for the generalized linear models. Numerical experiments show that our methods work well and they can be better than the $l_1$-penalization for the generalized linear models in generalization, parameter estimation, and model selection.",2019,ArXiv
Online Static Security Assessment of Power Systems Based on Lasso Algorithm,"As one important means of ensuring secure operation in a power system, the contingency selection and ranking methods need to be more rapid and accurate. A novel method-based least absolute shrinkage and selection operator (Lasso) algorithm is proposed in this paper to apply to online static security assessment (OSSA). The assessment is based on a security index, which is applied to select and screen contingencies. Firstly, the multi-step adaptive Lasso (MSA-Lasso) regression algorithm is introduced based on the regression algorithm, whose predictive performance has an advantage. Then, an OSSA module is proposed to evaluate and select contingencies in different load conditions. In addition, the Lasso algorithm is employed to predict the security index of each power system operation state with the consideration of bus voltages and power flows, according to Newton-Raphson load flow (NRLF) analysis in post-contingency states. Finally, the numerical results of applying the proposed approach to the IEEE 14-bus, 118-bus, and 300-bus test systems demonstrate the accuracy and rapidity of OSSA.",2018,ArXiv
Canonical Correlation and Regression Analyses of Globular Clusters in Milky Way Galaxy,"Study about complex relationships between different characteristics of an astronomical object is a momentous research topic in Astronomy as well as Astrostatistics. Correlation and regression analyses are the techniques which can quantify such relationships. A study on the relationships between different parameters of globular clusters in the Milky Way is used to uncover the formation and evolution of the Milky Way galaxy. We consider a
sample of 134 globular clusters in the Milky Way galaxy from the current catalog of globular clusters (2010 edition) compiled by William E. Harris. We have divided the globular clusters under study into three subpopulations (metal-rich disk, metal-poor disk, and metal-poor halo) according to the mixing proportion values of the fitted mixture model on metallicity values of clusters and distance from the galactic center. We investigate relationships between different parameter sets in different subpopulations using Canonical Correlation Analysis via Projection Pursuit (CCAPP) and Kernel Canonical Correlation Analysis (KCCA) using Radial Basis kernel function. According to the findings of CCAPP and KCCA, photometric and
structural parameter sets are highly associated. For the more elaborate study about these relationships, we have considered Multiple Regression Analysis with structure parameters as explanatory variables and cluster luminosity as response variables. We face multicollinearity problems (using variance inflation factor) among structure parameters and fit regression models specially designed for tackling multicollinearity problem (Ridge, LASSO or Elastic net). It has been found that some structure parameters have nonlinear relationships with cluster luminosity and we have explained such nonlinear relationships using polynomial regression models.",2019,International journal of applied mathematics and statistics
An accurate regression of developmental stages for breast cancer based on transcriptomic biomarkers.,"AIM
Breast cancers at different stages have tremendous differences on both phenotypic and molecular patterns. The developmental stage is an essential factor in the clinical decision of treatment plans, but was usually formulated as a classification problem, which ignored the consecutive relationships among them.


MATERIALS & METHODS
This study proposed a regression-based procedure to detect the stage biomarkers of breast cancers. Biomarkers were detected by the Lasso and Ridge algorithms.


RESULTS & CONCLUSION
A collaboration duet of Lasso and Ridge regression algorithms achieved the best performances, with classification accuracy (Acc) equal to 0.8294 and regression goodness-of-fit (R2) equal toÂ 0.7810. The 265 biomarker genes were enriched with the signal peptide-based secretion function with the Bonferroni-corrected p-value equal to 6.9408e-3 and false discovery rate (FDR) equal to 1.1614e-2.",2019,Biomarkers in medicine
Identification of an eight-lncRNA prognostic model for breast cancer using WGCNA network analysis and a Cox-proportional hazards model based on L1-penalized estimation,"An everâ€‘increasing number of long noncoding (lnc)RNAs has been identified in breast cancer. The present study aimed to establish an lncRNA signature for predicting survival in breast cancer. RNA expression profiling was performed using microarray gene expression data from the National Center for Biotechnology Information Gene Expression Omnibus, followed by the identification of breast cancerâ€‘related preserved modules using weighted gene coâ€‘expression network (WGCNA) network analysis. From the lncRNAs identified in these preserved modules, prognostic lncRNAs were selected using univariate Cox regression analysis in combination with the L1â€‘penalized (LASSO) Coxâ€‘proportional Hazards (Coxâ€‘PH) model. A risk score based on these prognostic lncRNAs was calculated and used for risk stratification. Differentially expressed RNAs (DERs) in breast cancer were identified using MetaDE. Gene Set Enrichment Analysis pathway enrichment analysis was conducted for these prognostic lncRNAs and the DERs related to the lncRNAs in the preserved modules. A total of five preserved modules comprising 73 lncRNAs were mined. An eightâ€‘lncRNA signature (IGHA1, IGHGP, IGKV2â€‘28, IGLL3P, IGLV3â€‘10, AZGP1P1, LINC00472 and SLC16A6P1) was identified using the LASSO Coxâ€‘PH model. Risk score based on these eight lncRNAs could classify breast cancer patients into two groups with significantly different survival times. The eightâ€‘lncRNA signature was validated using three independent cohorts. These prognostic lncRNAs were significantly associated with the cell adhesion molecules pathway, JAKâ€‘signal transducer and activator of transcriptionÂ 5A pathway, and erbb pathway and are potentially involved in regulating angiotensin II receptor typeÂ 1, neuropeptideÂ Y receptorÂ Y1, KISS1 receptor, and Câ€‘C motif chemokine ligandÂ 5. The developed eightâ€‘lncRNA signature may have clinical implications for predicting prognosis in breast cancer. Overall, this study provided possible molecular targets for the development of novel therapies against breast cancer.",2019,International Journal of Molecular Medicine
Random intercept selection in structured additive regression models,"This paper discusses random intercept selection within the context of semiparametric regression models with structured additive predictor (STAR). STAR models can deal simultaneously with nonlinear covariate effects and time trends, unit- or cluster-specific heterogeneity, spatial heterogeneity and complex interactions between covariates of different type. The random intercept selection is based on spike and slab priors for the variances of the random intercept coefficients. The aim is to achieve shrinkage of small random intercept coefficients to zero similar as for the LASSO in frequentist linear models. The mixture structure of the spike and slab prior allows for selective shrinkage, as coefficients are either heavily shrunk under the spike component or left almost unshrunk under the slab component. The hyperparameters of the spike and slab prior are chosen by theoretical considerations based on the prior inclusion probability of a particular random coefficient given the true effect size. Using extensive simulation experiments we compare random intercept models based on spike and slab priors for variances with the usual Inverse Gamma priors. A case study on malnutrition of children in Zambia illustrates the methodology in a real data example.",2015,
High-dimensional regression mixture models to perform clustering - application to electricity dataset.,"Model-based clustering is useful to understand how data is grouped. We propose to introduce the Lasso-MLE procedure, which uses finite mixture regression models to perform model-based clustering, on electricity dataset. To improve electricity consumption prediction, we cluster together consumers who have the same reliance between two successive days. To deal with functional datasets (response and regressors) we use the wavelet coefficients rather than the discretization. Then, we construct a model collection with more or less components and more or less relevant variables, and select some with the slope heuristic. Relevant variables are detected with the Lasso estimator, whereas we refit estimators with the maximum likelihood estimator. We run this procedure on Thursday 5 and Wednesday 6 January 2010. We analyze clusters done by the procedure with usual electricity consumption criterion, as the temperature, and the tarifs among others.",2015,International Federation of Classification Societies
Utility of Genetic Testing in Addition to Mammography for Determining Risk of Breast Cancer Depends on Patient Age,"While screening and treatment have sharply reduced breast cancer mortality in the past 50 years, more targeted diagnostic testing may improve the accuracy and efficiency of care. Our retrospective, age-matched, case-control study evaluated the differential value of mammography and genetic variants to predict breast cancer depending on patient age. We developed predictive models using logistic regression with group lasso comparing (1) diagnostic mammography findings, (2) selected genetic variants, and (3) a combination of both. For women older than 60, mammography features were most predictive of breast cancer risk (imaging AUC = 0.74, genetic variants AUC = 0.54, combined AUC = 0.71). For women younger than 60 there is additional benefit to obtaining genetic testing (imaging AUC = 0.69, genetic variants AUC = 0.70, combined AUC = 0.72). In summary, genetic testing supplements mammography in younger women while mammography appears sufficient in older women for breast cancer risk prediction.",2018,AMIA Summits on Translational Science Proceedings
Enhanced detection of solids from Gaussian spectral features,"We define a spectral feature approach to improve compositional exploitation for hyperspectral imaging. Focusing on the spectral feature characteristics of materials makes detection more robust to the spectral variability of both the target and background encountered during the collection process, consequently reducing detection false alarm rates without compromising sensitivity. Our method decomposes each spectrum into a small set of Gaussian-shaped components using LASSO regression (L1-regularization). A detection framework extracts the combinations of spectral features unique to a material of interest, allowing identification of target materials given its presence in intimate (i.e., nonlinear) mixtures and at different morphologies (e.g., particle sizes). We validate our methods with experimental data that incorporate variability from particle size, measurement angle, and atmospheric conditions. Initial exploitation results using our approach for fused silica demonstrate improved performance extendible across localized experimental conditions.",2017,2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)
A 1.06 Î¼W smart ECG processor in 65 nm CMOS for real-time biometrie authentication and personal cardiac monitoring,"A smart wearable electrocardiographic (ECG) processor is presented for secure ECG-based biometric authentication and cardiac monitoring, including arrhythmia and anomaly detection. Data-driven Lasso regression and low-precision techniques are developed to compress the neural networks by 24.4X. The prototype chip fabricated in 65 nm LP CMOS consumes 1.06 Î¼W at 0.55 V for real-time ECG authentication. Equal error rates of 0.74% and 1.7% are achieved on ECG-ID database and in-house 645-subject database, respectively.",2017,
"Identification of significant genetic variants via SLOPE, and its extension to group SLOPE","The method of Sorted L-One Penalized Estimation, abbreviated as SLOPE, is a novel sparse regression method for model selection introduced in a sequence of recent papers, [4], [3] and [7] by Bogdan, van den Berg, Sabatti, Su and Candes. It estimates the coefficients of a linear model that possibly has more unknown parameters than observations. In many settings the SLOPE method is shown to successfully control the false discovery rate (the proportion of the irrelevant among all selected predictors) at a user specified level. In this paper we evaluate its performance on genetic data, and show its superiority over LASSO which is a related and popular method. Often in genetic data sets, group structures among the predictor variables are given as prior knowledge, such as SNPs in a gene or genes in a pathway. Following this motivation we extend SLOPE in the spirit of Group LASSO to Group SLOPE, a method that can handle group structures between the predictor variables, which are ubiquitous in real genetic data. Our simulation results show that the proposed Group SLOPE method is capable of controlling the false discovery rate at a specified level. Moreover, our simulations show that compared to Group LASSO, Group SLOPE in general achieves a higher power as well as a lower false discovery rate.",2015,
Comment to â€œ ` 1-Penalization for Mixture Regression Models â€ by,"I would like to congratulate the authors for this very interesting contribution. The generalization of `1-penalized linear regression to the â€œmixture-of-Gaussian-regressionsâ€ model raises some very interesting questions both from theoretical and algorithmic points of view and the paper offers a variety of powerful tools to attack both problems. In this comment I would like to mention another direction in which algorithmic issues become a relevant and non-trivial challenge. The basic underlying assumption behind lasso and various related methods of linear regression is sparsity. In the simplest fixed design regression model, one observes a random vector Y = (Y1, . . . , Yn) generated by",2010,
A Panel of Learning Methods for the Reconstruction of Gene Regulatory Networks in a Systems Genetics Context,"In this chapter, we study different gene regulatory network learning methods based on penalized linear regressions (the Lasso regression and the Dantzig Selector), Bayesian networks, and random forests. We also replicated the learning scheme using bootstrapped sub-samples of the observations. The biological motiva- tion relies on a tough nut to crack in Systems Biology: understanding the intertwined action of genome elements and gene activity to model gene regulatory features of an organism. We introduce the used methodologies, and then assess the methods on simulated ""Systems Genetics"" (or genetical genomics) datasets. Our results show that methods have very different performances depending on tested simulation set- tings: total number of genes in the considered network, sample size, gene expression heritability, and chromosome length. We observe that the proposed approaches are",2013,
Letter to the Editor,"The paper by Alfons, Croux and Gelper (2013), Sparse least trimmed squares regression for analyzing high-dimensional large data sets, considered a combination of least trimmed squares (LTS) and lasso penalty for robust and sparse high-dimensional regression. In a recent paper [She and Owen (2011)], a method for outlier detection based on a sparsity penalty on the mean shift parameter was proposed (designated by â€œSOâ€ in the following). This work is mentioned in Alfons et al. as being an â€œentirely different approach.â€ Certainly the problem studied by Alfons et al. is novel and interesting. However, there is actually a connection between the LTS approach and that of She and Owen (2011). This connection can be roughly seen from Theorem 4.1 and Proposition 4.1 of She and Owen (2011), where iterative thresholding was related to penalized regression and also to the M-estimator. In particular, although not explicitly mentioned in She and Owen (2011), from this one can derive the close relationship between hard thresholding, L0 penalty and LTS [the relationship between hard thresholding and L0 penalty was mentioned on page 630 of She and Owen (2011)]. Given that LTS regression is not directly posed as an M-estimator, the following proposition can be directly shown via elementary arguments.",2013,
Pretreatment MR-Based Radiomics Signature as Potential Imaging Biomarker for Assessing the Expression of Topoisomerase II alpha (TOPO-IIÎ±) in Rectal Cancer.,"BACKGROUND
Rectal cancer (RC) is one of the most common cancers throughout the world. Chemotherapy or neoadjuvant chemotherapy play an important role in the treatment of advanced RC. Whether to add topoisomerase inhibitor to individualized chemotherapy is a puzzling question for clinicians.


PURPOSE
To investigate whether pretreatment MR-based radiomics signature can assess the expression of topoisomerase II alpha (TOPO-IIÎ±) in RC.


STUDY TYPE
Retrospective.


POPULATION
In all, 122 patients with RC. Field Strength/Sequence: Pretreatment 3.0T; T2 WI turbo spin echo (TSE) sequence.


ASSESSMENT
A training group (n = 85) and a test group (n = 37) with pathologically confirmed RC. Patients underwent TOPO-IIÎ± expression. A total of 180 radiomics features were extracted from oblique axial T2 WI TSE images of the entire primary tumor. The least absolute shrinkage and selection operator (LASSO) regression model was used to reduce the dimension of the data and select the features.


STATISTICAL TESTS
The assessment models were established by multivariable logistic regression analysis. The performance of the model was assessed by the receiver operating characteristic (ROC) curve, nomogram, and calibration.


RESULTS
The radiomics signature, which consisted of 10 selected optimal features, was significantly associated with TOPO-IIÎ± expression (P < 0.01 for both training and test groups). The area under the curve (AUC), the sensitivity, and the specificity for assessing TOPO-IIÎ± expression, were 0.859, 0.872, and 0.739, respectively, in the training group, while they were 0.762, 0.941, and 0.600 in the test group. The nomogram model of the radiomics signature (Rad-score) had good calibration. Calibration curves were plotted to assess the calibration of the radiomics nomogram that was accompanied with the Hosmer-Lemeshow test (P = 0.52).


DATA CONCLUSION
The proposed pretreatment MR-based radiomics signature was associated with TOPO-IIÎ± expression. A radiomics nomogram might be helpful in the individualized assessment of TOPO-IIÎ± expression in patients with RC.


LEVEL OF EVIDENCE
2 Technical Efficacy: Stage 2 J. Magn. Reson. Imaging 2019.",2019,Journal of magnetic resonance imaging : JMRI
Cardiorespiratory fitness in patients with rheumatoid arthritis is associated with the patient global assessment but not with objective measurements of disease activity,"Objective
Patients with rheumatoid arthritis (RA) suffer from more cardiovascular disease (CVD), and develop cardiovascular risk factors at an earlier age than the general population. Cardiorespiratory fitness (CRF) is an important predictor of cardiovascular health. There are few data regarding CRF of RA patients, measured as peak oxygen uptake (VO2peak) by the gold standard method; cardiopulmonary exercise testing. We compared CRF in RA patients to those from a healthy population, and investigated if risk factors for CVD and RA-specific variables including subjective and objective disease activity measures were associated with CRF in RA patients.


Methods
VO2peak tests of RA patients (n=93) were compared to those of an age-matched and gender-matched healthy population (n=4631) from the Nord-TrÃ¸ndelag Health Study. Predictors of VO2peak were found using Lasso (least absolute shrinkage and selection operator) regression, followed by standardised multiple linear regression.


Results
Women with RA â‰¥40 years and men with RA aged 40-49 years or 60-69 years had up to 20% lower CRF than the healthy population in the same age groups. By relative importance, body mass index (standardised coefficient=-0.25, p<0.001), physical activity level (coefficient=0.21, p<0.001), patient global assessment (PGA; coefficient=-0.14, p=0.006), systolic blood pressure (coefficient=-0.12, p=0.016), resting heart rate (coefficient=-0.11, p=0.032) and smoking (coefficient=-0.10, p=0.046) were significant predictors of CRF (R2=0.82, gender-adjusted and age-adjusted).


Conclusion
CRF in RA patients was lower than in a healthy population. CRF was associated with common risk factors for CVD and the PGA score. Focusing on fitness in RA patients may improve cardiovascular health.",2019,RMD Open
A Novel Methodology using CT Imaging Biomarkers to Quantify Radiation Sensitivity in the Esophagus with Application to Clinical Trials,"Personalized cancer therapy seeks to tailor treatment to an individual patientâ€™s biology. Therefore, a means to characterize radiosensitivity is necessary. In this study, we investigated radiosensitivity in the normal esophagus using an imaging biomarker of radiation-response and esophageal toxicity, esophageal expansion, as a method to quantify radiosensitivity in 134 non-small-cell lung cancer patients, by using K-Means clustering to group patients based on esophageal radiosensitivity. Patients within the cluster of higher response and lower dose were labelled as radiosensitive. This information was used as a variable in toxicity prediction modelling (lasso logistic regression). The resultant model performance was quantified and compared to toxicity prediction modelling without utilizing radiosensitivity information. The esophageal expansion-response was highly variable between patients, even for similar radiation doses. K-Means clustering was able to identify three patient subgroups of radiosensitivity: radiosensitive, radio-normal, and radioresistant groups. Inclusion of the radiosensitive variable improved lasso logistic regression models compared to model performance without radiosensitivity information. Esophageal radiosensitivity can be quantified using esophageal expansion and K-Means clustering to improve toxicity prediction modelling. Finally, this methodology may be applied in clinical trials to validate pre-treatment biomarkers of esophageal toxicity.",2017,Scientific Reports
Penalizied Logistic Regression for Classification,"Investigation for using different penalty functions ( L1 absolute value penalty or lasso,L2 standard weight decay or ridge regression, weight elimina tio etc.) on the weights for logistic regression for classification. 5 da ta sets from UCI Machine Learning Repository were used.",2006,
Establishment of validated models for non-invasive prediction of rectal temperature of sows using infrared thermography and chemometrics,"Rectal temperature is an important physiological indicator used to characterize the reproductive and health status of sows. Infrared thermography, a surface temperature measurement technology, was investigated in this study to explore its feasibility in non-invasive detection of rectal temperature in sows. A total of 124 records of rectal temperature and surface temperature in various body regions of 99 Landrace Ã— Yorkshire crossbred sows were collected. These surface temperatures together with ambient temperature, ambient humidity, and wind speed in pig pens were correlated with the real rectal temperature of sows to establish rectal temperature prediction models by introducing chemometrics algorithms. Two types of models, i.e., full feature models and selected feature models, were established by applying the partial least squares regression (PLSR) method. The optimal model was attained when 7 important features were selected by LARS-Lasso, where correlation coefficients and root mean squared errors of calibration were 0.80 and 0.30 Â°C, respectively. Particularly, the validity and stability of established simplified models were further evaluated by applying the model to an independent prediction set, where correlation coefficients and root mean squared errors for prediction were 0.80 and 0.35 Â°C, respectively. The validation of established models is scarce in previous similar studies. Above all, this study demonstrated that introduction of chemometrics methodologies would lead to more reliable and accurate model for predicting sow rectal temperature, thus the potential for ensuring animal welfare in a broader view if extended to more applications.",2019,International Journal of Biometeorology
Robust parametric classification and variable selection by a minimum distance criterion,"We investigate a robust penalized logistic regression algorithm based on a minimum distance criterion. Influential outliers are often associated with the explosion of parameter vector estimates, but in the context of standard logistic regression, the bias due to outliers always causes the parameter vector to implode, that is, shrink toward the zero vector. Thus, using LASSO-like penalties to perform variable selection in the presence of outliers can result in missed detections of relevant covariates. We show that by choosing a minimum distance criterion together with an elastic net penalty, we can simultaneously find a parsimonious model and avoid estimation implosion even in the presence of many outliers in the important small n large p situation. Minimizing the penalized minimum distance criterion is a challenging problem due to its nonconvexity. To meet the challenge, we develop a simple and efficient MM (majorizationâ€“minimization) algorithm that can be adapted gracefully to the small n large p context...",2014,Quality Engineering
Sparse Bayes estimation in non-Gaussian models via data augmentation,"In this paper we provide a data-augmentation scheme that unifies many common sparse Bayes estimators into a single class. This leads to simple iterative algorithms for estimating the posterior mode under arbitrary combinations of likelihoods and priors within the class. The class itself is quite large: for example, it includes quantile regression, support vector machines, and logistic and multinomial logistic regression, along with the usual ridge regression, lasso, bridge/â€˜ a estimators, and regression with heavy-tailed errors. To arrive at this unified framework, we represent a wide class of objective functions as varianceâ€mean mixtures of Gaussians involving both the likelihood and penalty functions. This generalizes existing theory based solely on variance mixtures for the penalty function, and allows the theory of conditionally normal linear models to be brought to bear on a much wider class of models. We focus on two possible choices of the mixing measures: the generalized inverse-Gaussian and Polya distributions, leading to the hyperbolic and Z distributions, respectively. We exploit this conditional normality to find sparse, regularized estimates using tilted iteratively re-weighted least squares (TIRLS). Finally, we characterize the conditional moments of the latent variances for any model in our proposed class, and show the relationship between our method and two recent algorithms: LQA (local quadratic approximation) and LLA (local linear approximation).",2011,
Directing Power towards Sub-regions of the Alternative Hypothesis,"In this paper, I propose a novel test statistic for testing hypotheses about a potentially high-dimensional parameter vector. To obtain the statistic, I generalize the Mahalanobis distance to measure length in a direction of interest. The test statistic is the sample analogue of the distance and directs power towards a sub-region of the alternative hypothesis (henceforth sub-alternative). Its existence depends on a restricted eigenvalue condition that is tied directly to the scope of the sub-alternative. I show that if the conventional sample covariance matrix is used, then the computation of the test statistic reduces to linear regression with a constant dependent variable, restricted by the same constraints that specify the sub-alternative. To demonstrate the test statistic, I consider the case of testing against a sparse sub-alternative, which is defined by the number of element-wise violations of a null hypothesis. In this case the computation reduces to `0-regularized regression (best subset selection). In addition, I show that `1-regularized regression (Lasso) corresponds to near-sparse sub-alternatives.",2019,
Accelerated Coordinate Descent with Adaptive Coordinate Frequencies,"Coordinate descent (CD) algorithms have become the method of choice for solving a number of machine learning tasks. They are particularly popular for training linear models, includ- ing linear support vector machine classication, LASSO regression, and logistic regression. We propose an extension of the CD algorithm, called the adaptive coordinate frequencies (ACF) method. This modied CD scheme does not treat all coordinates equally, in that it does not pick all coordinates equally often for optimization. Instead the relative frequen- cies of coordinates are subject to online adaptation. The resulting optimization scheme can result in signicant speed-ups. We demonstrate the usefulness of our approach on a number of large scale machine learning problems.",2013,
Improved estimation of dynamic connectivity from resting-state fMRI data,"Functional magnetic resonance imaging (fMRI) has been widely used for neuronal connectivity analysis. As a datadriven technique, independent component analysis (ICA) has become a valuable tool for fMRI studies. Recently, due to the dynamic nature of the human brain, time-varying connectivity analysis is regarded as an important measure to reveal essential information within the network. The sliding window approach has been commonly used to extract dynamic information from fMRI time series. However, it has some limitations due to the assumption that connectivity at a given time can be estimated from all the samples of the input time series data spanned by the selected window. To address this issue, we apply a time-varying graphical lasso model (TVGL) proposed by Hallac et al., which can infer the network even when the observation interval is at only one time point. On the other hand, recent results have shown that the individualâ€™s connectivity profiles can be used as â€œfingerprintâ€ to identify subjects from a large group. We hypothesize that the subject-specific FC profiles may have the critical effect on analyzing FC dynamics at a group level. In this work, we apply a group ICA (GICA) based data-driven framework to assess dynamic functional network connectivity (dFNC), based on the combination of GICA and TVGL. Also, we use the regression model to remove the subject-specific individuality in detecting functional dynamics. The results prove our hypothesis and suggest that removing the individual effect may benefit us to assess the connectivity dynamics within the human brain.",2019,
