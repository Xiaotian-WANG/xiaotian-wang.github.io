title,abstract,year,journal
Pathwise Coordinate Optimization,"We consider â€œone-at-a-timeâ€ coordinate-wise descent algorithms for a class of convex optimization problems. An algorithm of this kind has been proposed for the L1-penalized regression (lasso) in the literature, but it seems to have been largely ignored. Indeed, it seems that coordinate-wise algorithms are not often used in convex optimization. We show that this algorithm is very competitive with the well-known LARS (or homotopy) procedure in large lasso problems, and that it can be applied to related methods such as the garotte and elastic net. It turns out that coordinate-wise descent does not work in the â€œfused lasso,â€ however, so we derive a generalized algorithm that yields the solution in much less time that a standard convex optimizer. Finally, we generalize the procedure to the two-dimensional fused lasso, and demonstrate its performance on some image smoothing problems. 1. Introduction. In this paper we consider statistical models that lead to convex optimization problems with inequality constraints. Typically, the optimization for these problems is carried out using a standard quadratic programming algorithm. The purpose of this paper is to explore â€œone-at-a-timeâ€ coordinate-wise descent algorithms for these problems. The equivalent of a coordinate descent algorithm has been proposed for the L1-penalized regression (lasso) in the literature, but it is not commonly used. Moreover, coordinate-wise algorithms seem too simple, and they are not often used in convex optimization, perhaps because they only work in specialized problems. We ourselves never appreciated the value of coordinate descent methods for convex statistical problems before working on this paper. In this paper we show that coordinate descent is very competitive with the wellknown LARS (or homotopy) procedure in large lasso problems, can deliver a path of solutions efficiently, and can be applied to many other convex statistical problems such as the garotte and elastic net. We then go on to explore a nonseparable problem in which coordinate-wise descent does not workâ€”the â€œfused lasso.â€ We derive a generalized algorithm that yields the solution in much less time that a standard convex optimizer. Finally, we generalize the procedure to",2007,The Annals of Applied Statistics
Abstract 18245: Identifying Novel Predictors for Incident Heart Failure Using Statistical Learning Techniques in the Womenâ€™s Health Initiative (WHI) Cohort,"Introduction: Machine learning (statistical learning) techniques applied to high-dimensional health data may aid in identifying novel predictors of heart failure (HF). We used machine learning to identify novel predictors of HF in post-menopausal women and compared these models to an established HF risk model. Methods: After performing minimum-necessary data cleaning on all baseline WHI variables, 1227 variables remained. Without a priori input, we separately applied the Least Absolute Shrinkage and Selection Operator (LASSO) technique with cross-validation, and Classification and Regression Trees (CART) to select sets of variables that are predictive for our primary outcome of incident heart failure hospitalization. We built Cox Proportional Hazards models using each set of predictors and using published predictors from the Atherosclerosis risk in Communities (ARIC) cohort. Model discrimination was compared using Receiver Operator Characteristic (ROC). Results: Total sample size was 44,173; there were 2,355 outcomes and the median time to event was 8.7 years. LASSO and CART identified 12 and 9 significant predictors, respectively. The highest correlation between selected variables was 0.56. Selected novel predictors include physical function, Hodgkinâ€™s Lymphoma, prior pulmonary embolism, Medicare insurance, and use of cardiotonic, antiarrhythmic and mineral supplement medication among others. Other variables reflected known risk factors for HF (Table). In ROC analysis the model using CART variables had the highest C-statistic (0.794), followed by LASSO (0.775) and ARIC (0.712). Conclusions: When applied in the WHI, machine learning techniques can identify novel sets of variables without a priori input that yield risk prediction models with improved discrimination as compared to an established HF risk model. Both the models and the novel predictors provide a basis for hypothesis generation and future investigation.",2016,Circulation
Comparison of machine learning algorithms for soil salinity predictions in three dryland oases located in Xinjiang Uyghur Autonomous Region (XJUAR) of China,"ABSTRACT Many different machine learning approaches have been applied for various purposes. However, there has been limited guidance regarding which, if any, machine learning models and covariate sets might be optimal for predicting soil salinity across different oases in the Xinjiang Uyghur Autonomous Region (XJUAR) of China. This study aimed to compare five machine learning algorithms, Least Absolute Shrinkage and Selection Operator (LASSO), Multiple Adaptive Regression Splines (MARS), Classification and Regression Trees (CART), Random Forest tree ensembles (RF), and Stochastic Gradient Treeboost (SGT), to predict soil salinity in three geographically distinct areas (the Qitai, Kuqa, and Yutian oases). A total of 21 data sets from three oases were used to evaluate the performance of the algorithm and to screen the optimal variables. The results show the following indices are considered to be important indicators for quantitative assessment of soil salinity: EEVI, CSRI, EVI2, GDVI, SAIO, and SIT. Comparison results show that SGT is the most suitable algorithm for predicting soil salinity in arid areas. This study provides a comprehensive comparison of machine learning techniques for soil salinity prediction and may assist in the modeling and variable selection of digital soil mapping in the XJUAR of China.",2019,European Journal of Remote Sensing
Mortality risk factors in patients with gastric cancer using Bayesian and ordinary Lasso logistic models: a study in the Southeast of Iran,"Aim
The aim of this study was to apply two types of statistical models to determine the factors that influence the mortality rate in patients with gastric cancer.


Background
In Iran, gastric cancer ranks the first and second most prevalent among men and women, respectively. It is the first cause of death in Iran in both gendersival.


Methods
In this retrospective study, data were obtained from 339 (216 male) patients diagnosed with gastric cancer in the city of Kerman (South-East of Iran) during 2001-2015. In this study, ordinary and Bayesian Lasso (least absolute shrinkage and selection operator) logistic regression models, with goodness-of-fit indices, were compared and the models' risk factors were also determined.


Results
The mean age of the participants was 62.84 Â±14.53 years, and 12.4% of them were younger than 45 years. Also, the mortality rate was 57.7%. Gender, morphology of the tumor, and time of diagnosis were found to be significant factors in the mortality of the patients in both models. This study found that the Bayesian Lasso model had better fitness.


Conclusion
The high mortality rate of gastric cancer and its high prevalence at age below 45 years are alarming. Thus, great attention should be paid to prevention, early diagnosis, especially in females, and adenocarcinoma to improve the survival of patients with gastric cancer.",2020,Gastroenterology and Hepatology From Bed to Bench
"Next Generation Statistical Genetics: Modeling, Penalization, and Optimization in High-Dimensional Data.","Statistical genetics is undergoing the same transition to big data that all branches of applied statistics are experiencing. With the advent of inexpensive DNA sequencing, the transition is only accelerating. This brief review highlights some modern techniques with recent successes in statistical genetics. These include: (a) lasso penalized regression and association mapping, (b) ethnic admixture estimation, (c) matrix completion for genotype and sequence data, (d) the fused lasso and copy number variation, (e) haplotyping, (f) estimation of relatedness, (g) variance components models, and (h) rare variant testing. For more than a century, genetics has been both a driver and beneficiary of statistical theory and practice. This symbiotic relationship will persist for the foreseeable future.",2014,Annual review of statistics and its application
Nonnegative adaptive lasso for ultra-high dimensional regression models and a two-stage method applied in financial modeling,"Abstract This paper proposes the nonnegative adaptive lasso method for variable selection both in the classical fixed p setting (OLS initial estimator) and the ultra-high dimensional setting (root-n-consistent initial estimator). This method is an extension of the adaptive lasso with nonnegative constraint on the coefficients. It is shown to have asymptotic unbiasedness, asymptotic normality and variable selection consistency and its mean squared error decays fast too. Comparing with other procedures, nonnegative adaptive lasso satisfies oracle properties and can select the true variables under fewer assumptions. To get the solution of the nonnegative adaptive lasso, we extend the multiplicative approach for computing. This algorithm is valid for the general framework where the number of regression parameters p is allowed to very large. Simulations are performed to illustrate above results. The constrained index tracking problem in the stock market without short sales is studied in the empirical part. A two-stage method, nonnegative adaptive lasso + nonnegative LS, is applied in the financial modeling. The tracking results indicate that nonnegative adaptive lasso and the two-stage method can both get small tracking error and is successful in assets selection.",2016,Journal of Statistical Planning and Inference
Structured Detection of Interactions with the Directed Lasso,"When considering low-dimensional geneâ€“treatment or geneâ€“environment interactions, we might suspect groups of genes to interact with treatment or environment in a similar way. For example, genes associated with related biological processes might interact with an environmental factor or a clinical treatment in its effect on a phenotype correspondingly. We use the idea of a structured interaction model together with penalized regression to limit the model complexity in a model in which we believe the interactions might behave in a similar way. We propose the directed lasso, a regression modeling strategy using a pairwise fused lasso penalty to encourage interaction model simplicity through fusion of effect size. We compare the performance of the directed lasso to the lasso and other methods in a simulation study and on data sampled from a breast cancer clinical trial.",2017,Statistics in Biosciences
Body mass estimation in xenarthra: a predictive equation suitable for all quadrupedal terrestrial placentals?,"The Magnorder Xenarthra includes strange extinct groups, like glyptodonts, similar to large armadillos, and ground sloths, terrestrial relatives of the extant tree sloths. They have created considerable paleobiological interest in the last decades; however, the ecology of most of these species is still controversial or unknown. The body mass estimation of extinct species has great importance for paleobiological reconstructions. The commonest way to estimate body mass from fossils is through linear regression. However, if the studied species does not have similar extant relatives, the allometric pattern described by the regression could differ from those shown by the extinct group. That is the case for glyptodonts and ground sloths. Thus, stepwise multiple regression were developed including extant xenarthrans (their taxonomic relatives) and ungulates (their size and ecological relatives). Cases were weighted to maximize the taxonomic evenness. Twenty-eight equations were obtained. The distribution of the percent of prediction error (%PE) was analyzed between taxonomic groups (Perissodactyla, Artiodactyla, and Xenarthra) and size groups (0-20 kg, 20-300 kg, and more than 300 kg). To assess the predictive power of the functions, equations were applied to species not included in the regression development [test set cross validation, (TSCV)]. Only five equations had a homogeneous %PE between the aforementioned groups. These were applied to five extinct species. A mean body mass of 80 kg was estimated for Propalaehoplophorus australis (Cingulata: Glyptodontidae), 594 kg for Scelidotherium leptocephalum (Phyllophaga: Mylodontidae), and 3,550.7 kg for Lestodon armatus (Phyllophaga: Mylodontidae). The high scatter of the body mass estimations obtained for Catonyx tarijensis (Phyllophaga: Mylodontidae) and Thalassocnus natans (Phyllophaga: Megatheriidae), probably due to different specializations, prevented us from predicting its body mass. Surprisingly, although obtained from ungulates and xenarthrans, these five selected equations were also able to predict the body mass of species from groups as different as rodents, carnivores, hyracoideans, or tubulidentates. This result suggests the presence of a complex common allometric pattern for all quadrupedal placentals.",2008,Journal of morphology
Predicting progression from mild cognitive impairment to Alzheimer's disease using longitudinal callosal atrophy,"INTRODUCTION
We investigate whether longitudinal callosal atrophy could predict conversion from mild cognitive impairment (MCI) to Alzheimer's disease (AD).


METHODS
Longitudinal (baselineÂ +Â 1-year follow-up) MRI scans of 132 MCI subjects from the Alzheimer's Disease Neuroimaging Initiative were used. A total of 54 subjects did not convert to AD over an average (Â±SD) follow-up of 5.46 (Â±1.63) years, whereas 78 converted to AD with an average conversion time of 2.56 (Â±1.65) years. Annual change in the corpus callosum thickness profile was calculated from the baseline and 1-year follow-up MRI. A logistic regression model with fused lasso regularization for prediction was applied to the annual changes.


RESULTS
We found a sex difference. The accuracy of prediction was 84% in females and 61% in males. The discriminating regions of corpus callosum differed between sexes. In females, the genu, rostrum, and posterior body had predictive power, whereas the genu and splenium were relevant in males.


DISCUSSION
Annual callosal atrophy predicts MCI-to-AD conversion in females more accurately than in males.",2016,"Alzheimer's & Dementia : Diagnosis, Assessment & Disease Monitoring"
Locating rare and weak material anomalies by convex demixing of propagating wavefields,"This paper considers the problem of detecting and localizing material anomalies in solid structures, given spatiotemporal observations at a pre-defined grid of points that collectively describe the material displacement resulting from an induced, propagating acoustic surface wave. We propose an approach that seeks to separate or â€œdemixâ€ each temporal snapshot of the propagating wavefield into its constituent components, which are assumed to be morphologically dissimilar in the vicinity of material defects. We cast this demixing approach as a group lasso regression task, characterized by morphologically dissimilar dictionaries, and establish conditions under which material anomalies may be accurately identified using this approach. We demonstrate and validate the performance of this approach on synthetic data as well as real-world data.",2015,2015 IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)
Regional variability of controls on post-fire watershed system flow response,"This research investigates the impact of wildfires on watershed flow regimes throughout the continental United States, specifically focusing on evaluation of national fire events within specified subregions and determination of the impact of climate and geophysical variables in post- fire flow response. Fire events were collected through federal and state-level databases and streamflow data were collected from U.S. Geological Survey stream gages. 428 watersheds were identified with at least 10 years of continuous pre-fire daily streamflow records and 5 years of continuous post-fire daily flow records. For each watershed, percent changes in annual seven day low-flows (7Q2) and annual seven day high-flows (7Q10) were calculated from pre- to post-fire. 12 independent variables were identified for each watershed and fire event, including topographic, land cover, and soils data. The national watersheds were divided into eight regions and a lasso linear regression model, applying the Leave-One-Out calibration method, was calculated for each region. Nash-Sutcliffe Efficiency (NSE) was used to determine the accuracy of the resulting models. Moran's I and Localized Indicators of Spatial Autocorrelation (LISAs) were calculated for all model residuals to test for spatial autocorrelation. The South East Coast Plains, Eastern Highlands, and Western Plains regions produced the most accurate linear models and displayed no spatial autocorrelation. The Western Mountain and Central Plains region models produced spatially autocorrelated residuals, indicating that the regions need to be further subdivided. Results of linear regression modeling showed varying importance of watershed and fire event variables, with conflicting correlation between land cover types and soil types by region. Addition of further independent variables, such as burn severity and further subdivision of land cover types, is ongoing and should allow for more accurate linear regression modeling.",2015,
"Genetic aetiology of blood pressure relates to aortic stiffness with bi-directional causality: evidence from heritability, blood pressure polymorphisms, and Mendelian randomization.","AIMS
Haemodynamic determinants of blood pressure (BP) include cardiac output (CO), systemic vascular resistance (SVR), and arterial stiffness. We investigated the heritability of these phenotypes, their association with BP-related single-nucleotide polymorphisms (SNPs), and the causal association between BP and arterial stiffness.


METHODS AND RESULTS
We assessed BP, central BP components, and haemodynamic properties (during a single visit) including CO, SVR, and pulse wave velocity (PWV, measure of arterial stiffness) in 3531 (1934 monozygotic, 1586 dizygotic) female TwinsUK participants. Heritability was estimated using structural equation modelling. Association with 984 BP-associated SNP was examined using least absolute shrinkage and selection operator (LASSO) and generalized estimating equation regression. One and two-sample Mendelian randomization (MR) was used to estimate the causal direction between BP and arterial stiffness including data on 436Â 419 UK Biobank participants. We found high heritability for systolic and pulsatile components of BP (>50%) and PWV (65%) with overlapping genes accounting for >50% of their observed correlation. Environmental factors explained most of the variability of CO and SVR (>80%). Regression identified SNPs (n = 5) known to be associated with BP to also be associated with PWV. One-sample MR showed evidence of bi-directional causal association between BP and PWV in TwinsUK participants. Two-sample MR, confirmed a bi-directional causal effect of PWV on BP (inverse variance weighted (IVW) beta = 0.11, P < 0.02) and BP on arterial stiffness (IVW beta = 0.004, P < 0.0001).


CONCLUSION
The genetic basis of BP is mediated not only by genes regulating BP but also by genes that influence arterial stiffness. Mendelian randomization indicates a bi-directional causal association between BP and arterial stiffness.",2020,European heart journal
Lowest Left Ventricular Mass (LVM) confers survival benefit in Patients (PTS) with severe isolated Aortic Stenosis (AS) and normal LV Ejection Fraction (EF),"2 . Patients with â‰¥2+ valvular regurgitation or more than mild mitral stenosis were excluded. The dobutamine infusion protocol was be- gun at 5 Î¼g/kg/min body weight up to 20 Î¼g/kg/min, titrated upwards at steps of 5 Î¼g/kg/min every 3 min. The composite outcome endpoint (MACE) was de- fined as cardiac death, aortic valve replacement and hospitalization caused by AS symptoms according to patient's medical record. Results: No patient experienced a serious adverse event during or after DT. A to- tal of 70 patients had MACE (55.55%), of which 9 patients (7.14%) have died dur- ing follow-up. Out of 70 patients, 56 patients (80%) had an Aortic Valve Replace- ment (RAV). Patients who had an increase in AVA during DT â‰¤0.2 cm2 and/or final AVA â‰¤ 1c m 2 had more often RAV (hi=9.5311; df=1; p=0.002). The lasso penal- ized Cox regression, conducted solely on the variables at rest, showed that the greatest predictive capacity has the aortic valve resistance (AVR). At the same time, the AUC for the all analyzed pre-dobutamine variables combined, evaluated Abstract P4721 -T able 1 Quartile LV mass index:",2013,European Heart Journal
Nomogram for radiation-induced hypothyroidism prediction in nasopharyngeal carcinoma after treatment.,"OBJECTIVE
The aim of this study was to develop a nomogram for radiation-induced hypothyroidism (RHT) prediction.


METHODS
We collected data from 164 patients with nasopharyngeal carcinoma (NPC) in our previous prospective study. Biochemical hypothyroidism was defined as a serum thyroid-stimulating hormone level greater than the normal value. We collected both clinical and dose-volume factors. A univariate Cox regression analysis was performed to identify RHT risk factors. Optimal predictors were selected according to the least absolute shrinkage and selection operator (LASSO). We then selected the Cox regression models that best balanced the prediction performance and practicability to build a nomogram for RHT prediction.


RESULTS
There were 38 (23.2%) patients who developed RHT, and the median follow-up was 24 months. The univariate Cox regression analysis indicated that gender, minimum dose, mean dose (Dmean) and V25-V60 [Vx (%), the percentage of thyroid volume receiving >xâ€‰Gy] of the thyroid were significantly associated with RHT. The variables of gender, receiving chemotherapy or not (chemo), Dmean and V50 were selected using the LASSO analysis. A nomogram based on a three-variable (gender, chemo and V50) Cox regression model was constructed, and its concordance index was 0.72. Good accordance between prediction and observation was showed by calibration curves in the probability of RHT at 18, 24 and 30 months.


CONCLUSION
This study built a nomogram for RHT in NPC survivors by analyzing both clinical and dose-volume parameters using LASSO. Thus, the individual dose constraint could be achieved in a visual format. Advances in knowledge: This study used LASSO to more accurately address the multicollinear problem between variables. The resulting nomogram will help physicians predict RHT.",2017,The British journal of radiology
Regularization with the Smooth-Lasso procedure,"We consider the linear regression problem. We propose the S-Lasso procedure to estimate the unknown regression parameters. This estimator enjoys sparsity of the representation while taking into account correlation between successive covariates (or predictors). The study covers the case when $p\gg n$, i.e. the number of covariates is much larger than the number of observations. In the theoretical point of view, for fixed $p$, we establish asymptotic normality and consistency in variable selection results for our procedure. When $p\geq n$, we provide variable selection consistency results and show that the S-Lasso achieved a Sparsity Inequality, i.e., a bound in term of the number of non-zero components of the oracle vector. It appears that the S-Lasso has nice variable selection properties compared to its challengers. Furthermore, we provide an estimator of the effective degree of freedom of the S-Lasso estimator. A simulation study shows that the S-Lasso performs better than the Lasso as far as variable selection is concerned especially when high correlations between successive covariates exist. This procedure also appears to be a good challenger to the Elastic-Net (Zou and Hastie, 2005).",2008,arXiv: Statistics Theory
Feature Grouping Using Weighted l1 Norm for High-Dimensional Data,"Building effective predictive models from high-dimensional data is an important problem in several domains such as in bioinformatics, healthcare analytics and general regression analysis. Extracting feature groups automatically from such data with several correlated features is necessary, in order to use regularizers such as the group lasso which can exploit this deciphered grouping structure to build effective prediction models. Elastic net, fused-lasso and Octagonal Shrinkage Clustering Algorithm for Regression (oscar) are some of the popular feature grouping methods proposed in the literature which recover both sparsity and feature groups from the data. However, their predictive ability is affected adversely when the regression coefficients of adjacent feature groups are similar, but not exactly equal. This happens as these methods merge such adjacent feature groups erroneously, which is also called the misfusion problem. In order to solve this problem, in this paper, we propose a weighted l1 norm-based approach which is effective at recovering feature groups, despite the proximity of the coefficients of adjacent feature groups, building extremely accurate predictive models. This convex optimization problem is solved using the fast iterative soft-thresholding algorithm (FISTA). We depict how our approach is more effective at resolving the misfusion problem on synthetic datasets compared to existing feature grouping methods such as the elastic net, fused-lasso and oscar. We also evaluate the goodness of the model on real-world breast cancer gene expression and the 20-Newsgroups datasets.",2016,2016 IEEE 16th International Conference on Data Mining (ICDM)
Sparse Recovery via l1 and L1 Optimization,"Abstract : A sparse signal is a signal that has very few nonzero elements or one that becomes so under a basis change or through a certain transform. Exploiting sparsity has become a common task in data sciences. Compressed sensing, regularized regression (e.g., LASSO), and regularized inverse problems (e.g., total variation image reconstruction) have made l1 optimization a central tool in data processing problems. As the name suggests, l1 optimization problems recover sparse solutions by solving an optimization problem involving an l1-norm. Today, the scope of l1 optimization is quickly expanding. The size, complexity, and diversity of instances have grown significantly. Beyond 1D signals and 2D images, high-dimensional quantities such as video, 4D CT, and multi-way tensors have become the data or unknown variables in models. New applications have motivated structured solutions to optimization problems that significantly generalize our notion of sparsity. Such applications look for low-rank matrices or tensors, sparse graphs, tree structured data representations, and sparse representations involving only a few dictionary atoms. This article gives self-contained introductions to l1 optimization for sparse vectors (Section 2), L1 optimization for finding functions with compact support (Section 3), and computing sparse solutions from measurements that are corrupted by unknown noisy (Section 4).",2014,
Preoperative radiomic signature based on multiparametric magnetic resonance imaging for noninvasive evaluation of biological characteristics in rectal cancer,"AbstractObjectivesTo develop and validate radiomic models in evaluating biological characteristics of rectal cancer based on multiparametric magnetic resonance imaging (MP-MRI).MethodsThis study consisted of 345 patients with rectal cancer who underwent MP-MRI. We focused on evaluating five postoperative confirmed characteristics: lymph node (LN) metastasis, tumor differentiation, fraction of Ki-67-positive tumor cells, human epidermal growth factor receptor 2 (HER-2), and KRAS-2 gene mutation status. Data from 197 patients were used to develop the biological characteristics evaluation models. Radiomic features were extracted from MP-MRI and then refined for reproducibility and redundancy. The refined features were investigated for usefulness in building radiomic signatures by using two feature-ranking methods (MRMR and WLCX) and three classifiers (RF, SVM, and LASSO). Multivariable logistic regression was used to build an integrated evaluation model combining radiomic signatures and clinical characteristics. The performance was evaluated using an independent validation dataset comprising 148 patients.ResultsThe MRMR and LASSO regression produced the best-performing radiomic signatures for evaluating HER-2, LN metastasis, tumor differentiation, and KRAS-2 gene status, with AUC values of 0.696 (95% CI, 0.610â€“0.782), 0.677 (95% CI, 0.591â€“0.763), 0.720 (95% CI, 0.621â€“0.819), and 0.651 (95% CI, 0.539â€“0.763), respectively. The best-performing signatures for evaluating Ki-67 produced an AUC value of 0.699 (95% CI, 0.611â€“0.786), and it was developed by WLCX and RF algorithm. The integrated evaluation model incorporating radiomic signature and MRI-reported LN status had improved AUC of 0.697 (95% CI, 0.612â€“0.781).ConclusionRadiomic signatures based on MP-MRI have potential to noninvasively evaluate the biological characteristics of rectal cancer.Key Pointsâ€¢ Radiomic features were extracted from MP-MRI images of the rectal tumor.
 â€¢ The proposed radiomic signatures demonstrated discrimination ability in identifying the histopathological, immunohistochemical, and genetic characteristics of rectal cancer.â€¢ All MRI sequences were important and could provide complementary information in radiomic analysis.",2018,European Radiology
Efficient estimation and variable selection for infinite variance autoregressive models,"In this paper, a self-weighted composite quantile regression estimation procedure is developed to estimate unknown parameter in an infinite variance autoregressive (IVAR) model. The proposed estimator is asymptotically normal and more efficient than a single quantile regression estimator. At the same time, the adaptive least absolute shrinkage and selection operator (LASSO) for variable selection are also suggested. We show that the adaptive LASSO based on the self-weighted composite quantile regression enjoys the oracle properties. Simulation studies and a real data example are conducted to examine the performance of the proposed approaches.",2012,Journal of Applied Mathematics and Computing
Differential MicroRNA Signatures in the Pathogenesis of Barrett's Esophagus,"OBJECTIVES
Barrett's esophagus (BE) is the precursor lesion and a major risk factor for esophageal adenocarcinoma (EAC). Although patients with BE undergo routine endoscopic surveillance, current screening methodologies have proven ineffective at identifying individuals at risk of EAC. Since microRNAs (miRNAs) have potential diagnostic and prognostic value as disease biomarkers, we sought to identify an miRNA signature of BE and EAC.


METHODS
High-throughput sequencing of miRNAs was performed on serum and tissue biopsies from 31 patients identified either as normal, gastroesophageal reflux disease (GERD), BE, BE with low-grade dysplasia (LGD), or EAC. Logistic regression modeling of miRNA profiles with Lasso regularization was used to identify discriminating miRNA. Quantitative reverse transcription polymerase chain reaction was used to validate changes in miRNA expression using 46 formalin-fixed, paraffin-embedded specimens obtained from normal, GERD, BE, BE with LGD or HGD, and EAC subjects.


RESULTS
A 3-class predictive model was able to classify tissue samples into normal, GERD/BE, or LGD/EAC classes with an accuracy of 80%. Sixteen miRNAs were identified that predicted 1 of the 3 classes. Our analysis confirmed previous reports indicating that miR-29c-3p and miR-193b-5p expressions are altered in BE and EAC and identified miR-4485-5p as a novel biomarker of esophageal dysplasia. Quantitative reverse transcription polymerase chain reaction validated 11 of 16 discriminating miRNAs.


DISCUSSION
Our data provide an miRNA signature of normal, precancerous, and cancerous tissue that may stratify patients at risk of progressing to EAC. We found that serum miRNAs have a limited ability to distinguish between disease states, thus limiting their potential utility in early disease detection.",2020,Clinical and Translational Gastroenterology
Development and Validation of a Diagnostic Nomogram to Predict COVID-19 Pneumonia,"Background: The COVID-19 virus is an emerging virus rapidly spread worldwide This study aimed to establish an effective diagnostic nomogram for suspected COVID-19 pneumonia patients. METHODS: We used the LASSO aggression and multivariable logistic regression methods to explore the predictive factors associated with COVID-19 pneumonia, and established the diagnostic nomogram for COVID-19 pneumonia using multivariable regression. This diagnostic nomogram was assessed by the internal and external validation data set. Further, we plotted decision curves and clinical impact curve to evaluate the clinical usefulness of this diagnostic nomogram. RESULTS: The predictive factors including the epidemiological history, wedge-shaped or fan-shaped lesion parallel to or near the pleura, bilateral lower lobes, ground glass opacities, crazy paving pattern and white blood cell (WBC) count were contained in the nomogram. In the primary cohort, the C-statistic for predicting the probability of the COVID-19 pneumonia was 0.967, even higher than the C-statistic (0.961) in initial viral nucleic acid nomogram which was established using the univariable regression. The C-statistic was 0.848 in external validation cohort. Good calibration curves were observed for the prediction probability in the internal validation and external validation cohort. The nomogram both performed well in terms of discrimination and calibration. Moreover, decision curve and clinical impact curve were also beneficial for COVID-19 pneumonia patients. CONCLUSION: Our nomogram can be used to predict COVID-19 pneumonia accurately and favourably.",2020,medRxiv
Variable Selection Incorporating Prior Constraint Information into Lasso,"We propose the variable selection procedure incorporating prior constraint information into lasso. The proposed procedure combines the sample and prior information, and selects significant variables for responses in a narrower region where the true parameters lie. It increases the efficiency to choose the true model correctly. The proposed procedure can be executed by many constrained quadratic programming methods and the initial estimator can be found by least square or Monte Carlo method. The proposed procedure also enjoys good theoretical properties. Moreover, the proposed procedure is not only used for linear models but also can be used for generalized linear models({\sl GLM}), Cox models, quantile regression models and many others with the help of Wang and Leng (2007)'s LSA, which changes these models as the approximation of linear models. The idea of combining sample and prior constraint information can be also used for other modified lasso procedures. Some examples are used for illustration of the idea of incorporating prior constraint information in variable selection procedures.",2007,arXiv: Methodology
Sensitivity to prior specification in Bayesian genome-based prediction models,"Abstract Different statistical models have been proposed for maximizing prediction accuracy in genome-based prediction of breeding values in plant and animal breeding. However, little is known about the sensitivity of these models with respect to prior and hyperparameter specification, because comparisons of prediction performance are mainly based on a single set of hyperparameters. In this study, we focused on Bayesian prediction methods using a standard linear regression model with marker covariates coding additive effects at a large number of marker loci. By comparing different hyperparameter settings, we investigated the sensitivity of four methods frequently used in genome-based prediction (Bayesian Ridge, Bayesian Lasso, BayesA and BayesB) to specification of the prior distribution of marker effects. We used datasets simulated according to a typical maize breeding program differing in the number of markers and the number of simulated quantitative trait loci affecting the trait. Furthermore, we used an experimental maize dataset, comprising 698 doubled haploid lines, each genotyped with 56110 single nucleotide polymorphism markers and phenotyped as testcrosses for the two quantitative traits grain dry matter yield and grain dry matter content. The predictive ability of the different models was assessed by five-fold cross-validation. The extent of Bayesian learning was quantified by calculation of the Hellinger distance between the prior and posterior densities of marker effects. Our results indicate that similar predictive abilities can be achieved with all methods, but with BayesA and BayesB hyperparameter settings had a stronger effect on prediction performance than with the other two methods. Prediction performance of BayesA and BayesB suffered substantially from a non-optimal choice of hyperparameters.",2013,
A Homotopy Algorithm for the Quantile Regression Lasso and Related Piecewise Linear Problems,"We show that the homotopy algorithm of Osborne, Presnell, and Turlach (2000), which has proved such an effective optimal path following method for implementing Tibshiraniâ€™s â€œlassoâ€ for variable selection in least squares estimation problems, can be extended to polyhedral objectives in examples such as the quantile regression lasso. The new algorithm introduces the novel feature that it requires two homotopy sequences involving continuation steps with respect to both the constraint bound and the Lagrange multiplier to be performed consecutively. Performance is illustrated by application to several standard datasets, and these results are compared to calculations made with the original lasso homotopy program. This permits an assessment of the computational complexity to be made both for the new method and for the closely related linear programming post-optimality procedures as these generate essentially identical solution trajectories. This comparison strongly favors the least squares selection method. Howe...",2011,Journal of Computational and Graphical Statistics
Transformations of Data in Deterministic Modelling of Biological Networks,"The Gaussian graphical model (GGM) is a probabilistic modelling approach used in the system biology to represent the relationship between genes with an undirected graph. In graphical models, the genes and their interactions are denoted by nodes and the edges between nodes. Hereby, in this model, it is assumed that the structure of the system can be described by the inverse of the covariance matrix, \(\varTheta \), which is also called as the precision, when the observations are formulated via a lasso regression under the multivariate normality assumption of states. There are several approaches to estimate \(\varTheta \) in GGM. The most well-known ones are the neighborhood selection algorithm and the graphical lasso (glasso) approach. On the other hand, the multivariate adaptive regression splines (MARS) is a non-parametric regression technique to model nonlinear and highly dependent data successfully. From previous simulation studies, it has been found that MARS can be a strong alternative of GGM if the model is constructed similar to a lasso model and the interaction terms in the optimal model are ignored to get comparable results with respect to the GGM findings. Moreover, it has been detected that the major challenge in both modelling approaches is the high sparsity of \(\varTheta \) due to the possible non-linear interactions between genes, in particular, when the dimensions of the networks are realistically large. In this study, as the novelty, we suggest the Bernstein operators, namely, Bernstein and Szasz polynomials, in the raw data before any lasso type of modelling and associated inference approaches. Because from the findings via GGM with small and moderately large systems, we have observed that the Bernstein polynomials can increase the accuracy of the estimates. Hence, in this work, we perform these operators firstly into the most well-known inference approaches used in GGM under realistically large networks. Then, we investigate the assessment of these transformations for the MARS modelling as the alternative of GGM again under the same large complexity. By this way, we aim to propose these transformation techniques for all sorts of modellings under the steady-state condition of the protein-protein interaction networks in order to get more accurate estimates without any computational cost. In the evaluation of the results, we compare the precision and F-measures of the simulated datasets.",2016,
Building interpretable predictive models for pediatric hospital readmission using Tree-Lasso logistic regression,"OBJECTIVES
Quantification and early identification of unplanned readmission risk have the potential to improve the quality of care during hospitalization and after discharge. However, high dimensionality, sparsity, and class imbalance of electronic health data and the complexity of risk quantification, challenge the development of accurate predictive models. Predictive models require a certain level of interpretability in order to be applicable in real settings and create actionable insights. This paper aims to develop accurate and interpretable predictive models for readmission in a general pediatric patient population, by integrating a data-driven model (sparse logistic regression) and domain knowledge based on the international classification of diseases 9th-revision clinical modification (ICD-9-CM) hierarchy of diseases. Additionally, we propose a way to quantify the interpretability of a model and inspect the stability of alternative solutions.


MATERIALS AND METHODS
The analysis was conducted on >66,000 pediatric hospital discharge records from California, State Inpatient Databases, Healthcare Cost and Utilization Project between 2009 and 2011. We incorporated domain knowledge based on the ICD-9-CM hierarchy in a data driven, Tree-Lasso regularized logistic regression model, providing the framework for model interpretation. This approach was compared with traditional Lasso logistic regression resulting in models that are easier to interpret by fewer high-level diagnoses, with comparable prediction accuracy.


RESULTS
The results revealed that the use of a Tree-Lasso model was as competitive in terms of accuracy (measured by area under the receiver operating characteristic curve-AUC) as the traditional Lasso logistic regression, but integration with the ICD-9-CM hierarchy of diseases provided more interpretable models in terms of high-level diagnoses. Additionally, interpretations of models are in accordance with existing medical understanding of pediatric readmission. Best performing models have similar performances reaching AUC values 0.783 and 0.779 for traditional Lasso and Tree-Lasso, respectfully. However, information loss of Lasso models is 0.35 bits higher compared to Tree-Lasso model.


CONCLUSIONS
We propose a method for building predictive models applicable for the detection of readmission risk based on Electronic Health records. Integration of domain knowledge (in the form of ICD-9-CM taxonomy) and a data-driven, sparse predictive algorithm (Tree-Lasso Logistic Regression) resulted in an increase of interpretability of the resulting model. The models are interpreted for the readmission prediction problem in general pediatric population in California, as well as several important subpopulations, and the interpretations of models comply with existing medical understanding of pediatric readmission. Finally, quantitative assessment of the interpretability of the models is given, that is beyond simple counts of selected low-level features.",2016,Artificial intelligence in medicine
Adaptive LASSO for linear regression models with ARMA-GARCH errors,"ABSTRACT The linear regression models with the autoregressive moving average (ARMA) errors (REGARMA models) are often considered, in order to reflect a serial correlation among observations. In this article, we focus on an adaptive least absolute shrinkage and selection operator (LASSO) (ALASSO) method for the variable selection of the REGARMA models and extend it to the linear regression models with the ARMA-generalized autoregressive conditional heteroskedasticity (ARMA-GARCH) errors (REGARMA-GARCH models). This attempt is an extension of the existing ALASSO method for the linear regression models with the AR errors (REGAR models) proposed by Wang et al. in 2007. New ALASSO algorithms are proposed to determine important predictors for the REGARMA and REGARMA-GARCH models. Finally, we provide the simulation results and real data analysis to illustrate our findings.",2017,Communications in Statistics - Simulation and Computation
Variable Ranking by Solution-path Algorithms,"Variable Selection has always been a very important problem in statistics. We often meet situations where a huge data set is given and we want to find out the relationship between the response and the corresponding variables. With a huge number of variables, we often end up with a big model even if we delete those that are insignificant. There are two reasons why we are unsatisfied with a final model with too many variables[4]. The first reason is the prediction accuracy. Though the prediction bias might be small under a big model, the variance is usually very high. The second reason is interpretation. With a large number of variables in the model, itâ€™s hard to determine a clear relationship and explain the effects of variables we are interested in. A lot of variable selection methods have been proposed, such as Forwardand BackwardStepwise Selection, Forward-Stagewise Regression, shrinkage methods like Ridge Regression, Lasso and Least Angle Regression. However, one disadvantage of variable selection is that different sizes of model require different tuning parameters in the analysis, which is hard to choose for non-statisticians. Xin and Zhu [8] advocate variable ranking instead of variable selection. Once variables are ranked properly, we can make the selection by adopting a threshold rule. One possible variable ranking can be constructed using Random Forest, which gives two different variable importance measures. We can use either one to get a ranking and usually they lead to similar results. In this thesis, we try to rank the variables using Least Angle Regression (LARS). Some shrinkage methods like Lasso and LARS can shrink the coefficients to zero. The advantage of this kind of methods is that they can give a solution path which describes the order that variables enter the model. This provides an intuitive way to rank variables based on the path. However, Lasso can sometimes be difficult to apply to variable ranking directly. This is because that in a Lasso solution path, variables might enter the model and then get dropped. This dropping issue makes it hard to rank based on the order of entrance. However, LARS, which is a modified version of Lasso, doesnâ€™t have this problem. Weâ€™ll make use of this property and rank variables using LARS solution path.",2012,
Identification of 14-3-3 Proteins Phosphopeptide-Binding Specificity Using an Affinity-Based Computational Approach,"The 14-3-3 proteins are a highly conserved family of homodimeric and heterodimeric molecules, expressed in all eukaryotic cells. In human cells, this family consists of seven distinct but highly homologous 14-3-3 isoforms. 14-3-3Ïƒ is the only isoform directly linked to cancer in epithelial cells, which is regulated by major tumor suppressor genes. For each 14-3-3 isoform, we have 1,000 peptide motifs with experimental binding affinity values. In this paper, we present a novel method for identifying peptide motifs binding to 14-3-3Ïƒ isoform. First, we propose a sampling criteria to build a predictor for each new peptide sequence. Then, we select nine physicochemical properties of amino acids to describe each peptide motif. We also use auto-cross covariance to extract correlative properties of amino acids in any two positions. Finally, we consider elastic net to predict affinity values of peptide motifs, based on ridge regression and least absolute shrinkage and selection operator (LASSO). Our method tests on the 1,000 known peptide motifs binding to seven 14-3-3 isoforms. On the 14-3-3Ïƒ isoform, our method has overall pearson-product-moment correlation coefficient (PCC) and root mean squared error (RMSE) values of 0.84 and 252.31 for N-terminal sublibrary, and 0.77 and 269.13 for C-terminal sublibrary. We predict affinity values of 16,000 peptide sequences and relative binding ability across six permutated positions similar with experimental values. We identify phosphopeptides that preferentially bind to 14-3-3Ïƒ over other isoforms. Several positions on peptide motifs are in the same amino acid category with experimental substrate specificity of phosphopeptides binding to 14-3-3Ïƒ. Our method is fast and reliable and is a general computational method that can be used in peptide-protein binding identification in proteomics research.",2016,PLoS ONE
Many Average Partial Effects: with An Application to Text Regression,"We study estimation, pointwise and simultaneous inference, and confidence intervals for many average partial effects of lasso Logit. Focusing on high-dimensional, cluster-sampling environments, we propose a new average partial effect estimator and explore its asymptotic properties. Practical penalty choices compatible with our asymptotic theory are also provided. The proposed estimator allow for valid inference without requiring oracle property. We provide easy-to-implement algorithms for cluster-robust high-dimensional hypothesis testing and construction of simultaneously valid confidence intervals using a multiplier cluster bootstrap. We apply the proposed algorithms to the text regression model of Wu (2018) to examine the presence of gendered language on the internet.",2018,arXiv: Econometrics
Tissue-infiltrating lymphocytes signature predicts survival in patients with early/intermediate stage hepatocellular carcinoma,"BackgroundIntratumoral immune infiltrates have manifested a robust prognostic signature in patients with hepatocellular carcinoma (HCC). We hypothesized that a novel tissue-related immune signature (TRIS) could improve the prediction of postoperative survival for patients diagnosed with early/intermediate HCC.MethodsTwenty-eight immune features were immunohistochemically examined on 352 HCC specimens. The LASSO Cox regression model was used to construct a five-feature-based TRIS. The univariate and multivariate Cox analyses were performed. Based on independent predictors, the immune-clinical prognostic index (ICPI) was established. Performance assessment was measured with C-index and compared with seven traditional staging systems. The independent validation cohort (nÂ =â€‰393) was included to validate the model.ResultsBy using the LASSO method, the TRIS were constructed on the basis of five immune features, CD3intratumoral (T), CD27T, CD68peritumoral (P), CD103T, and PD1T. Multivariate Cox analysis showed that the TRIS was an independent prognostic predictor. In the training cohort, Î³-glutamyl transferase, tumor diameter, tumor differentiation, and TRIS were incorporated into the ICPI. The ICPI presented satisfactory discrimination ability, with C-index values of 0.691 and 0.686 in the training and validation cohorts, respectively. Compared with seven conventional staging systems (C-index, training cohort, 0.548â€“0.597; validation cohort, 0.519â€“0.610), the ICPI exhibited better performance for early/intermediate-stage HCCs. Further, the patients were categorized into three subgroups with X-tile software, and the stratified ICPI presented a superior corrected Akaike information criterion and homogeneity in both cohorts.ConclusionsOur ICPI was a useful and reliable prognostic tool which may offer good individualized prediction capability for HCC patients with early/intermediate stage.",2019,BMC Medicine
Software Fault Proneness Prediction with Group Lasso Regression: On Factors that Affect Classification Performance,"Machine learning algorithms have been used extensively for software fault proneness prediction. This paper presents the first application of Group Lasso Regression (G-Lasso) for software fault proneness classification and compares its performance to six widely used machine learning algorithms. Furthermore, we explore the effects of two factors on the prediction performance: the effect of imbalance treatment using the Synthetic Minority Over-sampling Technique (SMOTE), and the effect of datasets used in building the prediction models. Our experimental results are based on 22 datasets extracted from open source projects. The main findings include: (1) G-Lasso is robust to imbalanced data and significantly outperforms the other machine learning algorithms with respect to the Recall and G-Score, i.e., the harmonic mean of Recall and (1- False Positive Rate). (2) Even though SMOTE improved the performance of all learners, it did not have statistically significant effect on G-Lasso's Recall and G-Score. Random Forest was in the top performing group of learners for all performance metrics, while Naive Bayes performed the worst of all learners. (3) When using the same change metrics as features, the choice of the dataset had no effect on the performance of most learners, including G-Lasso. Naive Bayes was the most affected, especially when balanced datasets were used.",2019,2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)
Non-invasive genotype prediction of chromosome 1p/19q co-deletion by development and validation of an MRI-based radiomics signature in lower-grade gliomas,"To pre-operatively and non-invasively predict 1p/19q co-deletion in grade II and III (lower-grade) glioma based on a radiomics method using magnetic resonance imaging (MRI). We obtained 105 patients pathologically diagnosed with lower-grade glioma. We extracted 647 MRI-based features from T2-weighted images and selected discriminative features by lasso logistic regression approaches on the training cohort (n=69). Radiomics, clinical, and combined models were constructed separately to verify the predictive performance of the radiomics signature. The predictability of the three models were validated on a time-independent validation cohort (n = 36). Finally, 7 discriminative radiomic features were used constructed radiomics signature, which demonstrated satisfied performance on both the training and validation cohorts with AUCs of 0.822 and 0.731, respectively. Particularly, the combined model incorporating the radiomics signature and the clinic-radiological factors achieved the best discriminative capability with AUCs of 0.911 and 0.866 for training and validation cohorts, respectively.",2019,
Machine Learning Prediction of Photovoltaic Energy from Satellite Sources,"Satelliteâ€“measured irradiances can be an interesting source of information for the nowcasting of solar energy productions. Here we will consider the Machine Learning based prediction at hour H of the aggregated photovoltaic (PV) energy of Peninsular Spain using the irradiances measured by Meteosatâ€™s visible and infrared channels at hours \(H, H-1, H-2\) and \(H-3\). We will work with Lasso and Support Vector Regression models and show that both give best results when using \(H-1\) irradiances to predict H PV energy, with SVR being slightly ahead. We will also suggest possible ways to improve our current results.",2016,
Principal Component Clustered Factors for Determining Study Performance in Computer Programming Class,"Studying computer programming requires not only an understanding of theories and concepts, but also coding pragmatism. Success in studying or conducting such a course is definitely a challenge. This paper proposes a model that transforms studentsâ€™ attributes (including the cognitive and non-cognitive abilities, and traditional lagging measures of academic background) into a set of principal components (PCs). As opposed to traditional approaches, the proposed model optimally extracts the orthogonal PCs to form a basis for determining the studying performance of students in terms of declarative knowledge and procedural proficiency (or skill). The obtained relationship model yields two contributive values (1) an optimal set of determinants, in the form of studentsâ€™ clusters, to determine study performance and (2) the fully preserved interpretability of the original attributes of students in each PC. The experiment was conducted using 115 complete datasets of IT major students who enrolled the Introduction to Computer Programming course. The Best Subset Selection and LASSO algorithms were deployed to find the optimal set of features. The effectiveness of the model was validated by multiple linear regression to predict the performance in terms of knowledge and skills with an accuracy of 76.52%, and 70.44%, respectively. Insights into the interpretability of student clusters are provided.",2020,Wireless Personal Communications
Water level fluctuations and the ecosystem functioning of lakes,"Abstract Hydrological regimes are key drivers of productivity and structure in freshwater ecosystems but are increasingly impacted by human activity. Using 17 published food web models of 13 African lakes as a case study, we explored relationships between seasonal and interannual water level fluctuations and 15 attributes related to ecosystem function. We interpreted our results in the context of Odum's ecosystem maturity hypothesis, as systems with higher magnitude fluctuations may be kept at an earlier maturity stage than those that are relatively stable. The data we compiled indicate that long-term changes in the hydrological regimes of African lakes have already taken place. We used Least Absolute Shrinkage and Selection Operator (LASSO) regression to examine relationships between ecosystem attributes and seven physical characteristics. Of these characteristics, interannual water level fluctuation magnitude was the most frequently retained predictor in the regression models. Our results indicate that interannual water level fluctuations are positively correlated with primary and overall production, but negatively correlated with fish diversity, transfer efficiency, and food chain length. These trends are opposite those expected with increasing ecosystem maturity. Interestingly, we found seasonal water level fluctuations to be positively correlated with biomass. An increase in standing biomass is generally associated with more mature ecosystems. However, we found that less production and biomass occurred at high trophic levels in highly fluctuating compared to relatively stable systems. This synthesis provides evidence that water level fluctuations are a key process influencing ecosystem structure and function in lakes.",2018,Journal of Great Lakes Research
"Blood transfusions in colorectal cancer surgery: incidence, outcomes, and predictive factors: an American College of Surgeons National Surgical Quality Improvement Program analysis.","BACKGROUND
Data analyzing the short-term outcomes and predictors of blood transfusions (BTs) in colorectal cancer (CRC) surgery are limited.


METHODS
The American College of Surgeons National Surgical Quality Improvement Program (2005 to 2010) was retrospectively reviewed for CRC cases performed with or without BT. Patient demographics, comorbidities, and operative variables were analyzed. Multivariate regression analysis was performed examining the effect of BT on outcomes. The LASSO algorithm for logistic regression was used to build a predictive model for BT taking into account preoperative and operative variables.


RESULTS
A total of 27,120 patients underwent CRC, and 3,815 (14.07%) had BTs. Transfusions were associated with increased mortality (odds ratio [OR], 1.78), morbidity (OR, 2.38), length of stay (mean difference, 3.52 days), pneumonia (OR, 2.70), and surgical-site infection (OR, 1.45). This effect was ""dose dependent,"" as patients receiving â‰¥3 U of blood had increased morbidity (OR, 1.53), lengths of stay (mean difference, 1.82 days), pneumonia (OR, 2.52), and surgical-site infections (OR, 1.60) compared with those receiving 1 to 2 U. Predictors of BT were hematocrit <38%, open surgery, proctectomy, low platelet count, American Society of Anesthesiologists class IV or V, total colectomy, metastatic cancer, emergency, ascites, and infection. All P values were < .05.


CONCLUSIONS
BTs are associated with worse short-term outcomes after CRC surgery. Knowledge of predictive factors will help in risk stratification and counseling.",2013,American journal of surgery
Adaptive balancing of gradient and update computation times using global geometry and approximate subproblems,"First-order optimization methods comprise two important primitives: i) the computation of gradient information and ii) the computation of the update that leads to the next iterate. In practice there is often a wide mismatch between the time required for the two steps, leading to underutilization of resources. In this work, we propose a new framework, Approx Composite Minimization (ACM) that uses approximate update steps to ensure balance between the two operations. The accuracy is adaptively chosen in an online fashion to take advantage of changing conditions. Our unified analysis for approximate composite minimization generalizes and extends previous work to new settings. Numerical experiments on Lasso regression and SVMs demonstrate the effectiveness of the novel scheme.",2018,
Pharmacometabolomics applied to zonisamide pharmacokinetic parameter prediction,"IntroductionZonisamide is a new-generation anticonvulsant antiepileptic drug metabolized primarily in the liver, with subsequent elimination via the renal route.ObjectivesOur objective was to evaluate the utility of pharmacometabolomics in the detection of zonisamide metabolites that could be related to its disposition and therefore, to its efficacy and toxicity.MethodsThis study was nested to a bioequivalence clinical trial with 28 healthy volunteers. Each participant received a single dose of zonisamide on two separate occasions (period 1 and period 2), with a washout period between them. Blood samples of zonisamide were obtained from all patients at baseline for each period, before volunteers were administered any medication, for metabolomics analysis.ResultsAfter a Lasso regression was applied, age, height, branched-chain amino acids, steroids, triacylglycerols, diacyl glycerophosphoethanolamine, glycerophospholipids susceptible to methylation, phosphatidylcholines with 20:4 FA (arachidonic acid) and cholesterol ester and lysophosphatidylcholine were obtained in both periods.ConclusionTo our knowledge, this is the only research study to date that has attempted to link basal metabolomic status with pharmacokinetic parameters of zonisamide.",2018,Metabolomics
Prognostic value of a gene signature in clear cell renal cell carcinoma.,"Renal cancer is aÂ common urogenital system malignance. Novel biomarkers could provide more and more critical information onÂ tumor features and patients' prognosis. Here, we performed an integrated analysis on the discovery set and established a three-gene signature to predict the prognosis for clear cell renal cell carcinoma (ccRCC). By constructing a LASSO Cox regression model, a 3-messenger RNA (3-mRNA) signature was identified. Based on the 3-mRNA signature, we divided patients into high- and low-risk groups, and validated thisÂ by using three other data sets. In the discovery set, this signature could successfully distinguish between the high- and low-risk patients (hazard ratio (HR), 2.152; 95% confidence interval (CI),1.509-3.069; pâ€‰<â€‰0.0001). Analysis ofÂ internal and two external validation sets yielded consistent results (internal: HR, 2.824; 95% CI, 1.601-4.98; pâ€‰<â€‰0.001; GSE29609: HR, 3.002; 95% CI, 1.113-8.094; pâ€‰=â€‰0.031; E-MTAB-3267: HR, 2.357; 95% CI, 1.243-4.468; pâ€‰=â€‰0.006). Time-dependent receiver operating characteristic (ROC) analysis indicated that the area under the ROC curve at 5 years was 0.66 both in the discovery and internal validation set, while the two external validation sets also suggested good performance of the 3-mRNA signature. Besides that, a nomogram was built and the calibration plots and decision curve analysis indicated the good performance and clinical utility of the nomogram. In conclusion, this 3-mRNA classifier proved to be a useful tool for prognostic evaluation and could facilitate personalized management of ccRCC patients.",2019,Journal of cellular physiology
Identifying the Prognosis Factors in Death after Liver Transplantation via Adaptive LASSO in Iran,"Despite the widespread use of liver transplantation as a routine therapy in liver diseases, the effective factors on its outcomes are still controversial. This study attempted to identify the most effective factors on death after liver transplantation. For this purpose, modified least absolute shrinkage and selection operator (LASSO), called Adaptive LASSO, was utilized. One of the best advantages of this method is considering high number of factors. Therefore, in a historical cohort study from 2008 to 2013, the clinical findings of 680 patients undergoing liver transplant surgery were considered. Ridge and Adaptive LASSO regression methods were then implemented to identify the most effective factors on death. To compare the performance of these two models, receiver operating characteristic (ROC) curve was used. According to the results, 12 factors in Ridge regression and 9 ones in Adaptive LASSO regression were significant. The area under the ROC curve (AUC) of Adaptive LASSO was equal to 89% (95% CI: 86%-91%), which was significantly greater than Ridge regression (64%, 95% CI: 61%-68%) (p < 0.001). As a conclusion, the significant factors and the performance criteria revealed the superiority of Adaptive LASSO method as a penalized model versus traditional regression model in the present study.",2016,Journal of Environmental and Public Health
Identifying pathological subtypes of non-small-cell lung cancer by using the radiomic features of 18 F-fluorodeoxyglucose positron emission computed tomography,"Background: Radiomics provides promising opportunities in cancer diagnosis, endowing medical imaging with an increasingly important role in analyzing tumor phenotypes. Positron emission computed tomography (PET) imaging can detect functional changes before they become morphologically evident on computed tomography (CT) imaging. The aim of this study was to explore the feasibility of using quantitative PET radiomic and clinical features to identify subtypes of non-small-cell lung cancer (NSCLC). 
 Methods: In this study, one hundred patients who had been diagnosed with histologically confirmed NSCLC were collected retrospectively, including 61 patients with adenocarcinoma (ADC) and 39 patients with squamous cell carcinoma (SqCC). Then, the gross tumor volume (GTV) was delineated on PET images. A total of 107 features were extracted, which included 60 texture features and 47 metabolic features. The least absolute shrinkage and selection operator (LASSO) was used to select the optimal feature set, which was considered to be the best predictable features. Meanwhile, we analyzed the differences of selected features between two tumor types. Classification models were built by multivariable logistic regression analysis with three settings, namely: (I) radiomic features; (II) clinical features (smoking, age, sex, tumor size, T stage and N stage); and (III) radiomic features combined with clinical features. Finally, the area under the receiver operating characteristic (ROC) curve (AUC) was used to evaluate the performance of the classification models. 
 Results: Five out of 107 features were selected as the optimal feature set, which included four texture features and one metabolic feature. Significant differences were observed from these five features between ADC and SqCC subtypes (P Conclusions: The 18 F-FDG PET radiomic classification model is a promising and applicable approach for identifying subtypes of NSCLC, which may serve as a complementary tool to help doctors with clinical decisions.",2019,Translational cancer research
Sparse Estimation of Polynomial and Rational Dynamical Models,"In many practical situations, it is highly desirable to estimate an accurate mathematical model of a real system using as few parameters as possible. At the same time, the need for an accurate description of the system behavior without knowing its complete dynamical structure often leads to model parameterizations describing a rich set of possible hypotheses; an unavoidable choice, which suggests sparsity of the desired parameter estimate. An elegant way to impose this expectation of sparsity is to estimate the parameters by penalizing the criterion with the â„“0 â€œnormâ€ of the parameters. Due to the non-convex nature of the â„“0-norm, this penalization is often implemented as solving an optimization program based on a convex relaxation (e.g., â„“1/LASSO, nuclear norm, . . .). Two difficulties arise when trying to apply these methods: (1) the need to use cross-validation or some related technique for choosing the values of regularization parameters associated with the â„“1 penalty; and (2) the requirement that the (unpenalized) cost function must be convex. To address the first issue, we propose a new technique for sparse linear regression called SPARSEVA, with close ties with the LASSO (least absolute shrinkage and selection operator), which provides an automatic tuning of the amount of regularization. The second difficulty, which imposes a severe constraint on the types of model structures or estimation methods on which the â„“1 relaxation can be applied, is addressed by combining SPARSEVA and the Steiglitz-McBride method. To demonstrate the advantages of the proposed approach, a solid theoretical analysis and an extensive simulation study are provided.",2014,IEEE Transactions on Automatic Control
