title,abstract,year,journal
Comparison of Penalized Cox Regression Methods in Low-Dimensional Data with Few-Events: An Application to Dialysis Patients' Data.,"BACKGROUND
Dialysis is a dominant therapeutic method in patients with chronic renal failure. The ratio of those who experienced the event to the predictor variables is expressed as event per variable (EPV). When EPV is low, one of the common techniques which may help to manage the problem is penalized Cox regression model (PCRM). The aim of this study was to determine the survival of dialysis patients using the PCRM in low-dimensional data with few events.


STUDY DESIGN
A cross-sectional study.


METHODS
Information of 252 dialysis patients of Bandar Abbas hospitals, southern Iran, from 2010-16 were used. To deal with few mortality cases in the sample, the PCRM (lasso, ridge and elastic net, adaptive lasso) were applied. Models were compared in terms of calibration and discrimination.


RESULTS
Thirty-five (13.9%) mortality cases were observed. Dialysis data simulations revealed that the lasso had higher prediction accuracy than other models. For one unit of increase in the level of education, the risk of mortality was reduced by 0.32 (HR=0.68). The risk of mortality was 0.26 (HR=1.26) higher for the unemployed than the employed cases. Other significant factors were the duration of each dialysis session, number of dialysis sessions per week and age of dialysis onset (HR=0.93, 0.95 and 1.33).


CONCLUSION
The performance of penalized models, especially the lasso, was satisfying in low-dimensional data with low EPV based on dialysis data simulation and real data, therefore these models are the good choice for managing of this type of data.",2019,Journal of research in health sciences
Lost in Translation: On the Problem of Data Coding in Penalized Whole Genome Regression with Interactions,"Mixed models can be considered as a type of penalized regression and are everyday tools in statistical genetics. The standard mixed model for whole genome regression (WGR) is ridge regression best linear unbiased prediction (RRBLUP) which is based on an additive marker effect model. Many publications have extended the additive WGR approach by incorporating interactions between loci or between genes and environment. In this context of penalized regressions with interactions, it has been reported that translating the coding of single nucleotide polymorphisms -for instance from -1,0,1 to 0,1,2- has an impact on the prediction of genetic values and interaction effects. In this work, we identify the reason for the relevance of variable coding in the general context of penalized polynomial regression. We show that in many cases, predictions of the genetic values are not invariant to translations of the variable coding, with an exception when only the sizes of the coefficients of monomials of highest total degree are penalized. The invariance of RRBLUP can be considered as a special case of this setting, with a polynomial of total degree 1, penalizing additive effects (total degree 1) but not the fixed effect (total degree 0). The extended RRBLUP (eRRBLUP), which includes interactions, is not invariant to translations because it does not only penalize interactions (total degree 2), but also additive effects (total degree 1). This observation implies that translation-invariance can be maintained in a pair-wise epistatic WGR if only interaction effects are penalized, but not the additive effects. In this regard, approaches of pre-selecting loci may not only reduce computation time, but can also help to avoid the variable coding issue. To illustrate the practical relevance, we compare different regressions on a publicly available wheat data set. We show that for an eRRBLUP, the relevance of the marker coding for interaction effect estimates increases with the number of variables included in the model. A biological interpretation of estimated interaction effects may therefore become more difficult. Consequently, comparing reproducing kernel Hilbert space (RKHS) approaches to WGR approaches modeling effects explicitly, the supposed advantage of an increased interpretability of the latter may not be real. Our theoretical results are generally valid for penalized regressions, for instance also for the least absolute shrinkage and selection operator (LASSO). Moreover, they apply to any type of interaction modeled by products of predictor variables in a penalized regression approach or by Hadamard products of covariance matrices in a mixed model.",2019,G3: Genes|Genomes|Genetics
Identifying Genetic Associations with MRI-derived Measures via Tree-Guided Sparse Learning,"In recent imaging genetic studies, much work has been focused on regression analysis that treats large-scale single nucleotide polymorphisms (SNPs) and quantitative traits (QTs) as association variables. To deal with the weak detection and high-throughput data problem, feature selection methods such as the least absolute shrinkage and selection operator (Lasso) are often used for selecting the most relevant SNPs associated with QTs. However, one problem of Lasso as well as many other feature selection methods for imaging genetics is that some useful prior information, i.e., the hierarchical structure among SNPs throughout the whole genome, are rarely used for designing more powerful model. In this paper, we propose to identify the associations between candidate genetic features (i.e., SNPs) and magnetic resonance imaging (MRI)-derived measures using a tree-guided sparse learning (TGSL) method. The advantage of our method is that it explicitly models the priori hierarchical grouping structure among the SNPs in the objective function for feature selection. Specifically, two kinds of hierarchical structures, i.e., group by gene and group by linkage disequilibrium (LD) clusters, are imposed as a tree-guided regularization term in our sparse learning model. Experimental results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database show that our method not only achieves better predictions on the two MRI measures (i.e., left and right hippocampal formation), but also identifies the informative SNPs to guide the disease-induced interpretation compared with other reference methods.",2014,Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention
"High-Dimensional LASSO-Based Computational Regression Models: Regularization, Shrinkage, and Selection","Regression models are a form of supervised learning methods that are important for machine learning, statistics, and general data science. Despite the fact that classical ordinary least squares (OLS) regression models have been known for a long time, in recent years there are many new developments that extend this model significantly. Above all, the least absolute shrinkage and selection operator (LASSO) model gained considerable interest. In this paper, we review general regression models with a focus on the LASSO and extensions thereof, including the adaptive LASSO, elastic net, and group LASSO. We discuss the regularization terms responsible for inducing coefficient shrinkage and variable selection leading to improved performance metrics of these regression models. This makes these modern, computational regression models valuable tools for analyzing high-dimensional problems.",2019,Machine Learning and Knowledge Extraction
Adaptive boosting of weak regressors for forecasting of crop production considering climatic variability: An empirical assessment,"Abstract Crop yield forecasting based on different climatic conditions for coastal regions is a critical process. In this study, regression based adaptive boosting prediction model is presented, using the datasets of Kharif and Rabi seasons along with the climatic features of three coastal districts belonging to Odisha located in India. This study discusses and experiments on the different weak regressors, such as: linear, lasso, ridge, SVR regression, proposes strong predictors by avoiding the shortcomings of individual weak regressors and propagating the benefits of AdaBoost to improve the predictive accuracy on learning problems. AdaBoost helps to get a combined output of the weak regressors into a weighted sum that represents the final output of the boosted strong regressor and also the output of the weak regressors which is likely to be twisted in favour of wrongly predicted instances adaptively. It has been observed from the experiments that, the decision of weak regressors vary due to frequent, inherent attributes of climatic conditions for crop production. Obtained numerical simulation results in terms of errors, various performance measures and statistical analysis demonstrated have highlighted the attractiveness of the proposed strong regressors compared to weak regressors forecasting methods for crop production.",2017,Journal of King Saud University - Computer and Information Sciences
A no-reference bitstream-based perceptual model for video quality estimation of videos affected by coding artifacts and packet losses,"In this work, we propose a No-Reference (NR) bitstream-based model for predicting the quality of H.264/AVC video sequences, affected by both compression artifacts and transmission impairments. The proposed model is based on a feature extraction procedure, where a large number of features are calculated from the packet-loss impaired bitstream. Many of the features are firstly proposed in this work, and the specific set of the features as a whole is applied for the first time for making NR video quality predictions. All feature observations are taken as input to the Least Absolute Shrinkage and Selection Operator (LASSO) regression method. LASSO indicates the most important features, and using only them, it is possible to estimate the Mean Opinion Score (MOS) with high accuracy. Indicatively, we point out that only 13 features are able to produce a Pearson Correlation Coefficient of 0.92 with the MOS. Interestingly, the performance statistics we computed in order to assess our method for predicting the Structural Similarity Index and the Video Quality Metric are equally good. Thus, the obtained experimental results verified the suitability of the features selected by LASSO as well as the ability of LASSO in making accurate predictions through sparse modeling.",2015,
â€œPreconditioningâ€ for feature selection and regression in high-dimensional problems,"We consider regression problems where the number of predictors greatly exceeds the number of observations. We propose a method for variable selection that first estimates the regression function, yielding a ""preconditioned"" response variable. The primary method used for this initial regression is supervised principal components. Then we apply a standard procedure such as forward stepwise selection or the LASSO to the preconditioned response variable. In a number of simulated and real data examples, this two-step procedure outperforms forward stepwise selection or the usual LASSO (applied directly to the raw outcome). We also show that under a certain Gaussian latent variable model, application of the LASSO to the preconditioned response variable is consistent as the number of predictors and observations increases. Moreover, when the observational noise is rather large, the suggested procedure can give a more accurate estimate than LASSO. We illustrate our method on some real problems, including survival analysis with microarray data.",2008,Annals of Statistics
Maximum de vraisemblance et moindre carrÃ©s pÃ©nalisÃ©s dans des modÃ¨les de durÃ©e de vie censurÃ©es,"L'analyse de durees de vie censurees est utilisee dans des domaines d'application varies et differentes possibilites ont ete proposees pour la modelisation de telles donnees. Nous nous interessons dans cette these a deux types de modelisation differents, le modele de Cox stratifie avec indicateurs de strates aleatoirement manquants et le modele de regression lineaire censure a droite. Nous proposons des methodes d'estimation des parametres et etablissons les proprietes asymptotiques des estimateurs obtenus dans chacun de ces modeles. 
Dans un premier temps, nous considerons une generalisation du modele de Cox qui permet a differents groupes de la population, appeles strates, de posseder des fonctions d'intensite de base differentes tandis que la valeur du parametre de regression est commune. Dans ce modele a intensite proportionnelle stratifie, nous nous interessons a l'estimation des parametres lorsque l'indicateur de strate est manquant pour certains individus de la population. Des estimateurs du maximum de vraisemblance non parametrique pour les parametres du modele sont proposes et nous montrons leurs consistance et normalite asymptotique. L'efficacite du parametre de regression est etablie et des estimateurs consistants de sa variance asymptotique sont egalement obtenus. Pour l'evaluation des estimateurs du modele, nous proposons l'utilisation de l'algorithme Esperance-Maximisation et le developpons dans ce cas particulier. 
Dans un second temps, nous nous interessons au modele de regression lineaire lorsque la donnee reponse est censuree aleatoirement a droite. Nous introduisons un nouvel estimateur du parametre de regression minimisant un critere des moindres carres penalise et pondere par des poids de Kaplan-Meier. Des resultats de consistance et normalite asymptotique sont obtenus et une etude de simulations est effectuee pour illustrer les proprietes de cet estimateur de type LASSO. La methode bootstrap est utilisee pour l'estimation de la variance asymptotique.",2008,
Quantitative Biomarkers for Prediction of Epidermal Growth Factor Receptor Mutation in Non-Small Cell Lung Cancer,"OBJECTIVES
To predict epidermal growth factor receptor (EGFR) mutation status using quantitative radiomic biomarkers and representative clinical variables.


METHODS
The study included 180 patients diagnosed as of non-small cell lung cancer (NSCLC) with their pre-therapy computed tomography (CT) scans. Using a radiomic method, 485 features that reflect the heterogeneity and phenotype of tumors were extracted. Afterwards, these radiomic features were used for predicting epidermal growth factor receptor (EGFR) mutation status by a least absolute shrinkage and selection operator (LASSO) based on multivariable logistic regression. As a result, we found that radiomic features have prognostic ability in EGFR mutation status prediction. In addition, we used radiomic nomogram and calibration curve to test the performance of the model.


RESULTS
Multivariate analysis revealed that the radiomic features had the potential to build a prediction model for EGFR mutation. The area under the receiver operating characteristic curve (AUC) for the training cohort was 0.8618, and the AUC for the validation cohort was 0.8725, which were superior to prediction model that used clinical variables alone.


CONCLUSION
Radiomic features are better predictors of EGFR mutation status than conventional semantic CT image features or clinical variables to help doctors to decide who need EGFR tyrosine kinase inhibitor (TKI) treatment.",2018,Translational Oncology
Effect of color on some geometric attributes of visual appearance of non-effect coatings,"The aim of the present study was to investigate the effect of color attributes of appearance on the corresponding geometric attributes of appearance of non-effect coatings. Three scales, namely gloss, distinctness of image, and orange peel for three achromatic (black, gray, and white) and four chromatic (red, green, blue, and yellow) basecoats, each at varying levels, were prepared. The gloss and the distinctness of image scales had a sample with a maximum degree of gloss and distinctness of image, respectively, and the orange peel scale had a sample with a minimum degree of orange peel, which was considered to be the standard sample. The visual differences between the standard sample and those remaining in each scale were assessed by a panel of 28 observers using a prepared one-dimensional lightness scale based on the CIELAB and CIEDE2000 color difference equations. The correlations between visual and instrumental measurements of scales were checked, and instrumental performance with respect to visually assessed equivalent differences in gloss, distinctness of image, and orange peel were determined, giving STRESS (standardized residual sum of squares) valuesâ€‰=â€‰24.3, 11.6, and 9.7, respectively, in terms of CIELAB. ANOVA together with simple, lasso, and ridge regressions were applied to test the effect of color on the geometric attributes of appearance. The results illustrate that color attributes of appearance have no adverse significant effect on the main geometric attributes of appearance for non-effect coatings.",2020,Journal of Coatings Technology and Research
Mapping mineral chemistry of a lateritic outcrop in new Caledonia through generalized regression using Sentinel-2 and field reflectance spectra,"Abstract Mining is fundamental for human development, yet it currently requires innovative spatial techniques as it faces diverse environmental and social pressures. With the free Sentinel-2 data of the Copernicus programme, new opportunities arise for studies related to nickel laterite, especially with its reported potential in mapping iron-oxide. This work utilizes samples from drill-holes extracted from Tiebaghi, New Caledonia. The chemical composition and the hyperspectral reflectance of each sample are obtained. The reflectance spectra are resampled to Sentinel-2's characteristics, and generalized linear regression was used to accurately predict Fe2O3, MgO, SiO2, Al2O3, and nickel content where three regression approaches were compared: Ridge, Elastic Net, and the Least Absolute Shrinkage and Selection Operator (LASSO). With the resulting regression models, mineral chemistry of an outcrop in the vicinity of the drill-holes is mapped by a scene of Sentinel-2. The work shows the great potential of free satellite imagery in mapping chemical characteristics of minerals and rocks. It opens up great opportunities for monitoring outcrops and for achieving more efficient mineral exploration.",2018,Int. J. Appl. Earth Obs. Geoinformation
Determination of General Circulation Model Domain Using LASSO to Improve Rainfall Prediction Accuracy in West Java,The Statistical downscaling technique has often been used to predict rainfall. This technique needsa domain of general circulation model (GCM) data. The selection of GCM domain is an important factor to improvepredictionaccuracy.The goal of this study is to determine the optimum domain. This study uses GCM data from CFSRv2 with gridresolution 2.5Â°Ã—2.5Â°and local rainfall data in West Java. The GCM domain is determined basedon minimum correlation value of 0.3 between GCM data and local rainfall data. Correlations are calculated for the grid in the four directions of the compass with one grid as the reference that straightly above the local rainfall station. The domains are evaluated using the regression model with L1 (LASSO) regularization. The result showed that the optimum domain was 8Ã—5 grids.,2020,
Improving the efficiency of genomic selection,"Abstract We investigate two approaches to increase the efficiency of phenotypic prediction from genome-wide markers, which is a key step for genomic selection (GS) in plant and animal breeding. The first approach is feature selection based on Markov blankets, which provide a theoretically-sound framework for identifying non-informative markers. Fitting GS models using only the informative markers results in simpler models, which may allow cost savings from reduced genotyping. We show that this is accompanied by no loss, and possibly a small gain, in predictive power for four GS models: partial least squares (PLS), ridge regression, LASSO and elastic net. The second approach is the choice of kinship coefficients for genomic best linear unbiased prediction (GBLUP). We compare kinships based on different combinations of centring and scaling of marker genotypes, and a newly proposed kinship measure that adjusts for linkage disequilibrium (LD). We illustrate the use of both approaches and examine their performances using three real-world data sets with continuous phenotypic traits from plant and animal genetics. We find that elastic net with feature selection and GBLUP using LD-adjusted kinships performed similarly well, and were the best-performing methods in our study.",2013,
"Genome-wide prediction of maize single-cross performance, considering non-additive genetic effects.","The prediction of single-cross hybrids in maize is a promising technique for optimizing the use of financial resources in a breeding program. This study aimed to evaluate Genomic Best Linear Unbiased Predictors models for hybrid prediction and compare them with the Bayesian Ridge Regression, Bayes A, Bayesian LASSO, Bayes C, Bayes B, and Reproducing Kernel Hilbert Spaces Regression models, with inclusion or absence of non-additive effects under three heritability scenarios. Data from a maize germplasm bank belonging to USDA were used to determine the effects of molecular markers, which were considered to be parametric, to build 400 single-cross hybrids between two line groups via simulation. The following parameters were used to compare the models: predictive ability, estimation of variance components, heritability of genetic effects present in all situations, and the sum of squares of the predicted errors. The models responded positively when dominance effects were included in non-additive models, with all models tending to show an increase in the values of heritability parameters under all scenarios. Differences occur between models depending on the heritability range considered. Estimates of additive and dominant effects were better than estimates of epistatic effects. Estimates increased in accuracy for all models when non-additive effects for maize cob weight were considered.",2015,Genetics and molecular research : GMR
Lasso with long memory regression errors,"Abstract Lasso is a computationally efficient approach to model selection and estimation, and its properties are well studied when the regression errors are independent and identically distributed. We study the case, where the regression errors form a long memory moving average process. We establish a finite sample oracle inequality for the Lasso solution. We then show the asymptotic sign consistency in this setup. These results are established in the high dimensional setup ( p > n ) where p can be increasing exponentially with n. Finally, we show the consistency, n 1 / 2 âˆ’ d - consistency of Lasso, along with the oracle property of adaptive Lasso, in the case where p is fixed. Here d is the memory parameter of the stationary error sequence. The performance of Lasso is also analysed in the present setup with a simulation study.",2014,Journal of Statistical Planning and Inference
Machine Learningâ€“Based Prediction of Clinical Outcomes for Children During Emergency Department Triage,"Importance
While machine learning approaches may enhance prediction ability, little is known about their utility in emergency department (ED) triage.


Objectives
To examine the performance of machine learning approaches to predict clinical outcomes and disposition in children in the ED and to compare their performance with conventional triage approaches.


Design, Setting, and Participants
Prognostic study of ED data from the National Hospital Ambulatory Medical Care Survey from January 1, 2007, through December 31, 2015. A nationally representative sample of 52â€¯037 children aged 18 years or younger who presented to the ED were included. Data analysis was performed in August 2018.


Main Outcomes and Measures
The outcomes were critical care (admission to an intensive care unit and/or in-hospital death) and hospitalization (direct hospital admission or transfer). In the training set (70% random sample), using routinely available triage data as predictors (eg, demographic characteristics and vital signs), we derived 4 machine learning-based models: lasso regression, random forest, gradient-boosted decision tree, and deep neural network. In the test set (the remaining 30% of the sample), we measured the models' prediction performance by computing C statistics, prospective prediction results, and decision curves. These machine learning models were built for each outcome and compared with the reference model using the conventional triage classification information.


Results
Of 52â€¯037 eligible ED visits by children (median [interquartile range] age, 6 [2-14] years; 24â€¯929 [48.0%] female), 163 (0.3%) had the critical care outcome and 2352 (4.5%) had the hospitalization outcome. For the critical care prediction, all machine learning approaches had higher discriminative ability compared with the reference model, although the difference was not statistically significant (eg, C statistics of 0.85 [95% CI, 0.78-0.92] for the deep neural network vs 0.78 [95% CI, 0.71-0.85] for the reference; Pâ€‰=â€‰.16), and lower number of undertriaged critically ill children in the conventional triage levels 3 to 5 (urgent to nonurgent). For the hospitalization prediction, all machine learning approaches had significantly higher discrimination ability (eg, C statistic, 0.80 [95% CI, 0.78-0.81] for the deep neural network vs 0.73 [95% CI, 0.71-0.75] for the reference; Pâ€‰<â€‰.001) and fewer overtriaged children who did not require inpatient management in the conventional triage levels 1 to 3 (immediate to urgent). The decision curve analysis demonstrated a greater net benefit of machine learning models over ranges of clinical thresholds.


Conclusions and Relevance
Machine learning-based triage had better discrimination ability to predict clinical outcomes and disposition, with reduction in undertriaging critically ill children and overtriaging children who are less ill.",2019,JAMA Network Open
Prognostic and Predictive Value of Three DNA Methylation Signatures in Lung Adenocarcinoma,"Background: Lung adenocarcinoma (LUAD) is the leading cause of cancer-related mortality worldwide. Molecular characterization-based methods hold great promise for improving the diagnostic accuracy and for predicting treatment response. The DNA methylation patterns of LUAD display a great potential as a specific biomarker that will complement invasive biopsy, thus improving early detection. Method: In this study, based on the whole-genome methylation datasets from The Cancer Genome Atlas (TCGA) and several machine learning methods, we evaluated the possibility of DNA methylation signatures for identifying lymph node metastasis of LUAD, differentiating between tumor tissue and normal tissue, and predicting the overall survival (OS) of LUAD patients. Using the regularized logistic regression, we built a classifier based on the 3616 CpG sites to identify the lymph node metastasis of LUAD. Furthermore, a classifier based on 14 CpG sites was established to differentiate between tumor and normal tissues. Using the Least Absolute Shrinkage and Selection Operator (LASSO) Cox regression, we built a 16-CpG-based model to predict the OS of LUAD patients. Results: With the aid of 3616-CpG-based classifier, we were able to identify the lymph node metastatic status of patients directly by the methylation signature from the primary tumor tissues. The 14-CpG-based classifier could differentiate between tumor and normal tissues. The area under the receiver operating characteristic (ROC) curve (AUC) for both classifiers achieved values close to 1, demonstrating the robust classifier effect. The 16-CpG-based model showed independent prognostic value in LUAD patients. Interpretation: These findings will not only facilitate future treatment decisions based on the DNA methylation signatures but also enable additional investigations into the utilization of LUAD DNA methylation pattern by different machine learning methods.",2019,Frontiers in Genetics
Characterization of Weighted Quantile Sum Regression for Highly Correlated Data in a Risk Analysis Setting,"In risk evaluation, the effect of mixtures of environmental chemicals on a common adverse outcome is of interest. However, due to the high dimensionality and inherent correlations among chemicals that occur together, the traditional methods (e.g. ordinary or logistic regression) suffer from collinearity and variance inflation, and shrinkage methods have limitations in selecting among correlated components. We propose a weighted quantile sum (WQS) approach to estimating a body burden index, which identifies â€œbad actorsâ€ in a set of highly correlated environmental chemicals. We evaluate and characterize the accuracy of WQS regression in variable selection through extensive simulation studies through sensitivity and specificity (i.e., ability of the WQS method to select the bad actors correctly and not incorrect ones). We demonstrate the improvement in accuracy this method provides over traditional ordinary regression and shrinkage methods (lasso, adaptive lasso, and elastic net). Results from simulations demonstrate that WQS regression is accurate under some environmentally relevant conditions, but its accuracy decreases for a fixed correlation pattern as the association with a response variable diminishes. Nonzero weights (i.e., weights exceeding a selection threshold parameter) may be used to identify bad actors; however, components within a cluster of highly correlated active components tend to have lower weights, with the sum of their weights representative of the set.Supplementary materials accompanying this paper appear on-line.",2015,"Journal of Agricultural, Biological, and Environmental Statistics"
CG-Lasso Estimator for Multivariate Adaptive Regression Spline,"Multivariate adaptive regression spline (MARS) denotes a modern methodology from statistical learning which is important in both classification and regression. It is very useful for high-dimensional problems and shows a great promise for fitting nonlinear multivariate functions by using its ability to estimate the contributions of the basis functions so that both the additive and the interactive effects of the predictors are allowed to determine the response variable. The MARS algorithm for estimating the model function consists of two sub-algorithms. In our paper, we propose not to use second algorithm. Instead, we construct a penalized residual sum of squares (PRSS) for MARS as a higher-order Tikhonov regularization problem which is also known as ridge regression that shrinks coefficients and make them more stable. But it cannot perform variable selection in the model and, hence, does not give an easily interpretable model (especially, if the number of variable p is large). For this reason, we change the Tikhonov penalty function with the generalized Lasso penalty for solving the problem PRSS, taking an advantage for feature selection. We treat this problem using continuous optimization techniques which we consider to become an important complementary technology and model-based alternative to the concept of the backward stepwise algorithm. In particular, we apply the elegant framework of conic quadratic programming (CQP), and we call the solution as CG-Lasso. Here, we gain from an area of convex optimization whose programs are very well-structured, herewith, resembling linear programming and, hence, permitting the use of powerful interior point methods (IPMs).",2019,
Deviance residuals based PLS regression for censored data in high dimensional setting,"Abstract The PLS Cox regression has been proposed in the framework of PLS generalized linear regression as an alternative to the Cox model when dealing with highly correlated covariates. However, in high dimensional settings the algorithm becomes computer-intensive and a more efficient algorithm must be used. In this article we propose an alternative both faster and easier to carry out by the direct use of standard procedures which are available in most statistical softwares. Recently, Segal suggested a solution to the Coxâ€“Lasso algorithm when dealing with high dimensional data. Following Segal, we propose a Deviance Residuals based PLS regression (PLSDR) as an alternative to the PLSâ€“Cox model in high dimensional settings. The PLSDR algorithm only needs to carry out null deviance residuals using a simple intercept Cox model and use these as outcome in a standard PLS regression. This algorithm which can be extended to kernels to deal with non-linearity can also be viewed as a variable selection method in a threshold penalized formulation. An application carried out on gene expression from patients with diffuse large B-cell lymphoma shows the practical interest of using deviance residuals as outcomes in PLS regression when dealing with very many descriptors and censored data.",2008,Chemometrics and Intelligent Laboratory Systems
Development and validation of a predictive model for predicting cardiovascular morbidity in patients after pheochromocytoma surgery.,"OBJECTIVE
Although surgical resection is the primary treatment method for pheochromocytoma, it carries a high risk of morbidity, especially cardiovascular-related morbidity. There are no models for predicting cardiovascular morbidity after pheochromocytoma surgery. Thus, we developed and validated a model for the pre-operative prediction of cardiovascular morbidity after pheochromocytoma surgery.


DESIGN
The development cohort consisted of 262 patients who underwent unilateral laparoscopic or open pheochromocytoma surgery at our center between 1 January 2007 and 31 December 2016. Patient's clinicopathologic data were recorded. The Lasso regression was used for data dimension reduction and feature selection, then multi-variable logistic regression analysis was used to develop the prediction model. An independent cohort consisting of 112 consecutive patients from 1 January 2017 and 31 December 2018 was used for validation. The performance of this prediction model was assessed with respect to discrimination, calibration, and clinical usefulness.


RESULTS
The predictors in this prediction model included body mass index, history of coronary heart disease, tumor size, intra-operative hemodynamic instability, and use of crystal/colloid fluids pre-operatively. In the validation cohort, the model showed good discrimination with an AUROC of 0.869 (95% CI, 0.797, 0.940) and good calibration (Unreliability test, p=0.852). Decision curve analysis demonstrated that the model was also clinically useful.


CONCLUSION
This study presented a good nomogram that could facilitate the pre-operative individualized prediction of cardiovascular morbidity after pheochromocytoma surgery, which may help improve peri-operative strategy and good treatment outcomes. This article is protected by copyright. All rights reserved.",2019,Clinical endocrinology
Sparse NIR optimization method (SNIRO) to quantify analyte composition with visible (VIS)/near infrared (NIR) spectroscopy (350â€¯nm-2500â€¯nm).,"Visual-Near-Infra-Red (VIS/NIR) spectroscopy has led the revolution in high-throughput phenotyping methods used to determine chemical and structural elements of organic materials. In the current state of the art, spectrophotometers used for imaging techniques are either very expensive or too large to be used as a field-operable device. In this study we developed a Sparse NIR Optimization method (SNIRO) that selects a pre-determined number of wavelengths that enable quantification of analytes in a given sample using linear regression. We compared the computed complexity time and the accuracy of SNIRO to Marten's test, to forward selection test and to LASSO all applied to the determination of protein content in corn flour and meat and octane number in diesel using publicly available datasets. In addition, for the first time, we determined the glucose content in the green seaweed Ulva sp., an important feedstock for marine biorefinery. The SNIRO approach can be used as a first step in designing a spectrophotometer that can scan a small number of specific spectral regions, thus decreasing, potentially, production costs and scanner size and enabling the development of field-operable devices for content analysis of complex organic materials.",2019,Analytica chimica acta
Secret intake of antiretroviral treatment and HIV-1 viremia in a public routine clinic in Burkina Faso: a surprising relationship,"ABSTRACT In sub-Saharan Africa, where people living with HIV are frequently stigmatized, the intake of antiretroviral treatment (ART) remains a critical issue for many patients. Although the secret intake of ART may hinder the adherence to treatment, data on its specific impact on therapeutic effectiveness are lacking. We therefore assessed the association between secret intake of ART (i.e., hidden from family) and HIV-1 viremia among patients treated in a public routine clinic in Burkina Faso. We performed a cross-sectional study from December 2012 to September 2013 among patients on ART at the Day Care Unit in Bobo Dioulasso. Patients were eligible for the study if they were 15 years old or over, infected with HIV-1 or HIV-1â€‰+â€‰2, and on ART for at least six months. HIV-1 viral load was measured using Biocentric or Abbott Real Time assay. Study-specific data were collected by social workers using face-to-face interviews, and medical data using the routine electronic database. The association between secret intake of ART and viral load >300 copies/mL was assessed using a multivariate logistic regression. Of 771 patients (women 81.4%; median age 41 years; median time on ART 51 months), 408 reported secret intake of ART and 363 declared open intake. Compared to the latter, patients who hid their intake were younger, more likely to be women and to be involved in a polygamist or in a non-cohabiting union. Viremia was observed in 4.4% of patients hiding ART intake and 9.4% of those taking it openly. By multivariate analysis, secret intake of ART was significantly associated with a lower risk of viremia (adjusted odds ratio 0.41, 95% confidence interval 0.22â€“0.76). The unexpected relation between secret intake of ART and viremia found in this study requires further investigations. Quantitative and qualitative studies need to be performed.",2018,AIDS Care
Feature Selection With Weighted Importance Index in an Autism Spectrum Disorder Study,"AbstractElastic net regularization is a popular statistical tool for variable selection that combines lasso and ridge regression penalties. When used in combination with ensemble methods, it improv...",2019,Statistics in Biopharmaceutical Research
Regularized Linear Models in Stacked Generalization,"Stacked generalization is a flexible method for multiple classifier combination; however, it tends to overfit unless the combiner function is sufficiently smooth. Previous studies attempt to avoid overfitting by using a linear function at the combiner level. This paper demonstrates experimentally that even with a linear combination function, regularization is necessary to reduce overfitting and increase predictive accuracy. The standard linear least squares regression can be regularized with an L2 penalty (Ridge regression), an L1 penalty (lasso regression) or a combination of the two (elastic net regression). In multi-class classification, sparse linear models select and combine individual predicted probabilities instead of using complete probability distributions, allowing base classifiers to specialize in subproblems corresponding to different classes.",2009,
Feature Selection and Negative Binomial Regression for Predicting Number of Defects in Wire Mesh Production,"In wire mesh production, many types of defects are found. When the factors related to the number of defects occurring are correctly identified, various improvement methods can then be applied to reduce or control the number of defects. In this paper, the features that are strongly linked with the number of defects are identified by the feature selection process and then used in the prediction process. LASSO method and random forest are applied in the feature selection process. Using selected features from feature selection, a negative binomial generalized linear model (GLM) is employed to predict the number of defects in the mesh manufacturing process. A negative binomial regression is used since the nature of the mesh defect data in this study is count data and over-dispersed. Quality of the selected features from LASSO and random forest are compared using RMSE and RMSLE of the predicted results from the negative binomial regression.",2019,2019 8th International Conference on Industrial Technology and Management (ICITM)
Gene Regulatory Network Inference Using Time-Stamped Cross-Sectional Single Cell Expression Data,"Abstract: In this paper we presented a novel method for inferring gene regulatory network (GRN) from time-stamped cross-sectional single cell data. Our strategy, called SNIFS (Sparse Network Inference For Single cell data) seeks to recover the causal relationships among genes by analyzing the evolution of the distribution of gene expression levels over time, more specifically using Kolmogorov-Smirnov (KS) distance. In the proposed method, we formulated the GRN inference as a linear regression problem, where we used Lasso regularization to obtain the optimal sparse solution. We tested SNIFS using in silico single cell data from 10 - and 20-gene GRNs, and compared the performance of our method with Time Series Network Inference (TSNI), GEne Network Inference with Ensemble of trees (GENIE3), and an extension of GENIE3 for time series data called JUMP3. The results showed that SNIFS outperformed existing algorithms based on the Area Under the Receiver Operating Characteristic (AUROC) and Area Under the Precision-Recall (AUPR) curves.",2016,IFAC-PapersOnLine
Subgroup analysis based on prognostic and predictive gene signatures for adjuvant chemotherapy in early-stage non-small-cell lung cancer patients,"ABSTRACT In treating patients diagnosed with early Stage I non-small-cell lung cancer (NSCLC), doctors must choose surgery alone, Adjuvant Cisplatin-Based Chemotherapy (ACT) alone or both. For patients with resected stages IB to IIIA, clinical trials have shown a survival advantage from 4â€“15% with the adoption of ACT. However, due to the inherent toxicity of chemotherapy, it is necessary for doctors to identify patients whose chance of success with ACT is sufficient to justify the risks. This research seeks to use gene expression profiling in the development of a statistical decision-making algorithm to identify patients whose survival rates will improve from ACT treatment. Using the data from the National Cancer Institute, the lasso method in the Cox-Proportional-Hazards regression model is used as the main method to determine a feasible number of genes that are strongly associated with the treatment-related patient survival. Considering treatment groups separately, the patients are assigned a risk category based on the estimation of survival times. These risk categories are used to develop a Random Forests classification model to identify patients who are likely to benefit from chemotherapy treatment. This model allows the prediction of a new patientâ€™s prognosis and the likelihood of survival benefit from ACT treatment based on a feasible number of genomic biomarkers. The proposed methods are evaluated using a simulation study.",2018,Journal of Biopharmaceutical Statistics
Data-driven assessment of eQTL mapping methods,"BackgroundThe analysis of expression quantitative trait loci (eQTL) is a potentially powerful way to detect transcriptional regulatory relationships at the genomic scale. However, eQTL data sets often go underexploited because legacy QTL methods are used to map the relationship between the expression trait and genotype. Often these methods are inappropriate for complex traits such as gene expression, particularly in the case of epistasis.ResultsHere we compare legacy QTL mapping methods with several modern multi-locus methods and evaluate their ability to produce eQTL that agree with independent external data in a systematic way. We found that the modern multi-locus methods (Random Forests, sparse partial least squares, lasso, and elastic net) clearly outperformed the legacy QTL methods (Haley-Knott regression and composite interval mapping) in terms of biological relevance of the mapped eQTL. In particular, we found that our new approach, based on Random Forests, showed superior performance among the multi-locus methods.ConclusionsBenchmarks based on the recapitulation of experimental findings provide valuable insight when selecting the appropriate eQTL mapping method. Our battery of tests suggests that Random Forests map eQTL that are more likely to be validated by independent data, when compared to competing multi-locus and legacy eQTL mapping methods.",2010,BMC Genomics
Variable selection in multivariate multiple regression,"Multivariate analysis is a common statistical tool for assessing covariate effects 
when only one response or multiple response variables of the same type are collected 
in experimental studies. However with mixed continuous and discrete outcomes, 
traditional modeling approaches are no longer appropriate. The common approach 
used to make inference is to model each outcome separately ignoring the potential 
correlation among the responses. However a statistical analysis that incorporates association 
may result in improved precision. Coffey and Gennings (2007a) proposed 
an extension of the generalized estimating equations (GEE) methodology to simultaneously 
analyze binary, count and continuous outcomes with nonlinear functions. 
Variable selection plays a pivotal role in modeling correlated responses due to large 
number of covariate variables involved. Thus a parsimonious model is always desirable 
to enhance model predictability and interpretation. To perform parameter 
estimation and variable selection simultaneously in the presence of mixed discrete and continuous outcomes, we propose a penalized based approach of the extended 
generalized estimating equations. This approach only require to specify the first two 
marginal moments and a working correlation structure. An advantageous feature of 
the penalized GEE is that the consistency of the model holds even if the working 
correlation is misspecified. However it is important to use appropriate working correlation 
structure in small samples since it improves the statistical efficiency of the 
regression parameters. We develop a computational algorithm for estimating the parameters 
using local quadratic approximation (LQA) algorithm proposed by Fan and 
Li (2001). For tuning parameter selection, we explore the performance of unweighted 
Bayesian information criterion(BIC) and generalized cross validation (GCV) for least 
absolute shrinkage and selection operator(LASSO) and smoothly clipped absolute 
deviation (SCAD). We discuss the asymptotic properties for the penalized GEE estimator 
when the number of subjects n goes to infinity. Our simulation studies reveal 
that when correlated mixed outcomes are available, estimates of regression parameters 
are unbiased regardless of the choice of correlation structure. However, estimates 
obtained from the unstructured working correlation (UWC) have reduced standard 
errors. SCAD with BIC tuning criteria works well in selecting important variables. 
Our approach is applied to concrete slump test data set.",2015,
When does more regularization imply fewer degrees of freedom? Sufficient conditions and counterexamples,"Regularization aims to improve prediction performance by trading an increase in training error for better agreement between training and prediction errors, which is often captured through decreased degrees of freedom. In this paper we give examples which show that regularization can increase the degrees of freedom in common models, including the lasso and ridge regression. In such situations, both training error and degrees of freedom increase, making the regularization inherently without merit. Two important scenarios are described where the expected reduction in degrees of freedom is guaranteed: all symmetric linear smoothers and convex constrained linear regression models like ridge regression and the lasso, when compared to unconstrained linear regression.",2014,Biometrika
"Simulation Studies as Designed Experiments: The Comparison of Penalized Regression Models in the â€œLarge p, Small nâ€ Setting","New algorithms are continuously proposed in computational biology. Performance evaluation of novel methods is important in practice. Nonetheless, the field experiences a lack of rigorous methodology aimed to systematically and objectively evaluate competing approaches. Simulation studies are frequently used to show that a particular method outperforms another. Often times, however, simulation studies are not well designed, and it is hard to characterize the particular conditions under which different methods perform better. In this paper we propose the adoption of well established techniques in the design of computer and physical experiments for developing effective simulation studies. By following best practices in planning of experiments we are better able to understand the strengths and weaknesses of competing algorithms leading to more informed decisions about which method to use for a particular task. We illustrate the application of our proposed simulation framework with a detailed comparison of the ridge-regression, lasso and elastic-net algorithms in a large scale study investigating the effects on predictive performance of sample size, number of features, true model sparsity, signal-to-noise ratio, and feature correlation, in situations where the number of covariates is usually much larger than sample size. Analysis of data sets containing tens of thousands of features but only a few hundred samples is nowadays routine in computational biology, where ""omics"" features such as gene expression, copy number variation and sequence data are frequently used in the predictive modeling of complex phenotypes such as anticancer drug response. The penalized regression approaches investigated in this study are popular choices in this setting and our simulations corroborate well established results concerning the conditions under which each one of these methods is expected to perform best while providing several novel insights.",2014,PLoS ONE
Multidimensional analysis and detection of informative features in diffusion MRI measurements of human white matter,"The white matter contains long-range connections between different brain regions and the organization of these connections holds important implications for brain function in health and disease. Tractometry uses diffusion-weighted magnetic resonance imaging (dMRI) data to quantify tissue properties (e.g. fractional anisotropy (FA), mean diffusivity (MD), etc.), along the trajectories of these connections [1]. Statistical inference from tractometry usually either (a) averages these quantities along the length of each bundle in each individual, or (b) performs analysis point-by-point along each bundle, with group comparisons or regression models computed separately for each point along every one of the bundles. These approaches are limited in their sensitivity, in the former case, or in their statistical power, in the latter. In the present work, we developed a method based on the sparse group lasso (SGL) [2] that takes into account tissue properties measured along all of the bundles, and selects informative features by enforcing sparsity, not only at the level of individual bundles, but also across the entire set of bundles and all of the measured tissue properties. The sparsity penalties for each of these constraints is identified using a nested cross-validation scheme that guards against over-fitting and simultaneously identifies the correct level of sparsity. We demonstrate the accuracy of the method in two settings: i) In a classification setting, patients with amyotrophic lateral sclerosis (ALS) are accurately distinguished from matched controls [3]. Furthermore, SGL automatically identifies FA in the corticospinal tract as important for this classification â€“ correctly finding the parts of the white matter known to be affected by the disease. ii) In a regression setting, dMRI is used to accurately predict â€œbrain ageâ€ [4, 5]. In this case, the weights are distributed throughout the white matter indicating that many different regions of the white matter change with development and contribute to the prediction of age. Thus, SGL makes it possible to leverage the multivariate relationship between diffusion properties measured along multiple bundles to make accurate predictions of subject characteristics while simultaneously discovering the most relevant features of the white matter for the characteristic of interest.",2019,bioRxiv
Identification of a Five-Gene Signature and Establishment of a Prognostic Nomogram to Predict Progression-Free Interval of Papillary Thyroid Carcinoma,"Background: The incidence of papillary thyroid carcinoma (PTC) is high and increasing worldwide. Although prognosis is relatively good, it is important to select the minority of patients with poorer prognosis to avoid side effects associated with unnecessary over-treatment in low-risk patients; this requires accurate prognostic predictions. Materials and Methods: Six PTC expression datasets were obtained from the gene expression omnibus (GEO) database. Level 3 mRNA expression and clinicopathological data were obtained from The Cancer Genome Atlas Thyroid Cancer (TCGA-THCA) database. Through integrated analysis of these datasets, highly reliable differentially-expressed genes (DEGs) between tumor and normal tissue were identified and lasso Cox regression was applied to identify DEGs related to the progression-free interval (PFI) and to establish a prognostic gene signature. The performance of a five-gene signature was evaluated based on a Kaplan-Meier curve, receiver operating characteristic (ROC), and Harrell's concordance index (C-index). Multivariate Cox regression analysis was used to identify factors associated with PTC prognosis. Finally, a prognostic nomogram was established based on the TCGA-THCA dataset. Results: A novel five-gene signature was established to predict the PTC PFI, which included PLP2, LYVE1, FABP4, TGFBR3, and FXYD6, and the ROC curve and C-index showed good performance in both training and validation datasets. This could classify patients into high- and low-risk groups with distinct PFIs and differentiate PTC tumors from normal tissue. Univariate Cox regression revealed that this signature was an independent prognostic factor for PTC. The established nomogram, incorporating the prognostic gene signature and clinical parameters, was able to predict the PFI with high efficiency. The gene signature-based nomogram was superior to the American Thyroid Association (ATA) risk stratification to predict PTC PFI. Conclusions: Our study identified a five-gene signature and established a prognostic nomogram, which were reliable in predicting the PFI of PTC; this could be beneficial for individualized treatment and medical decision making.",2019,Frontiers in Endocrinology
