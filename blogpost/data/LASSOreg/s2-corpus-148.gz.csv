title,abstract,year,journal
Incidence and Predictors of Unsuspected Recurrent Laryngeal Nerve Lymph Node Metastases After Neoadjuvant Chemoradiotherapy in Patients with Esophageal Squamous Cell Carcinoma,"BackgroundRadical lymph node (LN) dissection along the recurrent laryngeal nerve (RLN) area carries a substantial morbidity rate, and its usefulness in neoadjuvant chemoradiotherapy (nCRT)-treated esophageal cancer patients remains unclear.MethodsThis study was conducted in two Asian thoracic surgery centers. Patients with esophageal squamous cell carcinoma (ESCC) who were judged to be ycN-RLN(âˆ’) after nCRT and received bilateral RLN LN dissection were eligible. The incidence of unsuspected RLN LN involvement was analyzed, and we used least absolute shrinkage and selection operator (LASSO) regression to identify its predictors.ResultsA total of 56 patients (53 males and 3 females; mean age: 55Â years) were included. The upper mediastinumâ€”including the bilateral RLN areaâ€”was covered by the radiation field in 48 (85.3%) patients. Although all of them were judged as ycN-RLN(âˆ’), unsuspected RLN LN involvement was identified on pathological examination in 11 (19.6%) subjects, being the only positive nodal station in seven. LASSO regression identified the pre-nCRT RLN LN(cN-RLN) status as the only independent predictor of ypN-RLN positivity; in contrast, neither the tumor location nor the radiation dose to the upper mediastinum were independently associated with ypN-RLN(+). RLN nodal dissection resulted in positive LN discovery rates of 30.8 and 10% in ycN-RLN(âˆ’) patients who had positive and negative cN-RLNs before nCRT, respectively. Consequently, 23.1 and 6.7% of patients in each subgroup would have been understaged in the absence of RLN nodal dissection.ConclusionNearly one-fifth of ESCC patients who were judged to be ycN-RLN(âˆ’) unexpectedly had positive ypN-RLN. The pre-nCRT cN-RLN status plays a key role in the selection of patients that should undergo RLN LN dissection after nCRT.",2018,World Journal of Surgery
A review of original articles published in the emerging field of radiomics.,"PURPOSE
To determine the characteristics of and trends in research in the emerging field of radiomics through bibliometric and hotspot analyses of relevant original articles published between 2013 and 2018.


METHODS
We evaluated 553 original articles concerning radiomics, published in a total of 61 peer-reviewed journals between 2013 and 2018. The following information was retrieved for each article: radiological subspecialty, imaging technique(s), machine learning technique(s), sample size, study setting and design, statistical result(s), study purpose, software used for feature calculation, funding declarations, author number, first author's affiliation, study origin, and journal name. Qualitative and quantitative analyses were performed for the manually extracted data for identification and visualization of the trends in radiomics research.


RESULTS
The annual growth rate in the number of published papers was 177.82% (p < 0.001). The characteristics and trends of research hotspots in the field of radiomics were clarified and visualized in this study. It was found that the field of radiomics is at a more mature stage for lung, breast, and prostate cancers than for other sites. Radiomics studies primarily focused on radiological characterization (215) and monitoring (182). Logistic regression and LASSO were the two most commonly used techniques for feature selection. Non-clinical researchers without a medical background dominated radiomics studies (70.52%), the vast majority of which only highlighted positive results (97.80%) while downplaying negative findings.


CONCLUSIONS
The reporting of quantifiable knowledge about the characteristics and trajectories of radiomics can inform researchers about the gaps in the field of radiomics and guide its future direction.",2020,European journal of radiology
Biomarkers of Environmental Enteropathy are Positively Associated with Immune Responses to an Oral Cholera Vaccine in Bangladeshi Children,"Environmental enteropathy (EE) is a poorly understood condition that refers to chronic alterations in intestinal permeability, absorption, and inflammation, which mainly affects young children in resource-limited settings. Recently, EE has been linked to suboptimal oral vaccine responses in children, although immunological mechanisms are poorly defined. The objective of this study was to determine host factors associated with immune responses to an oral cholera vaccine (OCV). We measured antibody and memory T cell immune responses to cholera antigens, micronutrient markers in blood, and EE markers in blood and stool from 40 Bangladeshi children aged 3-14 years who received two doses of OCV given 14 days apart. EE markers included stool myeloperoxidase (MPO) and alpha anti-trypsin (AAT), and plasma endotoxin core antibody (EndoCab), intestinal fatty acid binding protein (i-FABP), and soluble CD14 (sCD14). We used multiple linear regression analysis with LASSO regularization to identify host factors, including EE markers, micronutrient (nutritional) status, age, and HAZ score, predictive for each response of interest. We found stool MPO to be positively associated with IgG antibody responses to the B subunit of cholera toxin (P = 0.03) and IgA responses to LPS (P = 0.02); plasma sCD14 to be positively associated with LPS IgG responses (P = 0.07); plasma i-FABP to be positively associated with LPS IgG responses (P = 0.01) and with memory T cell responses specific to cholera toxin (P = 0.01); stool AAT to be negatively associated with IL-10 (regulatory) T cell responses specific to cholera toxin (P = 0.02), and plasma EndoCab to be negatively associated with cholera toxin-specific memory T cell responses (P = 0.02). In summary, in a cohort of children 3-14 years old, we demonstrated that the majority of biomarkers of environmental enteropathy were positively associated with immune responses after vaccination with an OCV.",2016,PLoS Neglected Tropical Diseases
Monotone regression in high (and lower) dimensions,"In this thesis, we first present an overview of monotone regression, both in the classical setting and in the high dimensional setting. High dimensional data means that the number of covariates, p, exceeds the number of observations, n. It is often reasonable to assume a monotone relationship between a predictor variable and the response, especially in medicine and biology. The monotone regression methods for the high dimensional data setting that are considered are the liso regression method and the monotone splines lasso regression method (to our knowledge, the only two methods). Both these methods are special forms of penalised regression. The performances of these two high dimensional methods in the classical setting are studied and compared to the performances of existing methods for monotone regression developed for the classical setting, known as MonBoost, scam and scar. The two high dimensional methods work well also in the classical setting, but they do not outperform the existing methods. The two methods can still be useful in the classical setting, since they can be used in situations where the monotonicity directions of the effects are not known, in contrast to the existing methods and also perform automatic variable selection. Furthermore, we investigate the robustness of the monotone splines lasso method to the number of interior knots used to fit the monotone splines and find that it is very robust. In addition, two new methods for fitting a partially linear model where the non-linear covariates are assumed to have a monotone effect on the response are developed. These two methods can be used in the setting where p > n as well as in the classical setting. To our knowledge, no such methods have been developed in the past. The first method, PLAMM-1, is a straight forward extension of the monotone splines lasso method to the partially linear setting. The second method developed, PLAMM-2, is a method with two penalties, one on the linear parameters and one on the non-linear parameters. In this last case, estimation has to be performed iteratively, and we prove convergence of the iterative scheme. The estimation, selection and prediction performances of the methods are investigated by simulation experiments in different settings. Through the simulation experiments, the methods are shown to work well in both the classical settings and in the high dimensional setting where the number of observations is not too small. We also apply the partially linear monotone model to a medical dataset where clinical covariates enter the linear part and genomic covariates are assumed to have a monotone effect on the outcome.",2016,
"Growth and sexual strategies in the fishThalassoma duperrey (Labridae), a protogynous hermaphrodite","SynopsisAdults of the fishThalassoma duperrey, a protogynous hermaphrodite, were collected and growth observed in captivity to study the relationship between growth and reproduction among primary males, females, and secondary males. Sexual maturity is reached at about 60 mm standard length, probably less than 1 year after fertilization. Gonosomatic index in both males and females peaks at about 120 mm, nearly 2 years later. Shortly thereafter females typically change sex, and both primary and secondary males undergo color change. At the same time gonosomatic index falls abruptly and remains low in large fish. The above changes appear to reflect differences in reproductive effort over a lifetime and are interpreted as the optimum strategy given the social and mating system of this fish. Unless they cannot acquire enough food to develop large gonads, small individuals put a much greater proportion of energy into growth than reproduction apparently to minimize the period of low fitness. Intermediate-sized males and females generally invest heavily in gametes, though some retain small gonads. Large individuals (both primary and secondary males) greatly reduce their investment in gametes, probably trading the energy required to maintain reproductive territories for it. This kind of gonad ontogeny involving gonad regression, as inT. duperrey and other labrid fishes, is unique among vertebrates.",2004,Environmental Biology of Fishes
The Behavioral Physiology of Labroid Fishes.,"Abstract : The cunner Tautogolabrus adspersus is one of two temperate-dwelling Western North Atlantic labrid fishes, and is one of the few fishes that remain in New England waters throughout the year. Observations indicate that cunner enter behavioral torpor in winter. The present study showed that cunner undergo physiological torpor, or hibernation, based on low oxygen consumption rates, contributing to a large Q10 value of 8.5. This establishes cunner as one of the few marine species that hibernate. Cunner withstood four months of starvation at 4 deg C. Glycogen, lipid, and protein in the liver decreased during this period, but remained unchanged in whole-body samples. Regression analysis predicts that cunner can live at least 6 months on their glycogen and lipid reserves, and 9 months based on their protein reserves. Cunner maintained a diel cycle in oxygen consumption rates (low at night, high during the day) during periods of warm temperature, but the cycle approximated 48 hours at temperatures generally below 8 deg C. Two tropical labroids, Thalassoma bifasciatum and Scarus iserti, also had a diel cycle in metabolic rate. The ability of labrids to undergo marked diel decreases in metabolic rate may have predisposed them to becoming established in temperate waters by surviving cold temperatures through hibernation.... Physiology, Fish, Hibernation.",1992,
Model Selection in Sparse Multi-Dimensional Contingency Tables,"We compare the Lasso method of variable selection in sparse multi-dimensional contingency tables with a new Smooth Lasso method which casts regularization in a standard regression analysis mould, and also with the classical backwards elimination algorithm, which is used in standard software packages. First, we make a general methodological point in relation to model selection with interactions. Next we undertake a simulation study which explores the ability of the three algorithms to identify the correct model. Finally, we analyse a set of comorbidities arising in a study of obesity. The findings do not favour the standard Lasso regardless of the optimization algorithm employed.",2016,
Development and validation of a prognostic classifier based on HIF-1 signaling for hepatocellular carcinoma,"HIF-1 (hypoxia-inducible factor 1) signaling played a vital role in HCC (hepatocellular carcinoma) prognosis. We aimed to establish an accurate risk scoring system for HCC prognosis prediction and treatment guidance. 424 samples from TCGA (The Cancer Genome Atlas) and 445 samples from GSE14520 dataset were included as the derivation and validation cohort, respectively. In the derivation cohort, prognostic relevant signatures were selected from sixteen HIF-1 related genes and LASSO regression was adopted for model construction. Tumor-infiltrating immune cells were calculated using CIBERSORT algorithm. HIF-1 signaling significantly increased in HCC samples compared with normal tissues. Scoring system based on SLC2A1, ENO1, LDHA and GAPDH exhibited a continuous predictive ability for OS (overall survival) in HCC patients. PCA and t-SNE analysis confirmed a reliable clustering ability of risk score in both cohorts. Patients were classified into high-risk and low-risk groups and the survival outcomes between the two groups showed significant differences. In the derivation cohort, Cox regression indicated the scoring system was an independent predictor for OS, which was validated in the validation cohort. Different infiltrating immune cells fraction and immune scores were also observed in different groups. Herein, a novel integrated scoring system was developed based on HIF-1 related genes, which would be conducive to the precise treatment of patients.",2020,Aging (Albany NY)
C-LASSO Estimator for Generalized Additive Logistic Regression Based on B-Spline,"Generalized Additive logistic Regression model (GALRM) is a very important nonparametric regression model. It can be used for binary classification or for predicting the certainty of a binary outcome by using generalized additive models, which known as modern techniques from statistical learning, and the penalized log-likelihood criterion. In our chapter, we develop an estimation problem for GALRM based on B-spline and Least Absolute Shrinkage and Selection Operator (LASSO), unlike the traditional solutions; we will express the LASSO problem as a conic quadratic optimization problem which is a well structured convex optimization program, and solve it great and very efficient interior points methods.",2019,
Penalised inference for autoregressive moving average models with time-dependent predictors,"Linear models that contain a time-dependent response and explanatory variables have attracted much interest in recent years. The most general form of the existing approaches is of a linear regression model with autoregressive moving average residuals. The addition of the moving average component results in a complex model with a very challenging implementation. In this paper, we propose to account for the time dependency in the data by explicitly adding autoregressive terms of the response variable in the linear model. In addition, we consider an autoregressive process for the errors in order to capture complex dynamic relationships parsimoniously. To broaden the application of the model, we present an $l_1$ penalized likelihood approach for the estimation of the parameters and show how the adaptive lasso penalties lead to an estimator which enjoys the oracle property. Furthermore, we prove the consistency of the estimators with respect to the mean squared prediction error in high-dimensional settings, an aspect that has not been considered by the existing time-dependent regression models. A simulation study and real data analysis show the successful applications of the model on financial data on stock indexes.",2014,arXiv: Methodology
Model uncertainty and variable selection inÂ Bayesian lasso regression,"While Bayesian analogues of lasso regression have become popular, comparatively little has been said about formal treatments of model uncertainty in such settings. This paper describes methods that can be used to evaluate the posterior distribution over the space of all possible regression models for Bayesian lasso regression. Access to the model space posterior distribution is necessary if model-averaged inferenceâ€”e.g., model-averaged prediction and calculation of posterior variable inclusion probabilitiesâ€”is desired. The key element of all such inference is the ability to evaluate the marginal likelihood of the data under a given regression model, which has so far proved difficult for the Bayesian lasso. This paper describes how the marginal likelihood can be accurately computed when the number of predictors in the model is not too large, allowing for model space enumeration when the total number of possible predictors is modest. In cases where the total number of possible predictors is large, a simple Markov chain Monte Carlo approach for sampling the model space posterior is provided. This Gibbs sampling approach is similar in spirit to the stochastic search variable selection methods that have become one of the main tools for addressing Bayesian regression model uncertainty, and the adaption of these methods to the Bayesian lasso is shown to be straightforward.",2010,Statistics and Computing
Theses and Dissertations 2010 Grouped variable selection in high dimensional partially linear additive Cox model,"In the analysis of survival outcome supplemented with both clinical information and high-dimensional gene expression data, traditional Cox proportional hazard model fails to meet some emerging needs in biological research. First, the number of covariates is generally much larger the sample size. Secondly, predicting an outcome with individual gene expressions is inadequate because a geneâ€™s expression is regulated by multiple biological processes and functional units. There is a need to understand the impact of changes at a higher level such as molecular function, cellular component, biological process, or pathway. The change at a higher level is usually measured with a set of gene expressions related to the biological process. That is, we need to model the outcome with gene sets as variable groups and the gene sets could be partially overlapped also. In this thesis work, we investigate the impact of a penalized Cox regression procedure on regularization, parameter estimation, variable group selection, and nonparametric modeling of nonlinear effects with a time-to-event outcome. We formulate the problem as a partially linear additive Cox model with high-dimensional data. We group genes into gene sets and approximate the nonparametric components by truncated series expansions with B-spline bases. After grouping and approximation, the problem of variable selection becomes that of selecting groups of coefficients in a gene set or in an approximation. We apply the group Lasso to obtain an initial solution path and reduce the dimension of",2016,
Outcome regression methods in causal inference : The difference LASSO and selection of effect modifiers,"In causal inference, a central aim of covariate selection is to provide a subset of covariates, that is sufficient for confounding adjustment. One approach for this is to construct a subset of covariates associated with the outcome. This is sometimes referred to as the outcome approach, which is the subject for this thesis. Apart from confounding, there may exist effect modification. This occurs when a treatment has different effect on the outcome, among different subgroups, defined by effect modifiers. We describe how the outcome approach implemented by regression models, can be used for estimating the ATE, and how sufficient subsets of covariates may be constructed for these models. We also describe a novel method, called the difference LASSO, which results in identification of effect modifiers, rather than determination of sufficient subsets. The method is defined by an algorithm where, in the first step, an incorrectly specified model is fitted. We investigate the bias, arising from this misspecification, analytically and numerically for OLS. The difference LASSO is also compared with a regression estimator. The comparison is done in a simulation study, where the identification of effect modifiers is evaluated. This is done by analyzing the proportion of times a selection procedure results in a set of covariates including only the effect modifiers, or a set where the effect modifiers are included as a subset. The results show that the difference LASSO works relatively well for identification of effect modifiers. Among four designs, a set containing only the true effect modifiers were selected in at least 83.2%. The corresponding result for the regression estimator was 27.9%. However, the difference LASSO builds on biased estimation. Therefore, the method is not plausible for interpretation of treatment effects. Sammanfattning Regressionsmetoder fÃ¶r utfall inom kausal inferens: â€The difference LASSOâ€ och val av effektmodifierare Ett centralt mÃ¥l med att vÃ¤lja bakgrundsvariabler (kovariater) inom kausal inferens, Ã¤r att vÃ¤lja en delmÃ¤ngd som Ã¤r tillrÃ¤cklig fÃ¶r att justera fÃ¶r confounding. Ett sÃ¤tt att skapa en sÌŠadan delmÃ¤ngd Ã¤r att vÃ¤lja de kovariater som har ett observerat samband med responsvariabeln. Detta kallas ibland fÃ¶r â€the outcome approachâ€ och Ã¤r det tillvÃ¤gagÌŠangssÃ¤tt som anvÃ¤nds i den hÃ¤r uppsatsen. FÃ¶rutom confounding kan det Ã¤ven finnas effektmodifikation, vilket uppstÌŠar nÃ¤r en behandling har olika effekt bland olika grupper som definieras av effektmodifierare. Vi beskriver hur regressionsmodeller kan anvÃ¤ndas fÃ¶r att skatta ATE och hur tillrÃ¤ckliga delmÃ¤ngder kan skapas fÃ¶r dessa modeller. Vi beskriver Ã¤ven en ny metod som kallas â€the difference LASSOâ€. Metoden resulterar i att kovariater som Ã¤r effektmodifierare identifieras, istÃ¤llet fÃ¶r att en delmÃ¤ngd kovariater som Ã¤r tillrÃ¤cklig fÃ¶r justering av confounding skapas. Metoden bestÌŠar av en algoritm, dÃ¤r det fÃ¶rsta steget innebÃ¤r att en felaktigt specificerad modell skattas. Vi undersÃ¶ker den bias som uppstÌŠar pÌŠa grund av detta, bÌŠade analytiskt och numeriskt, fÃ¶r OLS. â€The difference LASSOâ€ jÃ¤mfÃ¶rs ocksÌŠa med en regressionsestimator. JÃ¤mfÃ¶relsen gÃ¶rs i en simuleringsstudie, dÃ¤r identifieringen av effektmodifierare utvÃ¤rderas. Det gÃ¶rs genom en analys av hur mÃ¥nga gÌŠanger valet av kovariater resulterar i en delmÃ¤ngd som endast innehÌŠaller sanna effektmodifierare eller en delmÃ¤ngd dÃ¤r de ingÌŠar. Resultaten visar att â€the difference LASSOâ€ fungerar relativt vÃ¤l som metod fÃ¶r att identifiera effektmodifierare. Bland fyra designer resulterade metoden i att en delmÃ¤ngd, med enbart sanna effektmodifierare, valdes i minst 83,2 %, vilket kan jÃ¤mfÃ¶ras med 27,9 %, som Ã¤r motsvarande resultat fÃ¶r regressionsestimatorn. DÃ¤remot bygger â€the difference LASSOâ€ pÌŠa en felaktigt specificerad modell vilket ger upphov till systematiska fel av skattningar. Detta medfÃ¶r att metoden inte passar fÃ¶r att tolka effekten av en behandling. Popular science summary In causal inference we are interested in making causal statements about the effect of a treatment on some outcome. Consider an example where we study the effect of participation in a reading program on the reading ability among students. In this example, the treatment would be participation in the reading program, and the outcome could, for example, be a score on a given reading test. If the treatment is not randomly assigned there may be variables that affect the outcome or the treatment assignment, that is, the test score or if a student participates in the reading program or not. We call these variables covariates and an example of a covariate could be a studentâ€™s health condition. There may be covariates that affect both the treatment assignment and the outcome. We call these covariates confounding covariates, and the confounding makes it difficult to draw conclusions about the true treatment effect. For example, if students who enjoy reading decide to participate in the reading program in greater extent, and they also score higher on the reading test, the effect of the reading program will be overestimated due to the confounding variable â€œreading enjoymentâ€. This bias can be removed if we, for instance, only compare test scores of students who enjoy reading. In order to make valid inference about the true treatment effect, we must have access to all confounding covariates, in our data. This is sometimes referred to as an assumption of â€œno unmeasured confoundingâ€. In many situations we have access to a large number of covariates, where it is possible to find smaller sets of covariates, that imply no unmeasured confounding. In the example above, one approach for finding such a set of covariates could be to only include covariates that affect the test score, which is the approach we use in this thesis. The treatment may also have different effects on the outcome in subgroups, defined by some covariate(s). These covariates are called effect modifiers. Continuing the example above, suppose that students, whose parents are highly educated, are used to focus and therefore can benefit from the reading program in greater extent than other students. In this case the parents education is an effect modifier, and it may be of interest to identify these kind of covariates. In this thesis we describe standard regression methods for estimating the effect of a treatment on an outcome. We also describe how, as a part of these methods, a set of covariates that imply no unmeasured confounding, is chosen. Additionally, we describe a method, called the difference LASSO. Instead of finding confounding covariates, this method identifies effect modifiers. The method is defined by a procedure which causes systematic errors (bias), and we investigate these errors as well. Furthermore, a comparison, between the difference LASSO and one of the standard methods, is made in a simulation study. The comparison is based on the number of times each method found the true effect modifiers, under different scenarios. From this we have learned that the difference LASSO works relatively well for finding effect modifiers, for instance, the method resulted in that the true effect modifiers were found in at least 83.2%. This can be compared to 27.9%, which is the corresponding result for the standard method. However, the difference LASSO is based on a procedure which causes bias. This suggests that the method only should be used for identification of effect modifiers, and not for interpretation of treatment effects.",2018,
Dissecting Characteristics Non-Parametricallyâˆ—,"Academic research has identified more than 300 characteristics associated with cross-sectional return premia. We propose a novel, non-parametric methodolody to test which characteristics provide independent information for the cross section of expected returns. We use the adaptive group LASSO (least absolute shrinkage and selection operator) to select characteristics and estimate splines over intervals of the characteristic distribution. The proposed method overcomes issues traditional methods face and is robust to outliers. Many of the previously identified return predictors do not provide incremental information for expected returns and non-linearities are important. Our proposed methodology has higher out-of-sample explanatory power compared to linear panel regressions and increases Sharpe ratios by 70%.",2016,
Dynamic prediction of long-term survival in patients with primary gastric diffuse large B-cell lymphoma: a SEER population-based study,"BackgroundThis study investigated a large number of patients to develop a predictive nomogram for survival and a web-based survival rate calculator that can dynamically predict the long-term survival of patients with primary gastric diffuse large B-cell lymphoma.MethodsA total of 2647 patients diagnosed with primary gastric diffuse large B-cell lymphoma from 1998 to 2014 were extracted from the SEER database. We used the Lasso Cox regression model to identify independent risk factors for long-term survival and to develop a predictive nomogram for survival and a web-based survival rate calculator.ResultsThe median (mean) follow-up time was 30â€‰months (52.8â€‰months). Cancer-specific survival rates decreased with time, while the 5-year conditional survival increased with time. Cancer-specific deaths were not constant. Cancer-specific deaths of patients within the first 2â€‰years were high, while the risk remained relatively constant after 2â€‰years. The independent risk factors included surgery, chemotherapy, tumor stage and age, according to the Lasso Cox regression analysis. We developed a predictive nomogram and a web-based survival rate calculator (https://linjuli1991.shinyapps.io/dynnomapp/). The calibration plot suggested that the actual value exhibited good agreement with the predicted value.ConclusionsWe found that patients with primary gastric diffuse large B-cell lymphoma had a high risk of death during the first 2â€‰years. Additional active follow-up strategies should be provided during this period. This is the first study to develop a predictive nomogram and a web-based survival rate calculator that can provide evidence for individual treatment and follow-up.",2019,BMC Cancer
Model Selection and Multimodel Inference,"How to select a model or to base conclusions on more than one model depends on the purpose and the design of the study. In this chapter, we discuss the difference between confirmatory and predictive analyses and explain the tradeoff between bias and precision in statistical models. We present commonly used methods to rank models according to their predictive performance, such as cross-validation and the widely applicable information criterion (WAIC). We also introduce the least absolute shrinkage and selection operator (LASSO) and ridge regression as flexible tools to shrink model coefficients toward zero. Finally, we present how to do model averaging based on posterior model probabilities. Throughout the chapter, we emphasize the importance of prior knowledge and scientific reasoning when building models or combining information from different models.",2015,
Short-term forecasting with mixed-frequency data: A MIDASSO approach: a MIDASSO approach,"In this paper we extend the targeted-regressor approach suggested in Bai and Ng (2008) for variables sampled at the same frequency to mixed-frequency data. Our MIDASSO approach is a combination of the unrestricted MIxed-frequency DAta-Sampling approach (U-MIDAS) (see Foroni et al., 2015; Castle et al., 2009; Bec and Mogliani, 2013), and the LASSO-type penalised regression used in Bai and Ng (2008), called the elastic net (Zou and Hastie, 2005). We illustrate our approach by forecasting the quarterly real GDP growth rate in Switzerland.",2015,
Ensemble Method for Censored Demand Prediction,"Many economic applications, including optimal pricing and inventory management, require predictions of demand based on sales data and the estimation of the reaction of sales to price change. There is a wide range of econometric approaches used to correct biases in the estimates of demand parameters on censored sales data. These approaches can also be applied to various classes of machine learning (ML) models to reduce the prediction error of sales volumes. In this study we construct two ensemble models for demand prediction with and without accounting for demand censorship. Accounting for sales censorship is based on a censored quantile regression where the model estimation was split into two separate parts: a) a prediction of zero sales by the classification model; and b) a prediction of non-zero sales by the regression model. Models with and without censorship are based on the prediction aggregations of least squares, Ridge and Lasso regressions and the Random Forest model. Having estimated the predictive properties of both models, we empirically test the best predictive power of the model taking into account the censored nature of demand. We also show that ML with censorship provides bias corrected estimates of demand sensitivity to price change similar to econometric models",2018,ArXiv
Regularization parameter selection for a bayesian group sparse multi-task regression model with application to imaging genomics,"We investigate the choice of tuning parameters for a Bayesian multi-level group lasso model developed for the joint analysis of neuroimaging and genetic data. The regression model we consider relates multivariate phenotypes consisting of brain summary measures (volumetric and cortical thickness values) to single nucleotide polymorphism (SNPs) data and imposes penalization at two nested levels, the first corresponding to genes and the second corresponding to SNPs. Associated with each level in the penalty is a tuning parameter which corresponds to a hyperparameter in the hierarchical Bayesian formulation. Following previous work on Bayesian lassos we consider the estimation of tuning parameters through either hierarchical Bayes based on hyperpriors and Gibbs sampling or through empirical Bayes based on maximizing the marginal likelihood using a Monte Carlo EM algorithm. For the specific model under consideration we find that these approaches can lead to severe overshrinkage of the regression parameter estimates in the highdimensional setting or when the genetic effects are weak. We demonstrate these problems through simulation examples and study an approximation to the marginal likelihood which sheds light on the cause of this problem. We then suggest an alternative approach based on the widely applicable information criterion (WAIC), an asymptotic approximation to leave-one-out crossvalidation that can be computed conveniently within an MCMC framework.",2016,2016 International Workshop on Pattern Recognition in Neuroimaging (PRNI)
"543-P: A Clinical, Proteomics and Artificial Intelligence-Driven Model to Predict Acute Kidney Injury in Diabetic Patients Undergoing Coronary Angiographyâ€”Results from the Catheter Sampled Blood Archive in Cardiovascular Diseases Study","Background: We previously developed a clinical/proteomics panel for predicting procedural acute kidney injury (AKI) and now examine its performance in those with diabetes (DM). Methods: We measured 109 biomarkers in blood from patients undergoing coronary angiography. Procedural AKI defined as increase in serum creatinine â‰¥0.3 mg/dL, increase in serum creatinine of â‰¥50%, or documented oliguria â‰¤7 days after procedure. Clinical and biomarker predictors of AKI identified using least-angle regression; a final prognostic model was developed with LASSO; the model was then measured in those with DM. Results: Besides DM, 5 predictors were in the final model: 3 (blood urea nitrogen to creatinine ratio, C-reactive protein and osteopontin) had positive association, while 2 (CD5 antigen-like and Factor VII) had negative association with AKI risk. Among 217 patients with DM, 18 (8.3%) developed AKI. The final model had an AUC of 0.87 for predicting procedural AKI (P Conclusions: We describe a clinical and proteomics-supported biomarker model with high sensitivity/NPV for AKI in patients with DM following coronary angiography. Disclosure N.E. Ibrahim: Other Relationship; Self; Novartis Pharmaceuticals Corporation. C.P. McCarthy: None. S. Shrestha: None. H. Gaggin: Other Relationship; Self; Dr. Gaggin has received research grant support from Roche Diagnostics, Jana Care, Ortho Clinical, Novartis; consulting income from Merck, Roche Diagnostics; research payments for clinical endpoint com. R. Mukai: None. C.A. Magaret: Consultant; Self; Prevencio. R.F. Rhyne: Board Member; Self; Prevencio. Employee; Self; Prevencio. Stock/Shareholder; Self; Prevencio. J. Januzzi: Consultant; Self; Abbott, Roche Diagnostic USA. Research Support; Self; Abbott, Prevencio, Quest Diagnostics, Roche Diagnostic USA. Funding Prevencio, Inc.",2019,Diabetes
Active Learning for Recommender Systems with Multiple Localized Models,"For effective predictive modeling in large scale recommender systems, it is essential to have many customers rate a large number of products, i.e., obtain a large number of labeled data. However, most consumers often do not provide their preferences without proper incentives. Given a budget to reward consumers for their feedback, it would be beneficial to have a policy to suggest the ratings of which customers and for what products would be most cost-effective to acquire, so as to improve modeling the most. E-commerce businesses can use such a policy to cost-effectively acquire consumersâ€™ ratings or other forms of feedbacks, incrementally. This challenge can be mapped to the problem of active learning [2] in which a learner aims to intelligently select the labels of particularly informative examples from a pool of prospective acquisitions, so as to improve generalization accuracy the most for a given number of acquisitions. While there are published results for active learning in a regression setting [4, 5], there has been little study of approaches that are applicable to important, practical scenarios. In particular, most proposed approaches aim at optimizing the training input density (non pool based) rather than evaluate prospective acquisitions from an available pool, and focus on linear least squares models. In addition, most of the literature on active learning, especially in the machine learning community involves learning in the context of classification problems [2]. Also, these methods consider predictions obtained by either a single â€œglobalâ€ probabilistic classification model or an ensemble of global classifiers (e.g., bagging or boosting). As we discuss below, large scale data sets that are characteristic of recommender systems, suggest other types of modeling that are significantly more appropriate. The data encountered in large scale recommender systems typically exhibit inherent heterogeneity among the customers and products. For instance, Amazon.com being a large retailer has customers who exhibit varied purchase patterns. As we demonstrate, in this setting it is beneficial to model the behavior of different groups of customers separately. Similarly, because the retailerâ€™s products span a very wide range of categories, it is also advantageous to model ratings for homogeneous product groups separately. Thus, rather than induce a single predictive model, one can represent such data by a set of multiple local models, such that each local model captures consumersâ€™ ratings in a certain region of the input (consumer/product) space. We propose a radically different active learning scheme that (a) leverages a collection of localized predictive models, and (b) generalizes to both classification and regression prediction problems. Our approach is also applicable to a wide range of model types, including non linear models such as MLPs, or regularized linear models (ridge/lasso). Before developing our active learning strategy, we first discuss briefly how to learn a set of local predictive models to accurately represent such heterogeneous data. We recently proposed Simultaneous CO-clustering And Learning (SCOAL) [3], a versatile and effective framework for predictive modeling of large scale, heterogeneous, dyadic data. SCOAL interleaves simultaneous partitioning along both â€œcustomerâ€ and â€œproductâ€ modes (co-clustering) and the construction of prediction models to iteratively improve both the assignment of a consumerâ€™s rating to a given cluster, as well as improve the fit of the model induced within each data cluster. SCOAL exploits both neighborhood information and the available customer/product attributes, thereby combining the benefits of collaborative filtering and of content based approaches. The framework can be viewed as simultaneous co-segmentation and classification (or regression), and we show is substantially better than independently clustering the data a priori followed by model induction. In SCOAL, each model",2009,
Improving the prediction of going concern of Taiwanese listed companies using a hybrid of LASSO with data mining techniques,"The purpose of this study is to establish rigorous and reliable going concern doubt (GCD) prediction models. This study first uses the least absolute shrinkage and selection operator (LASSO) to select variables and then applies data mining techniques to establish prediction models, such as neural network (NN), classification and regression tree (CART), and support vector machine (SVM). The samples of this study include 48 GCD listed companies and 124 NGCD (non-GCD) listed companies from 2002 to 2013 in the TEJ database. We conduct fivefold cross validation in order to identify the prediction accuracy. According to the empirical results, the prediction accuracy of the LASSOâ€“NN model is 88.96Â % (Type I error rate is 12.22Â %; Type II error rate is 7.50Â %), the prediction accuracy of the LASSOâ€“CART model is 88.75Â % (Type I error rate is 13.61Â %; Type II error rate is 14.17Â %), and the prediction accuracy of the LASSOâ€“SVM model is 89.79Â % (Type I error rate is 10.00Â %; Type II error rate is 15.83Â %).",2016,SpringerPlus
Asymptotic analysis of high-dimensional LAD regression with Lasso,"The Lasso is an attractive approach to variable selection in sparse, highdimensional regression models. Much work has been done to study the selection and estimation properties of the Lasso in the context of least squares regression. However, the least squares based method is sensitive to outliers. An alternative to the least squares method is the least absolute deviations (LAD) method which is robust to outliers in the responses. In this paper, we study the selection and estimation properties of the Lasso in LAD regression. We provide sufficient conditions under which the LAD-Lasso is estimation or selection consistent in sparse, high-dimensional settings. We use simulation studies to evaluate the performance of the LAD-Lasso, and compare the proposed method with the LS-Lasso in a range of generating models.",2016,
Penalized estimation equation for an extended single-index model,"The single-index model is a useful extension of the linear regression model. Cui et al. (Ann Stat 39:1658â€“1688, 2011) proposed an estimating function method for the estimation of index vector in an extended single-index model (ESIM). Nevertheless, how to conduct variable selection for ESIM has not been studied. To solve this problem, we penalize the estimating equation with some types of penalty, such as smoothly clipped absolute deviation penalty and adaptive lasso penalty. Under some regularity conditions, the oracle property is established, i.e., the resulting estimator can be as efficient as the oracle estimator, thus we improve the explanatory ability and accuracy of estimator for the ESIM. A novel algorithm is proposed to solve the penalized estimating equation by combining quasi-Fisher scoring type algorithm and MM algorithm. Simulation study and real data application demonstrate the excellent performance of the proposed estimators.",2017,Annals of the Institute of Statistical Mathematics
Non-negative least squares for high-dimensional linear models: consistency and sparse recovery without regularization,"Least squares fitting is in general not useful for high-dimensional linear models, in which the number of predictors is of the same or even larger order of magnitude than the number of samples. Theory developed in recent years has coined a paradigm according to which sparsity-promoting regularization is regarded as a necessity in such setting. Deviating from this paradigm, we show that non-negativity constraints on the regression coefficients may be similarly effective as explicit regularization if the design matrix has additional properties, which are met in several applications of non-negative least squares (NNLS). We show that for these designs, the performance of NNLS with regard to prediction and estimation is comparable to that of the lasso. We argue further that in specific cases, NNLS may have a better $\ell_{\infty}$-rate in estimation and hence also advantages with respect to support recovery when combined with thresholding. From a practical point of view, NNLS does not depend on a regularization parameter and is hence easier to use.",2012,arXiv: Statistics Theory
Multiphase Liver MRI for Identifying the Macrotrabecular-Massive Subtype of Hepatocellular Carcinoma.,"Background The recently described ""macrotrabecular-massive"" (MTM) histologic subtype of hepatocellular carcinoma (HCC) (MTM-HCC) represents an aggressive form of HCC and is associated with poor survival. Purpose To investigate whether preoperative MRI can help identify MTM-HCCs in patients with HCC. Materials and Methods This retrospective study included patients with HCC treated with surgical resection between January 2008 and February 2018 and who underwent preoperative multiphase contrast material-enhanced MRI. Least absolute shrinkage and selection operator (LASSO)-penalized and multivariable logistic regression analyses were performed to identify clinical, biologic, and imaging features associated with the MTM-HCC subtype. Early recurrence (within 2 years) and overall recurrence were evaluated by using Kaplan-Meier analysis. Multivariable Cox regression analysis was performed to determine predictors of early and overall recurrence. Results One hundred fifty-two patients (median age, 64 years; interquartile range, 56-72 years; 126 men) with 152 HCCs were evaluated. Twenty-six of the 152 HCCs (17%) were MTM-HCCs. LASSO-penalized logistic regression analysis identified substantial necrosis, high serum Î±-fetoprotein (AFP) level (>100 ng/mL), and Barcelona Clinic Liver Cancer (BCLC) stage B or C as independent features associated with MTM-HCCs. At multivariable analysis, substantial necrosis (odds ratio = 32; 95% confidence interval [CI] = 8.9, 114; P < .001), high serum AFP level (odds ratio = 4.4; 95% CI = 1.3, 16; P = .02), and BCLC stage B or C (odds ratio = 4.2; 95% CI = 1.2, 15; P = .03) were independent predictors of MTM-HCC subtype. Substantial necrosis helped identify 65% (17 of 26; 95% CI: 44%, 83%) of MTM-HCCs (sensitivity) with a specificity of 93% (117 of 126; 95% CI: 87%, 97%). In adjusted models, only the presence of satellite nodules was independently associated with both early (hazard ratio = 3.7; 95% CI: 1.5, 9.4; P = .006) and overall (hazard ratio = 3.0; 95% CI: 1.3, 7.2; P = .01) tumor recurrence. Conclusion At multiphase contrast-enhanced MRI, substantial necrosis helped identify macrotrabecular-massive hepatocellular carcinoma subtype with high specificity. Â©â€‰RSNA, 2020.",2020,Radiology
A Note on the Adaptive LASSO for Zero-Inflated Poisson Regression,"We consider the problem of modelling count data with excess zeros using Zero-Inflated Poisson (ZIP) regression. Recently, various regularization methods have been developed for variable selection in ZIP models. Among these, EM LASSO is a popular method for simultaneous variable selection and parameter estimation. However, EM LASSO suffers from estimation inefficiency and selection inconsistency. To remedy these problems, we propose a set of EM adaptive LASSO methods using a variety of data-adaptive weights. We show theoretically that the new methods are able to identify the true model consistently, and the resulting estimators can be as efficient as oracle. The methods are further evaluated through extensive synthetic experiments and applied to a German health care demand dataset.",2018,Journal of Probability and Statistics
GG-05 Predictive ability of SLE genetic risk factors varies across ethnicities,"Background Systemic lupus erythematosus (SLE) exhibits marked ethnic disparities. The SLE Immunochip Consortiumâ€™s transancestral association study of SLE (27â€‰574 individuals of European (EA), African (AA) and Hispanic Amerindian (HA) ancestry) raised the number of common risk variants to >100 (Langefeld 2017). There, we proposed the cumulative hit hypothesis, where the cumulative effect of individual loci is greater than if each locus acted independently. Here, we explore the joint contribution of SLE-susceptibility loci, how it varies by ethnicity, and whether there are distinct genetic risk profiles. Methods The SLE Immunochip study design, identification of risk loci, and genetic load (risk allele count (RAC) in EA samples) were previously described (Langefeld 2017). Genetic load was tested for association with SLE in an independent set of 2000/2000 EA case/controls, and in the AA and HA cohorts. Individuals in lowest 10% of the RAC distribution were the reference sample. A logistic regression model, adjusting for admixture, computed the odds ratio (OR) comparing the reference group to samples within a moving window of 20 unweighted RAC (moving window of 4 for the weighted (SNPâ€™s log(OR)) analysis). Lasso regression identified EA risk SNPs that maximally predict SLE status in EA, then applied prediction to AA and HA. Factor analysis identified individual genetic risk profiles. Results The OR comparing lowest versus highest 10% of RAC was âˆ¼30,âˆ¼6, and âˆ¼3 for EA, HA and AA, respectively (figure 1), showing EA risk loci were not highly predictive of SLE risk in HA and AA. In EA, the moving window genetic load OR showed an increase beyond that predicted by independence but did not in HA and AA due to lower predictive ability. Lasso regression identified 51 risk alleles that maximally predicted SLE in EA, and a factor analysis identified seven uncorrelated risk profiles (one driven by HLA alleles and six by non-HLA loci). The lasso identified 31 (3 HLA) and 8 (no HLA) EA risk alleles as predictive in the HA and AA, respectively. Using predicted probabilities from the lasso in EA, the area under the ROC curve was 0.75 for EA, 0.72 for HA, and 0.60 for AA. Conclusions The EA SLE risk loci are highly predictive in EA (with a greater than additive effect), modestly predictive in HA, and weakly predictive in AA. We posit that the SLE genetics of AA are meaningfully different from EA and HA, merit increased study, and will require ethnicity-informed treatment strategies. Acknowledgements We would like to thank the SLE Immunochip Consortium, the Lupus Research Alliance, NIH (NIAMS and NIAID) and RILITE Foundation.",2018,Lupus science & medicine
Local Regression Model for Automatic Face Sketch Generation,"As one of the important artistic styles of portrait, sketch portrait has wide applications for both digital entertainment and law enforcement. In this paper, an automatic face sketch generation approach is presented by learning from photo-sketch pair examples. Specifically, the relationship between a face photo and its corresponding face sketch is learned on image patch level. By applying this relationship to the input face photo patch, we can infer the output face sketch patch by exploiting some regression techniques such as kNN, the Lasso and so on. Via our local regression model, we can synthesize an appealing sketch portrait from a given face photo in a few minutes. Experiments conducted on CUHK database have shown that our results are more compelling than previous methods especially in two respects: (1) our synthesized sketches preserve more identity information of the original face photo, (2) our synthesized sketches presents more pencil sketch texture.",2011,2011 Sixth International Conference on Image and Graphics
A group VISA algorithm for variable selection,"We consider the problem of selecting grouped variables in a linear regression model based on penalized least squares. The group-Lasso and the group-Lars procedures are designed for automatically performing both the shrinkage and the selection of important groups of variables. However, since the same tuning parameter is used (as in Lasso or Lars ) for both group variable selection and shrinkage coefficients, it can lead to over shrinkage the significant groups of variables or inclusion of many irrelevant groups of predictors. This situation occurs when the true number of non-zero groups of coefficients is small relative to the number $$p$$p of variables. We introduce a novel sparse regression method, called the Group-VISA (GVISA), which extends the VISA effect to grouped variables. It combines the idea of VISA algorithm which avoids the over shrinkage problem of regression coefficients and the idea of the GLars-type estimator which shrinks and selects the members of the group together. Hence, GVISA is able to select a sparse group model by avoiding the over shrinkage of GLars-type estimator. We distinguish two variants of the GVISA algorithm, each one is associated with each version of GLars (I and II). Moreover, we provide a path algorithm, similar to GLars, for efficiently computing the entire sample path of GVISA coefficients. We establish a theoretical property on sparsity inequality of GVISA estimator that is a non-asymptotic bound on the estimation error. A detailed simulation study in small and high dimensional settings is performed, which illustrates the advantages of the new approach in relation to several other possible methods. Finally, we apply GVISA on two real data sets.",2015,Statistical Methods & Applications
TU-AB-BRA-10: Prognostic Value of Intra-Radiation Treatment FDG-PET and CT Imaging Features in Locally Advanced Head and Neck Cancer,"Purpose: To predict response to radiation treatment using computational FDG-PET and CT images in locally advanced head and neck cancer (HNC). Methods: 68 patients with State III-IVB HNC treated with chemoradiation were included in this retrospective study. For each patient, we analyzed primary tumor and lymph nodes on PET and CT scans acquired both prior to and during radiation treatment, which led to 8 combinations of image datasets. From each image set, we extracted high-throughput, radiomic features of the following types: statistical, morphological, textural, histogram, and wavelet, resulting in a total of 437 features. We then performed unsupervised redundancy removal and stability test on these features. To avoid over-fitting, we trained a logistic regression model with simultaneous feature selection based on least absolute shrinkage and selection operator (LASSO). To objectively evaluate the prediction ability, we performed 5-fold cross validation (CV) with 50 random repeats of stratified bootstrapping. Feature selection and model training was solely conducted on the training set and independently validated on the holdout test set. Receiver operating characteristic (ROC) curve of the pooled Result and the area under the ROC curve (AUC) was calculated as figure of merit. Results: For predicting local-regional recurrence, our model built on pre-treatment PET of lymph nodes achieved the best performance (AUC=0.762) on 5-fold CV, which compared favorably with node volume and SUVmax (AUC=0.704 and 0.449, p<0.001). Wavelet coefficients turned out to be the most predictive features. Prediction of distant recurrence showed a similar trend, in which pre-treatment PET features of lymph nodes had the highest AUC of 0.705. Conclusion: The radiomics approach identified novel imaging features that are predictive to radiation treatment response. If prospectively validated in larger cohorts, they could aid in risk-adaptive treatment of HNC.",2015,Medical Physics
Ultra-fast preselection in lasso-type spatio-temporal solar forecasting problems,"Abstract Solar forecasting using data collected by satellites or sensor networks is often framed as a many-predictor spatio-temporal regression problem. Whereas the regressand is the irradiance at the focal location, the regressors could be the irradiance at any neighboring location with any time lag. Lassoâ€”the least absolute shrinkage and selection operatorâ€”is commonly used for regressor selection and regularization in order to enhance the forecast accuracy and interpretability of the regression model. However, when the number of regressors is much larger than the number of samples, lasso-type regressions are limited by the curse of dimensionality and the insufficient degree of freedom. The ultra-fast preselection algorithm herein proposed provides a remedy to the above-mentioned problem. The algorithm uses (probably) the worldâ€™s fastest similarity search routine, and preselects a user-defined number of most-relevant regressors based on the z-normalized Euclidean distance. The preselected regressors are then fed to lasso for forecasting. The algorithm is completely free from the curse of dimensionality, and does not require any meteorological prior, such as wind information or cloud vector field. It is customizable for other forecasting methods, such as vector autoregression or kriging, and can be implemented in just 10 lines of code.",2018,Solar Energy
Selection properties of type II maximum likelihood (empirical Bayes) in linear models with individual variance components for predictors,"Maximum likelihood (ML) in the linear model overfits when the number of predictors (M) exceeds the number of objects (N). One of the possible solution is the relevance vector machine (RVM) which is a form of automatic relevance detection and has gained popularity in the pattern recognition machine learning community by the famous textbook of Bishop (2006). RVM assigns individual precisions to weights of predictors which are then estimated by maximizing the marginal likelihood (type II ML or empirical Bayes). We investigated the selection properties of RVM both analytically and by experiments in a regression setting. We show analytically that RVM selects predictors when the absolute z-ratio (|least squares estimate|/standard error) exceeds 1 in the case of orthogonal predictors and, for M=2, that this still holds true for correlated predictors when the other z-ratio is large. RVM selects the stronger of two highly correlated predictors. In experiments with real and simulated data, RVM is outcompeted by other popular regularization methods (LASSO and/or PLS) in terms of the prediction performance. We conclude that type II ML is not the general answer in high dimensional prediction problems. In extensions of RVM to obtain stronger selection, improper priors (based on the inverse gamma family) have been assigned to the inverse precisions (variances) with parameters estimated by penalized marginal likelihood. We critically assess this approach and suggest a proper variance prior related to the Beta distribution which gives similar selection and shrinkage properties and allows a fully Bayesian treatment.",2012,Pattern Recognit. Lett.
"Blockwise coordinate descent procedures for the multi-task lasso, with applications to neural semantic basis discovery","We develop a cyclical blockwise coordinate descent algorithm for the multi-task Lasso that efficiently solves problems with thousands of features and tasks. The main result shows that a closed-form Winsorization operator can be obtained for the sup-norm penalized least squares regression. This allows the algorithm to find solutions to very large-scale problems far more efficiently than existing methods. This result complements the pioneering work of Friedman, et al. (2007) for the single-task Lasso. As a case study, we use the multi-task Lasso as a variable selector to discover a semantic basis for predicting human neural activation. The learned solution outperforms the standard basis for this task on the majority of test participants, while requiring far fewer assumptions about cognitive neuroscience. We demonstrate how this learned basis can yield insights into how the brain represents the meanings of words.",2009,
Combination of least absolute shrinkage and selection operator with Bayesian Regularization artificial neural network (LASSO-BR-ANN) for QSAR studies using functional group and molecular docking mixed descriptors,"Abstract A combination of least absolute shrinkage and selection operator (LASSO) with Bayesian Regularization feed-forward artificial neural network (LASSO-BR-ANN) was used as a new approach in the quantitative structure-activity relationship (QSAR) studies. A mixture of the docking derived descriptors with the simple functional group (structural) features was also introduced as a new ensemble of descriptors for accurate QSAR modeling. The performance of introduced approaches was tested with QSAR modeling of the biological activities (pEC50) of 73 azine derivatives as new non-nucleoside reverse transcriptase inhibitors (NNRTIs) for treatment of HIV disease. Molecular docking descriptors (MDDs) were generated from ligand-receptor interactions and functional group features derived using Dragon 5.5 software. The dataset was divided into three sets of training, validation, and test data. LASSO, as a penalized regression method, was applied to the training data set for the selection of the most relevant descriptors among the mixture of the structural and MDDs. LASSO selected descriptors were used as inputs in the construction of the Bayesian Regularization artificial neural network (BR-ANN) model. The results showed that the addition of functional group properties to the MDDs improves the accuracy of the model. Under the optimum conditions, LASSO-BR-ANN was successfully applied for the prediction of PEC50 values for compounds in the external test set with mean square error (MSE) and coefficient of determination (R2) values of 0.07 and 0.88, respectively. Some of the prediction statistical parameters of the model were calculated and all of them were in their acceptable ranges, which confirm the validity of the proposed QSAR model.",2020,Chemometrics and Intelligent Laboratory Systems
