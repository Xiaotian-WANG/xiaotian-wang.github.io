title,abstract,year,journal
Predicting later asthma in toddlers: Do environmental exposure data improve a clinical tool?,"Background: We recently developed a simple clinical tool for predicting asthma at school-age in toddlers presenting at the doctor with wheeze or cough (ERJ 2011;38(Supp 55):269-270s). It uses 10 predictors (severity of wheeze, atopic family history, eczema, age and sex), summarized in a score. We now assessed, whether environmental (EV) and socioeconomic (SE) factors improve the predictive performance of this tool.

Methods: From a population-based cohort (UK), we included 1-3 year-olds with current wheeze or recurrent cough and related healthcare visits. Current asthma (wheeze needing inhalers) was assessed 5 yrs later. As potential predictors we included the original prediction score, plus EV (nursery care, siblings, cooking and heating fuel, pets, smoking, breastfeeding) and SE factors (Townsend score, overcrowding, traffic density, urban living, parental education, single parents). We first looked at univariable associations between EV and SE factors and asthma 5 yrs later and then used lasso penalized logistic regression to select predictors in a model including all potential predictors.

Results: 345/1226 (28%) eligible children had asthma 5 yrs after baseline. Cooking with gas and maternal smoking were associated with asthma (p<0.05). However, in the lasso penalized logistic regression only the original score was selected.

Conclusion: Severity of wheeze and family history remain the most important predictors of later asthma in toddlers. Information on EV and SE factors adds little to improve predictive performance of the tool. Further research should investigate the additional value of physiological measurements.

Funding: SNF PDFMP3-123162, SNF 32003B-144068, Asthma UK 07/048.",2013,European Respiratory Journal
Factors related to and economic implications of inhospital death in German lung cancer patients - results of a Nationwide health insurance claims data based study,"BackgroundWhen patients die in a hospital their quality of life is lower than when they die at home or in a hospice. Despite efforts to improve palliative care supply structures, still about 60% of lung cancer patients die in a hospital. Studies have examined factors related to inhospital death in lung cancer patients, yet none used data of a representative German population, additionally including economic aspects. This study aimed to identify factors related to inhospital death in German lung cancer patients and analysed resulting costs.MethodsWe analysed a dataset of health insurance claims of 17,478 lung cancer patients (incident 2009) with 3 year individual follow-up. We grouped patients into inhospital death and death elsewhere. Studied factors were indicators of healthcare utilization, palliative care, comorbidities and disease spread. We used logistic regression models with LASSO selection method to identify relevant factors. We compared all-cause healthcare expenditures for the last 30Â days of life between both groups using generalized linear models with gamma distribution.ResultsTwelve thousand four hundred fifty-seven patients died in the observation period, thereof 6965 (55.9%) in a hospital. The key factors for increased likelihood of inhospital death were receipt of inpatient palliative care (ORâ€‰=â€‰1.85), chemotherapeutic treatments in the last 30Â days of life (ORâ€‰=â€‰1.61) and comorbid Congestive Heart Failure (ORâ€‰=â€‰1.21), and Renal Disease (ORâ€‰=â€‰1.19). In contrast, higher care level (ORâ€‰=â€‰0.16), nursing home residency (ORâ€‰=â€‰0.25) and receipt of outpatient palliative care (ORâ€‰=â€‰0.25) were associated with a reduced likelihood. All OR were significant (p-values<â€‰0.05). Expenditures in the last 30Â days of life were significantly higher for patients with inhospital death (â‚¬ 6852 vs. â‚¬ 33,254, p-value<â€‰0.0001).ConclusionFindings suggest that factors associated with inhospital death often relate to previous contact with hospitals like prior hospitalizations, and treatment of the tumour or comorbidities. Additionally, factors associated with dying elsewhere relate to access to care settings which are more focused on palliation than hospitals. From these results, we can derive that implementing tools like palliative care into tumour-directed therapy might help patients make self-determined decisions about their place of death. This can possibly be achieved at reduced economic burden for SHIs.",2018,BMC Health Services Research
Ultrahigh dimensional variable selection through the penalized maximum trimmed likelihood estimator,"Abstract The penalized maximum likelihood estimator (PMLE) has been widely used for variable selection in high-dimensional data. Various penalty functions have been employed for this purpose, e.g., Lasso, weighted Lasso, or smoothly clipped absolute deviations. However, the PMLE can be very sensitive to outliers in the data, especially to outliers in the covariates (leverage points). In order to overcome this disadvantage, the usage of the penalized maximum trimmed likelihood estimator (PMTLE) is proposed to estimate the unknown parameters in a robust way. The computation of the PMTLE takes advantage of the same technology as used for PMLE but here the estimation is based on subsamples only. The breakdown point properties of the PMTLE are discussed using the notion of $$d$$-fullness. The performance of the proposed estimator is evaluated in a simulation study for the classical multiple linear and Poisson linear regression models.",2014,Statistical Papers
Gene expression Gradient lasso for Cox proportional hazards model,"Motivation: There has been an increasing interest in expressing a survival phenotype (e.g. time to cancer recurrence or death) or its distribution in terms of a subset of the expression data of a subset of genes. Due to high dimensionality of gene expression data, however, there is a serious problem of collinearity in fitting a prediction model, e.g. Coxâ€™s proportional hazards model. To avoid the collinearity problem, several methods based on penalized Cox proportional hazards models have been proposed. However, those methods suffer from severe computational problems, such as slow or even failed convergence, because of high-dimensional matrix inversions required for model fitting. We propose to implement the penalized Cox regression with a lasso penalty via the gradient lasso algorithm that yields faster convergence to the global optimum than do other algorithms. Moreover the gradient lasso algorithm is guaranteed to converge to the optimum under mild regularity conditions. Hence, our gradient lasso algorithm can be a useful tool in developing a prediction model based on high-dimensional covariates including gene expression data. Results: Results from simulation studies showed that the prediction model by gradient lasso recovers the prognostic genes. Also results from diffuse large B-cell lymphoma datasets and Norway/Stanford breast cancer dataset indicate that our method is very competitive compared with popular existing methods by Park and Hastie and Goeman in its computational time, prediction and selectivity. Availability: R package glcoxph is available at http://datamining.dongguk.ac.kr/R/glcoxph. Contact: park463@uos.ac.kr",2009,
Significance of tumor-infiltrating immunocytes for predicting prognosis of hepatitis B virus-related hepatocellular carcinoma,"BACKGROUND
Hepatitis B virus (HBV) has been recognized as a leading cause of hepatocellular carcinoma (HCC). Numerous reports suggest that immune infiltration can predict the prognosis of HCC. Nonetheless, no creditable markers for prognosis of HBV-related HCC have been established by systematically assessing the immune-related markers based on tumor transcriptomes.


AIM
To establish an immune-related marker based on the cell compositions of immune infiltrate obtained based on tumor transcriptomes, so as to enhance the prediction accuracy of HBV-related HCC prognosis.


METHODS
RNA expression patterns as well as the relevant clinical data of HCC patients were obtained from The Cancer Genome Atlas. Twenty-two immunocyte fraction types were estimated by cell type identification by estimating relative subsets of RNA transcripts. Subsequently, the least absolute shrinkage and selection operator (LASSO) Cox regression model was employed to construct an immunoscore based on the immunocyte fraction types. Afterwards, the receiver operating characteristic (ROC) curve, Kaplan-Meier, and multivariate Cox analyses were performed. Additionally, a nomogram for prognosis that integrated the immunoscore as well as the clinical features was established. Meanwhile, the correlation of immunoscore with immune genes was also detected, and gene set enrichment analysis (GSEA) of the immunoscore was conducted.


RESULTS
A total of 22 immunocyte fraction types were predicted and compared among the tumor as well as non-tumor samples. An immunoscore was constructed through adopting the LASSO model, which contained eight immunocyte fraction types. Meanwhile, the areas under the ROC curves for the immunoscore biomarker prognostic model were 0.971, 0.912, and 0.975 for 1-, 3-, and 5-year overall survival (OS), respectively. Difference in OS between the high-immunoscore group and the low-immunoscore group was statistically significant [hazard ratio (HR) = 66.007, 95% confidence interval (CI): 8.361-521.105; P < 0.0001]. Moreover, multivariable analysis showed that the immunoscore was an independent factor for predicting the prognosis (HR = 2.997, 95%CI: 1.737-5.170). A nomogram was established, and the C-index was 0.757 (95%CI: 0.648-0.866). The immunoscore showed a significant negative correlation with the expression of PD-1 (P = 0.024), PD-L1 (P = 0.026), PD-L2 (P = 0.029), and CD27 (P = 0.033). Eight pathways were confirmed by GSEA.


CONCLUSION
The established immunoscore can potentially serve as a candidate marker to estimate the OS for HBV-related HCC cases.",2019,World Journal of Gastroenterology
Data Analysis and Machine Learning: Linear Regression and more Advanced Regression Analysis,"Why Linear Regression (aka Ordinary Least Squares and family) Fitting a continuous function with linear parameterization in terms of the parameters Î². â€¢ Method of choice for fitting a continuous function! â€¢ Gives an excellent introduction to central Machine Learning features with understandable pedagogical links to other methods like Neural Networks, Support Vector Machines etc â€¢ Analytical expression for the fitting parameters Î² â€¢ Analytical expressions for statistical propertiers like mean values, variances, confidence intervals and more â€¢ Analytical relation with probabilistic interpretations â€¢ Easy to introduce basic concepts like bias-variance tradeoff, cross-validation, resampling and regularization techniques and many other ML topics â€¢ Easy to code! And links well with classification problems and logistic regression and neural networks â€¢ Allows for easy hands-on understanding of gradient descent methods â€¢ and many more features For more discussions of Ridge and Lasso regression, Wessel van Wieringenâ€™s article is highly recommended. Similarly, Mehta et alâ€™s article is also recommended.",2018,
Identification of a 4â€mRNA metastasisâ€related prognostic signature for patients with breast cancer,"Metastasis-related mRNAs have showed great promise as prognostic biomarkers in various types of cancers. Therefore, we attempted to develop a metastasis-associated gene signature to enhance prognostic prediction of breast cancer (BC) based on gene expression profiling. We firstly screened and identified 56 differentially expressed mRNAs by analysing BC tumour tissues with and without metastasis in the discovery cohort (GSE102484, nÂ =Â 683). We then found 26 of these differentially expressed genes were associated with metastasis-free survival (MFS) in the training set (GSE20685, nÂ =Â 319). A metastasis-associated gene signature built using a LASSO Cox regression model, which consisted of four mRNAs, can classify patients into high- and low-risk groups in the training cohort. Patients with high-risk scores in the training cohort had shorter MFS (hazard ratio [HR] 3.89, 95% CI 2.53-5.98; PÂ <Â 0.001), disease-free survival (DFS) (HR 4.69, 2.93-7.50; PÂ <Â 0.001) and overall survival (HR 4.06, 2.56-6.45; PÂ <Â 0.001) than patients with low-risk scores. The prognostic accuracy of mRNAs signature was validated in the two independent validation cohorts (GSE21653, nÂ =Â 248; GSE31448, nÂ =Â 246). We then developed a nomogram based on the mRNAs signature and clinical-related risk factors (T stage and N stage) that predicted an individual's risk of disease, which can be assessed by calibration curves. Our study demonstrated that this 4-mRNA signature might be a reliable and useful prognostic tool for DFS evaluation and will facilitate tailored therapy for BC patients at different risk of disease.",2019,Journal of Cellular and Molecular Medicine
Autoimmune myelitis in a CLL patient undergoing treatment with ibrutinib,"Dear Editor, A 46-year-old male patient was diagnosed with chronic lymphocytic leukaemia (CLL) (IGHV mutated, normal karyotype, CD38+, ZAP70+, TP53 status not assessed) 14 years ago. Previous therapies consisted of R-CHOP (rituximab, cyclophosphamide, doxorubicin, vincristine, and prednisolone), FCR (fludarabine, cyclophosphamide, and rituximab), and rituximab plus bendamustine. However, 2 months after a thirdline therapy, he required further treatment due to bulky lymphadenopathy, pronounced constitutional symptoms, and lymphocyte doubling time < 3 months (absolute lymphocyte count of 79,6 G/l, platelets 103 G/l, haemoglobin 135 g/l). Cytogenetics revealed a normal karyotype. Ibrutinib 420 mg/ daywas started andwell tolerated resulting in an immediate and complete resolution of B-symptoms and > 70% regression of lymphadenopathy. However, after 1 month, he was referred to our hospital due to paraesthesiaâ€™s starting in the left foot and spreading within hours to the right leg, the pelvic floor, and the genital area, accompanied by bladder dysfunction. Cerebrospinal fluid (cytology, cell count, chemistry, isoelectric focusing, PCR tests for adenovirus, HSV1/2, VZV, CMV, EBV, HHV6, and toxoplasmosis) and serological analyses (including Treponema pallidum, Borrelia burgdorferi, HIV) were normal. Of note, his past medical history was negative for any neurological or autoimmune disease, and thorough neurological and medical assessment revealed no further symptoms. MRI showed signal enhancements of the spinal cord at the thoracolumbar transition and at height TH7 (Fig. 1); cerebral MRI was normal. Based on these findings and the clinical presentation with absence of any signs of infectious disease, a diagnosis of autoimmune myelitis was rendered. Treatment with methylprednisolone 1 g OD over 5 days was administered leading to a prompt but slow neurological improvement while ibrutinib was continued. After 2 months, the bladder dysfunction had completely disappeared but paraesthesias persisted, although to a lesser extent. After 10 months, most neurological symptoms have disappeared with only a slight hypaesthesia of the pelvic floor remaining. Ibrutinib was given for a total of over 2 years, and no further myelitis or other autoimmune symptoms were noted. To the best of our knowledge, this is the first report of an autoimmune myelitis occurring during treatment with ibrutinib. Ibrutinib has been shown to ameliorate CLLassociated autoimmune phenomena but may in turn trigger other inflammatory processes [1, 2]. Besides the inhibition of Brutonâ€™s tyrosine kinase (Btk), ibrutinib also inhibits interleukine-2-inducible T cell kinase (ITK) leading to a Th1 shift due to a decrease in downstream activation of Th2 cells. This imbalance leads to a decrement of potentially autoreactive Th2 cells but also to a pro-inflammatory response of Th1 cells [3, 4]. Th1-mediated immune responses are mainly driven by INF-Î³, TNF-Î±, and IL-2 and associated with various autoimmune disorders including multiple sclerosis and transverse myelitis [5]. Indeed, ibrutinib has been shown to induce such autoimmune phenomena, particular within the first months of treatment (e.g., skin lesions). They seem to be steroid-responsive or even only transient in nature [6, 7]. Although cases of autoimmune phenomena triggered by ibrutinib have been described, and the abovementioned influences of ibrutinib illustrate its impact on autoimmune responses, it has to be admitted that the myelitis possible developed in parallel but not because of ibrutinib treatment. In conclusion, we describe the occurrence and successful treatment of autoimmune myelitis in a CLL patient shortly * David Wanner David.Wanner@tirol-kliniken.at",2018,Annals of Hematology
Efficient Smoothed Concomitant Lasso Estimation for High Dimensional Regression,"In high dimensional settings, sparse structures are crucial for efficiency, both in term of memory, computation and performance. It is customary to consider 1 penalty to enforce spar-sity in such scenarios. Sparsity enforcing methods, the Lasso being a canonical example, are popular candidates to address high dimension. For efficiency, they rely on tuning a parameter trading data fitting versus sparsity. For the Lasso theory to hold this tuning parameter should be proportional to the noise level, yet the latter is often unknown in practice. A possible remedy is to jointly optimize over the regression parameter as well as over the noise level. This has been considered under several names in the literature: Scaled-Lasso, Square-root Lasso, Concomitant Lasso estimation for instance, and could be of interest for confidence sets or uncertainty quantification. In this work, after illustrating numerical difficulties for the Smoothed Concomitant Lasso formulation, we propose a modification we coined Smoothed Concomitant Lasso, aimed at increasing numerical stability. We propose an efficient and accurate solver leading to a computational cost no more expansive than the one for the Lasso. We leverage on standard ingredients behind the success of fast Lasso solvers: a coordinate descent algorithm, combined with safe screening rules to achieve speed efficiency, by eliminating early irrelevant features.",2016,ArXiv
"Four pairs of geneâ€“gene interactions associated with increased risk for type 2 diabetes (CDKN2BASâ€“KCNJ11), obesity (SLC2A9â€“IGF2BP2, FTOâ€“APOA5), and hypertension (MC4Râ€“IGF2BP2) in Chinese women","Metabolic disorders including type 2 diabetes, obesity and hypertension have growing prevalence globally every year. Genome-wide association studies have successfully identified many genetic markers associated to these diseases, but few studied their interaction effects. In this study, twenty candidate SNPs from sixteen genes are selected, and a lasso-multiple regression approach is implemented to consider the SNP-SNP interactions among them in an Asian population. It is found out that the main effects of the markers are weak but the interactions among the candidates showed a significant association to diseases. SNPs from genes CDKN2BAS and KCNJ11 are significantly associated to risk for developing diabetes, and SNPs from FTO and APOA5 might interact to play an important role for the onset of hypertension.",2014,Meta Gene
Estimating the trend in US real GDP using the â„“1 trend filtering,"ABSTRACTUsing non-Gaussian state-space models, Perron and Wada (2009, Journal of Monetary Economics, 56, 749â€“765) obtained a nearly piecewise linear trend estimate of US real gross domestic product such that its slope changed around 1973. Such a trend may be regarded as a result of occasional permanent shocks to the growth rate. This article shows that the trend filtering, which is quite similar to the Hodrickâ€“Prescott filtering and is a type of the recently popular lasso regression, yields almost the same trend estimate, and discusses the reason why this occurs.",2017,Applied Economics Letters
Predictive Modeling in Race Walking,This paper presents the use of linear and nonlinear multivariable models as tools to support training process of race walkers. These models are calculated using data collected from race walkers' training events and they are used to predict the result over a 3â€‰km race based on training loads. The material consists of 122 training plans for 21 athletes. In order to choose the best model leave-one-out cross-validation method is used. The main contribution of the paper is to propose the nonlinear modifications for linear models in order to achieve smaller prediction error. It is shown that the best model is a modified LASSO regression with quadratic terms in the nonlinear part. This model has the smallest prediction error and simplified structure by eliminating some of the predictors.,2015,Computational Intelligence and Neuroscience
LARS-type algorithm for group lasso,"The least absolute shrinkage and selection operator (lasso) has been widely used in regression analysis. Based on the piecewise linear property of the solution path, least angle regression provides an efficient algorithm for computing the solution paths of lasso. Group lasso is an important generalization of lasso that can be applied to regression with grouped variables. However, the solution path of group lasso is not piecewise linear and hence cannot be obtained by least angle regression. By transforming the problem into a system of differential equations, we develop an algorithm for efficient computation of group lasso solution paths. Simulation studies are conducted for comparing the proposed algorithm to the best existing algorithm: the groupwise-majorization-descent algorithm.",2017,Statistics and Computing
Estimation of Sparse Functional Additive Models with Adaptive Group LASSO,"We study a flexible model to address the lack of fit in conventional functional linear regression models. This model, called the sparse functional additive model, is used to characterize the relationship between a functional predictor and a scalar response of interest. The effect of the functional predictor is represented in a nonparametric additive form, where the arguments are the scaled functional principal component scores. Component selection and smoothing are considered when fitting the model in order to reduce the variability and enhance the prediction accuracy, while providing an adequate fit. To achieve these goals, we propose using the adaptive group LASSO method to select relevant components and smoothing splines and, thus, obtain a smoother estimate of those relevant components. Simulation studies show that the proposed estimation method compares favorably with conventional methods in terms of prediction accuracy and component selection. Furthermore, the advantages of our estimation method are demonstrated using two real-data examples.",2020,Statistica Sinica
Sparse Group Selection Through Co-Adaptive Penalties,"Recent work has focused on the problem of conducting linear regression when the number of covariates is very large, potentially greater than the sample size. To facilitate this, one useful tool is to assume that the model can be well approximated by a fit involving only a small number of covariates -- a so called sparsity assumption, which leads to the Lasso and other methods. In many situations, however, the covariates can be considered to be structured, in that the selection of some variables favours the selection of others -- with variables organised into groups entering or leaving the model simultaneously as a special case. This structure creates a different form of sparsity. In this paper, we suggest the Co-adaptive Lasso to fit models accommodating this form of `group sparsity'. The Co-adaptive Lasso is fast and simple to calculate, and we show that it holds theoretical advantages over the Lasso, performs well under a broad set of conclusions, and is very competitive in empirical simulations in comparison with previously suggested algorithms like the Group Lasso and the Adaptive Lasso.",2011,arXiv: Methodology
Imputation of missing data via penalization techniques,"The aim of this master thesis is to give the user an estimate of uncertainty over missing data imputation. The full factorization approach is compared to the state-of-the-art approach of full conditional. The special feature in both algorithms is the penalization techniques. Both algorithms are used with different types of missing data like MAR, MCAR and NMAR. Simulated datasets were conducted with copulas. Simulations were varied in rate of missing observations, refitting times and the use, or not, of LASSO regression for last fit. Results are given in terms of accuracy of predicted values, pooled variance estimates and errors which occurred during programming and runtime. The full factorization approach showed advantages over full conditional especially if one looks on ratios of 10:1 observations to covariables. In cases were covariables were in higher numbers than observations, full conditional and full factorization nearly covered same results when ridge regression was used for all fits. Generally lasso regression did not improve accuracy of imputation results. This result can be generalized for all missing types used and simulations conducted in this master thesis. Imputed observations showed paths which are similar to MCMC bayesian statistics. The imputation steps alternated and converged to certain values. Results were stable when different datasets and seeds for random numbers were processed. Run time for both approaches was high due to errors that occurred in different R packages and functions which are costly in terms of CPU usage.",2015,
Selection of Eye-Tracking Stimuli for Prediction by Sparsely Grouped Input Variables for Neural Networks: towards Biomarker Refinement for Autism,"Eye tracking has become a powerful tool in the study of autism spectrum disorder (ASD). Current, large-scale efforts aim to identify specific eye-tracking stimuli to be used as biomarkers for ASD, with the intention of informing the diagnostic process, monitoring therapeutic response, predicting outcomes, or identifying subgroups with the spectrum. However, there are hundreds of candidate experimental paradigms, each of which contains dozens or even hundreds of individual stimuli. Each stimuli is associated with an array of potential derived outcome variables, thus the number of variables to consider can be enormous. Standard variable selection techniques are not applicable to this problem, because selection must be done at the level of stimuli and not individual variables. In other words, this is a grouped variable selection problem. In this work, we apply lasso, group lasso, and a new technique, Sparsely Grouped Input Variables for Neural Network (SGIN), to select experimental stimuli for group discrimination and regression with clinical variables. Using a dataset obtained from children with and without ASD who were administered a battery containing 109 different stimuli presentations involving 9647 features, we are able to retain strong group separation even with only 11 out of the 109 stimuli. This work sets the stage for concerted techniques designed around engines to iteratively refine and define next-generation biomarkers using eye tracking for psychiatric conditions. http://github.com/beibinli/SGIN",2020,Symposium on Eye Tracking Research and Applications
Large-Scale Dynamic Predictive Regressions,"We develop a novel ""decouple-recouple"" dynamic predictive strategy and contribute to the literature on forecasting and economic decision making in a data-rich environment. Under this framework, clusters of predictors generate different latent states in the form of predictive densities that are later synthesized within an implied time-varying latent factor model. As a result, the latent inter-dependencies across predictive densities and biases are sequentially learned and corrected. Unlike sparse modeling and variable selection procedures, we do not assume a priori that there is a given subset of active predictors, which characterize the predictive density of a quantity of interest. We test our procedure by investigating the predictive content of a large set of financial ratios and macroeconomic variables on both the equity premium across different industries and the inflation rate in the U.S., two contexts of topical interest in finance and macroeconomics. We find that our predictive synthesis framework generates both statistically and economically significant out-of-sample benefits while maintaining interpretability of the forecasting variables. In addition, the main empirical results highlight that our proposed framework outperforms both LASSO-type shrinkage regressions, factor based dimension reduction, sequential variable selection, and equal-weighted linear pooling methodologies.",2018,arXiv: Methodology
"Hospital-Based Back Surgery: Geospatial-Temporal, Explanatory, and Predictive Models","BACKGROUND
Hospital-based back surgery in the United States increased by 60% from January 2012 to December 2017, yet the supply of neurosurgeons remained relatively constant. During this time, adult obesity grew by 5%.


OBJECTIVE
This study aimed to evaluate the demand and associated costs for hospital-based back surgery by geolocation over time to evaluate provider practice variation. The study then leveraged hierarchical time series to generate tight demand forecasts on an unobserved test set. Finally, explanatory financial, technical, workload, geographical, and temporal factors as well as state-level obesity rates were investigated as predictors for the demand for hospital-based back surgery.


METHODS
Hospital data from January 2012 to December 2017 were used to generate geospatial-temporal maps and a video of the Current Procedural Terminology codes beginning with the digit 63 claims. Hierarchical time series modeling provided forecasts for each state, the census regions, and the nation for an unobserved test set and then again for the out-years of 2018 and 2019. Stepwise regression, lasso regression, ridge regression, elastic net, and gradient-boosted random forests were built on a training set and evaluated on a test set to evaluate variables important to explaining the demand for hospital-based back surgery.


RESULTS
Widespread, unexplained practice variation over time was seen using geographical information systems (GIS) multimedia mapping. Hierarchical time series provided accurate forecasts on a blind dataset and suggested a 6.52% (from 497,325 procedures in 2017 to 529,777 in 2018) growth of hospital-based back surgery in 2018 (529,777 and up to 13.00% by 2019 [from 497,325 procedures in 2017 to 563,023 procedures in 2019]). The increase in payments by 2019 are estimated to be US $323.9 million. Extreme gradient-boosted random forests beat constrained and unconstrained regression models on a 20% unobserved test set and suggested that obesity is one of the most important factors in explaining the increase in demand for hospital-based back surgery.


CONCLUSIONS
Practice variation and obesity are factors to consider when estimating demand for hospital-based back surgery. Federal, state, and local planners should evaluate demand-side and supply-side interventions for this emerging problem.",2019,Journal of Medical Internet Research
Novel Hybrid Method for Gene Selection and Cancer Prediction,"Microarray data profiles gene expression on a whole genome scale, therefore, it provides a good way to study associations between gene expression and occurrence or progression of cancer. More and more researchers realized that microarray data is helpful to predict cancer sample. However, the high dimension of gene expressions is much larger than the sample size, which makes this task very difficult. Therefore, how to identify the significant genes causing cancer becomes emergency and also a hot and hard research topic. Many feature selection algorithms have been proposed in the past focusing on improving cancer predictive accuracy at the expense of ignoring the correlations between the features. In this work, a novel framework (named by SGS) is presented for stable gene selection and efficient cancer prediction . The proposed framework first performs clustering algorithm to find the gene groups where genes in each group have higher correlation coefficient, and then selects the significant genes in each group with Bayesian Lasso and important gene groups with group Lasso, and finally builds prediction model based on the shrinkage gene space with efficient classification algorithm (such as, SVM, 1NN, Regression and etc.). Experiment results on real world data show that the proposed framework often outperforms the existing feature selection and prediction methods, say SAM, IG and Lasso-type prediction model. Keywordsâ€”Gene Selection, Cancer Prediction, Lasso, Clustering, Classification.",2010,"World Academy of Science, Engineering and Technology, International Journal of Computer, Electrical, Automation, Control and Information Engineering"
Using Machine Learning to Construct Nomograms for Patients with Metastatic Colon Cancer.,"AIM
Patients with synchronous colon cancer metastases have highly variable overall survival (OS), making accurate predictive models challenging to build. We aim to use machine learning to more accurately predict OS in these patients and to present this predictive model in the form of nomograms for patients and clinicians.


METHODS
Using the National Cancer Database (2010-2014), we identified right colon (RC) and left colon (LC) cancer patients with synchronous metastases. Each primary site was split into training and testing datasets. Nomograms predicting 3-year overall survival were created for each site using Cox proportional hazard regression with lasso regression. Each model was evaluated by both calibration (comparison of predicted versus observed overall survival) and validation (degree of concordance as measured by c-index) methodologies.


RESULTS
A total of 11,018 RC and 8,346 LC patients were used to construct and validate the nomograms. After stratifying each model into 5 risk groups, the predicted OS was within the 95% CI of the observed OS in 4 out of 5 risk groups for both the RC and LC models. Externally validated c-indexes at 3 years for RC and LC models were 0.794 and 0.761, respectively.


CONCLUSIONS
Utilization of machine learning can result in more accurate predictive models for patients with metastatic colon cancer. Nomograms built from these models can assist clinicians and patients in the shared decision-making process of their cancer care.",2020,Colorectal disease : the official journal of the Association of Coloproctology of Great Britain and Ireland
"Chemometric technique performances in predicting forest soil chemical and biological properties from UV-Vis-NIR reflectance spectra with small, high dimensional datasets","Abstract: Chemometric analysis applied to diffuse reflectance spectroscopy is increasingly proposed as an effective and accurate methodology to predict soil physical, chemical and biological properties. Its effectiveness, however, largely varies in relation to the calibration techniques and the specific soil properties. In addition, the calibration of UV-Vis-NIR spectra usually requires large datasets, and the identification of techniques suitable to deal with small sample sizes and high dimensionality problems is a primary challenge. In order to investigate the predictability of many soil chemical and biological properties from a small dataset and to identify the most suitable techniques to deal with this type of problems, we analysed 20 top soil samples of three different forests (Fagus sylvatica, Quercus cerris and Quercus ilex) in southern Apennines (Italy). Diffuse reflectance spectra were recorded in the UV-Vis-NIR range (200-2500 nm) and 22 chemical and biological properties were analysed. Three different calibration techniques were tested, namely the Partial Least Square Regression (PLSR), the combinations wavelet transformation/Elastic net and wavelet transformation/Supervised Principal Component (SPC) regression/ Least Absolute Shrinkage and Selection Operator (LASSO), a kind of preconditioned LASSO. Calibration techniques were applied to both raw spectra and spectra subjected to wavelet shrinkage filtering, in order to evaluate the influence on predictions of spectra denoising. Overall, SPC/LASSO outperformed the other techniques with both raw and denoised spectra. Elastic net produced heterogeneous results, but outperformed SPC/LASSO for total organic carbon, whereas PLSR produced the worst results. Spectra denoising improved the prediction accuracy of many parameters, but worsen the predictions in some cases. Our approach highlighted that: (i) SPC/LASSO (and Elastic net in the case of total organic carbon) is especially suitable to calibrate spectra in the case of small, high dimensional datasets; and (ii) spectra denoising could be an effective technique to improve calibration results.",2016,Iforest - Biogeosciences and Forestry
Assessment of Weighted Quantile Sum Regression for Modeling Chemical Mixtures and Cancer Risk,"In evaluation of cancer risk related to environmental chemical exposures, the effect of many chemicals on disease is ultimately of interest. However, because of potentially strong correlations among chemicals that occur together, traditional regression methods suffer from collinearity effects, including regression coefficient sign reversal and variance inflation. In addition, penalized regression methods designed to remediate collinearity may have limitations in selecting the truly bad actors among many correlated components. The recently proposed method of weighted quantile sum (WQS) regression attempts to overcome these problems by estimating a body burden index, which identifies important chemicals in a mixture of correlated environmental chemicals. Our focus was on assessing through simulation studies the accuracy of WQS regression in detecting subsets of chemicals associated with health outcomes (binary and continuous) in site-specific analyses and in non-site-specific analyses. We also evaluated the performance of the penalized regression methods of lasso, adaptive lasso, and elastic net in correctly classifying chemicals as bad actors or unrelated to the outcome. We based the simulation study on data from the National Cancer Institute Surveillance Epidemiology and End Results Program (NCI-SEER) case-control study of non-Hodgkin lymphoma (NHL) to achieve realistic exposure situations. Our results showed that WQS regression had good sensitivity and specificity across a variety of conditions considered in this study. The shrinkage methods had a tendency to incorrectly identify a large number of components, especially in the case of strong association with the outcome.",2015,Cancer Informatics
The generalization performance of kernelized elastic net regularization based on exponentially strongly mixing observations,"The study of kernelized elastic net regularization (KENReg) is a promising topic in machine learning community. Different from the elastic net regularizer in Zou and Hastie [1] which focuses on selecting group and correlated features, KENReg aims at obtaining a sparse and stable approximation to the regression function. In terms of generalization, sparseness and stability, KENReg performs better than kernelized Lasso, we are concerned about the generalization performance of KENReg in this paper. For the purpose of this paper is to study the generalization ability of KENReg for the dependent samples, and the dependent samples we choose are exponentially strongly mixing sequence. So as to study the generalization ability of KENReg for exponentially strongly mixing samples, we first use the stepping-stone technique proposed in Wu and Zhou [2], then we shown the generalization bounds of KENReg based on exponentially strongly mixing samples, and finally we make the results more accurate with uniformly ergodic Markov chains (u.e.M.c.) samples.",2017,"2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)"
Distributed Lasso for in-network linear regression,"The least-absolute shrinkage and selection operator (Lasso) is a popular tool for joint estimation and continuous variable selection, especially well-suited for the under-determined but sparse linear regression problems. This paper develops an algorithm to estimate the regression coefficients via Lasso when the training data is distributed across different agents, and their communication to a central processing unit is prohibited for e.g., communication cost or privacy reasons. The novel distributed algorithm is obtained after reformulating the Lasso into a separable form, which is iteratively minimized using the alternating-direction method of multipliers so as to gain the desired degree of parallelization. The per agent estimate updates are given by simple soft-thresholding operations, and inter-agent communication overhead remains at affordable level. Without exchanging elements from the different training sets, the local estimates provably consent to the global Lasso solution, i.e., the fit that would be obtained if the entire data set were centrally available. Numerical experiments corroborate the convergence and global optimality of the proposed distributed scheme.",2010,"2010 IEEE International Conference on Acoustics, Speech and Signal Processing"
High dimensional QSAR study of mild steel corrosion inhibition in acidic medium by furan derivatives,"The inhibition of mild steel corrosion in 1 M HCl by 17 furan derivatives was investigated experimentally using potentiodynamic polarization measurements. The furan derivatives inhibit the mild steel corrosion. The experimental inhibition efficiency (IE) was used in a Quantitative Structure-Activity Relationship (QSAR) study. Dragon software was used to calculate the molecular descriptors. Penalized multiple linear regression (PMLR) was applied as a variable selection method using three penalties namely, ridge, LASSO, and elastic net. A number of 8 and 38 significant molecular descriptors were selected by LASSO and elastic net methods, respectively. The most significant descriptors namely, PJI3, P_VSA_s_4, Mor16u, MATS3p, and PDI were selected by both LASSO and elastic net methods. The elastic net results show low mean-squared error of the training set (MSEtrain) of 0.0004 and test set (MSEtest) of 5.332. The results confirm that the penalized multiple linear regression based on elastic net penalty is the most effective method to deal with high dimensional data",2015,International Journal of Electrochemical Science
Flu Detector - Tracking Epidemics on Twitter,"We present an automated tool with a web interface for tracking the prevalence of Influenza-like Illness (ILI) in several regions of the United Kingdom using the contents of Twitter's microblogging service. Our data is comprised by a daily average of approximately 200,000 geolocated tweets collected by targeting 49 urban centres in the UK for a time period of 40 weeks. Official ILI rates from the Health Protection Agency (HPA) form our ground truth. Bolasso, the bootstrapped version of LASSO, is applied in order to extract a consistent set of features, which are then used for learning a regression model.",2010,
Presenting logistic regression-based landslide susceptibility results,"Abstract A new work-flow is proposed to unify the way the community shares Logistic Regression results for landslide susceptibility purposes. Although Logistic Regression models and methods have been widely used in geomorphology for several decades, no standards for presenting results in a consistent way have been adopted; most papers report parameters with different units and interpretations, therefore limiting potential meta-analytic applications. We first summarize the major differences in the geomorphological literature and then investigate each one proposing current best practices and few methodological developments. The latter is mainly represented by a widely used approach in statistics for simultaneous parameter estimation and variable selection in generalized linear models, namely the Least Absolute Shrinkage Selection Operator (LASSO). The North-easternmost sector of Sicily (Italy) is chosen as a straightforward example with well exposed debris flows induced by extreme rainfall.",2018,Engineering Geology
Metabolome-based discrimination of chrysanthemum cultivars for the efficient generation of flower color variations in mutation breeding,"The color variations of ornamental flowers are often generated by ion-beam and gamma irradiation mutagenesis. However, mutation rates differ significantly even among cultivars of the same species, resulting in high cost and intensive labor for flower color breeding. We aimed to establish a metabolome-based strategy to identify biomarkers and select promising parental lines with high mutation rates using Chrysanthemum as the case study. The mutation rates associated with flower color were measured in 10 chrysanthemum cultivars with pink, yellow, or white flowers after soft X-ray irradiation at the floret-formation stage. The metabolic profiles of the petals of these cultivars were clarified by widely targeted metabolomics and targeted carotenoid analysis using liquid chromatography-tandem quadrupole mass spectrometry. Metabolome and carotenoid data were subjected to an un-supervised principal component analysis (PCA) and a supervised logistic regression with least absolute shrinkage and selection operator (LASSO). The PCA of the metabolic profile data separated chrysanthemum cultivars according to flower color rather than mutation rates. By contrast, logistic regression with LASSO generated a discrimination model to separate cultivars into two groups with high or low mutation rates, and selected 11 metabolites associated with mutation rates that can be biomarkers candidates for selecting parental lines for mutagenesis. This metabolome-based strategy to identify metabolite markers for mutation rates associated with flower color might be applied to other ornamental flowers to accelerate mutation breeding for generating new cultivars with a wider range of flower colors.",2019,Metabolomics
Robust learning of discriminative projection for multicategory classification on the Stiefel manifold,"Learning a robust projection with a small number of training samples is still a challenging problem in face recognition, especially when the unseen faces have extreme variation in pose, illumination, and facial expression. To address this problem, we propose a framework formulated under statistical learning theory that facilitates robust learning of a discriminative projection. Dimensionality reduction using the projection matrix is combined with a linear classifier in the regularized framework of lasso regression. The projection matrix in conjunction with the classifier parameters are then found by solving an optimization problem over the Stiefel manifold. The experimental results on standard face databases suggest that the proposed method outperforms some recent regularized techniques when the number of training samples is small.",2008,2008 IEEE Conference on Computer Vision and Pattern Recognition
Learning â„“1-penalized logistic regressions with smooth approximation,"The paper presents comparison of learning logistic regression model with different penalty terms. Main part of the paper concerns sparse regression, which includes absolute value function. This function is not strictly convex, thus common optimizers cannot be used directly. In the paper we show that in those cases smooth approximation of absolute value function can be effectively used either in the case of lasso regression or in fussed-lasso like case. One of examples focuses on two dimensional analogue of fussed-lasso model. The experimental results present the comparison of our implementations (in C++ and Python) on three benchmark datasets.",2017,2017 IEEE International Conference on INnovations in Intelligent SysTems and Applications (INISTA)
Employing Quantitative Systems Pharmacology to Characterize Differences in Igf1 and Insulin Signaling Pathways in Breast Cancer,"Insulin and insulin-like growth factor I (IGF1) have been shown to influence cancer risk and progression through poorly understood mechanisms. Here, new insights on the mechanisms of differential MAPK and Akt activation are revealed by an iterative quantitative systems pharmacology approach. In the first iteration, I combined proteomic screening with computational network inference to uncover differences in IGF1 and insulin induced signaling. Using reverse phase protein array of 21 breast cancer cell lines treated with a time course of IGF1 and insulin, I constructed directed protein expression networks using three separate methods: (i) lasso regression, (ii) conventional matrix inversion, and (iii) entropy maximization. These networks, named here as the time translation models, were analyzed and the inferred interactions were ranked by differential magnitude to identify pathway differences. The two top candidates, chosen for experimental validation, were shown to regulate IGF1/insulin induced phosphorylation events. Both of the knock-down perturbations caused phosphorylation responses stronger in IGF1 stimulated cells compared with insulin. Overall, the time-translation modeling coupled to wet-lab experiments has proven to be powerful in inferring differential interactions downstream of IGF1 and insulin signaling, in vitro. In the second iteration, mechanistic representation of IGF1 and insulin dual signaling cascades by a set of ODEs is generated by rule-based modeling. The mechanistic network modeling provided a framework to elucidate experimental targets downstream of two receptors, which were treated as indistinguishable in previous models. The model included cascades of both mitogen-activated protein kinase (MAPK) and Akt signaling, as well as the crosstalk and feedback loops in between. The parameter perturbation scanning employed for seven different models of seven cell lines yielded new experimental hypotheses on how differential responses of MAPK and Akt originate. Complementary to the first iteration, the results in this part suggested that regulation of insulin receptor substrate 1 (IRS1) is critical in inducing differential MAPK or Akt activation. Compensation and activating feedback mechanisms collectively depressed the efficacy of anti-IGF1R/InsR therapies. With the quantitative systems pharmacologic approach, the networks of signal transduction constructed in this thesis are aimed to discern novel downstream components of the IGF1R/InsR system, and to direct patients with suitable tumor subclasses to efficient personalized clinical interventions.",2018,
Learning Feature Nonlinearities with Regularized Binned Regression,"For various applications, the relations between the dependent and independent variables are highly nonlinear. Consequently, for large scale complex problems, neural networks and regression trees are commonly preferred over linear models such as Lasso. This work proposes learning the feature nonlinearities by binning feature values and finding the best fit in each quantile using non-convex regularized linear regression. The algorithm first captures the dependence between neighboring quantiles by enforcing smoothness via piecewise-constant/linear approximation and then selects a sparse subset of good features. We prove that the proposed algorithm is statistically and computationally efficient. In particular, it achieves linear rate of convergence while requiring near-minimal number of samples. Evaluations on real datasets demonstrate that algorithm is competitive with current state-of-the-art and accurately learns feature nonlinearities.",2019,2019 IEEE International Symposium on Information Theory (ISIT)
