title,abstract,year,journal
Inferring species interaction networks from species abundance data: A comparative evaluation of various statistical and machine learning methods,"Abstract The complexity of ecosystems is staggering, with hundreds or thousands of species interacting in a number of ways from competition and predation to facilitation and mutualism. Understanding the networks that form the systems is of growing importance, e.g. to understand how species will respond to climate change, or to predict potential knock-on effects of a biological control agent. In recent years, a variety of summary statistics for characterising the global and local properties of such networks have been derived, which provide a measure for gauging the accuracy of a mathematical model for network formation processes. However, the critical underlying assumption is that the true network is known. This is not a straightforward task to accomplish, and typically requires minute observations and detailed field work. More importantly, knowledge about species interactions is restricted to specific kinds of interactions. For instance, while the interactions between pollinators and their host plants are amenable to direct observation, other types of species interactions, like those mentioned above, are not, and might not even be clearly defined from the outset. To discover information about complex ecological systems efficiently, new tools for inferring the structure of networks from field data are needed. In the present study, we investigate the viability of various statistical and machine learning methods recently applied in molecular systems biology: graphical Gaussian models, L1-regularised regression with least absolute shrinkage and selection operator (LASSO), sparse Bayesian regression and Bayesian networks. We have assessed the performance of these methods on data simulated from food webs of known structure, where we combined a niche model with a stochastic population model in a 2-dimensional lattice. We assessed the network reconstruction accuracy in terms of the area under the receiver operating characteristic (ROC) curve, which was typically in the range between 0.75 and 0.9, corresponding to the recovery of about 60% of the true species interactions at a false prediction rate of 5%. We also applied the models to presence/absence data for 39 European warblers, and found that the inferred species interactions showed a weak yet significant correlation with phylogenetic similarity scores, which tended to weakly increase when including bio-climate covariates and allowing for spatial autocorrelation. Our findings demonstrate that relevant patterns in ecological networks can be identified from large-scale spatial data sets with machine learning methods, and that these methods have the potential to contribute novel important tools for gaining deeper insight into the structure and stability of ecosystems.",2010,Ecol. Informatics
Consistently accurate forecasts of temperature within buildings from sensor data using ridge and lasso regression,"Abstract A significant portion of all energy generated is used to heat and cool buildings. Some of that energy can be saved by using a temperature controller with access to an accurate forecast of a buildingâ€™s internal temperature. These forecasts depend on information gathered from sensors, including temperature, humidity, sunlight, and the electrical load of cooking and laundry appliances. Using publicly available data from two homes with a wide variety of sensors, we forecast internal temperature by modelling it as a linear function of recent sensor values. These models are built using techniques that improve upon standard least squares regression: forward stepwise, ridge and lasso regressions, using cross-validation. With lasso regression, we accurately forecast internal temperature every quarter hour over the next 48Â h within 1 . 8 Â° C in both houses. We also forecast temperature changes over each quarter-hour for the next two days, within 0 . 05 Â° C , which significantly improves on previous forecasts of temperature changes using the same data. We propose a business model for forecasting as a service, where guarantees of consistent accuracy are important for attracting clients and saving energy.",2018,Future Generation Computer Systems
Prediction of radiotherapy response with a 5â€microRNA signatureâ€based nomogram in head and neck squamous cell carcinoma,"Radiotherapy is unlikely to benefit all patients with head and neck squamous cell carcinoma (HNSCC). Therefore, novel method is warranted to predict the radiotherapy response. Our study aimed to construct a microRNA (miRNA)-based nomogram to predict clinical outcomes of patients with HNSCC receiving radiotherapy. We screened out 56 differential miRNAs by analyzing 44 paired tumor and adjacent normal samples miRNA expression profiles from The Cancer Genome Atlas (TCGA). A total of 307 patients with HNSCC receiving adjuvant radiotherapy were randomly divided into a training set (nÂ =Â 154) and a validation set (nÂ =Â 153). In the training set, we combined the differential miRNA profiles with clinical outcomes, and LASSO regression model was applied to establish a 5-miRNA signature. The prediction accuracy of the 5-miRNA signature was further validated. In addition, target genes of these miRNAs were predicted, and Gene Ontology (GO) analysis as well as KEGG pathway analysis was executed. A 5-miRNA signature including miR-99a, miR-31, miR-410, miR-424, and miR-495 was identified. With a cutoff value of 1.2201 from Youden's index, the training set was divided into high-risk and low-risk groups, and the 5-year overall survival was significantly different (30% vs. 73%, HR 3.65, CI 2.46-8.16; PÂ <Â 0.0001). Furthermore, our 5-miRNA signature revealed that only low-risk group would benefit from radiotherapy. Then, a nomogram combining 5-miRNA signature with clinical variables to predict radiotherapy response was constructed. The analysis of 108 target genes of these miRNAs revealed some potential mechanisms in HNSCC radiotherapy response for future investigations. In conclusion, the 5-miRNA signature-based nomogram is useful in predicting radiotherapy response in HNSCC and might become a promising tool to optimize radiation strategies.",2018,Cancer Medicine
Fast global convergence rates of gradient methods for high-dimensional statistical recovery,"Many statistical M-estimators are based on convex optimization problems formed by the weighted sum of a loss function with a norm-based regularizes We analyze the convergence rates of first-order gradient methods for solving such problems within a high-dimensional framework that allows the data dimension d to grow with (and possibly exceed) the sample size n. This high-dimensional structure precludes the usual global assumptionsâ€” namely, strong convexity and smoothness conditionsâ€”that underlie classical optimization analysis. We define appropriately restricted versions of these conditions, and show that they are satisfied with high probability for various statistical models. Under these conditions, our theory guarantees that Nesterov's first-order method [12] has a globally geometric rate of convergence up to the statistical precision of the model, meaning the typical Euclidean distance between the true unknown parameter Î¸* and the optimal solution ^Î¸. This globally linear rate is substantially faster than previous analyses of global convergence for specific methods that yielded only sublinear rates. Our analysis applies to a wide range of M-estimators and statistical models, including sparse linear regression using Lasso (l1-regularized regression), group Lasso, block sparsity, and low-rank matrix recovery using nuclear norm regularization. Overall, this result reveals an interesting connection between statistical precision and computational efficiency in high-dimensional estimation.",2010,
Approches pÃ©nalisÃ©es et autres dÃ©veloppements statistiques pour l'Ã©pidÃ©miologie,"Mes travaux portent principalement sur des developpements statistiques theoriques, methodologiques ou appliques, en lien avec des problematiques rencontrees en epidemiologie et en recherche biomedicale. Les questions soulevees dans ces domaines d'application s'interpretent souvent comme un probleme de selection de variables. Celui-ci est des plus classiques en statistique, et des approches derivees de criteres penalises sont connues pour le resoudre sous certaines hypotheses. Sous des modeles parametriques, ces approches encouragent des structures particulieres dans le vecteur des parametres telles que la parcimonie ou l'egalite de certaines composantes, etc. Une part importante de mes recherches porte sur des resultats generaux pour les approches penalisees par la norme L1 des parametres ou des derivees de cette norme. Nous avons notamment developpe une methode de preselection qui permet l'elimination a priori de covariables dans les problemes de type lasso. L'objectif des methodes de preselection est de travailler avec des matrices de taille plus faible afin d'accelerer la resolution numerique du lasso, ou de pouvoir tout simplement le resoudre dans les cas ou la matrice originale est trop grande. Notre approche etait la premiere a beneficier de la propriete suivante : les covariables eliminees n'auraient de toute facon pas figure dans le support de la solution du lasso et notre approche ne modifie donc pas cette solution. Je me suis par ailleurs interesse aux proprietes asymptotiques des estimateurs derives du fused lasso generalise dans les modeles lineaires generalises. Le fused lasso generalise est particulierement adapte lorsque les covariables d'un modele de regression sont naturellement organisees en reseau (proteines, genes, etc.), et s'il est raisonnable d'attendre de covariables connectees dans le reseau qu'elles partagent des effets similaires sur la variable d'interet. Le fused lasso generalise repose sur un graphe qui decrit le reseau (et donc la structure attendue dans le vecteur des parametres), et nous avons etudie les proprietes des estimateurs du fused lasso generalise en fonction de l'adequation entre ce graphe et la veritable structure du vecteur des parametres du modele de regression. Par la suite, nous avons etendu le fused lasso generalise au contexte des modeles non lineaires a effets mixtes, qui sont utilises en pharmacocinetique pour modeliser les concentrations de medicament dans le sang au cours du temps, en fonction de parametres individuels inconnus (volume sanguin, taux d'absorption, etc.). Je me suis egalement interesse au contexte specifique des donnees stratifiees. Dans ce contexte, la question principale est de determiner si le niveau d'association entre deux variables est identique chez tous les individus d'une population ou si au contraire il varie a travers des sous-groupes predefinis de cette population (ou strates). Le fused lasso generalise est adapte a ce contexte, mais souffre de certaines limites. J'ai travaille au developpement d'une nouvelle approche, et etudie ses proprietes theoriques, reposant sur une penalite specialement adaptee a l'identification des heterogeneites entre les parametres de modeles de regression definis dans differentes strates. Outre les modeles de regression, je me suis interesse aux approches penalisees dans le cadre de l'estimation des modeles graphiques binaires, qui permettent l'etude des relations d'independance conditionnelle parmi un ensemble de variables binaires. Enfin, les etudes epidemiologiques soulevent le plus souvent la question de l'inference des effets causaux des facteurs de risque etudies, et je me suis dernierement interesse a l'application des principes de l'inference causale en epidemiologie du risque routier.",2016,
Influence Plots for LASSO,"With many predictors in regression, fitting the full model can induce multicollinearity problems. Least Absolute Shrinkage and Selection Operation (LASSO) is useful when the effects of many explanatory variables are sparse in a high-dimensional dataset. Influential points can have a disproportionate impact on the estimated values of model parameters. This paper describes a new influence plot that can be used to increase understanding of the contributions of individual observations and the robustness of results. This can serve as a complement to other regression diagnostics techniques in the LASSO regression setting. Using this influence plot, we can find influential points and their impact on shrinkage of model parameters and model selection. We illustrate the methods with two examples. Copyright Â© 2016 John Wiley & Sons, Ltd.",2017,Quality and Reliability Eng. Int.
"Effects of climate factors on bacillary dysentery epidemic in Harbin City, China","Bacillary dysentery is an important infectious disease caused by shigella dysenteriae. Here, we characterized the dynamic temporal trend of bacillary dysentery, and identified climate-related risk factors and their roles in bacillary dysentery transmission in Harbin city, China. A database is integrated monthly climate factors and incidence rates of Harbin city from 1986 to 1990. In this study, three consecutive months' climate data are used to predicted one month's incidence. One popular algorithm, The Least Absolute Shrinkage and Selectionator operator (lasso), a shrinkage and selection method for linear regression is applied to select related climate factors and build prediction model. Through this study, monthly accumulative precipitation, daily maximum precipitation, the daily maximum precipitation of one month before and monthly mean minimum temperature were found to result in the highest relative risk for bacillary dysentery.",2013,2013 IEEE International Conference on Bioinformatics and Biomedicine
Analysis of energy signatures and planning of heating and domestic hot water energy use in buildings in Norway,"Widespread introduction of low energy buildings (LEBs), passive houses, and zero emission buildings (ZEBs) are national target in Norway. In order to achieve better energy performance in these types of buildings and successfully integrate them in energy system, reliable planning and prediction techniques for heat energy use are required. However, the issue of energy planning in LEBs currently remains challenging for district heating companies. This article proposed an improved methodology for planning and analysis of domestic hot water and heating energy use in LEBs based on energy signature method. The methodology was tested on a passive school in Oslo, Norway. In order to divide energy signature curve on temperature dependent and independent parts, it was proposed to use piecewise regression. Each of these parts were analyzed separately. The problem of dealing with outliers and selection of the factors that had impact of energy was considered. For temperature dependent part, the different methods of modelling were compared by statistical criteria. The investigation showed that linear multiple regression model resulted in better accuracy in the prediction than SVM, PLS, and LASSO models. In order to explain temperature independent part of energy signature the hourly profiles of energy use were developed.",2019,
Computational prediction of plasma protein binding of cyclic peptides from small molecule experimental data using sparse modeling techniques,"BackgroundCyclic peptide-based drug discovery is attracting increasing interest owing to its potential to avoid target protein depletion. In drug discovery, it is important to maintain the biostability of a drug within the proper range. Plasma protein binding (PPB) is the most important index of biostability, and developing a computational method to predict PPB of drug candidate compounds contributes to the acceleration of drug discovery research. PPB prediction of small molecule drug compounds using machine learning has been conducted thus far; however, no study has investigated cyclic peptides because experimental information of cyclic peptides is scarce.ResultsFirst, we adopted sparse modeling and small molecule information to construct a PPB prediction model for cyclic peptides. As cyclic peptide data are limited, applying multidimensional nonlinear models involves concerns regarding overfitting. However, models constructed by sparse modeling can avoid overfitting, offering high generalization performance and interpretability. More than 1000 PPB data of small molecules are available, and we used them to construct a prediction models with two enumeration methods: enumerating lasso solutions (ELS) and forward beam search (FBS). The accuracies of the prediction models constructed by ELS and FBS were equal to or better than those of conventional non-linear models (MAEâ€‰=â€‰0.167â€“0.174) on cross-validation of a small molecule compound dataset. Moreover, we showed that the prediction accuracies for cyclic peptides were close to those for small molecule compounds (MAEâ€‰=â€‰0.194â€“0.288). Such high accuracy could not be obtained by a simple method of learning from cyclic peptide data directly by lasso regression (MAEâ€‰=â€‰0.286â€“0.671) or ridge regression (MAEâ€‰=â€‰0.244â€“0.354).ConclusionIn this study, we proposed a machine learning techniques that uses low-dimensional sparse modeling to predict the PPB value of cyclic peptides computationally. The low-dimensional sparse model not only exhibits excellent generalization performance but also improves interpretation of the prediction model. This can provide common an noteworthy knowledge for future cyclic peptide drug discovery studies.",2018,BMC Bioinformatics
Quantile regression in high-dimension with breaking,"The paper considers a linear regression model in high-dimension for which the predictive variables can change the influence on the response variable at unknown times (called change-points). Moreover, the particular case of the heavy-tailed errors is considered. In this case, least square method with LASSO or adaptive LASSO penalty can not be used since the theoretical assumptions do not occur or the estimators are not robust. Then, the quantile model with SCAD penalty or median regression with LASSO-type penalty allows, in the same time, to estimate the parameters on every segment and eliminate the irrelevant variables. We show that, for the two penalized estimation methods, the oracle properties is not affected by the change-point estimation. Convergence rates of the estimators for the change-points and for the regression parameters, by the two methods are found. Monte-Carlo simulations illustrate the performance of the methods.",2013,JSTA
A General Framework for Structured Sparsity via Proximal Optimization,"We study a generalized framework for structured sparsity. It extends the well known methods of Lasso and Group Lasso by incorporating additional constraints on the variables as part of a convex optimization problem. This framework provides a straightforward way of favouring prescribed sparsity patterns, such as orderings, contiguous regions and overlapping groups, among others. Available optimization methods are limited to specific constraint sets and tend to not scale well with sample size and dimensionality. We propose a first order proximal method, which builds upon results on fixed points and successive approximations. The algorithm can be applied to a general class of conic and norm constraints sets and relies on a proximity operator subproblem which can be computed numerically. Experiments on different regression problems demonstrate state-of-the-art statistical performance, which improves over Lasso, Group Lasso and StructOMP. They also demonstrate the efficiency of the optimization algorithm and its scalability with the size of the problem.",2012,
Pretreatment Prediction of Adaptive Radiation Therapy Eligibility Using MRI-Based Radiomics for Advanced Nasopharyngeal Carcinoma Patients,"Background and purpose: Adaptive radiotherapy (ART) can compensate for the dosimetric impacts induced by anatomic and geometric variations in patients with nasopharyngeal carcinoma (NPC); Yet, the need for ART can only be assessed during the radiation treatment and the implementation of ART is resource intensive. Therefore, we aimed to determine tumoral biomarkers using pre-treatment MR images for predicting ART eligibility in NPC patients prior to the start of treatment. Methods: Seventy patients with biopsy-proven NPC (Stage II-IVB) in 2015 were enrolled into this retrospective study. Pre-treatment contrast-enhanced T1-w (CET1-w), T2-w MR images were processed and filtered using Laplacian of Gaussian (LoG) filter before radiomic features extraction. A total of 479 radiomics features, including the first-order (n = 90), shape (n = 14), and texture features (n = 375), were initially extracted from Gross-Tumor-Volume of primary tumor (GTVnp) using CET1-w, T2-w MR images. Patients were randomly divided into a training set (n = 51) and testing set (n = 19). The least absolute shrinkage and selection operator (LASSO) logistic regression model was applied for radiomic model construction in training set to select the most predictive features to predict patients who were replanned and assessed in the testing set. A double cross-validation approach of 100 resampled iterations with 3-fold nested cross-validation was employed in LASSO during model construction. The predictive performance of each model was evaluated using the area under the receiver operator characteristic (ROC) curve (AUC). Results: In the present cohort, 13 of 70 patients (18.6%) underwent ART. Average AUCs in training and testing sets were 0.962 (95%CI: 0.961-0.963) and 0.852 (95%CI: 0.847-0.857) with 8 selected features for CET1-w model; 0.895 (95%CI: 0.893-0.896) and 0.750 (95%CI: 0.745-0.755) with 6 selected features for T2-w model; and 0.984 (95%CI: 0.983-0.984) and 0.930 (95%CI: 0.928-0.933) with 6 selected features for joint T1-T2 model, respectively. In general, the joint T1-T2 model outperformed either CET1-w or T2-w model alone. Conclusions: Our study successfully showed promising capability of MRI-based radiomics features for pre-treatment identification of ART eligibility in NPC patients.",2019,Frontiers in Oncology
Genomic prediction applied to high-biomass sorghum for bioenergy production,"The increasing cost of energy and finite oil and gas reserves have created a need to develop alternative fuels from renewable sources. Due to its abiotic stress tolerance and annual cultivation, high-biomass sorghum (Sorghum bicolor L. Moench) shows potential as a bioenergy crop. Genomic selection is a useful tool for accelerating genetic gains and could restructure plant breeding programs by enabling early selection and reducing breeding cycle duration. This work aimed at predicting breeding values via genomic selection models for 200 sorghum genotypes comprising landrace accessions and breeding lines from biomass and saccharine groups. These genotypes were divided into two sub-panels, according to breeding purpose. We evaluated the following phenotypic biomass traits: days to flowering, plant height, fresh and dry matter yield, and fiber, cellulose, hemicellulose, and lignin proportions. Genotyping by sequencing yielded more than 258,000 single-nucleotide polymorphism markers, which revealed population structure between subpanels. We then fitted and compared genomic selection models BayesA, BayesB, BayesCÏ€, BayesLasso, Bayes Ridge Regression and random regression best linear unbiased predictor. The resulting predictive abilities varied little between the different models, but substantially between traits. Different scenarios of prediction showed the potential of using genomic selection results between sub-panels and years, although the genotype by environment interaction negatively affected accuracies. Functional enrichment analyses performed with the marker-predicted effects suggested several interesting associations, with potential for revealing biological processes relevant to the studied quantitative traits. This work shows that genomic selection can be successfully applied in biomass sorghum breeding programs.",2018,Molecular Breeding
Nonlinear sparse partial least squares: an investigation of the effect of nonlinearity and sparsity on the decoding of intracranial data.,"OBJECTIVE
Partial Least Squares regression is a suitable linear decoder model for correlated and high dimensional neural data. This algorithm has been widely used in the application of brain-computer interface (BCI) for decoding of motor parameters. PLS does not consider nonlinear relations between brain signal features. The nonlinear version of PLS that considers a nonlinear relationship between the latent variables has not been proposed for the decoding of intracranial data. This nonlinear model may cause overfitting in some cases due to more number of free parameters. In this paper, we develop a new version of nonlinear PLS namely nonlinear sparse PLS (NLS PLS) and test it in the BCI applications.


APPROACH
In motor related BCI systems, improving the decoding accuracy of both kinetic and kinematic parameters of movement is crucial. To do this, two BCI datasets were chosen to decode the force amplitude and position of hand trajectory using the nonlinear and sparse versions of PLS algorithm. In our new NLS PLS method, we considered a polynomial relationship between the latent variables and used the lasso penalization in the latent space to avoid overfitting and to improve the decoding accuracy.


MAIN RESULTS
Some linear and nonlinear based PLS models and our new proposed method, NLS PLS were applied to the two datasets. According to our results, significant improvement of NLS PLS method is confirmed over other methods. Our results show that nonlinear PLS outperforms generic PLS in the force decoding but it has lower accuracy in the hand trajectory decoding because of high dimensional feature space. By using lasso penalization, we presented a sparse nonlinear PLS-based model that outperforms generic PLS in both datasets and improves the coefficient of determination, 34% in the force decoding and 10% in the hand trajectory decoding.


SIGNIFICANCE
We construct a simple PLS-based model that considers a nonlinear relationship between features and it is also robust to overfitting because of using the lasso penalty in the latent space. This model is suitable for a high dimensional and correlated datasets like intracranial data and can improve the accuracy of estimation.",2019,Journal of neural engineering
A Target Selection Model for the Counseling Services in Long-Term Care Insurance,"In the long-term care insurance (LTCI) system, National Health Insurance Service (NHIS) provide counseling services for beneficiaries and their family caregivers, which help them use LTC services appropriately. The purpose of this study was to develop a Target Selection Model for the Counseling Services based on needs of beneficiaries and their family caregivers. To develope models, we used data set of total 2,000 beneficiaries and family caregivers who have used the long-term care services in their home in March 2013 and completed questionnaires. The Target Selection Model was established through various data-mining models such as logistic regression, gradient boosting, Lasso, decision-tree model, Ensemble, and Neural network. Lasso model was selected as the final model because of the stability, high performance and availability. Our results might improve the satisfaction and the efficiency for the NHIS counseling services.",2015,
"Calibration free, user-independent gaze estimation with tensor analysis","Abstract Human gaze directly signals visual attention, therefore, estimation of gaze has been an important research topic in fields such as human attention modeling and human-computer interaction. Accurate gaze estimation requires user, system and even session dependent parameters, which can be obtained by calibration process. However, this process has to be repeated whenever the parameter changes (head movement, camera movement, monitor movement). This study aims to eliminate the calibration process of gaze estimation by building a user-independent, appearance-based gaze estimation model. The system is ideal for multimodal interfaces, where the gaze is tracked without the cooperation from the users. The main goal is to capture the essential representation of the gaze appearance of the target user. We investigate the tensor analysis framework that decomposes the high dimension gaze data into different factors including individual differences, gaze differences, user-screen distances and session differences. The axis that is representative for a particular subject is automatically chosen in the tensor analysis framework using LASSO regression. The proposed approaches show promising results on capturing the test subject gaze changes. To address the estimation shift caused by the variations in individual heights, or relative position to the monitor, we apply domain adaptation to adjust the gaze estimation, observing further improvements. These promising results suggest that the proposed gaze estimation approach is a feasible and flexible scheme to facilitate gaze-based multimodal interfaces.",2018,Image Vis. Comput.
Classification of EEG Features for Prediction of Working Memory Load,"The objective of this research was to compare classification methods aimed at predicting working memory (WM) load. Electroencephalogram (EEG) data was collected from physicians while performing basic WM tasks and simulated medical scenarios. Data processing was performed to remove noise from the signal used for analysis (e.g., muscle activity, eye-blinks). The data from basic WM tasks was used to develop and test the four classification models (LASSO regression, support vector machines (SVM), nearest shrunken centroids (NSC), and iterated supervised principal components (ISPC) to predict a WM state indicative of physiciansâ€™ optimal performance. The naive misclassification rate was 19.74 %; LASSO and SVM outperformed this threshold: 18.10 and 12.21 % respectively). Both classification models had relatively high-specificity (LASSO: 97.2 %; SVM: 99.8 %); but relatively low-sensitivity LASSO: 20.7 %; SVM: 39.6 %). Results from simulated medical scenarios suggest that physicians were approximately 83 % of the time in the WM state that is likely indicative of optimal performance.",2017,
"Walking activity during ambulant cardiac rehabilitation is related to maximum working capacity, age, and smoking behavior","Background
A total of 6,500 to 8,000 steps per day are recommended for cardiovascular secondary prevention. The aim of this research was to examine how many steps per day patients achieve during ambulant cardiac rehabilitation (CR), and if there is a correlation between the number of steps and physical and cardiological parameters.


Methods
In all, 192 stable CR patients were included and advised for sealed pedometry. The assessed parameters included maximum working capacity and heart rate, body mass index (BMI), New York Heart Association (NYHA) class, ejection fraction (EF), coronary artery disease status, beta-blocker medication, age, sex, smoking behavior, and laboratory parameters. A regularized regression approach called least absolute shrinkage and selection operator (LASSO) was used to detect a small set of explanatory variables associated with the response for steps per day. Based on these selected covariates, a sparse additive regression model was fitted.


Results
The model noted that steps per day had a strong positive correlation with maximum working capacity (P=0.001), a significant negative correlation with higher age (P=0.01) and smoking (smoker: P<0.05; ex-smoker: P=0.01), a positive correlation with high-density lipoprotein (HDL), and a negative correlation with beta-blockers. Correlation between BMI and walking activity was nonlinear (BMI 18.5-24: 7,427Â±2,730 steps per day; BMI 25-29: 6,448Â±2,393 steps/day; BMI 30-34: 6,751Â±2,393 steps per day; BMI 35-39: 5,163Â±2,574; BMI >40: 6,077Â±1,567).


Conclusion
Walking activity during CR is reduced in patients who are unfit, older, smoke, or used to smoke. In addition to training recommendations, estimated steps per day during CR could be seen as a baseline orientation that helps patients to stay generally active or even to increase activity after CR.",2018,Vascular Health and Risk Management
Identification and validation of a 21-mRNA prognostic signature in diffuse lower-grade gliomas,"PurposeDiffuse low-grade and intermediate-grade gliomas, also known as lower-grade gliomas (LGGs), are a class of central nervous system tumors. Overall survival varies greatly between patients, highlighting the importance of evaluating exact outcomes to facilitate individualized clinical management. We aimed to identify an mRNA-based prognostic signature to predict the survival of patients with LGGs.MethodsA total of 874 LGGs from two public datasets were included. Least absolute shrinkage and selection operator (LASSO) Cox regression was used to select the most prognostic mRNAs and build a risk score. A nomogram incorporating the risk score and clinical factors was established for individualized survival prediction. The performance of the nomogram was assessed in the training set (329 patients), internal validation set (140 patients), and external validation set (405 patients).Results21 most prognostic mRNAs remained following the LASSO Cox regression. The 21-mRNA signature successfully stratified patients into high- and low-risk groups (Pâ€‰<â€‰0.001 for all datasets in Kaplanâ€“Meier analysis). Subsequent gene set enrichment analysis identified 19 essential biological processes in high-risk LGGs. Furthermore, a nomogram incorporating the risk score, age, grade, and 1p/19q status was developed with favorable calibration and high predictive accuracy in the training set and validation sets (C-index: 0.877, 0.878, and 0.812, respectively).ConclusionThe 21-mRNA signature has reliable prognostic value for LGGs and might facilitate the effective stratification and individualized management of patients.",2019,Journal of Neuro-Oncology
Sparse latent factor regression models for genome-wide and epigenome-wide association studies,"Association of phenotypes or exposures with genomic and epigenomic data faces important statistical challenges. One of these challenges is to remove variation due to unobserved confounding factors, such as individual ancestry or cell-type composition in tissues. This issue can be addressed with penalized latent factor regression models, where penalties are introduced to cope with high dimension in the data. If a relatively small proportion of genomic or epigenomic markers correlate with the variable of interest, sparsity penalties may help to capture the relevant associations, but the improvement over non-sparse approaches has not been fully evaluated yet. In this study, we introduced least-squares algorithms that jointly estimate effect sizes and confounding factors in sparse latent factor regression models. Computer simulations provided evidence that sparse latent factor regression models achieve higher statistical performance than other sparse methods, including the least absolute shrinkage and selection operator (LASSO) and a Bayesian sparse linear mixed model (BSLMM). Additional simulations based on real data showed that sparse latent factor regression models were more robust to departure from the generative model than non-sparse approaches, such as surrogate variable analysis (SVA) and other methods. We applied sparse latent factor regression models to a genome-wide association study of a flowering trait for the plant Arabidopsis thaliana and to an epigenome-wide association study of smoking status in pregnant women. For both applications, sparse latent factor regression models facilitated the estimation of non-null effect sizes while avoiding multiple testing problems. The results were not only consistent with previous discoveries, but they also pinpointed new genes with functional annotations relevant to each application.",2020,bioRxiv
Identifying the Driving Factors of Black Bloom in Lake Bay through Bayesian LASSO,"Black blooms are a serious and complex problem for lake bays, with far-reaching implications for water quality and drinking safety. While Fe(II) and S(-II) have been reported as the most important triggers of this phenomenon, little effort has been devoted in investigating the relationships between Fe(II) and S(-II) and the host of potentially important aquatic factors. However, a model involving many putative predictors and their interactions will be oversaturated and ill-defined, making ordinary least squares (OLS) estimation unfeasible. In such a case, sparsity assumption is typically required to exclude the redundant predictors from the model, either through variable selection or regularization. In this study, Bayesian least absolute shrinkage and selection operator (LASSO) regression was employed to identify the major influence variables from 11 aquatic factors for Fe(II), S(-II), and suspended sediment concentration (SSC) in the Chaohu Lake (Eastern of China) bay during black bloom maintenance. Both the main effects and the interactions between these factors were studied. The method successfully screened the most important variables from many items. The determination coefficients (R2) and adjusted determination coefficients (Adjust R2) showed that all regression equations for Fe(II), S(-II), and SSC were in good agreement with the situation observed in the Chaohu Lake. The outcome of correlation and LASSO regression indicated that total phosphorus (TP) was the single most important factor for Fe(II), S(-II), and SSC in black bloom with explanation ratios (ERs) of 76.1%, 37.0%, and 12.9%, respectively. The regression results showed that the interaction items previously deemed negligible have significant effects on Fe(II), S(-II), and SSC. For the Fe(II) equation, total nitrogen (TN) Ã— dissolved oxygen (DO) and chlorophyll a (CHLA) Ã— oxidation reduction potential (ORP), which contributed 10.6% and 13.3% ERs, respectively, were important interaction variables. TP emerged in each key interaction item of the regression equation for S(-II). Water depth (DEP) Ã— Fe(II) (30.7% ER) was not only the main interaction item, but DEP (5.6% ER) was also an important single factor for the SSC regression equation. It also indicated that the sediment in shallow bay is an important source for SSC in water. The uncertainty of these relationships was also estimated by the posterior distribution and coefficient of variation (CV) of these items. Overall, our results suggest that TP concentration is the most important driver of black blooms in a lake bay, whereas the other factors, such as DO, DEP, and CHLA act in concert with other aquatic factors. There results provide a basis for the further control and management policy development of black blooms.",2019,International Journal of Environmental Research and Public Health
Critical Decisions for Asset Allocation via Penalized Quantile Regression,"We extend the analysis of investment strategies derived from penalized quantile regression models, introducing alternative approaches to improve state\textendash of\textendash art asset allocation rules. First, we use a post\textendash penalization procedure to deal with overshrinking and concentration issues. Second, we investigate whether and to what extent the performance changes when moving from convex to nonconvex penalty functions. Third, we compare different methods to select the optimal tuning parameter which controls the intensity of the penalization. Empirical analyses on real\textendash world data show that these alternative methods outperform the simple LASSO. This evidence becomes stronger when focusing on the extreme risk, which is strictly linked to the quantile regression method.",2019,arXiv: Portfolio Management
Degrees of freedom in submodular regularization: A computational perspective of Stein's unbiased risk estimate,"Abstract Degrees of freedom is a covariance penalty related to penalized model selection procedures such as Mallowsâ€™ C p and AIC. We study the degrees of freedom of two polyhedral convex regularization classes defined through submodular functions called the Lovasz extension regularization and submodular norm regularization. It has been pointed out that submodular regularization contains many existing penalties that induce structural sparsity. In this paper, we show that the degrees of freedom of submodular regularization estimators can be represented in terms of partitions induced by the estimators. Our formula does not depend on the choice of the design matrix and the penalty function. Moreover, if the design matrix has full column rank, calculating an unbiased estimator of the degrees of freedom requires an additional computational cost of only O ( p log p ) after a solution for the estimator is obtained, where p is the dimension of the parameter. Existing results for some regularization and projection type estimators, such as the lasso, the fused lasso, and the isotonic regression, are also recovered.",2020,J. Multivar. Anal.
Towards Accurate Predictions of Customer Purchasing Patterns,"A range of algorithms was used to classify online retail customers of a UK company using historical transaction data. The predictive capabilities of the classifiers were assessed using linear regression, Lasso and regression trees. Unlike most related studies, classifications were based upon specific and marketing focused customer behaviours. Prediction accuracy on untrained customers was generally better than 80%. The models implemented (and compared) for classification were: Logistic Regression, Quadratic Discriminant Analysis, Linear SVM, RBF SVM, Gaussian Process, Decision Tree, Random Forest and Multi-layer Perceptron (Neural Network). Postcode data was then used to classify solely on demographics derived from the UK Land Registry and similar public data sources. Prediction accuracy remained better than 60%.",2017,2017 IEEE International Conference on Computer and Information Technology (CIT)
Sparse principal component analysis with measurement errors,"Abstract Traditional principal component analysis often produces non-zero loadings, which makes it hard to interpret the principal components. This drawback can be overcome by the sparse principal component analysis procedures developed in the past decade. However, similar work has not been done when the random variables or vectors are contaminated with measurement errors. Simply applying the existing sparse principal component analysis procedure to the error-contaminated data might lead to biased loadings. This paper tries to modify an existing sparse principal component procedure to accommodate the measurement error setup. Similar to error-free cases, we show that the sparse principal component for the latent variables can be formulated as a bias-corrected lasso (elastic net) regression problem based on the observed surrogates, efficient algorithms are also developed to implement the procedure. Numerical simulation studies are conducted to illustrate the finite sample performance of the proposed method.",2016,Journal of Statistical Planning and Inference
Novel Resampling Methods for Tuning Parameter Selection in Robust Sparse Regression Modeling,"The robust lasso-type regularized regression is a useful tool for simultaneous estimation and variable selection even in the presence of outliers. Crucial issues in the robust modeling procedure include the selection of regularization parameters and also a tuning constant in outlier detection. Although the performance of the robust sparse regression strongly depends on the proper choice of these tuning parameters, little attention was paid for this issue, particularly in the presence of outliers. We consider the problem of choosing the tuning parameters and propose an information-theoretic criterion based on the bootstrap. Although the bootstrap information criterion has several advantages on its flexibility and weak assumptions, a bootstrap sample may contain more outliers compared with those included in the original sample, since the bootstrap sample is drawn randomly. This implies that the bootstrap information criterion may be obtained from the highly contaminated bootstrap sample by outliers, so the resulting criterion may produce biased results. In order to overcome the drawback, we propose a robust bootstrap information criterion via winsorizing technique (Srivastava et al., 2010) in line with the efficient bootstrap information criterion (Konishi and Kitagawa, 1996) for choosing an optimal set of tuning parameters. Monte Carlo simulations and real data analysis are conducted to investigate the effectiveness of the proposed method. We observe that the proposed robust efficient bootstrap information criterion produces reliable model estimates and performs well in the presence of outliers.",2012,Bulletin of informatics and cybernetics
Prognostic nomogram incorporating inflammatory cytokines for overall survival in patients with aggressive non-Hodgkin's lymphoma,"BACKGROUND
This study aimed to investigate the association of pre-treatment inflammatory status with survival time and to develop a prognostic nomogram incorporating inflammatory cytokines in non-Hodgkin's lymphoma.


METHODS
A total of 228 patients with diffuse large B-cell lymphoma (DLBCL) received R-CHOP-based regimens from a prospective randomized study (NCT01852435) were included as a training cohort. Other cohorts of 886 lymphoma patients were served as validation cohorts. Lymphocyte-monocyte ratio (LMR), serum levels of soluble interleukin s(IL)-2R, IL-6, IL-8, IL-10 and tumor necrosis factor-Î± (TNF-Î±), were assessed before treatment. Least absolute shrinkage and selection operator (LASSO) regression were used to select variables for nomogram of overall survival (OS). The predictive accuracy of the nomogram was determined by concordance index (C-index).


FINDINGS
The nomogram included lactate dehydrogenase (LDH), sIL-2R, TNF-Î± and decreased LMR. The C-index of the nomogram for OS prediction were range from 0.61 to 0.86 for training cohort of DLBCL and validation cohorts of DLBCL, PTCL, NKTCL and ASCT, which were superior to the predictive power of International Prognostic Index (IPI, 0.67 to 0.84) or NCCN-IPI (0.59 to 0.78), but not in those of indolent lymphoma like FL and MALT.


INTERPRETATIONS
The nomogram incorporating inflammatory cytokines provides a useful tool for risk stratification in aggressive non-Hodgkin's lymphomas. FUND: National Natural Science Foundation of China, the Shanghai Commission of Science and Technology, Multicenter Clinical Research Project by Shanghai Jiao Tong University School of Medicine, Clinical Research Plan of SHDC, and Chang Jiang Scholars Program.",2019,EBioMedicine
Multivariate Pairs Trading Using Temporal Dependence Structures,"Multivariate pairs trading is a strategy that tries to exploit inefficiencies in the relative value pricing between stocks and baskets of related assets. In this research we set up such strategies, where the baskets are identified by elastic net regularization. The elastic net rigorously combines Lasso and ridge regression resulting in compact and robust baskets. We model the spread dynamics of pairs using copula-based (semi-)parametric time series models. This type of model allows for a range of dependency structures and marginals that can be modelled separately. This affords great flexibility and opens up a new way on modelling the spread dynamics. We investigate the strategiesâ€™ performance for the Japanese universe using daily stock prices of the Nikkei 225 index constituents ranging from August 3rd 2001 to April 1st 2010. We find that the generalization to account for nonlinear associations in the spread dynamics does not necessarily lead to more trading opportunities. However, this generalization leads to â€˜betterâ€™ trading signals, i.e. a higher rate of trades that converges. After optimizing the input parameters we find annualized Sharpe ratios up to 1.35 for the copula model and 0.69 for its linear counterpart. Hedging the positions by the identified baskets rather than only stocksâ€™ sector members lowers the portfoliosâ€™ standard deviations, but does not lead to significant higher Sharpe ratios.",2018,
Iterative Reweighted l 1 Penalty Regression Approach for Line Spectral Estimation,"In this paper, we proposed an iterative reweighted l1Â penalty 
regression approach to solve the line spectral estimation problem. In each 
iteration process, we first use the ideal of Bayesian lasso to update the sparse vectors; the 
derivative of the penalty function forms the regularization parameter. We 
choose the anti-trigonometric function as a penalty function to approximate theÂ l0Â  norm. Then we 
use the gradient descent method to update the dictionary parameters. The 
theoretical analysis and simulation results demonstrate the effectiveness of 
the method and show that the proposed algorithm outperforms other 
state-of-the-art methods for many practical cases.",2018,Advances in Pure Mathematics
A sparse method to handle two high dimensional symetric data sets,"When dealing with high dimensional biological data, one important issue is to handle the n << p problem, as most variables are irrelevant or noisy to explain the biological experiment. This issue is even more challenging when there are more than one group of variables and when the aim is to highlight the relationships between the different sets of variables. Here, we especially focus on the situation where there are two groups of variables measured on the same observations (symetric data sets). Very few methods can deal with two (or more) data sets. Among them, Canonical Correlation Analysis (CCA, [2]) and Partial Least Squares regression (PLS, [3]) can answer the biological question. However, both approaches do not allow feature selection. To deal with the major drawback of CCA (p < n and q < n), [1] proposed to regularize CCA with an L2 penalization. But so far, no sparse method has been developped yet to handle this problem, as it is proposed by lasso in the context of regression. We propose a sparse approach to select variables from each of the two data sets with two variants: either to model the relationships between the two sets of variables, or to predict one set of variables with respect to the other. We apply this method to some real world data sets with two types of measurements, and which purpose is to explain which group of variable imply the other group of variables (and/or vice versa).",2008,
Integrated analysis reveals microRNA networks coordinately expressed with key proteins in breast cancer,"BackgroundThe role played by microRNAs in the deregulation of protein expression in breast cancer is only partly understood. To gain insight, the combined effect of microRNA and mRNA expression on protein expression was investigated in three independent data sets.MethodsProtein expression was modeled as a multilinear function of powers of mRNA and microRNA expression. The model was first applied to mRNA and protein expression for 105 selected cancer-associated genes and to genome-wide microRNA expression from 283 breast tumors. The model considered both the effect of one microRNA at a time and all microRNAs combined. In the latter case the Lasso penalized regression method was applied to detect the simultaneous effect of multiple microRNAs.ResultsAn interactome map for breast cancer representing all direct and indirect associations between the expression of microRNAs and proteins was derived. A pattern of extensive coordination between microRNA and protein expression in breast cancer emerges, with multiple clusters of microRNAs being associated with multiple clusters of proteins. Results were subsequently validated in two independent breast cancer data sets. A number of the microRNA-protein associations were functionally validated in a breast cancer cell line.ConclusionsA comprehensive map is derived for the co-expression in breast cancer of microRNAs and 105 proteins with known roles in cancer, after filtering out the in-cis effect of mRNA expression. The analysis suggests that group action by several microRNAs to deregulate the expression of proteins is a common modus operandi in breast cancer.",2015,Genome Medicine
Fuzzy c-Regression Models with Cluster Characteristics Clarification,"In order to improve the comparative interpretability among cluster-wise local regression models, this paper proposes a modified fuzzy c-regression models (FCRM), which is a fuzzy c-means (FCM)-type switching regression. Based on the combined concepts of ridge regression and intra-cluster exclusive variable selection, cluster-wise meaningful explanatory variables are emphasized. Additionally, it is further extended with the LASSO concept for reducing the inappropriate influences of larger coefficient values. The characteristics of the proposed methods are demonstrated through some numerical experiments.",2019,2019 International Conference on Fuzzy Theory and Its Applications (iFUZZY)
Effect of the prior distribution of SNP effects on the estimation of total breeding value,"BackgroundFive main methods, commonly applied in genomic selection, were used to estimate the GEBV on the 15th QTLMAS workshop dataset: GBLUP, LASSO, Bayes A and two Bayes B type of methods (BBn and BBt). GBLUP is a mixed model approach where GEBV are obtained using a relationship matrix calculated from the SNP genotypes. The remaining methods are regression-based approaches where the SNP effects are first estimated and, then GEBV are calculated given the individuals' genotypes.MethodsThe differences between the regression-based methods are in their prior distributions for the SNP effects. The prior distribution for LASSO is a Laplace distribution, for Bayes A is a scaled Student-t distribution, and the Bayes B type methods have a Spike and Slab prior where only a proportion (Ï€) of SNP has an effect, following a given distribution. In this study, two different distributions were considered for the Bayes B type methods: (i) normal and (ii) scaled Student-t. They are referred here as the BBn and BBt methods, respectively. These prior distributions are defined by one or more parameters controlling their scale/rate (Î»), shape (df) or proportion of SNP with effect (Ï€). LASSO requires one (Î»); two for Bayes A (Î», df) and Bayes Bn (Î», Ï€); and three for Bayes Bt (Î», df, Ï€). In this study, all parameters were estimated from the data. An extra scenario for Bayes A and BBt was included where df was not estimated but fixed to 4 (suffixed _4df). The implementation of GBLUP was done using ASREML, the heritability was also estimated from the data. All other methods were implemented using a MCMC approach.ResultsAll Bayes A and B methods showed accuracy (correlation between True and Estimated BV) as high as 0.94 except for BA_4df (r = 0.91). Compared to the traditional BLUP using pedigree information, these methods improved the accuracy between 50 and 55%. GBLUP and LASSO were less accurate (0.81 and 0.85 respectively) and the improvements were 34 and 40% compared to BLUP.ConclusionsResults of all methods were consistent and the accuracies for GEBV ranged between 0.81 and 0.94. When all parameters were estimated the results were similar for the Bayes A and Bayes B methods. Results showed that Bayes A was more sensitive to the changes in the shape parameter, and the parameter changes led to change in the accuracy of GEBV. However BBt was more robust to the change in this parameter. This may be explained by the fact that BBt estimates one extra parameter and it can buffer against a non-proper shape parameter.",2012,BMC Proceedings
Sparse additive models,"We present a new class of methods for high dimensional non-parametric regression and classification called sparse additive models. Our methods combine ideas from sparse linear modelling and additive non-parametric regression. We derive an algorithm for fitting the models that is practical and effective even when the number of covariates is larger than the sample size. Sparse additive models are essentially a functional version of the grouped lasso of Yuan and Lin. They are also closely related to the COSSO model of Lin and Zhang but decouple smoothing and sparsity, enabling the use of arbitrary non-parametric smoothers. We give an analysis of the theoretical properties of sparse additive models and present empirical results on synthetic and real data, showing that they can be effective in fitting sparse non-parametric models in high dimensional data. Copyright (c) 2009 Royal Statistical Society.",2007,Journal of The Royal Statistical Society Series B-statistical Methodology
Evaluation of Parametric and Nonparametric Statistical Methods in Genomic Prediction,. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvii CHAPTER 1. GENERAL INTRODUCTION . . . . . . . . . . . . . . . . . . . 1 CHAPTER 2. PARAMETRIC AND NONPARAMETRIC STATISTICAL METHODS FOR GENOMIC SELECTION OF TRAITS WITH ADDITIVE AND EPISTATIC GENETIC ARCHITECTURES . . . . . . . . . . 5 2.1 Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 2.2.1 Parametric Methods in Genome-Wide Selection . . . . . . . . . . . . . . 10 2.2.2 Nonparametric Methods in Genome-Wide Selection . . . . . . . . . . . 20 2.3 Materials and Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 2.3.1 Least Squares Regression . . . . . . . . . . . . . . . . . . . . . . . . . . 32 2.3.2 Ridge Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 2.3.3 Bayesian Ridge Regression: . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.3.4 BLUP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.3.5 LASSO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 2.3.6 Bayesian LASSO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 2.3.7 Bayesian Alphabet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 2.3.8 Nadaraya-Watson Estimator . . . . . . . . . . . . . . . . . . . . . . . . 34 2.3.9 Reproducing Kernel Hilbert Space . . . . . . . . . . . . . . . . . . . . . 35,2016,
On Weighted Support Vector Regression,"We propose a new type of weighted support vector regression (SVR), motivated by modeling local dependencies in time and space in prediction of house prices. The classic weights of the weighted SVR are added to the slack variables in the objective function (OF-weights). This procedure directly shrinks the coefficient of each observation in the estimated functions; thus, it is widely used for minimizing influence of outliers. We propose to additionally add weights to the slack variables in the constraints (CF-weights) and call the combination of weights the doubly weighted SVR. We illustrate the differences and similarities of the two types of weights by demonstrating the connection between the Least Absolute Shrinkage and Selection Operator (LASSO) and the SVR. We show that an SVR problem can be transformed to a LASSO problem plus a linear constraint and a box constraint. We demonstrate the capabilities of the doubly weighted approach through an example of prediction of house prices. The weight functions in the house pricing model depend on the geographical distance to the house of interest and the difference in time of sale (CF-weights) as well as the differences lying in variables (OF-weights), such as house size and number of floors. The results illustrate that the combination of the two types of weights describes the relative importance of observations very well and lowers the influence of possible outliers. Therefore, it enables the SVR models to have good performance. Copyright Â© 2014 John Wiley & Sons, Ltd.",2014,Quality and Reliability Eng. Int.
What health records data are required for accurate prediction of suicidal behavior?,"OBJECTIVE
The study sought to evaluate how availability of different types of health records data affect the accuracy of machine learning models predicting suicidal behavior.


MATERIALS AND METHODS
Records from 7 large health systems identified 19Â 061Â 056 outpatient visits to mental health specialty or general medical providers between 2009 and 2015. Machine learning models (logistic regression with penalized LASSO [least absolute shrinkage and selection operator] variable selection) were developed to predict suicide death (nâ€‰=â€‰1240) or probable suicide attempt (nâ€‰=â€‰24Â 133) in the following 90 days. Base models were used only historical insurance claims data and were then augmented with data regarding sociodemographic characteristics (race, ethnicity, and neighborhood characteristics), past patient-reported outcome questionnaires from electronic health records, and data (diagnoses and questionnaires) recorded during the visit.


RESULTS
For prediction of any attempt following mental health specialty visits, a model limited to historical insurance claims data performed approximately as well (C-statistic 0.843) as a model using all available data (C-statistic 0.850). For prediction of suicide attempt following a general medical visit, addition of data recorded during the visit yielded a meaningful improvement over a model using all data up to the prior day (C-statistic 0.853 vs 0.838).


DISCUSSION
Results may not generalize to setting with less comprehensive data or different patterns of care. Even the poorest-performing models were superior to brief self-report questionnaires or traditional clinical assessment.


CONCLUSIONS
Implementation of suicide risk prediction models in mental health specialty settings may be less technically demanding than expected. In general medical settings, however, delivery of optimal risk predictions at the point of care may require more sophisticated informatics capability.",2019,Journal of the American Medical Informatics Association : JAMIA
