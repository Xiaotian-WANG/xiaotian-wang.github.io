title,abstract,year,journal
Fully Bayesian Classification with Heavy-tailed Priors for Selection in High-dimensional Features with Grouping Structure,"Author(s): Jiang, Lai; Li, Longhai; Yao, Weixin | Abstract: Feature selection is demanded in many modern scientific research problems that use high-dimensional data. A typical example is to find the most useful genes that are related to a certain disease (eg, cancer) from high-dimensional gene expressions. The expressions of genes have grouping structures, for example, a group of co-regulated genes that have similar biological functions tend to have similar expressions. Many statistical methods have been proposed to take the grouping structure into consideration in feature selection, including group LASSO, supervised group LASSO, and regression on group representatives. In this paper, we propose a fully Bayesian Robit regression method with heavy-tailed (sparsity) priors (shortened by FBRHT) for selecting features with grouping structure. The main features of FBRHT include that it discards more aggressively unrelated features than LASSO, and it can make feature selection within groups automatically without a pre-specified grouping structure. In this paper, we use simulated and real datasets to demonstrate that the predictive power of the sparse feature subsets selected by FBRHT are comparable with other much larger feature subsets selected by LASSO, group LASSO, supervised group LASSO, penalized logistic regression and random forest, and that the succinct feature subsets selected by FBRHT have significantly better predictive power than the feature subsets of the same size taken from the top features selected by the aforementioned methods.",2018,arXiv: Methodology
Targeted metabolomics reveals reduced levels of polyunsaturated choline plasmalogens and a smaller dimethylarginine/arginine ratio in the follicular fluid of patients with a diminished ovarian reserve,"STUDY QUESTION
Does the metabolomic profile of the follicular fluid (FF) of patients with a diminished ovarian reserve (DOR) differ from that of patients with a normal ovarian reserve (NOR)?


SUMMARY ANSWER
The metabolomic signature of the FF reveals a significant decrease in polyunsaturated choline plasmalogens and methyl arginine transferase activity in DOR patients compared to NOR patients.


WHAT IS KNOWN ALREADY
The composition of the FF reflects the exchanges between the oocyte and its microenvironment during its acquisition of gametic competence. Studies of the FF have allowed identification of biomarkers and metabolic pathways involved in various pathologies affecting oocyte quality, but no large metabolomic analysis in the context of ovarian ageing and DOR has been undertaken so far.


STUDY DESIGN, SIZE, DURATION
This was an observational study of the FF retrieved from 57 women undergoing in vitro fertilization at the University Hospital of Angers, France, from November 2015 to September 2016. The women were classified in two groups: one including 28 DOR patients, and the other including 29 NOR patients, serving as controls.


PARTICIPANTS/MATERIALS, SETTING, METHODS
Patients were enrolled in the morning of oocyte retrieval after ovarian stimulation. Once the oocytes were isolated for fertilization and culture, the FF was pooled and centrifuged for analysis. A targeted quantitative metabolomic analysis was performed using high-performance liquid chromatography coupled with tandem mass spectrometry, and the Biocrates Absolute IDQ p180 kit. The FF levels of 188 metabolites and several sums and ratios of metabolic significance were assessed by multivariate and univariate analyses.


MAIN RESULTS AND THE ROLE OF CHANCE
A total of 136 metabolites were accurately quantified and used for calculating 23 sums and ratios. Samples were randomly divided into training and validation sets. The training set, allowed the construction of multivariate statistical models with a projection-supervised method, i.e. orthogonal partial least squares discriminant analysis (OPLS-DA), applied to the full set of metabolites, or the penalized least absolute shrinkage and selection operator with logistic regression (LASSO-LR), applied to the ratios and sums of the metabolites. Both multivariate models showed good predictive performances when applied to the validation set. The final penalized model retained the three most significant variables, i.e. the total dimethylarginine-to-arginine ratio (Total DMA/Arginine), the sum of the polyunsaturated choline plasmalogens (PUFA ae), and the patient's age. The negative coefficients of Total DMA/Arginine and PUFA ae indicated that these FF variables had lower values in DOR patients than in NOR patients.


LARGE SCALE DATA
N/A.


LIMITATIONS REASONS FOR CAUTION
This study presents two limitations. First, with this targeted metabolomics analysis, we have explored only a limited portion of the FF metabolome. Second, although the signature found was highly significant, the mechanism underlying the dysfunction remains undetermined.


WIDER IMPLICATIONS OF THE FINDINGS
The understanding of the mechanisms implied in ovarian ageing is essential for providing an adequate response to affected women desiring pregnancy. Our study proposes an incoming signature that may open new paths towards this goal.


STUDY FUNDING/COMPETING INTEREST(S)
This study was supported by the University Hospital of Angers, the University of Angers, and the French national research centers, INSERM and the CNRS. There were no competing interests.",2017,Human Reproduction
Regularized quantile regression applied to genome-enabled prediction of quantitative traits.,"Genomic selection (GS) is a variant of marker-assisted selection, in which genetic markers covering the whole genome predict individual genetic merits for breeding. GS increases the accuracy of breeding values (BV) prediction. Although a variety of statistical models have been proposed to estimate BV in GS, few methodologies have examined statistical challenges based on non-normal phenotypic distributions, e.g., skewed distributions. Traditional GS models estimate changes in the phenotype distribution mean, i.e., the function is defined for the expected value of trait-conditional on markers, E(Y|X). We proposed an approach based on regularized quantile regression (RQR) for GS to improve the estimation of marker effects and the consequent genomic estimated BV (GEBV). The RQR model is based on conditional quantiles, QÏ„(Y|X), enabling models that fit all portions of a trait probability distribution. This allows RQR to choose one quantile function that ""best"" represents the relationship between the dependent and independent variables. Data were simulated for 1000 individuals. The genome included 1500 markers; most had a small effect and only a few markers with a sizable effect were simulated. We evaluated three scenarios according to symmetrical, positively, and negatively skewed distributions. Analyses were performed using Bayesian LASSO (BLASSO) and RQR considering three quantiles (0.25, 0.50, and 0.75). The use of RQR to estimate GEBV was efficient; the RQR method achieved better results than BLASSO, at least for one quantile model fit for all evaluated scenarios. The gains in relation to BLASSO were 86.28 and 55.70% for positively and negatively skewed distributions, respectively.",2017,Genetics and molecular research : GMR
"Dietary exposures, epigenetics and pubertal tempo","Gene expression changes mediated by DNA methylation may play a role in pubertal tempo regulation, and availability of methyl donor nutrients affects these pathways. We examined first trimester maternal and adolescent diet patterns that may be associated with DNA methylation at long interspersed nucleotide (LINE-1) repetitive elements in adolescence using least absolute shrinkage and selection operator (LASSO) and calculated an 'Epigenetics-Associated Diet Score' (EADS) for each pattern; then tested the associations of these scores with pubertal tempo among adolescent boys and girls. The analytic sample included 118 boys and 132 girls aged 10-18 years. DNA methylation at LINE-1 repetitive elements was quantified. Typical maternal and adolescent nutrient intakes were estimated using food frequency questionnaires. Interval-censored time to event and ordinal regression models were used to examine associations EADS scores with pubertal tempo using physician-assessed Tanner stages and self-reported menarche, respectively, adjusted for confounders. We observed associations between maternal EADS and pubertal onset, but not pubertal progression. Each standard deviation (SD) greater maternal EADS was associated with 52% higher odds of having later onset of menarche in both cross-sectional and prospective analysis (P = 0.031 and 0.028, respectively). In contrast, we observed associations between adolescent EADS and pubertal progression, but not pubertal onset. Among boys, for each SD higher adolescent EADS, there was 13% increase in odds of slower genital progression (P = 0.050), as well as 26 and 27% increase in odds of slower left and right testicular development, respectively (P = 0.001). Epigenetic-associated diet influences pubertal tempo in a sex- and timing-specific manner.",2019,Environmental Epigenetics
bamlss: A Lego Toolbox for Flexible Bayesian Regression (and Beyond),"Over the last decades, the challenges in applied regression and in predictive modeling have been changing considerably: (1) More flexible model specifications are needed as big(ger) data become available, facilitated by more powerful computing infrastructure. (2) Full probabilistic modeling rather than predicting just means or expectations is crucial in many applications. (3) Interest in Bayesian inference has been increasing both as an appealing framework for regularizing or penalizing model estimation as well as a natural alternative to classical frequentist inference. However, while there has been a lot of research in all three areas, also leading to associated software packages, a modular software implementation that allows to easily combine all three aspects has not yet been available. For filling this gap, the R package bamlss is introduced for Bayesian additive models for location, scale, and shape (and beyond). At the core of the package are algorithms for highly-efficient Bayesian estimation and inference that can be applied to generalized additive models (GAMs) or generalized additive models for location, scale, and shape (GAMLSS), also known as distributional regression. However, its building blocks are designed as ""Lego bricks"" encompassing various distributions (exponential family, Cox, joint models, ...), regression terms (linear, splines, random effects, tensor products, spatial fields, ...), and estimators (MCMC, backfitting, gradient boosting, lasso, ...). It is demonstrated how these can be easily recombined to make classical models more flexible or create new custom models for specific modeling challenges.",2019,ArXiv
A Metaheuristic LASSO Model for Diabetic Readmission Prediction,"Hospital readmission prediction continues to be a highly-encouraged area of investigation mainly because of the readmissions reduction program by the Centers for Medicare and Medicaid services (CMS). The overall goal is to reduce the number of early hospital readmissions by identifying the key risk factors that cause hospital readmissions. This is especially important in Intensive Care Unit (ICU), where patient readmission increases the likelihood of mortality due to the worsening of the patient condition. Traditional approaches use simple logistic regression or other linear classification methods to identify the key features that provide high prediction accuracy. However, these methods are not sufficient since they cannot capture the complex patterns between different features. In this paper, we propose a hybrid Evolutionary Simulating Annealing LASSO Logistic Regression (ESALOR) model to accurately predict the hospital readmission rate and identify the important risk factors. The proposed model combines the evolutionary simulated annealing method with a sparse logistic regression model of Lasso. The ESALOR model was tested on a publicly available diabetes readmission dataset, and the results show that the proposed model provides better results compared to conventional classification methods including Support Vector Machines (SVM), Decision Tree, Naive Bayes, and Logistic Regression.",2016,
Joint multiple quantitative trait loci mapping for allometries of body compositions and metabolic traits to body weights in broiler.,"In order to map quantitative trait loci (QTLs) for allometries of body compositions and metabolic traits in chicken, we phenotypically characterize the allometric growths of multiple body components and metabolic traits relative to BWs using joint allometric scaling models and then establish random regression models (RRMs) to fit genetic effects of markers and minor polygenes derived from the pedigree on the allometric scalings. Prior to statistically inferring the QTLs for the allometric scalings by solving the RRMs, the LASSO technique is adopted to rapidly shrink most of marker genetic effects to zero. Computer simulation analysis confirms the reliability and adaptability of the so-called LASSO-RRM mapping method. In the F2 population constructed by multiple families, we formulate two joint allometric scaling models of body compositions and metabolic traits, in which six of nine body compositions are tested as significant, while six of eight metabolic traits are as significant. For body compositions, a total of 14 QTLs, of which 9 dominant, were detected to be associated with the allometric scalings of drumstick, fat, heart, shank, liver and spleen to BWs; while for metabolic traits, a total of 19 QTLs also including 9 dominant be responsible for the allometries of T4, IGFI, IGFII, GLC, INS, IGR to BWs. The detectable QTLs or highly linked markers can be used to regulate relative growths of the body components and metabolic traits to BWs in marker-assisted breeding of chickens.",2020,Animal : an international journal of animal bioscience
Improvement of experimental testing and network training conditions with genome-wide microarrays for more accurate predictions of drug gene targets,"BackgroundGenome-wide microarrays have been useful for predicting chemical-genetic interactions at the gene level. However, interpreting genome-wide microarray results can be overwhelming due to the vast output of gene expression data combined with off-target transcriptional responses many times induced by a drug treatment. This study demonstrates how experimental and computational methods can interact with each other, to arrive at more accurate predictions of drug-induced perturbations. We present a two-stage strategy that links microarray experimental testing and network training conditions to predict gene perturbations for a drug with a known mechanism of action in a well-studied organism.ResultsS. cerevisiae cells were treated with the antifungal, fluconazole, and expression profiling was conducted under different biological conditions using Affymetrix genome-wide microarrays. Transcripts were filtered with a formal network-based method, sparse simultaneous equation models and Lasso regression (SSEM-Lasso), under different network training conditions. Gene expression results were evaluated using both gene set and single gene target analyses, and the drugâ€™s transcriptional effects were narrowed first by pathway and then by individual genes. Variables included: (i) Testing conditions â€“ exposure time and concentration and (ii) Network training conditions â€“ training compendium modifications. Two analyses of SSEM-Lasso output â€“ gene set and single gene â€“ were conducted to gain a better understanding of how SSEM-Lasso predicts perturbation targets.ConclusionsThis study demonstrates that genome-wide microarrays can be optimized using a two-stage strategy for a more in-depth understanding of how a cell manifests biological reactions to a drug treatment at the transcription level. Additionally, a more detailed understanding of how the statistical model, SSEM-Lasso, propagates perturbations through a network of gene regulatory interactions is achieved.",2012,BMC Systems Biology
"Complementing the power of deep learning with statistical model fusion: Probabilistic forecasting of influenza in Dallas County, Texas, USA.","Influenza is one of the main causes of death, not only in the USA but worldwide. Its significant economic and public health impacts necessitate development of accurate and efficient algorithms for forecasting of any upcoming influenza outbreaks. Most currently available methods for influenza prediction are based on parametric time series and regression models that impose restrictive and often unverifiable assumptions on the data. In turn, more flexible machine learning models and, particularly, deep learning tools whose utility is proven in a wide range of disciplines, remain largely under-explored in epidemiological forecasting. We study the seasonal influenza in Dallas County by evaluating the forecasting ability of deep learning with feedforward neural networks as well as performance of more conventional statistical models, such as beta regression, autoregressive integrated moving average (ARIMA), least absolute shrinkage and selection operators (LASSO), and non-parametric multivariate adaptive regression splines (MARS) models for one week and two weeks ahead forecasting. Furthermore, we assess forecasting utility of Google search queries and meteorological data as exogenous predictors of influenza activity. Finally, we develop a probabilistic forecasting of influenza in Dallas County by fusing all the considered models using Bayesian model averaging.",2019,Epidemics
Short-term forecasting of emerging on-demand ride services,"In the last few years, on-demand ride services boomed worldwide, and different modes of ridesourcing services emerged, too. However, there have been few qualitative and quantitative analyses on these ride service patterns, partially due to the lack or unavailability of detailed on-demand ride service data. In this paper, we analyze the real-world individual-level order and the trip data extracted from the DiDi's on-demand mobility platform in Hangzhou, China. This study intends to understand the temporal and spatial travel pattern of passengers' demand and ride services which include four types, i.e., Taxi Hailing, Private Car Service, Hitch, and Express. We study the relationship between different service modes of the drivers from a selected region in specific time periods. In order to predict travel demand of the aforementioned on-demand ride services, we utilize LASSO (least absolute shrinkage and selection operator) to rank features of the on-demand platform data (e.g., distance, fee, and waiting time). An on-demand ride prediction model is established based on the random forest (RF), which is then compared with the autoregressive integrated moving average (ARIMA) and support vector regression (SVR). The results show that RF outperforms other models and it is utilized to provide an insight for forecasting the demand of distinctive on-demand ride service patterns. To the best knowledge of authors, this paper is among the first attempts to learn the temporal and spatial travel patterns, also to forecast emerging on-demand ride services.",2017,2017 4th International Conference on Transportation Information and Safety (ICTIS)
Graph Projection Block Splitting for Distributed Optimization,"This paper describes a general purpose method for solving convex optimization problems in a distributed computing environment. In particular, if the problem data includes a large linear operator or matrix A, the method allows for handling each subblock of A on a separate machine. The approach works as follows. First, we define a canonical problem form called graph form, in which we have two sets of variables x and y related by a linear operator A, such that the objective function is separable across these two sets of variables. Many problems are easily expressed in graph form, including cone programs and a wide variety of regularized loss minimization problems from statistics, like logistic regression, the support vector machine, and the lasso. Next, we describe graph projection splitting, a form of Douglas-Rachford splitting or the alternating direction method of multipliers, to solve graph form problems serially. Finally, we derive a distributed block splitting algorithm based on graph projection splitting. In a statistical or machine learning context, this allows for training models exactly with a huge number of both training examples and features, such that each processor handles only a subset of both. To the best of our knowledge, this is the only general purpose method with this property. We present several numerical experiments in both the serial and distributed settings.",2012,
Cyst Fluid Biosignature to Predict Intraductal Papillary Mucinous Neoplasms of the Pancreas with High Malignant Potential.,"BACKGROUND
Current standard-of-care technologies, such as imaging and cyst fluid analysis, are unable to consistently distinguish intraductal papillary mucinous neoplasms (IPMNs) of the pancreas at high risk of pancreatic cancer from low-risk IPMNs. The objective was to create a single-platform assay to identify IPMNs that are at high risk for malignant progression.


STUDY DESIGN
Building on the Verona International Consensus Conference branch duct IPMN biomarker review, additional protein, cytokine, mucin, DNA, and microRNA cyst fluid targets were identified for creation of a quantitative polymerase chain reaction-based assay. This included messenger RNA markers: ERBB2, GNAS, interleukin 1Î², KRAS, MUCs1, 2, 4, 5AC, 7, prostaglandin E2R, PTGER2, prostaglandin E synthase 2, prostaglandin E synthase 1, TP63; microRNA targets: miRs 101, 106b, 10a, 142, 155, 17, 18a, 21, 217, 24, 30a, 342, 532, 92a, and 99b; and GNAS and KRAS mutational analysis. A multi-institutional international collaborative contributed IPMN cyst fluid samples to validate this platform. Cyst fluid gene expression levels were normalized, z-transformed, and used in classification and regression analysis by a support vector machine training algorithm.


RESULTS
From cyst fluids of 59 IPMN patients, principal component analysis confirmed no institutional bias/clustering. Lasso (least absolute shrinkage and selection operator)-penalized logistic regression with binary classification and 5-fold cross-validation used area under the curve as the evaluation criterion to create the optimal signature to discriminate IPMNs as low risk (low/moderate dysplasia) or high risk (high-grade dysplasia/invasive cancer). The most predictive signature was achieved with interleukin 1Î², MUC4, and prostaglandin E synthase 2 to accurately discriminate high-risk cysts from low-risk cysts with an area under the curve of up to 0.86 (pÂ = 0.002).


CONCLUSIONS
We have identified a single-platform polymerase chain reaction-based assay of cyst fluid to accurately predict IPMNs with high malignant potential for additional studies.",2019,Journal of the American College of Surgeons
Classification and Regression Using an Outer Approximation Projection-Gradient Method,"This paper deals with sparse feature selection and grouping for classification and regression. The classification or regression problems under consideration consists of minimizing a convex empirical risk function subject to an <inline-formula><tex-math notation=""LaTeX"">$\ell ^1$</tex-math></inline-formula> constraint, a pairwise <inline-formula> <tex-math notation=""LaTeX"">$\ell ^\infty$</tex-math></inline-formula> constraint, or a pairwise <inline-formula> <tex-math notation=""LaTeX"">$\ell ^1$</tex-math></inline-formula> constraint. Existing work, such as the Lasso formulation, has focused mainly on Lagrangian penalty approximations, which often require <italic>ad hoc</italic> or computationally expensive procedures to determine the penalization parameter. We depart from this approach and address the constrained problem directly via a splitting method. The structure of the method is that of the classical gradient-projection algorithm, which alternates a gradient step on the objective and a projection step onto the lower level set modeling the constraint. The novelty of our approach is that the projection step is implemented via an outer approximation scheme in which the constraint set is approximated by a sequence of simple convex sets consisting of the intersection of two half-spaces. Convergence of the iterates generated by the algorithm is established for a general smooth convex minimization problem with inequality constraints. Experiments on both synthetic and biological data show that our method outperforms penalty methods.",2017,IEEE Transactions on Signal Processing
Automated Variable Selection and Shrinkage for Day-Ahead Electricity Price Forecasting,"In day-ahead electricity price forecasting (EPF) variable selection is a crucial issue. Conducting an empirical study involving state-of-the-art parsimonious expert models as benchmarks, datasets from three major power markets and five classes of automated selection and shrinkage procedures (single-step elimination, stepwise regression, ridge regression, lasso and elastic nets), we show that using the latter two classes can bring significant accuracy gains compared to commonly-used EPF models. In particular, one of the elastic nets, a class that has not been considered in EPF before, stands out as the best performing model overall.",2016,Energies
Sparse Principal Component Analysis,"Principal component analysis (PCA) is widely used in data processing and dimensionality reduction. However, PCA suffers from the fact that each principal component is a linear combination of all the original variables, thus it is often difficult to interpret the results. We introduce a new method called sparse principal component analysis (SPCA) using the lasso (elastic net) to produce modified principal components with sparse loadings. We first show that PCA can be formulated as a regression-type optimization problem; sparse loadings are then obtained by imposing the lasso (elastic net) constraint on the regression coefficients. Efficient algorithms are proposed to fit our SPCA models for both regular multivariate data and gene expression arrays. We also give a new formula to compute the total variance of modified principal components. As illustrations, SPCA is applied to real and simulated data with encouraging results.",2006,Journal of Computational and Graphical Statistics
Selection of Spatial-Temporal Lattice Models: Assessing the Impact of Climate Conditions on a Mountain Pine Beetle Outbreak,"Insects are among the most significant indicators of a changing climate. Here we evaluate the impact of temperature, precipitation, and elevation on the tree-killing ability of an eruptive species of bark beetle in pine forests of British Columbia, Canada. We consider a spatial-temporal linear regression model and in particular, a new statistical method that simultaneously performs model selection and parameter estimation. This approach is penalized maximum likelihood estimation under a spatial-temporal adaptive Lasso penalty, paired with a computationally efficient algorithm to obtain approximate penalized maximum likelihood estimates. A simulation study shows that finite-sample properties of these estimates are sound. In a case study, we apply this approach to identify the appropriate components of a general class of landscape models which features the factors that propagate an outbreak. We interpret the results from ecological perspectives and compare our method with alternative model selection procedures.",2012,"Journal of Agricultural, Biological, and Environmental Statistics"
References,"1. National Kidney Foundation. K/DOQI clinical practice guidelines for chronic kidney disease: evaluation, classification, and stratification. Am J Kidney Dis 2002; 39: S1â€“266. 2. Astor BC, Matsushita K, Gansevoort RT et al. Lower estimated glomerular filtration rate and higher albuminuria are associated with mortality and end-stage renal disease. A collaborative meta-analysis of kidney disease population cohorts. Kidney Int 2011; 79: 1331â€“1340. 3. Gansevoort RT, Matsushita K, van der Velde M et al. Lower estimated GFR and higher albuminuria are associated with adverse kidney outcomes. A collaborative meta-analysis of general and high-risk population cohorts. Kidney Int 2011; 80: 93â€“104. 4. Matsushita K, van der Velde M, Astor BC et al. Association of estimated glomerular filtration rate and albuminuria with all-cause and cardiovascular mortality in general population cohorts: a collaborative metaanalysis. Lancet 2010; 375: 2073â€“2081. 5. van der Velde M, Matsushita K, Coresh J et al. Lower estimated glomerular filtration rate and higher albuminuria are associated with allcause and cardiovascular mortality. A collaborative meta-analysis of high-risk population cohorts. Kidney Int 2011; 79: 1341â€“1352. 6. Levey AS, Stevens LA, Coresh J. Conceptual model of CKD: applications and implications. Am J Kidney Dis 2009; 53: S4â€“16. 7. KDIGO AKI Work Group. KDIGO clinical practice guideline for acute kidney injury. Kidney inter., Suppl. 2012; 2: 1â€“138. 8. KDIGO GN Work Group. KDIGO clinical practice guideline for glomerulonephritis. Kidney inter., Suppl. 2012; 2: 139â€“274. 9. KDIGO CKD-MBD Work Group. KDIGO clinical practice guideline for the diagnosis, evaluation, prevention, and treatment of Chronic Kidney DiseaseMineral and Bone Disorder (CKD-MBD). Kidney Int Suppl 2009; 76(Suppl 113): S1â€“130. 10. KDIGO BP Work Group. KDIGO clinical practice guideline for the management of blood pressure in chronic kidney disease. Kidney inter., Suppl. 2012; 2: 337â€“414. 11. KDIGO Anemia Work Group. KDIGO clinical practice guideline for anemia in chronic kidney disease. Kidney inter., Suppl. 2012; 2: 279â€“335. 12. Herzog CA, Asinger RW, Berger AK et al. Cardiovascular disease in chronic kidney disease. A clinical update from Kidney Disease: Improving Global Outcomes (KDIGO). Kidney Int 2011; 80: 572â€“586. 13. Matzke GR, Aronoff GR, Atkinson AJ, Jr. et al. Drug dosing consideration in patients with acute and chronic kidney disease-a clinical update from Kidney Disease: Improving Global Outcomes (KDIGO). Kidney Int 2011; 80: 1122â€“1137. 14. Hsu CY, Ordonez JD, Chertow GM et al. The risk of acute renal failure in patients with chronic kidney disease. Kidney Int 2008; 74: 101â€“107. 15. Hailpern SM, Melamed ML, Cohen HW et al. Moderate chronic kidney disease and cognitive function in adults 20 to 59 years of age: Third National Health and Nutrition Examination Survey (NHANES III). J Am Soc Nephrol 2007; 18: 2205â€“2213. 16. James MT, Hemmelgarn BR, Wiebe N et al. Glomerular filtration rate, proteinuria, and the incidence and consequences of acute kidney injury: a cohort study. Lancet 2010; 376: 2096â€“2103. 17. James MT, Quan H, Tonelli M et al. CKD and risk of hospitalization and death with pneumonia. Am J Kidney Dis 2009; 54: 24â€“32. 18. Wilhelm-Leen ER, Hall YN, M KT et al. Frailty and chronic kidney disease: the Third National Health and Nutrition Evaluation Survey. Am J Med 2009; 122: 664â€“671 e662. 19. Levey AS, Coresh J. Chronic kidney disease. Lancet 2012; 379: 165â€“180. 20. Wesson L. Physiology of the human kidney. Grune & Stratton: New York, 1969. 21. Rowe JW, Andres R, Tobin JD. Letter: Age-adjusted standards for creatinine clearance. Ann Intern Med 1976; 84: 567â€“569. 22. Poggio ED, Rule AD, Tanchanco R et al. Demographic and clinical characteristics associated with glomerular filtration rates in living kidney donors. Kidney Int 2009; 75: 1079â€“1087. 23. Rule AD, Amer H, Cornell LD et al. The association between age and nephrosclerosis on renal biopsy among healthy adults. Ann Intern Med 2010; 152: 561â€“567. 24. Barai S, Gambhir S, Prasad N et al. Levels of GFR and protein-induced hyperfiltration in kidney donors: a single-center experience in India. Am J Kidney Dis 2008; 51: 407â€“414. 25. Eastwood JB, Kerry SM, Plange-Rhule J et al. Assessment of GFR by four methods in adults in Ashanti, Ghana: the need for an eGFR equation for lean African populations. Nephrol Dial Transplant 2010; 25: 2178â€“2187. 26. Jafar TH, Islam M, Jessani S et al. Level and determinants of kidney function in a South Asian population in Pakistan. Am J Kidney Dis 2011; 58: 764â€“772. 27. Stevens LA, Coresh J, Greene T et al. Assessing kidney functionâ€“ measured and estimated glomerular filtration rate. N Engl J Med 2006; 354: 2473â€“2483. 28. Remuzzi G, Benigni A, Remuzzi A. Mechanisms of progression and regression of renal lesions of chronic nephropathies and diabetes. J Clin Invest 2006; 116: 288â€“296. 29. KDIGO Transplant Work Group. KDIGO clinical practice guideline for the care of kidney transplant recipients. Am J Transplant 2009; 9 (Suppl 3): S1â€“155. 30. Levey AS, de Jong PE, Coresh J et al. The definition, classification, and prognosis of chronic kidney disease: a KDIGO Controversies Conference report. Kidney Int 2011; 80: 17â€“28. 31. Levey AS, Eckardt KU, Tsukamoto Y et al. Definition and classification of chronic kidney disease: a position statement from Kidney Disease: Improving Global Outcomes (KDIGO). Kidney Int 2005; 67: 2089â€“2100. 32. Eckardt KU, Berns JS, Rocco MV et al. Definition and classification of CKD: the debate should be about patient prognosisâ€“a position statement from KDOQI and KDIGO. Am J Kidney Dis 2009; 53: 915â€“920. 33. Eknoyan G. Chronic kidney disease definition and classification: no need for a rush to judgment. Kidney Int 2009; 75: 1015â€“1018. 34. El Nahas M. Cardio-Kidney-Damage: a unifying concept. Kidney Int 2010; 78: 14â€“18. 35. Levey AS, Astor BC, Stevens LA et al. Chronic kidney disease, diabetes, and hypertension: whatâ€™s in a name? Kidney Int 2010; 78: 19â€“22. 36. Winearls CG, Glassock RJ. Dissecting and refining the staging of chronic kidney disease. Kidney Int 2009; 75: 1009â€“1014. 37. Silva FG. The aging kidney: a review â€“ part I. Int Urol Nephrol 2005; 37: 185â€“205. 38. Silva FG. The aging kidney: a reviewâ€“part II. Int Urol Nephrol 2005; 37: 419â€“432. 39. Weinstein JR, Anderson S. The aging kidney: physiological changes. Adv Chronic Kidney Dis 2010; 17: 302â€“307. 40. King AJ, Levey AS. Dietary protein and renal function. J Am Soc Nephrol 1993; 3: 1723â€“1737. 41. Vehaskari VM. Orthostatic proteinuria. Arch Dis Child 1982; 57: 729â€“730. 42. Seikaly MG, Ho PL, Emmett L et al. Chronic renal insufficiency in children: the 2001 Annual Report of the NAPRTCS. Pediatr Nephrol 2003; 18: 796â€“804. 43. Hogg RJ, Furth S, Lemley KV et al. National Kidney Foundationâ€™s Kidney Disease Outcomes Quality Initiative clinical practice guidelines for chronic kidney disease in children and adolescents: evaluation, classification, and stratification. Pediatrics 2003; 111: 1416â€“1421. 44. Schwartz GJ, Brion LP, Spitzer A. The use of plasma creatinine concentration for estimating glomerular filtration rate in infants, children, and adolescents. Pediatr Clin North Am 1987; 34: 571â€“590. 45. Aperia A, Broberger O, Elinder G et al. Postnatal development of renal function in pre-term and full-term infants. Acta Paediatr Scand 1981; 70: 183â€“187. 46. Bueva A, Guignard JP. Renal function in preterm neonates. Pediatr Res 1994; 36: 572â€“577. 47. Fetterman GH, Shuplock NA, Philipp FJ et al. The Growth and Maturation of Human Glomeruli and Proximal Convolutions from Term to Adulthood: Studies by Microdissection. Pediatrics 1965; 35: 601â€“619. 48. Guignard JP, Torrado A, Da Cunha O et al. Glomerular filtration rate in the first three weeks of life. J Pediatr 1975; 87: 268â€“272. 49. Haycock GB. Development of glomerular filtration and tubular sodium reabsorption in the human fetus and newborn. Br J Urol 1998; 81 (Suppl 2): 33â€“38. 50. Gallini F, Maggio L, Romagnoli C et al. Progression of renal function in preterm neonates with gestational age o or 1â„4 32 weeks. Pediatr Nephrol 2000; 15: 119â€“124. r e f e r e n c e s http://www.kidney-international.org",2012,Kidney International Supplements
Super Resolution Image Reconstruction Using Linear Regression Regularized Sparse Representation,"This thesis addresses the generation and reconstruction of the high resolution (HR) image by using the single low resolution (LR) image and the linear coalition of sparse coefficients from a suitably chosen over-complete dictionary.The study of compressive sensing shows that under vague conditions the sparse representation of a signal can be effectively recovered from the downsampled version of the original signal. By training both LR and HR image patches simultaneously by coupled dictionary learning, we are enforcing the similarity between the sparse representation(SR) of LR and HR image patch pairs with respective to their LR and HR dictionaries. Literature survey suggests that different extracted features are used to compute the coefficients to boost the prediction accuracy of the HR image patch reconstruction. A set of Gabor filters has been employed to extract useful features from the LR dictionary. As the super resolution is an ill posed problem, in this thesis we have considered it as an optimization problem for getting the sparsest representation of image patches using linear regression regularized with L1 norm, known as a LASSO in statistics.Our method is found to be outperforming the other previous state of art methods in both quantitative and qualitative analysis. The results reveal that proposed method shows promising results in reconstructing the image textures and edges.",2015,
Incomplete Label Multitask Deep Learning for Spatio-temporal Event Subtype Forecasting ( Supplemental Material ) Related Work,"Spatio-temporal Event Forecasting. Most previous research in this area has focused on temporal event, in various studies on forecasting elections (Oâ€™Connor et al. 2010), stock market movements (Argyriou, Evgeniou, and Pontil 2007), disease outbreaks (Achrekar et al. 2011), and box office ticket sales (Arias, Arratia, and Xuriguera 2013). There are several existing approaches that provide true spatiotemporal resolution for predicted events. For example, Gerber et al. (Gerber 2014) utilized a logistic regression model for spatiotemporal event forecasting using topic-related tweet volumes as features, Ramakrishnan et al. (Ramakrishnan et al. 2014) built separate LASSO models for different locations to predict the occurrence of civil unrest events, and Zhao et al. (Zhao et al. 2015a) designed a new predictive model based on a topic model that jointly characterizes the temporal evolution in terms of both the semantics and geographical burstiness. However, all these focus on the occurrence only, and are not able to handle specific subtypes of future events. There are few existing reports of research on event subtype forecasting. Ning et al. (Ning et al. 2016) performs a primitive experiment in forecasting event populations, but the model proposed in this paper is designed for the distant supervised learning setting (e.g., multi-instance learning), which can not be applied directly to generic multiclass classification. Multi-task Learning. Multi-task learning (MTL) refers to models that learn multiple related tasks simultaneously to improve their generalization performance (Arias, Arratia, and Xuriguera 2013; Thrun and OSullivan 1998). For event forecasting, many MTL approaches have been proposed (Tutz 2003). For example, Evgeniou et al. (Evgeniou and Pontil 2004) proposed a regularized MTL framework that constrains all task models to be close to each other. The task relatedness can also be modeled by constraining multiple tasks to share a common underlying structure, e.g., a common set of features (Argyriou, Evgeniou, and Pontil 2007), or a common subspace (Ando and Zhang 2005). Zhao et al. (Zhao et al. 2015b) demonstrated the utility of applying a Multi-Task Learning framework for spatiotemporal event forecasting. Recent years, multi-task learning has also been well stud-",2018,
Prediction of forest unit volume based on hybrid feature selection and ensemble learning,"Aiming at the characteristics of forestry data with high dimensionality and complex samples, this paper explores an ensemble learning method suitable for predicting forest unit volume, which provides a scientific basis for forest resource management and decision-making. According to the real data provided by the National Forestry Science Data Sharing Service Platform, a FL-Stacking model based on hybrid feature selection and ensemble learning is proposed. Firstly, the model extracts features based on Filter-Lasso hybrid method, then constructs the prediction model of forest unit volume based on ensemble learning, and uses eight prediction models such as Linear SVM regression as the fusion basis model in the training set by Stacking scheme. The data are verified by 10 folds cross-validation. Finally, the fusion and optimization of the basic model are carried out. The experimental results show that the optimal accuracy of the single model is 83.81%, the multi-model predicted by FL-Stacking model is 84.55%, and the R2 value is increased by 0.74 percentage points. The comparative analysis results of different models on real data sets show that the FL-Stacking integrated prediction model proposed in this paper has a high accuracy in estimating forest unit volume, and has a great practical research value.",2020,Evolutionary Intelligence
Discrete Data Analysis with R : Visualization and Modeling Techniques for Categorical and Count Data,"This book makes a very useful contribution by focusing on graphical methods for portraying discrete data and the results of fitting models to such data. Existing books on the analysis of discrete data pay relatively little attention to graphics. This bookâ€™s main emphasis is on categorical data and logistic and loglinear models for them, but two chapters deal with count data, including dealing with the common existence of overdispersion and zero-inflation. The authors show three types of plots: Data plots, Model plots, and Data+Model plots that combine the two, showing how well the model fits the data and portraying the uncertainty of estimated response means. The book has three sections: Getting Started introduces graphical methods for categorical data, working with the data in various forms (e.g., types of contingency tables), and fitting and graphing discrete distributions with useful displays, such as â€œrootograms,â€ â€œOrd plots,â€ and â€œPoissonness plots,â€ and extensions due to Dave Hoaglin and John Tukey for other distributions. Exploratory and Hypothesis-Testing Methods presents displays and plots for two-way contingency tables, mosaic displays for multiway contingency tables, and plots such as biplots for correspondence analysis. Model-Building Methods presents plots relevant for standard models for discrete data, emphasizing logistic regression and its extensions for multinomial data, loglinear models for contingency tables, and generalized linear models for count data and their extensions. The 11 chapters each have exercises for practicing the methods and their graphic displays. As the section outline suggests, the book covers the most popular statistical methods for analyzing discrete data. Among the types of graphical displays not presented are classification trees, graphical models for conditional independence structure, and depictions of estimates for models with large numbers of predictors (such as lasso estimates as functions of a smoothing parameter). Discrete modeling methods not covered include quasi-likelihood methods, such as generalized estimating equations for marginal models with multivariate responses, generalized linear mixed models, and Bayesian inference. But I believe it was sensible for the authors to emphasize graphics for basic methods, such as contingency table analysis and ordinary logistic regression, as the book already contains an impressive amount of material and will be very useful for most discrete-data analyses conducted by applied statisticians. Also, the authors consider many nonstandard models within these general classes, such as ordinal loglinear models and specialized models for square contingency tables. Probably, the reason graphics have received relatively little attention in existing books for categorical data is because of the challenge of reducing even a bivariate association between qualitative variables to a simple graphic in which the key information is quickly clear to the eye. It is easier to do this in the context of logistic regression with quantitative explanatory variables, in which case many of the plots resemble standard ones from normal regression modeling. Examples of useful plots include influence and diagnostic plots (e.g., plotting studentized residuals against hat values, with Cookâ€™s distance values portrayed by the size of a bubble) and added-variable plots. Especially helpful for portraying practical implications of the model parameter estimates are â€œeffect plotsâ€ that portray how the probability of an outcome varies across values",2016,
TIMSS 2011 Student and Teacher Predictors for Mathematics Achievement Explored and Identified via Elastic Net,"A substantial body of research has been conducted on variables relating to students' mathematics achievement with TIMSS. However, most studies have employed conventional statistical methods, and have focused on selected few indicators instead of utilizing hundreds of variables TIMSS provides. This study aimed to find a prediction model for students' mathematics achievement using as many TIMSS student and teacher variables as possible. Elastic net, the selected machine learning technique in this study, takes advantage of both LASSO and ridge in terms of variable selection and multicollinearity, respectively. A logistic regression model was also employed to predict TIMSS 2011 Korean 4th graders' mathematics achievement. Ten-fold cross-validation with mean squared error was employed to determine the elastic net regularization parameter. Among 162 TIMSS variables explored, 12 student and 5 teacher variables were selected in the elastic net model, and the prediction accuracy, sensitivity, and specificity were 76.06, 70.23, and 80.34%, respectively. This study showed that the elastic net method can be successfully applied to educational large-scale data by selecting a subset of variables with reasonable prediction accuracy and finding new variables to predict students' mathematics achievement. Newly found variables via machine learning can shed light on the existing theories from a totally different perspective, which in turn propagates creation of a new theory or complement of existing ones. This study also examined the current scale development convention from a machine learning perspective.",2018,Frontiers in Psychology
Bridging Computational Features Toward Multiple Semantic Features with Multi-task Regression: A Study of CT Pulmonary Nodules,"The gap between the computational and semantic features is the one of major factors that bottlenecks the computer-aided diagnosis (CAD) performance from clinical usage. To bridge such gap, we propose to utilize the multi-task regression (MTR) scheme that leverages heterogeneous computational features derived from deep learning models of stacked denoising autoencoder (SDAE) and convolutional neural network (CNN) as well as Haar-like features to approach 8 semantic features of lung CT nodules. We regard that there may exist relations among the semantic features of â€œspiculationâ€, â€œtextureâ€, â€œmarginâ€, etc., that can be exploited with the multi-task learning technique. The Lung Imaging Database Consortium (LIDC) data is adopted for the rich annotations, where nodules were quantitatively rated for the semantic features from many radiologists. By treating each semantic feature as a task, the MTR selects and regresses the heterogeneous computational features toward the radiologistsâ€™ ratings with 10 fold cross-validation evaluation on the randomly selected LIDC 1400 nodules. The experimental results suggest that the predicted semantic scores from MTR are closer to the radiologistsâ€™ rating than the predicted scores from single-task LASSO and elastic net regression methods. The proposed semantic scoring scheme may provide richer quantitative assessments of nodules for deeper analysis and support more sophisticated clinical content retrieval in medical databases.",2016,
The Instability of Cross-Validated Lasso,"In a situation where the number of available covariates greatly exceeds the number of observations, the fitting of a regression model to explain the connection between the response and the explanatory variables can be a challenging task. The problem can be compared to a set of equations with more unknowns than there are equations and requires application of a regularisation method to result in a useful solution. There are several such methods, with different properties. This thesis focuses on one such method: the Lasso in combination with crossvalidation (CV) to determine the level of regularisation. Specifically, we consider the method when applied on survival data where the covariates are thousands of gene expression levels. The combination of Lasso and CV proves to be unstable in the sense that repeated application of the standard R implementation often give varying results. This studyâ€™s main focus is to investigate what the causes of this instability may be. Data was simulated to map the factors that affect the stability. The simulated data setsâ€™ properties are easy to control and the effects on the regularisation results are easily observed. The tests show that the CV process cause marked instability (varying results) when the division into training and test sets involve test sets with size larger than one. Moreover, the stability of the regularisation depends on the properties of the data set. A unique prediction result is preferable to easily choose a prognostic gene signature. However, a range of signatures from repeated regularisations can be utilised to indicate the accuracy of the suggested signature. This thesis maps several factors that affect the stability of Lasso and CV, and will hopefully contribute to caution be a warning flag when utilising the Lasso method to find a prognostic model.",2013,
Risk factor selection in rate making: EM adaptive LASSO for zero-inflated poisson regression models.,"Risk factor selection is very important in the insurance industry, which helps precise rate making and studying the features of high-quality insureds. Zero-inflated data are common in insurance, such as the claim frequency data, and zero-inflation makes the selection of risk factors quite difficult. In this article, we propose a new risk factor selection approach, EM adaptive LASSO, for a zero-inflated Poisson regression model, which combines the EM algorithm and adaptive LASSO penalty. Under some regularity conditions, we show that, with probability approaching 1, important factors are selected and the redundant factors are excluded. We investigate the finite sample performance of the proposed method through a simulation study and the analysis of car insurance data from SAS Enterprise Miner database.",2014,Risk analysis : an official publication of the Society for Risk Analysis
Model selection and parameter estimation of a multinomial logistic regression model,"In the multinomial regression model, we consider the methodology for simultaneous model selection and parameter estimation by using the shrinkage and LASSO (least absolute shrinkage and selection operation) [R. Tibshirani, Regression shrinkage and selection via the LASSO, J. R. Statist. Soc. Ser. B 58 (1996), pp. 267â€“288] strategies. The shrinkage estimators (SEs) provide significant improvement over their classical counterparts in the case where some of the predictors may or may not be active for the response of interest. The asymptotic properties of the SEs are developed using the notion of asymptotic distributional risk. We then compare the relative performance of the LASSO estimator with two SEs in terms of simulated relative efficiency. A simulation study shows that the shrinkage and LASSO estimators dominate the full model estimator. Further, both SEs perform better than the LASSO estimators when there are many inactive predictors in the model. A real-life data set is used to illustrate the suggested shrinkage and LASSO estimators.",2014,Journal of Statistical Computation and Simulation
Estimation of the Endotracheal Tube Pressure Drop During HFPV: A Flow-Independent Model,"High frequency percussive ventilation (HFPV) is a non-conventional ventilatory modality which has proven very effective and safe in patients with acute respiratory failure. HFPV ventilator measures airway pressure that represents the sum of the endotracheal tube pressure drop and the tracheal pressure dissipated to inflate a lung. The estimation of the difference between the peak airway and tracheal pressure âˆ†Pp may be very useful to the clinician to avoid lung injury. The aim of this study is to provide a comprehensive solution for estimation of âˆ†Pp in adult endotracheal tubes, by developing a flow-independent model, based on endotracheal tube size, ventilator set parameters (i.e. peak pressures, pulsatile frequencies) and patientâ€™s respiratory system resistance and compliance. The model for the estimation of âˆ†Pp was determined by using the Least Absolute Shrinkage and Selection Operator (LASSO) regularized least-squares regression technique. The identified model was successively assessed on test data set.",2016,
The degrees of freedom of penalized l1 minimization,"In this paper, we investigate the degrees of freedom (df) of penalized l1 minimization (also known as the Lasso) for linear regression models. We give a closed-form expression of the degrees of freedom of the Lasso response. Namely, we show that for any given Lasso regularization parameter$ \lambda$ and any observed data y belongs to a set of full measure, the cardinal of the support of a particular solution of the Lasso problem is an unbiased estimator of the degrees of freedom of the Lasso response. This work is achieved without any assumption on the uniqueness of the Lasso solution. Thus, our result remains true for both the underdetermined and the overdetermined case studied originally in Zou et al.. We also prove that a key result in Zou et al. is not true by providing a simple counterexample. An effective estimator of the number of degrees of freedom may have several applications including an objectively guided choice of the regularization parameter in the Lasso through the SURE framework.",2011,ArXiv
Identification of Novel Genes in Human Airway Epithelial Cells associated with Chronic Obstructive Pulmonary Disease (COPD) using Machine-Based Learning Algorithms,"The aim of this project was to identify candidate novel therapeutic targets to facilitate the treatment of COPD using machine-based learning (ML) algorithms and penalized regression models. In this study, 59 healthy smokers, 53 healthy non-smokers and 21 COPD smokers (9 GOLD stage I and 12 GOLD stage II) were included (nâ€‰=â€‰133). 20,097 probes were generated from a small airway epithelium (SAE) microarray dataset obtained from these subjects previously. Subsequently, the association between gene expression levels and smoking and COPD, respectively, was assessed using: AdaBoost Classification Trees, Decision Tree, Gradient Boosting Machines, Naive Bayes, Neural Network, Random Forest, Support Vector Machine and adaptive LASSO, Elastic-Net, and Ridge logistic regression analyses. Using this methodology, we identified 44 candidate genes, 27 of these genes had been previously been reported as important factors in the pathogenesis of COPD or regulation of lung function. Here, we also identified 17 genes, which have not been previously identified to be associated with the pathogenesis of COPD or the regulation of lung function. The most significantly regulated of these genes included: PRKAR2B, GAD1, LINC00930 and SLITRK6. These novel genes may provide the basis for the future development of novel therapeutics in COPD and its associated morbidities.",2018,Scientific Reports
Inflammatory-Related Genetic Variants in Non-Muscle-Invasive Bladder Cancer Prognosis: A Multimarker Bayesian Assessment.,"BACKGROUND
Increasing evidence points to the role of tumor immunologic environment on urothelial bladder cancer prognosis. This effect might be partly dependent on the host genetic context. We evaluated the association of SNPs in inflammation-related genes with non-muscle-invasive bladder cancer (NMIBC) risk-of-recurrence and risk-of-progression.


METHODS
We considered 822 NMIBC included in the SBC/EPICURO Study followed-up >10 years. We selected 1,679 SNPs belonging to 251 inflammatory genes. The association of SNPs with risk-of-recurrence and risk-of-progression was assessed using Cox regression single-marker (SMM) and multimarker methods (MMM) Bayes A and Bayesian LASSO. Discriminative abilities of the models were calculated using the c index and validated with bootstrap cross-validation procedures.


RESULTS
While no SNP was found to be associated with risk-of-recurrence using SMM, three SNPs in TNIP1, CD5, and JAK3 showed very strong association with posterior probabilities >90% using MMM. Regarding risk-of-progression, one SNP in CD3G was significantly associated using SMM (HR, 2.69; P = 1.55 Ã— 10(-5)) and two SNPs in MASP1 and AIRE, showed a posterior probability â‰¥80% with MMM. Validated discriminative abilities of the models without and with the SNPs were 58.4% versus 60.5% and 72.1% versus 72.8% for risk-of-recurrence and risk-of-progression, respectively.


CONCLUSIONS
Using innovative analytic approaches, we demonstrated that SNPs in inflammatory-related genes were associated with NMIBC prognosis and that they improve the discriminative ability of prognostic clinical models for NMIBC.


IMPACT
This study provides proof of concept for the joint effect of genetic variants in improving the discriminative ability of clinical prognostic models. The approach may be extended to other diseases. Cancer Epidemiol Biomarkers Prev; 25(7); 1144-50. Â©2016 AACR.",2016,"Cancer epidemiology, biomarkers & prevention : a publication of the American Association for Cancer Research, cosponsored by the American Society of Preventive Oncology"
Identifying key radiogenomic associations between DCE-MRI and micro-RNA expressions for breast cancer,"Understanding the key radiogenomic associations for breast cancer between DCE-MRI and micro-RNA expressions is the foundation for the discovery of radiomic features as biomarkers for assessing tumor progression and prognosis. We conducted a study to analyze the radiogenomic associations for breast cancer using the TCGA-TCIA data set. The core idea that tumor etiology is a function of the behavior of miRNAs is used to build the regression models. The associations based on regression are analyzed for three study outcomes: diagnosis, prognosis, and treatment. The diagnosis group consists of miRNAs associated with clinicopathologic features of breast cancer and significant aberration of expression in breast cancer patients. The prognosis group consists of miRNAs which are closely associated with tumor suppression and regulation of cell proliferation and differentiation. The treatment group consists of miRNAs that contribute significantly to the regulation of metastasis thereby having the potential to be part of therapeutic mechanisms. As a first step, important miRNA expressions were identified and their ability to classify the clinical phenotypes based on the study outcomes was evaluated using the area under the ROC curve (AUC) as a figure-of-merit. The key mapping between the selected miRNAs and radiomic features were determined using least absolute shrinkage and selection operator (LASSO) regression analysis within a two-loop leave-one-out cross-validation strategy. These key associations indicated a number of radiomic features from DCE-MRI to be potential biomarkers for the three study outcomes.",2017,
Consistent selection via the Lasso for high dimensional approximating regression models,"In this article we investigate consistency of selection in regression models via the popular Lasso method. Here we depart from the traditional linear regression assumption and consider approximations of the regression function $f$ with elements of a given dictionary of $M$ functions. The target for consistency is the index set of those functions from this dictionary that realize the most parsimonious approximation to $f$ among all linear combinations belonging to an $L_2$ ball centered at $f$ and of radius $r_{n,M}^2$. In this framework we show that a consistent estimate of this index set can be derived via $\ell_1$ penalized least squares, with a data dependent penalty and with tuning sequence $r_{n,M}>\sqrt{\log(Mn)/n}$, where $n$ is the sample size. Our results hold for any $1\leq M\leq n^{\gamma}$, for any $\gamma>0$.",2008,arXiv: Statistics Theory
Prediction of Insurance Claim Severity Loss Using Regression Models,"The objective of this work is to predict the severity loss value of an insurance claim using machine learning regression techniques. The high dimensional data used for this research work is obtained from Allstate insurance company which consists of 116 categorical and 14 continuous predictor variables. We implemented Linear regression, Random forest regression (RFR), Support vector regression (SVR) and Feed forward neural network (FFNN) for this problem. The performance and accuracy of the models are compared using mean squared error (MSE) value and coefficient of determination (Rsquare) value. We predicted the claim severity loss value with a MSE value of 0.390 and a Rsquare value 0.562 using bagged RFR model. In addition where applicable, the final loss value was also predicted with an error of 0.440 using FFNN regression model. We also demonstrate the use of lasso regularization to avoid over-fitting for some of the regression models.",2017,
Transpiration dynamics support resource partitioning in African savanna trees and grasses,"It is still far from clear whether and to what extent trees and grasses partition soil moisture in tropical savannas. A major reason for this is that we don't know how snapshot data on rooting differences translate into ecologically relevant patterns of water use at seasonal scales. We used stable isotopes in soil and stem water to quantify functional rooting profiles in grasses and two tree species in a South African savanna. Concurrently, we measured tree sap-flow velocity, grass canopy temperature (a transpiration correlate), and soil moisture content at multiple depths over the course of a growing season. We used lasso regression to identify the dominant soil moisture layers driving daily variation in tree and grass water-use metrics while controlling for weather variables. We found clear rooting depth differences between grasses (shallow) and trees (deep) from the isotopic data, and these patterns were strongly supported by the water-use data, which showed that grasses and trees predominantly respond...",2015,Ecology
The Informational Content of the Term-Spread in Forecasting the U.S. Inflation Rate: A Nonlinear Approach,"The difficulty in modelling inflation and the significance in discovering the underlying data generating process of inflation is expressed in an ample literature regarding inflation forecasting. In this paper we evaluate nonlinear machine learning and econometric methodologies in forecasting the U.S. inflation based on autoregressive and structural models of the term structure. We employ two nonlinear methodologies: the econometric Least Absolute Shrinkage and Selection Operator (LASSO) and the machine learning Support Vector Regression (SVR) method. The SVR has never been used before in inflation forecasting considering the term--spread as a regressor. In doing so, we use a long monthly dataset spanning the period 1871:1 â€“ 2015:3 that covers the entire history of inflation in the U.S. economy. For comparison reasons we also use OLS regression models as benchmark. In order to evaluate the contribution of the term-spread in inflation forecasting in different time periods, we measure the out-of-sample forecasting performance of all models using rolling window regressions. Considering various forecasting horizons, the empirical evidence suggests that the structural models do not outperform the autoregressive ones, regardless of the modelâ€™s method. Thus we conclude that the term-spread models are not more accurate than autoregressive ones in inflation forecasting.",2017,Journal of Forecasting
New framework that uses patterns and relations to understand terrorist behaviors,"A new framework is proposed to understand the activity patterns and relations.A new similarity function is proposed to estimate the relationships among events.The new model is proposed to estimate the importance of the features.Over-training in the model is prevented by using the LASSO regularization.The government can control the terrorist behaviors using the intelligent framework. Terrorism is a complex phenomenon with high uncertainties in user strategy. The uncertain nature of terrorism is a main challenge in the design of counter-terrorism policy. Government agencies (e.g., CIA, FBI, NSA, etc.) cannot always use social media and telecommunications to capture the intentions of terrorists because terrorists are very careful in the use of these environments to plan and prepare attacks. To address this issue, this research aims to propose a new framework by defining the useful patterns of suicide attacks to analyze the terrorist activity patterns and relations, to understand behaviors and their future moves, and finally to prevent potential terrorist attacks. In the framework, a new network model is formed, and the structure of the relations is analyzed to infer knowledge about terrorist attacks. More specifically, an Evolutionary Simulating Annealing Lasso Logistic Regression (ESALLOR) model is proposed to select key features for similarity function. Subsequently, a new weighted heterogeneous similarity function is proposed to estimate the relationships among attacks. Moreover, a graph-based outbreak detection is proposed to define hazardous places for the outbreak of violence. Experimental results demonstrate the effectiveness of our framework with high accuracy (more than 90% accuracy) for finding patterns when compared with that of actual terrorism events in 2014 and 2015. In conclusion, by using this intelligent framework, governments can understand automatically how terrorism will impact future events, and governments can control terrorists behaviors and tactics to reduce the risk of future events.",2017,Expert Syst. Appl.
Scalable sparse machine learning methods for big data,"Sparse machine learning models have become increasingly popular in analyzing high-dimensional data. With the evolving era of Big Data, ultrahigh-dimensional, large-scale data sets are constantly collected in many areas such as genetics, genomics, biomedical imaging, social media analysis, and high-frequency finance. Mining valuable information efficiently from these massive data sets requires not only novel statistical models but also advanced computational techniques. This thesis focuses on the development of scalable sparse machine learning methods to facilitate Big Data analytics. Built upon the feature screening technique, the first part of this thesis proposes a family of hybrid safe-strong rules (HSSR) that incorporate safe screening rules into the sequential strong rule to remove unnecessary computational burden for solving the lasso-type models. We present two instances of HSSR, namely SSR-Dome and SSR-BEDPP, for the standard lasso problem. We further extend SSR-BEDPP to the elastic net and group lasso problems to demonstrate the generalizability of the hybrid screening idea. In the second part, we design and implement an R package called biglasso to extend the lasso model fitting to Big Data in R. Our package biglasso utilizes memory-mapped files to store the massive data on the disk, only reading data into memory when necessary during model fitting, and is thus able to handle data-larger-than-RAM cases seamlessly. Moreover, itâ€™s built upon our redesigned algorithm incorporated with the proposed HSSR screening, making it much more memoryand computation-efficient than existing R packages. Extensive numerical experiments with synthetic and real data sets are conducted in both parts to show the effectiveness of the proposed methods. In the third part, we consider a novel statistical model, namely the overlapping group logistic regression model, that allows for selecting important groups of features",2017,
The Third Special Issue on Advances in Mixture Models,"There is little doubt that mixture models are now established as a standard approach in manymodelling scenarios. Their ubiquity owes much to their simple, and often meaningful, interpretation and the ease with which the mixture paradigm allows models to be extended to capture heterogeneity while simultaneously providing a clustering, or classification, of units. The apparent simplicity of the EM algorithm (Dempster et al., 1977) for mixtures has also been pivotal in this development, although problems with the performance of this and its implementation have also spurred many new developments in computational approaches for fittingmixtures. CSDA is a natural home for papers related tomixturemodels and as well as a steady flow of papers in regular issues there have been two previous special issues devoted to advances in mixture models. The first of these special issues (volume 51, issue 11, 2007) contained 20 papers and in the second special issue (volume 71, issues 1â€“2, 2014) a further 19 papers appeared on very diverse methodological developments and applications. This is now continued in this third special issue, where once again we are able to present 17 papers showing the scope of the mixture model paradigm and the ingenuity of work in this area. One issue in using mixture models for clustering is that there is no guarantee that mixture components will correspond to well defined clusters. For example, in using Gaussian finite mixture models two or more mixture components may be needed to reasonably approximate the distribution within a homogeneous group of observations. Scrucca (2016) addresses this problemusing the identification of high density regions to form cluster cores and shows that this approach improves the identification of non-Gaussian clusters. Oâ€™Hagan et al. (2016) consider the same issue but bymoving away from the Gaussian distribution and its implied elliptical group structure. Using a meanâ€“variance mixture of multivariate normal distributions with an inverse Gaussian mixing distribution (MNIG) provides a more flexible family of component distributions that can be skewed and have fatter tails than the normal distribution. The range of MNIG models is extended to include various eigendecomposed covariance structures and they provide a variation on the Kolmogorovâ€“Smirnov test to assess goodness of fit. Novel applications of mixture clustering continue to provide interesting challenges. Melnykov (2016) considers clickstream data, which are the sequences of visited web-sites or categories taken by individual users. The aim is to use these data to group users according to their preferences and subsequently target themwith related items and products. The problem hasmany particular aspects and difficulties; the large number of different categories, the time element, the varying length of the sequences. The approach adopted here is to use biclustering of both categories and userswith amixture of firstorder Markov models to capture the time element. In another application of biclustering, FernÃ¡ndez et al. (2016) consider ordinal responses and use finitemixtures of the stereotypemodel (Anderson, 1984). They develop estimationmethods using the EM algorithm and consider clustering of individuals (rows), the ordinal responses (columns), and row and columns simultaneously, illustrating their approach with examples from student feedback and ecology. Functional data analysis (Ramsay and Silverman, 1997, 2002) is widely used for the study of curves and more recently surfaces, although clustering and classification has concentrated on univariate functions. Nguyen et al. (2016) combine recent techniques in spatial spline regression with finite mixture and mixed effects models to provide techniques for the fitting, clustering, and discrimination classification of surfaces and demonstrate these in the context of handwritten character recognition. Functional data analysis also features in the work of Ciarleglio and Ogden (2016) where they extend the classical finite mixture regression model to incorporate functional predictors using a wavelet-based approach. Estimation again involves an EM algorithm approach with lasso penalization for regularization and feature selection. The method is applied to diffusion tensor imaging data frommultiple sclerosis patients and is able to identify two distinct groups with differing cognitive ability.",2016,Comput. Stat. Data Anal.
A New Approach to Predict Progression-free Survival in Stage IV EGFR-mutant NSCLC Patients with EGFR-TKI Therapy.,"Purpose: We established a CT-derived approach to achieve accurate progression-free survival (PFS) prediction to EGFR tyrosine kinase inhibitors (TKI) therapy in multicenter, stage IV EGFR-mutated non-small cell lung cancer (NSCLC) patients.Experimental Design: A total of 1,032 CT-based phenotypic characteristics were extracted according to the intensity, shape, and texture of NSCLC pretherapy images. On the basis of these CT features extracted from 117 stage IV EGFR-mutant NSCLC patients, a CT-based phenotypic signature was proposed using a Cox regression model with LASSO penalty for the survival risk stratification of EGFR-TKI therapy. The signature was validated using two independent cohorts (101 and 96 patients, respectively). The benefit of EGFR-TKIs in stratified patients was then compared with another stage-IV EGFR-mutant NSCLC cohort only treated with standard chemotherapy (56 patients). Furthermore, an individualized prediction model incorporating the phenotypic signature and clinicopathologic risk characteristics was proposed for PFS prediction, and also validated by multicenter cohorts.Results: The signature consisted of 12 CT features demonstrated good accuracy for discriminating patients with rapid and slow progression to EGFR-TKI therapy in three cohorts (HR: 3.61, 3.77, and 3.67, respectively). Rapid progression patients received EGFR TKIs did not show significant difference with patients underwent chemotherapy for progression-free survival benefit (P = 0.682). Decision curve analysis revealed that the proposed model significantly improved the clinical benefit compared with the clinicopathologic-based characteristics model (P < 0.0001).Conclusions: The proposed CT-based predictive strategy can achieve individualized prediction of PFS probability to EGFR-TKI therapy in NSCLCs, which holds promise of improving the pretherapy personalized management of TKIs. Clin Cancer Res; 24(15); 3583-92. Â©2018 AACR.",2018,Clinical cancer research : an official journal of the American Association for Cancer Research
A lava attack on the recovery of sums of dense and sparse signals,"Common high-dimensional methods for prediction rely on having either a sparse signal model, a model in which most parameters are zero and there are a small number of non-zero parameters that are large in magnitude, or a dense signal model, a model with no large parameters and very many small non-zero parameters. We consider a generalization of these two basic models, termed here a â€œsparse + denseâ€ model, in which the signal is given by the sum of a sparse signal and a dense signal. Such a structure poses problems for traditional sparse estimators, such as the lasso, and for traditional dense estimation methods, such as ridge estimation. We propose a new penalization-based method, called lava, which is computationally efficient. With suitable choices of penalty parameters, the proposed method strictly dominates both lasso and ridge. We derive analytic expressions for the finite-sample risk function of the lava estimator in the Gaussian sequence model. We also provide a deviation bound for the prediction risk in the Gaussian regression model with fixed design. In both cases, we provide Stein's unbiased estimator for lava's prediction risk. A simulation example compares the performance of lava to lasso, ridge, and elastic net in a regression example using data-dependent penalty parameters and illustrates lava's improved performance relative to these benchmarks.",2015,ArXiv
Transmission Line Fault Classification Based on Dynamic State Estimation and Support Vector Machine,"The transmission line is an essential part of the power system, while the faults in the transmission line are inevitable due to a number of reasons, such as lightning, tree limps, wind, etc. This paper presents a technique to classify the short circuit faults in transmission lines, which distinguishes fault phases and fault types, such as phase A to ground fault and phase A to phase B fault. The proposed method combines the dynamic state estimation (DSE) based protection technique and Support Vector Machine (SVM) to achieve an accurate classification model with physical foundation. DSE utilizes measurement data from merging units and the model of transmission line to obtain estimated states of the line. The differences of measurements and estimated values are referred as residuals. Different fault types possess different patterns of residuals and include features that can be used in a classification scheme. Therefore, these residuals are applied to SVM to set up classification models. A feature selection method based on Lasso regression is deployed to increase the training speed for SVM. The performance of the technique is evaluated using simulation test cases. Different fault types with different fault impedance and fault locations are included in the test cases. The test results show that the classifiers are able to accurately categorize the fault types, which is very useful for protection functions.",2018,2018 North American Power Symposium (NAPS)
Perbedaan Metode Geographically Weighted Lasso (gwl)-lokal Dan Geographically Weighted Lasso (gwl) Global Dalam Mengatasi Kasus Multikolinieritas Pada Model Geographically Weighted Regression (gwr),"Salah satu metode yang digunakan untuk mengatasi multikolinieritas lokal pada model Geographically Weighted Regression adalah metode Geographically Weighted Lasso (GWL). GWL merupakan pengembangan dari metode GWR(Geographically Weighted Regression) dengan menambahkan metode Least Absolute Shrinkage and Selection Operator(Lasso) pada model karena GWR belum mampu mengatasi kasus multikolinieritas. GWL terdiri dari dua metode yaitu GWL Lokal dan GWL Global. Pendeteksi adanya multikolinieritas adalah nilai VIF (Variance Inflation Factor) yang Â lebih dari 10.GWL menggunakan parameter shrinkage sebagai batasan lasso untuk menduga parameter. Pada pemodelan data tingkat kemiskinan dengan metode GWL Lokal didapatkan model yang berbeda-beda di setiap wilayah, sedangkan pada metode GWL Global didapatkan satu model untuk keseluruhan wilayah Jawa Timur. Berdasarkan nilai MSE dapat disimpulkan bahwa metode GWL Lokal lebih efisien untuk memodelkan data tingkat kemiskinan dikarenakan terdapat faktor keheterogenitas spasial dan perbedaan geografis di setiap wilayah yang berpengaruh terhadap tingkat kemiskinan JawaTimur. Kata kunci: multikolinieritas lokal, GWL Lokal, GWL Global, tingkat kemiskinan",2013,
Error modeling for surrogates of dynamical systems using machine learning,"Summary 
A machine-learning-based framework for modeling the error introduced by surrogate models of parameterized dynamical systems is proposed. The framework entails the use of high-dimensional regression techniques (e.g., random forests, LASSO) to map a large set of inexpensively computed â€˜error indicatorsâ€™ (i.e., features) produced by the surrogate model at a given time instance to a prediction of the surrogate-model error in a quantity of interest (QoI). This eliminates the need for the user to hand-select a small number of informative features. The methodology requires a training set of parameter instances at which the time-dependent surrogate-model error is computed by simulating both the high-fidelity and surrogate models. Using these training data, the method first determines regression-model locality (via classification or clustering), and subsequently constructs a â€˜localâ€™ regression model to predict the time-instantaneous error within each identified region of feature space. We consider two uses for the resulting error model: (1) as a correction to the surrogate-model QoI prediction at each time instance, and (2) as a way to statistically model arbitrary functions of the time-dependent surrogate-model error (e.g., time-integrated errors). We apply the proposed framework to model errors in reduced-order models of nonlinear oilâ€“water subsurface flow simulations, with time-varying well-control (bottom-hole pressure) parameters. The reduced-order models used in this work entail application of trajectory piecewise linearization in conjunction with proper orthogonal decomposition. When the first use of the method is considered, numerical experiments demonstrate consistent improvement in accuracy in the time-instantaneous QoI prediction relative to the original surrogate model, across a large number of test cases. When the second use is considered, results show that the proposed method provides accurate statistical predictions of the time- and well-averaged errors. This article is protected by copyright. All rights reserved.",2017,International Journal for Numerical Methods in Engineering
