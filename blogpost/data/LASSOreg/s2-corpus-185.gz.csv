title,abstract,year,journal
Evaluation and Validation of Plasma Proteins Using Two Different Protein Detection Methods for Early Detection of Colorectal Cancer,"OBJECTIVE
Plasma protein biomarkers could be an efficient alternative for population-based screening for early detection of colorectal cancer (CRC). The objective of this study was to evaluate and validate plasma proteins individually and as a signature for early detection of CRC.


METHODS
In a three-stage design, proteins were measured firstly by liquid chromatography/multiple reaction monitoring-mass spectrometry (LC/MRM-MS) and later by proximity extension assay (PEA) in a discovery set consisting of 96 newly diagnosed CRC cases and 94 controls free of neoplasms at screening colonoscopy. Two algorithms (one for each measurement method) were derived by Lasso regression and .632+ bootstrap based on 11 proteins that were included in both the LC/MRM-MS and PEA measurements. Additionally, another algorithm was constructed from the same eleven biomarkers plus amphireglin, the most promising protein marker in the PEA measurements that had not been available from the LC/MRM-MS measurements. Lastly the three prediction signatures were validated with PEA in independent samples of participants of screening colonoscopy (CRC (n = 56), advanced adenoma (n = 101), and participants free of neoplasm (n = 102)).


RESULTS
The same four proteins were included in all three prediction signatures; mannan binding lectin serine protease 1, osteopontin, serum paraoxonase lactonase 3 and transferrin receptor protein 1, and the third prediction signature additionally included amphiregulin. In the independent validation set from a true screening setting, the five-marker blood-based signature including AREG presented areas under the curves of 0.82 (95% CI, 0.74-0.89), 0.86 (95% CI, 0.77-0.92) and 0.76 (95% CI, 0.64-0.86) for all, early and late stages CRC, respectively.


CONCLUSION
Two different measurement methods consistently identified four protein markers and an algorithm additionally including amphiregulin, a marker measured by PEA only, showed promising performance for detecting early stage CRC in an independent validation in a true screening setting. These proteins may be potential candidates for blood-based tests for early detection of CRC.",2019,Cancers
Sparse Learning over Infinite Subgraph Features,"We present a supervised-learning algorithm from graph data (a set of graphs) for arbitrary twice-differentiable loss functions and sparse linear models over all possible subgraph features. To date, it has been shown that under all possible subgraph features, several types of sparse learning, such as Adaboost, LPBoost, LARS/LASSO, and sparse PLS regression, can be performed. Particularly emphasis is placed on simultaneous learning of relevant features from an infinite set of candidates. We first generalize techniques used in all these preceding studies to derive an unifying bounding technique for arbitrary separable functions. We then carefully use this bounding to make block coordinate gradient descent feasible over infinite subgraph features, resulting in a fast converging algorithm that can solve a wider class of sparse learning problems over graph data. We also empirically study the differences from the existing approaches in convergence property, selected subgraph features, and search-space sizes. We further discuss several unnoticed issues in sparse learning over all possible subgraph features.",2014,arXiv: Machine Learning
Detecting genetic interactions in pathway-based genome-wide association studies.,"Pathway-based genome-wide association studies (GWAS) can exploit collective effects of causal variants in a pathway to increase power of detection. However, current methods for pathway-based GWAS do not consider epistatic effects of genetic variants, although interactions between genetic variants may play an important role in influencing complex traits. In this paper, we employed a Bayesian Lasso logistic regression model for pathway-based GWAS to include all possible main effects and a large number of pairwise interactions of single nucleotide polymorphisms (SNPs) in a pathway, and then inferred the model with an efficient group empirical Bayesian Lasso (EBLasso) method. Using the inferred model, the statistical significance of a pathway was tested with the Wald statistics. Reliable effects in a significant pathway were selected using the stability selection technique. Extensive computer simulations demonstrated that our group EBlasso method significantly outperformed two competitive methods in most simulation setups and offered similar performance in other simulation setups. When applying to a GWAS dataset for Parkinson disease, EBLasso identified three significant pathways including the primary bile acid biosynthesis pathway, the neuroactive ligand-receptor interaction, and the MAPK signaling pathway. All effects identified in the primary bile acid biosynthesis pathway and many of effects in the other two pathways were epistatic effects. The group EBLasso method provides a valuable tool for pathway-based GWAS to identify main and epistatic effects of genetic variants.",2014,Genetic epidemiology
Wavenumber selection based analysis in Raman spectroscopy improves skin cancer diagnostic specificity.,"Real-time Raman spectroscopy can be used to assist in assessing skin lesions suspicious for cancer. Most of the diagnostic algorithms are based on full band of the Raman spectra, either in the fingerprint region or the high wavenumber region. In this paper we explored wavenumber selection based analysis in Raman spectroscopy for skin cancer diagnosis. Wavenumber selection was implemented using windows of wavenumber and leave-one-out cross-validated stepwise regression or least and shrinkage selection operator (LASSO). The diagnostic algorithms were then generated from the selected windows of wavenumber using multivariate statistical analyses, including principal component and general discriminate analysis (PC-GDA) and partial least squares (PLS). In total a combined cohort of 645 confirmed lesions from 573 patients encompassing skin cancers, precancers and benign skin lesions were included, which were divided into training cohort (n = 518) and testing cohort (n = 127) according to the measurement time. It was found that the area under the receiver operating characteristic curve (ROC) was improved from 0.861-0.891 to 0.891-0.911 and the diagnostic specificity for fixed sensitivity 0.99-0.90 was improved from 0.17-0.65 to 0.20-0.75 with wavenumber selection based analysis.",2016,The Analyst
Product â€™ s Quality Prediction with respect to equipments data,The semiconductor manufacturing process is a complex process that consists in a big number of equipments and enormous data. This paper presents a Least Absolute Shrinkage and Selection Operator (LASSO) based method for predicting the productâ€™s quality with respect to data of many equipments. The ability of the prediction model allows the productâ€™s quality to be estimated in real-time instead of a sampling inspection. An application to data provided by semiconductor manufacturing is presented and the results show the ability of the proposed method to predict the product quality efficiently and effectively with an improvement of more than 90% compared to the multivariate linear regression.,2015,
A novel immune-related genes prognosis biomarker for melanoma: associated with tumor microenvironment.,"BACKGROUND
Melanoma is a cancer of the skin with potential to spread to other organs and is responsible for most deaths due to skin cancer. It is imperative to identify immune biomarkers for early melanoma diagnosis and treatment.


RESULTS
63 immune-related genes of the total 1039 unique IRGs retrieved were associated with overall survival of melanoma. A multi-IRGs classifier constructed using eight IRGs showed a powerful predictive ability. The classifier had better predictive power compared with the current clinical data. GSEA analysis showed multiple signaling differences between high and low risk score group. Furthermore, biomarker was associated with multiple immune cells and immune infiltration in tumor microenvironment.


CONCLUSIONS
The immune-related genes prognosis biomarker is an effective potential prognostic classifier in the immunotherapies and surveillance of melanoma.


METHODS
Melanoma samples of genes were retrieved from TCGA and GEO databases while the immune-related genes (IRGs) were retrieved from the ImmPort database. WGCNA, Cox regression analysis and LASSO analysis were used to classify melanoma prognosis. ESTIMATE and CIBERSORT algorithms were used to explore the relationship between risk score and tumor immune microenvironment. GSEA analysis was performed to explore the biological signaling pathway.",2020,Aging
PredSym: estimating software testing budget for a bug-free release,"Symbolic execution tools are widely used during a software testing phase for finding hidden bugs and software vulnerabilities. Accurately predicting the time required by a symbolic execution tool to explore a chosen code coverage helps in planning the budget required in the testing phase. In this work, we present an automatic tool, PredSym, that uses static program features to predict the coverage explored by a symbolic execution tool Ã¢Â€Â“ KLEE, for a given time budget and to predict the time required to explore a given coverage. PredSym uses LASSO regression to build a model that does not suffer from overfitting and can predict both the coverage and the time with a worst error of 10% on unseen datapoints. PredSym also gives code improvement suggestions based on a heuristic for improving the coverage generated by KLEE.",2016,"Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, and Evaluation"
Eigenvalue Condition and model selection consistency of lasso,"Lasso is a popular method for sparse linear regression, especially for problems in which $p > n$. But when $p \gg n$, existing results from literature about the model selection consistency of lasso always require special and strong conditions, including the information from unknown true coefficients. An important question is: If the lasso solution can select the true variables without such strict condition? 
In this paper, we investigate a new train of thought to lead the model selection consistency of lasso. One important but more standard and much weaker condition, Eigenvalue Condition, is proposed. We can prove that the probability of lasso selecting wrong variables can decays at an exponential rate in ultra-high dimensional settings without other restrains except Eigenvalue Condition. Since penalized least squares have similar framework of solution. This technical tool can be extended to other methods which have similar structure. In the different dimensional settings, we show the different performance of lasso under different assumptions of noise terms. Results from simulations are carried out to demonstrate our results.",2015,arXiv: Statistics Theory
Experimental evaluation of regression model-based walking speed estimation using lower body-mounted IMU,"This study provides a concurrent comparison of regression model-based walking speed estimation accuracy using lower body mounted inertial sensors. The comparison is based on different sets of variables, features, mounting locations and regression methods. An experimental evaluation was performed on 15 healthy subjects during free walking trials. Our results show better accuracy of Gaussian process regression compared to least square regression using Lasso. Among the variables, external acceleration tends to provide improved accuracy. By using both time-domain and frequency-domain features, waist and ankle-mounted sensors result in similar accuracies: 4.5% for the waist and 4.9% for the ankle. When using only frequency-domain features, estimation accuracy based on a waist-mounted sensor suffers more compared to the one from ankle.",2016,2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)
Model-aware Quantile Regression for Discrete Data,"Quantile regression is a class of methods voted to the modelling of conditional quantiles. In a Bayesian framework quantile regression has typically been carried out exploiting the Asymmetric Laplace Distribution as a working likelihood. Despite the fact that this leads to a proper posterior for the regression coefficients, the resulting posterior variance is however affected by an unidentifiable parameter, hence any inferential procedure beside point estimation is unreliable. We propose a model-based approach for quantile regression that considers quantiles of the generating distribution directly, and thus allows for a proper uncertainty quantification. We then create a link between quantile regression and Generalized Linear Models by mapping the quantiles to the parameter of the response variable, and we exploit it to fit the model with R-INLA. We extend it also to the case of discrete responses, where there is no 1-to-1 relationship between quantiles and distributionâ€™s parameter, by introducing continuous generalizations of the most common discrete variables (Poisson, Binomial and Negative Binomial) to be exploited in the fitting. Introduction Quantile regression is a supervised technique aimed at modeling the quantiles of the conditional distribution of some response variable. With respect to â€œstandardâ€ regression, which is concerned with modeling the conditional mean, quantile regression is especially useful when the tails of the distribution are of interest, as for example when the focus is on extreme behavior rather than average, or when it is important to assess whether or not covariates affect uniformly different levels of the population. Even though the idea dates back to Galton (1883) (as noted in Gilchrist (2008)), quantile regression was formally introduced only relatively recently by Koenker and Bassett (1978). Since then, the use of quantiles in regression problems has seen an impressive growth and has been thoroughly explored in both the parametric (see Yue and Rue (2011), Wang et al. (2017)), and non-parametric framework (see Yu and Jones (1998), Takeuchi et al. (2005), Li et al. (2007)) with applications ranging from the Random Forest quantile regression of Meinshausen (2006) to D-vine copulas for quantiles in Kraus and Czado (2017), through quantile regression in graphical models as in Ali et al. (2016). Despite these many different flavors of quantile regression, as noted by Lum and Gelfand (2012), all quantile-based models can be grouped into just two categories: Conditional Quantile Models, where the estimation procedure is carried out separately for each quantile of interest and Joint Quantile Models, where multiple quantiles of interest are estimated simultaneously. Modelling quantiles jointly requires stronger assumptions on both 1 ar X iv :1 80 4. 03 71 4v 1 [ st at .M E ] 1 0 A pr 2 01 8 covariates and responses, does not allow for linear modeling of the quantiles and it is computationally intensive even when using rough approximations. Its advocates, such as Reich et al. (2011) and Tokdar and Kadaney (2012) stress the fact that joint modeling results in ordered quantile curves, hence it is noticeable immune to quantile crossing, which is a paradoxical phenomenon occurring when the quantile curves are not an increasing function of the quantile level Î±. As we believe quantile crossing should be interpreted as a flag that the model is not correct or that data is insufficient rather than an issue to be solved, in the following we will refer exclusively to Conditional Quantile Models. One of the most significant developments in the quantile regression literature has been the introduction of the Asymmetric Laplace Distribution (ALD) as a working likelihood Yu and Moyeed (2001). From a frequentist point of view, the use of the ALD gave rise to a class of likelihood based method for fitting quantile models and has been instrumental in introducing random effects in linear and non linear quantile regression models; see for example Geraci and Bottai (2007), Geraci and Bottai (2014), Geraci (2017) or Marino and Farcomeni (2015) for a more comprehensive review. The introduction of the ALD has been even more critical in the Bayesian framework, where the likelihood is a required in inferential procedure Yu and Moyeed (2001). As a result fully bayesian versions of quantile regression, such as Yue and Rue (2011), as well as Bayesian versions of regularized methods, such as Quantile Bayesian Lasso and Quantile Bayesian Elastic Net, have been developed in the last couple of years, exples being Alhamzawi et al. (2011) or Li et al. (2010). Extensions of the Asymmetric Laplace Distribution such as the Asymmetric Laplace Process Lum and Gelfand (2012), broadened quantile regression to spatially dependent data. Despite their popularity however, ALD based methods are not always satisfactory, especially in terms uncertainty quantification. The use of the ALD introduces an identifiable parameter in the posterior variance, hence any inference beside point estimation is precluded. In this work we propose a new approach to quantile regression, based on the direct modelling of the quantiles of the generating distribution. Our proposal allows to extend the GLMM framework to quantile modeling by reformulating quantile regression in terms of link functions. This formulation not only recast quantile regression in a much more cohesive setting and overcomes the natural fragmentation that derives from the vastness of the quantile regression literature, but it is also key to an efficient and ready to use fitting procedute, as the connection allows to estimate the model using R-INLA Rue et al. (2009) Rue et al. (2017). We focus on the delicate case of discrete responses, where the quantiles cannot be direct modeled. The literature on quantiles for counts (or discrete data in general) is largely based on the works of Machado and Santos Silva (2005), which proposes a jittering procedure to make discrete observations continuous by adding noise. In the Bayesian framework count responses have also been modeled through the ALD. For example Lee and Neocleous (2010) couples the jittering with the ALD; alternatively, Congdon (2017) proposes a twostage regression that uses ALD based quantile regression to model the continuous rate parameter of a Poisson distribution. This work is structured as follows. In Section 1, after giving a brief refresher of what quantile regression is and what are the issues with the ALD, we introduce our model based approach for quantile regression. In Section 2 we analyze the case where the response variable is discrete, by introducing a continuous version of the most popular distributions for counts. Finally Section 3 shows an application of our proposed method in disease mapping, using the Scottish Lip Cancer data.",2018,
A Machine Learning Approach to Predicting Need for Hospitalization for Pediatric Asthma Exacerbation at the Time of Emergency Department Triage,"OBJECTIVES
Pediatric asthma is a leading cause of emergency department (ED) utilization and hospitalization. Earlier identification of need for hospital-level care could triage patients more efficiently to high- or low-resource ED tracks. Existing tools to predict disposition for pediatric asthma use only clinical data, perform best several hours into the ED stay, and are static or score-based. Machine learning offers a population-specific, dynamic option that allows real-time integration of available nonclinical data at triage. Our objective was to compare the performance of four common machine learning approaches, incorporating clinical data available at the time of triage with information about weather, neighborhood characteristics, and community viral load for early prediction of the need for hospital-level care in pediatric asthma.


METHODS
Retrospective analysis of patients ages 2 to 18 years seen at two urban pediatric EDs with asthma exacerbation over 4Â years. Asthma exacerbation was defined as receiving both albuterol and systemic corticosteroids. We included patient features, measures of illness severity available in triage, weather features, and Centers for Disease Control and Prevention influenza patterns. We tested four models: decision trees, LASSO logistic regression, random forests, and gradient boosting machines. For each model, 80% of the data set was used for training and 20% was used to validate the models. The area under the receiver operating characteristic (AUC) curve was calculated for each model.


RESULTS
There were 29,392 patients included in the analyses: mean (Â±SD) age of 7.0 (Â±4.2) years, 42% female, 77% non-Hispanic black, and 76% public insurance. The AUCs for each model were: decision tree 0.72 (95% confidence interval [CI]Â = 0.66-0.77), logistic regression 0.83 (95% CIÂ = 0.82-0.83), random forests 0.82 (95% CIÂ = 0.81-0.83), and gradient boosting machines 0.84 (95% CIÂ = 0.83-0.85). In the lowest decile of risk, only 3% of patients required hospitalization; in the highest decile this rate was 100%. After patient vital signs and acuity, age and weight, followed by socioeconomic status (SES) and weather-related features, were the most important for predicting hospitalization.


CONCLUSIONS
Three of the four machine learning models performed well with decision trees preforming the worst. The gradient boosting machines model demonstrated a slight advantage over other approaches at predicting need for hospital-level care at the time of triage in pediatric patients presenting with asthma exacerbation. The addition of weight, SES, and weather data improved the performance of this model.",2018,Academic Emergency Medicine
EMLasso: logistic lasso with missing data.,"In clinical settings, missing data in the covariates occur frequently. For example, some markers are expensive or hard to measure. When this sort of data is used for model selection, the missingness is often resolved through a complete case analysis or a form of single imputation. An alternative sometimes comes in the form of leaving the most damaged covariates out. All these strategies jeopardise the goal of model selection. In earlier work, we have applied the logistic Lasso in combination with multiple imputation to obtain results in such settings, but we only provided heuristic arguments to advocate the method. In this paper, we propose an improved method that builds on firm statistical arguments and that is developed along the lines of the stochastic expectation-maximisation algorithm. We show that our method can be used to handle missing data in both categorical and continuous predictors, as well as in a nonpenalised regression. We demonstrate the method by applying it to data of 273 lung cancer patients. The objective is to select a model for the prediction of acute dysphagia, starting from a large set of potential predictors, including clinical and treatment covariates as well as a set of single-nucleotide polymorphisms.",2013,Statistics in medicine
Elastic Net for Cox's Proportional Hazards Model with a Solution Path Algorithm.,"For least squares regression, Efron et al. (2004) proposed an efficient solution path algorithm, the least angle regression (LAR). They showed that a slight modification of the LAR leads to the whole LASSO solution path. Both the LAR and LASSO solution paths are piecewise linear. Recently Wu (2011) extended the LAR to generalized linear models and the quasi-likelihood method. In this work we extend the LAR further to handle Cox's proportional hazards model. The goal is to develop a solution path algorithm for the elastic net penalty (Zou and Hastie (2005)) in Cox's proportional hazards model. This goal is achieved in two steps. First we extend the LAR to optimizing the log partial likelihood plus a fixed small ridge term. Then we define a path modification, which leads to the solution path of the elastic net regularized log partial likelihood. Our solution path is exact and piecewise determined by ordinary differential equation systems.",2012,Statistica Sinica
BARD1 serum autoantibodies for the detection of lung cancer,"PURPOSE
Currently the screening for lung cancer for risk groups is based on Computed Tomography (CT) or low dose CT (LDCT); however, the lung cancer death rate has not decreased significantly with people undergoing LDCT. We aimed to develop a simple reliable blood test for early detection of all types of lung cancer based on the immunogenicity of aberrant forms of BARD1 that are specifically upregulated in lung cancer.


METHODS
ELISA assays were performed with a panel of BARD1 epitopes to detect serum levels of antibodies against BARD1 epitopes. We tested 194 blood samples from healthy donors and lung cancer patients with a panel of 40 BARD1 antigens. Using fitted Lasso logistic regression we determined the optimal combination of BARD1 antigens to be used in ELISA for discriminating lung cancer from healthy controls. Random selection of samples for training sets or validations sets was applied to validate the accuracy of our test.


RESULTS
Fitted Lasso logistic regression models predict high accuracy of the BARD1 autoimmune antibody test with an AUC = 0.96. Validation in independent samples provided and AUC = 0.86 and identical AUCs were obtained for combined stages 1-3 and late stage 4 lung cancers. The BARD1 antibody test is highly specific for lung cancer and not breast or ovarian cancer.


CONCLUSION
The BARD1 lung cancer test shows higher sensitivity and specificity than previously published blood tests for lung cancer detection and/or diagnosis or CT scans, and it could detect all types and all stages of lung cancer. This BARD1 lung cancer test could therefore be further developed as i) screening test for early detection of lung cancers in high-risk groups, and ii) diagnostic aid in complementing CT scan.",2017,PLoS ONE
"Research of Features in the Pulse Waves of HBP Patients based on Principal Component Analysis and LS,Lasso","Objective: To study the features in the pulse waves of HBP patients.Methods: To collect the pulse waves of HBP patients and compare them with normal volunteers.We choose continuous cycles waves with different period length and then do the LSQ regression by 12 harmonics fitting which are correspond with every cycle lengths to build mathematical model and extract 193 parameters after pretreatment,then do principal component analysis and regression for classification and identification to find the features of HBP patients pulse waves by EFBLS.Result: There are significant differences between HBP patients pulse waves and the normal volunteers'and the accurate rate is 81% to identify by principal component analysis,the accurate rate of LSQ regression by 7 features is 93%,of Lasso is 82%.And the features distribute at different places in radial artery called ""zuoguan"" and ""youchi"" in pulse-diagnosis of TCM.Conclusion: Pathological changes of HBP patients can embody in pulse waves we collected from the radial artery and the characters of the waves change regularly in special places.This research can offer some scientific basis for taking pulse in radial artery in TCM,also for the method of feeling different places when pulse-taking.",2013,Chinese Journal of Basic Medicine in Traditional Chinese Medicine
Risk factors for postoperative urinary tract infection and urinary retention in patients undergoing surgery for colorectal cancer.,"The aim of this study was to analyze risk factors for postoperative urinary tract infection (UTI) and urinary retention (UR) in patients with colorectal cancer. Using Nationwide Inpatient Sample 2006-2009, a retrospective analysis of surgical patients with colorectal cancer was conducted. Patients were stratified into groups, with or without UTI/UR. The LASSO algorithm for logistic regression identified independent risk factors. A total of 93,931 surgical patients with colorectal cancer were identified. The incidences of UTI and UR were 5.91 and 2.52 per cent, respectively. Overall in-hospital mortality was 2.68 per cent. The UTI group demonstrated significantly higher in-hospital mortality rates compared with those without. Both UTI and UR groups were associated with prolonged hospital stay and increased hospital charge. Multivariate logistic regression analysis revealed age older than 60 years, females, anemia, congestive heart failure, coagulopathy, diabetes with chronic complications, fluid and electrolyte, paralysis, pulmonary circulation disorders, renal failure, and weight loss were independent risk factors of UTI. Age older than 60 years, male gender, rectal and rectosigmoid cancers, and postoperative anastomotic leakage and ileus were independent risk factors for UR. Postoperative UTI increases in-house mortality. Postoperative UTI/UR in patients with colorectal cancer increases length of stay and hospital charges. Knowledge of these specific risk factors for UTI and UR is needed to counsel patients and prevent these complications in this high-risk population.",2012,The American surgeon
Redefining the Protein-Protein Interface: Coarse Graining and Combinatorics for an Improved Understanding of Amino Acid Contributions to the Protein-Protein Binding Affinity.,"The ability to intervene in biological pathways has for decades been limited by the lack of a quantitative description of protein-protein interactions (PPIs). Herein we generate and compare millions of simple PPI models for insight into the mechanisms of specific recognition and binding. We use a coarse-grained approach whereby amino acids are counted in the interface, and these counts are used as binding affinity predictors. We perform lasso regression, a modern regression technique aimed at interpretability, with every possible amino acid combination (over 106 unique feature sets) to select only those amino acid predictors that provide more information than noise. This approach circumvents arbitrary binning and assumptions about the binding environment that obscure other binding affinity models. Aggregated analysis of these models trained at various interfacial cutoff distances informs the roles of specific amino acids in different binding contexts. We find that a simple amino acid count model outperforms detailed intermolecular contact and binned residue type models. We identify the prevalence of serine, glycine, and tryptophan in the interface as particularly important for predicting binding affinity across a range of distance cutoffs. Although current sample size limitations prevent a robust consensus model for binding affinity prediction, our approach underscores the relevance of a residue-based description of the protein-protein interface to increase our understanding of specific interactions.",2017,Langmuir : the ACS journal of surfaces and colloids
Identification of genes associated with survival of breast cancer patients,"BackgroundWe aimed to investigate the potential of microRNA expression profiles to predict survival in breast cancer.MethodsMicroRNA and mRNA expression data of breast cancer were downloaded from The Cancer Genome Atlas. LASSO regression was used to identify microRNAs signature predicting survival of breast cancer patients. Transfection experiment was conducted to explore the influence of microRNAs on their potential targets.ResultsWe identified 56 differentially expressed microRNAs in breast cancer tissues compared to adjacent normal tissues. 10 microRNAs with non-zero coefficient were selected from the 56 microRNAs using LASSO Cox regression. After predicting the targets for the 10 microRNAs, we further obtained 155 targets that were associated with overall survival of breast cancer patients. Spearmanâ€™s correlation analysis found that the expression of SCUBE2, SCRN3, YTHDF3, ITFG1, ITPRIPL2, and JAK1 was an inversely correlated with their microRNAs. Transfection experiment showed that YTHDF3 was down-regulated in cells transfected with miR-106b-5p mimics compared with those transfected with negative control of mimics (fold change 4.21; Pâ€‰<â€‰0.01).ConclusionsIn conclusion, we identified a 10-miRNA signature associated with prognosis of breast cancer patients. The expression of YTHDF3 was down-regulated by miR-106b-5p.",2018,Breast Cancer
Development and validation of a survival model for lung adenocarcinoma based on autophagy-associated genes,"Given that abnormal autophagy is involved in the pathogenesis of cancers, we sought to explore the potential value of autophagy-associated genes in lung adenocarcinoma (LUAD). RNA sequencing and clinical data on tumour and normal samples were acquired from The Cancer Genome Atlas (TCGA) database and randomly assigned to training and testing groups. Differentially expressed autophagy-associated genes (AAGs) were screened. Within the training group, Cox regression and Lasso regression analyses were conducted to screen five prognostic AAGs, which were used to develop a model. Kaplanâ€“Meier (KM) and receiver operating characteristic (ROC) curves were plotted to determine the performance of the model in both groups. Immunohistochemistry was used to demonstrate the differential expression of AAGs in tumour and normal tissues at the protein level. Gene Ontology (GO) functional annotation and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment analyses were utilized to further elucidate the roles of AAGs in LUAD. The data from the TCGA database included 497 tumour and 54 normal samples, within which 30 differentially expressed AAGs were screened. Using Cox regression and Lasso regression analyses for the training group, 5 prognostic AAGs were identified and the prognostic model was constructed. Patients with low risk had better overall survival (OS) in the training group (3-year OS, 73.0% vs 48.0%; 5-year OS, 45.0% vs 33.8%; Pâ€‰=â€‰1.305Eâˆ’04) and in the testing group (3-year OS, 66.8% vs 41.2%; 5-year OS, 31.7% vs 25.8%; Pâ€‰=â€‰1.027Eâˆ’03). The areas under the ROC curves (AUC) were significant for both the training and testing groups (3-year AUC, 0.810 vs 0.894; 5-year AUC, 0.792 vs 0.749). We developed a survival model for LUAD and validated the performance of the model, which may provide superior outcomes for the patients.",2020,Journal of Translational Medicine
A Comparative Study of Feature Selection Methods on Genomic Datasets,"Feature selection plays an important role in reducing the size of datasets by choosing the most informative features and discarding the rest. The use of feature selection in microarray datasets for detecting cancer is widely investigated. In this paper we provide a series of comparisons between perturbation-based feature selection (PFS) and traditional methods, such as principal component analysis (PCA), correlation based feature selection (CFS), and least-angle regression (LARS), and more recent methods, such as Hilbert-Schmidt independence criterion Lasso (HSIC-Lasso), minimum redundancy maximum relevance (mRMR), and a feature selection using support vector machines (FS-SVM). The performance of each method is demonstrated by conducting a series of comparisons on genomic cancer datasets, as well as, inflammatory bowel disease datasets. The experiments show that PFS and HSIC-Lasso are both scalable to large datasets.",2019,2019 IEEE 32nd International Symposium on Computer-Based Medical Systems (CBMS)
Scaled sparse linear regression,"Scaled sparse linear regression jointly estimates the regression coefficients and noise level in a linear model. It chooses an equilibrium with a sparse regression method by iteratively estimating the noise level via the mean residual square and scaling the penalty in proportion to the estimated noise level. The iterative algorithm costs little beyond the computation of a path or grid of the sparse regression estimator for penalty levels above a proper threshold. For the scaled lasso, the algorithm is a gradient descent in a convex minimization of a penalized joint loss function for the regression coefficients and noise level. Under mild regularity conditions, we prove that the scaled lasso simultaneously yields an estimator for the noise level and an estimated coefficient vector satisfying certain oracle inequalities for prediction, the estimation of the noise level and the regression coefficients. These inequalities provide sufficient conditions for the consistency and asymptotic normality of the noise-level estimator, including certain cases where the number of variables is of greater order than the sample size. Parallel results are provided for least-squares estimation after model selection by the scaled lasso. Numerical results demonstrate the superior performance of the proposed methods over an earlier proposal of joint convex minimization. Copyright 2012, Oxford University Press.",2011,Biometrika
Are Higher-Order Factors Useful in Pricing the Cross-Section of Hedge Fund Returns?,"This paper investigates hedge fundsâ€™ exposures to various risk factors across different investment strategies through models with both linear and second-order factors. We extend the analysis from an augmented linear model based on FamaÂ & French (1993) and Fung & Hsieh (2001) to second-order models that include all quadratic and interaction terms by adopting a novel multistep strategy that combines the variable selection capabilities of the LASSO regression with the Fama & MacBeth (1973) two-step method. We find that, for some strategies, several quadratic and interaction terms are statistically significant. Nonetheless, there is no evidence that the second-order models have more overall explanatory or predictive power than the linear model. Moreover, while both linear and second-order models perform well for directional funds (like emerging markets, event driven and managed futures), missing factors may still remain for semi-directional funds, such as fund of funds, long/short equity hedge and multi-strategy.",2019,Brazilian Review of Finance
Predicting bacterial resistance from whole-genome sequences using k-mers and stability selection,"BackgroundSeveral studies demonstrated the feasibility of predicting bacterial antibiotic resistance phenotypes from whole-genome sequences, the prediction process usually amounting to detecting the presence of genes involved in antibiotic resistance mechanisms, or of specific mutations, previously identified from a training panel of strains, within these genes. We address the problem from the supervised statistical learning perspective, not relying on prior information about such resistance factors. We rely on a k-mer based genotyping scheme and a logistic regression model, thereby combining several k-mers into a probabilistic model. To identify a small yet predictive set of k-mers, we rely on the stability selection approach (Meinshausen et al., J R Stat Soc Ser B 72:417â€“73, 2010), that consists in penalizing logistic regression models with a Lasso penalty, coupled with extensive resampling procedures.ResultsUsing public datasets, we applied the resulting classifiers to two bacterial species and achieved predictive performance equivalent to state of the art. The models are extremely sparse, involving 1 to 8 k-mers per antibiotic, hence are remarkably easy and fast to evaluate on new genomes (from raw reads to assemblies).ConclusionOur proof of concept therefore demonstrates that stability selection is a powerful approach to investigate bacterial genotype-phenotype relationships.",2018,BMC Bioinformatics
Balanced estimation for high-dimensional measurement error models,"Noisy and missing data are often encountered in real applications such that the observed covariates contain measurement errors. Despite the rapid progress of model selection with contaminated covariates in high dimensions, methodology that enjoys virtues in all aspects of prediction, variable selection, and computation remains largely unexplored. In this paper, we propose a new method called as the balanced estimation for high-dimensional error-in-variables regression to achieve an ideal balance between prediction and variable selection under both additive and multiplicative measurement errors. It combines the strengths of the nearest positive semi-definite projection and the combined L1 and concave regularization, and thus can be efficiently solved through the coordinate optimization algorithm. We also provide theoretical guarantees for the proposed methodology by establishing the oracle prediction and estimation error bounds equivalent to those for Lasso with the clean data set, as well as an explicit and asymptotically vanishing bound on the false sign rate that controls overfitting, a serious problem under measurement errors. Our numerical studies show that the amelioration of variable selection will in turn improve the prediction and estimation performance under measurement errors.",2018,Comput. Stat. Data Anal.
Regularization and clustering of neuron spike data with the Group Lasso,"We model neuron spiking data by a set of logistic regressions, one for each neuron. We regularize them with a Group Lasso penalty on the pairwise differences between coefficient vectors.",2006,
FASt global convergence of gradient methods for solving regularized M-estimation,"We analyze the convergence rates of composite gradient methods for solving problems based on regularized M-estimators, working within a high-dimensional framework that allows the data dimension d to grow with (and possibly exceed) the sample size n. This high-dimensional structure precludes the usual global assumptions-namely, strong convexity and smoothness conditions-that underlie much of classical optimization analysis. We define appropriately restricted versions of these conditions, and show that they are satisfied with high probability for various statistical models. Under these conditions, our theory guarantees that composite gradient descent has a globally geometric rate of convergence up to the statistical precision of the model, meaning the typical distance between the true unknown parameter Î¸* and an optimal solution Î¸Ì‚. This result is substantially sharper than previous results, which yielded sublinear convergence or linear convergence up to the noise level, and builds on our earlier work for constrained estimation problems. Our analysis applies to a wide range of M-estimators and statistical models, including sparse linear regression using Lasso (â„“1-regularized regression); group Lasso for block sparsity; log-linear models with regularization; low-rank matrix recovery using nuclear norm regularization; and matrix decomposition. Overall, our analysis reveals interesting connections between statistical precision and computational efficiency in high-dimensional estimation.",2012,2012 IEEE Statistical Signal Processing Workshop (SSP)
Evaluation of multiple variate selection methods from a biological perspective: a nutrigenomics case study,"Genomics-based technologies produce large amounts of data. To interpret the results and identify the most important variates related to phenotypes of interest, various multivariate regression and variate selection methods are used. Although inspected for statistical performance, the relevance of multivariate models in interpreting biological data sets often remains elusive. We compare various multivariate regression and variate selection methods applied to a nutrigenomics data set in terms of performance, utility and biological interpretability. The studied data set comprised hepatic transcriptome (10,072 predictor variates) and plasma protein concentrations [2 dependent variates: Leptin (LEP) and Tissue inhibitor of metalloproteinase 1 (TIMP-1)] collected during a high-fat diet study in ApoE3Leiden mice. The multivariate regression methods used were: partial least squares â€œPLSâ€; a genetic algorithm-based multiple linear regression, â€œGA-MLRâ€; two least-angle shrinkage methods, â€œLASSOâ€ and â€œELASTIC NETâ€; and a variant of PLS that uses covariance-based variate selection, â€œCovProc.â€ Two methods of ranking the genes for Gene Set Enrichment Analysis (GSEA) were also investigated: either by their correlation with the protein data or by the stability of the PLS regression coefficients. The regression methods performed similarly, with CovProc and GA performing the best and worst, respectively (R-squared values based on â€œdouble cross-validationâ€ predictions of 0.762 and 0.451 for LEP; and 0.701 and 0.482 for TIMP-1). CovProc, LASSO and ELASTIC NET all produced parsimonious regression models and consistently identified small subsets of variates, with high commonality between the methods. Comparison of the gene ranking approaches found a high degree of agreement, with PLS-based ranking finding fewer significant gene sets. We recommend the use of CovProc for variate selection, in tandem with univariate methods, and the use of correlation-based ranking for GSEA-like pathway analysis methods.",2012,Genes & Nutrition
A comparison of genomic selection methods for breeding value prediction,"Recent advances in molecular genetics techniques have made dense marker maps available, and the prediction of breeding value at the genome level has been employed in genetics research. However, an increasingly large number of markers raise both statistical and computational issues in genomic selection (GS), and many methods have been developed for genomic prediction to address these problems, including ridge regression-best linear unbiased prediction (RR-BLUP), genomic best linear unbiased prediction, BayesA, BayesB, BayesCÏ€, and Bayesian LASSO. In this paper, these methods were compared regarding inference under different conditions, using real data from a wheat data set and simulated scenarios with a small number of quantitative trait loci (QTL) (20), a moderate number of QTL (60, 180) and an extreme number of QTL (540). This study showed that the genetic architecture of a trait should be fully considered when a GS method is chosen. If a small amount of loci had a large effect on a trait, great differences were found between the predictive ability of various methods and BayesCÏ€ was recommended. Although there was almost no significant difference between the predictive ability of BayesCÏ€ and BayesB, BayesCÏ€ is more feasible than BayesB for real data analysis. If a trait was controlled by a moderate number of genes, the absolute differences between the various methods were small, but BayesA was also found to be the most accurate method. Furthermore, BayesA was widely adaptable and could perform well with different numbers of QTL. If a trait was controlled by an extreme number of minor genes, almost no significant differences were detected between the predictive ability of various methods, but RR-BLUP slightly outperformed the others in both simulated scenarios and real data analysis, thus demonstrating its robustness and indicating that it was quite effective in this case.",2015,Science Bulletin
A Machine Learning Approach to Forecast Bitcoin Prices,"Bitcoin is an established cryptographic digital currency whose value lays in the computational complexity rather than a physical commodity. Bitcoin is an open source software program with three aspects. (i) Peer-to-Peer network â€“ low barrier entry; (ii) Mining â€“ inevitable concentration of power; (iii) Software upgrades. The nodes on the network follow a decentralized consensus for establishing the value of ledger and updating the blockchain which serves as a single source of truth for all transactions. As cryptocurrencies are developing more compelling utilities, creating ever faster and safer payment systems they are shifting the â€œmoney paradigmâ€. Bitcoins are an evolution in money and provide a unique opportunity to forecast their price unlike the existing fiat currencies. The goal of this paper is to implement, train and evaluate several machine learning models in order to predict the price of the most popular cryptocurrency â€“ Bitcoins. The various machine learning algorithms employed are â€“ Linear Regression, K-Nearest Neighbors, Ridge Regression, Lasso Regression, Polynomial Regression, Linear Support Vector Machine, and Kernel Support Vector Machine. General Terms Bitcoins, Cryptocurrency, Blockchain, Machine Learning, Regression, Forecasting.",2018,International Journal of Computer Applications
Parallel Selective Algorithms for Nonconvex Big Data Optimization,"We propose a decomposition framework for the parallel optimization of the sum of a differentiable (possibly nonconvex) function and a (block) separable nonsmooth, convex one. The latter term is usually employed to enforce structure in the solution, typically sparsity. Our framework is very flexible and includes both fully parallel Jacobi schemes and Gauss-Seidel (i.e., sequential) ones, as well as virtually all possibilities â€œin betweenâ€ with only a subset of variables updated at each iteration. Our theoretical convergence results improve on existing ones, and numerical results on LASSO, logistic regression, and some nonconvex quadratic problems show that the new method consistently outperforms existing algorithms.",2015,IEEE Transactions on Signal Processing
On algorithms for solving least squares problems under an L1 penalty or an L1 constraint,"Tibshirani (1996) proposed the least absolute shrinkage and selection operator (LASSO) which estimates a vector of regression coefficients by minimising the residual sum of squares subject to a constraint (penalty) on the sum of the absolute values of the coefficient estimates. In this paper, we describe several algorithms that can be used to calculate the LASSO solution.",2005,
Randomised and L1-penalty approaches to segmentation in time series and regression models,"It is a common approach in statistics to assume that the parameters of a stochastic model change. The simplest model involves parameters than can be exactly or approximately piecewise constant. In such a model, the aim is the posteriori detection of the number and location in time of the changes in the parameters. This thesis develops segmentation methods for non-stationary time series and regression models using randomised methods or methods that involve L1 penalties which force the coefficients in a regression model to be exactly zero. Randomised techniques are not commonly found in nonparametric statistics, whereas L1 methods draw heavily from the variable selection literature. Considering these two categories together, apart from other contributions, enables a comparison between them by pointing out strengths and weaknesses. This is achieved by organising the thesis into three main parts. 
First, we propose a new technique for detecting the number and locations of the change-points in the second-order structure of a time series. The core of the segmentation procedure is the Wild Binary Segmentation method (WBS) of Fryzlewicz (2014), a technique which involves a certain randomised mechanism. The advantage of WBS over the standard Binary Segmentation lies in its localisation feature, thanks to which it works in cases where the spacings between change-points are short. Our main change-point detection statistic is the wavelet periodogram which allows a rigorous estimation of the local autocovariance of a piecewise-stationary process. We provide a proof of consistency and examine the performance of the method on simulated and real data sets. 
Second, we study the fused lasso estimator which, in its simplest form, deals with the estimation of a piecewise constant function contaminated with Gaussian noise (Friedman et al. (2007)). We show a fast way of implementing the solution path algorithm of Tibshirani and Taylor (2011) and we make a connection between their algorithm and the taut-string method of Davies and Kovac (2001). In addition, a theoretical result and a simulation study indicate that the fused lasso estimator is suboptimal in detecting the location of a change-point. 
Finally, we propose a method to estimate regression models in which the coefficients vary with respect to some covariate such as time. In particular, we present a path algorithm based on Tibshirani and Taylor (2011) and the fused lasso method of Tibshirani et al. (2005). Thanks to the adaptability of the fused lasso penalty, our proposed method goes beyond the estimation of piecewise constant models to models where the underlying coefficient function can be piecewise linear, quadratic or cubic. Our simulation studies show that in most cases the method outperforms smoothing splines, a common approach in estimating this class of models.",2014,
Sequential adaptive elastic net approach for single-snapshot source localization,"This paper proposes efficient algorithms for accurate recovery of direction-of-arrivals (DoAs) of sources from single-snapshot measurements using compressed beamforming (CBF). In CBF, the conventional sensor array signal model is cast as an underdetermined complex-valued linear regression model and sparse signal recovery methods are used for solving the DoA finding problem. A complex-valued pathwise weighted elastic net (c-PW-WEN) algorithm is developed that finds solutions at the knots of penalty parameter values over a path (or grid) of elastic net (EN) tuning parameter values. c-PW-WEN also computes least absolute shrinkage and selection operator (LASSO) or weighted LASSO in its path. A sequential adaptive EN (SAEN) method is then proposed that is based on c-PW-WEN algorithm with adaptive weights that depend on previous solution. Extensive simulation studies illustrate that SAEN improves the probability of exact recovery of true support compared to conventional sparse signal recovery approaches such as LASSO, EN, or orthogonal matching pursuit in several challenging multiple target scenarios. The effectiveness of SAEN is more pronounced in the presence of high mutual coherence.",2018,The Journal of the Acoustical Society of America
Development and Validation of a Prognostic Nomogram for Gastric Cancer Based on DNA Methylation-Driven Differentially Expressed Genes,"Background/Aims: The incidence of gastric cancer (GC) ranks fifth among common tumors and GC is the third leading cause of cancer-related death worldwide. The aim of this study was to develop and validate a nomogram for predicting the overall survival (OS) of patients with GC. Methods: DNA methylation (DNAm)-driven genes were identified by integrating DNAm and gene expression profiling analyses from The Cancer Genome Atlas (TCGA) GC cohort. Then, a risk score model was built based on Kaplan-Meier (K-M), least absolute shrinkage and selector operation (LASSO), and multivariate Cox regression analyses. After analyzing the clinical parameters, a nomogram was constructed and assessed. Another cohort (GSE62254) was used for external validation. Results: Thirteen differentially expressed DNAm-driven genes were narrowed down to a six-gene signature (PODN, NPY, MICU3, TUBB6 and RHOJ were hypermethylated, and MYO1A was hypomethylated), which was associated with OS (P < 0.05) after survival and LASSO regression analyses. These differentially expressed genes (DEGs) with altered DNAm statuses were included in the prognostic risk score model. The univariate Cox regression analysis indicated that risk score, age, and number of positive lymph nodes were significantly associated with survival time in GC patients. The multivariate Cox regression analysis also indicated that these variables were significant prognostic factors for GC. A nomogram including these variables was constructed, and its performance in predicting the 1-, 3- and 5-year survival outcomes of GC patients was estimated through time-dependent receiver operating characteristic (ROC) curves. In addition, the clinical benefit of this model was revealed by decision curve analysis (DCA). Pathway enrichment analysis suggested that these DNAm-driven genes might impact tumor progression by affecting signaling pathways such as the ""ECM RECEPTOR INTERACTION"" and ""DNA REPLICATION"" pathways. Conclusions: The altered status of the DNAm-driven gene signature (PODN, MYO1A, NPY, MICU3, TUBB6 and RHOJ) was significantly associated with the OS of GC patients. A nomogram incorporating risk score, age and number of positive lymph nodes can be conveniently used to facilitate the individualized prediction of OS in patients with GC.",2020,International Journal of Biological Sciences
Empirical Study on Risk Factors for Long-Only Equity Hedge Funds in China,"This paper utilizes the multi-factor model to identify risk factors of long-only equity hedge funds in China. These factors cover asset based style factors, liquidity factor, sentiment factors and macro factors. In addition to the conventional OLS model, this paper also employs Stepwise and LASSO regression models to select the subset of effective factors for each hedge fund sample. The results show that these factors can explain over 50% of the return variations of most long-only equity hedge funds in terms of adjust R2s with different sets of effective factors. Meanwhile, from the perspective of statistical significance (|t| > 2), about 88%, 64% and 41% of long-only equity hedge funds are characterized mainly by the asset-based style factors, sentiment factors and macro factors respectively, whereas about 13% of hedge funds are explained significantly by the liquidity factor.",2019,
The Adaptive Gril Estimator with a Diverging Number of Parameters,"We consider the problem of variables selection and estimation in linear regression model in situations where the number of parameters diverges with the sample size. We propose the adaptive Generalized Ridge-Lasso (\mboxAdaGril) which is an extension of the the adaptive Elastic Net. AdaGril incorporates information redundancy among correlated variables for model selection and estimation. It combines the strengths of the quadratic regularization and the adaptively weighted Lasso shrinkage. In this article, we highlight the grouped selection property for AdaCnet method (one type of AdaGril) in the equal correlation case. Under weak conditions, we establish the oracle property of AdaGril which ensures the optimal large performance when the dimension is high. Consequently, it achieves both goals of handling the problem of collinearity in high dimension and enjoys the oracle property. Moreover, we show that AdaGril estimator achieves a Sparsity Inequality, i.e., a bound in terms of the number of non-zero components of the â€œtrueâ€ regression coefficient. This bound is obtained under a similar weak Restricted Eigenvalue (RE) condition used for Lasso. Simulations studies show that some particular cases of AdaGril outperform its competitors.",2013,Communications in Statistics - Theory and Methods
"Discussion of ""least Angle Regression"" by Efron Et Al.","DISCUSSION OF â€œLEAST ANGLE REGRESSIONâ€ BY EFRONET AL.By Berwin A. TurlachUniversity of Western AustraliaI would like to begin by congratulating the authors (referred to belowas EHJT) for their interesting paper in which they propose a new variableselection method (LARS) for building linear models and show how their newmethod relates to other methods that have been proposed recently. I foundthe paper to be very stimulating and found the additional insight that itprovides about the Lasso technique to be of particular interest.My comments center around the question of how we can select linearmodels that conform with the marginality principle [Nelder (1977, 1994)and McCullagh and Nelder (1989)]; that is, the response surface is invariantunder scaling and translation of the explanatory variables in the model.Recently one of my interests was to explore whether the Lasso techniqueor the nonnegative garrote [Breiman (1995)] could be modiï¬ed such that itincorporates the marginality principle. However, it does not seem to be atrivial matter to change the criteria that these techniques minimize in such away that the marginality principle is incorporated in a satisfactory manner.On the other hand, it seems to be straightforward to modify the LARStechnique to incorporate this principle. In their paper, EHJT address thisissue somewhat in passing when they suggest toward the end of Section 3that one ï¬rst ï¬t main eï¬€ects only and interactions in a second step to controlthe order in which variables are allowed to enter the model. However, sucha two-step procedure may have a somewhat less than optimal behavior asthe following, admittedly artiï¬cial, example shows.Assume we have a vector of explanatory variables X =(X",2004,arXiv: Statistics Theory
A multi-task learning formulation for predicting disease progression,"Alzheimer's Disease (AD), the most common type of dementia, is a severe neurodegenerative disorder. Identifying markers that can track the progress of the disease has recently received increasing attentions in AD research. A definitive diagnosis of AD requires autopsy confirmation, thus many clinical/cognitive measures including Mini Mental State Examination (MMSE) and Alzheimer's Disease Assessment Scale cognitive subscale (ADAS-Cog) have been designed to evaluate the cognitive status of the patients and used as important criteria for clinical diagnosis of probable AD. In this paper, we propose a multi-task learning formulation for predicting the disease progression measured by the cognitive scores and selecting markers predictive of the progression. Specifically, we formulate the prediction problem as a multi-task regression problem by considering the prediction at each time point as a task. We capture the intrinsic relatedness among different tasks by a temporal group Lasso regularizer. The regularizer consists of two components including an L2,1-norm penalty on the regression weight vectors, which ensures that a small subset of features will be selected for the regression models at all time points, and a temporal smoothness term which ensures a small deviation between two regression models at successive time points. We have performed extensive evaluations using various types of data at the baseline from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database for predicting the future MMSE and ADAS-Cog scores. Our experimental studies demonstrate the effectiveness of the proposed algorithm for capturing the progression trend and the cross-sectional group differences of AD severity. Results also show that most markers selected by the proposed algorithm are consistent with findings from existing cross-sectional studies.",2011,
