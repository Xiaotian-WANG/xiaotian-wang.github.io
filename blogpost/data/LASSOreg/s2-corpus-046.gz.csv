title,abstract,year,journal
Confidence intervals of prediction accuracy measures for multivariable prediction models based on the bootstrap-based optimism correction methods,"In assessing prediction accuracy of multivariable prediction models, optimism corrections are essential for preventing biased results. However, in most published papers of clinical prediction models, the point estimates of the prediction accuracy measures are corrected by adequate bootstrap-based correction methods, but their confidence intervals are not corrected, e.g., the DeLongâ€™s confidence interval is usually used for assessing the Cstatistic. These naÃ¯ve methods do not adjust for the optimism bias and do not account for statistical variability in the estimation of parameters in the prediction models. Therefore, their coverage probabilities of the true value of the prediction accuracy measure can be seriously below the nominal level (e.g., 95%). In this article, we provide two generic bootstrap methods, namely (1) location-shifted bootstrap confidence intervals and (2) two-stage bootstrap confidence intervals, that can be generally applied to the bootstrapbased optimism correction methods, i.e., the Harrellâ€™s bias correction, 0.632, and 0.632+ methods. In addition, they can be widely applied to various methods for prediction model development involving modern shrinkage methods such as the ridge and lasso regressions. Through numerical evaluations by simulations, the proposed confidence intervals showed favourable coverage performances. Besides, the current standard practices based on the optimism-uncorrected methods showed serious undercoverage properties. To avoid erroneous results, the optimism-uncorrected confidence intervals should not be used in practice, and the adjusted methods are recommended instead. We also developed the R package predboot for implementing these methods (https://github.com/nomahi/predboot). The effectiveness of the proposed methods are illustrated via applications to the GUSTO-I clinical trial.",2020,
LASSO-Driven Inference in Time and Space,"We consider the estimation and inference in a system of high-dimensional regression equations allowing for temporal and cross-sectional dependency in covariates and error processes, covering rather general forms of weak dependence. A sequence of large-scale regressions with LASSO is applied to reduce the dimensionality, and an overall penalty level is carefully chosen by a block multiplier bootstrap procedure to account for multiplicity of the equations and dependencies in the data. Correspondingly, oracle properties with a jointly selected tuning parameter are derived. We further provide high-quality de-biased simultaneous inference on the many target parameters of the system. We provide bootstrap consistency results of the test procedure, which are based on a general Bahadur representation for the Z-estimators with dependent data. Simulations demonstrate good performance of the proposed inference procedure. Finally, we apply the method to quantify spillover effects of textual sentiment indices in a financial market and to test the connectedness among sectors.",2018,arXiv: Econometrics
Dynamic Quantile Lasso Regression,"Quantile regression has been becoming a relevant and powerfult echnique to study the whole conditional distribution of a response variable without relying on strong assumptions about the underlying data generating process. Furthermore, quantile regression has been effectively used in many real applications, providing a representation of the relation between the response variable and the covariates, that overcomes traditional mean regression. In this paper, we consider a quantile regression model in which the regression coefï¬cients are assumed to evolve over time, following a stationary stochastic process. Furthermore, since homoskedastic quantile regression models result in location shifts of the regression hyperplane, we extend the timeâ€“varying parameter model to allow for heteroskedastic innovations. A dynamic version of the adaptiveâ€“Lasso penalty is then introduced to force the dynamic evolution of non relevant parameters to shrink towards zero. A simulation study is carried out to illustrate the model performances.",2016,
A Geometric Approach to Subset Selection and Sparse Sufficient Dimension Reduction,"Sufficient dimension reduction methods allow to estimate lower dimensional subspaces while retaining most of the information about the regression of a response variable on a set of predictors. However, it may happen that only a subset of the predictors is needed. We propose a geometric approach to subset selection by imposing sparsity constraints on some coefficients. The proposed method can be applied to most existing dimension reduction methods, such as sliced inverse regression and sliced average variance estimation, and may help to improve the estimation accuracy and facilitate interpretation. Simulation studies are presented to show the effectiveness of the proposed method applied to two popular dimension reduction methods, namely SIR and SAVE, and a comparison is made with LASSO and stepwise OLS regression.",2011,
Estimasi Koefisien Regresi Logistik Biner Dengan Metode Least Absolute Shrinkage and Selection Operator,"High correlation between predictor variables (multicollinearity) become a problem in logistic regression. There are some method to solve the problem, but the methods have drawbacks i.e. they can not shrink some coefficients to 0 and do variable-selection technique simultaneity. Least Absolute Shrinkage and Selection Operator (LASSO) method can shrink some coefficients to 0 and do variableselection technique simultaneity. This paper proposed to estimate binary logistic regression coefficients with LASSO method. Then it will be applied on proverty data of all village in Jeneponto. According to the binary logistic regression model with LASSO method, the estimated model shows that if number of household that which using lighting source i.e. oil lamp and not State Electricity Enterprise more than number of household using which State Electricity Enterprise and work in industry sector then that village is classificated in proverty village. Accuracy of classification with LASSO method is 80,53%.",2015,
Isotonic Modeling with Non-Differentiable Loss Functions with Application to Lasso Regularization,"In this paper we present an algorithmic approach for fitting isotonic models under convex, yet non-differentiable, loss functions. It is a generalization of the greedy non-regret approach proposed by Luss and Rosset (2014) for differentiable loss functions, taking into account the sub-gradiental extensions required. We prove that our suggested algorithm solves the isotonic modeling problem while maintaining favorable computational and statistical properties. As our suggested algorithm may be used for any nondifferentiable loss function, we focus our interest on isotonic modeling for either regression or two-class classification with appropriate log-likelihood loss and lasso penalty on the fitted values. This combination allows us to maintain the non-parametric nature of isotonic modeling, while controlling model complexity through regularization. We demonstrate the efficiency and usefulness of this approach on both synthetic and real world data. An implementation of our suggested solution is publicly available from the first author's website (https://sites.google.com/site/amichaipainsky/software).",2016,IEEE Transactions on Pattern Analysis and Machine Intelligence
Data-driven Optimal Cost Selection for Distributionally Robust Optimization,"Recently, (Blanchet, Kang, and Murhy 2016, and Blanchet, and Kang 2017) showed that several machine learning algorithms, such as square-root Lasso, Support Vector Machines, and regularized logistic regression, among many others, can be represented exactly as distributionally robust optimization (DRO) problems. The distributional uncertainty is defined as a neighborhood centered at the empirical distribution. We propose a methodology which learns such neighborhood in a natural data-driven way. We show rigorously that our framework encompasses adaptive regularization as a particular case. Moreover, we demonstrate empirically that our proposed methodology is able to improve upon a wide range of popular machine learning estimators.",2017,arXiv: Machine Learning
Uniformly valid confidence sets based on the Lasso,"In a linear regression model of fixed dimension $p \leq n$, we construct confidence regions for the unknown parameter vector based on the Lasso estimator that uniformly and exactly hold the prescribed in finite samples as well as in an asymptotic setup. We thereby quantify estimation uncertainty as well as the ""post-model selection error"" of this estimator. More concretely, in finite samples with Gaussian errors and asymptotically in the case where the Lasso estimator is tuned to perform conservative model selection, we derive exact formulas for computing the minimal coverage probability over the entire parameter space for a large class of shapes for the confidence sets, thus enabling the construction of valid confidence regions based on the Lasso estimator in these settings. The choice of shape for the confidence sets and comparison with the confidence ellipse based on the least-squares estimator is also discussed. Moreover, in the case where the Lasso estimator is tuned to enable consistent model selection, we give a simple confidence region with minimal coverage probability converging to one. Finally, we also treat the case of unknown error variance and present some ideas for extensions.",2018,Electronic Journal of Statistics
Super-resolution for facial image using multilateral affinity function,"In this paper, a patch-based super-resolution (SR) method is proposed to hallucinate facial images, where the image patches are selected and weighted based on a multilateral affinity function (MAF). Inspired by the property of human faces, we design the MAF by combining four parts, each of which is also an affinity function and inspired from different insights. The first part describes the similarity of two patches by their appearances. The second one takes the probable positions of patches into account. The third part incorporates the global information of faces by Lasso regression. The fourth one includes the information of significant facial components. Through the data consistency constraint, weights of training patches are calculated from MAF. The final SR results are obtained by the stitching of inferred HR patches and a post-processing. The experiments on two public databases demonstrate the superiority of the proposed method over some state-of-the-art methods via various criteria. The feasibility of our method in the real-world scenario is also demonstrated experimentally.",2014,Neurocomputing
Parkinsonâ€™s Disease Rigidity: Relation to Brain Connectivity and Motor Performance,"OBJECTIVE
(1) To determine the brain connectivity pattern associated with clinical rigidity scores in Parkinson's disease (PD) and (2) to determine the relation between clinically assessed rigidity and quantitative metrics of motor performance.


BACKGROUND
Rigidity, the resistance to passive movement, is exacerbated in PD by asking the subject to move the contralateral limb, implying that rigidity involves a distributed brain network. Rigidity mainly affects subjects when they attempt to move; yet the relation between clinical rigidity scores and quantitative aspects of motor performance are unknown.


METHODS
Ten clinically diagnosed PD patients (off-medication) and 10 controls were recruited to perform an fMRI squeeze-bulb tracking task that included both visually guided and internally guided features. The direct functional connectivity between anatomically defined regions of interest was assessed with Dynamic Bayesian Networks (DBNs). Tracking performance was assessed by fitting Linear Dynamical System (LDS) models to the motor performance, and was compared to the clinical rigidity scores. A cross-validated Least Absolute Shrinkage and Selection Operator (LASSO) regression method was used to determine the brain connectivity network that best predicted clinical rigidity scores.


RESULTS
The damping ratio of the LDS models significantly correlated with clinical rigidity scores (pâ€‰=â€‰0.014). An fMRI connectivity network in subcortical and primary and premotor cortical regions accurately predicted clinical rigidity scores (pâ€‰<â€‰10(-5)).


CONCLUSION
A widely distributed cortical/subcortical network is associated with rigidity observed in PD patients, which reinforces the importance of altered functional connectivity in the pathophysiology of PD. PD subjects with higher rigidity scores tend to have less overshoot in their tracking performance, and damping ratio may represent a robust, quantitative marker of the motoric effects of increasing rigidity.",2013,Frontiers in Neurology
Predicting Mitochondrial tRNA Modification,"M itochondria are integral to proper cell function, and mutations in its small genome (mtDNA) are associated with many diseases, along with the progression of normal aging [9]. While mtDNA has been extensively studied, not much is known about transcriptional variations of mitochondrial genes [3]. Recently, tRNA modifications have been the focus of intense study owing to their putative role in diseases [4]. Identifying genes responsible for mitochondrial tRNA modification is an important step towards a better understanding of transcriptional variation. To the best of my knowledge, a machine learning approach has never been utilized in order to identify such genes. Here, I used penalized linear regression to predict tRNA modification activity using gene expression as features. After controlling for confounding factors, I was able to predict modification activity at several putative modified tRNA positions. These models explained between 19% and 51% of the variance. Most notably, I used preconditioned lasso [7] which yielded four promising gene candidates that affect tRNA modification: ALKBH8 (an E. coli homolog DNA repair enzyme), MAD2L1 Binding Protein, C1orf103 (an open reading frame gene with unknown function), and TRMT5 (tRNA methyltransferase 5).",2014,
A Coordinate-Descent-Based Approach to Solving the Sparse Group Elastic Net,"ABSTRACTGroup sparse approaches to regression modeling are finding ever increasing utility in an array of application areas. While group sparsity can help assess certain data structures, it is desirable in many instances to also capture element-wise sparsity. Recent work exploring the latter has been conducted in the context of l2/l1 penalized regression in the form of the sparse group lasso (SGL). Here, we present a novel model, called the sparse group elastic net (SGEN), which uses an lâˆž/l1/ridge-based penalty. We show that the lâˆž-norm, which induces group sparsity is particularly effective in the presence of noisy data. We solve the SGEN model using a coordinate descent-based procedure and compare its performance to the SGL and related methods in the context of hyperspectral imaging in the presence of noisy observations. Supplementary materials for this article are available online.",2017,Technometrics
Genomic Selection of Forage Quality Traits in Winter Wheat,"Phenotyping forage quality traits is timeconsuming in forage wheat breeding. In this study, prediction accuracies of three genomic selection (GS) models (ridge regression best linear unbiased prediction [RRBLUP], Gaussian kernel [GAUSS], and Bayesian LASSO [BL, where LASSO stands for least absolute shrinkage and selection operator]) for forage quality traits of winter wheat (Triticum aestivum L.) were compared using two genotype sampling methods. In addition, the impact of training population (TP) size and marker density on prediction accuracy was explored. The study was done using a diversity panel (n = 298) that was genotyped using 90K single nucleotide polymorphisms (SNPs) and phenotyped for forage quality traits including crude protein, acid detergent fiber, neutral detergent fiber, sugars, lignin content, and in vitro true dry matter digestibility. Generally, the three models produced similar prediction accuracies, which ranged from 0.34 to 0.61, for all traits. The sampling method had little effect on accuracy. Crude protein was one of the traits with the highest prediction accuracy, and it required only 1000 markers to attain its highest prediction accuracy value. Increasing TP size and marker density increased accuracies of all traits, and increasing the TP size was more effective than increasing marker density. For this panel, the optimal TP size (nTP) was 150, at which point prediction accuracies of all traits, except for sugars, reached over 90% of the highest value at nTP = 250. However, the sampling method for marker density had no effect on accuracy. The results suggest that GS can be an alternative approach to facilitate selection of forage quality traits during forage wheat breeding. F. Maulana, J.D. Anderson, T.J. Butler, and X.-F. Ma, Noble Research Institute, Ardmore, OK 73401, USA; K.-S. Kim, LG ChemFarmHannong, Daejeon 34115, Korea; M.E. Sorrells, School of Integrative Plant Science, Cornell Univ., Ithaca, NY 14853-1902, USA; S. Liu, Texas A&M AgriLife Research, Amarillo, TX 79106, USA; P.S. Baenziger, Dep. of Agronomy and Horticulture, Univ. of Nebraska, Lincoln NE 68583-0915, USA; P. F. Byrne, Dep. of Soil and Crop Sciences, Colorado State Univ., Fort Collins CO, 80523-1170, USA. Frank Maulana and Ki-Seung Kim contributed equally to this work. Received 31 Oct. 2018. Accepted 1 July 2019. *Corresponding author (xma@noble.org). Assigned to Associate Editor Heathcliffe Riday. Abbreviations: ADF, acid detergent fiber; ADL, acid detergent lignin; BL, Bayesian least absolute shrinkage and selection operator; CP, crude protein; ESM, evenly sampling method; GAUSS, Gaussian kernel; GEBV, genomic estimated breeding value; GS, genomic selection; IVTDMD, in vitro true dry matter digestibility; LC, lignin content; LD, linkage disequilibrium; MAF, minor allele frequency; MAS, marker-assisted selection; NDF, neutral detergent fiber; NDFD, neutral detergent fiber digestibility; NIRS, near-infrared reflectance spectroscopy; NJ, neighbor-joining; PEBV, phenotypically estimated breeding value; QTL, quantitative trait locus/loci; RRBLUP, ridge regression best linear unbiased prediction; RSM, random sampling method; SNP, single nucleotide polymorphism; SSM, stratified sampling method; SUG, sugars; TCAP, Triticeae Coordinated Agricultural Project; TP, training population; VP, validation population. Published in Crop Sci. 59:2473â€“2483 (2019). doi: 10.2135/cropsci2018.10.0655 Â© 2019 The Author(s). This is an open access article distributed under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Published September 12, 2019",2019,Crop Science
Multimarker Proteomic Profiling for the Prediction of Cardiovascular Mortality in Patients with Chronic Heart Failure,"Risk stratification of patients with systolic chronic heart failure (HF) is critical to better identify those who may benefit from invasive therapeutic strategies such as cardiac transplantation. Proteomics has been used to provide prognostic information in various diseases. Our aim was to investigate the potential value of plasma proteomic profiling for risk stratification in HF. A proteomic profiling using surface enhanced laser desorption ionization - time of flight - mass spectrometry was performed in a case/control discovery population of 198 patients with systolic HF (left ventricular ejection fraction <45%): 99 patients who died from cardiovascular cause within 3 years and 99 patients alive at 3 years. Proteomic scores predicting cardiovascular death were developed using 3 regression methods: support vector machine, sparse partial least square discriminant analysis, and lasso logistic regression. Forty two ion m/z peaks were differentially intense between cases and controls in the discovery population and were used to develop proteomic scores. In the validation population, score levels were higher in patients who subsequently died within 3 years. Similar areas under the curves (0.66 - 0.68) were observed for the 3 methods. After adjustment on confounders, proteomic scores remained significantly associated with cardiovascular mortality. Use of the proteomic scores allowed a significant improvement in discrimination of HF patients as determined by integrated discrimination improvement and net reclassification improvement indexes. In conclusion, proteomic analysis of plasma proteins may help to improve risk prediction in HF patients.",2015,PLoS ONE
High-Grade Soft-Tissue Sarcomas: Can Optimizing Dynamic Contrast-Enhanced MRI Postprocessing Improve Prognostic Radiomics Models?,"BACKGROUND
Heterogeneity on pretreatment dynamic contrast-enhanced (DCE)-MRI of sarcomas may be prognostic, but the best technique to capture this characteristic remains unknown.


PURPOSE
To investigate the best method to extract prognostic data from baseline DCE-MRI.


STUDY TYPE
Retrospective, single-center.


POPULATION
Fifty consecutive uniformly-treated adults with nonmetastatic high-grade sarcomas.


FIELD STRENGTH/SEQUENCE
1.5T; T2 -weighted-imaging, fat-suppressed fast spoiled gradient echo DCE-MRI.


ASSESSMENT
Ninety-two radiomics features (RFs) were extracted at each DCE-MRI phase (11, from t = 0-88 sec). Relative changes in RFs (rRFs) since the acquisition baseline were calculated (11â€‰Ã—â€‰92 rRFs). Curves of rRF as function of time postinjection were integrated (92 integrated-rRFs [irRFs]). Ktrans and area under the time-intensity curve at 88-sec parametric maps were computed and 2â€‰Ã—â€‰92 parametric-RFs (pRFs) were extracted. Five DCE-MRI-based radiomics models were built on: an RFs subset (32 sec, 64 sec, 88 sec); all rRFs; all irRFs; and all pRFs. Two models were elaborated as reference, on: conventional radiological features; and T2 -WI RFs.


STATISTICAL TESTS
A common machine-learning approach was applied to radiomics models. Features with P <â€‰0.05 at univariate analysis were entered in a LASSO-penalized Cox regression including bootstrapped 10-fold cross-validation. The resulting radiomics scores (RScores) were dichotomized per their median and entered in multivariate Cox models for predicting metastatic relapse-free survival. Models were compared with integrative area under the curve (AUC) and concordance index.


RESULTS
Only dichotomized RScores from models based on rRFs subset, all rRFS and irRFS correlated with prognostic (P = 0.0107-0.0377). The models including all rRFs and irRFs had the highest c-index (0.83), followed by the radiological model. The radiological model had the highest integrative AUC (0.87), followed by models including all rRFs and irRFs. The radiological and full rRFs models were significantly better than the T2 -based radiomics model (P = 0.02).


DATA CONCLUSION
The initial DCE-MRI of STS contains prognostic information. It seems more relevant to make predictions on rRFs instead of pRFs. Evidence Level: 3 Technical Efficacy: 3 J. Magn. Reson. Imaging 2020.",2020,Journal of magnetic resonance imaging : JMRI
Forecasting hotel reservations with long short-term memory-based recurrent neural networks,"Hotel reservations tie up a much large portion of a hotels annual revenue. It is of great benefit for hotel managers to accurately forecast the numbers of reservations each day so that they can make better operational and tactical decisions. In this study, we review three types of forecasting methods commonly used in practice and briefly illustrate the concepts of neural networks. We then propose two long short-term memory (LSTM) models based on recurrent neural networks. Actual reservations of four hotels in the USA are used to estimate and test the proposed two models. To measure the relative performance, six machine learning (ML) models of decision tree, multilayer perceptron, lasso, linear regression, random forest, and ridge are also estimated and tested against the same datasets. The empirical results show that, on average, the forecasting accuracy of using LSTM models has been improved about 3.0% over that of using the best of the ML models.",2018,International Journal of Data Science and Analytics
Prevalence and Factors Associated with Alcohol Consumption in Urban Schools in Burkina Faso,"Background: In 2005, the World Health Assembly asked member states to develop effective strategies and programs to reduce the negative consequences of harmful use of alcohol. To develop effective policies, we must already understand the phenomenon of alcohol consumption. But in Francophone west Africa, there are very few studies on the prevalence of alcohol, consumption patterns and factors associated with this consumption. The objectives of this study were to estimate the prevalence of alcohol use in schools in Burkina Faso and to identify socio-demographic factors associated with episodes of â€œheavy drinkingâ€. Method: A cross-sectional study was conducted in October 2013 in six secondary schools of Bobo-Dioulasso. Three hundred and sixty-two students randomly drawn by stratified cluster sampling were interviewed by using a self-administered questionnaire adapted from the model ESPAD and WHO AUDIT questionnaire. HED (Heavy Episodic Drinking) was defined as consuming at least six local measures of alcoholic beverages around the 30 days prior investigation. The search for factors was performed using logistic regression and estimating standard errors were adjusted for clustering data. Results: The prevalence of experimentation of alcohol was estimated to 45.6% [CI 95% = 40.4 - 50.7]. This prevalence was reduced to 34.8% [CI 95% = 29.9 - 39.7], 24.3% [CI 95% = 19.9 - 28.7] and 18% [CI 95% = 14 - 21.9] if one considered the use of alcohol at least once respectively in the 12 months, 30 days and 7 days before the survey. The prevalence of HED was 16% [CI95% = 12.2 - 19.8]. Independent factors associated with the HED were alcohol use by parents or friends and fatherâ€™s occupation. Episodes of â€œheavy drinkingâ€ were 8.3 (CI 95% = 4.9 - 14) and 2.8 (CI 95% = 1.3 - 5.8) respectively more frequent among students whose parents and friends were drinking. Neither religion nor sex nor age was not statistically associated with HED. Conclusion: This study confirms the high prevalence of alcohol consumption in schools in Burkina Faso and challenges policy makers to adopt effective policies to fight against the harmful use of alcohol especially in schools.",2017,Open Journal of Gastroenterology
Lymphotoxin-Î± gene 252G allelic variant is a risk factor for large-vessel-associated ischemic stroke,"A direct role of lymphotoxin-Î± (LTA) in promoting atherosclerotic plaque growth has been demonstrated recently. The different protein transcripts of the naturally occurring genetic variants of the LTA gene have been demonstrated to exhibit affected functions, and an allelic difference in binding to transcription factor(s) has also been suggested. The homozygous variant of LTA characterized by the intron 1 252Aâ†’G (252G) transition, which naturally coexists with an exon 3 804Câ†’A (804A) single-nucleotide polymorphism (SNP), has been reported as a susceptibility gene for myocardial infarction. Because the atherosclerotic process is also an integral component in the pathogenesis of certain types of vascular stroke, we investigated the possible significance of the above SNPs in 353 ischemic stroke patients and 180 healthy controls. The homozygous LTA allele with the 252G and 804C SNPs occurred more frequently in stroke patients (13.9%) than in controls (7.20%, p<0.025). Specific subclassification of the patients revealed an accumulation of these SNPs in large-vessel, pathology-associated cerebral infarction (18.2%); multivariate logistic regression analysis of the data confirmed this association, with an odds ratio of 2.1 (95% confidence interval, 1.3â€“6.2; p<0.005). Elimination of all subjects with a history or evidence of ischemic heart disease, including myocardial infarction, did not affect this association. These data show that besides the role in the development of myocardial infarction, the homozygous carriage of the LTA allele with 252G and 804A SNPs is a novel susceptibility factor for largevesselassociated ischemic stroke.",2007,Journal of Molecular Neuroscience
Gene Expression Profile Alone Is Inadequate In Predicting Complete Responses In Multiple Myeloma,"Abstract 306 Current therapy for multiple myeloma (MM) remains empiric. With advancement in the understanding of its molecular basis, newer therapies are emerging faster than ever with increasing the difficulty in the selection of treatment regime to maximize response and minimize the rising cost of therapy. In recent years, treatment response prediction using gene expression profiling is being evaluated to identify expression signature that can classify patients likely to benefit from chemotherapy, e.g., there are several multi-gene expression assays available to predict treatment responses. However, expression signatures and predictive power vary significantly among these assays. Here, we have assessed the ability of gene expression profile to predict complete response (CR) in patients with MM. We evaluated 128 newly-diagnosed patients with MM enrolled on IFM protocol and treated uniformly with high-dose melphalan followed by autologous stem cell transplant. Seventy one of 128 patients (56%) had achieved CR while the rest 57 (44%) had partial response (PR) or less to this therapeutic intervention. CD138+ MM cells collected at the time of diagnosis were profiled for gene expression and processed using the dChip and aroma.affymetrix module in R software. We have used all common machine learning packages in R/Bioconductor and BRB-array Tools software to build response signature models; the packages used but not limited to were: Decision tree, Support Vector Machines (SVM), Prediction Analysis of Microarray (PAM), K-Nearest Neighbors, Bayesian Additive Regression Trees (BART), Lasso, Ridge regression, amongst others. For accurate assessment of model prediction ability, the dataset was split into training and test sets. Classifier gene models were built, trained and evaluated using K-fold cross-validation followed by model selection based on minimum prediction error. We built several models using different classification methods and experimented with gene inclusion criteria in our datasets according to those features most differentially expressed between CR and non-CR patients. Final model from each of these methods was applied to test dataset to predict CR vs non-CR, and prediction results were evaluated using area under the ROC curve (AUC) as a predictive measure. The maximum AUC among all the training-testing splits was 0.63. The true positive rate (Sensitivity) to correctly predict CR case reached maximum 70% or more at the cost of higher false negative, which is to misclassify a patient as non-CR who might have responded to the treatment. Among the number of methods employed, our best predictive capability provided 66% sensitivity, 60% specificity, 67% positive predictive value and 59% negative predictive value. Importantly, comparing real CR proportion (71/128 = 56%) with that of predicted by the best model (66%), no statistically significant difference was observed (Chi-square; p-value: 0.09). We observe similar results using two independent datasets available in public data repository. Based on our analysis, we recognize and in fact foresee that the expression profile alone has limited ability to predict treatment response especially when response rate is high. This lack of predictability using current approach of response prediction with gene expression alone may be related to several limitations, like alternate splicing, miRNA-based gene regulation, post-translational modifications, binary distribution of response status, inherent variability of new samples, and developing unified signature without consideration of myeloma subtypes. A comprehensive model needs to be developed using global genomic changes to have meaningful output for clinical application. Disclosures: Munshi: Millennium Pharmaceuticals: Membership on an entity9s Board of Directors or advisory committees; Celgene: Membership on an entity9s Board of Directors or advisory committees; Novartis: Membership on an entity9s Board of Directors or advisory committees; Onyx: Membership on an entity9s Board of Directors or advisory committees.",2010,Blood
Local Adaptive Grouped Regularization and its Oracle Properties for Varying Coefficient Regression,"Varying coefficient regression is a flexible technique for modeling data where the coefficients are functions of some effect-modifying parameter, often time or location in a certain domain. While there are a number of methods for variable selection in a varying coefficient regression model, the existing methods are mostly for global selection, which includes or excludes each covariate over the entire domain. Presented here is a new local adaptive grouped regularization (LAGR) method for local variable selection in spatially varying coefficient linear and generalized linear regression. LAGR selects the covariates that are associated with the response at any point in space, and simultaneously estimates the coefficients of those covariates by tailoring the adaptive group Lasso toward a local regression model with locally linear coefficient estimates. Oracle properties of the proposed method are established under local linear regression and local generalized linear regression. The finite sample properties of LAGR are assessed in a simulation study and for illustration, the Boston housing price data set is analyzed.",2014,arXiv: Methodology
Lifting the curse of dimensionality Group-regularized elastic net regression in high dimensional space,"Introduction In genomics research, several different types of data are at the disposal of the researcher. The common denominator of these data types is high dimensionality of the data. Another characteristic of these types of data is the sparsity that is often expected or found. Prediction based on genomics data is complicated by these two issues. Often, extra information on the predictor variables is available, e.g. gene pathways or p-values from a previous study. In this thesis we propose two penalized regression methods for high dimensional data that make use of this extra information. Both methods are suitable for variable selection in a prediction setting. Methods The methods proposed are based on empirical Bayes techniques to estimate multiple penalty parameters. The different penalty parameters are estimated for groups of variables, where the groups are based on the extra information. Estimation is achieved by maximisation of the marginal likelihood of the penalty parameters. The first method proposed maximises the Laplace approximation of this marginal likelihood, while the second method maximises the Monte Carlo approximation of the likelihood. Predictive performance and variable selection of the Monte Carlo method is compared to penalization methods currently available in literature in both a simulation study and a real data example. Conclusion Maximisation of the Laplace approximated log-likelihood proved difficult and not feasible in high-dimensional space. The Monte Carlo approximated likelihood method was reasonably able to estimate the penalty parameters. The method outperformed traditional ridge, lasso and elastic net in terms of prediction. The method competes with GRridge, but is inferior to the group lasso. The proposed method achieves better variable selection than GRridge, ridge, lasso, elastic net and group lasso in most simulated settings. In the real data example performance of all methods is comparable.",2016,
Identification of a nomogram based on long non-coding RNA to improve prognosis prediction of esophageal squamous cell carcinoma,"PURPOSE
Esophageal squamous cell carcinoma (ESCC) remains a common aggressive malignancy in the world. Several long non-coding RNAs (lncRNAs) are reported to predict the prognosis of ESCC. Therefore, an in-depth research is urgently needed to further investigate the prognostic value of lncRNAs in ESCC.


RESULTS
From the training set, we identified a eight-lncRNA signature (including AP000487, AC011997, LINC01592, LINC01497, LINC01711, FENDRR, AC087045, AC137770) which separated the patients into two groups with significantly different overall survival (hazard ratio, HR = 3.79, 95% confidence interval, 95% CI [2.56-5.62]; P < 0.001). The signature was applied to the validation set (HR = 2.73, 95%CI [1.65-4.53]; P < 0.001) and showed similar prognostic values. Stratified, univariate and multivariate Cox regression analysis indicated that the signature was an independent prognostic factor for patients with ESCC. A nomogram based on the lncRNAs signature, age, grade and stage was developed and showed good accuracy for predicting 1-, 3- and 5-year survival probability of ESCC patients. We found a strong correlation between the gene significance for the survival time and T stage. Eight modules were constructed, among which the key module most closely associated with clinical information was identified.


CONCLUSIONS
Our eight-lincRNA signature and nomogram could be practical and reliable prognostic tools for esophageal squamous cell carcinoma.


METHODS
We downloaded the lncRNA expression profiles of ESCC patients from Gene Expression Omnibus (GEO) and The Cancer Genome Atlas (TCGA) datasets and separated to training and validation cohort. The univariate, least absolute shrinkage and selection operator (LASSO) and multivariate Cox regression analysis were used to identify a lncRNA-based signature. The predictive value of the signature was assessed using the Kaplan-Meier method, receiver operating characteristic (ROC) curves and area under curve (AUC). Weighted gene co-expression network analysis (WGCNA) was applied to predict the intrinsic relationship between gene expressions. In addition, we further explored the combination of clinical information and module construction.",2020,Aging (Albany NY)
Application of CT-based radiomics in predicting portal pressure and patient outcome in portal hypertension.,"PURPOSE
Portal venous pressure (PVP) measurement is of clinical significance, especially in patients with portal hypertension. However, the invasive nature and associated complications limits its application. The aim of the study is to propose a noninvasive predictive model of PVP values based on CT-extracted radiomic features.


METHODS
Radiomics PVP (rPVP) models based on liver, spleen and combined features were established on an experimental cohort of 169 subjects. Radiomics features were extracted from each ROI and reduced via the LASSO regression to achieve an optimal predictive formula. A validation cohort of 62 patients treated for gastroesophageal varices (GOV) was used to confirm the utility of rPVP in predicting variceal recurrence. The association between rPVP and response to treatment was observed.


RESULTS
Three separate predictive formula for PVP were derived from radiomics features. rPVP was significantly correlated to patient response to endoscopic treatment for GOV. Among which, the model containing both liver and spleen features has the highest predictability of variceal recurrence, with an optimal cut-off value at 29.102â€¯mmHg (AUC 0.866). A Kaplan Meier analysis further confirmed the difference between patients with varying rPVP values.


CONCLUSION
PVP values can be accurately predicted by a non-invasive, CT derived radiomics model. rPVP serves as a non-invasive and precise reference for predicting treatment outcome for GOV secondary to portal hypertension.",2020,European journal of radiology
Agronomic Practices for Reducing Wheat Yield Gaps: A Quantitative Appraisal of Progressive Producers,"There is limited information on agronomic practices affecting wheat (Triticum aestivum L.) yield in intensively managed dryland systems despite the opportunity to narrow the existing yield gap (YG). We used a unique database of 100 intensively managed field-years entered in the Kansas Wheat Yield Contest during the 2010 to 2017 harvest seasons to (i) quantify the YG, (ii) describe wheat management, and (iii) identify management opportunities and weather patterns associated with yield. We simulated wheat water-limited yield (Yw) using Simple Simulation Modelingâ€“Wheat (SSM-Wheat) model for each field-year to estimate YG as the difference between Yw and actual yield (Ya) and used 11 statistical approaches to test the association of management practices and weather variables with Ya. Wheat Ya averaged 5.5 Mg ha âˆ’1, and simulated Yw averaged 6.4 Mg ha âˆ’1, resulting in a YG of 0.9 Mg haâˆ’1 (15% of Yw). High-yielding fields had lower maximum and minimum temperatures and greater cumulative solar radiation and precipitation during grain fill. Varieties susceptible to fungal diseases responded to foliar fungicide (0.8â€“1.4 Mg haâˆ’1), whereas resistant varieties did not. Seeding rate was negatively associated with Ya, as yield quantile 0.99 was 7.5 Mg ha âˆ’1 and decreased by 2.7 Mg haâˆ’1 for every 100-seed mâˆ’2 increase in seeding rate above 305 seeds mâˆ’2. In-furrow P fertilizer, previous crop, tillage practice, and N timing were also associated with Ya. We conclude that fields entered in yield contests have closed the exploitable YG, and there are opportunities to improve Ya through improved management in regions with stagnant wheat yield. R.P. Lollato, D.A. Ruiz Diaz, M. Knapp, D.E. Peterson, and A.K. Fritz, Dep. of Agronomy, Kansas State Univ., Manhattan, KS 66506; E. DeWolf, Dep. of Plant Pathology, Kansas State Univ., Manhattan, KS 66506. Received 13 Apr. 2018. Accepted 7 Oct. 2018. *Corresponding author (lollato@ksu.edu). Assigned to Associate Editor Qingwu Xue. Abbreviations: BIC, Bayesian information criterion; DOY, day of year; ETc, crop evapotranspiration; ETo, reference crop evapotranspiration; ICC, intraclass correlation coefficient; LAR, least angle regression; LASSO, least squared shrinkage operator; RS, incident solar radiation; SSM-Wheat, Simple Simulation Modelingâ€“Wheat; TKW, 1000-kernel weight; Tmax, maximum temperature; Tmin, minimum temperature; Ya, actual yield; YG, yield gap; Yw, water-limited yield. Published in Crop Sci. 59:333â€“350 (2019). doi: 10.2135/cropsci2018.04.0249 Â© Crop Science Society of America | 5585 Guilford Rd., Madison, WI 53711 USA This is an open access article distributed under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Published December 20, 2018",2019,Crop Science
Screening active ingredients of rosemary based on spectrum-effect relationships between UPLC fingerprint and vasorelaxant activity using three chemometrics.,"Rosmarinus officinalis L., rosemary, is traditionally used to treat headache and improve cardiovascular disease partly due to its vasorelaxant activity, while the vasorelaxant ingredients remain unclear. In this study, chemical spectrum-pharmacological effect relationship (spectrum-effect relationship) was utilized for efficiently discovering the main vasorelaxant ingredients of rosemary. Ten kinds of rosemary extracts were prepared by different extracting solvents and macroporous resin purification, and their chemical components were analyzed by UPLC. At the same time, the vasorelaxant activities of the 10 kinds of rosemary extracts were estimated on isolated rat thoracic aorta, and three chemometrics named partial least squares regression (PLSR), grey correlation analysis (GRA), and the least absolute shrinkage and selection operator (LASSO) were applied to construct spectrum-effect relationship between the UPLC fingerprints and vasorelaxant activity of rosemary extracts. As a result, most rosemary extracts showed dose-dependent increase in vasorelaxant activity and five kinds of ingredients, including carnosol, carnosic acid, epirosmanol methyl ether, carnosol isomer, and augustic acid were screened as vasorelaxant ingredients. Further, the vasorelaxant activities of carnosic acid and carnosol were verified. Moreover, the increase of nitric oxide (NO) and the decrease of angiotensin-II (Ang-II) were thought to contribute to the vasorelaxant activity of rosemary.",2019,"Journal of chromatography. B, Analytical technologies in the biomedical and life sciences"
A model using concomitant markers for predicting outcome in human papillomavirus positive oropharyngeal cancer.,"OBJECTIVE
Head-neck cancer therapy has become intensified. With radiotherapy alone, 3-year disease-free survival (DFS) is 80% for HPV-positive TSCC/BOTSCC and better for patients with favorable characteristics, suggesting therapy could be tapered for some, decreasing side-effects. Therefore, we built a model to predict progression-free survival for patients with HPV-positive TSCC and BOTSCC.


MATERIAL AND METHODS
TSCC/BOTSCC patients treated curatively between 2000 and 2011, with HPV16 DNA/E7 mRNA positive tumors examined for CD8+ TILs, HPV16 mRNA and HLA class I expression were included. Patients were split randomly 65/35 into training and validation sets, and LASSO regression was used to select a model in the training set, the performance of which was evaluated in the validation set.


RESULTS
258 patients with HPV DNA/E7 mRNA positive tumors could be included, 168 and 90 patients in the respective sets. No treatment improved prognosis compared to radiotherapy alone. CD8+ TIL counts and young age were the strongest predictors of survival, followed by T-stage <3 and presence of HPV16 E2 mRNA. The model had an area under curve (AUC) of 76%. A model where the presence of three of four of these markers defined good prognosis captured 56% of non-relapsing patients with a positive predictive value of 98% in the validation set. Furthermore, the model identified 35% of our cohort that was overtreated and could safely have received de-escalated therapy.


CONCLUSION
CD8+ TIL counts, age, T-stage and E2 expression could predict progression-free survival, identifying patients eligible for randomized trials with milder treatment, potentially reducing side effects without worsening prognosis.",2017,Oral oncology
Modeling of Biological Data Based on Regression Methods,"The ordinary least square estimates of multiple regression parameters is characterized by low bias and large variance leading to poor performance in both prediction and interpretation of the regression model under study. Penalized regression techniques represented in ridge, lasso and elastic net were used to improve the ordinary least square estimates performance. Categorical regression algorithm provides efficient procedure for computing the regression coefficients of ridge, lasso, and elastic Net models. The statistical analysis was done on ten single nucleotide polymorphisms simulated data with strong linkage disequilibrium as predictors of a continuous phenotypic trait. The coefficients were 39%, 34%, 29% and 28% for ridge, elastic net, lasso and stepwise multiple regression methods, respectively. The current study finished that ridge regression followed by elastic net regression performed better than the other regression methods.",2018,
Regenerative Simulation for the Bayesian Lasso,"The Gibbs sampler of Park and Casella is one of the most popular MCMC methods for sampling from the posterior density of the Bayesian Lasso regression. As with many Markov chain samplers, their Gibbs sampler lacks a theoretically sound method of output analysis --- a method for estimating the variance of a given ergodic average and estimating how closely the chain is sampling from the stationary distribution, that is, the burn-in. 
In this paper, we address this shortcoming by identifying regenerative structure in the sampler of Park and Casella, thus providing a theoretically sound method of assessing its performance. The regenerative structure provides both a strongly consistent variance estimator, and an estimator of (an upper bound on) the total variation distance from the target posterior density. The result is a simple and theoretically sound way to assess the stationarity of the Park and Casella and, more generally, other MCMC samplers, for which regenerative simulation is possible. 
We perform a numerical study in which we validate the standard errors calculated by our regenerative method by comparing it with the standard errors calculated by an AR(1) heuristic approximation. Thus, we show that for the Bayesian Lasso model, the regenerative method is a viable and theoretically justified alternative to the existing ad-hoc MCMC convergence diagnostics.",2018,arXiv: Computation
"Pain catastrophizing, anxiety, and depression in hip pathology.","AIMS
Psychological factors play a critical role in patient presentation, satisfaction, and outcomes. Pain catastrophizing, anxiety, and depression are important to consider, as they are associated with poorer outcomes and are potentially modifiable. The aim of this study was to assess the level of pain catastrophizing, anxiety, and depression in patients with a range of hip pathology and to evaluate their relationship with patient-reported psychosocial and functional outcome measures.


PATIENTS AND METHODS
Patients presenting to a tertiary-centre specialist hip clinic were prospectively evaluated for outcomes of pain catastrophizing, anxiety, and depression. Validated assessments were undertaken such as: the Pain Catastrophizing Scale (PCS), the Hospital Anxiety Depression Scale (HADS), and the 12-Item Short-Form Health Survey (SF-12). Patient characteristics and demographics were also recorded. Multiple linear regression modelling, with adaptive least absolute shrinkage and selection operator (LASSO) variable selection, was used for analysis.


RESULTS
A total of 328 patients were identified for inclusion, with diagnoses of hip dysplasia (DDH; n = 50), femoroacetabular impingement (FAI; n = 55), lateral trochanteric pain syndrome (LTP; n = 23), hip osteoarthrosis (OA; n = 184), and avascular necrosis of the hip (AVN; n = 16) with a mean age of 31.0 years (14 to 65), 38.5 years (18 to 64), 63.7 years (20 to 78), 63.5 years (18 to 91), and 39.4 years (18 to 71), respectively. The percentage of patients with abnormal levels of pain catastrophizing, anxiety, or depression was: 22.0%, 16.0%, and 12.0% for DDH, respectively; 9.1%, 10.9%, and 7.3% for FAI, respectively; 13.0%, 4.3%, and 4.3% for LTP, respectively; 21.7%, 11.4%, and 14.1% for OA, respectively; and 25.0%, 43.8%, and 6.3% for AVN, respectively. HADS Anxiety (HADSA) and Hip Disability Osteoarthritis Outcome Score Activities of Daily Living subscale (HOOS ADL) predicted the PCS total (adjusted R2 = 0.4599). Age, HADS Depression (HADSD), and PCS total predicted HADSA (adjusted R2 = 0.4985). Age, HADSA, patient's percentage of perceived function, PCS total, and HOOS Quality of Life subscale (HOOS QOL) predicted HADSD (adjusted R2 = 0.5802).


CONCLUSION
Patients with hip pathology may exhibit significant pain catastrophizing, anxiety, and depression. Identifying these factors and understanding the impact of psychosocial function could help improve patient treatment outcomes. Perioperative multidisciplinary assessment may be a beneficial part of comprehensive orthopaedic hip care. Cite this article: Bone Joint J 2019;101-B:800-807.",2019,The bone & joint journal
