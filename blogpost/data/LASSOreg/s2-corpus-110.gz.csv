title,abstract,year,journal
CT-based radiomic signatures for prediction of pathologic complete response in esophageal squamous cell carcinoma after neoadjuvant chemoradiotherapy,"The objective of this study was to build models to predict complete pathologic response (pCR) after neoadjuvant chemoradiotherapy (nCRT) in esophageal squamous cell carcinoma (ESCC) patients using radiomic features. A total of 55 consecutive patients pathologically diagnosed as having ESCC were included in this study. Patients were divided into a training cohort (44 patients) and a testing cohort (11 patients). The logistic regression analysis using likelihood ratio forward selection was performed to select the predictive clinical parameters for pCR, and the least absolute shrinkage and selection operator (LASSO) with logistic regression to select radiomic predictors in the training cohort. Model performance in the training and testing groups was evaluated using the area under the receiver operating characteristic curves (AUC). The multivariate logistic regression analysis identified no clinical predictors for pCR. Thus, only radiomic features selected by LASSO were used to build prediction models. Three logistic regression models for pCR prediction were developed in the training cohort, and they were able to predict pCR well in both the training (AUC, 0.84-0.86) and the testing cohorts (AUC, 0.71-0.79). There were no differences between these AUCs. We developed three predictive models for pCR after nCRT using radiomic parameters and they demonstrated good model performance.",2019,Journal of Radiation Research
Machine Learning Enabled Computational Screening of Inorganic Solid Electrolytes for Dendrite Suppression with Li Metal Anode,"Next generation batteries based on lithium (Li) metal anodes have been plagued by the dendritic electrodeposition of Li metal on the anode during cycling, resulting in short circuit and capacity loss. Suppression of dendritic growth through the use of solid electrolytes has emerged as one of the most promising strategies for enabling the use of Li metal anodes. We perform a computational screening of over 12,000 inorganic solids based on their ability to suppress dendrite initiation in contact with Li metal anode. Properties for mechanically isotropic and anisotropic interfaces that can be used in stability criteria for determining the propensity of dendrite initiation are 1 ar X iv :1 80 4. 04 65 1v 1 [ co nd -m at .m tr lsc i] 1 2 A pr 2 01 8 usually obtained from computationally expensive first-principles methods. In order to obtain a large dataset for screening, we use machine learning models to predict the mechanical properties of several new solid electrolytes. The machine learning models are trained on purely structural features of the material, which do not require any first-principles calculations. We train a convolutional neural network on the shear and bulk moduli because of the availability of a large training dataset that has low noise due to low uncertainty in their first-principles calculated values. We use AdaBoost, Lasso and Bayesian ridge regression to train the elastic constants, where the choice of the model depended on the size of the training data and the noise that it can handle. Our models give us direct interpretability by revealing the dominant structural features affecting the elastic constants. The stiffness is found to increase with a decrease in volume per atom, increase in minimum anion-anion separation, and increase in sublattice (all but Li) packing fraction. Cross-validation/test performance suggests our models generalize well. We predict over twenty mechanically anisotropic interfaces between Li metal and six solid electrolytes which can be used to suppress dendrite growth. Our screened candidates are generally soft and highly anisotropic, and present opportunities for simultaneously obtaining dendrite suppression and high ionic conductivity in solid electrolytes.",2018,ArXiv
Super-Resolution Image Reconstruction using Sparse Representation,"This thesis addresses theigeneration andireconstruction of theihigh resolution (HR) imageiby using theisingle low resolution (LR) imageiand the linear coalitioniof sparse coefficientsifrom a suitablyichosen over-complete dictionary. The studyiof compressiveisensing shows thatiunder vague conditionsithe sparseirepresentation of a signalican be effectivelyirecovered from the down-samplediversion of the originalisignal. By training bothiLR and HRiimage patches simultaneouslyiby coupled dictionaryilearning, we areienforcing the similarityibetween the sparseirepresentation(SR) of LR and HRiimage patch pairsiwith respective toitheir LR and HR dictionaries. Literature surveyisuggests that differentiextracted features areiused to computeithe coefficients toiboost the predictioniaccuracy of the HRiimage patch reconstruction. Aiset of firstiand second orderi filters hasibeen employed toiextract useful features fromithe LR patch. As theisuper resolution is aniill posed problem, in this thesis weihave considered it asian optimization problemifor getting theisparsest representation ofiimage patches usingilinear regression regularizediwith L1 norm, known as a LASSOiin statistics. Our method isifound to beioutperforming the other previousistate of art methodsiin both quantitativeiand qualitative analysis. The resultsireveal that proposedimethod shows promisingiresults in reconstructing the imageitextures andiedges.",2017,
Data-Driven Bus Crowding Prediction Based on Real-Time Passenger Counts and Vehicle Locations,"The paper addresses the bus crowding prediction problem based on real-time vehicle location and passenger count data and evaluates the performance of a data-driven lasso regression prediction method. The problem is studied for a highfrequency bus line in Stockholm, Sweden. Prediction accuracy is evaluated with respect to absolute passenger loads and predefined discrete crowding levels. When available, predictions with realtime vehicle location and, in particular, passenger count data significantly outperform predictions based only on historical data, with accuracy improvements varying in magnitude across target stations and prediction horizons.",2019,
Shrinkage and Penalty Estimation Strategies in Some Spatial Models,"In this dissertation, we study the asymptotic properties of pretest and shrinkage estimators of the large-scale effect in some spatial regression models, and compare their relative performance with respect to the classical maximum likelihood estimator (MLE) analytically and numerically through Monte Carlo experiments and real data examples. The shrinkage estimators were also numerically compared with three penalty estimators, namely, the LASSO, adaptive LASSO, and the SCAD penalty functions. A linear model with conditional autoregressive errors was studied in Chapter 2. The asymptotic properties of the shrinkage estimators, under local alternatives, were established, including the derivations of the asymptotic distributional bias, asymptotic mean squared error matrix, and the asymptotic quadratic risk. These results showed the effectiveness of the suggested estimation technique. Monte Carlo experiments with two real data examples were conducted to demonstrate the superiority of the proposed shrinkage estimators over the MLE and the penalty estimators. In Chapter 3, we consider another spatial case of a linear model with simultaneous autoregressive errors. We study the properties of the shrinkage estimators and compare their performance with the penalty estimators numerically through simulation studies and real data examples. Chapter 4 contains a study of a general linear model with spatial moving average error terms. Asymptotic properties of the shrinkage estimators for the mean parameter vector are investigated. A numerical comparison is carried out and the relative performance of estimators is investigated. Finally, we summarize the findings of the thesis in Chapter 5. Also, some problems for future research are outlined in Chapter 5.",2013,
Analyse d'un grand jeu de donnÃ©es en Ã©pidÃ©miologie : problÃ©matiques et perspectives mÃ©thodologiques,"L'augmentation de la taille des jeux de donnees est une problematique croissante en epidemiologie. La cohorte CoPanFlu-France (1450 sujets), proposant une etude du risque d'infection par la grippe H1N1pdm comme une combinaison de facteurs tres divers en est un exemple. Les methodes statistiques usuelles (e.g. les regressions) pour explorer des associations sont limitees dans ce contexte. Nous comparons l'apport de methodes exploratoires data-driven a celui de methodes hypothesis-driven.Une premiere approche data-driven a ete utilisee, evaluant la capacite a detecter des facteurs de l'infection de deux methodes de data mining, les forets aleatoires et les arbres de regression boostes, de la methodologie "" regressions univariees/regression multivariee"" et de la regression logistique LASSO, effectuant une selection des variables importantes. Une approche par simulation a permis d'evaluer les taux de vrais et de faux positifs de ces methodes. Nous avons ensuite realise une etude causale hypothesis-driven du risque d'infection, avec un modele d'equations structurelles (SEM) a variables latentes, pour etudier des facteurs tres divers, leur impact relatif sur l'infection ainsi que leurs relations eventuelles. Cette these montre la necessite de considerer de nouvelles approches statistiques pour l'analyse des grands jeux de donnees en epidemiologie. Le data mining et le LASSO sont des alternatives credibles aux outils conventionnels pour la recherche d'associations. Les SEM permettent l'integration de variables decrivant differentes dimensions et la modelisation explicite de leurs relations, et sont des lors d'un interet majeur dans une etude multidisciplinaire comme CoPanFlu.",2014,
High dimensional confounding adjustment using continuous spike and slab priors,"In observational studies, estimation of a causal effect of a treatment on an outcome relies on proper adjustment for confounding. If the number of the potential confounders ($p$) is larger than the number of observations ($n$), then direct control for all potential confounders is infeasible. Existing approaches for dimension reduction and penalization are generally aimed at predicting the outcome, and are less suited for estimation of causal effects. Under standard penalization approaches (e.g. Lasso), if a variable $X_j$ is strongly associated with the treatment $T$ but weakly with the outcome $Y$, the coefficient $\beta_j$ will be shrunk towards zero thus leading to confounding bias. 
Under the assumption of a linear model for the outcome and sparsity, we propose continuous spike and slab priors on the regression coefficients $\beta_j$ corresponding to the potential confounders $X_j$. Specifically, we introduce a prior distribution that does not heavily shrink to zero the coefficients ($\beta_j$s) of the $X_j$s that are strongly associated with $T$ but weakly associated with $Y$. We compare our proposed approach to several state of the art methods proposed in the literature. Our proposed approach has the following features: 1) it reduces confounding bias in high dimensional settings; 2) it shrinks towards zero coefficients of instrumental variables; and 3) it achieves good coverages even in small sample sizes. We apply our approach to the National Health and Nutrition Examination Survey (NHANES) data to estimate the causal effects of persistent pesticide exposure on triglyceride levels.",2017,arXiv: Methodology
Bayesian Adaptive Lasso for Ordinal Regression with Latent Variables.,We consider an ordinal regression model with latent variables to investigate the effects of observable and latent explanatory variables on the ordinal responses of interest. Each latent variable is characterized by correlated observed variables through a confirmatory factor analysis model. We develop a Bayesian adaptive lasso procedure to conduct simultaneous estimation and variable selection. Nice features including empirical performance of the proposed methodology are demonstrated by simulation studies. The model is applied to a study on happiness and its potential determinants from the Inter-university Consortium for Political and Social Research.,2017,Sociological Methods & Research
Sparse Relaxed Regularized Regression: SR3,"Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression in particular has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a new and highly effective approach for regularized regression, called SR3. 
The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: (1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning, (2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations, and (3) the methods apply to composite regularizers such as total variation (TV) and its nonconvex variants. We demonstrate the improved performance of SR3 across a range of regularized regression problems with synthetic and real data, including compressed sensing, LASSO, matrix completion and TV regularization. To promote reproducible research, we include a companion Matlab package that implements these popular applications.",2018,ArXiv
Analysis of Influencing Factors of Fiscal Revenue in Zhejiang Province Based on Data Mining Technology,"è´¢æ”¿æ˜¯æ”¿åºœå®žçŽ°å…¶èŒèƒ½çš„åŸºç¡€ï¼Œæ‰¿æ‹…ç€èµ„æºæ•´åˆã€èµ„æºå†åˆ†é…ä»¥åŠå®è§‚ç»æµŽè°ƒæŽ§çš„èŒèƒ½ã€‚ä¸Žæ­¤åŒæ—¶ï¼Œè´¢æ”¿ä¹Ÿæ˜¯ç¤¾ä¼šç»æµŽå‘å±•æ°´å¹³çš„é‡è¦ä½“çŽ°ã€‚ç”±æ­¤å¯è§ï¼Œæé«˜è´¢æ”¿æ”¶å…¥çš„é¢„æµ‹ç²¾åº¦å¯¹å›½å®¶ã€åœ°æ–¹æ¥è¯´æ„ä¹‰é‡å¤§ã€‚ä¸ºäº†æå‡æµ™æ±Ÿçœè´¢æ”¿æ”¶å…¥çš„é¢„æµ‹ç²¾åº¦ï¼Œæˆ‘ä»¬ä»¥Rè¯­è¨€ä¸ºç¼–ç¨‹å·¥å…·ï¼Œé¦–å…ˆé€šè¿‡æœ€ä¼˜å­é›†æ³•ã€å‘å‰é€æ­¥å›žå½’æ³•ã€å‘åŽé€æ­¥å›žå½’æ³•ã€å²­å›žå½’åŠLassoæ³•åˆ†åˆ«å¯¹æµ™æ±Ÿçœè´¢æ”¿æ”¶å…¥çš„å½±å“å› ç´ è¿›è¡Œåˆ†æžï¼Œå¾—åˆ°äº†5ç§å›žå½’æ¨¡åž‹å¹¶é€šè¿‡å®ƒä»¬å„è‡ªçš„å‡æ–¹æ ¹è¯¯å·®(RMSE)æ¥è¯„ä¼°å…¶å›žå½’æ•ˆæžœã€‚æœ€åŽï¼Œé€‰å–Lassoå›žå½’æ¨¡åž‹ä¸ºæœ€ä¼˜å›žå½’æ¨¡åž‹ã€‚å…¶ä¸­ï¼Œå½±å“æµ™æ±Ÿçœè´¢æ”¿æ”¶å…¥çš„å…³é”®æ€§å› ç´ ä¸ºï¼šæ—…æ¸¸åˆ›æ±‡æ”¶å…¥ã€åŸŽé•‡å•ä½å°±ä¸šäººå‘˜å¹³å‡å·¥èµ„ã€ç¬¬ä¸‰äº§ä¸šä¸Žç¬¬äºŒäº§ä¸šäº§å€¼æ¯”ã€å…¨éƒ¨é‡‘èžæœºæž„äººæ°‘å¸å­˜æ¬¾ä½™é¢è¿™å››é¡¹æŒ‡æ ‡ã€‚ Finance is the basis of governments to perform their functions whose basic responsibilities are the resource integration, resource reallocation and macroeconomic regulation and control. Besides, finance reflects the level of the development of social and economic to a great degree. This is why, to our country, enhancing the predict accuracy of finance means a lot. In order to accomplish this task, we analyzed the factors of influencing Zhejiang Provinceâ€™s fiscal revenue, used best subset selection, forward stepwise selection, backward stepwise selection, ridge regression and Lasso regression respectively by using R software. We also give evaluation efficiency of each model by using root-mean-square errors. Finally, we find that the Lasso regression model is the optimal regression model, which can pick the key factors affecting the financial income of Zhejiang province for the four balances: tourism earned foreign exchange earnings, the average wage of urban employees employed, the ratio of the third industry to the second industry, and the RMB deposits of all financial institutions.",2017,
The lasso method for variable selection in the Cox model.,"I propose a new method for variable selection and shrinkage in Cox's proportional hazards model. My proposal minimizes the log partial likelihood subject to the sum of the absolute values of the parameters being bounded by a constant. Because of the nature of this constraint, it shrinks coefficients and produces some coefficients that are exactly zero. As a result it reduces the estimation variance while providing an interpretable final model. The method is a variation of the 'lasso' proposal of Tibshirani, designed for the linear regression context. Simulations indicate that the lasso can be more accurate than stepwise selection in this setting.",1997,Statistics in medicine
Endmember finding and spectral unmixing using least-angle regression,"A new endmember finder and spectral unmixing algorithm based on the LARS/Lasso method for linear regression is developed. The endmember finder is sequential; a single endmember is identified at first and further endmembers which depend on the previous ones are found. The process terminates once a pre-determined number of endmembers have been found, or when the modeling error has attained the noise floor. The unmixing algorithm is a straightforward procedure that expresses each pixel as a linear combination of endmembers in a physically meaningful way. This algorithm successfully unmixes simulated data, and shows promising results on real hyperspectral images as well.",2010,
"Regression Shrinkage and Selection via the Elastic Net , with Applications to Microarrays","We propose the elastic net, a new regression shrinkage and selection method. Real data and a simulation study show that the elastic net often outperforms the lasso, while it enjoys a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strong correlated predictors are kept in the model. The elastic net is particularly useful in the analysis of microarray data in which the number of genes (predictors) is much bigger than the number of samples (observations). We show how the elastic net can be used to construct a classification rule and do automatic gene selection at the same time in microarray data, where the lasso is not very satisfied. We also propose an efficient algorithm for solving the elastic net based on the recently invented LARS algorithm. keywords: Gene selection; Grouping effect; Lasso; LARS algorithm; Microarray classification.",2003,
Shrinkage Estimation of the Varying Coefficient Model,"The varying coefficient model is a useful extension of the linear regression model. Nevertheless, how to conduct variable selection for the varying coefficient model in a computationally efficient manner is poorly understood. To solve the problem, we propose here a novel method, which combines the ideas of the local polynomial smoothing and the Least Absolute Shrinkage and Selection Operator (LASSO). The new method can do nonparametric estimation and variable selection simultaneously. With a local constant estimator and the adaptive LASSO penalty, the new method can identify the true model consistently, and that the resulting estimator can be as efficient as the oracle estimator. Numerical studies clearly confirm our theories. Extension to other shrinkage methods (e.g., the SCAD, i.e., the Smoothly Clipped Absolute Deviation.) and other smoothing methods is straightforward.",2009,Journal of the American Statistical Association
ë°ì¼ë¦¬ ë Œì¦ˆ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ë°ì´í„°ë§ˆì´ë‹ ê¸°ë²• ë¹„êµ,"ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì¼€íŒ…ê³¼ ì‹œìž¥ì˜ˆì¸¡ ë“±ì˜ ë¶„ì•¼ì—ì„œ ë¶„ë¥˜ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ë°ì´í„°ë§ˆì´ë‹ ê¸°ë²•ë“¤ì´ ì ìš©ë˜ê³  ìžˆë‹¤. ë³¸ ì—°êµ¬ì—ì„œëŠ” ë°ì¼ë¦¬ ë Œì¦ˆ ê³ ê°ë“¤ì˜ ê±°ëž˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ì‚¬ê²°ì •ë‚˜ë¬´, ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜•ê³¼ ê°™ì€ ê¸°ì¡´ì˜ í†µê³„ì  ë¶„ë¥˜ê¸°ë²•ê³¼ ìµœê·¼ì— ê°œë°œëœ ë°°ê¹…, ë¶€ìŠ¤íŒ…, ë¼ì†Œ, ëžœë¤ í¬ë¦¬ìŠ¤íŠ¸ ê·¸ë¦¬ê³  ì§€ì§€ë²¡í„°ê¸°ê³„ì˜ ë¶„ë¥˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³ ìž í•œë‹¤. ë¹„êµ ì‹¤í—˜ì„ ìœ„í•´ ë°ì´í„° ì •ì œ, íƒìƒ‰, íŒŒìƒë³€ìˆ˜ ìƒì„±, ê·¸ë¦¬ê³  ë³€ìˆ˜ ì„ íƒê³¼ì •ì„ ê±°ì³¤ë‹¤. ì‹¤í—˜ê²°ê³¼ ì •ë¶„ë¥˜ìœ¨ ì¸¡ë©´ì—ì„œëŠ” ì§€ì§€ë²¡í„°ê¸°ê³„ê°€ ë‹¤ë¥¸ ëª¨í˜•ë³´ë‹¤ ê·¼ì†Œí•˜ê²Œ ë†’ì•˜ì§€ë§Œ í‘œì¤€íŽ¸ì°¨ê°€ í¬ê²Œ ë‚˜ì™”ë‹¤. ì •ë¶„ë¥˜ìœ¨ê³¼ í‘œì¤€íŽ¸ì°¨ì˜ ê´€ì ì—ì„œëŠ” ëžœë¤ í¬ë¦¬ìŠ¤íŠ¸ê°€ ê°€ìž¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜ ëª¨í˜•ì˜ í•´ì„, ê°„ëª…ì„± ê·¸ë¦¬ê³  í•™ìŠµì— ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ê³ ë ¤í•˜ì˜€ì„ ë•Œ ë¼ì†Œëª¨í˜•ì´ ì í•©í•˜ë‹¤ëŠ” ê²°ë¡ ì„ ë‚´ë ¸ë‹¤. ã€To solve the classification problems, various data mining techniques have been applied to database marketing, credit scoring and market forecasting. In this paper, we compare various techniques such as bagging, boosting, LASSO, random forest and support vector machine with the daily lens transaction data. The classical techniques-decision tree, logistic regression-are used too. The experiment shows that the random forest has a little smaller misclassification rate and standard error than those of other methods. The performance of the SVM is good in the sense of misclassfication rate and bad in the sense of standard error. Taking the model interpretation and computing time into consideration, we conclude that the LASSO gives the best result.ã€‘",2013,
Estimation methodology for portfolio construction under uncertainty.,"Portfolio selection is a financial decision problem faced by all investors. Private investors, companies or financial institutions need to decide on how to invest in assets by selecting a portfolio according to some optimality criterion and under possible constraints. Expressed in mathematical terms, the portfolio optimization problem involves quantities which are usually estimated from historical data. Such estimates are accompanied by uncertainty which, via the optimization process, is transferred to the investment decisions, thus rendering many portfolio estimators unstable or unreliable. This thesis approaches the problem from two angles. On the one hand, we propose an improvement of the sample moments plug-in estimator through its bootstrap distribution. A robust measure of location of this distribution results, on average, in better out-of-sample performance, especially when the original estimator exhibits high instability, as illustrated by simulations. On the other hand we propose an alternative way of choosing the optimal intensity of two shrinkage estimators. These estimators stabilize the portfolio by applying shrinkage towards desirable targets. In the first case, these targets are the conventional ones for the mean and the covariance matrix, whereas in the second case we allow for additional market information to be included. Our method again uses bootstrap resamples to account for each estimator's possible out-of-sample performance. Finally, we consider the problem from a practitioner's perspective by including transaction costs. We exploit a striking similarity between the new optimization problem and the lasso estimator, a variation of the ordinary least squares estimator. We modify accordingly and extend further an existing algorithm for the solution of this problem and present the results. The new algorithm allows for additional constraints on the model coefficients and could be useful in a regression framework when assumptions on the coefficients' sign or magnitude are made.",2004,
Comparison of partial least squares and lasso regression techniques as applied to laser-induced breakdown spectroscopy of geological samples,"Abstract A remote laser-induced breakdown spectrometer (LIBS) designed to simulate the ChemCam instrument on the Mars Science Laboratory Rover Curiosity was used to probe 100 geologic samples at a 9-m standoff distance. ChemCam consists of an integrated remote LIBS instrument that will probe samples up to 7Â m from the mast of the rover and a remote micro-imager (RMI) that will record context images. The elemental compositions of 100 igneous and highly-metamorphosed rocks are determined with LIBS using three variations of multivariate analysis, with a goal of improving the analytical accuracy. Two forms of partial least squares (PLS) regression are employed with finely-tuned parameters: PLS-1 regresses a single response variable (elemental concentration) against the observation variables (spectra, or intensity at each of 6144 spectrometer channels), while PLS-2 simultaneously regresses multiple response variables (concentrations of the ten major elements in rocks) against the observation predictor variables, taking advantage of natural correlations between elements. Those results are contrasted with those from the multivariate regression technique of the l east a bsolute s hrinkage and s election o perator (lasso), which is a penalized shrunken regression method that selects the specific channels for each element that explain the most variance in the concentration of that element. To make this comparison, we use results of cross-validation and of held-out testing, and employ unscaled and uncentered spectral intensity data because all of the input variables are already in the same units. Results demonstrate that the lasso, PLS-1, and PLS-2 all yield comparable results in terms of accuracy for this dataset. However, the interpretability of these methods differs greatly in terms of fundamental understanding of LIBS emissions. PLS techniques generate principal components, linear combinations of intensities at any number of spectrometer channels, which explain as much variance in the response variables as possible while avoiding multicollinearity between principal components. When the selected number of principal components is projected back into the original feature space of the spectra, 6144 correlation coefficients are generated, a small fraction of which are mathematically significant to the regression. In contrast, the lasso models require only a small number (",2012,Spectrochimica Acta Part B: Atomic Spectroscopy
Application of variable selection and dimension reduction on predictors of MSEâ€™s development,"Nature create variables using its character component, and variables are sharing characters from a vary small to relatively large scale. This results, variables to have from a vary different to a more similar character, and leads to have a relation ship. Literature suggested different relation measures based on the nature of variable and type of relation ship exist. Today, due to having high variety of frequently produced large data size, currently suggested variable filtering and selection methods have gaps to full fill the need. This research desires to fill this gap by comparing literature suggested methods to finding out a better variable selection and dimension reduction methods. The result from regression analysis using all literature suggested factors shows that none of the predictors for development status of enterprise are significant, and only 10 predictors for number of employer in an enterprise are significant out of 81 factors. Since, variable selection and dimension reduction methods are applied to find out predictors of a response by removing variable redundancy, and complexity of incorporating large number variable. Based on statistical power, for the results from variable selection methods, specially association and correlation methods showed that, CANOVA more efficiently detects non-linear or non-monotonic correlation between a continuousâ€“continuous and a continuous-categorical variables. Spearmanâ€™s correlation coefficient more efficiently detects a monotonic correlation between a continuous with a continuous, and a continuous with a categorical variable. Pearson correlation coefficient more efficiently detects the linear correlation between continuous variables. MIC efficiently detects non-linear or non-monotonic relation between continuous variables. Chi-square test of independence efficiently detects relation between a continuous with a continuous, and categorical with categorical variables, but the non linear or non monotonic relation between a continuous with a categorical are not well detected. On the other hand, the result from lasso and stepwise methods reveals that, the relation between the predictor and response due to interaction effect not detected by correlation and association methods are detected by stepwise variable selection method, and the multicollinearity is detected and removed by lasso method. Regressing the response variable â€œnumber of employer in an enterpriseâ€ based on variables selected by lasso and stepwise method does bring greater model fitness (based on adjusted R-squared value) than variables selected by association and correlation methods. Similarly, regressing the response variable â€œdevelopment status of an enterpriseâ€ based on variables selected by association and correlation methods does bring 12 significant variables, where none of variables are significant from variables selected by lasso and stepwise methods. As a result, 51 predictors for number of employment in an enterprise, and 40 predictors for development status of an enterprise are detected as significantly related variables. And, lasso and stepwise methods are preferred to select predictors of a continuous response variable â€œnumber of employers in an enterpriseâ€, and association and correlation methods are preferred to select predictors of a categorical response variable â€œdevelopment status of an enterpriseâ€. Finally, the reduced regression models result reveals that, 20 predictors have causal relation with number of employment in an enterprise, and 12 predictors have causal relation with development status of an enterprise. On the other hand, based on model fitness, information lost, and number of significant factors, principal factor is preferred and applied in dimension reduction for a categorical response variable â€œdevelopment status of an enterpriseâ€, and factor score based regression is preferred and applied for a continuous response variable â€œnumber of employers in an enterpriseâ€. However, the comparison of the results in variable selection and dimension reduction indicates that, variable selection methods gave more gain in model fitness than dimension reduction methods. Hence, the suggested variable selection methods are more preferred than dimension reduction methods, and applied to find out predictors. In general, the suggested procedure for variable selection methods are recommended when small number of variables are studied, and the suggested dimension reduction methods are recommended for large number of variant variables (Big data case).",2018,Journal of Big Data
Tumor-infiltrating immune cells signature predicts recurrence free survival after complete resection of localized primary gastrointestinal stromal tumors,"Background: Growing evidence has proposed prognostic value of immune infiltration in gastrointestinal stromal tumors (GISTs). Therefore, we aimed to develop a novel immune-based prognostic classifier (IPC) to help better stratify and predict prognosis of GISTs. Methods: The gene expression profiles of 22 immune features of GISTs were detected from GEO dataset. The IPC was constructed using the LASSO Cox regression model and validated in a cohort including 54 patients with complete resection of localized primary GISTs via immunohistochemistry process. The performance assessment of the IPC was estimated, then compared with conventional risk prognostic criteria. Results: The IPC was established based on 4 features: CD8, CD8/CD3, CD68, CD163/CD68 and validated to be an independent predictor of RFS for GISTs (HR 5.2, 95%CI 1.99-13.65). Significant differences were found between low- and high-IPC group in 5-year RFS (92.6% vs 48.1%, p < 0.001). Using the IPC, the high-risk group of the Modified NIH classification was split into two groups in 5-year RFS (low-IPC vs high-IPC, 85.7% vs 30.0%, p < 0.001). The IPC showed a higher net benefit than both ""treat all"" or ""treat none"" methods for the threshold probability within a range of 0-0.62 and exhibited a performance (AUC 0.842) superior to modified NIH classification (AUC 0.763). Conclusion: The IPC was effective to predict RFS after complete resection of localized primary GISTs, adding prognostic value to the routine clinical prognostic criteria. Prospective studies are needed to further validate the analytical accuracy and practicability of the IPC in estimating prognosis of GISTs.",2020,medRxiv
Modified-INSAT Multi-Spectral Rainfall Algorithm (M-IMSRA) at climate region scale: Development and validation,"Abstract The present article reports an improvement in the INSAT Multispectral Rainfall Algorithm which is currently operational in the Indian Meteorological Department (IMD). The proposed Modified-IMSRA (M-IMSRA) algorithm deviates from original IMSRA in two ways: first is by improvement in rain/no-rain area detection scheme using a Multi-Index Rain Detection (MIRD) index; second is based on the climate region-wise correction through Least Absolute Shrinkage and Selection Operator (LASSO) models developed for each climate regions using rainfall (obtained based on first improvement) and static topographic variables extracted from Digital Elevation Model (DEM). The overall results indicate that the M-IMSRA is performing better than the IMSRA in all climatic regions when compared with the IMD gridded gauge data. However, the improvement is not uniform in all the regions. The inclusion of the MIRD index led to considerable improvement in M-IMSRA-based rainfall estimates mainly in the arid regions. Likewise, the results obtained after the LASSO regression corrections indicate that they are necessary only for the orographic regions where significant improvements are observed in the rainfall estimates. Finally, the inter-comparison of the simple hybrid M-IMSRA estimates with Tropical Rainfall Measuring Mission (TRMM) 3B42 V7 and TRMM 3B42-RT V7 illustrates that the M-IMSRA performs nearly as well as even better (except in terms of Correlation Coefficient) than the complex multi-satellite-based rainfall estimates in all the climate regions of India. Considering the above results, it can be said that the performance of simple hybrid algorithms such as IMSRA can be improved to match the quality or even outperform complex multi-satellite rainfall estimates by incorporating appropriate corrections.",2016,Remote Sensing of Environment
Inflation Forecasting Using Machine Learning Methods,"Inflation forecasting is an important practical problem. This paper proposes a solution to this problem for Russia using several basic machine learning methods: LASSO, Ridge, Elastic Net, Random Forest, and Boosting. Despite the fact that these methods already existed in the early 2000s, for a long time they remained almost unnoticed in the professional literature related to the forecasting of inflation in general, and Russian inflation in particular. This paper is one of the first attempts to apply machine learning methods to the forecasting of inflation in Russia. The present empirical study demostrates that the Random Forest model and the Boosting model are at least as good at inflation forecasting as more traditional models, such as Random Walk and autoregression. The main result of this paper is the confirmation of the possibility of more accurate forecasting of inflation in Russia using machine learning methods.",2018,
Sparse kernel learning with LASSO and Bayesian inference algorithm,"Kernelized LASSO (Least Absolute Selection and Shrinkage Operator) has been investigated in two separate recent papers [Gao, J., Antolovich, M., & Kwan, P. H. (2008). L1 LASSO and its Bayesian inference. In W. Wobcke, & M. Zhang (Eds.), Lecture notes in computer science: Vol. 5360 (pp. 318-324); Wang, G., Yeung, D. Y., & Lochovsky, F. (2007). The kernel path in kernelized LASSO. In International conference on artificial intelligence and statistics (pp. 580-587). San Juan, Puerto Rico: MIT Press]. This paper is concerned with learning kernels under the LASSO formulation via adopting a generative Bayesian learning and inference approach. A new robust learning algorithm is proposed which produces a sparse kernel model with the capability of learning regularized parameters and kernel hyperparameters. A comparison with state-of-the-art methods for constructing sparse regression models such as the relevance vector machine (RVM) and the local regularization assisted orthogonal least squares regression (LROLS) is given. The new algorithm is also demonstrated to possess considerable computational advantages.",2010,Neural networks : the official journal of the International Neural Network Society
Pattern-based local linear regression models for short-term load forecasting,"Abstract In this paper univariate models for short-term load forecasting based on linear regression and patterns of daily cycles of load time series are proposed. The patterns used as input and output variables simplify the forecasting problem by filtering out the trend and seasonal variations of periods longer than the daily one. The nonstationarity in mean and variance is also eliminated. The simplified relationship between variables (patterns) is modeled locally in the neighborhood of the current input using linear regression. The load forecast is constructed from the forecasted output pattern and the current values of variables describing the load time series. The proposed stepwise and lasso regressions reduce the number of predictors to a few. In the principal components regression and partial least-squares regression only one predictor is used. This allows us to visualize the data and regression function. The performances of the proposed methods were compared with that of other models based on ARIMA, exponential smoothing, neural networks and Nadarayaâ€“Watson estimator. Application examples confirm valuable properties of the proposed approaches and their high accuracy.",2016,Electric Power Systems Research
Sparsity by Worst-Case Quadratic Penalties,"This paper proposes a new robust regression interpretation of sparse penalties such as the elastic net and the group-lasso. Beyond providing a new viewpoint on these penalization schemes, our approach results in a unified optimization strategy. Our evaluation experiments demonstrate that this strategy, implemented on the elastic net, is computationally extremely efficient for small to medium size problems. Our accompanying software solves problems at machine precision in the time required to get a rough estimate with competing state-of-the-art algorithms.",2012,arXiv: Machine Learning
Reducing the number of reconstructions needed for estimating channelized observer performance,"A challenge for task-based optimization is the time required for each reconstructed image in applications where reconstructions are time consuming. Our goal is to reduce the number of reconstructions needed to estimate the area under the receiver operating characteristic curve (AUC) of the infinitely-trained optimal channelized linear observer. We explore the use of classifiers which either do not invert the channel covariance matrix or do feature selection. We also study the assumption that multiple low contrast signals in the same image of a non-linear reconstruction do not significantly change the estimate of the AUC. We compared the AUC of several classifiers (Hotelling, logistic regression, logistic regression using Firth bias reduction and the least absolute shrinkage and selection operator (LASSO)) with a small number of observations both for normal simulated data and images from a total variation reconstruction in magnetic resonance imaging (MRI). We used 10 Laguerre-Gauss channels and the Mann-Whitney estimator for AUC. For this data, our results show that at small sample sizes feature selection using the LASSO technique can decrease bias of the AUC estimation with increased variance and that for large sample sizes the difference between these classifiers is small. We also compared the use of multiple signals in a single reconstructed image to reduce the number of reconstructions in a total variation reconstruction for accelerated imaging in MRI. We found that AUC estimation using multiple low contrast signals in the same image resulted in similar AUC estimates as doing a single reconstruction per signal leading to a 13x reduction in the number of reconstructions needed.",2018,
