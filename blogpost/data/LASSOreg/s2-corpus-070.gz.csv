title,abstract,year,journal
Fast Convex Pruning of Deep Neural Networks,"We develop a fast, tractable technique called Net-Trim for simplifying a trained neural network. The method is a convex post-processing module, which prunes (sparsifies) a trained network layer by layer, while preserving the internal responses. We present a comprehensive analysis of Net-Trim from both the algorithmic and sample complexity standpoints, centered on a fast, scalable convex optimization program. Our analysis includes consistency results between the initial and retrained models before and after Net-Trim application and guarantees on the number of training samples needed to discover a network that can be expressed using a certain number of nonzero terms. Specifically, if there is a set of weights that uses at most $s$ terms that can re-create the layer outputs from the layer inputs, we can find these weights from $\mathcal{O}(s\log N/s)$ samples, where $N$ is the input size. These theoretical results are similar to those for sparse regression using the Lasso, and our analysis uses some of the same recently-developed tools (namely recent results on the concentration of measure and convex analysis). Finally, we propose an algorithmic framework based on the alternating direction method of multipliers (ADMM), which allows a fast and simple implementation of Net-Trim for network pruning and compression.",2020,ArXiv
Simultaneous nonparametric regression in RADWT dictionaries,"Abstract A new technique for nonparametric regression of multichannel signals is presented. The technique is based on the use of the Rational-Dilation Wavelet Transform (RADWT), equipped with a tunable Q-factor able to provide sparse representations of functions with different oscillations persistence. In particular, two different frames are obtained by two RADWT with different Q-factors that give sparse representations of functions with low and high resonance. It is assumed that the signals are measured simultaneously on several independent channels and that they share the low resonance component and the spectral characteristics of the high resonance component. Then, a regression analysis is performed by means of the grouped lasso penalty. Furthermore, a result of asymptotic optimality of the estimator is presented using reasonable assumptions and exploiting recent results on group-lasso like procedures. Numerical experiments show the performance of the proposed method in different synthetic scenarios as well as in a real case example for the analysis and joint detection of sleep spindles and K-complex events for multiple electroencephalogram (EEG) signals.",2019,Comput. Stat. Data Anal.
Activity-Aware Wearable System for Power-Efficient Prediction of Physiological Responses,"Wearable health monitoring has emerged as a promising solution to the growing need for remote health assessment and growing demand for personalized preventative care and wellness management. Vital signs can be monitored and alerts can be made when anomalies are detected, potentially improving patient outcomes. One major challenge for the use of wearable health devices is their energy efficiency and battery-lifetime, which motivates the recent efforts towards the development of self-powered wearable devices. This article proposes a method for context aware dynamic sensor selection for power optimized physiological prediction using multi-modal wearable data streams. We first cluster the data by physical activity using the accelerometer data, and then fit a group lasso model to each activity cluster. We find the optimal reduced set of groups of sensor features, in turn reducing power usage by duty cycling these and optimizing prediction accuracy. We show that using activity state-based contextual information increases accuracy while decreasing power usage. We also show that the reduced feature set can be used in other regression models increasing accuracy and decreasing energy burden. We demonstrate the potential reduction in power usage using a custom-designed multi-modal wearable system prototype.",2019,"Sensors (Basel, Switzerland)"
The efficiency of modified jackknife and ridge type regression estimators: a comparison.,"A common problem in multiple regression models is multicollinearity, which pro- duces undesirable eects on the least squares estimator. To circumvent this problem, two well known estimation procedures are often suggested in the literature. They are Generalized Ridge Regression (GRR) estimation suggested by Hoerl and Kennard (8) and the Jackknifed Ridge Regression (JRR) estimation suggested by Singh et al. (13). The GRR estimation leads to a reduction in the sampling variance, whereas, JRR leads to a reduction in the bias. In this paper, we propose a new estimator namely, Modied Jackknife Ridge Regression Estimator (MJR). It is based on the criterion that combines the ideas underlying both the GRR and JRR estimators. We have investigated standard properties of this new estimator. From a simulation study, we nd that the new estimator often outperforms the LASSO, and it is superior to both GRR and JRR estimators, using the mean squared error criterion. The conditions under which the MJR estimator is better than the other two competing estimators have been investigated. Full text",2008,
Fast Bayesian model assessment for nonparametric additive regression,"Variable selection techniques for the classical linear regression model have been widely investigated. Variable selection in fully nonparametric and additive regression models has been studied more recently. A Bayesian approach for nonparametric additive regression models is considered, where the functions in the additive model are expanded in a B -spline basis and a multivariate Laplace prior is put on the coefficients. Posterior probabilities of models defined by selection of predictors in the working model are computed, using a Laplace approximation method. The prior times the likelihood is expanded around the posterior mode, which can be identified with the group LASSO, for which a fast computing algorithm exists. Thus Markov chain Monte-Carlo or any other time consuming sampling based methods are completely avoided, leading to quick assessment of various posterior model probabilities. This technique is applied to the high-dimensional situation where the number of parameters exceeds the number of observations.",2014,Comput. Stat. Data Anal.
Psychological Distress is increasing among customer-facing retail employees: Evidence from 1997 to 2015,"Do customer-facing retail employees in the US have a higher prevalence of psychological distress? We examine psychological distress in a sample that includes 19,832 customer-facing retail employees from a sample of 1,115,280 employees of a cross-sectional National Health Interview Survey (NHIS) from 1997 through 2015. Our results show that customer-facing retail employees report significantly higher psychological distress than do employees in other industries and that its prevalence is increasing. These findings are consistent with mild and high levels of psychological distress. LASSO regression shows that, after self-reported health and poverty level, being a customer-facing retail employee is the third most important predictor of psychological distress.",2018,Journal of Business Research
Assessing Robustness of Regularized Regression Models with Applications,"In this Big-data and computational innovation era, advanced level analysis and modelling strategies are essential in data science to understanding the individual activities which occur within very complex behavioral, socio-economic and ecological systems. However, the scales at which models can be developed, and the subsequent problems they can inform, are often limited by our inability or challenges to effectively understand data that mimic interactions at the finest spatial, temporal, or organizational resolutions. Linear regression analysis is the one of the widely used methods for investigating such relationship between variables. Multicollinearity is one of the major problem in regression analysis. Multicollinearity can be reduced by using the appropriate regularized regression methods. This study aims to measure the robustness of regularized regression models such as ridge and Lasso type models designed for the high dimensional data having the multicollinearity problems. Empirical results show that Lasso and Ridge models have less residual sum of squares values. Findings also demonstrate an improved accuracy of estimated parameters on the best model.",2019,
Development and temporal validation of a prognostic model for 1-year clinical outcome after decompression surgery for lumbar disc herniation,"Surgeons need tools to provide individualised estimates of surgical outcomes and the uncertainty surrounding these, to convey realistic expectations to the patient. This study developed and validated prognostic models for patients undergoing surgical treatment of lumbar disc herniation, to predict outcomes 1 year after surgery, and implemented these models in an online prediction tool. Using the data of 1244 patients from a large spine unit, LASSO and linear regression models were fitted with 90% upper prediction limits, to predict scores on the Core Outcome Measures Index, and back and leg pain. Candidate predictors included sociodemographic factors, baseline symptoms, medical history, and surgeon characteristics. Temporal validation was conducted on 364 more recent patients at the same unit, by examining the proportion of observed outcomes exceeding the threshold of the 90% upper prediction limit (UPL), and by calculating mean bias and other calibration measures. Poorer outcome was predicted by obesity, previous spine surgery, and having basic obligatory (rather than private) insurance. In the validation data, fewer than 12% of outcomes were above the 90% UPL. Calibration plots for the model validation showed values for mean biasâ€‰<â€‰0.5 score points and regression slopes close to 1. While the model accuracy was good overall, the prediction intervals indicated considerable predictive uncertainty on the individual level. Implementation studies will assess the clinical usefulness of the online tool. Updating the models with additional predictors may improve the accuracy and precision of outcome predictions. These slides can be retrieved under Electronic Supplementary Material.",2020,European Spine Journal
Predicting clinical variables from neuroimages using fused sparse group lasso,"Predictive models in which neuroimage features serve as predictors and a clinical variable is modeled as the outcome are good candidates for clinical application because (1) they can exploit dependencies between predictor variables and thus potentially explain more variability in the outcome than a mass univariate approach, and (2) they allow inference at the individual level, such that a prediction can be obtained for a new individual whose data was not used to train the model. This dissertation proposes methods for neuroimaging prediction models that not only aim for predictive accuracy, but also seek interpretability and potential insight into the underlying pathophysiology of neuropsychiatric disorders. 
 
In the first part of this dissertation we propose the fused sparse group lasso penalty, which encourages structured, sparse, interpretable solutions by incorporating prior information about spatial and group structure among voxels. We derive optimization steps for fused sparse group lasso penalized regression using the alternating direction method of multipliers algorithm. With simulation studies, we demonstrate conditions under which fusion and group penalties together outperform either of them alone. We then use fused sparse group lasso to predict continuous measures from resting state magnetic resonance imaging data using the Autism Brain Imaging Data Exchange dataset. In the second part of this dissertation we use fused sparse group lasso to predict age from multimodal neuroimaging data in a sample of cognitively normal adults aged 65 and older. In general, we show how the incorporation of prior information via the fused sparse group lasso penalty can enhance the interpretability of neuroimaging predictive models while also yielding good predictive performance. 
 
Public health significance: Psychiatric disorders and neurological diseases such as Alzheimer's present a large public health burden. As of yet, there have been relatively few translations of basic neuroscience findings to clinical applications in psychiatry. Prediction models using neuroimaging data can potentially help clinicians with diagnosis and prediction of prognosis and treatment response. Establishing interpretable neuroimaging-based biomarkers can improve our understanding of the neurobiological mechanisms underlying neuropsychiatric disorders and suggest approaches for prevention and treatment.",2018,
Malnutrition in HIV-Infected Children Is an Indicator of Severe Disease with an Impaired Response to Antiretroviral Therapy,"This observational study aimed to describe immunopathogenesis and treatment outcomes in children with and without severe acute malnutrition (SAM) and HIV-infection. We studied markers of microbial translocation (16sDNA), intestinal damage (iFABP), monocyte activation (sCD14), T-cell activation (CD38, HLA-DR) and immune exhaustion (PD1) in 32 HIV-infected children with and 41 HIV-infected children without SAM prior to initiation of antiretroviral therapy (ART) and cross-sectionally compared these children to 15 HIV-uninfected children with and 19 HIV-uninfected children without SAM. We then prospectively measured these markers and correlated them to treatment outcomes in the HIV-infected children at 48 weeks following initiation of ART. Plasma levels of 16sDNA, iFABP and sCD14 were measured by quantitative real time PCR, ELISA and Luminex, respectively. T cell phenotype markers were measured by flow cytometry. Multiple regression analysis was performed using generalized linear models (GLMs) and the least absolute shrinkage and selection operator (LASSO) approach for variable selection. Microbial translocation, T cell activation and exhaustion were increased in HIV-uninfected children with SAM compared to HIV-uninfected children without SAM. In HIV-infected children microbial translocation, immune activation, and exhaustion was strongly increased but did not differ by SAM-status. SAM was associated with increased mortality rates early after ART initiation. Malnutrition, age, microbial translocation, monocyte, and CD8 T cell activation were independently associated with decreased rates of CD4% immune recovery after 48 weeks of ART. SAM is associated with increased microbial translocation, immune activation, and immune exhaustion in HIV-uninfected children and with worse prognosis and impaired immune recovery in HIV-infected children on ART.",2018,AIDS Research and Human Retroviruses
Comment on article by Polson and Scott,"Polson and Scottâ€™s paper presents the enlightening observation that the standard SVM can be embedded into a statistical latent variable model. This is aligned with other recent work, in which the penalty term in the convex optimization for several popular non-Bayesian models has been replaced by a prior distribution in order to develop an alternative Bayesian approach. See, for example, the Bayesian lasso model by Park and Casella (2008) and Hans (2009), and the Bayesian bridge regression model by Armagan (2009). Following the work of Andrews and Mallows (1974) and West (1987), the prior distributions used in these methods are expressed as scale mixtures of normal distributions. For example, in bridge regression (Frank and Friedman 1993), which includes both ridge regression (Hoerl and Kennard 1970) and lasso (Tibshirani 1996) as special cases, the regression parameters are estimated by minimizing the penalized residual sum of squares (using centered data),",2011,Bayesian Analysis
Estimating TTC for wind farm integrated power systems based on nonparametric regression analytics,"Assessing security margin of operation is vital in situation awareness for power systems with centralized wind farm integration. Total transfer capability (TTC) can be used as an indicator referring to the maximal loadability of transmission corridors. However, the calculation of TTC considering wind generation is a computation-intensive procedure. In order to assess TTC, an estimation approach based on nonparametric regression analytics is presented which takes into account clustering, feature confirmation, samples generation and group Lasso regression modeling. The estimated result is comparable to the performance of conventional techniques such as artificial neural network (ANN). However, the novelty of this approach lies in that it provides explicit spline functions showing the correlation between the selected features and the TTC value. In addition, the spline expression for every single feature against TTC is obtained, revealing highly nonlinear sensitivity of the related parameters. A numerical example is presented using the modified New England 39-bus test system.",2016,2016 IEEE Power and Energy Society General Meeting (PESGM)
Composite quantile regression and variable selection of the partial linear single-index models,"In this paper, we propose a composite minimizing average check loss estimation(CMACLE)method for the composite quantile regression(CQR)of the partial linear single-index model(PLSIM)by local linear method. Based on constructive approach, the estimators by CMACLE are able to achieve the best convergence rate. The asymptotical normalities of the estimators are also derived. Meanwhile, the asymptotic efficiency of the CQR estimation relative to the mean regression are investigated. Further more, we propose a variable selection method for the CQR of PLSIM by combining the CMACLE procedure with the adaptive LASSO penalized method. The oracle properties of the proposed variable selection method are also established. Simulations with various non-normal errors and a real data analysis are conducted to assess the finite sample property of the proposed estimation and variable selection methods.",2014,
"One-carbon metabolism, cognitive impairment and CSF measures of Alzheimer pathology: homocysteine and beyond","BackgroundHyperhomocysteinemia is a risk factor for cognitive decline and dementia, including Alzheimer disease (AD). Homocysteine (Hcy) is a sulfur-containing amino acid and metabolite of the methionine pathway. The interrelated methionine, purine, and thymidylate cycles constitute the one-carbon metabolism that plays a critical role in the synthesis of DNA, neurotransmitters, phospholipids, and myelin. In this study, we tested the hypothesis that one-carbon metabolites beyond Hcy are relevant to cognitive function and cerebrospinal fluid (CSF) measures of AD pathology in older adults.MethodsCross-sectional analysis was performed on matched CSF and plasma collected from 120 older community-dwelling adults with (nâ€‰=â€‰72) or without (nâ€‰=â€‰48) cognitive impairment. Liquid chromatography-mass spectrometry was performed to quantify one-carbon metabolites and their cofactors. Least absolute shrinkage and selection operator (LASSO) regression was initially applied to clinical and biomarker measures that generate the highest diagnostic accuracy of a priori-defined cognitive impairment (Clinical Dementia Rating-based) and AD pathology (i.e., CSF tau phosphorylated at threonine 181 [p-tau181]/Î²-Amyloid 1â€“42 peptide chain [AÎ²1â€“42] >0.0779) to establish a reference benchmark. Two other LASSO-determined models were generated that included the one-carbon metabolites in CSF and then plasma. Correlations of CSF and plasma one-carbon metabolites with CSF amyloid and tau were explored. LASSO-determined models were stratified by apolipoprotein E (APOE) Îµ4 carrier status.ResultsThe diagnostic accuracy of cognitive impairment for the reference model was 80.8% and included age, years of education, AÎ²1â€“42, tau, and p-tau181. A model including CSF cystathionine, methionine, S-adenosyl-L-homocysteine (SAH), S-adenosylmethionine (SAM), serine, cysteine, and 5-methyltetrahydrofolate (5-MTHF) improved the diagnostic accuracy to 87.4%. A second model derived from plasma included cystathionine, glycine, methionine, SAH, SAM, serine, cysteine, and Hcy and reached a diagnostic accuracy of 87.5%. CSF SAH and 5-MTHF were associated with CSF tau and p-tau181. Plasma one-carbon metabolites were able to diagnose subjects with a positive CSF profile of AD pathology in APOE Îµ4 carriers.ConclusionsWe observed significant improvements in the prediction of cognitive impairment by adding one-carbon metabolites. This is partially explained by associations with CSF tau and p-tau181, suggesting a role for one-carbon metabolism in the aggregation of tau and neuronal injury. These metabolites may be particularly critical in APOE Îµ4 carriers.",2017,Alzheimer's Research & Therapy
Variable selection for high dimensional transformation model,"Transformation Regression Model is an important semiparametric regression model. At the initial stage of the regression model building, a lot of variables are available which may result in a very large model, or make model misspecification. Hence Variable selection is a necessary process in practice. However most traditional variable selection methods are not available for the transformation model because of the unknown transformation function and some constraint identified conditions of the model. On the other hand, when the number of variables in the model is larger than the sample size, such as LASSO, SCAD, those penalized methods developed in recently are still suffered in computational burden, and difficult to be applied for the transformation model directly. This research aims to employ the general idea of SIS proposed by Fan and Lv (2008) and rank correlation to propose a new screening method for the ultrahigh dimensional transformation model. By such screening method, the dimension of the model can be reduced, then those penalized methods can be applied to select variables for the transformation model. Hence the two step variable selection procedure for the ultra-high dimension transformation model is proposed, that is applying a screener at first and followed by a non-parametric penalized estimation. Basic screening properties of the proposed method has been investigated and supported by the numerical study.",2010,
Investigating gene expression array with outliers and missing data in bladder cancer,"In this article, we present a methodology to perform selection among genes based on their expression in various groups of patients, in order to find new genetic markers for specific pathologies. Our approach is based on clustering the denoised data and computing a LASSO (Least Absolute Shrinkage and Selection Operator) estimator, in order to select the relevant genes. This latter belongs to the class of penalized regression estimators where the penalty is a multiple of the â„“1-norm of the regression vector. Gene markers of the most severe tumor state are finally provided using the proposed approach.",2015,2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)
LASSO as a tool for downscaling summer rainfall over the Yangtze River Valley,"ABSTRACT Building statistical downscaling models often faces a large number of potential predictors from atmospheric circulation fields. The least absolute shrinkage and selection operator (LASSO) has been used to downscale monthly rainfall in summer over the Yangtze River Valley. Based on the shrinkage of coefficients of the model, LASSO can provide sparse models with many coefficients being zero. Geopotential height at 500-hPa was used as the predictor set. The results show that LASSO can reproduce the spatial pattern of anomalies of rainfall in most years. Furthermore, LASSO can reproduce the shift of the rainfall over the Yangtze River Valley in the late 1970s. The performance of the elastic net was also tested, and its grouping effect should be noted. It was also found that LASSO performs better than principal component regression.",2019,Hydrological Sciences Journal
Optimal Regression Method for Near-Infrared Spectroscopic Evaluation of Articular Cartilage,"Near-infrared (NIR) spectroscopy has been successful in nondestructive assessment of biological tissue properties, such as stiffness of articular cartilage, and is proposed to be used in clinical arthroscopies. Near-infrared spectroscopic data include absorbance values from a broad wavelength region resulting in a large number of contributing factors. This broad spectrum includes information from potentially noisy variables, which may contribute to errors during regression analysis. We hypothesized that partial least squares regression (PLSR) is an optimal multivariate regression technique and requires application of variable selection methods to further improve the performance of NIR spectroscopy-based prediction of cartilage tissue properties, including instantaneous, equilibrium, and dynamic moduli and cartilage thickness. To test this hypothesis, we conducted for the first time a comparative analysis of multivariate regression techniques, which included principal component regression (PCR), PLSR, ridge regression, least absolute shrinkage and selection operator (Lasso), and least squares version of support vector machines (LS-SVM) on NIR spectral data of equine articular cartilage. Additionally, we evaluated the effect of variable selection methods, including Monte Carlo uninformative variable elimination (MC-UVE), competitive adaptive reweighted sampling (CARS), variable combination population analysis (VCPA), backward interval PLS (BiPLS), genetic algorithm (GA), and jackknife, on the performance of the optimal regression technique. The PLSR technique was found as an optimal regression tool (R2Tissue thicknessâ€‰=â€‰75.6%, R2Dynamic modulusâ€‰=â€‰64.9%) for cartilage NIR data; variable selection methods simplified the prediction models enabling the use of lesser number of regression components. However, the improvements in model performance with variable selection methods were found to be statistically insignificant. Thus, the PLSR technique is recommended as the regression tool for multivariate analysis for prediction of articular cartilage properties from its NIR spectra.",2017,Applied Spectroscopy
De-biasing the Lasso: Optimal Sample Size for Gaussian Designs,"Performing statistical inference in high-dimension is an outstanding challenge. A major source of difficulty is the absence of precise information on the distribution of high-dimensional estimators. Here, we consider linear regression in the high-dimensional regime $p\gg n$. In this context, we would like to perform inference on a high-dimensional parameters vector $\theta^*\in{\mathbb R}^p$. Important progress has been achieved in computing confidence intervals for single coordinates $\theta^*_i$. A key role in these new methods is played by a certain debiased estimator $\hat{\theta}^{\rm d}$ that is constructed from the Lasso. Earlier work establishes that, under suitable assumptions on the design matrix, the coordinates of $\hat{\theta}^{\rm d}$ are asymptotically Gaussian provided $\theta^*$ is $s_0$-sparse with $s_0 = o(\sqrt{n}/\log p )$. The condition $s_0 = o(\sqrt{n}/ \log p )$ is stronger than the one for consistent estimation, namely $s_0 = o(n/ \log p)$. We study Gaussian designs with known or unknown population covariance. When the covariance is known, we prove that the debiased estimator is asymptotically Gaussian under the nearly optimal condition $s_0 = o(n/ (\log p)^2)$. Note that earlier work was limited to $s_0 = o(\sqrt{n}/\log p)$ even for perfectly known covariance. The same conclusion holds if the population covariance is unknown but can be estimated sufficiently well, e.g. under the same sparsity conditions on the inverse covariance as assumed by earlier work. For intermediate regimes, we describe the trade-off between sparsity in the coefficients and in the inverse covariance of the design. We further discuss several applications of our results to high-dimensional inference. In particular, we propose a new estimator that is minimax optimal up to a factor $1+o_n(1)$ for i.i.d. Gaussian designs.",2015,arXiv: Statistics Theory
Evaluation of statistical models for predicting Escherichia coli particle attachment in fluvial systems.,"Modeling surface water Escherichia coli fate and transport requires partitioning E. coli into particle-attached and unattached fractions. Attachment is often assumed to be a constant fraction or is estimated using simple linear models. The objectives of this study were to: (i) develop statistical models for predicting E. coli attachment and virulence marker presence in fluvial systems, and (ii) relate E. coli attachment to a variety of environmental parameters. Stream water samples (n = 60) were collected at four locations in a rural, mixed-use watershed between June and October 2012, with four storm events (>20 mm rainfall) being captured. The percentage of E. coli attached to particles (>5 Î¼m) and the occurrences of virulence markers were modeled using water quality, particle concentration, particle size distribution, hydrology and land use factors as explanatory variables. Three types of statistical models appropriate for highly collinear, multidimensional data were compared: least angle shrinkage and selection operator (LASSO), classification and regression trees using the general, unbiased, interaction detection and estimation (GUIDE) algorithm, and multivariate adaptive regression splines (MARS). All models showed that E. coli particle attachment and the presence of E. coli virulence markers in the attached and unattached states were influenced by a combination of water quality, hydrology, land-use and particle properties. Model performance statistics indicate that MARS models outperform LASSO and GUIDE models for predicting E. coli particle attachment and virulence marker occurrence. Validating the MARS modeling approach in multiple watersheds may allow for the development of a parameterizing model to be included in watershed simulation models.",2013,Water research
The Broken Adaptive Ridge Procedure and Its Applications,"In this study, we employ the broken adaptive ridge method to estimate the lower-dimensional patterns of the coefficients in regression models. Based on a reweighted `2-penalization, the new method simultaneously recovers the true sparsity and the inherent structures of the features, making it theoretically and practically appealing. The resulting estimate is shown to enjoy the oracle property. The proposed method also contains a set of variable selection or pattern estimation methods. As a special case, the fused broken adaptive ridge, which penalizes the differences between adjacent coefficients, is thoroughly discussed, with applications to signal approximation and image processing. The associated algorithms are numerically easy to implement. Simulation studies and real-data analyses illustrate the advantages of the proposed method over the fused lasso method.",2020,Statistica Sinica
Variable selection in Cox regression models with varying coefficients,"We deal with two kinds of Cox regression models with varying coefficients. The coefficients vary with time in one model. In the other model, there is an important random variable called an index variable and the coefficients vary with the variable. In both models, we have p-dimensional covariates and p increases moderately. However, it is the case that only a small part of the covariates are relevant in these situations. We carry out variable selection and estimation of the coefficient functions by using the group SCAD-type estimator and the adaptive group Lasso estimator. We examine the theoretical properties of the estimators, especially the L2 convergence rate, the sparsity, and the oracle property. Simulation studies and a real data analysis show the performance of these new techniques.",2014,Journal of Statistical Planning and Inference
Model selection: a decision-theoretic approach,"This manuscript addresses the problem of model selection, studied in the linear regression framework. The objective is to determine the best predictive model based on observed data, that is, the model realizing the best tradeoff between goodness of fit and complexity. Our main contribution consists in deriving model evaluation criteria based on tools from Decision Theory, in particular loss estimation. Such criteria rely on a distributional assumption larger than the classical Gaussian hypothesis with independent observations: the family of spherically symmetric distributions. This family of laws allows us to relax the independence assumption and thus brings robustness, since our criteria do not depend on the specific form of the distribution. We also propose a method for comparing model evaluation criteria through a Mean-Squared Error type measure. Our second contribution tackles the problem of constructing the models we compare. The conditions of models considered are obtained from sparse regularization methods, namely the Lasso and related methods. In particular, we studied the Minimax Concave Penalty (MCP), which keeps Lasso's selection while correcting its estimation bias. However, this penalty corresponds to a non differentiable and non- convex optimization problem. The generalization of subdifferentials with Clarke differentials allowed us to derive the optimality conditions d'optimalite and to propose a regularization path algorithm for MCP. Finally, we compare our propositions to the literature through a numerical study, in which we verify the quality of the selection. The results especially show that our criteria yield performances similar to the literature, and that frequently used criteria such as Cross Validation do not always result in good performances.",2013,
Serum metabolites predict response to angiotensin II receptor blockers in patients with diabetes mellitus,"BackgroundIndividual patients show a large variability in albuminuria response to angiotensin receptor blockers (ARB). Identifying novel biomarkers that predict ARB response may help tailor therapy. We aimed to discover and validate a serum metabolite classifier that predicts albuminuria response to ARBs in patients with diabetes mellitus and micro- or macroalbuminuria.MethodsLiquid chromatography-tandem mass spectrometry metabolomics was performed on serum samples. Data from patients with type 2 diabetes and microalbuminuria (nÂ =Â 49) treated with irbesartan 300Â mg/day were used for discovery. LASSO and ridge regression were performed to develop the classifier. Improvement in albuminuria response prediction was assessed by calculating differences in R2 between a reference model of clinical parameters and a model with clinical parameters and the classifier. The classifier was externally validated in patients with type 1 diabetes and macroalbuminuria (nÂ =Â 50) treated with losartan 100Â mg/day. Molecular process analysis was performed to link metabolites to molecular mechanisms contributing to ARB response.ResultsIn discovery, median change in urinary albumin excretion (UAE) was âˆ’42Â % [Q1â€“Q3: âˆ’69 to âˆ’8]. The classifier, consisting of 21 metabolites, was significantly associated with UAE response to irbesartan (pÂ <Â 0.001) and improved prediction of UAE response on top of the clinical reference model (R2 increase from 0.10 to 0.70; pÂ <Â 0.001). In external validation, median change in UAE was âˆ’43Â % [Q1â€“Q35: âˆ’63 to âˆ’23]. The classifier improved prediction of UAE response to losartan (R2 increase from 0.20 to 0.59; pÂ <Â 0.001). Specifically ADMA impacting eNOS activity appears to be a relevant factor in ARB response.ConclusionsA serum metabolite classifier was discovered and externally validated to significantly improve prediction of albuminuria response to ARBs in diabetes mellitus.",2016,Journal of Translational Medicine
"Somatic Mutations of ASXL1, RUNX1 and SETBP1 Improve Prognostic Stratification of Patients with Chronic Myelomonocytic Leukemia","Chronic myelomonocytic leukemia (CMML) is a myelodysplastic/myeloproliferative neoplasm characterized by a highly variable clinical course. Based on clinical, hematologic and cytogenetic parameters, we previously developed a CMML-specific Prognostic Scoring System (CPSS) that stratifies patients into 4 different risk groups [ Blood 2013;121:3005-15 ]. Recently, recurrent somatic mutations have been identified in CMML, and preliminary evidence suggests that selected mutated genes may provide useful prognostic information.

In this study, we performed a comprehensive mutation analysis of genes implicated in myeloid malignancies in a large and well characterized cohort of CMML patients with the aim to dissect relationships between genotype and disease phenotype and to integrate somatic mutations into a clinical/molecular prognostic model.

Thirty-eight genes were analyzed by high throughput sequencing (Illumina MiSeq, San Diego, CA) in a cohort of 199 CMML patients (pts) diagnosed according to WHO classification, and in 12 pts with monocytosis not fulfilling WHO diagnostic criteria. Myelodysplastic and myeloproliferative subtypes (CMML-MD and CMML-MP, respectively) were defined according to FAB criteria. Least absolute shrinkage and selection operator (Lasso) and Cox proportional hazards methods were adopted to select and weight variables for prognostic scoring.

Ninety-three percent of pts showed at least one somatic mutation (median number per patient: 2, range 0-6). The most frequently mutated genes were TET2 (44%), SRSF2 (43%), ASXL1 (34%), KRAS (11%), NRAS (10%), CUX1 (10%) , CBL (9%), RUNX1 (7%), SETBP1 (7%), JAK2 (6%), SF3B1 (6%), and U2AF1 (5%). A significant association was found between mutations in TET2 and RNA splicing factors (P=.037), 42 of 199 CMML pts (21%) showing co-occurrence of TET2 and SRSF2 mutations. Mutations in genes involved in signaling were significantly associated with CMML-MP (P=.002), whereas SF3B1 mutations were associated with CMML-MD (P=.024).

The number of mutations per patient inversely correlated with overall survival (OS) (HR=1.32, P=.021). In univariate analysis, mutations in ASXL1 (HR=2.31, P=.026) , RUNX1 (HR=3.53, P=.02) and SETBP1 (HR=3.85, P=.005) significantly affected OS. Focusing the analysis on disease subtype, ASXL1 mutations significantly affected survival in CMML-MD (HR=3.45, P=.025), whereas CUX1 and SETBP1 had a significant prognostic value in CMML-MP (HR=4.33, P=.013 and HR=4.4, P=.025, respectively).

In order to investigate the additive value of somatic mutations to current prognostic assessment, we first fitted a Lasso Cox regression model for genetic variable selection. The selected variables were then included in an unpenalized Cox regression in order to obtain unbiased coefficients. The statistically significant variables were CPSS-specific cytogenetic risk groups (HR=2.49, P=.001), mutations in ASXL1 (HR=2.77, P=.018), RUNX1 (HR=5.39, P=.009) and SETBP1 (HR=3.96, P=.013). Based on regression coefficients, we defined a CMML-specific genetic risk score that was able to identify three different groups (Low risk: normal karyotype and â€“Y; Intermediate: other abnormalities, mutations in ASXL1 ; High: trisomy 8, complex karyotype, mutations in RUNX1 or SETBP1 ), with significantly different OS (HR=2.24, P<.001). The Akaike information criterion showed that this genetic risk score performed better than the original CPSS cytogenetic risk classification (AIC 274 vs. 282, respectively). According to the CMML-specific genetic risk score, 36% of patients had a shift toward a higher risk category compared with cytogenetic risk classification. Then, the new genetic risk categories were integrated in the CPSS (CPSS-Mol), which was able to identify 4 risk groups with different OS (HR=2.29, P<.001) and risk of disease progression (HR=2.62, P<.001). As a robustness analysis, we also fitted a Lasso Cox regression model including clinical and genetic variables, and all variables included in the clinical/molecular score were confirmed. The Akaike information criterion showed that the CPSS-Mol performed better than the original CPSS (AIC 251 vs. 253, respectively).

In conclusion, this study showed that mutation pattern in CMML significantly correlates with disease phenotype. The integration of somatic mutations in current scoring systems significantly improves prognostic stratification of patients.

Disclosures No relevant conflicts of interest to declare.",2014,Blood
Non-asymptotic Confidence Regions for Regularized Linear Regression Estimates,"Building confidence regions for regression models is of high importance, for example, they can be used for uncertainty quantification and are also fundamental for robust optimization. In practice, these regions are often computed from the asymptotic distributions, which however only lead to heuristic confidence sets. Sign-Perturbed Sums (SPS) is a resampling method which can construct exact, non-asymptotic, distribution-free confidence regions under very mild statistical assumptions. In its standard form, the SPS regions are built around the least-squares estimate of linear regression problems, and have favorable properties, such as they are star convex, strongly consistent, and have efficient ellipsoidal outer-approximations. In this paper, we extend the SPS method to regularized estimates, particularly, we present variants of SPS for ridge regression, LASSO and elastic net regularization.",2019,
"The Theory Behind Overfitting, Cross Validation, Regularization, Bagging, and Boosting: Tutorial","In this tutorial paper, we first define mean squared error, variance, covariance, and bias of both random variables and classification/predictor models. Then, we formulate the true and generalization errors of the model for both training and validation/test instances where we make use of the Stein's Unbiased Risk Estimator (SURE). We define overfitting, underfitting, and generalization using the obtained true and generalization errors. We introduce cross validation and two well-known examples which are $K$-fold and leave-one-out cross validations. We briefly introduce generalized cross validation and then move on to regularization where we use the SURE again. We work on both $\ell_2$ and $\ell_1$ norm regularizations. Then, we show that bootstrap aggregating (bagging) reduces the variance of estimation. Boosting, specifically AdaBoost, is introduced and it is explained as both an additive model and a maximum margin model, i.e., Support Vector Machine (SVM). The upper bound on the generalization error of boosting is also provided to show why boosting prevents from overfitting. As examples of regularization, the theory of ridge and lasso regressions, weight decay, noise injection to input/weights, and early stopping are explained. Random forest, dropout, histogram of oriented gradients, and single shot multi-box detector are explained as examples of bagging in machine learning and computer vision. Finally, boosting tree and SVM models are mentioned as examples of boosting.",2019,ArXiv
