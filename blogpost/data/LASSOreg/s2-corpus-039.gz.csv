title,abstract,year,journal
Robust variable selection based on the random quantile LASSO,"AbstractIn this paper, we study robust variable selection problem by combining the idea of quantile regression and random LASSO. A two-step algorithm is proposed to solve the proposed optimization ...",2019,Communications in Statistics - Simulation and Computation
Editorial,"Over the last three decades, there has been increasing interest in exploiting sparseness constraints in signal processing, that is, searching for target signals with as few non-zero entries as possible. This approach was, perhaps, first exploited in the modelling of excitation signals in speech processing or reflectivity sequences in seismic deconvolution with only a small number of non-zero values. Some 30 years later, the associated mathematical methods and application domains, both for singleand multiple-dimensional signals, have evolved to a point where sparse signal processing has become an area of study in its own right. This special issue on sparse signal processing, therefore, begins with a review article by Marvasti et al. [1], entitled A unified approach to sparse signal processing which provides a tutorial review of sparse signal recovery using various techniques with minimal sampling measurements, in effect, compressed sampling, and also describes applications of sparsity in a number of other challenging domains. Many of the articles in this special issue are related to applications of sparse signal processing. The next set of articles provides examples of where sparsity can be exploited in parameter estimation problems. The article by Djafari [2] uses a Bayesian inference approach to address both signal and image inversion problems wherein sparsity is considered either in the original or transformed signal space. Taxonomy of prior models is provided for the related probabilistic frameworks, and associated estimation algorithms are developed. Angelosante and Giannakis [3], in an invited article, consider the problem of estimating the parameters of timevarying autoregressive models. They overcome the lack of continuity and high computational complexity in working with high-dimensional datasets by casting their problem as a sparse regression with grouped variables. This is then solved with a group least-absolute shrinkage and selection operator, denoted Lasso. Numerical evaluations are employed to demonstrate the merits of the approach. Zhu et al [4]. also examine a parameter estimation problem in the context of Synthetic Aperture Radar (SAR). They address a difficult nonlinear problem by employing linearization and an over-complete dictionary. This is motivated by the sparse distribution in the observation space of SAR micromotion targets. A variational approximation framework is also exploited for Bayesian computation, and numerical simulations confirm the higher resolution achievable by the proposed approach over conventional methods. Xie et al. [5] provide a hybrid approach for 2D directionof-arrival estimation in the presence of mutual coupling across the array. They employ a manifold decomposition approach for the case when the number of sensors is sparse, smaller than required in traditional beamspacebased algorithms. In particular, an algorithm to estimate azimuth angle without exact knowledge of the mutual coupling is provided. Blanco and NÃ¡jar [6] propose an algorithm for estimating the angles of arrival of multiple uncorrelated sources impinging upon a uniform linear array. They use an overcomplete dictionary representation of the spatial covariance matrix model. A sparsity penalty is applied and a least angle regression/homotopic approach is used to solve the resulting objective function. Their approach is shown to achieve high resolution with the advantage of low computational cost. Li et al. [7] focus upon source localization with a single snapshot and improve the efficiency of an iterative adaptive approach by utilizing the optimal filter only on the spatial components corresponding to the impinging angles of the sources. Their evaluations confirm that this simplification attains comparable accuracy of source angle and power estimation with a substantial reduction in computational load. Sahnoun et al. [8] address multi-dimensional modal estimation using sparse estimation techniques in combination with an efficient multigrid approach. To overcome huge size in the necessary dictionaries, they refine their dictionaries over several levels of resolution. Their sparse modal * Correspondence: fmarvasti@gmail.com Advanced Communications Research Institute, Sharif University of Technology, Tehran, Iran Full list of author information is available at the end of the article Marvasti et al. EURASIP Journal on Advances in Signal Processing 2012, 2012:90 http://asp.eurasipjournals.com/content/2012/1/90",1998,Polibits
Developing a claimsâ€™-based algorithm to identify US patients with COPD,"Background: Claims databases are useful sources to design algorithms for care management strategies. However, for conditions like COPD that depend on clinical data (e.g., spirometry) for accurate diagnosis, their non-availability in claims implies that any claimsâ€™ based identification algorithm that is developed will need to be validated in order to minimize potential misclassification. Aim and Objective: To develop and validate a predictive model to identify COPD patients using claims data integrated with medical records. Methods: A predictive model was developed using US administrative claims from the HealthCore Integrated Research Database linked to spirometry results data of 2,005 patients with a claims-based diagnosis of COPD between 01/01/12â€“11/30/13. LASSO regression with 10-fold cross-validation was used to model 1,505 COPD cases (post-bronchodilator FEV1/FVC Results: The final model included 14 predictors, the strongest of which included: presence of â‰¥3 COPD diagnostic codes each 30 days apart, â‰¥1 pulmonary rehabilitation claim, COPD hospitalization count, and â‰¥1 claim for smoking. The model had good discrimination in identifying COPD cases (c-statistic 0.73) and a high cross-validated positive predictive value (0.86, 95%CI=0.84-0.88) for a probability threshold of â‰¥75% to identify COPD cases. Conclusions: Using multiple diagnostic codes in combination with COPD related healthcare utilization data were found to be valid parameters for identifying COPD patients using claims data alone.",2019,European Respiratory Journal
The LASSO and Sparse Least Squares Regression Methods for SNP Selection in Predicting Quantitative Traits,"Recent work concerning quantitative traits of interest has focused on selecting a small subset of single nucleotide polymorphisms (SNPs) from among the SNPs responsible for the phenotypic variation of the trait. When considered as covariates, the large number of variables (SNPs) and their association with those in close proximity pose challenges for variable selection. The features of sparsity and shrinkage of regression coefficients of the least absolute shrinkage and selection operator (LASSO) method appear attractive for SNP selection. Sparse partial least squares (SPLS) is also appealing as it combines the features of sparsity in subset selection and dimension reduction to handle correlations among SNPs. In this paper, we investigate application of the LASSO and SPLS methods for selecting SNPs that predict quantitative traits. We evaluate the performance of both methods with different criteria and under different scenarios using simulation studies. Results indicate that these methods can be effective in selecting SNPs that predict quantitative traits but are limited by some conditions. Both methods perform similarly overall but each exhibit advantages over the other in given situations. Both methods are applied to Canadian Holstein cattle data to compare their performance.",2012,IEEE/ACM Transactions on Computational Biology and Bioinformatics
Sparse Regression,"Yuan an Lin (2004) proposed the grouped LASSO, which achieves shrinkage and selection simultaneously, as LASSO does, but works on blocks of covariates. That is, the grouped LASSO provides a model where some blocks of regression coefficients are exactly zero. The grouped LASSO is useful when there are meaningful blocks of covariates such as polynomial regression and dummy variables from categorical variables. In this paper, we propose an extension of the grouped LASSO, called â€˜Blockwise Sparse Regressionâ€™ (BSR). The BSR achieves shrinkage and selection simultaneously on blocks of covariates similarly to the grouped LASSO, but it works for general loss functions including generalized linear models. An efficient computational algorithm is developed and a blockwise standardization method is proposed. Simulation results show that the BSR compromises the ridge and LASSO for logistic regression. The proposed method is illustrated with two datasets.",2006,
Genetic Determinants of Weight Loss After Bariatric Surgery,"BackgroundThe weight loss after bariatric surgery shows considerable individual variation. Twin studies of response to dietary interventions and studies of bariatric surgery patients suggest that genetic differences may play a role. This study aimed to examine the effect of three genetic risk scores on the inter-individual variation in excess body mass index loss (EBMIL) after Roux-en-Y gastric bypass. Furthermore, we searched among known adiposity-related single nucleotide polymorphisms (SNPs) for genetic determinants of the inter-individual variation in EBMIL.MethodsPatients with morbid obesity underwent Roux-en-Y gastric bypass and were genotyped (nâ€‰=â€‰577). Two genetic risk scores for weight loss after bariatric surgery and a genetic risk score for body mass index were calculated. Associations between the genetic risk scores and EBMIL were evaluated. Lasso regression was performed on 126 SNPs known to be associated with adiposity.ResultsThe average EBMIL was 76.9% (range 21.7â€“149.2%). EBMIL was 81.1% (SD 20.6) and 73.9% (SD 21.7) in the high and low tertile groups of a genetic risk score for weight loss. Patients with a low genetic risk score for body mass index (in the lowest 5% percentile) had an EBMIL of 68.8% (SD 20.6, pâ€‰=â€‰0.018). Thirteen adiposity-related SNPs were identified to associate with EBMIL through lasso regression.DiscussionA genetic risk score was associated with EBMIL after bariatric surgery, but may not yet be applicable to clinical practice. Patients genetically predisposed to low body mass index had lower weight loss after bariatric surgery.",2019,Obesity Surgery
[Study on polymorphisms of genes with susceptibility to drug induced liver injury in a cohort receiving anti-tuberculosis treatment].,"OBJECTIVE
To investigate the association between the polymorphisms of genes involving in drug metabolism and transport as well as immunological reaction and the risk of anti-tuberculosis drug-induced liver injury(ATLI)in Chinese.


METHODS
This 1âˆ¶4 matched case-control study was conducted by using the data from a cohort study of Anti-tuberculosis Drugs Induced Adverse Reactions in National Tuberculosis Prevention and Control Progtam of China. Genes involving in three phase of drug metabolism and transport as well as related immunological reaction were chosen and single nucleotide polymorphisms(SNPs)were genotyped by TaqMan allele discrimination technology. Lasso regression and multivariate conditional logistic regression analysis were used to select susceptible genes.


RESULTS
A total of 33 genes with 75 SNPs were tested. The combined results of Lasso and regression logistic regression analysis showed that genetic polymorphism of SLCO1B1 rs4149014, HSPA1L rs2227956, STAT3 rs1053023 and IL-6 rs2066992 were significantly associated with the risk of ATLI(P<0.05).


CONCLUSION
SLCO1B1, HSPA1L, STAT3 and IL-6 might be the susceptibility genes of drug induced liver injury in patients receiving anti-tuberculosis treatment.",2016,Zhonghua liu xing bing xue za zhi = Zhonghua liuxingbingxue zazhi
Improved Incremental First-Order Oracle Complexity of Variance Reduced Methods for Nonsmooth Convex Stochastic Composition Optimization,"We consider the nonsmooth convex composition optimization problem where the objective is a composition of two finite-sum functions and analyze stochastic compositional variance reduced gradient (\textsf{SCVRG}) methods for them. \textsf{SCVRG} and its variants have recently drawn much attention given their edge over stochastic compositional gradient descent (\textsf{SCGD}); but the theoretical analysis exclusively assumes strong convexity of the objective, which excludes several important examples such as Lasso, logistic regression, principle component analysis and deep neural nets. In contrast, we prove non-asymptotic incremental first-order oracle (\textsf{IFO}) complexity of \textsf{SCVRG} or its novel variants for nonsmooth convex composition optimization and show that they are provably faster than \textsf{SCGD} and gradient descent. More specifically, our method achieves the total \textsf{IFO} complexity of $O\left((m+n)\log\left(1/\epsilon\right)+1/\epsilon^3\right)$ which improves that of $O\left(1/\epsilon^{3.5}\right)$ and $O\left((m+n)/\sqrt{\epsilon}\right)$ obtained by \textsf{SCGD} and accelerated gradient descent respectively. Experiments on sparse mean-variance optimization problem demonstrates that our method outperforms other competing methods.",2018,arXiv: Optimization and Control
Stacked Penalized Logistic Regression for Selecting Views in Multi-View Learning,"In biomedical research many different types of patient data can be collected, including various types of omics data and medical imaging modalities. Applying multi-view learning to these different sources of information can increase the accuracy of medical classification models compared with single-view procedures. However, the collection of biomedical data can be expensive and taxing on patients, so that superfluous data collection should be avoided. It is therefore necessary to develop multi-view learning methods which can accurately identify the views most important for prediction. In recent years, several biomedical studies have used an approach known as multi-view stacking (MVS), where a model is trained on each view separately and the resulting predictions are combined through stacking. In these studies, MVS has been shown to increase classification accuracy. However, the MVS framework can also be used for selecting a subset of important views. To study the view selection potential of MVS, we develop a special case called stacked penalized logistic regression (StaPLR). Compared with existing view-selection methods, StaPLR can make use of faster optimization algorithms and is easily parallelized. We show that nonnegativity constraints on the parameters of the function which combines the views are important for preventing unimportant views from entering the model. We investigate the performance of StaPLR through simulations, and consider two real data examples. We compare the performance of StaPLR with an existing view selection method called the group lasso and observe that, in terms of view selection, StaPLR has a consistently lower false positive rate.",2018,ArXiv
MRI-Based Radiomics: Associations With the Recurrence-Free Survival of Patients With Hepatocellular Carcinoma Treated With Conventional Transcatheter Arterial Chemoembolization.,"BACKGROUND
Preoperative estimation of hepatocellular carcinoma (HCC) recurrence after conventional transcatheter arterial chemoembolization (c-TACE) is crucial for subsequent follow-up and therapy decisions.


PURPOSE
To evaluate the associations of radiomics models based on pretreatment contrast-enhanced MRI, a clinical-radiological model and a combined model with the recurrence-free survival (RFS) of patients with HCC after c-TACE, and to develop a radiomics nomogram for individual RFS estimations and risk stratification.


STUDY TYPE
Retrospective.


POPULATION
In all, 184 consecutive HCC patients.


FIELD STRENGTH/SEQUENCE
1.5T or 3.0T, including T2 WI, T1 WI, and contrast-enhanced T1 WI.


ASSESSMENT
All HCC patients were randomly divided into the training (n = 110) and validation datasets (n = 74). Radiomics signatures capturing intratumoral and peritumoral expansion (1, 3, and 5â€‰mm) were constructed, and the radiomics models were set up using least absolute shrinkage and selection operator (LASSO) Cox regression. Clinical-radiological features were identified by univariate and multivariate Cox regression. The clinical-radiological model and the combined model fusing the radiomics signature with the clinical-radiological risk factors were developed by a multivariate Cox proportional hazard model. A radiomics nomogram derived from the combined model was established.


STATISTICAL TESTS
LASSO Cox regression, univariate and multivariate Cox regression, Kaplan-Meier analysis were performed. The discrimination performance of each model was quantified by the C-index.


RESULTS
Among the different peritumoral expansion models, only the 3-mm peritumoral expansion model (C-index, 0.714) showed a comparable performance (P = 0.4087) to that of the portal venous phase intratumoral model (C-index, 0.727). The combined model showed the best performance and the C-index was 0.802. Kaplan-Meier analysis showed that the cutoff values of the combined model relative to a median value (1.7426) perfectly stratified these patients into high-risk and low-risk subgroups.


DATA CONCLUSION
The combined model is more valuable than the clinical-radiological model or radiomics model alone for evaluating the RFS of HCC patients after c-TACE, and the radiomics nomogram can be used to preoperatively and individually estimate RFS.


LEVEL OF EVIDENCE
3 Technical Efficacy Stage: 4 J. MAGN. RESON. IMAGING 2019.",2019,Journal of magnetic resonance imaging : JMRI
Bayesian Quantile Regression Modeling to Estimate Extreme Rainfall in Indramayu,Quantile regression can be used to analyze symmetric or asymmetric data. Estimates of quantile regression parameters are obtained by the simplex method. Another approach is the Bayesian method based on Laplace's asymmetric distribution using MCMC. MCMC is used numerically to estimate parameters from each posterior distribution. The Bayesian quantile regression and the quantile regression can be used for statistical downscaling in extreme rainfall cases. This study used statistical downscaling to obtain relationship between global-scale data and local-scale data. The data used were monthly rainfall data in Indramayu and GCM output data. LASSO regularization was used to overcome multicollinearity problems in GCM output data. The purpose of this study was to compare Bayesian quantile regression models with quantile regression. The Bayesian quantile regression and the quantile regression couldpredict extreme rainfallmore accurate and consistent in one year ahead. The Bayesian quantile regression model is relatively better than the quantile regression.,2020,
Algorithms for Sparse Linear Classifiers in the Massive Data Setting,"Classifiers favoring sparse solutions, such as support vector machines, relevance vector machines, LASSO-regression based classifiers, etc., provide competitive methods for classification problems in high dimensions. However, current algorithms for training sparse classifiers typically scale quite unfavorably with respect to the number of training examples. This paper proposes online and multi-pass algorithms for training sparse linear classifiers for high dimensional data. These algorithms have computational complexity and memory requirements that make learning on massive data sets feasible. The central idea that makes this possible is a straightforward quadratic approximation to the likelihood function.",2008,Journal of Machine Learning Research
A Three-Gene Classifier Associated With MicroRNA-Mediated Regulation Predicts Prostate Cancer Recurrence After Radical Prostatectomy,"Background and Objective After radical prostatectomy (RP), prostate cancer (PCa) patients may experience biochemical recurrence (BCR) and clinical recurrence, which remains a dominant issue in PCa treatment. The purpose of this study was to identify a protein-coding gene classifier associated with microRNA (miRNA)-mediated regulation to provide a comprehensive prognostic index to predict PCa recurrence after RP. Methods Candidate classifiers were constructed using two machine-learning algorithms (a least absolute shrinkage and selector operation [LASSO]-based classifier and a decision tree-based classifier) based on a discovery cohort (n = 156) from The Cancer Genome Atlas (TCGA) database. After selecting the LASSO-based classifier based on the prediction accuracy, both an internal validation cohort (n = 333) and an external validation cohort (n = 100) were used to examined the classifier using survival analysis, time-dependent receiver operating characteristic (ROC) curve analysis, and univariate and multivariate Cox proportional hazards regression analyses. Functional enrichment analysis of co-expressed genes was carried out to explore the underlying moleculer mechanisms of the genes included in the classifier. Results We constructed a three-gene classifier that included FAM72B, GNE, and TRIM46, and we identified four upstream prognostic miRNAs (hsa-miR-133a-3p, hsa-miR-222-3p, hsa-miR-1301-3p, and hsa-miR-30c-2-3p). The classifier exhibited a remarkable ability (area under the curve [AUC] = 0.927) to distinguish PCa patients with high and low Gleason scores in the discovery cohort. Furthermore, it was significantly associated with clinical recurrence (p < 0.0001, log rank statistic = 20.7, AUC = 0.733) and could serve as an independent prognostic factor of recurrence-free survival (hazard ratio: 1.708, 95% CI: 1.180â€“2.472, p < 0.001). Additionally, it was a predictor of BCR according to BCR-free survival analysis (p = 0.0338, log rank statistic = 4.51). Conclusions The three-gene classifier associated with miRNA-mediated regulation may serve as a novel prognostic biomarker for PCa patients after RP.",2019,Frontiers in Genetics
Prediction of outcomes in mild TBI in the NTDB,"Traumatic brain injury (TBI) accounts for >1.3 million ED visits and >2750,000 hospitalizations each year. Although guidelines exist for how to triage and treat these patients based on the severity of TBI, there is no clear consensus statement on which patients need intensive care unit (ICU) admission, and wide variability in practice. Many hospital guidelines currently suggest that all patients with intracranial hemorrhage of any severity be observed in ICU due to risk of decompensation and possible need for intervention. Several studies have tried to make prediction models of outcomes after head trauma. In particular, some single-center datasets have shown that certain classes of low-risk patients have low probabilities of decompensation, and so may be better observed on the hospital floor in order to conserve hospital resources. For instance, Nishijima et al used binary recursive partitioning on the UC Davis TBI-ICU data set and found that four parameters (abnormal mental status (GCS < 15), non-isolated head injury, age > 65 years, and swelling/shift on CT) was 98% sensitive and 50% specific with a ROC AUC of 0.74. Washington et al. showed that age >65 years, anticoagulation therapy, frontal contusions and high volume intracranial hemorrhage were significant predictors of decompensation, but did not evaluate their model. Overall, no consensus prediction formula exists. Thus a robust formula for clinical decision support with regard to ICU admission for mild TBI patients is needed (since moderate-severe TBI is an easier call for ICU admission); only one study to date has looked at ICU admission in mild TBI. Here the goal was to find a robust score for prediction that is also sparse. Clinicians are highly unlikely to apply a complicated rule, especially if requires input to a computer in a â€˜black-boxâ€™ model. Thus penalized linear regression was chosen, with a hypothesis that the Lasso penalty would be able to identify a sparse model for easy applicability.",2013,
Integrative analysis of multiple diverse omics datasets by sparse group multitask regression,"A variety of high throughput genome-wide assays enable the exploration of genetic risk factors underlying complex traits. Although these studies have remarkable impact on identifying susceptible biomarkers, they suffer from issues such as limited sample size and low reproducibility. Combining individual studies of different genetic levels/platforms has the promise to improve the power and consistency of biomarker identification. In this paper, we propose a novel integrative method, namely sparse group multitask regression, for integrating diverse omics datasets, platforms, and populations to identify risk genes/factors of complex diseases. This method combines multitask learning with sparse group regularization, which will: (1) treat the biomarker identification in each single study as a task and then combine them by multitask learning; (2) group variables from all studies for identifying significant genes; (3) enforce sparse constraint on groups of variables to overcome the ""small sample, but large variables"" problem. We introduce two sparse group penalties: sparse group lasso and sparse group ridge in our multitask model, and provide an effective algorithm for each model. In addition, we propose a significance test for the identification of potential risk genes. Two simulation studies are performed to evaluate the performance of our integrative method by comparing it with conventional meta-analysis method. The results show that our sparse group multitask method outperforms meta-analysis method significantly. In an application to our osteoporosis studies, 7 genes are identified as significant genes by our method and are found to have significant effects in other three independent studies for validation. The most significant gene SOD2 has been identified in our previous osteoporosis study involving the same expression dataset. Several other genes such as TREML2, HTR1E, and GLO1 are shown to be novel susceptible genes for osteoporosis, as confirmed from other studies.",2014,Frontiers in Cell and Developmental Biology
Approximation Lasso Methods for Language Modeling,"Lasso is a regularization method for parameter estimation in linear models. It optimizes the model parameters with respect to a loss function subject to model complexities. This paper explores the use of lasso for statistical language modeling for text input. Owing to the very large number of parameters, directly optimizing the penalized lasso loss function is impossible. Therefore, we investigate two approximation methods, the boosted lasso (BLasso) and the forward stagewise linear regression (FSLR). Both methods, when used with the exponential loss function, bear strong resemblance to the boosting algorithm which has been used as a discriminative training method for language modeling. Evaluations on the task of Japanese text input show that BLasso is able to produce the best approximation to the lasso solution, and leads to a significant improvement, in terms of character error rate, over boosting and the traditional maximum likelihood estimation.",2006,
Variable Selection for Nonparametric Learning with Power Series Kernels,"In this letter, we propose a variable selection method for general nonparametric kernel-based estimation. The proposed method consists of two-stage estimation: (1) construct a consistent estimator of the target function, and (2) approximate the estimator using a few variables by â„“1-type penalized estimation. We see that the proposed method can be applied to various kernel nonparametric estimation such as kernel ridge regression, kernel-based density, and density-ratio estimation. We prove that the proposed method has the property of variable selection consistency when the power series kernel is used. Here, the power series kernel is a certain class of kernels containing polynomial and exponential kernels. This result is regarded as an extension of the variable selection consistency for the nonnegative garrote (NNG), a special case of the adaptive Lasso, to the kernel-based estimators. Several experiments, including simulation studies and real data applications, show the effectiveness of the proposed method.",2019,Neural Computation
Inference robust to outliers with l1-norm penalization.,"This paper considers the problem of inference in a linear regression model with outliers where the number of outliers can grow with sample size but their proportion goes to 0. We apply the square-root lasso estimator penalizing the l1-norm of a random vector which is non-zero for outliers. We derive rates of convergence and asymptotic normality. Our estimator has the same asymptotic variance as the OLS estimator in the standard linear model. This enables to build tests and confidence sets in the usual and simple manner. The proposed procedure is also computationally advantageous as it amounts to solving a convex optimization program. Overall, the suggested approach constitutes a practical robust alternative to the ordinary least squares estimator.",2019,arXiv: Statistics Theory
Enhanced Noisy Sparse Subspace Clustering via Reweighted L1-Minimizationâ€ ,"Sparse subspace clustering (SSC) relies on sparse regression for accurate neighbor identification. Inspired by recent progress in compressive sensing (CS), this paper proposes a new sparse regression scheme for SSC via reweighted ï¬1-minimization, which also generalizes a two-step ï¬1-minimization algorithm introduced by E. J. CandÃ¨s al all in [The Annals of Statistics, vol. 42, no. 2, pp. 669â€“699, 2014] without incurring extra complexity burden. To fully exploit the prior information conveyed by the computed sparse vector in the first step, our approach places a weight on each component of the regression vector, and solves a weighted LASSO in the second step. We discuss the impact of weighting on neighbor identification, argue that a popular weighting rule used in CS literature is not suitable for the SSC purpose, and propose a new weighting scheme for enhancing neighbor identification accuracy. Extensive simulation results are provided to validate our discussions and evidence the effectiveness of the proposed approach. Some key issues for future works are also highlighted.",2018,2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)
Comparison of Different Methods for Handling Linkage Disequilibrium in Genetic-Association Analyses via Simulation,"Multiple makers exhibiting strong linkage disequilibrium (LD) in a single genomic region and a phenotype of interest generate very compelling statistical associations in the large-scale genetic-association studies. LD, especially strong LD, between variations at neighboring loci can not only make it difficult to discern markers associated with phenotype, but also create difficulties for distinguishing the functionally relevant variations from nonfunctional variations. In this paper, we compared 5 different methods, Boosting, LASSO, Ridge regression, Stepwise and Single locus analysis, for identifying real functional variations in the circumstance of LD exiting in the variations at different loci via simulation. We found that in the case of strong LD between 20 loci, Ridge regression performs the best while in the case of degenerated LD between 500 and 1000 loci, Boosting outperforms other methods.",2009,2009 2nd International Conference on Biomedical Engineering and Informatics
Prediction of Time to Tumor Recurrence in Ovarian Cancer: Comparison of Three Sparse Regression Methods,"Ovarian cancer is the most fatal gynecological malignancy among women. Making a reliable prediction of time to tumor recurrence would be a valuable contribution to post-surgery follow-up care. In this paper we study three well-known data sets, known as TCGA, Tothill and Yoshihara, and compare three sparse regression methods, two of which (LASSO and EN) are well-known and the third (CLOT) is from our laboratory. It is established that the three data sets are very different from each other. Therefore a two-stage predictor is built, whereby each test sample is first assigned to the most likely data set and then the corresponding predictor is used. The weighted concordance of each regression method is computed to compare the methods and select the best one. CLOT uses a biomarker panel of 103 genes and achieves a concordance index of 0.7829, which is higher than that achieved by the other two methods.",2017,
Learning dynamic temporal graphs for oil-production equipment monitoring system,"Learning temporal graph structures from time series data reveals important dependency relationships between current observations and histories. Most previous work focuses on learning and predicting with ""static"" temporal graphs only. However, in many applications such as mechanical systems and biology systems, the temporal dependencies might change over time. In this paper, we develop a dynamic temporal graphical models based on hidden Markov model regression and lasso-type algorithms. Our method is able to integrate two usually separate tasks, i.e. inferring underlying states and learning temporal graphs, in one unified model. The output temporal graphs provide better understanding about complex systems, i.e. how their dependency graphs evolve over time, and achieve more accurate predictions. We examine our model on two synthetic datasets as well as a real application dataset for monitoring oil-production equipment to capture different stages of the system, and achieve promising results.",2009,
Bayesian semiparametric additive quantile regression,"Quantile regression provides a convenient framework for analyzing the impact of covariates on the complete conditional distribution of a response variable instead of only the mean. While frequentist treatments of quantile regression are typically completely nonparametric, a Bayesian formulation relies on assuming the asymmetric Laplace distribution as auxiliary error distribution that yields posterior modes equivalent to frequentist estimates. In this paper, we utilize a location-scale-mixture of normals representation of the asymmetric Laplace distribution to transfer different flexible modeling concepts from Gaussian mean regression to Bayesian semiparametric quantile regression. In particular, we will consider high-dimensional geoadditive models comprising LASSO regularization priors and mixed models with potentially non-normal random effects distribution modeled via a Dirichlet process mixture. These extensions are illustrated using two large-scale applications on net rents in Munich and longitudinal measurements on obesity among children.",2013,Statistical Modelling
Regularization for Cox's Proportional Hazards Model with Np-dimensionality.,"High throughput genetic sequencing arrays with thousands of measurements per sample and a great amount of related censored clinical data have increased demanding need for better measurement specific model selection. In this paper we establish strong oracle properties of non-concave penalized methods for non-polynomial (NP) dimensional data with censoring in the framework of Cox's proportional hazards model. A class of folded-concave penalties are employed and both LASSO and SCAD are discussed specifically. We unveil the question under which dimensionality and correlation restrictions can an oracle estimator be constructed and grasped. It is demonstrated that non-concave penalties lead to significant reduction of the ""irrepresentable condition"" needed for LASSO model selection consistency. The large deviation result for martingales, bearing interests of its own, is developed for characterizing the strong oracle property. Moreover, the non-concave regularized estimator, is shown to achieve asymptotically the information bound of the oracle estimator. A coordinate-wise algorithm is developed for finding the grid of solution paths for penalized hazard regression problems, and its performance is evaluated on simulated and gene association study examples.",2011,Annals of statistics
"The Usage of Lasso, Ridge, and Linear Regression to Explore the Most Influential Metabolic Variables that Affect Fasting Blood Sugar in Type 2 Diabetes Patients","Abstract Background and aims: To explore the most influential variables of fasting blood sugar (FBS) with three regression methods, to identify the existence chance of type 2 diabetes based on influential variables with logistic regression (LR), and to compare the three regression methods according to Mean Squared Error (MSE) value. Material and Methods: In this cross-sectional study, 270 patients suffering from type 2 diabetes for at least 6 months and 380 healthy people were participated. The Linear regression, Ridge regression, and Least Absolute Shrinkage and Selection Operator (Lasso) regression were used to find influential variables for FBS. Results: Among 15 variables (8 metabolic, 7 characteristic), Lasso regression selected HbA1c, Urea, age, BMI, heredity, and gender, Ridge regression selected HbA1c, heredity, gender, smoking status, and drug use, and Linear regression selected HbA1c as the most effective predictors for FBS. Conclusion: HbA1c is the most influential predictor of FBS among 15 variables according to the result of three regression methods. Controlling the variation of HbA1c leads to a more stable FBS. Beside FBS that should be checked before breakfast, maybe HbA1c could be helpful in diagnosis of Type 2 diabetes.",2019,Romanian Journal of Diabetes Nutrition and Metabolic Diseases
Frequency of recurrence of atrial fibrillation within 48 hours after ablation and its impact on long-term outcome.,"Because of delayed structural and electrophysiologic effects of radiofrequency ablation of atrial fibrillation (AF), early recurrence of AF after ablation does not necessarily indicate long-term ablation failure. This study was intended to assess the prognostic value of early recurrence of AF within 48 hours after ablation. The study included 234 patients (aged 23 to 80 years; 72% men) with symptomatic drug-resistant paroxysmal (n = 165) or persistent AF (n = 69) who underwent either Lasso-guided segmental pulmonary vein isolation (n = 83) or CARTO-guided left atrial circumferential ablation (n = 151). After a median follow-up of 12.7 months, 64% of patients with paroxysmal and 45% of patients with persistent AF were AF free. Early recurrence of AF occurred in 43% of patients and was more frequently observed in the persistent-AF group (paroxysmal vs persistent 39% vs 54%; p = 0.037). Early recurrence of AF was a significant predictor of long-term ablation failure in univariate (hazard ratio [HR] 2.29, p <0.001) and multivariate (HR 2.17. p <0.001) Cox regression analysis. Nevertheless, 46% of patients with early recurrence of AF were AF free during long-term follow-up compared with 68% of patients without early recurrence of AF. The prognostic value of early recurrence of AF was found in patients with paroxysmal (HR 2.05, p = 0.005) and persistent AF (HR 2.35, p = 0.013). In conclusion, early recurrence of AF within 48 hours after ablation was a significant predictor of a poor long-term ablation outcome. However, because nearly half the patients with early recurrence of AF remained AF free during long-term follow-up, early recurrence of AF should not automatically result in an early repeated procedure.",2008,The American journal of cardiology
Improved Assessment of Hepatic Steatosis in Humans Using Multi-Parametric Quantitative Ultrasound,"Nonalcoholic fatty liver disease (NAFLD) affects ~25% of the world population. Confounder-corrected chemical-shift-encoded MRI-derived proton density fat fraction (MRI-PDFF) is an established quantitative noninvasive biomarker of hepatic steatosis but has limited availability. There is a clinical need for more practical and accessible methods to noninvasively assess hepatic steatosis. Previous work has shown that two quantitative ultrasound (QUS) biomarkers - attenuation coefficient (AC) and backscatter coefficient (BSC) - are correlated with hepatic steatosis. Examining a broad range of QUS biomarkers, this study aims to develop an improved, multi-parametric QUS-based approach to diagnose NAFLD and quantify hepatic fat, with MRI-PDFF as the reference standard. 102 participants recruited from the UCSD NAFLD Research Center underwent QUS exams on the right liver lobe with an Acuson S3000 ultrasound scanner and the 4C1 and 6C1HD transducers. Seven QUS biomarkers - AC, BSC, three Lizzi-Feleppa parameters (slope, intercept, midband), and two envelope parameters (k and Î¼) - were derived from ultrasound radiofrequency data. Two multivariable models were developed based on QUS biomarkers: a generalized linear regression model to predict hepatic PDFF using stepwise regression for biomarker selection and a regularized logistic regression model to classify NAFLD (MRI-PDFF>5%, N=78/102) versus no NAFLD (MRI-PDFFâ‰¤5%) using LASSO regularization for biomarker selection. Leave-one-out cross-validation was performed. The final regression model selected the midband and k-parameter. The cross-validated predicted PDFF values were correlated with the reference MRI-PDFF values (Spearman Ï = 0.82 and Pearsonâ€™s r = 0.76). In comparison, Pearsonâ€™s r was 0.59 between AC and MRI-PDFF and 0.58 between BSC and MRI-PDFF. The final classifier model selected the midband, k-parameter and Î¼-parameter, achieving an area under the receiver operating characteristic curve (AUROC) of 0.88. In comparison, AUROC was 0.83 using AC and 0.84 using BSC. The results suggest that multi-parametric QUS can improve the quantification of hepatic steatosis and diagnosis of NAFLD.",2019,2019 IEEE International Ultrasonics Symposium (IUS)
Selecting the LASSO regularization parameter via Bayesian principles,"We investigate the Bayesian interpolation method for estimator selection, and apply it to the problem of regularization parameter selection in Ridge and LASSO regressions. Specifically, the Bayesian interpolation method leads to criteria for choosing the Ridge and LASSO regularizations; the criterion for LASSO is novel. We show that our proposed technique gives comparable and sometimes superior performance compared with other methods like the Generalized Cross Validation (GCV), the extended Akaike Information Criterion (AIC) and the extended Bayesian Information Criterion (BIC).",2016,2016 IEEE International Conference on the Science of Electrical Engineering (ICSEE)
Dietary Habits and Cooking Methods Could Reduce Avoidable Exposure to PCBs in Maternal and Cord Sera,"Polychlorinated biphenyls (PCBs), like other persistent organic pollutants, are accumulating throughout the food chain and pose health threats to humans, especially children and foetuses. There is no protocol for reducing the contamination levels of the PCBs in humans. This study identified food items and cooking methods that reduce serum PCB levels by analysing data collected from the Chiba Study of Mother and Child Health. The sample size was 194 subjects. Serum PCB levels were measured using gas chromatographyâ€“electron capture negative ionization quadrupole mass spectrometry. Information on dietary habits was obtained from a brief diet history questionnaire that included questions about food items and cooking methods. Food items were categorized into food groups, and nutrient levels were calculated based on food item consumption. Principal component analysis and lasso regression were used as statistical methods. The analyses of food items and nutrients suggested that food items rich in dietary fibre reduce avoidable exposure to PCBs, as could grilling and deep frying of food, which could reduce avoidable exposure to serum PCBs in mothers and foetuses. (174 words).",2017,Scientific Reports
Exploration de donnÃ©es pour l'optimisation de trajectoires aÃ©riennes,"Cette these porte sur l'utilisation de donnees de vols pour l'optimisation de trajectoires de montee vis-a-vis de la consommation de carburant.Dans un premier temps nous nous sommes interesse au probleme d'identification de modeles de la dynamique de l'avion dans le but de les utiliser pour poser le probleme d'optimisation de trajectoire a resoudre. Nous commencont par proposer une formulation statique du probleme d'identification de la dynamique. Nous l'interpretons comme un probleme de regression multi-tÃ¢che a structure latente, pour lequel nous proposons un modele parametrique. L'estimation des parametres est faite par l'application de quelques variations de la methode du maximum de vraisemblance.Nous suggerons egalement dans ce contexte d'employer des methodes de selection de variable pour construire une structure de modele de regression polynomiale dependant des donnees. L'approche proposee est une extension a un contexte multi-tÃ¢che structure du bootstrap Lasso. Elle nous permet en effet de selectionner les variables du modele dans un contexte a fortes correlations, tout en conservant la structure du probleme inherente a nos connaissances metier.Dans un deuxieme temps, nous traitons la caracterisation des solutions du probleme d'optimisation de trajectoire relativement au domaine de validite des modeles identifies. Dans cette optique, nous proposons un critere probabiliste pour quantifier la proximite entre une courbe arbitraire et un ensemble de trajectoires echantillonnees a partir d'un meme processus stochastique. Nous proposons une classe d'estimateurs de cette quantitee et nous etudions de facon plus pratique une implementation nonparametrique base sur des estimateurs a noyau, et une implementation parametrique faisant intervenir des melanges Gaussiens. Ce dernier est introduit comme penalite dans le critere d'optimisation de trajectoire dans l'objectif l'intention d'obtenir directement des trajectoires consommant peu sans trop s'eloigner des regions de validite.",2018,
Investigating structural and occupant drivers of annual residential electricity consumption using regularization in regression models,"Abstract Achieving further reductions in building electricity usage requires a detailed characterization of electricity consumption in homes. Understanding drivers of consumption can inform strategies for promoting conservation and efficiency. While there exist numerous approaches for modeling building energy demand, the use of regularization methods in statistical models can address challenges inherent to building energy modeling while also enabling more accurate predictions and better identification of variables that influence consumption. This paper applies five regularization techniques to regression models of original survey and electricity consumption data for more than one thousand households in California. It finds that of these, elastic net and two extensions of the lassoâ€”group lasso and adaptive lassoâ€”outperform other approaches in terms of prediction accuracy and model interpretability. These findings contribute to methodological approaches for modeling energy consumption in buildings as well as to our understanding of key drivers of consumption. The paper shows that while structural factors predominate in explaining annual electricity consumption patterns, habitual actions taken to save energy in the home are important for reducing consumption while pro-environmental attitudes and energy literacy are not. Implications for improving building energy modeling and for informing demand reduction strategies are discussed in the context of the low-carbon transition.",2019,Energy
An evaluation of penalised survival methods for developing prognostic models with rare events.,"Prognostic models for survival outcomes are often developed by fitting standard survival regression models, such as the Cox proportional hazards model, to representative datasets. However, these models can be unreliable if the datasets contain few events, which may be the case if either the disease or the event of interest is rare. Specific problems include predictions that are too extreme, and poor discrimination between low-risk and high-risk patients. The objective of this paper is to evaluate three existing penalised methods that have been proposed to improve predictive accuracy. In particular, ridge, lasso and the garotte, which use penalised maximum likelihood to shrink coefficient estimates and in some cases omit predictors entirely, are assessed using simulated data derived from two clinical datasets. The predictions obtained using these methods are compared with those from Cox models fitted using standard maximum likelihood. The simulation results suggest that Cox models fitted using maximum likelihood can perform poorly when there are few events, and that significant improvements are possible by taking a penalised modelling approach. The ridge method generally performed the best, although lasso is recommended if variable selection is required.",2012,Statistics in medicine
TEDAS - Tail Event Driven ASset Allocation,"Portfolio selection and risk management are very actively studied topics in quantitative finance and applied statistics. They are closely related to the dependency structure of portfolio assets or risk factors. The correlation structure across assets and opposite tail movements are essential to the asset allocation problem, since they determine the level of risk in a position. Correlation alone is not informative on the distributional details of the assets. By introducing TEDAS -Tail Event Driven ASset allocation, one studies the dependence between assets at different quantiles. In a hedging exercise, TEDAS uses adaptive Lasso based quantile regression in order to determine an active set of negative non-zero coefficients. Based on these active risk factors, an adjustment for intertemporal correlation is made. Finally, the asset allocation weights are determined via a Cornish-Fisher Value-at-Risk optimization. TEDAS is studied in simulation and a practical utility-based example using hedge fund indices.",2014,
"Fine mapping and single nucleotide polymorphism effects estimation on pig chromosomes 1, 4, 7, 8, 17 and X","Fine mapping of quantitative trait loci (QTL) from previous linkage studies was performed on pig chromosomes 1, 4, 7, 8, 17, and X which were known to harbor QTL. Traits were divided into: growth performance, carcass, internal organs, cut yields, and meat quality. Fifty families were used of a F2 population produced by crossing local Brazilian Piau boars with commercial sows. The linkage map consisted of 237 SNP and 37 microsatellite markers covering 866 centimorgans. QTL were identified by regression interval mapping using GridQTL. Individual marker effects were estimated by Bayesian LASSO regression using R. In total, 32 QTL affecting the evaluated traits were detected along the chromosomes studied. Seven of the QTL were known from previous studies using our F2 population, and 25 novel QTL resulted from the increased marker coverage. Six of the seven QTL that were significant at the 5% genome-wide level had SNPs within their confidence interval whose effects were among the 5% largest effects. The combined use of microsatellites along with SNP markers increased the saturation of the genome map and led to smaller confidence intervals of the QTL. The results showed that the tested models yield similar improvements in QTL mapping accuracy.",2013,Genetics and Molecular Biology
Model selection strategies in genome-wide association studies,"Unravelling the genetic architecture of common diseases is a continuing challenge in human genetics. While genome-wide association studies (GWAS) have proven to be successful in identifying many new disease susceptibility loci, the extension of these studies beyond single-SNP methods of analysis has been limited. The incorporation of multi-locus methods of analysis may, however, increase the power of GWAS to detect genes of smaller effect size, as well as genes that interact with each other and the environment. This investigation carried out large-scale simulations of four multi-locus model selection techniques; namely forward and backward selection, Bayesian model averaging (BMA) and least angle regression with a lasso modification (lasso), in order to compare the type I error rates and power of each method. At a type I error rate of ~5%, lasso showed the highest power across varied effect sizes, disease frequencies and genetic models. Lasso penalized regression was then used to perform three different types of analysis on GWAS data. Firstly, lasso was applied to the Wellcome Trust Case Control Consortium (WTCCC) data and identified many of the WTCCC SNPs that had a moderate-strong association (p<10-5) type 2 diabetes (T2D), as well as some of the moderate WTCCC associations (p<10-4) that have since been replicated in a large-scale meta-analysis. Secondly, lasso was used to fine-map the 17q21 childhood asthma risk locus and identified putative secondary signals in the 17q21 region, that may further contribute to childhood asthma risk. Finally, lasso identified three potential interaction effects potentially contributing towards coronary artery disease (CAD) risk. While the validity of these findings hinges on their replication in follow-up studies, the results suggest that lasso may provide scientists with exciting new methods of dissecting, and ultimately understanding, the complex genetic framework underlying common human diseases.",2011,Genetic Epidemiology
RÃ©cupÃ©ration clinico-radiologique dâ€™un syndrome dâ€™embolie graisseuse cÃ©rÃ©brale chez un patient drÃ©panocytaire,"Introduction La drepanocytose est une hemoglobinopathie genetique, responsable dâ€™une anemie hemolytique chronique et de phenomenes vaso-occlusifs pouvant atteindre tous les organes. La complication la plus redoutee est la necrose medullaire etendue pouvant se compliquer dâ€™un syndrome dâ€™embolie graisseuse. Elle est responsable dâ€™un taux de mortalite eleve.Â Lâ€™amelioration de la prise en charge de ces patients et les sequelles cerebrales secondaires sont peu decrites. Des cas similaires a celui que nous rapportons existent, mais la survie du patient et son suivi nâ€™ont ete que rarement permis. Observation Un patient de 19Â ans thalasso-drepanocytaire est hospitalise pour une crise vaso-occlusive (CVO) avec des douleurs intenses du rachis lombaire et du bassin. Initialement favorable, mais lâ€™evolution est marquee a 48Â heures par un tableau de detresse respiratoire aigue associee a une obnubilation. Lâ€™angioscanner thoracique realise retrouve de multiples embols sous-segmentaires suspects dâ€™etre dâ€™origine a la fois cruorique et graisseuse. Le patient est transfere en service de reanimation et intube rapidement devant lâ€™aggravation de la defaillance respiratoire et neurologique. Plusieurs echanges transfusionnels sont realises en urgence, permettant la diminution de son taux dâ€™hemoglobine S de 73Â a 14Â %. Une IRM cerebrale est realisee et retrouve de multiples micro hemorragies, evocatrices dâ€™embols graisseux, de lâ€™ensemble du parenchyme cerebral. Apres quatre jours de ventilation mecanique le patient se reveille en presentant initialement un ralentissement psychomoteur, sans deficit sensitivomoteur focal, sans desorientation temporo-spatiale, associe a une bonne evolution clinicobiologique, permettant un transfert en medecine. Quatre jours apres sa sortie de reanimation, le patient presente une irritabilite et une agitation inhabituelles, suivies dâ€™hallucinations visuelles et auditives pour lesquelles une nouvelle IRM cerebrale est realisee. Celle-ci retrouve une restriction de diffusion de lâ€™ensemble du corps calleux et de la substance blanche periventriculaire frontoparietale, egalement visible en T2. Une atteinte toxique est initialement suspectee. Lâ€™evolution sera spontanement favorable, avec une amelioration progressive de son etat neurologique. Une IRM de controle realisee deux semaines plus tard retrouve une regression presque complete des hypersignaux du corps calleux et de la substance blanche parietale posterieure. Le patient ne presenteÂ aucune sequelle cognitive ou motrice. Discussion Le syndrome dâ€™embolie graisseuse est une complication rare mais extremement grave de la drepanocytose faisant suite a une necrose medullaire etendue lors dâ€™une CVO. Il survient frequemment chez les patients drepanocytaires avec une double heterozygotie. La mortalite est elevee, estimee a 40Â %. Cependant, de plus en plus de cas sont rapportes suite a lâ€™amelioration de la prise en charge therapeutique de ces patients avec la realisation rapide dâ€™echanges transfusionnels, qui ont montre leur efficacite [1] . Le diagnostic doit etre evoque devant une atteinte respiratoire, neurologique, voir un tableau de defaillance multi-visceral, compliquant une CVO. Les atteintes cliniques du syndrome dâ€™embolie graisseuse cerebrale sont variables et non specifiques. Celles presentees par notre patient, telles que lâ€™irritabilite, lâ€™agitation, ou les hallucinations ont deja ete decrites [2] . Lâ€™imagerie de reference est lâ€™IRM, qui retrouve typiquement des lesions punctiformes hyperintenses en sequence T2Â et en sequence de diffusion.Â Elles sont visibles dans lâ€™ensemble du parenchyme cerebral mais predominent au niveau de la substance blanche, correspondant a de multiples hemorragies petechiales [2] , [3] . Le mecanisme physiopathologique correspondant aux lesions visibles sur la seconde IRM de notre patient, montrant un hypersignal du corps calleux et de la substance blanche parietale posterieure, reste difficile a expliquer. Un phenomene toxique a ete evoque, secondaire a un passage direct des produits dâ€™anesthesie au travers de la barriere hemato-encephalique lesee. Mais des lesions similaires ont ete decrites lors de syndromes dâ€™embolies graisseuses cerebrales [2] . On peut donc suggerer quâ€™il sâ€™agit de lâ€™evolution de lâ€™atteinte cerebrale du syndrome dâ€™embolie graisseuse chez notre patient. Ces lesions se sont manifestees par des troubles de lâ€™humeur et des hallucinations, pouvant sâ€™expliquer par les lesions predominantes au niveau des noyaux gris centraux et periventriculaires. Elles avaient regressees sur lâ€™IRM de controle a 3Â semaines. Conclusion Les atteintes cerebrales du syndrome dâ€™embolie graisseuse chez le patient drepanocytaire sont encore peu decrites. Notre observation illustre sur le plan clinique et radiologique une recuperation possible grÃ¢ce a la realisation precoce dâ€™echanges transfusionnels.",2017,Revue de MÃ©decine Interne
Full-genomic Network Inference for Non-model organisms: A Case Study for the Fungal Pathogen Candida albicans,"Reverse engineering of full-genomic interaction net- works based on compendia of expression data has been successfully applied for a number of model organisms. This study adapts these approaches for an important non-model organism: The major human fungal pathogen Candida albicans. During the infection process, the pathogen can adapt to a wide range of environmental niches and reversibly changes its growth form. Given the importance of these processes, it is important to know how they are regulated. This study presents a reverse engineering strategy able to infer full- genomic interaction networks for C. albicans based on a linear regression, utilizing the sparseness criterion (LASSO). To overcome the limited amount of expression data and small number of known interactions, we utilize different prior-knowledge sources guiding the network inference to a knowledge driven solution. Since, no database of known interactions for C. albicans exists, we use a text- mining system which utilizes full-text research papers to identify known regulatory interactions. By comparing with these known regulatory interactions, we find an optimal value for global modelling parameters weighting the influence of the sparseness criterion and the prior-knowledge. Furthermore, we show that soft integration of prior-knowledge additionally improves the performance. Finally, we compare the performance of our approach to state of the art network inference approaches.",2011,"World Academy of Science, Engineering and Technology, International Journal of Biological, Biomolecular, Agricultural, Food and Biotechnological Engineering"
Selection of Variables in Quantile Regression (Linear Lasso- Goal Programming),"Quantile regression is a statistical technique intended to estimate, and conduct inference about the conditional quantile functions. Since Koenker and Bassett (1978) introduced quantile regression, which models conditional quantiles as functions of predictors. The quantile regression can give complete information about the relationship between the response variable and covariates on the entire conditional distribution, and has no distributional assumption about the error term in the model. The study evaluates the performance of three methods; two methods of linear programming linear lasso ( 12L1""> -Lasso, 12L2""> -Lasso) and one method of Goal programming. The three methods are used to select the best subset of variables and estimate the parameters of the quantile regression equation when four error distributions, with two different sample sizes and two different parameters for each error distribution. The study found that the estimated risk and relative estimated risk which produced from Goal programming method is less than ER and ERE of ( 12L1""> -Lasso and 12L2""> -Lasso methods.",2014,Asian Journal of Applied Sciences
