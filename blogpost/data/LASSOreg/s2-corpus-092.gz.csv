title,abstract,year,journal
Sparse Principal Covariates Regression for high-dimensional data,"Prediction in a context of high-dimensional data, this is data with many more covariates than observations, is an ill-posed problem. Popular solutions are the introduction of penalties that perform variable selection (e.g., the lasso or elastic net in regression) and the use of dimension reduction methods to reduce the covariates to a few components (e.g., principal covariates regression that simultaneously optimizes the reduction of the covariates to a few components and the prediction of the outcome by these components). From an interpretational point of view it is attractive to reduce the covariate space to a few meaningful components. However, in a high-dimensional context interpretation of the components is daunting as the components are based on a linear combination of a huge number of variables. To account for this interpretational issue, we propose a sparse principal covariates regression approach that selects a limited number of relevant variables to construct the components and that uses an alternating least squares and coordinate descent estimation procedure. We will compare with sparse partial least squares and illustrate with a systems vaccinology example with the aim to predict the antibody titers for subjects vaccinated against the flu by thousands of genes.",2015,International Federation of Classification Societies
LassoNet: Neural networks with Feature Sparsity.,"We introduce LassoNet, a neural network model with global feature selection. The model uses a residual connection to learn a subset of the most informative input features. Specifically, the model honors a hierarchy restriction that an input neuron only be included if its linear variable is important. This produces a path of feature-sparse models in close analogy with the lasso for linear regression, while effectively capturing complex nonlinear dependencies in the data. Using a single residual block, our iterative algorithm yields an efficient proximal map which accurately selects the most salient features. On systematic experiments, LassoNet achieves competitive performance using a much smaller number of input features. LassoNet can be implemented by adding just a few lines of code to a standard neural network.",2019,arXiv: Machine Learning
Simultaneous Variable Selection and Outlier Detection Using Lasso with Applications to Aircraft Landing Data Analysis,"OF THE DISSERTATION Simultaneous Variable Selection and Outlier Detection Using LASSO with Applications to Aircraft Landing Data Analysis by Wei Li Dissertation Director: Regina Y. Liu, Minge Xie, and Cun-Hui Zhang We propose a LASSO-type penalized regression method for simultaneous variable selection and outlier detection in high dimensional linear regression. We apply a mean-shift model to incorporate the coefficients associated with the potential outliers by expressing them as different intercept terms. The sparsity assumption is imposed on both X-covariates and the outlier indicator variables. With suitable penalty factors between X-covaraites and the outlier indicators, we show that the proposed method selects a model of the correct order of dimensionality, under the sparse Riesz condition on the correlation of design variables and a joint sparse Reisz condition on the augmented design matrix. We also show that the estimation/prediction of the selected model can be controlled at a level determined by the sizes of the true model, the outliers and the thresholding level. Moreover, the estimation has a positive breakdown point when both the dimension p and the sample size n tend to infinity, and p >> n. We also provide a generalized version for the estimator by adjusting the penalty weight factor. Finally, we apply the proposed method to analyze an aircraft landing performance data set, for identifying the precursors for undesirable landing performance and reducing the risk of runway overruns.",2012,
One-step estimator paths for concave regularization,"ABSTRACTThe statistics literature of the past 15 years has established many favorable properties for sparse diminishing-bias regularization: techniques that can roughly be understood as providing estimation under penalty functions spanning the range of concavity between l0 and l1 norms. However, lasso l1-regularized estimation remains the standard tool for industrial Big Data applications because of its minimal computational cost and the presence of easy-to-apply rules for penalty selection. In response, this article proposes a simple new algorithm framework that requires no more computation than a lasso path: the path of one-step estimators (POSE) does l1 penalized regression estimation on a grid of decreasing penalties, but adapts coefficient-specific weights to decrease as a function of the coefficient estimated in the previous path step. This provides sparse diminishing-bias regularization at no extra cost over the fastest lasso algorithms. Moreover, our gamma lasso implementation of POSE is accompani...",2013,Journal of Computational and Graphical Statistics
"ModÃ¨les de mÃ©lange pour la rÃ©gression en grande dimension, application aux donnÃ©es fonctionnelles","Les modeles de melange pour la regression sont utilises pour modeliser la relation entre la reponse et les predicteurs, pour des donnees issues de differentes sous-populations. Dans cette these, on etudie des predicteurs de grande dimension et une reponse de grande dimension. Tout dâ€™abord, on obtient une inegalite oracle l1 satisfaite par lâ€™estimateur du Lasso. On sâ€™interesse a cet estimateur pour ses proprietes de regularisation l1. On propose aussi deux procedures pour pallier ce probleme de classification en grande dimension. La premiere procedure utilise lâ€™estimateur du maximum de vraisemblance pour estimer la densite conditionnelle inconnue, en se restreignant aux variables actives selectionnees par un estimateur de type Lasso. La seconde procedure considere la selection de variables et la reduction de rang pour diminuer la dimension. Pour chaque procedure, on obtient une inegalite oracle, qui explicite la penalite necessaire pour selectionner un modele proche de lâ€™oracle. On etend ces procedures au cas des donnees fonctionnelles, ou les predicteurs et la reponse peuvent etre des fonctions. Dans ce but, on utilise une approche par ondelettes. Pour chaque procedure, on fournit des algorithmes, et on applique et evalue nos methodes sur des simulations et des donnees reelles. En particulier, on illustre la premiere methode par des donnees de consommation electrique.",2015,
Definition of a novel vascular invasion-associated multi-gene signature for predicting survival in patients with hepatocellular carcinoma,"The aim of the present study was to identify a vascular invasion-associated gene signature for predicting prognosis in patients with hepatocellular carcinoma (HCC). Using RNA-sequencing data of 292 HCC samples from The Cancer Genome Atlas (TCGA), the present study screened differentially expressed genes (DEGs) between patients with and without vascular invasion. Feature genes were selected from the DEGs by support vector machine (SVM)-based recursive feature elimination (RFE-SVM) algorithm to build a classifier. A multi-gene signature was selected by L1 penalized (LASSO) Cox proportional hazards (PH) regression model from the feature genes selected by the RFE-SVM to develop a prognostic scoring model. TCGA set was defined as the training set and was divided by the gene signature into a high-risk group and a low-risk group. Involvement of the DEGs between the two risk groups in pathways was also investigated. The presence and absence of vascular invasion between patients of training set was 175 DEGs. A classification model of 42 genes performed well in differentiating patients with and without vascular invasion on the training set and the validation set. A 14-gene prognostic model was built that could divide the training set or the validation set into two risk groups with significantly different survival outcomes. A total of 762 DEGs in the two risk groups of the training set were revealed to be significantly associated with a number of signaling pathways. The present study provided a 42-gene classifier for predicting vascular invasion, and identified a vascular invasion-associated 14-gene signature for predicting prognosis in patients with HCC. Several genes and pathways in HCC development are characterized and may be potential therapeutic targets for this type of cancer.",2020,Oncology Letters
Variable selection in a flexible parametric mixture cure model with intervalâ€censored data,"In standard survival analysis, it is generally assumed that every individual will experience someday the event of interest. However, this is not always the case, as some individuals may not be susceptible to this event. Also, in medical studies, it is frequent that patients come to scheduled interviews and that the time to the event is only known to occur between two visits. That is, the data are interval-censored with a cure fraction. Variable selection in such a setting is of outstanding interest. Covariates impacting the survival are not necessarily the same as those impacting the probability to experience the event. The objective of this paper is to develop a parametric but flexible statistical model to analyze data that are interval-censored and include a fraction of cured individuals when the number of potential covariates may be large. We use the parametric mixture cure model with an accelerated failure time regression model for the survival, along with the extended generalized gamma for the error term. To overcome the issue of non-stable and non-continuous variable selection procedures, we extend the adaptive LASSO to our model. By means of simulation studies, we show good performance of our method and discuss the behavior of estimates with varying cure and censoring proportion. Lastly, our proposed method is illustrated with a real dataset studying the time until conversion to mild cognitive impairment, a possible precursor of Alzheimer's disease.",2016,Statistics in Medicine
Tail behavior of dependent V-statistics and its applications,"We establish exponential inequalities and Cramer-type moderate deviation theorems for a class of V-statistics under strong mixing conditions. Our theory is developed via kernel expansion based on random Fourier features. This type of expansion is new and useful for handling many notorious classes of kernels. While the developed theory has a number of applications, we apply it to lasso-type semiparametric regression estimation and high-dimensional multiple hypothesis testing.",2019,arXiv: Statistics Theory
The development of a practical and uncomplicated predictive equation to determine liver volume from simple linear ultrasound measurements of the liver,"This study sought to develop a practical and uncomplicated predictive equation that could accurately calculate liver volumes, using multiple simple linear ultrasound measurements combined with measurements of body size. Penalized (lasso) regression was used to develop a new model and compare it to the ultrasonic linear measurements currently used clinically. A Blandâ€“Altman analysis showed that the large limits of agreement of the new model render it too inaccurate to be of clinical use for estimating liver volume per se, but it holds value in tracking disease progress or response to treatment over time in individuals, and is certainly substantially better as an indicator of overall liver size than the ultrasonic linear measurements currently being used clinically.",2016,Radiography
"Bayesian LASSO, Scale Space and Decision Making in Association Genetics","BACKGROUND
LASSO is a penalized regression method that facilitates model fitting in situations where there are as many, or even more explanatory variables than observations, and only a few variables are relevant in explaining the data. We focus on the Bayesian version of LASSO and consider four problems that need special attention: (i) controlling false positives, (ii) multiple comparisons, (iii) collinearity among explanatory variables, and (iv) the choice of the tuning parameter that controls the amount of shrinkage and the sparsity of the estimates. The particular application considered is association genetics, where LASSO regression can be used to find links between chromosome locations and phenotypic traits in a biological organism. However, the proposed techniques are relevant also in other contexts where LASSO is used for variable selection.


RESULTS
We separate the true associations from false positives using the posterior distribution of the effects (regression coefficients) provided by Bayesian LASSO. We propose to solve the multiple comparisons problem by using simultaneous inference based on the joint posterior distribution of the effects. Bayesian LASSO also tends to distribute an effect among collinear variables, making detection of an association difficult. We propose to solve this problem by considering not only individual effects but also their functionals (i.e. sums and differences). Finally, whereas in Bayesian LASSO the tuning parameter is often regarded as a random variable, we adopt a scale space view and consider a whole range of fixed tuning parameters, instead. The effect estimates and the associated inference are considered for all tuning parameters in the selected range and the results are visualized with color maps that provide useful insights into data and the association problem considered. The methods are illustrated using two sets of artificial data and one real data set, all representing typical settings in association genetics.",2015,PLoS ONE
Automatic Feature Selection via Weighted Kernels and Regularization,"Selecting important features in nonlinear kernel spaces is a difficult challenge in both classification and regression problems. This article proposes to achieve feature selection by optimizing a simple criterion: a feature-regularized loss function. Features within the kernel are weighted, and a lasso penalty is placed on these weights to encourage sparsity. This feature-regularized loss function is minimized by estimating the weights in conjunction with the coefficients of the original classification or regression problem, thereby automatically procuring a subset of important features. The algorithm, KerNel Iterative Feature Extraction (KNIFE), is applicable to a wide variety of kernels and high-dimensional kernel problems. In addition, a modification of KNIFE gives a computationally attractive method for graphically depicting nonlinear relationships between features by estimating their feature weights over a range of regularization parameters. The utility of KNIFE in selecting features through simulati...",2013,Journal of Computational and Graphical Statistics
Substanzbezogene StÃ¶rungen,"ZusammenfassungHintergrundAlkohol- und substanzmittelassoziierte StÃ¶rungen (ASUD) gehÃ¶ren zur hÃ¤ufigsten KomorbiditÃ¤t bei schizophrenen und affektiven StÃ¶rungsbildern und haben einen signifikanten negativen Einfluss auf deren Verlauf und Prognose. In der vorliegenden Studie wurden in einer multizentrischen Querschnittserhebung an 9 baden-wÃ¼rttembergischen KrankenhÃ¤usern fÃ¼r Psychiatrie und Psychotherapie Patienten mit einer Diagnose aus der ICD-10-Kategorie F2 oder F3 bezÃ¼glich eines Substanzmittelkonsums untersucht. Ziel dieser Arbeit ist es, PrÃ¤valenz und Charakteristika der ASUD an einer deutschen Stichprobe zu erheben und anhand der Ergebnisse den aktuellen Forschungsstand zu den theoretischen Konzepten der KomorbiditÃ¤t von Sucht und F2-/F3-Diagnosen zu diskutieren.MethodeSoziodemographische und krankheitsrelevante Daten wurden bei 50 konsekutiv aufgenommenen Patienten pro Zentrum mit einer verkÃ¼rzten Version des EuropASI erhoben, die Aussagen zum aktuellen Drogenkonsum wurden mit einem Urin-Drogenscreening objektiviert. Neben korrelativen Analysen dienten Regressionsanalysen zur Untersuchung prÃ¤diktiver Variablen fÃ¼r einen Substanzkonsum.ErgebnisseDie Stichprobe umfasste 448Â Patienten, Doppeldiagnosen aus den ICD-Klassifikationen F2x und F1x wiesen 169Â Patienten (37,7%) und mit den Klassifikationen F3x und F1x 144Â Patienten (32,1%) auf. 64Â Patienten (14,3%) hatten eine F2-Diagnose und 71Â Patienten (15,8%) eine F3-Diagnose jeweils ohne ASUD. Neben Alkohol (nâ€‰=â€‰268) und Tabak (nâ€‰=â€‰325) wurden verordnete und nichtverordnete Hypnotika/Tranquilizer (nâ€‰=â€‰214), Cannabis (nâ€‰=â€‰156), Psychostimulanzien (nâ€‰=â€‰96), Opiate (nâ€‰=â€‰71) und Halluzinogene (nâ€‰=â€‰36) konsumiert. Die hÃ¤ufigste Kombination und lÃ¤ngste Einnahmedauer umfassen anamnestisch und aktuell Tabak, Alkohol, Hypnotika/Tranquilizer, Cannabis und Psychostimulanzien vor allem bei MÃ¤nnern mit schizophrenen StÃ¶rungen. Hinsichtlich der Motivation vor Erstkonsum standen allgemeine psychische AnpassungsstÃ¶rungen (51%), Peer-EinflÃ¼sse (42%) und unspezifische affektive Symptome im Vordergrund. Patienten mit schizophrenen und affektiven Erkrankungen mit komorbidem ASUD leiden signifikant hÃ¤ufiger unter substanzmittelassoziierten StÃ¶rungen im familiÃ¤ren Umfeld und suizidaler GefÃ¤hrdung als Patienten ohne Substanzmissbrauch.SchlussfolgerungDie im Querschnitt erfassten hohen PrÃ¤valenzwerte und die Bedeutung des Konsums von Nikotin, Alkohol sowie von Cannabis und Psychostimulanzien bei Patienten mit F2- und F3-Diagnosen erfordern effektivere prÃ¤ventive und stÃ¶rungsspezifische therapeutische MaÃŸnamen.SummaryBackgroundAlcohol and substance use disorders (ASUD) are considered to be among the most frequent comorbidities in schizophrenic and affective psychoses and have a significant negative influence on their course and prognosis. In the present study patients with diagnosis from the ICD-10 category F2 or F3 were examined regarding a substance use disorder in a multicentre cross-section evaluation at nine psychiatric hospitals in Baden-WÃ¼rttemberg. The aim of this study is to discuss the current research on substance use disorders and psychosis comorbidity regarding the theoretical models by means of collected data.MethodsThe examination of 50 consecutive admissions per centre is based on a shortened version of the European Severity Index (Europ ASI). An initial urine drug screening was carried out with all patients after admission. Statistical assessment was based on percentage distributions, mean values, standard deviations and suitable correlation analysis.ResultsThe representative sample included 448 patients. A proportion of 169 patients (37.7%) had a dual diagnosis F2 and F1 and a proportion of 144 patients (32.1%) had a dual diagnosis F3 and F1; 64 patients (14.3%) had an F2 diagnosis and 71 patients (15.8%) had an F3 diagnosis without ASUD. Apart from lifetime use of alcohol (nâ€‰=â€‰268) and tobacco (nâ€‰=â€‰325) hypnotics/tranquilizers (nâ€‰=â€‰214), cannabis (nâ€‰=â€‰156), opioids (nâ€‰=â€‰71), stimulants (nâ€‰=â€‰96) and hallucinogens (nâ€‰=â€‰36) were consumed. The most frequent combination and long-term intake consisted of tobacco, alcohol, hypnotics/tranquilizer, cannabis and psychostimulants especially in men with schizophrenic disorders. Regarding motivation before first substance use general psychological adjustment disorders (51%), peer impact (42%) and unspecific affective symptoms were predominant.ConclusionsAltogether the present study clearly demonstrates that patients suffering from schizophrenia, affective disorders and ASUD have significantly higher rates of more severe substance use disorders in their psychosocial environment and more suicidal behaviour than patients without substance misuse. The high rate in the cross-sectional prevalence of tobacco, alcohol, cannabis and psychostimulant use calls for more effective drug prevention.",2011,Der Nervenarzt
Supervised Learning Models,"The main objective of this chapter is to discuss various supervised learning models in detail. The supervised learning models provide parametrized mapping that projects a data domain into a response set, and thus helps extract knowledge (known) from data (unknown). These learning models, in simple form, can be grouped into predictive models and classification models. Firstly, the predictive models, such as the standard regression, ridge regression, lasso regression, and elastic-net regression are discussed in detail with their mathematical and visual interpretations using simple examples. Secondly, the classification models are discussed and grouped into three models: mathematical models, hierarchical models, and layered models. Also discussed are the mathematical models, such as the logistic regression and support vector machine; the hierarchical models, like the decision tree and the random forest; and the layered models, like the deep learning. They are discussed only from the modeling point of view, and they will be discussed in detail together as the modeling and algorithms in separate chapters later in the book.",2016,
Quantitative structure-activity relationship investigation of pyridinone derivatives as anti-HIV prodrug,"We have designed a lead HIV-1 standard transfer(ST) inhibitors strategically assembled on a pyridinone scaffold. Quantitative structure-activity relationship (QSAR) study has been done on pyridinone derivatives as anti-Hiv prodrug.Genetic algorithm (GA), Artificial neural network (ANN), Multiple linear regression (MLR), partial least squares (PLS), principal component regression (PCR), and least absolute shrinkage and selection operator (LASSO) were used to create QSAR models. The root mean square error of the calibration and R using MLR method were obtained as 0.1434 and 0.95, respectively. The R value using LASSO method were obtained as 0.98.The root mean square error of the calibration and R using PLS method were obtained as 0.02 and 0.99, respectively. According to the obtained results, it was found that GAPLS model is the most favorable method in comparison with other statistical methods and is suitable for use",2014,
Sparse seasonal and periodic vector autoregressive modeling,"Seasonal and periodic vector autoregressions are two common approaches to modeling vector time series exhibiting cyclical variations. The total number of parameters in these models increases rapidly with the dimension and order of the model, making it difficult to interpret the model and questioning the stability of the parameter estimates. To address these and other issues, two methodologies for sparse modeling are presented in this work: first, based on regularization involving adaptive lasso and, second, extending the approach of Davis et al. (2015) for vector autoregressions based on partial spectral coherences. The methods are shown to work well on simulated data, and to perform well on several examples of real vector time series exhibiting cyclical variations.",2017,Comput. Stat. Data Anal.
Investigating the determinants of timing of first childbirth among women of the reproductive age In Mozambique,"This study is aimed at investigating the determinants of timing of first childbirth among women of the reproductive age (15-49) in Mozambique. The response variable is age at first childbirth which is defined as the age, in years, at which a woman gives birth to her first child. The cross-sectional dataset used in this study was obtained from the Demographic and Health Surveys (DHS) Program 2011 and contains a total of 22 357 women. Survival analysis was used to model the determinants of age at first childbirth. Kaplan-Meier survival curves were used during exploratory data analysis to come up with some descriptive statistics while the proportional hazards (PH) model was used to model the timing of first childbirth at 5% level of significance. Prior to fitting the multivariate Cox PH model, the least absolute shrinkage and selection operator (LASSO) method was used for variable selection. The factors that were found to have an effect on age at first childbirth were educational attainment of a women, region of residence, religion and ethnicity, the knowledge of contraceptive use and the age at which the woman first engaged in sexual intercourse. The logistic regression model was used to model pregnancy outcome and stepwise method was used for variable selection. The results showed that variables like smoking, working and knowledge of contraceptive use among women of the reproductive age had a positive effect on the response while age at first sexual intercourse had a negative effect on pregnancy outcome. Other factors that had an effect on pregnancy outcome were region of residence, womanâ€™s wealth index and educational attainment. Womanâ€™s marital status and age at which she had given birth to her first child were not related to pregnancy termination. The researcher thus recommends the government of Mozambique to implement policies and programs that seek to increase educational opportunities, especially for the girl child, so as to reduce the cases of early age at first childbirth. Pregnant women are also encouraged not to smoke or do strenuous jobs as these can increase the risk of pregnancy termination as a result of spontaneous abortions or miscarriages",2019,
Stable feature selection for clinical prediction: Exploiting ICD tree structure using Tree-Lasso,"Modern healthcare is getting reshaped by growing Electronic Medical Records (EMR). Recently, these records have been shown of great value towards building clinical prediction models. In EMR data, patients' diseases and hospital interventions are captured through a set of diagnoses and procedures codes. These codes are usually represented in a tree form (e.g. ICD-10 tree) and the codes within a tree branch may be highly correlated. These codes can be used as features to build a prediction model and an appropriate feature selection can inform a clinician about important risk factors for a disease. Traditional feature selection methods (e.g. Information Gain, T-test, etc.) consider each variable independently and usually end up having a long feature list. Recently, Lasso and related l1-penalty based feature selection methods have become popular due to their joint feature selection property. However, Lasso is known to have problems of selecting one feature of many correlated features randomly. This hinders the clinicians to arrive at a stable feature set, which is crucial for clinical decision making process. In this paper, we solve this problem by using a recently proposed Tree-Lasso model. Since, the stability behavior of Tree-Lasso is not well understood, we study the stability behavior of Tree-Lasso and compare it with other feature selection methods. Using a synthetic and two real-world datasets (Cancer and Acute Myocardial Infarction), we show that Tree-Lasso based feature selection is significantly more stable than Lasso and comparable to other methods e.g. Information Gain, ReliefF and T-test. We further show that, using different types of classifiers such as logistic regression, naive Bayes, support vector machines, decision trees and Random Forest, the classification performance of Tree-Lasso is comparable to Lasso and better than other methods. Our result has implications in identifying stable risk factors for many healthcare problems and therefore can potentially assist clinical decision making for accurate medical prognosis.",2015,Journal of biomedical informatics
A Multiple-SNP Approach for Genome-Wide Association Study of Milk Production Traits in Chinese Holstein Cattle,"The multiple-SNP analysis has been studied by many researchers, in which the effects of multiple SNPs are simultaneously estimated and tested in a multiple linear regression. The multiple-SNP association analysis usually has higher power and lower false-positive rate for detecting causative SNP(s) than single marker analysis (SMA). Several methods have been proposed to simultaneously estimate and test multiple SNP effects. In this research, a fast method called MEML (Mixed model based Expectation-Maximization Lasso algorithm) was developed for simultaneously estimate of multiple SNP effects. An improved Lasso prior was assigned to SNP effects which were estimated by searching the maximum joint posterior mode. The residual polygenic effect was included in the model to absorb many tiny SNP effects, which is treated as missing data in our EM algorithm. A series of simulation experiments were conducted to validate the proposed method, and the results showed that compared with SMMA, the new method can dramatically decrease the false-positive rate. The new method was also applied to the 50k SNP-panel dataset for genome-wide association study of milk production traits in Chinese Holstein cattle. Totally, 39 significant SNPs and their nearby 25 genes were found. The number of significant SNPs is remarkably fewer than that by SMMA which found 105 significant SNPs. Among 39 significant SNPs, 8 were also found by SMMA and several well-known QTLs or genes were confirmed again; furthermore, we also got some positional candidate gene with potential function of effecting milk production traits. These novel findings in our research should be valuable for further investigation.",2014,PLoS ONE
Ensembling Variable Selectors by Stability Selection for the Cox Model,"As an effective tool to build interpretive models, variable selection plays an increasingly important role in high-dimensional data analysis. It has been proven that ensemble learning can significantly improve selection accuracy, alleviate the instability of traditional selection methods, and reduce false discovery rate (FDR). Therefore, variable selection ensembles (VSEs) have gained much interest in recent years. Stability selection [1], a VSE technique based on subsampling in combination with a base algorithm like lasso, is an effective method to control FDR and to improve selection accuracy in linear regression models. In this paper, we apply it to handle variable selection problems in a Cox model. Some simulated data with various censoring rates are used to study the influence of one parameter Amin in stability selection to its performance. In the meantime, stability selection is compared with other variable selection approaches. The experimental results demonstrate its good performance.",2017,Computational Intelligence and Neuroscience
Abstract 18948: A Clinical and Biomarker Scoring System to Predict the Presence of Obstructive Peripheral Artery Disease: Results From the Catheter Sampled Blood Archive in Cardiovascular Diseases (CASABLANCA) Study,"Introduction: Simple non-invasive tools to predict the presence of obstructive peripheral artery disease (PAD) may help reduce the need for imaging or invasive diagnostic testing. Hypothesis: In a prospective cohort of patients referred for diagnostic peripheral angiography, we hypothesized that a combination of clinical variables and biomarkers would identify patients with obstructive PAD. Methods: Among 258 patients referred for diagnostic peripheral angiography, predictors of â‰¥50% stenosis in at least one peripheral vessel were identified from over fifty clinical variables and 109 biomarkers, measured in blood obtained prior to angiography. Predictive models were generated using LASSO with logistic regression. A score derived from the final model was built with the entire population, and evaluated within the same population to predict obstructive PAD. Results: The scoring system consisted of clinical variables (body-mass index, history of hypertension) and 6 biomarkers (fetuin A, interleukin 8, kidney injury molecule 1, osteopontin, T cell specific protein RANTES and Tamm Horsfall urinary glycoprotein). The score had an area under the receiver operating characteristic curve (AUC) of 0.76 for obstructive PAD. At optimal cut-off, the score had 63% sensitivity, 75% specificity, 84% positive predictive value (PPV) and 50% negative predictive value (NPV) for obstructive PAD. When the score was divided into low risk (score of â‰¤3/10) and high risk (score of â‰¥7/10) groups, the score had a NPV of 67% and a PPV of 100% for obstructive PAD for each subgroup respectively. An elevated score predicted revascularization within 1 year follow up (hazard ratio: 2.13; p (Figure) . Conclusion: In a prospective cohort study, we derived a clinical and biomarker score with high accuracy for predicting the presence of anatomically significant PAD.",2017,Circulation
Adaptive-Lasso analysis for number of urban fires and meteorological factors,"In this paper,in order to research the relation between the number of urban fires and meteorological factors,a linear regression model is constructed on the number of fires from the fire data of Tianjin between the monthly number of fires and meteorological factors,such as the temperature,wind speed,rainfall,sunshine,and humidity.The variables above are selected,and the parameters through the Adaptive-Lasso method are estimated.Also,the model is analyzed,and the number of fires in the first half of 2008 is predictd.The research results show that the linear model established by the Adaptive-Lasso method can better predict the number of fires.",2013,Communication on Applied Mathematics and Computation
Comprehensive performance indicators for road pavement condition assessment,"AbstractThe selection and use of technical parameters and performance indicators plays an essential role in the pavement management process. It is known that if more parameters are used, a more accurate evaluation of pavement condition is achieved, improving the choice of maintenance and rehabilitation interventions. However, one of the most expensive activities of the pavement management process is data collection. Accordingly, it is necessary to find a balance between the data collected and the real needs of the process. This paper presents a new approach for the development of pavement condition indicators using a machine learning algorithm named regularised regression with lasso. The present discussion is supported by a case study, which compares the proposed method with current practice for the description of the condition of a Portuguese motorway. The results suggest that the application of machine learning methods can improve the accuracy of pavement condition indicators when less data are availabl...",2018,Structure and Infrastructure Engineering
Learning Feature Nonlinearities with Non-Convex Regularized Binned Regression,"For various applications, the relations between the dependent and independent variables are highly nonlinear. Consequently, for large scale complex problems, neural networks and regression trees are commonly preferred over linear models such as Lasso. This work proposes learning the feature nonlinearities by binning feature values and finding the best fit in each quantile using non-convex regularized linear regression. The algorithm first captures the dependence between neighboring quantiles by enforcing smoothness via piecewise-constant/linear approximation and then selects a sparse subset of good features. We prove that the proposed algorithm is statistically and computationally efficient. In particular, it achieves linear rate of convergence while requiring near-minimal number of samples. Evaluations on synthetic and real datasets demonstrate that algorithm is competitive with current state-of-the-art and accurately learns feature nonlinearities. Finally, we explore an interesting connection between the binning stage of our algorithm and sparse Johnson-Lindenstrauss matrices.",2017,ArXiv
Architecture Selection via the Trade-off Between Accuracy and Robustness,"We provide a general framework for characterizing the trade-off between accuracy and robustness in supervised learning. We propose a method and define quantities to characterize the trade-off between accuracy and robustness for a given architecture, and provide theoretical insight into the trade-off. Specifically we introduce a simple trade-off curve, define and study an influence function that captures the sensitivity, under adversarial attack, of the optima of a given loss function. We further show how adversarial training regularizes the parameters in an over-parameterized linear model, recovering the LASSO and ridge regression as special cases, which also allows us to theoretically analyze the behavior of the trade-off curve. In experiments, we demonstrate the corresponding trade-off curves of neural networks and how they vary with respect to factors such as number of layers, neurons, and across different network structures. Such information provides a useful guideline to architecture selection.",2019,ArXiv
LASSO with cross-validation for genomic selection.,"We used a least absolute shrinkage and selection operator (LASSO) approach to estimate marker effects for genomic selection. The least angle regression (LARS) algorithm and cross-validation were used to define the best subset of markers to include in the model. The LASSO-LARS approach was tested on two data sets: a simulated data set with 5865 individuals and 6000 Single Nucleotide Polymorphisms (SNPs); and a mouse data set with 1885 individuals genotyped for 10 656 SNPs and phenotyped for a number of quantitative traits. In the simulated data, three approaches were used to split the reference population into training and validation subsets for cross-validation: random splitting across the whole population; random sampling of validation set from the last generation only, either within or across families. The highest accuracy was obtained by random splitting across the whole population. The accuracy of genomic estimated breeding values (GEBVs) in the candidate population obtained by LASSO-LARS was 0.89 with 156 explanatory SNPs. This value was higher than those obtained by Best Linear Unbiased Prediction (BLUP) and a Bayesian method (BayesA), which were 0.75 and 0.84, respectively. In the mouse data, 1600 individuals were randomly allocated to the reference population. The GEBVs for the remaining 285 individuals estimated by LASSO-LARS were more accurate than those obtained by BLUP and BayesA for weight at six weeks and slightly lower for growth rate and body length. It was concluded that LASSO-LARS approach is a good alternative method to estimate marker effects for genomic selection, particularly when the cost of genotyping can be reduced by using a limited subset of markers.",2009,Genetics research
Multiclass classification by sparse multinomial logistic regression,"In this paper we consider high-dimensional multiclass classification by sparse multinomial logistic regression extending the results of Abramovich and Grinshtein (2019) for the binary case. We propose a feature selection procedure based on penalized maximum likelihood with a complexity penalty on the model size and derive the nonasymptotic bounds for misclassification excess risk of the resulting classifier. We establish also their tightness by deriving the corresponding minimax lower bounds. In particular, we show that there exist two regimes corresponding to small and large number of classes. The bounds can be reduced under the additional low noise condition. Implementation of any complexity penalty based procedure, however, requires a combinatorial search over all possible models. To find a feature selection procedure computationally feasible for high-dimensional data, we propose multinomial logistic group Lasso and Slope classifiers and show that they also achieve the optimal order in the minimax sense.",2020,ArXiv
Component Selection in the Additive Regression Model,"Similar to variable selection in the linear regression model, selecting significant components in the popular additive regression model is of great interest. However, such components are unknown smooth functions of independent variables, which are unobservable. As such, some approximation is needed. In this paper, we suggest a combination of penalized regression spline approximation and group variable selection, called the lasso-type spline method (LSM), to handle this component selection problem with a diverging number of strongly correlated variables in each group. It is shown that the proposed method can select significant components and estimate nonparametric additive function components simultaneously with an optimal convergence rate simultaneously. To make the LSM stable in computation and able to adapt its estimators to the level of smoothness of the component functions, weighted power spline bases and projected weighted power spline bases are proposed. Their performance is examined by simulation studies across two set-ups with independent predictors and correlated predictors, respectively, and appears superior to the performance of competing methods. The proposed method is extended to a partial linear regression model analysis with real data, and gives reliable results.",2010,
Identification of two microRNA signatures in whole blood as novel biomarkers for diagnosis of nasopharyngeal carcinoma,"BackgroundEarly diagnosis is critical to reduce the mortality caused by nasopharyngeal carcinoma (NPC). MicroRNAs (miRNAs) are dysregulated and play important roles in carcinogenesis. Therefore, this study aimed to identify diagnostically relevant circulating miRNA signatures in patients with NPC.MethodsTotal RNA was extracted from whole blood samples obtained from 120 patients with NPC, 30 patients with head-neck tumors (HNT), and 30 healthy subjects (HSs), and examined by using a custom microarray. The expression levels of four miRNAs identified by using the microarray were validated with quantitative real-time reverse transcription polymerase chain reaction. The 120 patients with NPC and 30 HSs were randomly assigned to training group-1 and validation group-1, respectively. By using significance analysis of microarray (SAM), the specific miRNA expression profiles in whole blood from patients with NPC are obtained. By using lasso regression and adaptive boosting, a diagnostic signature was identified in training group-1, and its accuracy was verified in validation group-1. By using the same methods, another signature to distinguish patients with NPC from those with HNT and HSs was identified in training group-2 and confirmed in validation group-2.ResultsThere were 117 differentially expressed miRNAs (upregulated and downregulated fold change â‰¥â€‰1.5) between the patients with NPC and HSs, among which an 8-miRNA signature was identified with 96.43% sensitivity and 100% specificity [area under the curve (AUC)â€‰=â€‰0.995] to diagnose NPC in training group-1 and 86.11% sensitivity and 88.89% specificity (AUCâ€‰=â€‰0.941) in validation group-1. Compared with traditional Epsteinâ€“Barr virus (EBV) seromarkers, this signature was more specific for NPC. Furthermore, a 16-miRNA signature to differentiate NPC from HNT and HS (HNT-HS) was established from 164 differentially expressed miRNAs, which diagnosed NPC and HNT-HS with 100% accuracy (AUCâ€‰=â€‰1.000) in training group-2 and 87.04% (AUCâ€‰=â€‰0.924) in validation group-2.ConclusionsThe present study identified two miRNA signatures for the highly accurate diagnosis and differential diagnosis of patients with NPC from HSs and patients with HNT. The identified miRNAs might represent novel serological biomarkers and potential therapeutic targets for NPC.",2019,Journal of Translational Medicine
Testing the prediction error difference between 2 predictors.,"We develop an inference framework for the difference in errors between 2 prediction procedures. The 2 procedures may differ in any aspect and possibly utilize different sets of covariates. We apply training and testing on the same data set, which is accommodated by sample splitting. For each split, both procedures predict the response of the same samples, which results in paired residuals to which a signed-rank test is applied. Multiple splits result in multiple p-values. The median p-value and the mean inverse normal transformed p-value are proposed as summary (test) statistics, for which bounds on the overall type I error rate under a variety of assumptions are proven. A simulation study is performed to check type I error control of the least conservative bound. Moreover, it confirms superior power of our method with respect to a one-split approach. Our inference framework is applied to genomic survival data sets to study 2 issues: compare lasso and ridge regression and decide upon use of both methylation and gene expression markers or the latter only. The framework easily accommodates any prediction paradigm and allows comparing any 2, possibly nonmodel-based, prediction procedures.",2009,Biostatistics
Development of Regression Model Using Lasso for End Milling on AL6061 Alloy,"The development of various non-ferrous materials is increasing at an exponential rate as the usage of non-ferrous materials has seen a greater than before preference over the traditional ferrous metals. Al6061 alloy has become the forerunner and is widely used in various industrial applications. This paper includes the study of machinability properties of Al6061 alloy by performing various experiments under vertical milling machine using HSS end mill cutter. Full-factorial approach was used to conduct the experimentation, a regression model was developed using Least Absolute Shrinkage and Selection Operator (Lasso) between the input parameters and output responses.",2017,
Robust least angle regression and LASSO using bootstrap aggregation (real case study: Iranian poultry farms),"Over the past ten years, many researchers and practitioners have concentrated on the topic of least angle regression, LASSO and forward stagewise (LARS) considerably instead of other subset selection models such as forward and backward stepwise. This model selection algorithm is useful and less greedy in comparison with traditional approaches similar forward stepwise. In this study, we present a taxonomy of all researches that pertains to LARS, and a review of this literature including extensions of it. Next, we introduce a robust LARS by applying bootstrap aggregation to reduce the variance of LARS model. For this purpose, we employ real world case of Iranian poultry farms so as to illustrate our proposed models. The results indicate the proposed hybrid model predicts more accurate compared to classic LARS algorithm. At last, we suggest opportunities for future research in this area.",2017,International Journal of Industrial and Systems Engineering
Prevalence and risk factors for Plasmodium falciparum malaria in pregnant women attending antenatal clinic in Bobo-Dioulasso (Burkina Faso),"BackgroundMalaria during pregnancy remains a serious public health problem. The aim of this study was to determine the prevalence and possible risk factors for malaria in pregnant women attending antenatal clinic at two primary health facilities in Bobo-Dioulasso.MethodsWe conducted a cross sectional study from September to December 2010 in two primary health facilities located in the periurban area of Bobo-Dioulasso. Pregnant women attending antenatal clinic (ANC) were included in the study after signing informed consent. For each participant, the social-demographic profile, malaria and obstetric histories were investigated through a questionnaire. Peripheral blood was collected and thick and thin blood smears were prepared to check Plasmodium falciparum parasitaemia. Hemoglobin concentration was measured. The associations between age, parity, gestational age, schooling, number of ANC visits, use of IPTp-SP, use of insecticide-treated nets (ITN) and anemia with the occurrence of P. falciparum malaria infection during pregnancy were analyzed through logistic regression.ResultsDuring the period of study, 105 (18.1%) out of 579 pregnant women were infected by P. falciparum. The hemoglobin concentration mean was 10.5 Â± 1.7/dL and was significantly lower in pregnant women with malaria infection (9.8 g/dL Â±1.6) than in those who had no malaria infection (10.6 g/dL Â±1.7) (P < 0.001). Multivariate analysis indicated that, education (AOR 1.9, 95% CI = [1.2-3.2]), parity [primigravidae (AOR 5.0, 95% CI = [2.5-9.8]) and secundigravidae (AOR 2.1, 95% CI = [1.2-3.8])], and anaemia (AOR 2.1, 95% CI = [1.3-3.5]) were significantly associated with P. falciparum malaria infection. The use of IPTp-SP was not associated with P. falciparum malaria infection.ConclusionsP. falciparum malaria infection is common in pregnant women attending antenatal clinic and anaemia is an important complication. The results show that the use of IPTp-SP does not reduce the risk of malaria incidence during pregnancy.",2014,BMC Infectious Diseases
